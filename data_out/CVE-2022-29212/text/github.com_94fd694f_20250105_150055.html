
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Ff3b9bf4c3c0597563b289c0512e98d4ce81f886e%2Ftensorflow%2Flite%2Fkernels%2Finternal%2Fquantization_util.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Ff3b9bf4c3c0597563b289c0512e98d4ce81f886e%2Ftensorflow%2Flite%2Fkernels%2Finternal%2Fquantization_util.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  831](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 f3b9bf4
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e)
2. /[tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow)
3. /[lite](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite)
4. /[kernels](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite/kernels)
5. /[internal](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite/kernels/internal)
/
# quantization\_util.cc

 Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite/kernels/internal/quantization_util.cc)416 lines (375 loc) · 15.9 KB f3b9bf4
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e)
2. /[tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow)
3. /[lite](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite)
4. /[kernels](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite/kernels)
5. /[internal](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite/kernels/internal)
/
# quantization\_util.cc

Top
## File metadata and controls

* Code
* Blame

416 lines (375 loc) · 15.9 KB[Raw](https://github.com/tensorflow/tensorflow/raw/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/lite/kernels/internal/quantization_util.cc)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416/\* Copyright 2017 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#include "tensorflow/lite/kernels/internal/quantization\_util.h"
#include <algorithm>#include <cmath>#include <limits>
#include "tensorflow/lite/kernels/internal/compatibility.h"#include "tensorflow/lite/kernels/internal/cppmath.h"
namespace tflite {
namespace {// These constants are used to manipulate the binary representation of doubles.// Double-precision binary64 floating point format is:// Bit | 63 | 62-52 | 51-0 |// | Sign | Exponent | Fraction |// To avoid 64-bit integers as much as possible, I break this into high and// low 32-bit chunks. High is:// Bit | 31 | 30-20 | 19-0 |// | Sign | Exponent | High Fraction |// Low is:// Bit | 31-0 |// | Low Fraction |// We then access the components through logical bit-wise operations to// extract the parts needed, with the positions and masks derived from the// layout shown above.constexpr uint64\_t kSignMask = 0x8000000000000000LL;constexpr uint64\_t kExponentMask = 0x7ff0000000000000LL;constexpr int32\_t kExponentShift = 52;constexpr int32\_t kExponentBias = 1023;constexpr uint32\_t kExponentIsBadNum = 0x7ff;constexpr uint64\_t kFractionMask = 0x000fffffffc00000LL;constexpr uint32\_t kFractionShift = 22;constexpr uint32\_t kFractionRoundingMask = 0x003fffff;constexpr uint32\_t kFractionRoundingThreshold = 0x00200000;} // namespace
void QuantizeMultiplier(double double\_multiplier, int32\_t\* quantized\_multiplier, int\* shift) {#if TFLITE\_SINGLE\_ROUNDING // Single-rounding MultiplyByQuantizedMultiplier only supports positive // multipliers. // TFLITE\_DCHECK(double\_multiplier >= 0);#endif if (double\_multiplier == 0.) { \*quantized\_multiplier = 0; \*shift = 0; return; }#ifdef TFLITE\_EMULATE\_FLOAT // If we're trying to avoid the use of floating-point instructions (for // example on microcontrollers) then use an alternative implementation // that only requires integer and bitwise operations. To enable this, you // need to set the define during the build process for your platform. int64\_t q\_fixed = IntegerFrExp(double\_multiplier, shift);#else // TFLITE\_EMULATE\_FLOAT const double q = std::frexp(double\_multiplier, shift); auto q\_fixed = static\_cast<int64\_t>(TfLiteRound(q \* (1LL << 31)));#endif // TFLITE\_EMULATE\_FLOAT TFLITE\_CHECK(q\_fixed <= (1LL << 31)); if (q\_fixed == (1LL << 31)) { q\_fixed /= 2; ++\*shift; } TFLITE\_CHECK\_LE(q\_fixed, std::numeric\_limits<int32\_t>::max()); // A shift amount smaller than -31 would cause all bits to be shifted out // and thus all results would be zero. We implement that instead with // q\_fixed==0, so as to avoid hitting issues with right-shift // operations with shift amounts greater than 31. Note that this happens // roughly when abs(double\_multiplier) < 2^-31 and the present handling means // that we're effectively flushing tiny double\_multiplier's to zero. // We could conceivably handle values in the range (roughly) [32, 63] // as 'denormals' i.e. (shift==0, q\_fixed < 2^30). In that point of view // the present handling is just doing 'flush denormals to zero'. We could // reconsider and actually generate nonzero denormals if a need arises. if (\*shift < -31) { \*shift = 0; q\_fixed = 0; }#if TFLITE\_SINGLE\_ROUNDING // Single-rounding MultiplyByQuantizedMultiplier doesn't support a shift > 30, // saturate it. if (\*shift > 30) { \*shift = 30; q\_fixed = (1LL << 31) - 1; }#endif \*quantized\_multiplier = static\_cast<int32\_t>(q\_fixed);}
void QuantizeMultiplierGreaterThanOne(double double\_multiplier, int32\_t\* quantized\_multiplier, int\* left\_shift) { TFLITE\_CHECK\_GT(double\_multiplier, 1.); QuantizeMultiplier(double\_multiplier, quantized\_multiplier, left\_shift); TFLITE\_CHECK\_GE(\*left\_shift, 0);}
void QuantizeMultiplierSmallerThanOneExp(double double\_multiplier, int32\_t\* quantized\_multiplier, int\* left\_shift) { TFLITE\_CHECK\_LT(double\_multiplier, 1.); TFLITE\_CHECK\_GT(double\_multiplier, 0.); int shift; QuantizeMultiplier(double\_multiplier, quantized\_multiplier, &shift); TFLITE\_CHECK\_LE(shift, 0); \*left\_shift = shift;}
int64\_t IntegerFrExp(double input, int\* shift) { // Make sure our assumptions about the double layout hold. TFLITE\_CHECK\_EQ(8, sizeof(double));
 // We want to access the bits of the input double value directly, which is // tricky to do safely, so use a union to handle the casting. union { double double\_value; uint64\_t double\_as\_uint; } cast\_union; cast\_union.double\_value = input; const uint64\_t u = cast\_union.double\_as\_uint;
 // If the bitfield is all zeros apart from the sign bit, this is a normalized // zero value, so return standard values for this special case. if ((u & ~kSignMask) == 0) { \*shift = 0; return 0; }
 // Deal with NaNs and Infs, which are always indicated with a fixed pattern in // the exponent, and distinguished by whether the fractions are zero or // non-zero. const uint32\_t exponent\_part = ((u & kExponentMask) >> kExponentShift); if (exponent\_part == kExponentIsBadNum) { \*shift = std::numeric\_limits<int>::max(); if (u & kFractionMask) { // NaN, so just return zero (with the exponent set to INT\_MAX). return 0; } else { // Infinity, so return +/- INT\_MAX. if (u & kSignMask) { return std::numeric\_limits<int64\_t>::min(); } else { return std::numeric\_limits<int64\_t>::max(); } } }
 // The shift is fairly easy to extract from the high bits of the double value, // just by masking it out and applying a bias. The std::frexp() implementation // always returns values between 0.5 and 1.0 though, whereas the exponent // assumes 1.0 to 2.0 is the standard range, so I add on one to match that // interface. \*shift = (exponent\_part - kExponentBias) + 1;
 // There's an implicit high bit in the double format definition, so make sure // we include that at the top, and then reconstruct the rest of the fractional // value from the remaining fragments. int64\_t fraction = 0x40000000 + ((u & kFractionMask) >> kFractionShift);
 // We're cutting off some bits at the bottom, so to exactly match the standard // frexp implementation here we'll apply rounding by adding one to the least // significant bit of the result if the discarded portion is over half of the // maximum. if ((u & kFractionRoundingMask) > kFractionRoundingThreshold) { fraction += 1; } // Negate the fraction if the sign bit was set. if (u & kSignMask) { fraction \*= -1; }
 return fraction;}
double DoubleFromFractionAndShift(int64\_t fraction, int shift) { union { double double\_value; uint64\_t double\_as\_uint; } result;
 // Detect NaNs and infinities. if (shift == std::numeric\_limits<int>::max()) { if (fraction == 0) { return std::numeric\_limits<double>::quiet\_NaN(); } else if (fraction > 0) { return std::numeric\_limits<double>::infinity(); } else { return -std::numeric\_limits<double>::infinity(); } }
 // Return a normalized zero for a zero fraction. if (fraction == 0) { result.double\_as\_uint = 0; return result.double\_value; }
 bool is\_negative = (fraction < 0); int64\_t encoded\_fraction = is\_negative ? -fraction : fraction; int64\_t encoded\_shift = (shift - 1); while (encoded\_fraction < 0x40000000) { encoded\_fraction \*= 2; encoded\_shift -= 1; } while (encoded\_fraction > 0x80000000) { encoded\_fraction /= 2; encoded\_shift += 1; } encoded\_fraction -= 0x40000000; if (encoded\_shift < -1022) { encoded\_shift = -1023; } else if (encoded\_shift > 1022) { encoded\_shift = 1023; } encoded\_shift += kExponentBias; uint64\_t encoded\_sign = is\_negative ? kSignMask : 0; result.double\_as\_uint = encoded\_sign | (encoded\_shift << kExponentShift) | (encoded\_fraction << kFractionShift); return result.double\_value;}
double IntegerDoubleMultiply(double a, double b) { int a\_shift; const int64\_t a\_fraction = IntegerFrExp(a, &a\_shift); int b\_shift; const int64\_t b\_fraction = IntegerFrExp(b, &b\_shift); // Detect NaNs and infinities. if (a\_shift == std::numeric\_limits<int>::max() || (b\_shift == std::numeric\_limits<int>::max())) { return std::numeric\_limits<double>::quiet\_NaN(); } const int result\_shift = a\_shift + b\_shift + 1; const int64\_t result\_fraction = (a\_fraction \* b\_fraction) >> 32; return DoubleFromFractionAndShift(result\_fraction, result\_shift);}
int IntegerDoubleCompare(double a, double b) { int a\_shift; const int64\_t a\_fraction = IntegerFrExp(a, &a\_shift); int b\_shift; const int64\_t b\_fraction = IntegerFrExp(b, &b\_shift);
 // Detect NaNs and infinities. if (a\_shift == std::numeric\_limits<int>::max() || (b\_shift == std::numeric\_limits<int>::max())) { return 1; }
 if ((a\_fraction == 0) && (b\_fraction < 0)) { return 1; } else if ((a\_fraction < 0) && (b\_fraction == 0)) { return -1; } else if (a\_shift < b\_shift) { return -1; } else if (a\_shift > b\_shift) { return 1; } else if (a\_fraction < b\_fraction) { return -1; } else if (a\_fraction > b\_fraction) { return 1; } else { return 0; }}
void PreprocessSoftmaxScaling(double beta, double input\_scale, int input\_integer\_bits, int32\_t\* quantized\_multiplier, int\* left\_shift) { // If the overall multiplier (input and beta) is large, then exp() of an // input difference of 1 scaled by this will be large. In other words, we // can cap the multiplier and know that, when it is used, the output will be // (round to) zero wherever the input is not at the maximum value.
 // If the overall scale is less than one, and input\_integer\_bits=0, then the // result is double equivalent of Q0.31 (actually with more precision). Thus // this generates a Q(input\_integer\_bits).(31-input\_integer\_bits) // representation.#if TFLITE\_SINGLE\_ROUNDING const double max\_real\_multiplier = (1LL << 30) - 1.0;#else const double max\_real\_multiplier = (1LL << 31) - 1.0;#endif
#ifdef TFLITE\_EMULATE\_FLOAT const double input\_beta = IntegerDoubleMultiply(beta, input\_scale); int shift; int64\_t fraction = IntegerFrExp(input\_beta, &shift); shift += (31 - input\_integer\_bits); double input\_beta\_real\_multiplier = DoubleFromFractionAndShift(fraction, shift); if (IntegerDoubleCompare(input\_beta\_real\_multiplier, max\_real\_multiplier) > 0) { input\_beta\_real\_multiplier = max\_real\_multiplier; }#else // TFLITE\_EMULATE\_FLOAT const double input\_beta\_real\_multiplier = std::min<double>(beta \* input\_scale \* (1 << (31 - input\_integer\_bits)), max\_real\_multiplier);#endif // TFLITE\_EMULATE\_FLOAT
 QuantizeMultiplierGreaterThanOne(input\_beta\_real\_multiplier, quantized\_multiplier, left\_shift);}
void PreprocessLogSoftmaxScalingExp(double beta, double input\_scale, int input\_integer\_bits, int32\_t\* quantized\_multiplier, int\* left\_shift, int32\_t\* reverse\_scaling\_divisor, int\* reverse\_scaling\_left\_shift) { PreprocessSoftmaxScaling(beta, input\_scale, input\_integer\_bits, quantized\_multiplier, left\_shift);
 // Also calculate what amounts to the inverse scaling factor for the input. const double real\_reverse\_scaling\_divisor = (1 << (31 - \*left\_shift)) / static\_cast<double>(\*quantized\_multiplier); tflite::QuantizeMultiplierSmallerThanOneExp(real\_reverse\_scaling\_divisor, reverse\_scaling\_divisor, reverse\_scaling\_left\_shift);}
int CalculateInputRadius(int input\_integer\_bits, int input\_left\_shift, int total\_signed\_bits) {#ifdef TFLITE\_EMULATE\_FLOAT int64\_t result = (1 << input\_integer\_bits) - 1; result <<= (total\_signed\_bits - input\_integer\_bits); result >>= input\_left\_shift; return result;#else // TFLITE\_EMULATE\_FLOAT const double max\_input\_rescaled = 1.0 \* ((1 << input\_integer\_bits) - 1) \* (1LL << (total\_signed\_bits - input\_integer\_bits)) / (1LL << input\_left\_shift); // Tighten bound using floor. Suppose that we could use the exact value. // After scaling the difference, the result would be at the maximum. Thus we // must ensure that our value has lower magnitude. return static\_cast<int>(std::floor(max\_input\_rescaled));#endif // TFLITE\_EMULATE\_FLOAT}
void NudgeQuantizationRange(const float min, const float max, const int quant\_min, const int quant\_max, float\* nudged\_min, float\* nudged\_max, float\* nudged\_scale) { // This code originates from tensorflow/core/kernels/fake\_quant\_ops\_functor.h. const float quant\_min\_float = static\_cast<float>(quant\_min); const float quant\_max\_float = static\_cast<float>(quant\_max); \*nudged\_scale = (max - min) / (quant\_max\_float - quant\_min\_float); const float zero\_point\_from\_min = quant\_min\_float - min / \*nudged\_scale; uint16\_t nudged\_zero\_point; if (zero\_point\_from\_min < quant\_min\_float) { nudged\_zero\_point = static\_cast<uint16\_t>(quant\_min); } else if (zero\_point\_from\_min > quant\_max\_float) { nudged\_zero\_point = static\_cast<uint16\_t>(quant\_max); } else { nudged\_zero\_point = static\_cast<uint16\_t>(TfLiteRound(zero\_point\_from\_min)); } \*nudged\_min = (quant\_min\_float - nudged\_zero\_point) \* (\*nudged\_scale); \*nudged\_max = (quant\_max\_float - nudged\_zero\_point) \* (\*nudged\_scale);}
void FakeQuantizeArray(const float nudged\_scale, const float nudged\_min, const float nudged\_max, const float\* input\_data, float\* output\_data, const float size) { // This code originates from tensorflow/core/kernels/fake\_quant\_ops\_functor.h. const float inv\_nudged\_scale = 1.0f / nudged\_scale;
 for (int i = 0; i < size; i++) { const float src\_val = input\_data[i]; const float clamped = std::min(nudged\_max, std::max(nudged\_min, src\_val)); const float clamped\_shifted = clamped - nudged\_min; const float dst\_val = TfLiteRound(clamped\_shifted \* inv\_nudged\_scale) \* nudged\_scale + nudged\_min; output\_data[i] = dst\_val; }}
bool CheckedLog2(const float x, int\* log2\_result) { // Using TfLiteRound instead of std::round and std::log instead of // std::log2 to work around these functions being missing in a toolchain // used in some TensorFlow tests as of May 2018. const float x\_log2 = std::log(x) \* (1.0f / std::log(2.0f)); const float x\_log2\_rounded = TfLiteRound(x\_log2); const float x\_log2\_fracpart = x\_log2 - x\_log2\_rounded;
 \*log2\_result = static\_cast<int>(x\_log2\_rounded); return std::abs(x\_log2\_fracpart) < 1e-3f;}
void QuantizeMultiplierArray(const double\* effective\_scales, size\_t size, int32\_t\* effective\_scale\_significand, int\* effective\_shift) { for (size\_t i = 0; i < size; ++i) { QuantizeMultiplier(effective\_scales[i], &effective\_scale\_significand[i], &effective\_shift[i]); }}
} // namespace tflite

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

