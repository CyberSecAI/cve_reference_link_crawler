```
{
  "vulnerability_details": {
    "root_cause": "The vulnerability lies in the `_load_model` function within `mlflow/pytorch/__init__.py`. It uses `torch.load` to deserialize a PyTorch model from a file path, which allows an attacker to inject a malicious pickle object into the model during the saving process. During the model loading process using `torch.load` this malicious code will be executed.",
    "weaknesses": [
      "Deserialization of untrusted data",
      "Code Injection"
    ],
    "impact": "Remote code execution on the victim's machine.",
    "attack_vectors": [
      "Attacker crafts a malicious PyTorch model containing a malicious pickle object",
      "Attacker logs the malicious model to an MLflow tracking server using `mlflow.pytorch.log_model`",
      "Victim loads the model from the MLflow server using `mlflow.pytorch.load_model`"
    ],
    "attacker_capabilities": "The attacker needs to be able to create and log a malicious PyTorch model to a server accessible to the victim, or trick the victim into using a model created by an attacker."
  }
}
```