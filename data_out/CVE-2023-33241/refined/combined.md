=== Content from www.fireblocks.com_8faec3e9_20250111_113511.html ===


[Skip To Content](#main)

[Fireblocks](https://www.fireblocks.com)

Menu

* Platform
  + Back
    #### Platform

    ### Products

    - #### Treasury Management

      Manage and secure your digital asset treasury and trading operations.
    - #### Wallets as a Service

      Create secure MPC wallets at scale | Embedded Wallets and Direct Custody Wallets
    - #### Tokenization

      Securely mint, custody, and transfer tokenized assets and manage smart contracts.
    - #### Payments

      Suite of tools to accept, orchestrate, and settle digital asset payments.
  + ### Platform

    - #### Governance and Policy Engine

      Automate permissions, transaction rules, and approvals
    - #### Security

      Multi-layer key management, certifications, policies.
    - #### Staking

      Stake tokens and manage rewards across blockchains.
    - #### Compliance

      Automate detection and removal of high-risk transactions.
    - #### Fireblocks Network

      Simplify transfers and trading with trusted counterparties.
    - #### Off-Exchange

      Eliminate exchange counterparty risk
    - #### Flexible Deployment

      Cloud, Hybrid, On-Prem
    - #### DeFi

      Create and manage wallets for end users at scale.
    - #### Web3

      Automate permissions, transaction rules, and approvals.
    - #### Automation

      Eliminate manual operations in minutes[All Support and Integrations](/integrations/exchanges)
* Solutions
  + Back
    #### Solutions

    ### SOLUTIONS

    - #### Trading Firms
    - #### Fintechs and Exchanges
    - #### Financial Institutions
    - #### Web3 Companies
    - #### Blockchain Payments
    - #### Startups
  + ### ECOSYSTEM

    - #### Partners
    - #### Professional Services
    - #### Support
* Resources
  + Back
    #### Resources

    ###

    - #### SPARK
    - #### Blogs
    - #### Webinars
    - #### Customer Stories
    - #### White Papers and Guides
    - #### Fireblocks Academy
    - #### ETH Savings Calculator
  + ###
* [Developers](https://www.fireblocks.com/developers/)
* Company
  + Back
    #### Company

    ###

    - #### About Fireblocks
    - #### Executive Team
    - #### Culture
    - #### Careers
  + ###
* [Pricing](https://www.fireblocks.com/pricing/)
* [Login](https://console.fireblocks.io/)
* [Try in Sandbox](https://www.fireblocks.com/developer-sandbox-sign-up/)
* [Request Demo](https://www.fireblocks.com/#request-demo/)

![](/wp-content/themes/studio-simpatico/public/img/orange-blur.svg)
![](/wp-content/themes/studio-simpatico/public/img/blue-blur.svg)

August 9, 2023

[Knowledge Base](https://www.fireblocks.com/category/knowledge-base/)

# GG18 and GG20 Paillier Key Vulnerability [CVE-2023-33241]: Technical Report

[![Marketing Headshot](https://www.fireblocks.com/wp-content/uploads/2024/05/FB-user-profile.jpg)

Daniel Evans

Marketing](https://www.fireblocks.com/author/daniel-evans)

9 min. read
![](https://www.fireblocks.com/wp-content/uploads/2023/08/Fireblocks-BitForge-Tech-GG-Blog_2x-1024x572.jpg)

This newfound vulnerability allows an attacker to extract a full private key from any wallet using the GG18 and GG20 protocols. More than 10 wallets and libraries have been found vulnerable, including Binance custody.

## Executive Summary

Fireblocks’ research team has discovered a vulnerability in the specification of two popular multi-party computation (MPC) protocols: [GG18](https://eprint.iacr.org/2019/114) and [GG20](https://eprint.iacr.org/2020/540). These protocols are considered pioneering for the MPC wallet industry and have been widely adopted by companies in the space. The vulnerability was found at the pseudocode level, and **all vendors implementing the protocol should be considered vulnerable**. The vulnerability can be exploited **to exfiltrate the key.**

The vulnerability originates with parties not checking to see if the attacker’s Paillier modulus, denoted N, has small factors or that it is a biprime. If exploited, the vulnerability allows a threat actor interacting with the signatories in the MPC protocol to steal their secret shards and ultimately obtain the master secret key. The severity of the vulnerability depends on the implementation parameters, so different parameter choices give rise to different attacks with varying degrees of effort/resources required to extract the full key. **Some implementations are vulnerable to key extraction in 16 signatures**, while others could require as many as 1 billion signatures.

The exploit was validated on major open source implementations and a working POC was built on one of the open libraries.

We ran a responsible disclosure process with more than 10 wallet providers, blockchains and libraries in parallel and actively looked for impacted products, but given the popularity of the protocols we assume additional products might be impacted.

## Vulnerability Risk Profile

The vulnerability is a full private key extraction vulnerability allowing the attacker to steal all funds that are kept in the crypto wallet. The main source of the vulnerability is that the signatories’ Paillier public keys are not checked for small prime factors, where a prime of size, sayß, 2\*\*20 is considered small.

Since the severity of the vulnerability depends on the implementation parameters, different parameter choices give rise to different attacks with varying degrees of effort/resources required to extract the full key. Namely, the distinguishing parameter choices are as follows:

**1.** Beta Parameter in MTA ~ q^5 (where q is the size of the elliptic curve)

**2.** Beta Parameter in MTA ~ N (where N is the Paillier public key of the compromised party

*a. N is not checked for small factors at all (not even 3,5,7,..)*
*b. N is checked manually for smallish factors (< 2\*\*12)*

***Case 1.*** By using maliciously-crafted messages, the attacker obtains leakage of the private key shards of the parties by interacting with the signatories in the first round of the MPC protocol. To obtain the full private key, it is sufficient to iterate the attack **sixteen** times.

A specific sub-scenario of Case1 was identified in the [Apache Milagro](https://github.com/apache/incubator-milagro-MPC) library which had an extremely low beta parameter (256 bits) allowing an attacker to extract the key without crafting any malicious messages and simply recovering the key from the transcript of the signature ceremony.

***Case 2.*** In this case, the attacker actively controls one of the signatories (so it also needs to “know” the corresponding secret shard) and interacts with the signatories for the entire MPC protocol. By using maliciously-crafted messages, the attacker obtains leakage of the private key shards whenever the signature generation process terminates successfully. The total number of signature-generation attempts depends on the number of parties and the malicious Paillier modulus N. For two parties, the number of (failed) signatures ranges from 200K (for case 2.a) to 1B (for case 2.b).

## Recommended mitigation for clients

Since GG18/20 is a widely used MPC protocol and the vulnerability affects all users of the protocol it’s important to understand what parameters are being used and act accordingly. If you are using an open source library please make sure that it was upgraded. Some of the commonly used libraries for GG18/20 are no longer actively maintained and using them can be risky.

To fix the issue, we recommend using a key-generation process that can detect maliciously formed Paillier modulus using a suitable ZK proof.

## A short introduction to MPC and GG 18/20 protocol

Multi-party computation (MPC)offers an innovative way for several parties to collaboratively generate a shared public key and jointly sign transactions, thereby eliminating the risk of a single point of failure. Specifically, within a MPC-enabled wallet, an attacker must breach a sufficient number of parties possessing a *key share*. This contrasts with the traditional non-threshold paradigm, where compromising a single party suffices to gain control of the wallet.

The Elliptic Curve Digital Signature Algorithm (ECDSA) is the preferred signature scheme within the blockchain space. Even though ECDSA is a traditional non-threshold signature scheme, it can be transformed into a threshold variant through MPC.

GG18, along with the follow-up GG20, are among the most widely-used MPC protocols for threshold-ECDS. Both protocols make extensive use of advanced cryptographic techniques like homomorphic (Paillier) encryption and zero-knowledge proofs. At a high level, the parties in the protocol perform calculations and exchange messages in a predetermined way, and the protocol uses zero-knowledge proofs to validate that no party deviates from the protocol instructions.

## Technical Attack Description

The attack differs depending on the beta parameter, so in this section we will be talking about two separate attacks.

Our first attack (case 1) exfiltrates the key in 16-bit chunks at a time and 16 signatures suffice to recover the key in full, regardless of the number of parties.

Our second attack (case 2) exfiltrates the key also 16 bits at a time but the success probability of the attacker (i.e. the probability that the attack will result in leakage) is somewhat small, and thus the attack needs to be iterated many times (as many as 1B in certain cases) in order to recover the key in full. Furthermore, our second attack deteriorates with the number of parties, so recovering the key in full when a single party is compromised against two honest parties is twice as expensive, in terms of the number of required signatures to extract the key, compared to a single honest party.

Both of our attacks target the so-called Multiplication-to-Addition phase which proceeds as follows (this phase of the protocol is executed between each pair of parties; for simplicity we only assume two parties, A and B).

**1.** A sends Enc(k) to B encrypted under A’s own Paillier pk N, where k is a random value.

*A also sends a zero-knowledge proof (ZKP) that k is not-too-big a value*

**2.** B sends Enc(k\*x + \beta) to A by homomorphically evaluating the above, where \beta is a random value and x is B’s ECDSA private share.

*B also sends a ZKP that calculates the above correctly.*

**3.** A outputs \alpha = k\*x + \beta % N by decrypting the above and B outputs \beta

**Prep for both attacks.** Party is malicious in both attacks and A picks a Paillier modulus composed of 16 small primes p1, … p16 of bit-length 16, and a single big prime q (to match the expected length of N). A sets N = p1p2…p16\*q

Then, for both attacks,

**1.** A will choose a malicious k = N/pi (this choice is malicious because k is almost as big as N which the ZKP is supposed to detect)

*The value of k is updated after each successful attack (k= N/p1, N/p2, N/p3…)*

**2.** A cheats in the ZKP to pass the malicious k as benign.

*We omit the details of the above which can be found in the technical research paper.*

**Case 1.**

As soon as A obtains \alpha, it deduces x % pi = (\alpha – [\alpha % N/pi])/ (N/pi)

After 16 signature attempts in total, A recovers the x’s in full from all parties using Chinese Remainder Theorem (CRT).

**Case 2.**

The previous leakage is no longer relevant because the value of \alpha is implicitly reduced modulo N on B’s side, and, because beta is as big as N, \alpha perfectly hides x. To obtain leakage on x, compromised party A does the following: it guesses that x \mod pi = y (at random) and reassigns \alpha = \alpha – y \* N/pi % N, and proceeds as the protocol prescribes until the end.

If the signature is valid at the end of the execution, then the guess was correct and A proceeds to the next attack. If the signature is invalid there is no leakage (it may be that x \mod pi = y and yet the signature is invalid because of other random choices in the attack).

After 16 successful leakages for each of the honest parties, A recovers the secret in full using the Chinese remainder theorem.

*On the expected number of signatures to extract the key.* We note that there is a tradeoff between the number of signatures, the number of honest, non-compromised, parties, and the size of the primes. For instance, in the presence of a single non-compromised party, when choosing the smallest possible primes {3,5,..,} our attack extracts the key with probability 2\*\*(-40) after 200K signatures, or with probability 0.5 after approx 1M signatures.

For bigger primes, e.g. choosing p1, p2, … t be roughly 2\*\*12, our attack extracts the key with probability 0.15 after 2B signatures (cf. research document).

### Responsible Disclosure

We found and validated the vulnerability by May 5th, 2023 and started identifying affected parties. Thus initiating a multi company 90-day responsible disclosure process with more than 10 vendors and library publishers.

On August 9th, 2023 we published our findings publicly and attached a CVE for this issue: CVE-2023-33241.

### Affected Open Source Libraries

* <https://github.com/bnb-chain/tss-lib>
* <https://github.com/Safeheron/multi-party-ecdsa-cpp> – prior to [patch](https://github.com/Safeheron/multi-party-ecdsa-cpp/commit/f99c4e87cec7434c296f4891562b55dec0d26877) (validated by library maintainers)
* <https://github.com/ZenGo-X/multi-party-ecdsa> – the GG protocols in the library are not actively maintained and not patched
* <https://github.com/apache/incubator-milagro-MPC> – prior to patch (validated by library maintainers)
* <https://github.com/BitGo/BitGoJS/tree/master/modules/sdk-core/src/bitgo/utils/tss/ecdsa>

**POC:** <https://github.com/fireblocks-labs/safeheron-gg20-exploit-poc>

**CVE Link:** <https://www.cve.org/CVERecord?id=CVE-2023-33241>

**Academic paper:** <https://github.com/fireblocks-labs/mpc-ecdsa-attacks-23>

#### Share This Article

* [![](https://www.fireblocks.com/wp-content/themes/studio-simpatico/public/img/twitter.svg)
  Share on Twitter](https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.fireblocks.com%2Fblog%2Fgg18-and-gg20-paillier-key-vulnerability-technical-report%2F)
* [![](https://www.fireblocks.com/wp-content/themes/studio-simpatico/public/img/linkedin.svg)
  Share on LinkedIn](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fwww.fireblocks.com%2Fblog%2Fgg18-and-gg20-paillier-key-vulnerability-technical-report%2F)
* [![](https://www.fireblocks.com/wp-content/themes/studio-simpatico/public/img/facebook.svg)
  Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.fireblocks.com%2Fblog%2Fgg18-and-gg20-paillier-key-vulnerability-technical-report%2F)

#### Table of Contents

[Executive Summary](#h-executive-summary)[Vulnerability Risk Profile](#h-vulnerability-risk-profile)[Recommended mitigation for clients](#h-recommended-mitigation-for-clients)[A short introduction to MPC and GG 18/20 protocol](#h-a-short-introduction-to-mpc-and-gg-18-20-protocol)[Technical Attack Description](#h-technical-attack-description)[Responsible Disclosure](#h-responsible-disclosure)[Affected Open Source Libraries](#h-affected-open-source-libraries)
#### Ready to get started?

Join the largest institutional players running their businesses with Fireblocks.

[Request Demo](/request-demo)

#### About Us

Fireblocks is an easy-to-use platform to create new blockchain based products, and manage day-to-day digital asset operations. Exchanges, banks, PSPs, lending desks, custodians, trading desks, and hedge funds can securely scale their digital asset operations through the Fireblocks Network and MPC-based Wallet Infrastructure. Fireblocks serves thousands of organizations in the financial, payments, and web3 space, has secured the transfer of over $6 trillion in digital assets and has a unique insurance policy that covers assets in storage & transit. Find out why CISOs and Ops Teams love Fireblocks at www.Fireblocks.com.

#### Topics

* Security

Get Started

* [Request Demo](https://www.fireblocks.com/request-demo)
* [Start Developing](https://www.fireblocks.com/developer-sandbox-sign-up/)

Close

###### Ready for a deeper dive?

# Get a Fireblocks Platform Demo

Find out how Fireblocks helps your digital asset business to grow fast and stay secure.

![g2 & 4.5/5 stars](https://www.fireblocks.com/wp-content/uploads/2024/10/g2-stars-1.svg)

[![Fireblocks](https://www.fireblocks.com/wp-content/themes/studio-simpatico/svgs/logo.svg)](https://www.fireblocks.com)

Fireblocks is an enterprise-grade platform delivering a secure infrastructure for moving, storing, and issuing digital assets. Fireblocks enables exchanges, custodians, banks, trading desks, and hedge funds to securely scale digital asset operations through patent-pending SGX & MPC technology.

[[email protected]](/cdn-cgi/l/email-protection#e1888f878ea187889384838d8e828a92cf828e8c)

* [Twitter](https://twitter.com/FireblocksHQ)
* [LinkedIn](https://www.linkedin.com/company/fireblocks)
* [Facebook](https://www.facebook.com/pg/FireblocksHQ)

* Platform
  + [Treasury Management](https://www.fireblocks.com/platforms/treasury-management/)
  + [Wallet as a Service](https://www.fireblocks.com/platforms/wallet-as-a-service/)
  + [Tokenization](https://www.fireblocks.com/platforms/tokenization/)
  + [Payments](https://www.fireblocks.com/platforms/payments/)
  + [Governance & Policy Engine](https://www.fireblocks.com/platforms/governance-and-policy-engine/)
  + [Off Exchange](https://www.fireblocks.com/platforms/off-exchange/)
  + [Security](https://www.fireblocks.com/platforms/security/)
  + [Staking](https://www.fireblocks.com/platforms/staking/)
  + [Web3](https://www.fireblocks.com/platforms/web3/)
  + [Fireblocks Network](https://www.fireblocks.com/platforms/fireblocks-network/)
  + [Flexible Deployment](https://www.fireblocks.com/platforms/flexible-deployment/)
  + [Compliance](https://www.fireblocks.com/platforms/compliance/)
  + [DeFi](https://www.fireblocks.com/platforms/defi)
  + [Automation](https://www.fireblocks.com/platforms/automation/)
  + [Integrations](https://www.fireblocks.com/integrations/)
  + [How Fireblocks Compares](https://www.fireblocks.com/compare/)
* Solutions
  + [Trading Firms](https://www.fireblocks.com/use-case/trading-firms/)
  + [Fintechs and Exchanges](https://www.fireblocks.com/use-case/fintechs-and-exchanges/)
  + [Financial Institutions](https://www.fireblocks.com/use-case/financial-institutions/)
  + [Web3 Companies](https://www.fireblocks.com/use-case/web3-companies/)
  + [Blockchain Payments](https://www.fireblocks.com/use-case/blockchain-payments/)
  + [Startups](https://www.fireblocks.com/startups/)
* Ecosystem
  + [Partners](https://www.fireblocks.com/partners/)
  + [Professional Services](https://www.fireblocks.com/professional-services/)
  + [Support](https://www.fireblocks.com/global-platinum-support/)
* Company
  + [About](https://www.fireblocks.com/about/)
  + [Custody & Risk Principles](https://www.fireblocks.com/principles/)
  + [Executive Team](https://www.fireblocks.com/team/)
  + [Culture](https://www.fireblocks.com/careers/)
  + [Modern Slavery Statement](https://www.fireblocks.com/modern-slavery-statement/)
  + [Careers](https://www.fireblocks.com/careers/current-openings/)
* [Developers](https://developers.fireblocks.com)
* Blog & Resources
  + [SPARK](https://www.fireblocks.com/spark/)
  + [Blog](https://www.fireblocks.com/blog/)
  + [Webinars](https://www.fireblocks.com/webinars/)
  + [Customer Stories](https://www.fireblocks.com/customers/)
  + [White Papers and Guides](https://www.fireblocks.com/resources/)
  + [Fireblocks Academy](https://www.fireblocks.com/academy/)
  + [ETH Savings Calculator](https://www.fireblocks.com/eth-fees-calculator/)
  + [Glossary](https://www.fireblocks.com/glossary/)
  + [Secure Multi-Party Computation Framework](https://www.fireblocks.com/secure-multi-party-computation-framework/)
  + [Crypto Treasury Management 101](https://www.fireblocks.com/crypto-treasury-management-101/)
  + [Digital Asset Custody 101](https://www.fireblocks.com/digital-asset-custody/)
  + [Institutional DeFi 101](https://www.fireblocks.com/institutional-defi/)
  + [MPC 101](https://www.fireblocks.com/what-is-mpc/)
* [Pricing](https://www.fireblocks.com/pricing/)
* [Request Demo](https://www.fireblocks.com/request-demo/)
* [Bug Bounty](https://hackerone.com/fireblocks_mpc)
* [Login](https://console.fireblocks.io/)

Fireblocks © 2025 All Rights Reserved. Fireblocks LLC NMLS Registration Number: 2066055

[Privacy Policy](https://www.fireblocks.com/privacy-policy/)[Cookie Policy](https://www.fireblocks.com/fireblocks-cookie-policy/)Manage Cookies[Terms of Use](https://www.fireblocks.com/terms-of-use/)[Fireblocks LLC State Licenses](https://www.fireblocks.com/state-licenses/)
![](https://www.fireblocks.com/wp-content/uploads/2025/01/FB-Footer-Badges-Jan-2025.svg)



=== Content from eprint.iacr.org_b1591bc2_20250111_113507.html ===
Fast Multiparty Threshold ECDSA with Fast Trustless
Setup

Rosario Gennaro1 and Steven Goldfeder2

1 City University of New York
rosario@cs.ccny.cuny.edu
2 Cornell Universty§
goldfeder@cornell.edu

Abstract. A threshold signature scheme enables distributed signing among n players such
that any subgroup of size t + 1 can sign, whereas any group with t or fewer players cannot.
While there exist previous threshold schemes for the ECDSA signature scheme, we present
the ﬁrst protocol that supports multiparty signatures for any t ≤ n with eﬃcient, dealerless
key generation. Our protocol is faster than previous solutions and signiﬁcantly reduces the
communication complexity as well. We prove our scheme secure against malicious adversaries
with a dishonest majority. We implemented our protocol, demonstrating its eﬃciency and
suitability to be deployed in practice.

Note: This revised version ﬁxes some crucial details in the protocol. The proof
of the protocol described in the previous version is not correct, though no attack
has been shown that exploits the bug in the proof. More details appear in the
intoduction.

1 Introduction

A threshold signature scheme enables n parties to share the power to issue digital signatures
under a single public key. A threshold t is speciﬁed such that any subset of t + 1 players can
jointly sign, but any smaller subset cannot. Generally, the goal is to produce signatures that are
compatible with an existing centralized signature scheme. In a threshold scheme the key generation
and signature algorithm are replaced by a communication protocol between the parties, but the
veriﬁcation algorithm remains identical to the veriﬁcation of a signature issued by a centralized
party.

In recent years there has been renewed attention to this topic, in particular to the threshold
generation of ECDSA signatures, mostly due to the use of ECDSA in Bitcoin and other cryptocur-
rencies. Indeed, a secure threshold signature schemes for ECDSA would be an eﬀective counter-
measure to the constant theft of bitcoins due to the compromise of the secret signing key that
authorizes transactions. Securing Bitcoin is equivalent to securing these keys. Instead of storing
them in a single location, keys should be split and signing should be authorized by a threshold set
of computers. A breach of any one of these machines—or any number of machines less than the
threshold—will not allow the attacker to steal any money or glean any information about the key.
Before the advent of Bitcoin, the best ECDSA threshold signature scheme was the work by
Gennaro et al. [18], which has a considerable setback. To implement a security threshold of t
players (i.e. t or less players cannot sign) it is necessary to share the key among at least 2t + 1
players, and the participation of at least 2t + 1 players is required to sign. This limitation rules out
an n-of-n sharing where all parties are required to sign. Furthermore, it requires setting up many
servers holding key shares, which may be costly and also makes the job of the attacker easier in

This is a major revision of our paper [16] that appeared at ACM CCS 2018.
§ Steven Goldfeder was at Princeton University when this research took place

2

Rosario Gennaro and Steven Goldfeder

some way (as there are more servers that can be targeted and while the honest participants need
2t + 1 players to sign, an attacker need only compromise t + 1 servers to steal the key).

In an attempt to address these issues, Mackenzie and Reiter built a specialized scheme for
the 2-out-of-2 signature case (i.e. t = 1 and n = 2) [30], a case not covered by Gennaro et al.’s
scheme. Recently much improved 2-out-of-2 schemes have been presented [12, 28]. However 2-out-
of-2 sharing is very limited and can’t express more ﬂexible sharing policies that might be required
in certain applications.

Gennaro and others in [17] (improved in [4]) address the more general (t, n) case in the threshold
optimal setting, meaning n ≥ t + 1 and that only t + 1 players are needed to sign. However, their
scheme too has a setback in that the distributed key generation protocol is very costly.

Our Result: We present a new threshold-optimal protocol for ECDSA that improves in many
signiﬁcant ways over [4, 17]. Our new protocol is faster and requires much less communication than
[4, 17]; it is also conceptually simpler and does not require a complicated distributed key generation
protocol (details of the comparison appear below).

In concurrent work that appeared in the same proceedings, Lindell et al. present a similar

protocol for multiparty threshold ECDSA with an eﬃcient key generation [29].

1.1 Overview of our solution

Consider a “generic” DSA signature algorithm that works over any cyclic group G of prime order
q generated by an element g. It uses a hash function H deﬁned from arbitrary strings into Zq, and
another hash function H (cid:48) deﬁned from G to Zq. The secret key is x chosen uniformly at random in
Zq, with a matching public key y = gx. To sign a message M , the signer computes m = H(M ) ∈ Zq,
chooses k uniformly at random in Zq and computes R = gk−1
in G and r = H (cid:48)(R) ∈ Zq. Then
she computes s = k(m + xr) mod q. The signature on M is the pair (r, s) which is veriﬁed by
computing

R(cid:48) = gms−1 mod qyrs−1 mod q in G

and accepting if H (cid:48)(R(cid:48)) = r.

The technical complication with sharing DSA signatures comes from having to jointly compute
R (which requires raising g to the inverse of a secret value k) and to compute s which requires
multiplying two secret values k, x. As shown in [18], it is suﬃcient to show how to compute two
multiplications over secret values that are shared among the players. In [18] the values are shared
via Shamir’s secret sharing, i.e., as points on a polynomial of degree t with free term the secret.
The eﬀect of multiplication is that the degree of the polynomial is doubled, which explains why
the solution in [18] requires at least 2t + 1 players to participate. To address this problem [30] uses
a multiplicative sharing of the secret key x as x = x1 · x2 (an approach taken also in [12, 28]) which
is however hard to generalize to t > 2.

A diﬀerent approach was taken in [17]: the secret key x is encrypted under a public key en-
cryption scheme E, and it is the secret key of E that is shared among the players, eﬀectively
providing a secret sharing of x. If E is an additively homomorphic encryption scheme (e.g. Pail-
lier’s [33]) they show that it is possible to construct a reasonably eﬃcient protocol, with a few
troubling bottlenecks. The major one is that the protocol requires a joint generation of the public
key/secret key pair for the additively homomorphic encryption E. When E is instantiated using
Paillier, this requires the distributed generation of an RSA modulus. Although solutions are known
for this problem (e.g. [24]), they are far from scalable and eﬃcient. To our knowledge the protocol
from [24] has never been implemented for the malicious multiparty case. The only benchmark we
are aware of for this protocol is that for the two-party semi-honest case it takes 15 minutes [28],
and we can extrapolate that it would take signiﬁcantly longer in the multiparty malicious setting.
Moreover the signature generation protocols in [4, 17] require long messages and complicated ZK
proofs.

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

3

In this paper we take a diﬀerent path inspired by the SPDZ approach to multiparty computation
[9]. Given two secrets a, b shared additively among the players, i.e. a = a1 + . . . + an and b =
b1 + . . . + bn where Pi holds ai, and bi, we want to generate an additive sharing of c = ab. We
note that ab = (cid:80)
i,j aibj and therefore to get an additive sharing of ab, it is suﬃcient to obtain an
additive sharing of each individual term aibj. To that extent we use a 2-party protocol that allows
two parties to transform multiplicative shares of a secret to additive shares of the same secret. The
players engage in this protocol in a pairwise fashion to obtain an additive sharing of the product
ab.

Using this approach, we build a simple and elegant threshold ECDSA protocol for the general
multiparty setting. The players start with a (t, n) Shamir sharing of the secret key x. When t + 1
players want to sign, they generate an additive sharing of two random values k = (cid:80)
i ki and
γ = (cid:80)
i γi and they use the above idea to compute additive sharings of the products δ = kγ (which
is reconstructed in the clear) and σ = kx = (cid:80)
i wi (which is kept shared). By multiplying the local
shares of γ by the public value δ−1 the players end up with an additive sharing3 of k−1. The value
R is then easily computed in the exponent R = (cid:81)
. The value s is shared additively among
the players since each player holds si = kim + wir and s = (cid:80)

i gγiδ−1

i si.

1.2 Avoid expensive ZK Proofs in case of a Malicious Adversary

Following [28] we make minimal use of ZK proofs to detect malicious behavior by the players.

Instead we take an “optimistic” approach and run the protocol assuming everybody is honest.
We then check the validity of the resulting signature to detect if there were players who deviated
from the protocol (if the signature does not verify then obviously at least one player did not follow
the instructions).

At that point, because we possibly have a dishonest majority among the players, there is no
guarantee that we can generate a correct signature so the protocol stops and aborts. This creates
a technical complication in the proof as we have to make sure that the values revealed by the good
players do not leak any valuable information, not only in the case of good executions, but also in
the case of aborting executions. As we will see, this will require us to “distributively” check that the
shares si reconstruct a valid signature before revealing them. This check is somewhat reminiscent
of the way Canetti and Goldwasser solve a similar problem in [7] to construct threshold CCA secure
encryption based on the Cramer-Shoup scheme.
Range Proofs. Even when using the signature veriﬁcation step to detect cheating, we have to
run two relatively expensive ZK proofs during the share conversion protocol:

– a “range proof” that certain values encrypted under Paillier’s encryption scheme are “small”;
– a proof that a party knows x such that c = E(x) and y = gx where E is Paillier’s encryption

scheme.

1.3 The issue with the previous version

The previous version of the protocol did not check the range of all values encrypted under Paillier’s
encryption scheme. This creates an adversarial strategy that could leak information about an honest
party’s share. The proof of the protocol in the previous version did not take into account this leakage
and incorrectly assumed that certain subprotocols were zero-knowledge and simulatable. The issue
was reported in [37, 32].

Moreover in [37] the authors show how to leverage this information leakage to actually recover
the entire share of an honest party, and for the adversary to learn the entire secret key of the group.
Crucially, however, the attack relies on choosing a very small Paillier modulus N (approximately
the same size of the modulus q used in the DSA scheme). In our previous version we clearly stated

3 This is the famous Bar-Ilan and Beaver inversion trick [1].

4

Rosario Gennaro and Steven Goldfeder

that N > q7 therefore the attack does not apply to our previous scheme (though it worked against
implementations that neglected to check the size of the modulus).

We have now changed the protocol to make sure that all values encrypted under Paillier’s
scheme are checked to be ”small”. All changes from the previous protocol are discussed when they
arise and marked with Note about previous version header.

Finally, in the previous version we discussed a protocol where the ZK range proofs were removed
entirely. We discussed how removing these ZK proofs creates an attack that leaks some information
about the DSA secret key (and the randomizer k used in each signature) shared among the servers.
We conjectured that this information would still not allow the adversary to forge signatures. We did
not consider this ”light” protocol to be ”secure”, and never recommended it for implementation in
commercial systems. We made the conjecture to stimulate research on the ”danger” of leaking that
information. Our conjecture has been disproven in [37, 32] where it is also shown that removing
the ZK range proofs does indeed lead to an insecure protocol. We are going to leave Section 5 in
the paper as an historical record but will preface it with this new information.

1.4 Experimental Results

We implemented our scheme and found both the key generation and signing protocols to be very
eﬃcient.

The key generation protocol is easy to implement and is quite fast (under a second for any
reasonable choice of parameters). This is in stark contrast to [4, 17] for which the key generation
protocol has never been implemented, and it is hard to estimate what the actual running time
would be.

Our signing protocol is also extremely eﬃcient, and is a signiﬁcant improvement over previous

works both in terms of data transferred and running time.

With the combination of an eﬃcient key generation and signing protocol, our scheme is suitable

to be deployed in practice. We present full benchmarks and evaluations in Section 7.

2 Preliminaries

Communication Model. We assume the existence of a broadcast channel as well as point-to-point
channels connecting every pair of players.

The Adversary. We assume a probabilistic polynomial time malicious adversary, who may de-
viate from the protocol description arbitrarily. The adversary can corrupt up to t players, and it
learns the private state of all corrupted players. As in previous threshold ECDSA schemes [4, 17,
18, 28], we limit ourselves to static corruptions, meaning the adversary must choose which players
to corrupt at the beginning of the protocol. There are standard techniques for converting a protocol
secure against static corruptions to secure against adaptive corruptions [6, 25], but these will incur
an overhead.

We assume a rushing adversary, meaning that the adversary gets to speak last in a given round

and, in particular, can choose his message after seeing the honest parties’ messages.

Following [4, 17] (but unlike [18]), we assume a dishonest majority, meaning t, the number
of players the adversary corrupts, can be up to n − 1. In this case, there is no guarantee that the
protocol will complete, and we therefore do not attempt to achieve robustness, or the ability to
complete the protocol even in the presence of some misbehaving participants.

2.1 Signature Schemes

A digital signature scheme S consists of three eﬃcient algorithms:

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

5

– (sk, pk)←Key-Gen(1λ), the randomized key generation algorithm which takes as input the

security parameter and returns the private signing key sk and public veriﬁcation key pk.

– σ←Sig(sk, m), the possibly randomized signing algorithm which takes as input the private key
sk and the message to be signed m and outputs a signature, σ. As the signature may be
randomized, there may be multiple valid signatures. We denote the set of valid signatures as
{Sig(sk, m)} and require that σ ∈ {Sig(sk, m)}.

– b ←Ver (pk, m, σ), the deterministic veriﬁcation algorithm, which takes as input a public key
pk, a message m and a signature σ and outputs a bit b which equals 1 if and only if σ is a valid
signature on m under pk.

To prove a signature scheme secure, we recall the standard notion of existential unforgeability

against chosen message attacks (EU-CMA) as introduced in [23].

Deﬁnition 1 (Existential unforgeability). Consider a PPT adversary A who is given public
key pk output by Key-Gen and oracle access to the signing algorithm Sig(sk, ·) with which it can
receive signatures on adaptively chosen messages of its choosing. Let M be the set of messages
queried by A. A digital signature scheme S =(Key-Gen,Sig,Ver) is said to be existentially unforge-
able if there is no such PPT adversary A that can produce a signature on a message m /∈ M,
except with negligible probability in λ.

2.2 Threshold Signatures

Threshold secret sharing. A (t, n)−threshold secret sharing of a secret x consists of n shares
x1, . . . , xn such that an eﬃcient algorithm exists that takes as input t + 1 of these shares and
outputs the secret, but t or fewer shares do not reveal any information about the secret.

Threshold signature schemes. Consider a signature scheme, S=(Key-Gen, Sig, Ver). A (t, n)-
threshold signature scheme T S for S enables distributing the signing among a group of n players,
P1, . . . , Pn such that any group of at least t + 1 of these players can jointly generate a signature,
whereas groups of size t or fewer cannot. More formally, T S consists of two protocols:

– Thresh-Key-Gen, the distributed key generation protocol, which takes as input the security
parameter 1λ. Each player Pi receives as output the public key pk as well as a private output
ski, which is Pi’s share of the private key. The values sk1, . . . , skn constitute a (t, n) threshold
secret sharing of the private key sk.

– Thresh-Sig, the distributed signing protocol which takes as public input a message m to be
signed as well as a private input ski from each player. It outputs a signature σ ∈ {Sig(sk, m)}.

Notice that the signature output by Thresh-Sig is a valid signature under Sig, the centralized
signing protocol. Thus we do not specify a threshold variant of the veriﬁcation algorithm as we
will use the centralized veriﬁcation algorithm, Ver.

In some applications, it may be acceptable to have a trusted dealer generate the private key

shares for each party. In this case, Thresh-Key-Gen would not be run.

Following [18, 19], we present a game-based deﬁnition of security analogous to EU-CMA.

Deﬁnition 2 (Unforgeable threshold signature scheme [18]). We say that a (t, n)-threshold
signature scheme T S =(Thresh-Key-Gen,Thresh-Sig) is unforgeable, if no malicious adversary who
corrupts at most t players can produce, with non-negligible (in λ) probability, the signature on any
new (i.e., previously unsigned) message m, given the view of the protocol Thresh-Key-Gen and of
the protocol Thresh-Sig on input messages m1, . . . , mk which the adversary adaptively chose as well
as signatures on those messages.

6

Rosario Gennaro and Steven Goldfeder

This is a game-based deﬁnition of security which is analogous to the notion of existential unforge-
ability under chosen message attack as deﬁned by Goldwasser, Micali, and Rivest [23]. Unlike in the
centralized EU-CMA deﬁnition, the adversary is additionally given the corrupted players’ views
of the key generation protocol as well as their views in the signing protocol for the messages it
chooses. A stronger simulation-based deﬁnition is also possible (see e.g. [17, 18, 28]). See Section
6.3 in which we show how to prove security of our protocol using this stronger simulation-based
deﬁnition.

2.3 Additively Homomorphic Encryption

Our protocol relies on an encryption scheme E that is additively homomorphic modulo a large
integer N . Let Epk(·) denote the encryption algorithm for E using public key pk. Given ciphertexts
c1 = Epk(a) and c2 = Epk(b), there is an eﬃciently computable function +E such that

c1 +E c2 = Epk(a + b mod N )

The existence of a ciphertext addition operation also implies a scalar multiplication operation,

which we denote by ×E. Given an integer a ∈ N and a ciphertext c = Epk(m), then we have

a ×E c = Epk(am mod N )

Informally, we say that E is semantically secure if for the probability distributions of the en-

cryptions of any two messages are computationally indistinguishable.

We instantiate our protocol using the additively homomorphic encryption scheme of Paillier

[33], and we recall the details here:

– Key-Gen: generate two large primes P, Q of equal length, and set N = P Q. Let λ(N ) =
lcm(P − 1, Q − 1) be the Carmichael function of N , and denote Γ = N + 1. The public key is
ZN and the secret key is λ(N ).

– Encryption: to encrypt a message m ∈ ZN , select x ∈R Z ∗
– Decryption: to decrypt a ciphertext c ∈ ZN 2, let L be a function deﬁned over the set {u ∈
ZN 2 : u = 1 mod N } computed as L(u) = (u − 1)/N . Then the decryption of c is computed as
L(cλ(N ))/L(Γ λ(N )) mod N .

N and return c = Γ mxN mod N 2.

– Homomorphic Properties: Given two ciphertexts c1, c2 ∈ ZN 2 deﬁne c1 +E c2 = c1c2 mod N 2. If
ci = E(mi) then c1 +E c2 = E(m1 + m2 mod N ). Similarly, given a ciphertext c = E(m) ∈ ZN 2
and a number a ∈ Zn we have that a ×E c = ca mod N 2 = E(am mod N ).

The security of Paillier’s cryptosystem relies on the N -residuosity decisional assumption [33],
which informally says that it is infeasible to distinguish random N -residues from random group
elements in Z ∗

N 2.

2.4 Non-Malleable Equivocable Commitments

A trapdoor commitment scheme allows a sender to commit to a message with information-theoretic
privacy. i.e., given the transcript of the commitment phase the receiver, even with inﬁnite computing
power, cannot guess the committed message better than at random. On the other hand when it
comes to opening the message, the sender is only computationally bound to the committed message.
Indeed the scheme admits a trapdoor whose knowledge allows to open a commitment in any possible
way (we will refer to this also as equivocate the commitment). This trapdoor should be hard to
compute eﬃciently.

Formally a (non-interactive) trapdoor commitment scheme consists of four algorithms KG, Com,

Ver, Equiv with the following properties:

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

7

– KG is the key generation algorithm, on input the security parameter it outputs a pair {pk,
tk} where pk is the public key associated with the commitment scheme, and tk is called the
trapdoor.

– Com is the commitment algorithm. On input pk and a message M it outputs [C(M ), D(M )] =
Com(pk, M, R) where r are the coin tosses. C(M ) is the commitment string, while D(M ) is
the decommitment string, which is kept secret until opening time.

– Ver is the veriﬁcation algorithm. On input C, D and pk it either outputs a message M or ⊥.
– Equiv is the algorithm that opens a commitment in any possible way given the trapdoor in-
formation. It takes as input pk, strings M, R with [C(M ), D(M )] = Com(pk, M, R), a message
M (cid:48) (cid:54)= M and a string T . If T = tk then Equiv outputs D(cid:48) such that Ver(pk, C(M ), D(cid:48)) = M (cid:48).

We note that if the sender refuses to open a commitment we can set D = ⊥ and Ver(pk, C, ⊥) = ⊥.
Trapdoor commitments must satisfy the following properties

Correctness If [C(M ), D(M )] = Com(pk, M, R) then

Ver(pk, C(M ), D(M )) = M .

Information Theoretic Security For every message pair M, M (cid:48) the distributions C(M ) and

C(M (cid:48)) are statistically close.

Secure Binding We say that an adversary A wins if it outputs C, D, D(cid:48) such that Ver(pk, C, D) =
M , Ver(pk, C, D(cid:48)) = M (cid:48) and M (cid:54)= M (cid:48). We require that for all eﬃcient algorithms A, the
probability that A wins is negligible in the security parameter.

Such a commitment is non-malleable [13] if no adversary A, given a commitment C to a messages
m, is able to produce another commitment C (cid:48) such that after seeing the opening of C to m, A can
successfully decommit to a related message m(cid:48) (this is actually the notion of non-malleability with
respect to opening introduced in [10]).

The non-malleable commitment schemes in [10, 11] are not suitable for our purpose because
they are not “concurrently” secure, in the sense that the security deﬁnition holds only for t = 1
(i.e. the adversary sees only 1 commitment).

The stronger concurrent security notion of non-malleability for t > 1 is achieved by the schemes

presented in [8, 15, 31]), and any of them can be used in our threshold DSA scheme.

However in practice one can use any secure hash function H and deﬁne the commitment to
x as h = H(x, r), for a uniformly chosen r of length λ and assume that H behaves as a random
oracle. We use this eﬃcient random oracle version in our implementation.

2.5 The Digital Signature Standard

The Digital Signature Algorithm (DSA) was proposed by Kravitz in 1991, and adopted by NIST
in 1994 as the Digital Signature Standard (DSS) [3, 27]. ECDSA, the elliptic curve variant of DSA,
has become quite popular in recent years, especially in cryptocurruencies.

All of our results in this paper apply to both the traditional DSA and ECDSA. We present our

results using the generic G-DSA notation from [17], which we recall here.

The Public Parameters consist of a cyclic group G of prime order q, a generator g for G, a hash

function H : {0, 1}∗ → Zq, and another hash function H (cid:48) : G → Zq.

.

Key-Gen On input the security parameter, outputs a private key x chosen uniformly at random in Zq,

and a public key y = gx computed in G.

Sig On input an arbitrary message M ,
• compute m = H(M ) ∈ Zq
• choose k ∈R Zq
• compute R = gk−1
• compute s = k(m + xr) mod q

in G and r = H (cid:48)(R) ∈ Zq

8

Rosario Gennaro and Steven Goldfeder

• output σ = (r, s)
Ver On input M, σ and y,

• check that r, s ∈ Zq
• compute R(cid:48) = gms−1 mod qyrs−1 mod q in G
• Accept (output 1) iﬀ H (cid:48)(R(cid:48)) = r.

The traditional DSA algorithm is obtained by choosing large primes p, q such that q|(p − 1)
p . In this case the multiplication operation in G is

and setting G to be the order q subgroup of Z ∗
multiplication modulo p. The function H (cid:48) is deﬁned as H (cid:48)(R) = R mod q.

The ECDSA scheme is obtained by choosing G as a group of points on an elliptic curve of
cardinality q. In this case the multiplication operation in G is the group operation over the curve.
The function H (cid:48) is deﬁned as H (cid:48)(R) = Rx mod q where Rx is the x-coordinate of the point R.

2.6 Feldman’s VSS Protocol

Recall that in Shamir’s scheme [36], to share a secret σ ∈ Zq, the dealer generates a random degree
t polynomial p(·) over Zq such that p(0) = σ. The secret shares are evaluations of the polynomial

p(x) = σ + a1x + a2x2 + · · · + atxt mod q

Each player Pi receives a share σi = p(i) mod q.
In a veriﬁable secret sharing scheme, auxiliary information is published that allows players to

check that their shares are consistent and deﬁne a unique secret.

Feldman’s VSS is an extension of Shamir secret sharing in which the dealer also publishes

vi = gai in G for all i ∈ [1, t] and v0 = gσ in G.

Using this auxiliary information, each player Pi can check its share σi for consistency by veri-

fying:

gσi ?=

t
(cid:89)

j=0

vij
j

in G

If the check does not hold for any player, it raises a complaint and the protocol terminates. Note
that this is diﬀerent than the way Feldman VSS was originally presented as it assumed an honest
majority and could recover if a dishonest player raised a complaint. However, since we assume
dishonest majority in this paper, the protocol will abort if a complaint is raised.

While Feldman’s scheme does leak gσ, it can be shown via a simulation argument that nothing

else is leaked, but we omit the details here.

2.7 Assumptions

DDH. Let G be a cyclic group of prime order q, generated by g. The DDH Assumption states that
the following two distributions over G3 are computationally indistinguishable: DH = {(ga, gb, gab)
for a, b ∈R Zq} and R = {(ga, gb, gc) for a, b, c ∈R Zq}.
Strong-RSA. Let N be the product of two safe primes, N = pq, with p = 2p(cid:48) + 1 and q = 2q(cid:48) + 1
with p(cid:48), q(cid:48) primes. With φ(N ) we denote the Euler function of N , i.e. φ(N ) = (p − 1)(q − 1) = p(cid:48)q(cid:48).
With Z ∗
N we denote the set of integers between 0 and N − 1 and relatively prime to N .

Let e be an integer relatively prime to φ(N ). The RSA Assumption [34] states that it is infeasible
N it is hard to ﬁnd x such that

N . That is, given a random element s ∈R Z ∗

to compute e-roots in Z ∗
xe = s mod N .

The Strong RSA Assumption (introduced in [2]) states that given a random element s in Z ∗
N
it is hard to ﬁnd x, e (cid:54)= 1 such that xe = s mod N . The assumption diﬀers from the traditional

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

9

RSA assumption in that we allow the adversary to freely choose the exponent e for which she will
be able to compute e-roots.

We now give formal deﬁnitions. Let SRSA(n) be the set of integers N , such that N is the

product of two n/2-bit safe primes.

Assumption 1 We say that the Strong RSA Assumption holds, if for all probabilistic polynomial
time adversaries A the following probability

P rob[ N ← SRSA(n) ; s ← Z ∗

N : A(N, s) = (x, e) s.t. xe = s mod N ]

is negligible in n.

3 A share conversion protocol

Assume that we have two parties Alice and Bob holding two secrets a, b ∈ Zq respectively which
we can think of as multiplicative shares of a secret x = ab mod q. Alice and Bob would like to
compute secret additive shares α, β of x, that is random values such that α + β = x = ab mod q
with Alice holding α (and a) and Bob holding β (and b).

Here we show a protocol based on an additively homomorphic scheme which has appeared many
times before in the literature (e.g. [9, 26, 28, 30]) but that we adapt to our needs. We assume that
Alice is associated with a public key EA for an additively homomorphic scheme E over an integer
N .

In the following we will refer to this protocol as an MtA (for Multiplicative to Additive) share
conversion protocol. In our protocol we also assume that B = gb might be public. In this case
an extra check for Bob is used to force him to use the correct value b. We refer to this enhanced
protocol as MtAwc (as MtA “with check”).

1. Alice initiates the protocol by

– sending cA = EA(a) to Bob
– proving in ZK that he knows a < q3 via a range proof

2. Bob computes the ciphertext cB = b ×E cA +E EA(β(cid:48)) = EA(ab + β(cid:48)) where β(cid:48) is chosen
uniformly at random in Zq5 . Bob sets his share to β = −β(cid:48) mod q. He responds to Alice by

– sending cB
– proving in ZK that he knows b < q3, β(cid:48) < q7 such that cB = b ×E cA +E EA(β(cid:48)).
– and only if B = gb is public that B = gb and
3. Alice decrypts cB to obtain α(cid:48) and sets α = α(cid:48) mod q.

Correctness. Assume both players are honest and N > q8. Then note that Alice decrypts the
value α(cid:48) = ab + β(cid:48) mod N . Note that β(cid:48) < N − ab and therefore the reduction mod N is not
executed which implies that the protocol correctly computes α, β such that α + β = x mod q.

Simulation. We ﬁrst point out that as a stand-alone protocol, we can prove security even without
the range proofs. Indeed, if the adversary corrupts Alice, then Bob’s message can be simulated
without knowledge of its input b. Indeed a simulator can just choose a random b(cid:48) ∈ Zq and act as
Bob. The distribution of the message decrypted by Alice in this simulation is statistically close to
the message decrypted when Bob uses the real b, because the “noise” β(cid:48) is uniformly distributed
in Zq5.

If the adversary corrupts Bob, then Alice’s message can be simulated without knowledge of its
input a. Indeed a simulator can just choose a random a(cid:48) ∈ Zq and act as Alice. In this case the
view of Bob is computationally indistinguishable from the real one due to the semantic security of
the encryption scheme E.

However if the range proofs are not used, a malicious Alice or Bob can cause the protocol to
“fail” by choosing large inputs. As a stand-alone protocol this is not an issue since the parties are

10

Rosario Gennaro and Steven Goldfeder

not even aware that the reduction mod N took place and no information is leaked about the other
party’s input. However, when used inside our threshold DSA protocol, this attack will cause the
signature veriﬁcation to fail, and this information is linked to the size of the other party’s input.
Consider for example the case of Alice running the protocol with input a(cid:48) = q7 + a. If Bob’s
input is “small” then the reduction mod N will not take place and the protocol will succeed, and
eventually the signature produced by our threshold DSA protocol will verify (since a(cid:48) = a mod q).
But if Bob’s input is large the protocol will fail. Similar issues arise if one does not check the range
of b and β(cid:48).

So we need security in the presence of an oracle that tells the parties if the reduction mod N
happens or not, but due to the ZK “range proofs” such reduction will only happen with negligible
probability and security holds.
Remark. On the ZK proofs and the size of the modulus N . For the ZK proofs required in the
protocol we use simpliﬁed versions of similar ZK proofs presented in [30] (and already used in
[17]). These are ZK arguments with security holding under the Strong RSA Assumption. Moreover
they require N ≈ q8 as pointed above. We point out that for typical choices of parameters, N is
approximately q8 (since q is typically 256-bit long while N is a 2048-bit RSA modulus), so this
requirement is not problematic. It is however imperative that the size of N is checked by the parties
to ensure the ZK property of the proofs4.

Note about the previous version: In our previous version we chose β(cid:48) uniformly at random
in ZN and did not impose any range check on it. This leads to a similar information leakage as
described above where if β(cid:48) is chosen close to N , a modular reduction (and therefore a failure of
the protocol) happens based on the distribution of the input a.

4 Our scheme

We now describe our protocol. The players run on input G, g the cyclic group used by the DSA
signature scheme. We assume that each player Pi is associated with a public key Ei for an additively
homomorphic encryption scheme E.

4.1 Key generation protocol

– Phase 1. Each Player Pi selects ui ∈R Zq; computes [KGCi, KGDi] = Com(gui) and broadcasts

KGCi. Each Player Pi broadcasts Ei the public key for Paillier’s cryptosystem.

– Phase 2. Each Player Pi broadcasts KGDi. Let yi be the value decommitted by Pi. The player
Pi performs a (t, n) Feldman-VSS of the value ui, with yi as the “free term in the exponent”
The public key is set to y = (cid:81)
i yi. Each player adds the private shares received during the
n Feldman VSS protocols. The resulting values xi are a (t, n) Shamir’s secret sharing of the
secret key x = (cid:80)

i ui. Note that the values Xi = gxi are public.

– Phase 3 Let Ni = piqi be the RSA modulus associated with Ei. Each player Pi proves in ZK
that he knows xi using Schnorr’s protocol [35] and that Ni is square-free using the proof of
Gennaro, Micciancio, and Rabin [21].

4.2 Signature Generation

We now describe the signature generation protocol, which is run on input m (the hash of the
message M being signed) and the output of the key generation protocol described above. We note

4 For the simple range proof that a, b < K one could alternatively use a variation of Boudot’s proof [5]
which establish K ∼ q which sets N ∼ q3. This proof is less eﬃcient that the ones from [17, 30] which
are anyway required for Bob in the MtAwc protocol. Moreover as we said earlier, N > q8 in practice
anyway so the improvement in the size of N is irrelevant for ECDSA.

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

11

that the latter protocol is a t-out-of-n protocol (and thus the secret key x is shared using (t, n)
Shamir secret-sharing).

Let S ⊆ [1..n] be the set of players participating in the signature protocol. We assume that |S| =
t + 1. For the signing protocol we can share any ephemeral secrets using a (t, t + 1) secret sharing
scheme, and do not need to use the general (t, n) structure. We note that using the appropriate
Lagrangian coeﬃcients λi,S each player in S can locally map its own (t, n) share xi of x into a
(t, t + 1) share of x, wi = (λi,S)(xi), i.e. x = (cid:80)
i∈S wi. Since Xi = gxi and λi,S are public values,
all the players can compute Wi = gwi = X λi,S
.

i

– Phase 1. Each Player Pi selects ki, γi ∈R Zq; computes [Ci, Di] = Com(gγi) and broadcast Ci.

Deﬁne k = (cid:80)

i∈S ki, γ = (cid:80)

i∈S γi. Note that

kγ =

kx =

(cid:88)

i,j∈S

(cid:88)

i,j∈S

kiγj mod q

kiwj mod q

– Phase 2. Every pair of players Pi, Pj engages in two multiplicative-to-additive share conversion

subprotocols

• Pi, Pj run MtA with shares ki, γj respectively. Let αij [resp. βij] be the share received by

player Pi [resp. Pj] at the end of this protocol, i.e.

Player Pi sets δi = kiγi + (cid:80)
sharing of kγ = (cid:80)

i∈S δi

kiγj = αij + βij

j(cid:54)=i αij + (cid:80)

j(cid:54)=i βji. Note that the δi are a (t, t + 1) additive

• Pi, Pj run MtAwc with shares ki, wj respectively. Let µij [resp. νij] be the share received

by player Pi [resp. Pj] at the end of this protocol, i.e.

kiwj = µij + νij

j(cid:54)=i µij + (cid:80)

j(cid:54)=i νji. Note that the σi are a (t, t + 1) additive

Player Pi sets σi = kiwi + (cid:80)
sharing of kx = (cid:80)

i∈S σi

players compute δ−1 mod q.

– Phase 3. Every player Pi broadcasts δi and the players reconstruct δ = (cid:80)

i∈S δi = kγ. The

– Phase 4. Each Player Pi broadcasts Di. Let Γi be the values decommitted by Pi who proves in

ZK that he knows γi s.t. Γi = gγi using Schnorr’s protocol [35].
The players compute

R = [

(cid:89)

Γi]δ−1

= g((cid:80)

i∈S

γi)k−1γ−1

= gγk−1γ−1

= gk−1

i∈S

and r = H (cid:48)(R).

– Phase 5. Each player Pi sets si = mki + rσi. Note that

(cid:88)

i∈S

si = m

(cid:88)

i∈S

ki + r

(cid:88)

i∈S

σi = mk + rkx = k(m + xr) = s

i.e. the si are a (t, t + 1) sharing of s.

• (5A) Player Pi chooses (cid:96)i, ρi ∈R Zq computes Vi = Rsig(cid:96)i , Ai = gρi, and [ ˆCi, ˆDi] =

Com(Vi, Ai) and broadcasts ˆCi.
Let (cid:96) = (cid:80)

i (cid:96)i and ρ = (cid:80)

i ρi.

12

Rosario Gennaro and Steven Goldfeder

• (5B) Player Pi broadcasts ˆDi and proves in ZK that he knows si, (cid:96)i, ρi such that Vi = Rsig(cid:96)i
i∈S Vi (this should be

i . If a ZK proof fails, the protocol aborts. Let V = g−my−r (cid:81)

and Aρi
V = g(cid:96)) and A = (cid:81)

i∈S Ai.

• (5C) Player Pi computes Ui = V ρi and Ti = A(cid:96)i. It commits [ ˜Ci, ˜Di] = Com(Ui, Ti) and

broadcasts ˜Ci.

aborts.

• (5D) Player Pi broadcasts ˜Di to decommit to Ui, Ti If (cid:81)

i∈S[Ti] (cid:54)= (cid:81)

i∈S Ui the protocol

• (5E) Otherwise player Pi broadcasts si. The players compute s = (cid:80)

i∈S si. If (r, s) is not a

valid signature the players abort, otherwise they accept and end the protocol.

Let us explain the intuition behind Phase 5. To avoid expensive ZK proofs, we are potentially
reconstructing an incorrect signature, which is then checked and possibly rejected. A naive approach
to the last phase is for the players to reveal si and reconstruct s = (cid:80)
i si. But, for reasons that
will become clear in the proof, this is not provably secure—the intuitive reason being that if the
adversary makes the protocol fail by outputting an invalid signature, then the values si held by the
good players may give him valuable information.5 Naively this could be done by ﬁrst broadcasting
Si = Rsi and check that (cid:81)
i Si = Rs = gmyr according to the DSA veriﬁcation algorithm. But
for similar reasons, this step makes the proof fail. So in our protocol the players mask Rsi with
a random value g(cid:96)i. Let Vi = Rsig(cid:96)i. Then (cid:81)
i Vi = Rsg(cid:96) and therefore V = g(cid:96). The players
cannot reveal g(cid:96)i to check the correctness of V as this would “de-mask” Rsi so we “randomize” the
“aggregate” value to U = g(cid:96)ρ. Alongside the players compute g(cid:96)ρ via a distributed “Diﬃe-Hellman”
exchange. If this distributed randomized signature veriﬁcation carries out, then it is safe to release
the shares si, but if the signature does not verify then the protocol aborts here and the values si
held by the good players are never revealed in the clear.

4.3 The Zero-Knowledge Proofs

In step (5B) a player P outputs V = Rsg(cid:96) and A = gρ and must prove that he knows s, (cid:96), ρ
satisfying the above relationship. The proof for A is the classic Schnorr’s proof. For the value V a
classic (honest-veriﬁer) ZK proof for this task is as follows:

– The Prover chooses a, b ∈R Zq and sends α = Ragb
– The Veriﬁer sends a random challenge c ∈R Zq
– The Prover answers with t = a + cs mod q and u = b + c(cid:96) mod q.
– The Veriﬁer checks that Rtgu = αV c

4.4 Security Proof

In this section we prove the following

Theorem 1. Assuming that

– The DSA signature scheme is unforgeable;
– The Strong RSA Assumption holds;
– KG, Com, Ver, Equiv is a non-malleable equivocable commitment scheme;
– the DDH Assumption holds

then our threshold DSA scheme in the previous section is unforgeable.

5 We do not have an attack but we do not see a way to make a proof work either.

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

13

The proof of this theorem will proceed by a traditional simulation argument, in which we show
that if there is an adversary A that forges in the threshold scheme with a signiﬁcant probability,
then we can build a forger F that forges in the centralized DSA scheme also with a signiﬁcant
probability.

So let’s assume that there is an adversary A that forges in the threshold scheme with probability

larger than (cid:15) ≥ λ−c.

We assume that the adversary controls players P2, . . . , Pt+1 and that P1 is the honest player.
We point out that because we use concurrently non-malleable commitments (where the adversary
can see many commitments from the honest players) the proof also holds if the adversary controls
less than t players and we have more than 1 honest player. So the above assumption is without
loss of generality.

Because we are assuming a rushing adversary, P1 always speaks ﬁrst at each round. Our sim-
ulator will act on behalf of P1 and interact with the adversary controlling P2, . . . , Pn. Recall how
A works: it ﬁrst participates in the key generation protocol to generate a public key y for the
threshold scheme. Then it requests the group of players to sign several messages m1, . . . , m(cid:96), and
the group engages in the signing protocol on those messages. At the end with probability at least
(cid:15) the adversary outputs a message m (cid:54)= mi and a valid signature (r, s) for it under the DSA key y.
This probability is taken over the random tape τA of A and the random tape τ1 of P1. If we denote
with A(τA)P1(τ1) the output of A at the end of the experiment described above, we can write

We say that an adversary random tape τA is good if

P robτ1,τA [ A(τA)P1(τ1) is a forgery ] ≥ (cid:15)

P robτ1[ A(τA)P1(τ1) is a forgery ] ≥

(cid:15)
2

By a standard application of Markov’s inequality we know that if τA is chosen uniformly at random,
the probability of choosing a good one is at least (cid:15)
2 .
We now turn to building the adversary F that forges in the centralized scheme. This forger
will use A as a subroutine in a “simulated” version of the threshold scheme: F will play the role
of P1 while A will control the other players. F will choose a random tape τA for A: we know that
with probability at least (cid:15)
2 it will be a good tape. From now on we assume that A runs on a good
random tape.

F runs on input a public key y for the centralized DSA scheme, which is chosen according to
the uniform distribution in G. The ﬁrst task for F is to set up an indistinguishable simulation of
the key generation protocol to result in the same public key y.

Similarly every time A requests the signature of a message mi, the forger F will receive the real
signature (ri, si) from its signature oracle. It will then simulate, in an indistinguishable fashion, an
execution of the threshold signature protocol that on input mi results in the signature (ri, si).

Because these simulations are indistinguishable from the real protocol for A, the adversary will
output a forgery with the same probability as in real life. Such a forgery m, r, s is a signature on
a message that was never queried by F to its signature oracle and therefore a valid forgery for F
as well. We now turn to the details of the simulations.

4.5 Simulating the key generation protocol

The simulation Sim-Key-Gen is described below. On input a public key y = gx for DSA the forger
F plays the role of P1 as follows. The forger F also runs on input a Paillier public key E for which
he does not know the matching secret key (this is necessary for when we have to make a reduction
to the semantic security of the Paillier encryption scheme).

Simulation: Repeat the following steps (by rewinding A) until A sends valid messages (i.e. a correct
decommitment) for P2, . . . , Pn on both iterations.

14

Rosario Gennaro and Steven Goldfeder

– F (as P1) selects a random value u1 ∈ Zq, computes [KGC1, KGD1]= Com(gu1) and broadcasts

KGC1. A broadcasts commitments KCGi for i > 1;

– Each player Pi broadcasts KGDi; let yi be the decommitted value and the accompanying
Feldman-VSS (F will follow the protocol instructions). Each player broadcasts Ei. F broacasts
E1 = E.

– Let yi denote the revealed commitment values of each party. F rewinds the adversary to the

decommitment step and

• changes the opening of P1 to

ˆKGD1 so that the committed value revealed is now ˆy1 =

y · (cid:81)n

i=2 y−1

i

.

• simulates the Feldman-VSS with free term ˆy1

– The adversary A broadcasts

ˆKGDi. Let ˆyi be the committed value revealed by A at this point

(this could be ⊥ if the adversary refused to decommit).

– The players compute ˆy = (cid:81)n

i=1 ˆyi (set to ⊥ if any of the ˆyi are set to ⊥ in the previous step).

We now prove a few lemmas about this simulation.

Lemma 1. The simulation terminates in expected polynomial time and is indistinguishable from
the real protocol.

Proof (of Lemma 1). Since A is running on a good random tape, we know that the probability
over the random choices of F, that A will correctly decommit is at least (cid:15)
2λc . Therefore we
will need to repeat the loop only a polynomial number of times in expectation.

2 > 1

The only diﬀerences between the real and the simulated views is that P1 runs a simulated
Feldman-VSS with free term in the exponent ˆy1 for which it does not know the discrete log. But
we know (see Section 2.6) that this simulation is identically distributed from the real Feldman-VSS.
So the simulation of the protocol is perfect.

Lemma 2. For a polynomially large fraction of inputs y, the simulation terminates with output y
except with negligible probability.

Proof (of Lemma 2). First we prove that if the simulation terminates on an output which is not
⊥, then it terminates with output y except with negligible probability. This is a consequence of
the non-malleability property of the commitment scheme. Indeed, if A correctly decommits KGCi
twice it must do so with the same string, no matter what P1 decommits too (except with negligible
probability)6. Therefore ˆyi = yi for i > 1 and therefore ˆy = y.

Then we prove that this happens for a polynomially large fractions of input y. Let yA = (cid:81)n
i=2 yi,
i.e.the contribution of the adversary to the output of the protocol. Note that because of non-
malleability, this value is determined and known to F by the time it rewinds the adversary. At
that point F rewinds the adversary and chooses ˆy1 = y(y−1
A ). Since y is uniformly distributed, we
have that ˆy1 is also uniformly distributed. Because A is running on a good random tape we know
that at this point there is an (cid:15)
2λc fraction of ˆy1 for which A will correctly decommit. Since
there is a 1-to-1 correspondence between y and ˆy1 we can conclude that for a (cid:15)
2λc fraction of
the input y the protocol will successfully terminate.

2 > 1

2 > 1

4.6 Signature generation simulation

After the key generation is over, F must handle the signature queries issued by the adversary A.
When A requests to sign a message m, our forger F will engage in a simulation of the threshold
signature protocol. During this simulation F will have access to a signing oracle that produces
DSA signatures under the public key y issued earlier to F.

6 This property is actually referred to as independence. This is introduced in [20] as a stronger version of

non-malleability and then proven equivalent to non-malleability in [4]).

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

15

and let ˜k be the value deﬁned by the
Semi-Correct Executions. Let k be such that R = gk−1
inputs of the players in the MtA and MtAwc protocols. More speciﬁcally if ci is the encryption sent
by player Pi in the ﬁrst round of those protocols, then deﬁne ˜ki = Deci(ci) and ˜k = (cid:80)

˜ki.

We say that a protocol execution is semi-correct if in step (4) it holds that k = ˜k. Note that
this condition is well deﬁned since the values k, ˜k are uniquely determined by step (4). Note that
an execution is not semi-correct if the adversary “messes up” the computation of R by revealing
wrong shares in the computation of δ.

i

In the real run of the protocol, it is not feasible to decide if an execution is semi-correct or not.
However, as we will see, in the simulation, we can detect whether an execution is semi-correct or
not, and depending on whether it is semi-correct the simulator will decide how to simulate Phase
5.

Bird-Eye View of Simulation. First we note that for semi-correct executions the adversary,
after Step 4 can already detect if the value Rs1 which will be broadcast in Step (5) by the good
player is correct or not. In fact by this point the adversary has si for i > 1 and for a “candidate”
Rs1 can check if

(cid:89)

Rsi = Rs = gmyr

i

Moreover in such executions when we arrive to step (5A) the simulator will be able to “extract”
the value s1 for the good player, which will allow the simulation to terminate successfully.

Second, we show that a simulation that is not semi-correct will fail at step (5D) with high
probability since the value U1 contributed by the good player is indistinguishable from random.
This allows us to simulate Phase (5) by simply using a random ˜s1 for P1.

Finally, the simulator needs to detect whether or not the execution is semi-correct in order
to know which path to choose. Although detecting this is not possible in the real protocol, the
simulator can extract appropriate values to faciliate this detection. We now proceed with the
details.

4.7 Semi-correct executions

We now present a simulation that works for a semi-correct execution.

We point out that F does not know the secret values associated with P1: its correct share w1
of the secret key, and the secret key of its public key E1. The latter is necessary in order to reduce
unforgeability to the semantic security of the encryption scheme.

However F does know the shares wj of all other players. It also knows the “public key” of P1,

W1 = gw1 from the simulation of the key generation protocol.

In the following simulation F aborts whenever the protocol is supposed to abort, i.e. if the
adversary (i) refuses to decommit in steps 4, 5B or 5D or (ii) fails the ZK proof in Step 2 or 5 or
(iii) the signature (r, s) does not verify.

– Phase 1 All the players execute the protocol by broadcasting Ci (F runs the protocol correctly

for P1).
– Phase 2

• All the players execute the MtA protocol for k and γ using the values k1 and γ1 that it
chose in Phase 1. F runs the protocol correctly for P1. For each other player Pi>1, F runs
two MtA protocols, one in which it initiates (using the value k1) and one in which it is the
respondent (using the value γ1). F extracts the following values from the range proofs for
i > 1:
∗ ki
∗ γi
∗ β(cid:48)
1i

16

Rosario Gennaro and Steven Goldfeder

Note that when F is the initiator, it cannot decrypt its own share α1j during the execution
of the protocol with Pj on input k1, γj. However, using the values it extracted, it can
compute α1j = k1γi + β(cid:48)

i mod q.

• All the players execute the MtAwc protocol for k and x. Here F simulates P1 according to

the simulation described in Section 3 since it does not know its own value w1.
Moreover it extracts Pj’s resulting share ν1j from its ZK proof.

• In the protocol with Pj on input kj, w1, F does not know w1 so it just sends a random µj1

to Pj.

Note that at this point F knows the sum of σi for the bad players. Indeed

(cid:88)

i>1

σi =

(cid:88)

kiwj +

(cid:88)

µj1 +

(cid:88)

ν1j

i,j>1

j

j

and F knows all the values on the right hand side of the equation.

– Phase 3 All the players execute the protocol by revealing δi. Let δ = (cid:80)

i δi (F runs the
protocol correctly for P1 with the random shares it chose in step 2 – therefore F is eﬀectively
broadcasting a random δ1).

– Phase 4

1. Each player reveals Di to decommit to Γi
2. F queries its signature oracle and receives a signature (r, s) on m. It computes R =

gms−1

yrs−1

∈ G (note that H (cid:48)(R) = r ∈ Zq).

Rδ (cid:81)

3. F rewinds A to the decommitment step, and for P1 changes the decommitment to ˆΓ1 =
= R
Note that at this point F knows the value si held by the bad players since si = kim + σir. So
F can compute the correct s1 held by P1 as s − (cid:80)

. Note that [ ˆΓ1

i>1 Γi]δ−1

i>1 Γ −1

(cid:81)

i

i>1 si.

– Phase 5 All players execute all the steps in this phase. F uses s1 as the share for P1.

We prove the following lemma about the simulation.

Lemma 3. Assuming that

– The Strong RSA Assumption holds
– KG, Com, Ver, Equiv is a non-malleable equivocable commitment;

then the simulation has the following properties

– on input m it outputs a valid signature (r, s) or aborts.
– it is computationally indistinguishable from a semi-correct real execution

Proof (of Lemma 3).

The only diﬀerences between the real and the simulated views is the following: In the MtA
protocol the values ci = Ei(ki) are published and in the real protocol R = gk−1
i ki,
while in the simulated execution R = gˆk−1
for the ˆk chosen by the signature oracle. This is easily
seen to be computationally indistinguishable under the semantic security of Paillier’s encryption.
Indeed, when F rewinds the adversary to “ﬁx” the value of R, it implicitly changes the value
k1 that F contributes for P1 to R. If R = gˆk−1
i>1 ki. Note that Rˆk1
ki. So to distinguish between the real
is known since R
execution and the simulated one, the adversary should detect if the ciphertext sent by F for P1
in the ﬁrst round of the MtAwc protocol contains a random k1 or the random ˆk1 determined as
logR(gR− (cid:80)
ki) which is infeasible under the semantic security of Paillier’s encryption (given
that all values are proven to be “small” and no wraparound mod N happens).

ki = g, therefore Rˆk1 = gR− (cid:80)

, let (implicitly) ˆk1 = ˆk − (cid:80)

where k = (cid:80)

ˆk1+(cid:80)

i>1

i>1

i>1

Note that we are simulating a semi-correct execution with an execution which is not semi-

correct, but that’s okay because the two are indistinguishable.

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

17

However, because the real execution is a semi-correct one, we know that the correct shares of
k for the adversary are the ki that the simulator knows. Therefore the value s1 computed by the
simulator is consistent with a correct share for P1 for a valid signature (r, s), which makes Phase
5 indistinguishable from the real execution to the adversary.

Let (r, s) be the signature that F receives by its signature oracle in Step 2 of Phase 4. This
is a valid signature for m. We prove that if the protocol terminates, it does so with output (r, s).
This is a consequence of the non-malleability property of the commitment scheme. Indeed, if the
adversary correctly decommits, its openings must be the same except with negligible probability.

4.8 Simulation of a non semi-correct execution

We now show how to simulate the last execution for a non semi-correct execution when ˜k (cid:54)= k.
Details follow.

– Phases 1 to 3 The simulator runs the semi-correct simulation through Phase 3 (including

aborting at Phase 4 if the adversary fails to decommit).

– Phase 4 F does not rewind the adversary to “ﬁx” the value of R, but runs the protocol normally

for P1.

– Phase 5 F chooses ˜s1 ∈R Zq and runs Phase 5 with this value instead of s1, and choosing U1

as a random group element.

Before we prove that this simulation is indistinguishable for non-semi-correct executions let us
give an intuition. Note that the only diﬀerence with the previous simulation is that here F uses
a random share ˜s1 instead of the s1 that it computed in the other simulation. The reason is that
the value s1 computed in the previous simulation is only guaranteed to be the “correct” share
of s if the execution is semi-correct. If the adversary shares ki don’t match anymore the value R
then s1 is incorrect, and therefore F chooses a random value instead. In turn this causes U1 to be
uniformly distributed and the check in step (5D) to fail.

The main point of the proof is that if the execution is not semi-correct then the value U1 is
(given the view of the adversary) computationally indistinguishable from uniform even in the real
execution (under the DDH assumption).

Our proof reﬂects the above intuition. First we prove that a real non-semi-correct execution
is indistinguishable from one in which P1 outputs a random U1. And then we prove that this is
indistinguishable from the simulation above, where the good player uses a random ˜s1 instead of
the correct s1.

Lemma 4. Assuming that

– KG, Com, Ver, Equiv is a non-malleable equivocable commitment;
– the DDH Assumptions holds

then the simulation is computationally indistinguishable from a non-semi-correct real execution

Proof (of Lemma 4).

We construct three games between the simulator (running P1) and the adversary (running all
the other players). In G0 the simulator will just run the real protocol. In G1 the simulator will
follow the real protocol but will choose U1 as a random group element. In G2 the simulator will
run the above simulation.

Indistinguishability of G0 and G1. Let us assume that there is an adversary A0 that can distinguish

between G0 and G1. We show how this contradicts the DDH Assumption.

Let ˜A = ga, ˜B = gb, ˜C = gc be the DDH challenge where either c = ab or is chosen at random

in Zq.

18

Rosario Gennaro and Steven Goldfeder

The distinguisher F0 runs A0, simulating the key generation phase so that y = ˜B = gb. It does
that by rewinding the adversary at the end of Phase 2 of the key generation protocol and changing
the decommitment of P1 to y1 = b (cid:81)

.

i>1 y−1

i

F0 also extracts the values xi from the adversary via the proof of knowledge at the end of the
key generation. Note that at this point y = ˜B and F0 knows xi, but not b and therefore not x1. In
this simulation F0 does know the secret key matching E1 (since we are not making any reduction
to the security of the encryption scheme).

Then F0 runs the signature generation protocol for a not-semi-correct execution. Remember
i∈S wi with F0 knowing
i>1 wi (which is known to F0) and therefore

here we assume that we have a (t, t + 1) sharing of the secret key. So b = (cid:80)
wi for i > 1 but not knowing w1. Denote with wA = (cid:80)
w1 = b − wA.

F0 runs the protocol normally for Phases 1,2,3, and 4. It extracts the value γi for i > 1
(and he knows γ1 since he ran P1 normally). Therefore F0 knows k such that R = gk−1
since
k = ((cid:80)
i γi)δ−1. It also knows k1 since it was chosen normally according to the protocol. Before
moving to the simulation of Phase 5, let’s look at the MtAwc protocol for the computation of the
shares σi.

We note that since F0 knows the decryption key for E1 he also knows all the shares µ1j from

the invocation of the MtAwc protocol between P1 and Pj on input k1 and wj respectively7.

For the MtAwc protocol between P1 and Pj on input w1 and kj respectively, F0 knows the
value kj input by Pj since he extracts it from the range proof in the MtA protocol, which is also
a proof of knowledge of kj. However F0 does not know w1, so he therefore sends a random µj1 to
Pj and sets (implicitly) νj1 = kjw1 − µj1.

At the end we have that the share σ1 held by P1 is

σ1 = k1w1 +

(cid:88)

j>1

µ1j +

(cid:88)

j>1

νj1

by rearranging the terms and substituting the above we get
(cid:88)

(cid:88)

σ1 = ˜kw1 +

µ1j −

µj1

j>1

j>1

where ˜k = (cid:80)
R = gk−1

.

i ki. Remember that since this is not a semi-correct execution then ˜k (cid:54)= k where

Since w1 = b − wA we have

where

σ1 = ˜kb + µ1

µ1 =

(cid:88)

j>1

µ1j −

(cid:88)

j>1

µj1 − ˜kwA

with µ1, ˜k known to F0.

Note that this allows F0 to compute the correct value

gσ1 = ˜B

˜kgµ1

and therefore the correct value of Rs1 as

Rs1 = Rk1m+rσ1 = gk−1(k1m+rσ1) = gk−1(k1m+rµ1) ˜Bk−1 ˜kr

or

Rs1 = g ˆµ1 ˜B

ˆβ1

where ˆµ1 = k−1(k1m + rµ1) and ˆβ1 = k−1˜kr and ˆµ1 and ˆβ1 are known to F0.

We now continue the simulation

7 In this case we do not need to extract anything from Pj’s ZK proof, but we still need to check that the

value sent by Pj is correct.

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

19

– 5A/5B F0 selects a random (cid:96)1 and sets V1 = Rs1g(cid:96)1 A1 = gρ1 = ˜A = ga. It simulates the
ZK proof (since it does not know ρ1 or s1). It extracts si, (cid:96)i, ρi from the adversary such that
Vi = Rsig(cid:96)i = gk−1sig(cid:96)i and Ai = gρi. Let sA = (cid:80)
Note that

i>1 k−1si

V = g−my−r (cid:89)

Vi = g−my−rV1

(cid:89)

Vi

and therefore substituting the above relations (and setting (cid:96) = (cid:80)

i (cid:96)i )

i

i>1

V = g(cid:96)Rs1gsA−my−r

Note that y = ˜B so y−r = ˜B−r. Therefore

V = g(cid:96)g ˆµ1 ˜B

ˆβ1 gsA−m ˜B−r

or

V = g(cid:96)gθ ˜Bκ
where θ = ˆµ1 + sA − m and κ = ˆβ1 − r known to F0.
Note that for executions that are not semi-correct κ (cid:54)= 0

– 5C/5D F0 computes T1 = A(cid:96)1 correctly (which he can do since he knows (cid:96)1) but for U1 outputs

U1 = ˜A(cid:96)+θ ˜C κ and it aborts.

Note what happens when ˜C = gab. By our choice of a = ρ1 and b = x we have that U1 = V ρ1 as
in Game G0. However when ˜C is a random group element, U1 is uniformly distributed as in G1.

Therefore under the DDH assumption G0 and G1 are indistinguishable.

Indistinguishability of G1 and G2. We note that in G2 the simulator broadcasts a random ˜V1 = R˜s1g(cid:96)1
which is indistinguishable from the correct V1 = Rs1g(cid:96)1 because of the “mask” g(cid:96)1 which (under
the DDH) is computationally indistinguishable from a random value, given that the adversary only
has A1.

More in detail, let ˜A = ga−δ, ˜B = gb and ˜C = gab be the DDH challenge where δ = 0 or

random in Zq.

The simulator here proceeds as in G0 (i.e. the regular protocol) until Phase 5.

– 5A/5B F0 broadcasts V1 = Rs1 ˜A and A1 = ˜B. It simulates the ZK proof (since it does not
know (cid:96)1 or ρ1). It extracts si, (cid:96)i, ρi from the adversary such that Vi = Rsig(cid:96)i = gk−1sig(cid:96)i and
Ai = gρi.

– 5C/5D F0 computes U1 as a random element and T1 = ˜C ˜A

j>1

ρj and it aborts.

(cid:80)

Note what happens when ˜A = ga. By our choice, a = (cid:96)1 and b = ρ1, and we have that
V1 = Rs1 g(cid:96)1 and T1 = A(cid:96)1 as in Game G1. However when ˜A = gag−δ with a random δ, then this
is equivalent to have V1 = R˜s1g(cid:96)1 and T1 = A(cid:96)1 with a randomly distributed ˜s1 as in Game G2.

Therefore under the DDH assumption G1 and G2 are indistinguishable.

4.9 Finishing up the proof

Before we conclude the proof we note that our protocol detects the presence of a malicious adversary
by noticing that the signature does not verify. As pointed out by Lindell in [28] this strategy is
not immediately simulatable against a malicious adversary for the following reason. Consider what
happens in Phase 5: In the semi-correct simulation F rewinds the adversary to “hit” the correct
s. But if the adversary had decided to be malicious and terminate the protocol with an invalid
signature, then the protocol would not be simulatable. If F hits an invalid signature “on purpose”
(e.g. by not rewinding), then the simulation is distinguishable by a semi-honest adversary who
does hit the correct signature.

20

Rosario Gennaro and Steven Goldfeder

Luckily for a “game-based” deﬁnition of security, this is not an issue as discussed in [28]. Let
Q < λc be the maximum number of signature queries that the adversary makes. In the real protocol,
the adversary will output a forgery after (cid:96) < Q queries, either because it stops submitting queries,
or because the protocol aborts. Therefore in our simulation, following Lindell [28], we choose a
random index ι ∈ [0...Q]:

– if ι = 0 we assume that all executions are semi-correct. In this case we can always simulates

as in the previous section

– otherwise we assume that the ﬁrst ι − 1 executions are semi-correct, but at the ιth execution

the value V is not equal to g(cid:96).

With probability 1/(Q + 1) ≥ λ−c this is a correct guess.

We can now complete the proof.

Proof (of Theorem 1).

Unforgeability. The forger F described above produces an indistinguishable view for the ad-
versary A, and therefore, A will produce a forgery with the same probability as in real life. The
success probability of F is at least (cid:15)3
8Q where Q is the maximum number of queries. That’s because
F has to succeed in

– choosing a good random tape for A (this happens with probability larger than (cid:15)
2 )
– hitting a good public key y (this also happens with probability larger than (cid:15)
2 )
– guessing the correct index query (cid:96) (this happens with probability larger than 1/Q)

Under those conditions, the adversary A will output a forgery with probability at least (cid:15)
2 .

Under the security of the DSA signature scheme, the probability of success of F must be
negligible, which implies that (cid:15) must also be negligible, contradicting the assumption that A has
a non-negligible probability of forging.
Correctness. If all players are honest, the protocol fails only if one of the MtA protocols fails.
Since we have a total of 4n2 such sub-protocols executed during a run of our signature protocol,
we have that our protocol fails with probability at most 4n2

q which is negligible.

5 Removing the ZK proofs from the MtA protocol

Note about the previous version: The protocol described in this section is not secure as shown
in [37, 32]. We are leaving the section in the paper as historical record.

As we mentioned in the Introduction, the ZK proofs in the MtA protocol are the most expensive
step of our protocol due not only to the fact that these are ZK proofs over the Paillier cryptosystem,
but also that every player has to run n of them (since they are speciﬁc to each execution of the
MtA protocol).

We consider what happens if the range proofs are eliminated. As we discussed in Section 3, the
MtA protocol needs to be secure in the presence of an oracle that tells the parties if a reduction
mod N happens during the execution. Note that in reality the oracle represents the failure of the
veriﬁcation of the signature generated by the protocol, and if that happens the system is reset.
So the oracle is a very weak oracle, which stops working the moment it tells you that a reduction
mod N happened.

We conjecture that our protocol remains secure even if the ZK proofs are eliminated for Alice
and simpliﬁed for Bob in the MtA and MtAwc protocol. More precisely both the MtA and MtAwc
protocol work as follows:

– Neither party proves that their values a, b are “small”

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

21

– Bob broadcasts B = gb, B(cid:48) = gβ(cid:48)

together with a ZK proof of knowledge for b, β(cid:48) mod q using

Schnorr’s prooof [35]. Alice also checks that gα = BaB(cid:48).
We point out that B = gb is public in our threshold DSA protocol. Indeed in one case b = wi,
the share of the secret key x held by player Pi and B = gb is public at the end of the key
generation phase together with a ZK proof of knowledge. In the other case b = γi, and B = gb
will be public at the end of following round which is when Alice performs the above check.

For sake of completeness here is a description of the sMtA (simpliﬁed MtA) protocol which will

replace the MtA and MtAwc protocols in our full protocol.

1. Alice initiates the protocol by

– sending cA = EA(a) to Bob

2. Bob computes the ciphertext cB = b ×E cA +E EA(β(cid:48)) = EA(ab + β(cid:48)) where β(cid:48) is chosen
uniformly at random in ZN . Bob sets his share to β = −β(cid:48) mod q. He responds to Alice by
– sending cB and B(cid:48) = gβ(cid:48)
– proving in ZK that he knows b, β(cid:48) such that B = gb and B(cid:48) = gβ(cid:48)

3. Alice decrypts cB to obtain α(cid:48). She sets α = α(cid:48) mod q and accepts only if gα = BaB(cid:48).

To support our conjecture we propose some “ad-hoc” computational assumptions, which if true
would guarantee the security of the protocol. The assumptions are new and non-standard, yet they
look reasonable. We discuss them informally below – a full proof of security will appear in the ﬁnal
version.
Information Leaked to Alice by removing the Range Proof. If we remove the proofs
that the input a used by Alice is small, we leak information about the input used by Bob via the
knowledge of whether a reduction mod N happened or not (see discussion in Section 3).

The standard approach to model this leakage is to give the simulator access to an oracle that
tells if the reduction happened or not. Recall that the Bob simulator does not know the inout b
and instead chooses a random input b(cid:48) and a random mask β(cid:48). However the simulator also queries
a modular reduction oracle with values N, a, β(cid:48) and the oracle will tell the simulator if ab + β(cid:48) is less
than N . The output of the simulator includes this “ﬂag” bit.

The oracle will stop working once a moduar reduction takes place (since in the main protocol

there will be an abort).
Information Leaked to Bob by removing the ZK Consistency Proof. Here instead we
are able to simulate Bob’s view under a stronger assumption on the Paillier cryptosystem.

If Bob is corrupted, then the simulated Alice sends the encryption of a random value cA = E(ˆa).
But then it must decide whether to accept or reject at the end of step (2) (where the real Alice
checks that gα = BaB(cid:48)) without knowing ˆa. Here we assume that the simulator is provided with
an oracle ΩcA(cB, b, β) which answers 1 if and only if Dec(cB) = b · Dec(cA) + β mod q. Then the
simulator will extract b, β from the malicious Bob’s proof of knowledge, and query ΩcA (cB, b, β),
and it accepts if the oracle answers 1.

Security cannot be based on the semantic security of the Paillier encryption scheme anymore
since the presence of the oracle immediately implies that Paillier is not semantically secure anymore.
However consider the following experiment:

– Generate a Paillier key (E, D)
– Generate two random values a0, a1 ∈R Zq and publish A = ga0
– Choose a random bit b and publish c = E(ab)
– Let b(cid:48) be the output of the adversary who is allowed restricted access to the oracle Ωc – by

restricted we mean that the oracle will stop working after it outputs 0.

We say that the Paillier-ECR assumption holds if for every PPT adversary, the probability that
b = b(cid:48) is negligibly close to 1/2. Under the Paillier-ECR assumption we can prove that no adversary
given ga0 can distinguish if the sMtA protocol was run with a0 or a1 (with both values being “high

22

Rosario Gennaro and Steven Goldfeder

entropy”—in particular randomly chosen). This is suﬃcient to simulate sMtA with high entropy
inputs, which is what is needed to prove security of our threshold DSA protocol.

We note that our Paillier-ECR assumption is a weaker version of the Paillier-EC assumption in
[28]. In the latter the oracle access is not restricted, which makes the assumption much stronger.
In our case it is suﬃcient to consider the restricted oracle since the real protocol stops if Alice
detects cheating.

5.1 Modiﬁed simulation for the threshold protocol

We ﬁrst point out that in the presence of the modular reduction oracle and under the Paillier-ECR
assumption, the sMtA protocol is simulatable so the simulation of the threshold DSA protocol
remains basically the same, with one crucial diﬀerence. When in any of the sMtA simulation the
modular reduction oracle ﬂags that a reduction mod N took place, the main simulator immediately
switches to a non-semi-correct execution since in this case the shares of k held by the players do
not match the ones used in the signature computation (i.e. the signature veriﬁcation is going to
fail). Because in real life the protocol aborts the simulation will also stop at this point.

Remark: Note that the simulation of the main protocol uses the range proofs also to extract
values known by the adversary. Since we removed the range proofs, obviously our simulator cannot
do that. However we can augment the key generation protocol with a proof of knowledge of the
secret key of the Paillier encryption key. This will allow the simulator to extract the secret keys
held by the adversary and it is easy to verify that this will enable the simulator to decrypt the
values that in the main simulation were extracted from the range proofs.

5.2 Security of the simpliﬁed protocol

The two new assumptions that we introduce are very diﬀerent in nature. The Paillier-ECR as-
sumption just makes a stronger requirement on the Paillier encryption scheme. It is orthogonal to
the security of the DSA signature scheme.

On the other hand, assuming the presence of the modular reduction oracle implies stronger
security assumptions on the unforgeability of DSA. Indeed note that when the honest player plays
the respondent (Bob) role in the sMtA protocols, his inputs are his share of ρ (the mask for
the inversion of k) and his share of x (the secret key). That means that the protocol is leaking
information about these values, and that we need to assume that DSA remains unforgeable even
when this information is leaked to the adversary.

To make things more complicated, the adversary controls n − 1 players, each with its own
Paillier modulus Ni, and therefore gets information about ρ and x from each sMtA interaction the
adversary has with the honest player (each over a diﬀerent modulus Ni).

On the positive side, the shares of ρ and x are “high entropy” secrets and a reduction mod N
can only happen once in any of the invocations of the sMtA protocol, since if that happens the
protocol ends. It is therefore plausible to assume that we do not leak enough information to allow
the adversary to forge.

This can be formalized via the following stronger assumption on the unforgeability of DSA. We

deﬁne a game between a Challenger and an Attacker:

– The Challenger receives a random DSA public key y = gx and gives the attacker a random

number ˆx ∈R Zq. Let x1 = x − ˆx mod q.

– The Attacker chooses n − 1 RSA moduli Ni > q3 for i = 2, . . . , n.
– The Attacker submits a message m and 2(n − 1) + 1 numbers λi1, λi2 ∈ ZN and ˆρ ∈ Zq for

i = 2, . . . , n.

– The Challenger chooses ρ1 ∈R Zq and βi1, βi2 ∈R ZN for i = 2, . . . , n..

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

23

– The Challenger has access to an oracle that if all the values λi1x1 + β1 and λi2ρ1 + β2 are less
than N , will return (r, s) a valid DSA signature on m and also α = ρk mod q where k ∈R Zq
and r = gk−1

and ρ = ˆρ + ρ(cid:48). In this case these values are returned to the Challenger.

– Otherwise the oracle returns nothing and the game ends.

The Attacker wins if he forges a signature on a message for which the Challenger did not output
a signature. We say that the Modular DSA Security Assumption holds if the probability that an
eﬃcient adversary wins the above game is infeasible.

Theorem 2. Assuming

– The Modular DSA Security Assumption;
– The Paillier-ECR Assumption;
– that KG, Com, Ver, Equiv is a non-malleable equivocable commitment scheme;
– the DDH Assumption

then our threshold DSA scheme where the sMtA protocol replaces the MtA and MtAwc protocols,
is unforgeable.

To prove the theorem we show that an adversary who is able to forge a DSA signature in our
simpliﬁed protocol, can be turned into an attacker breaking the Modular DSA Security Assumption.
Let y = gx the DSA public key received by the Challenger. The Challenger runs a simulation
for the distributed Adversary which ends with y as the public key. This simulation is identical to
the one described in Section 4.5. Here too we assume that the adversary controls players 2, . . . , n
and that the simulator controls player 1. The Adversary now knows ˆx the sum of the shares of the
bad players but not x1 the share of the good player with x = x1 + ˆx mod q.

When the Adversary submits a message m, the Challenger runs a simulation similar to the one

described in Section 4.6.

Here the value λi1 is the value a submitted by player Pi (controlled by the adversary) as the
initiator in the ﬁrst instance of the sMtA protocol with P1 running on input x1 – βi1 is the mask
β(cid:48) used by P1 as the respondent in that same protocol.

Similarly the value λi2 is the value a submitted by player Pi (controlled by the adversary) as
the initiator in the second instance of the sMtA protocol with P1 running on input ρ1 – βi2 is the
mask β(cid:48) used by P1 as the respondent in that same protocol.

Now the oracle allowed to the Challenger is exactly the Modular Reduction Oracle needed to
simulate P1 in the sMtA protocol. Therefore the Challenger can complete the simulation, with the
only diﬀerence that if the oracle signals that a modular reduction happened in any of the protocols,
the simulation follows the non-semi-correct case.

This simulation is clearly indistinguishable from the real execution, therefore the Adversary

will forge, and therefore we have created a succesful attacker for the Modular DSA game.

6 Extensions

Here we present the following natural extensions to our result.

6.1 Other additively homomorphic schemes.

Our scheme works with any additively homomorphic scheme with no modiﬁcation. It requires an
assumption analogous to the Paillier-EC or an eﬃcient ZK Proof for the statement in the MtAwc
protocol.

We also note that it is important that security holds under “adversarially chosen” public keys
(i.e. we need to prove or assume that the adversary cannot generate a public key such that it gives
him and advantage in the MtA protocol).

24

Rosario Gennaro and Steven Goldfeder

6.2 Other multiplicative to share conversions.

Our threshold DSA scheme works with any MtA protocol, i.e. any protocol that allows two parties
to convert their multiplicative shares of a secret into additive shares.

In particular the classic approach based on oblivious transfer by Gilboa [22] can be used. The
original protocol in [22] is secure only against semi-honest adversaries, but it can be strengthened
against a malicious adversary (see the literature on SPDZ or the recent work on threshold DSA in
[12]).

6.3 Simulation-Based Security

Our proof uses the game-based deﬁnition of unforgeability. The main technical reason is that
the simulator cannot detect if the current execution is semi-correct or not, and therefore has to
guess. This prevents us from achieving the stronger notion of simulation-based security (where
each execution of the protocol can be fully simulated).

While in the real world it is unfeasible to decide if an execution is semi-correct or not, the
simulator can do that if it were able to “extract” the bad players’ inputs to the MtA protocols.
Indeed that would allow the simulator to check that the values δi, Γi sent by the bad players
in Phases 3 and 4 are consistent with the inputs entered in the MtA protocols. If they are, the
execution is semi-correct, if they are not then the execution is not semi-correct. Once the simulator
knows which execution it is, it can choose the correct simulation strategy.

We note that in our current simulation, the simulator can already extract the input ki (from the
range proof in the MtA protocol) and the input wi (the share of the secret key, which it extracted
during the key generation). But in our current simulation it is not able to extract γi since we do
not require the players to prove knowledge of it. This is the section we discussed. Even in the
current protocol, we can extract γi from the range proof and indeed we do this in our simulation.
So is our protocol simulatable as is? And if it is should we just modify the main proof to no longer
guess whether the execution is semi-correct but to use this technique

The best way to solve this is to require Pi, Pj to run MtAwc also when interacting on inputs
ki, γj, since MtAwc forces the respondent (which runs on input γi) to prove knowledge of its input.
In turn this will allow the simulator to extract γi for the bad players and detect what kind of
execution is being run.

We note that the maliciously secure OT-based MtA protocol from [12] also allows for input

extraction, and therefore if used in our protocol, it will yield a fully simulatable protocol.

6.4 Deterministic Key Generation

A very popular feature of Bitcoin wallets is deterministic key generation. Introduced in Bitcoin-
Improvement-Proposal 32 (BIP32), the idea of this scheme is to allow one to deterministicly gen-
erate many keys from a single ECDSA key. Our key sharing is compatible with BIP32 public
derivations, and we leave it as future work to prove security in this setting.

7 Implementation, Benchmarks, and Evaluation

We implemented both the key generation and signature generation of our protocol, and we conﬁrm
that they are highly eﬃcient and fast enough to be used in practice. We benchmarked the version of
our protocol from Section 5 that does not contain the range proofs, but relies on the Paillier-ECR
assumption. We compare the performance of our protocol to the runtimes of Gennaro et al. [17]
and Boneh et al. [4]. All benchmarks were single-threaded and run on an an Intel quad-core i7-6700
CPU @ 3.40GHz and 64GB of RAM. We ran the code [17] and [4] on our benchmark machine to
get an accurate comparison. It should be noted that we implemented our scheme in C while theirs

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

25

is a Java implementation which calls native C libraries for the heaviest arithmetic computations.
All benchmarks were taken over the secp256k1 curve, which is is the curve used in Bitcoin and
more recently a NIST standard.

For the curve operations, we used libsecp256k1.8 We implemented the MtA protocol with Paillier

using the implementation from libhcs.9.

7.1 Benchmarking the data complexity

When compared to [17, 4], we reduce the amount of data transmitted. All ﬁgures in this section
were measured empirically from the respective implementations, and thus it is possible that they
may be further optimized in practice. For a threshold of t (i.e. when there are t + 1 participants
in the signing protocol), the total data d in bytes sent and received by a given player to/from all
other players during the signing protocol is given by: ’

In contrast, the data sent to/from a given player in [17] is given by:

dours(t) = 2, 328 + t × 5, 024 Bytes

dGennaro(t) = (t + 1) × 34, 578 Bytes

And the data transmitted per player in [4] is given by:

dBoneh(t) = (t + 1) × 38, 189 Bytes

Lastly, we mention that for the 2-of-n case, we have dours(t = 1) = 3, 976 B. In contrast, the
recent protocol of [12] requires far more than that with 86.7 KiB for 2-of-2 signing and 106.7 KiB
for 2-of-n signing. Lindell’s scheme [28] only requires 769 B to be communicated in the 2-of-2 case
(but does not support 2-of-n).

7.2 Benchmarking signature generation time

Following the methodology of [4, 17], we benchmark the raw computation time of a single player
without counting network costs. Since each player runs their computation in parallel, this represents
the running time of the entire protocol other than network latency. We ﬁnd that our protocol
signiﬁcantly outperforms both of [4, 17] when using this metric.

As in [4, 17], the protocol running time has a ﬁxed cost that is independent of the number of
players plus a linear marginal cost as the threshold increases. We stress that the signing time only
depends on the number of active participants (t + 1), but does not depend on n, the total number
of players. All times are given on a single core, and were averaged over 1000 iterations.

Our protocols running time is given by:

The running time of [17] is given by:

rours(t) = 29 + (t) × 24 milliseconds

The running time of [4] is given by:

rGennaro(t) = 142 + (t) × 52 milliseconds

rBoneh(t) = 397 + (t) × 91 milliseconds

We can see that our protocol signiﬁcantly outperforms both previous schemes. See Figure 1 for

a comparison of the concrete raw computation times for thresholds up to 20.

8 https://github.com/bitcoin-core/secp256k1
9 https://github.com/tiehuis/libhcs

26

Rosario Gennaro and Steven Goldfeder

Fig. 1. Comparison of the raw computation time as the threshold increases between this work
and previous schemes.

8 Conclusion

We have presented a threshold ECDSA protocol that is an improvement over the existing schemes
by every metric. Although [17] has been available for some time, there are still to our knowledge
no Bitcoin services or user wallets that oﬀer threshold-signature security. We believe that this is
due to the impracticality of their distributed key generation protocol. Having to rely on a trusted
dealer to distribute key shares exposes a single point of failure for the system and in doing so runs
contrary to the entire premise of using threshold signatures in the ﬁrst place.

We solve this problem by presenting and implementing a new scheme with a highly eﬃcient
distributed key generation protocol. Together with our reduction in running time and data trans-
ferred, we believe that ECDSA threshold signatures are ﬁnally mature enough for adoption.

9 Acknowledgements

We thank Harry Kalodner, Yehuda Lindell, Ariel Nof, Ben Riva, and Omer Shlomovits for useful
feedback and discussions and for pointing out errors in earlier versions.

Rosario Gennaro is supported by NSF Grant 1565403. Steven Goldfeder is supported by an NSF
Graduate Research Fellowship under grant number DGE 1148900 and NSF award CNS-1651938.

References

1. Bar-Ilan, J., Beaver, D.: Non-cryptographic fault-tolerant computing in constant number of rounds
of interaction. In: Proceedings of the eighth annual ACM Symposium on Principles of distributed
computing. pp. 201–209. ACM (1989)

2. Bari´c, N., Pﬁtzmann, B.: Collision-free accumulators and fail-stop signature schemes without trees. In:
International Conference on the Theory and Applications of Cryptographic Techniques. pp. 480–494.
Springer (1997)

3. Boneh, D.: Digital signature standard. In: Encyclopedia of cryptography and security, pp. 347–347.

Springer (2011)

4. Boneh, D., Gennaro, R., Goldfeder, S.: Using level-1 homomorphic encryption to improve threshold

dsa signatures for bitcoin wallet security. In: Latincrypt (2017)

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

27

5. Boudot, F.: Eﬃcient proofs that a committed number lies in an interval. In: International Conference

on the Theory and Applications of Cryptographic Techniques. pp. 431–444. Springer (2000)

6. Canetti, R., Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Adaptive security for threshold cryp-

tosystems. In: Annual International Cryptology Conference. pp. 98–116. Springer (1999)

7. Canetti, R., Goldwasser, S.: An eﬃcient Threshold public key cryptosystem secure against adaptive
chosen ciphertext attack. In: Advances in Cryptology - EUROCRYPT ’99, International Conference
on the Theory and Application of Cryptographic Techniques, Prague, Czech Republic, May 2-6, 1999,
Proceeding. pp. 90–106 (1999)

8. Damgard, I., Groth, J.: Non-interactive and reusable non-malleable commitment schemes. In: Proceed-
ings of the thirty-ﬁfth annual ACM symposium on Theory of computing. pp. 426–437. ACM (2003)
9. Damg˚ard, I., Keller, M., Larraia, E., Miles, C., Smart, N.P.: Implementing aes via an actively/covertly
secure dishonest-majority mpc protocol. In: International Conference on Security and Cryptography
for Networks. pp. 241–263. Springer (2012)

10. Di Crescenzo, G., Ishai, Y., Ostrovsky, R.: Non-interactive and non-malleable commitment. In: Pro-
ceedings of the thirtieth annual ACM symposium on Theory of computing. pp. 141–150. ACM (1998)
11. Di Crescenzo, G., Katz, J., Ostrovsky, R., Smith, A.: Eﬃcient and non-interactive non-malleable com-
mitment. In: International Conference on the Theory and Applications of Cryptographic Techniques.
pp. 40–59. Springer (2001)

12. Doerner, J., Kondi, Y., Lee, E., et al.: Secure two-party threshold ecdsa from ecdsa assumptions. In:

IEEE Symposium on Security and Privacy. p. 0. IEEE (2018)

13. Dolev, D., Dwork, C., Naor, M.: Non-malleable cryptography,”. In: Proceedings of the 23rd Annual

Symposium on the Theory of Computing, ACM (1991)

14. Fujisaki, E., Okamoto, T.: Statistical zero knowledge protocols to prove modular polynomial relations.

In: Annual International Cryptology Conference. pp. 16–30. Springer (1997)

15. Gennaro, R.: Multi-trapdoor commitments and their applications to proofs of knowledge secure under
concurrent man-in-the-middle attacks. In: Annual International Cryptology Conference. pp. 220–236.
Springer (2004)

16. Gennaro, R., Goldfeder, S.: Fast multiparty threshold ecdsa with fast trustless setup. In: Proceedings
of the 2018 ACM SIGSAC Conference on Computer and Communications Security. pp. 1179–1194.
ACM (2018)

17. Gennaro, R., Goldfeder, S., Narayanan, A.: Threshold-optimal dsa/ecdsa signatures and an application
to bitcoin wallet security. In: International Conference on Applied Cryptography and Network Security.
pp. 156–174. Springer (2016)

18. Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Robust threshold dss signatures. In: International
Conference on the Theory and Applications of Cryptographic Techniques. pp. 354–371. Springer (1996)
19. Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Robust threshold dss signatures. Information and

Computation 164(1), 54–84 (2001)

20. Gennaro, R., Micali, S.: Independent zero-knowledge sets. In: International Colloquium on Automata,

Languages, and Programming. pp. 34–45. Springer (2006)

21. Gennaro, R., Micciancio, D., Rabin, T.: An eﬃcient non-interactive statistical zero-knowledge proof
system for quasi-safe prime products. In: In Proc. of the 5th ACM Conference on Computer and
Communications Security (CCS-98. Citeseer (1998)

22. Gilboa, N.: Two party rsa key generation. In: Advances in Cryptology - CRYPTO ’99. pp. 116–129

(1999)

23. Goldwasser, S., Micali, S., Rivest, R.L.: A digital signature scheme secure against adaptive chosen-

message attacks. SIAM Journal on Computing 17(2), 281–308 (1988)

24. Hazay, C., Mikkelsen, G.L., Rabin, T., Toft, T.: Eﬃcient rsa key generation and threshold paillier in
the two-party setting. In: Cryptographers’ Track at the RSA Conference. pp. 313–331. Springer (2012)
25. Jarecki, S., Lysyanskaya, A.: Adaptively secure threshold cryptography: Introducing concurrency, re-
moving erasures. In: International Conference on the Theory and Applications of Cryptographic Tech-
niques. pp. 221–242. Springer (2000)

26. Keller, M., Pastro, V., Rotaru, D.: Overdrive: making spdz great again. In: Annual International
Conference on the Theory and Applications of Cryptographic Techniques. pp. 158–189. Springer (2018)

27. Kravitz, D.W.: Digital signature algorithm (Jul 27 1993), uS Patent 5,231,668
28. Lindell, Y.: Fast secure two-party ecdsa signing. In: Annual International Cryptology Conference. pp.

613–644. Springer (2017)

28

Rosario Gennaro and Steven Goldfeder

29. Lindell, Y., Nof, A.: Fast secure multiparty ecdsa with practical distributed key generation and appli-
cations to cryptocurrency custody. In: Proceedings of the 2018 ACM SIGSAC Conference on Computer
and Communications Security. pp. 1837–1854. ACM (2018)

30. MacKenzie, P., Reiter, M.K.: Two-party generation of dsa signatures. In: Annual International Cryp-

tology Conference. pp. 137–154. Springer (2001)

31. MacKenzie, P., Yang, K.: On simulation-sound trapdoor commitments. In: International Conference

on the Theory and Applications of Cryptographic Techniques. pp. 382–400. Springer (2004)

32. Makriyannis, N., Peled, U.: A note on the security of GG18 (2021), Fireblocks Blog
33. Paillier, P.: Public-key cryptosystems based on composite degree residuosity classes. In: International
Conference on the Theory and Applications of Cryptographic Techniques. pp. 223–238. Springer (1999)
34. Rivest, R.L., Shamir, A., Adleman, L.: A method for obtaining digital signatures and public-key

cryptosystems. Communications of the ACM 21(2), 120–126 (1978)

35. Schnorr, C.: Eﬃcient signature generation by smart cards. J. Cryptology 4(3), 161–174 (1991)
36. Shamir, A.: How to share a secret. Communications of the ACM 22(11), 612–613 (1979)
37. Tymokhanov, D., Shlomovits, O.: Alpha-rays: Key extraction attacks on threshold ecdsa implementa-

tions. Cryptology ePrint Archive, Report 2021/1621 (2021), https://ia.cr/2021/1621

A The ZK Proofs for the MtA protocol

In this section we describe the ZK proofs that are needed in the MtA protocol (see Section 3). The
proofs are based on similar ones from [30]: speciﬁcally we prove statements that are simpler than
the ones needed in [30].

In these proofs the Veriﬁer uses an auxiliary RSA modulus ˜N which is the product of two safe
primes ˜P = 2˜p + 1 and ˜Q = 2˜q + 1 with ˜p, ˜q primes. The Veriﬁer also uses two values h1, h2 ∈ Z ∗
˜N
according to the commitment scheme in [14]. Security is based on the assumption that the Prover
cannot solve the Strong RSA problem over ˜N .

Therefore our initialization protocol must be augmented with each player Pi generating an
additional RSA modulus ˜Ni, and values h1i, h2i, together with a proof that they are of the correct
form (see [14]).

Note: The respondent proofs have been modiﬁed with respect to the previous version of this paper
to address weaknesses pointed out in [37, 32].

A.1 Range Proof

This proof is run by Alice (the initiator) in both MtA and MtAwc protocols.

The input for this proof is a Paillier public key N, Γ and a value c ∈ ZN 2. The prover knows

m ∈ Zq and r ∈ Z ∗

N such that c = Γ mrN mod N 2, where q is the order of the DSA group.

At the end of the protocol the Veriﬁer is convinced that m ∈ [−q3, q3].

– The Prover selects α ∈R Zq3, β ∈R Z ∗

N , γ ∈R Zq3 ˜N and ρ ∈R Zq ˜N .

The Prover computes z = hm
The Prover sends z, u, w to the Veriﬁer.

1 hρ

2 mod ˜N , u = Γ αβN mod N 2, w = hα

1 hγ

2 mod ˜N .

– The Veriﬁer selects a challenge e ∈R Zq and sends it to the Prover.
– The Prover computes s = reβ mod N , s1 = em + α and s2 = eρ + γ and sends s, s1, s2 to the

Veriﬁer.

– The Veriﬁer checks that s1 ≤ q3, u = Γ s1sN c−e mod N 2 and hs1

1 hs2

2 z−e = w mod ˜N .

Completeness. By inspection. Note that there is a negligible probability of failure for the honest
prover (when α > q3 − q2 – which happens with negligible probability – it might happen that
s1 > q3).
Soundness. Let ˜N , ˜s be our Strong RSA challenge. We show how to solve it using a Prover who
succeeds on incorrect instances (i.e. where |m| > q3).

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

29

Let h2 = ˜s and h1 = hχ

2 for a random χ ∈ Zq ˜N . It is not hard to see that the distribution of

these values is indistinguishable from the real one with suﬃciently high probability.

Run the Prover on a successful execution over a challenge e and then rewind him and ﬁnd a
successful execution with challenge ˆe. Therefore we have the same ﬁrst message z, u, w and two
set of answers s, s1, s2 for challenge e, and ˆs, ˆs1, ˆs2 for challenge ˆe both satisfying the veriﬁcation
equations. Let ∆E = e − ˆe, ∆s1 = s1 − ˆs1 and ∆s2 = s2 − ˆs2.

Let λ = GCD(∆s2 + χ∆s1, ∆E). Assume λ (cid:54)= ∆E: denote with λs = (∆s2 + χ∆s1)/λ and

λE = ∆E/λ > 1. Then we ﬁnd µ, ν such that µλs + νλE = 1.

Then the solution to the Strong RSA challenge is ˜x = zµ˜sν mod ˜N , λE. Indeed note that

w = hs1

1 hs2

2 z−e = hˆs1

1 hˆs2

2 z−ˆe mod ˜N

therefore

which implies

Concluding

z∆E = h∆s1

1 h∆s2

2 = ˜s∆s2+χ∆s1 mod ˜N

zλE = ˜sλS mod ˜N

˜s = ˜sµλs+νλE = [zµ˜sν]λE mod ˜N

We now need to prove that the case λ = ∆E cannot happen with high probability.
Consider ﬁrst the case λ = ∆E but ∆E does not divide ∆s1. Write χ = χ0 +χ1 ˜p˜q with χ1 chosen
uniformly at random from a set of size > q. Note that the value χ1 is information theoretically
secret from the adversary (who only has h1, h2). We have that

∆s2 + χ∆s1 = ∆s2 + χ0∆s1 + χ1∆s1 ˜p˜q

Then there is a prime power ab (with a ≥ 2) such that ab|∆E, ab−1|∆s1 but ab does not divide
∆s1. Note that this implies that ab−1|∆s2. Set c0 = (∆s2 + χ0∆s1)/ab−1 and c1 = ∆s1 ˜p˜q/ab−1.
We have that c0 + χ1c1 = 0 mod a and c1 (cid:54)= 0 mod a. The number of elements χ1 for which this
equivalence holds is at most q/a + 1 and thus the probability of this holding for a random choice
of χ1 is at most 1
q . Otherwise we are in the case above with λ (cid:54)= ∆E.
Now consider the case λ = ∆E and ∆E|∆s1. Note that this implies that ∆E|∆s2 as well. Deﬁne

q which is at most 1

a + 1

2 + 1

m1 = ∆s1/∆E, ρ1 = ∆s2/∆E, α1 = (eˆs1 − ˆes1)/∆E, γ1 = (eˆs2 − ˆes2)/∆E.

These ensure that z = hm1
Finally denote with m(cid:48)
1 = m1 mod N and α(cid:48)

2 mod ˜N , w = hα1

1 hρ1
1 = ∆s1∆−1

1 hγ1
E mod N and α(cid:48)
1 = α1 mod N , there must be r1, β(cid:48) ∈ Z ∗

2 mod ˜N , s1 = em1 + α1 and ˆs1 = ˆem1 + α1.
1 = (eˆs1 − ˆes1)∆−1
E mod N . Note that since

N such that

m(cid:48)

c = Γ m(cid:48)

1rN
1

and u = Γ α(cid:48)

1 (β(cid:48))N mod N 2

At this point we know the following facts

s1 < q3 s1 = em1 + α1 s1 = em(cid:48)

1 + α1 mod N

ˆs1 < q3 ˆs1 = ˆem1 + α1 ˆs1 = ˆem(cid:48)

1 + α1 mod N

Therefore we can prove that m1 ∈ [−q3, q3] since |m1| ≤ |∆s1| ≤ q3. But this implies that m(cid:48)
[−q3, q3] since m(cid:48)

1 = m1 mod N and N > q7.

1 ∈

Honest-Verifier Zero-Knowledge. The simulator proceeds as in [30]. Choose z, s, s1, s2, e
according to the appropriate distribution and set u = Γ s1sN c−e mod N and w = hs1
2 z−e mod
˜N .

1 hs2

30

Rosario Gennaro and Steven Goldfeder

A.2 Respondent ZK Proof for MtAwc

This proof is run by Bob (the responder) in the MtAwc protocol. For the MtA protocol a simpler
version of this proof if needed, which we present later.

The input for this proof is a Paillier public key N, Γ and two values c1, c2 ∈ ZN 2, together with

a value X in G the DSA group.

The Prover knows x ∈ Zq, y ∈ Zq5 and r ∈ Z ∗

N such that c2 = cx

1 Γ yrN mod N 2, and X = gx ∈

G, where q is the order of the DSA group.

At the end of the protocol the Veriﬁer is convinced of the above and that x ∈ [−q3, q3] and

y ∈ [−q7, q7].

– The Prover selects α ∈R Zq3 , ρ ∈R Zq ˜N , ρ(cid:48) ∈R Zq3 ˜N , σ ∈ Zq ˜N , β ∈R Z ∗

N , γ ∈R Zq7 and

τ ∈R Zq3 ˜N .
The Prover computes u = gα, z = hx
1 Γ γβN mod N 2, and w = hγ
cα
The Prover sends u, z.z(cid:48), t, v, w to the Veriﬁer.

1 hρ
2 mod ˜N .

1 hτ

2 mod ˜N , z(cid:48) = hα

1 hρ(cid:48)

2 mod ˜N , t = hy

1hσ

2 mod ˜N , v =

– The Veriﬁer selects a challenge e ∈R Zq and sends it to the Prover.
– The Prover computes s = reβ mod N , s1 = ex + α, s2 = eρ + ρ(cid:48), t1 = ey + γ and t2 = eσ + τ .

The Prover sends s, s1, s2, t1, t2 to the Veriﬁer.

– The Veriﬁer checks that s1 ≤ q3, t1 ≤ q7, g1 = X eu ∈ G, hs1

1 hs2

2 = zez(cid:48) mod ˜N , ht1

1 ht2

2 =

tew mod ˜N , and cs1

1 sN Γ t1 = ce

2v mod N 2.

Completeness. By inspection (as before there is a negligible chance of failure for the honest
prover when either α > q3 − q2 or γ > q7 − q6

Soundness. Let ˜N , ˜s be our Strong RSA challenge. We show how to solve it using a Prover who
succeeds on incorrect instances (i.e. where |x| > q3).

Let h2 = ˜s and h1 = hχ

2 for a random χ ∈ Zq ˜N . It is not hard to see that the distribution of

these values is indistinguishable from the real one with suﬃciently high probability.

Run the prover on a successful execution over a challenge e and then rewind him and ﬁnd a
successful execution with challenge ˆe. Therefore we have the same ﬁrst message u, z, z(cid:48), t, v, w and
two set of answers s, s1, s2, t1, t2 for challenge e, and ˆs, ˆs1, ˆs2, ˆt1, ˆt2 for challenge ˆe both satisﬁng
theveriﬁcation equations. Let ∆E = e − ˆe, ∆s1 = s1 − ˆs1, ∆s2 = s2 − ˆs2, ∆t1 = t1 − ˆt1 and
∆t2 = t2 − ˆt2.

Let λ = GCD(∆s2 + χ∆s1, ∆E). Assume λ (cid:54)= ∆E: denote with λs = (∆s2 + χ∆s1)/λ and

λE = ∆E/λ > 1. Then we ﬁnd µ, ν such that µλs + νλE = 1.

Then the solution to the Strong RSA challenge is ˜x = zµ˜sν mod ˜N , λE. Indeed note that

z(cid:48) = hs1

1 hs2

2 z−e = hˆs1

1 hˆs2

2 z−ˆe mod ˜N

therefore

which implies

Concluding

z∆E = h∆s1

1 h∆s2

2 = ˜s∆s2+χ∆s1 mod ˜N

zλE = ˜sλS mod ˜N

˜s = ˜sµλs+νλE = [zµ˜sν]λE mod ˜N

Let λ(cid:48) = GCD(∆t2 + χ∆t1, ∆E). In a similar way as above we can prove that if λ(cid:48) (cid:54)= ∆E then

we can solve our Strong RSA challenge.

Therefore we can limit ourselves to the case λ = λ(cid:48) = ∆E.

Fast Multiparty Threshold ECDSA with Fast Trustless Setup

31

Consider ﬁrst the case λ = λ(cid:48) = ∆E but ∆E does not divide ∆s1. Write χ = χ0 + χ1 ˜p˜q with
χ1 chosen uniformly at random from a set of size > q. Note that the value χ1 is information
theoretically secret from the adversary (who only has h1, h2). We have that

∆s2 + χ∆s1 = ∆s2 + χ0∆s1 + χ1∆s1 ˜p˜q

Then there is a prime power ab (with a ≥ 2) such that ab|∆E, ab−1|∆s1 but ab does not divide
∆s1. Note that this implies that ab−1|∆s2. Set c0 = (∆s2 + χ0∆s1)/ab−1 and c1 = ∆s1 ˜p˜q/ab−1.
We have that c0 + χ1c1 = 0 mod a and c1 (cid:54)= 0 mod a. The number of elements χ1 for which this
equivalence holds is at most q/a + 1 and thus the probability of this holding for a random choice
of χ1 is at most 1
q . Otherwise we are in the case above with λ (cid:54)= ∆E.
In a similar fashion we can remove the case in which λ = λ(cid:48) = ∆E but ∆E does not divide ∆t1.
Now consider the case λ = λ(cid:48) = ∆E with ∆E|∆s1 and ∆E|∆t1. Note that this implies that

q which is at most 1

a + 1

2 + 1

∆E|∆s2 and ∆E|∆t2as well.

Deﬁne x1 = ∆s1/∆E, ρ1 = ∆s2/∆E, α1 = (eˆs1 − ˆes1)/∆E, ρ(cid:48)

σ1 = ∆t2/∆E, γ1 = (eˆt1 − ˆet1)/∆E and τ1 = (eˆt2 − ˆet2)/∆E.

Deﬁne x(cid:48)

1 = x1 mod N and y(cid:48)

1 = y1 mod N . Note that by deﬁnition

1 = (eˆs2 − ˆes2)/∆E, y1 = ∆t1/∆E,

cx(cid:48)
1 Γ y(cid:48)

1

1 κN = c2 mod N 2

for some κ as needed. And gx1 = X ∈ G. So we have extracted the required x, y. As in the previous
proof we can establish that x1, x(cid:48)
Honest-Verifier Zero-Knowledge. The simulator proceeds as in [30] and in the previous ZK
proof.

1 ∈ [−q3, q3] and y1, y(cid:48)

1 ∈ [−q7, q7].

A.3 Respondent ZK Proof for MtA

This proof is run by Bob (the responder) in the MtA protocol. It is a simpler version of the previous
protocol where Bob only proves that x, y are small (without proving that x is the discrete log of
any public value).

The input for this proof is a Paillier public key N, Γ and two values c1, c2 ∈ ZN 2 .
The Prover knows x ∈ Zq, y ∈ Zq5 and r ∈ Z ∗

N such that c2 = cx

1 Γ yrN mod N 2 where q is the

order of the DSA group.

At the end of the protocol the Veriﬁer is convinced of the above and that x ∈ [−q3, q3] and

y ∈ [−q7, q7].

– The Prover selects α ∈R Zq3 , ρ ∈R Zq ˜N , ρ(cid:48) ∈R Zq3 ˜N , σ ∈ Zq ˜N , β ∈R Z ∗

N , γ ∈R Zq7 and

τ ∈R Zq3 ˜N .
The Prover computes z = hx
2 mod ˜N .
N 2, and w = hγ
The Prover sends z, z(cid:48), t, v, w to the Veriﬁer.

2 mod ˜N , z(cid:48) = hα

1 hρ

1 hτ

1 hρ(cid:48)

2 mod ˜N , t = hy

1hσ

2 mod ˜N , v = cα

1 Γ γβN mod

– The Veriﬁer selects a challenge e ∈R Zq and sends it to the Prover.
– The Prover computes s = reβ mod N , s1 = ex + α, s2 = eρ + ρ(cid:48), t1 = ey + γ and t2 = eσ + τ .

The Prover sends s, s1, s2, t1, t2 to the Veriﬁer.
– The Veriﬁer checks that s1 ≤ q3, t1 ≤ q7 hs1

cs1
1 sN Γ t1 = ce

2v mod N 2.

1 hs2

2 = zez(cid:48) mod ˜N , ht1

1 ht2

2 = tew mod ˜N , and

The proof is immediate from the previous one.

Note about the previous version: The respondent ZK proofs have been modiﬁed as follows.
First of all note that now y ∈ Zq5 as required by the MtA protocols. This leads to the following
changes in the ZK proof: γ was chosen in ZN while now it is chosen in Zq7 and the veriﬁer performs
the additional range check t1 ≤ q7 (no range check on t1 was performed prior). Additionally there
was a typo in the range of τ which was chosen in Zq ˜N while now it is chosen in Zq3 ˜N .



=== Content from eprint.iacr.org_f9da7eb5_20250111_113509.html ===
One Round Threshold ECDSA with Identiﬁable Abort

Rosario Gennaro
The City University of New York
rosario@ccny.cuny.edu

Steven Goldfeder
Cornell Tech/Oﬀchain Labs
goldfeder@cornell.edu

Abstract

Threshold ECDSA signatures have received much attention in recent years due to the widespread
use of ECDSA in cryptocurrencies. While various protocols now exist that admit eﬃcient dis-
tributed key generation and signing, these protocols have two main drawbacks. Firstly, if a
player misbehaves, the protocol will abort, but all current protocols give no way to detect
In distributed settings, this can be catastrophic
which player is responsible for the abort.
as any player can cause the protocol to fail without any consequence. General techniques to
realize dishonest-majority MPC with identiﬁable abort add a prohibitive overhead, but we
show how to build a tailored protocol for threshold ECDSA with minimal overhead. Secondly,
current threshold ECDSA protocols (that do not rely on generic MPC) have numerous rounds
of interaction. We present a highly eﬃcient protocol with a non-interactive online phase al-
lowing for players to asynchronously participate in the protocol without the need to be online
simultaneously. We benchmark our protocols and ﬁnd that our protocol simultaneously re-
duces the rounds and computations of current protocols, while adding signiﬁcant functionality:
identiﬁable abort and noninteractivity.

Note: This report is now obsolete and readers should refer to the joint paper [8]
which subsumes it. The paper below is a revised version of the previous eprint
version which ﬁxes some crucial details in the protocol. The proof of the protocol
described in the previous version is not correct, though no attack has been shown
that exploits the bug in the proof. More details appear in the Introduction.

1

Introduction

Digital signatures are a crucial component to modern internet-based systems. When technology
companies issue software updates, they digitally sign those updates so that users can verify their
authenticity. Certiﬁcate Authorities (CAs) secure the web by issuing certiﬁcates attesting to the
authenticity of a website’s public key, and web servers in turn use those authenticated keys to
securely communicate with clients. In cryptocurrencies, digital signatures are used to authenticate
transactions, and the ability to generate a signature is equivalent to the ability to spend one’s
money. The commonality between all of these applications is that the theft or loss of the signing
key can be catastrophic, and a key diﬃculty is how to store signing keys in a manner that is both
easy to use and resilient to theft and loss.

Threshold cryptography [19], and threshold signatures in particular, has been gaining traction as
an approach to solving this problem. In a threshold signature scheme, signing keys are distributed
among several servers which need to act jointly in order to issue a signature. More speciﬁcally, in
a threshold signature scheme, a key is split into n shares and a parameter t is deﬁned such that
an adversary that compromises t or fewer shares is unable to generate a signature and learns no
information about the key. On the other hand, in a threshold optimal scheme, t + 1 shares can
be used to jointly issue a signature without ever reconstructing the key. Splitting the key in this
way eliminates a single point of failure and allows the honest parties to recover even in the face of
partial compromise.

1

Perhaps the most popular signature algorithm in deployed systems is the Elliptic Curve Digital
Signature Algorithm (ECDSA) [1]. Building a threshold signature scheme for (EC)DSA has been
a research topic for over two decades [30], but has gained increased interest recently due to the
adoption of ECDSA in Bitcoin, Ethereum, and other cryptocurrencies. Over the past two years,
several highly eﬃcient schemes have been proposed that support threshold signatures with any
number of participants [22, 27, 41], and indeed at least a dozen companies are now integrating
threshold ECDSA into their commercial products.

Identiﬁable and attributable aborts. The current state-of-the-art threshold ECDSA protocols
operate in the dishonest majority model. This model is highly desirable as it allows building
threshold signature protocols where the threshold t can take on any value so long as it is less than
n, the total number of players.

It is well known that in this model, guaranteeing output delivery is impossible, and indeed
if parties misbehave, the protocol may abort without producing a signature. Clearly, as t + 1
players are required to sign, and the adversary can corrupt up to t nodes, there is no guarantee
in the dishonest majority setting that a signature will be generated since there may simply not be
t + 1 honest nodes. But even if aborts are unavoidable, one may want to identify which player(s)
misbehaved and caused the abort. Unfortunately, current protocols do not address this issue and
aborts are completely unattributable.

For some uses of threshold ECDSA, identifying aborting parties is merely a convenience. Con-
sider for example a cryptocurrency exchange that splits its signing key among two servers that it
controls in order to gain resilience against an attacker that compromises one of the servers. When
the exchange wishes to sign, it can do so using a threshold signature scheme that requires the
participation of both servers. If the signing protocol fails, it knows that something has gone wrong
and needs to reboot one of its servers. It would certainly be convenient to know which server is
the corrupted one, but it is by no means critical as it is perfectly feasible to simply reset all of the
servers.

However, for other use cases, particularly ones which involve key shares that are controlled
by several distinct participants, the inability to identify aborts can be catastrophic. One such
use case is a protocol that was recently presented by Keep Network 1 to enable users to trade
bitcoins on the Ethereum blockchain. To facilitate this, a committee of nodes “locks up” coins in
a jointly held address on the Bitcoin blockchain and simultaneously unlocks them on Ethereum.
Conversely, when an Ethereum user wants to “cash out”, the committee will unlock funds on the
Bitcoin blockchain and send them to the user’s address. To lock up funds in their protocol, coins
are sent to a Bitcoin address that is jointly controlled by the committee. To achieve this, they
employ the threshold protocol of Gennaro and Goldfeder [27].

Crucial to their design is incentivizing the committee to lock and unlock user funds when
requested. But there’s a problem. What happens if one of the committee members misbehaves
and causes the signing protocol to abort? The ability to punish only the misbehaving player is
crucial, but doing so is impossible since in [27] (and all known protocols) there is no way to identify
which party caused the abort. In other words, a single rogue committee member could deny service
to the protocol and go completely undetected. Indeed Keep acknowledges this issue as problematic,
but it is impossible to ﬁx using any known dishonest-majority threshold ECDSA protocol.

Oﬀ/Online Processing. One major advantage of ECDSA (and all the other Schnorr-based [46]
signature schemes) is the ability to move all the expensive computation (in the case of ECDSA an
expensive point multiplication/group exponentiation) to an oﬄine preprocessing stage that can be
performed before the message is known. Once the message to be signed is available a single scalar
multiplication needs to be performed.

1https://keep.network/

2

Ideally one would like this property to be replicated in a distributed system that computes
signatures as well. Unfortunately all the recent dishonest-majority proposals that do not rely on
generic MPC do not have this property, and indeed, it’s much worse. The protocols of [29, 27, 41, 22]
require players to perform many rounds of expensive computation after the message is known. The
reason for this is that all the schemes above must perform a multi-round “distributed validity check”
which outputs the signature if the players indeed hold shares of a valid signature, but otherwise
reveals nothing except the fact that the protocol failed. The intuitive reason for the necessity of
this check is that an adversary controlling most of the players can induce incorrect signatures that
if reconstructed may reveal information about the key.

Our Contribution.
result (Section 3) is a new protocol with the following properties

In this paper, we present two new threshold ECDSA protocols. Our main

• Noninteractive online phase. The protocol can be split into an oﬄine preprocessing stage
with most of the computation and communication, and an online stage when the message
is known, consisting of a single communication round where each player performs a single
scalar multiplication. Interestingly, our protocol has an overall lower number of rounds than
[22, 27, 41], so even if the entire protocol was run online, it would still be fewer rounds.

• Identiﬁable Abort. The protocol allows the eﬃcient detection of aborting parties.

Our protocol can be proven secure in a simulation-based deﬁnition that assures that the ad-
versary learns nothing beyond a valid signature. However, the simulation game assumes that the
adversary sees the randomizer r before he chooses the message m to be signed (this is an inevitable
consequence of enforcing a single round in the online phase). This implies that the security of our
distributed protocol reduces to a stronger but thoroughly reasonable assumption on the unforge-
ability of the centralized ECDSA scheme (details in Section 2.7).

Our second protocol (Section 5) stems from the realization that for settings in which identiﬁable
abort is not necessary, we can use a further simpliﬁed version that also only requires a single online
round, but with a pre-processing phase of reduced round and computational complexity.

Our analysis shows that the protocol with anonymous aborts (Section 5) is slightly faster than
the identiﬁable abort protocol (Section 3) and both are slightly slower but competitive with [27]
(roughly 10% slower), and both of our protocols use less bandwidth than [27] as well.

We implemented both protocols and the results of our experimental benchmarks agree with the

analysis. The results of our extensive experimental evaluations are shown in Section 6.

Overview of our approach. We start with the protocol of Gennaro and Goldfeder [27], which
as mentioned above does not support identifying aborts and requires several rounds even in the
online phase once the message is known.

Using the multiplicative group notation, recall that an (EC)DSA signature is deﬁned over a
group G of order q generated by g. A public key is deﬁned as y = gx ∈ G with x ∈R Zq. To sign a
message M we ﬁrst hash it to obtain m = H(M ) and then choose k ∈R Zq and compute R = gk−1
,
r = H (cid:48)(R) and s = km + kxr mod q.

Single Round. The protocol of [27] starts with additive sharings of x, k and uses techniques due to
Gilboa [33] and Beaver [3] to create additive sharings of k−1 and kx and, by linear homomorphism,
additive shares of s. Then a “distributed signature veriﬁcation” check is performed on shares of s
to make sure they reconstruct a correct signature.

Our ﬁrst major observation is that we identify a new distributed veriﬁcation check can be
performed on the shares of k−1 and kx before the message is known, and therefore can be done in
a pre-processing phase. If those sharings are consistent and correct, then it is safe to reveal shares
of s once the message m is known. This will take just a single scalar multiplication per player and

3

one communication round (i.e. each player sends just a single message) and no online interactivity
is required.

Both of our protocols use this new distributed check. Our protocol in Section 5 replaces the
signature check from [27] with our new check, yielding a more eﬃcient protocol both in terms of
round complexity, computation, and bandwidth. Our protocol in Section 3 additionally adds the
ability to identify and attribute misbehavior.

Identification of Bad Players. We use the deﬁnition of identiﬁable abort from [36]. A
standard way to identify malicious players is to require each player to prove in zero-knowledge
that he is performing the protocol correctly [34], though alternative approaches exist (e.g.
[36]).
Although such ZK proofs could be instantiated for the [27] protocol, they would result in an
unacceptable level of communication and computation for the players.

Our key observation however is that if the abort happens during the preprocessing stage then
the full signature has not been revealed yet (and indeed the message being signed may not even be
known at this point). Therefore it is safe for the players to reveal the random choices they made
during the protocol so far (that includes “opening up” any encryption, etc.) so that their behavior
can be veriﬁed, and bad players identiﬁed.

Moreover, an abort during the online stage can be easily attributed as the shares of the signature
s that each player reveals can be easily checked to be correct against public information produced
by the oﬄine stage.

The key technical complication in the security proof is that when simulating the identiﬁcation
of bad players during the oﬄine phase, the simulator may not be able to correctly “open” an
encryption due to the fact that the simulation is proceeding with a value diﬀerent than the one
encrypted. Without the identiﬁcation step this would not be a problem as the semantic security
of the encryption would guarantee the simulated and real protocol views to be computationally
indistinguishable. But the encryption commits the simulator to the value so if identiﬁcation requires
opening it, then the views would be distinguishable.

We solve this problem by carefully constructing the protocol in a way that allows the simulator
to make sure that whenever the protocol fails and opening the randomness is required, then the
simulator can decommit to the correct value and not be “caught”. The full details appear in the
proof, but we are able to accomplish this without resorting to any heavyweight primitives such as
non-commiting encryption, and indeed, the ability to detect aborts eﬃciently is a key contribution
of our paper.

1.1 Related Work

The ﬁrst scheme for threshold DSA was presented by Gennaro, Jarecki, Krawczyk, and Rabin
[30, 31] in the honest majority setting. The key drawback of this scheme is that generating a
signature requires the participation of 2t + 1 players, whereas an adversary need only corrupt
t + 1 players to learn the key. Moreover, as it is in the honest majority setting, it restricts t and
requires t < n/2. This rules out n-of-n threshold signatures, and in particular the oft-desired 2-of-2
threshold signatures.

Noticing this limitation, Mackenzie and Reiter [42] partially addressed it by building a scheme
tailored for the 2-of-2 setting. This scheme uses a multiplicative sharing of the secret key and
employed Paillier’s additively homomorphic encryption scheme [44] to facilitate additions.

Gennaro, Goldfeder, and Narayanan revisited the multiparty case and presented a scheme that
supports arbitrary thresholds t ≤ n [29] (subsequently improved in [6]) in the dishonest-majority
setting. In their scheme, the ECDSA key is encrypted under a distributed threshold Paillier key
and the ciphertext is held by each participant. Beginning with the encrypted key and using the
homomorphic properties of Paillier, the players interactively create a ciphertext of the signature
and then jointly decrypt it using Paillier threshold decryption. While signing in [6, 29] is eﬃcient,
the key generation requires the distributed generation of an RSA modulus. While at the time it

4

was not known how to do this eﬃciently for more than two parties, recent work [14] may make
this approach feasible.

Lindell [40] and Doerner et al.[23] revisited the 2-of-2 setting and presented highly eﬃcient
constructions. Like [42], Lindell’s protocol used Paillier encryption, but it removed the expensive
zero-knowledge proofs required by [42]. Doerner et al. replaced Paillier with an oblivious transfer
protocol. The resulting scheme was fast and had a security proof that did not rely on Paillier
assumptions, but the cost of achieving this was greatly increasing the bandwidth of the protocol.
[22] pre-
sented eﬃcient protocols in the multiparty case that supported eﬃcient distributed key generation.
While all three boasted excellent concrete performance, [27] and [41] are constant round protocols,
while the number of communication rounds in [22] is logarithmic in the number of players.

Subsequently, Gennaro and Goldfeder [27], Lindell and Nof [41] and Doerner et al.

In two papers, Castagnos et al.

[12, 11] presented eﬃcient protocols for the two party case
and multiparty case respectively. Their protocols employ an additively homomorphic encryption
scheme based on class groups. The advantage of using this scheme is that it is homomorphic
modulo the same prime q over which ECDSA is deﬁned, and they are therefore able to eliminate
the need for expensive range proofs that were required by [27, 41] due to the mismatch between
the Paillier modulus and the ECDSA modulus and the potential for “overﬂow” that could leak
information about the key. Their schemes require less communication but are more expensive
computationally than the Paillier-based protocols.

While all of the above papers use non-generic tailored protocols, Dalskov et al.

[15] show a
one-round (online) protocol based on generic MPC – however their techniques achieve comparable
or better eﬃciency than the above protocols only for a small number of participants and thresholds
of size 2 or 3.

Recently three papers2 appeared on the IACR Eprint Archive, including [17] which presents
an improved protocol for threshold ECDSA with honest majority which is incomparable to our
dishonest majority result. More relevant to our work are the results in [10] and [25] which both
present eﬃcient online signing in the dishonest majority model.

The protocol in [10] has one-round on-line signing but does not achieve identiﬁable aborts. The
approach in [10] makes much more extensive use of Zero-Knowledge proofs of consistency between
group elements (in the cyclic group where ECDSA is run) and ring elements (in the RSA ring where
the Paillier encryption is constructed). As pointed out in [27], these ZK proofs are an eﬃciency
bottleneck and our protocol minimizes their use. No code was available for [10] to perform a direct
comparison, but if one refers to their complexity estimation they claim an almost 2x slowdown
compared to [27]. Our experimental results instead show that both of our protocols are roughly
1.1x slower than [27]. The protocol in [10] requires 2 less rounds of interaction in the oﬀ-line phase
and provides proactive security. The latter was not the focus of our eﬀort, but we believe could be
easily achieved for our protocol as well, and we plan to do so in the future.

The protocol in [25] achieves 3-round on-line signing.

It provides for a very weak form of
accountability, where aborts are only identiﬁed during the online phase. The oﬀ-line phase, requires
the full cooperation of all parties to succeed, which is a serious drawback as it allows unattributed
DoS attacks during the oﬄine phase, and anybody can prevent it from completing without being
caught. While this may be justiﬁed in some applications, this is a strong assumption, which is not
needed in our protocol, where the oﬄine component of the signature protocol is fully accountable
as well. No implementation, benchmark or complexity estimation is available for [25].

1.2 The issue with the previous version

The previous version of the protocol uses the same ”multiplicative to additive” share conversion
protocol presented in [27]. As pointed out in [?, ?], the claimed simulatability property for that

2We point out that our work is independent from these.

5

protocol does not hold, and actually information about the private shares of honest parties is
leaked.

Moreover in [?] the authors show how to leverage this information leakage to actually recover
the entire share of an honest party, and for the adversary to learn the entire secret key of the group.
Crucially, however, the attack relies on choosing a very small Paillier modulus N (approximately
the same size of the modulus q used in the DSA scheme). In our previous version we clearly stated
that N > q7 therefore the attack does not apply to our previous scheme (though it worked against
implementations that neglected to check the size of the modulus).

The share conversion protocol was repaired in [28] and we use the same ”ﬁx” in this paper.

More detailes in Section 2.10.

2 Background

2.1 Communication and adversarial model

We assume the existence of a broadcast channel as well as point-to-point channels connecting every
pair of players. As in [27, 41], security does not require a full reliable broadcast channel, but a
simple echo broadcast suﬃces in which each party sends to every other party the hash of all of
the broadcasted messages. If any party receives an inconsistent hash from some other party, it
aborts and notiﬁes every other party. While unforgeability does not rely on full broadcast, the
identiﬁcation protocol does require broadcast. The use of a broadcast channel is standard in all
work of MPC-with-abort and indeed it has been shown that MPC-IA indeed implies the existence
of a broadcast channel.

We assume a probabilistic polynomial time malicious adversary, who may deviate from the
protocol description arbitrarily. The adversary can corrupt up to t players, and it learns the
private state of all corrupted players. As in previous threshold ECDSA schemes [6, 29, 30, 40], we
limit ourselves to static corruptions, meaning the adversary must choose which players to corrupt
at the beginning of the protocol. There are standard techniques for converting a protocol secure
against static corruptions to secure against adaptive corruptions [9, 37, 10].

We assume a rushing adversary, meaning that the adversary gets to speak last in a given round

and, in particular, can choose his message after seeing the honest parties’ messages.

Following [6, 29] (but unlike [30, 31]), we assume a dishonest majority, meaning t, the number
of players the adversary corrupts, can take on any value up to n − 1. In this setting, there is no
guarantee that the protocol will complete, and we therefore do not attempt to achieve robustness,
or the ability to complete the protocol even in the presence of some misbehaving participants.
Instead, we show security with abort meaning that the adversary can cause the protocol to abort,
but in doing so cannot learn any useful information, other than its outputs. In this model, we
cannot guarantee that the honest parties will receive a signature. In this paper, unlike previous
works, we guarantee that aborts are identiﬁable meaning that the identity of at least one party
responsible for causing the protocol to abort becomes known to the honest players.

2.2 Signature Schemes

A digital signature scheme S consists of three eﬃcient algorithms:

• (sk, pk)←Key-Gen(1λ), the randomized key generation algorithm which takes as the security

parameter and returns the private signing key sk and public veriﬁcation key pk.

• σ←Sig(sk, m), the possibly randomized signing algorithm which takes as input the private
key sk and the message to be signed m and outputs a signature, σ. As the signature may be
randomized, there may be multiple valid signatures. We denote the set of valid signatures as
{Sig(sk, m)} and require that σ ∈ {Sig(sk, m)}.

6

• b ←Ver (pk, m, σ), the deterministic veriﬁcation algorithm, which takes as input a public key
pk, a message m and a signature σ and outputs a bit b which equals 1 if and only if σ is a
valid signature on m under pk.

To prove a signature scheme secure, we recall the standard notion of existential unforgeability

against chosen message attacks (EU-CMA) as introduced in [35].

[Existential unforgeability] Consider a PPT adversary A who is given public key pk output by
Key-Gen and oracle access to the signing algorithm Sig(sk, ·) with which it can receive signatures
on adaptively chosen messages of its choosing. Let M be the set of messages queried by A. A
digital signature scheme S =(Key-Gen,Sig,Ver) is said to be existentially unforgeable if there is no
such PPT adversary A that can produce a signature on a message m /∈ M, except with negligible
probability in λ.

2.3 Threshold Signatures

Threshold secret sharing. A (t, n)−threshold secret sharing of a secret x consists of n shares
x1, . . . , xn such that an eﬃcient algorithm exists that takes as input t + 1 of these shares and
outputs the secret, but t or fewer shares do not reveal any information about the secret.

Threshold signature schemes. Consider a signature scheme, S=(Key-Gen, Sig, Ver). A (t, n)-
threshold signature scheme T S for S enables distributing the signing among a group of n players,
P1, . . . , Pn such that any group of at least t + 1 of these players can jointly generate a signature,
whereas groups of size t or fewer cannot. More formally, T S consists of two protocols:

• Thresh-Key-Gen, the distributed key generation protocol, which takes as input the security
parameter 1λ. Each player Pi receives as output the public key pk as well as a private output
ski, which is Pi’s share of the private key. The values sk1, . . . , skn constitute a (t, n) threshold
secret sharing of the private key sk.

• Thresh-Sig, the distributed signing protocol which takes as public input a message m to be
signed as well as a private input ski from each player. It outputs a signature σ ∈ {Sig(sk, m)}.

Notice that the signature output by Thresh-Sig is a valid signature under Sig, the centralized
signing protocol. Thus we do not specify a threshold variant of the veriﬁcation algorithm as we
will use the centralized veriﬁcation algorithm, Ver.

In some applications, it may be acceptable to have a trusted dealer generate the private key
shares for each party. In this case, Thresh-Key-Gen would not be run. We require our protocols to
be simulatable (see e.g. [29, 30, 40]), meaning that

• There exists a simulator SIM1 that, on input the public key y runs an execution of the Thresh-
Key-Gen on behalf of the honest players which results in y as the output and generates a view
for the adversary which is indistinguishable from the real one.

• There exists a simulator SIM2 that, on input the public input of Thresh-Sig (in particular
the public key y and the message m) and the resulting signature σ, runs an execution of the
Thresh-Sig on behalf of the honest players which results in σ as the output and generates a
view for the adversary which is indistinguishable from the real one.

2.4 Identiﬁable Abort

We use the notion of secure multi-party computation with identiﬁable abort presented in [36],
which allows the computation to fail (abort), while guaranteeing that all the honest parties agree
on the identity Pi of a corrupted player.

If F is the functionality computed by the original MPC protocol, then a protocol for F with
identiﬁable aborts, computes a modiﬁed functionality F (cid:48) that either computes F or outputs the
identity Pi of a corrupted player in case of an abort.

7

2.5 Additively Homomorphic Encryption

Our protocol relies on an encryption scheme E that is additively homomorphic modulo a large
integer N . Let Epk(·) denote the encryption algorithm for E using public key pk. Given ciphertexts
c1 = Epk(a) and c2 = Epk(b), there is an eﬃciently computable function +E such that

The existence of a ciphertext addition operation also implies a scalar multiplication operation,

which we denote by ×E. Given an integer a ∈ N and a ciphertext c = Epk(m), then we have

c1 +E c2 = Epk(a + b mod N )

a ×E c = Epk(am mod N )

Informally, we say that E is semantically secure if for the probability distributions of the en-

cryptions of any two messages are computationally indistinguishable.

We instantiate our protocol using the additively homomorphic encryption scheme of Paillier

[44], and we recall the details here:

• Key-Gen: generate two large primes P, Q of equal length, and set N = P Q. Let λ(N ) =
lcm(P − 1, Q − 1) be the Carmichael function of N , and denote Γtoencryptamessagem
∈ ZN , select x ∈R Z ∗

N and return c = ΓmxN mod N 2.

• Decryption: to decrypt a ciphertext c ∈ ZN 2, let L be a function deﬁned over the set {u ∈
ZN 2 : u = 1 mod N } computed as L(u) = (u − 1)/N . Then the decryption of c is computed
as L(cλ(N ))/L(Γλ(N )) mod N .

• Homomorphic Properties: Given two ciphertexts c1, c2 ∈ ZN 2 deﬁne c1 +E c2 = c1c2 mod N 2.
If ci = E(mi) then c1 +E c2 = E(m1 + m2 mod N ). Similarly, given a ciphertext c = E(m) ∈
ZN 2 and a number a ∈ Zn we have that a ×E c = ca mod N 2 = E(am mod N ).

The security of Paillier’s cryptosystem relies on the N -residuosity decisional assumption [44],
which informally says that it is infeasible to distinguish random N -residues from random group
elements in Z ∗

N 2 .

2.6 Non-Malleable Equivocable Commitments

A trapdoor commitment scheme allows a sender to commit to a message with information-theoretic
privacy.
i.e., given the transcript of the commitment phase the receiver, even with inﬁnite com-
puting power, cannot guess the committed message better than at random. On the other hand
when it comes to opening the message, the sender is only computationally bound to the committed
message. Indeed the scheme admits a trapdoor whose knowledge allows to open a commitment in
any possible way (we will refer to this also as equivocate the commitment). This trapdoor should
be hard to compute eﬃciently.

Formally a (non-interactive) trapdoor commitment scheme consists of four algorithms KG, Com,

Ver, Equiv with the following properties:

• KG is the key generation algorithm, on input the security parameter it outputs a pair {pk,
tk} where pk is the public key associated with the commitment scheme, and tk is called the
trapdoor.

• Com is the commitment algorithm. On input pk and a message M it outputs [C(M ), D(M )] =
Com(pk, M, R) where r are the coin tosses. C(M ) is the commitment string, while D(M ) is
the decommitment string, which is kept secret until opening time.

• Ver is the veriﬁcation algorithm. On input C, D and pk it either outputs a message M or ⊥.

8

• Equiv is the algorithm that opens a commitment in any possible way given the trapdoor infor-
mation. It takes as input pk, strings M, R with [C(M ), D(M )] = Com(pk, M, R), a message
M (cid:48) (cid:54)= M and a string T . If T = tk then Equiv outputs D(cid:48) such that Ver(pk, C(M ), D(cid:48)) = M (cid:48).

We note that if the sender refuses to open a commitment we can set D = ⊥ and Ver(pk, C, ⊥) = ⊥.
Trapdoor commitments must satisfy the following properties

Correctness If [C(M ), D(M )] = Com(pk, M, R) then

Ver(pk, C(M ), D(M )) = M .

Information Theoretic Security For every message pair M, M (cid:48) the distributions C(M ) and

C(M (cid:48)) are statistically close.

Secure Binding We say that an adversary A wins if it outputs C, D, D(cid:48) such that Ver(pk, C, D) =
M , Ver(pk, C, D(cid:48)) = M (cid:48) and M (cid:54)= M (cid:48). We require that for all eﬃcient algorithms A, the
probability that A wins is negligible in the security parameter.

Such a commitment is non-malleable [24] if no adversary A, given a commitment C to a messages
m, is able to produce another commitment C (cid:48) such that after seeing the opening of C to m, A can
successfully decommit to a related message m(cid:48) (this is actually the notion of non-malleability with
respect to opening introduced in [20]).

The non-malleable commitment schemes in [20, 21] are not suitable for our purpose because
they are not “concurrently” secure, in the sense that the security deﬁnition holds only for t = 1
(i.e. the adversary sees only 1 commitment).

The stronger concurrent security notion of non-malleability for t > 1 is achieved by the schemes

presented in [16, 26, 43]), and any of them can be used in our threshold DSA scheme.

However in practice one can use any secure hash function H and deﬁne the commitment to
x as h = H(x, r), for a uniformly chosen r of length λ and assume that H behaves as a random
oracle. We use this eﬃcient random oracle version in our implementation.

2.7 The Digital Signature Standard

The Digital Signature Algorithm (DSA) was proposed by Kravitz in 1991, and adopted by NIST in
1994 as the Digital Signature Standard (DSS) [5, 39]. ECDSA, the elliptic curve variant of DSA,
has become quite popular in recent years, especially in cryptocurruencies.

All of our results in this paper apply to both the traditional DSA and ECDSA. We present our

results using the generic G-DSA notation from [29], which we recall here.

The Public Parameters consist of a cyclic group G of prime order q, a generator g for G, a hash

function H : {0, 1}∗ → Zq, and another hash function H (cid:48) : G → Zq.

Key-Gen On input the security parameter λ, outputs a private key x chosen uniformly at random in

Zq, and a public key y = gx computed in G.

Sig On input an arbitrary message M ,

– compute m = H(M ) ∈ Zq
– choose k ∈R Zq
– compute R = gk−1
– compute s = k(m + xr) mod q

in G and r = H (cid:48)(R) ∈ Zq

– output σ = (r, s)

Ver On input M, σ and y,

– check that r, s ∈ Zq

9

– compute R(cid:48) = gms−1 mod qyrs−1 mod q in G
– Accept (output 1) iﬀ H (cid:48)(R(cid:48)) = r.

The traditional DSA algorithm is obtained by choosing large primes p, q such that q|(p − 1)
p . In this case the multiplication operation in G is

and setting G to be the order q subgroup of Z ∗
multiplication modulo p. The function H (cid:48) is deﬁned as H (cid:48)(R) = R mod q.

The ECDSA scheme is obtained by choosing G as a group of points on an elliptic curve of
cardinality q. In this case the multiplication operation in G is the group operation over the curve.
The function H (cid:48) is deﬁned as H (cid:48)(R) = Rx mod q where Rx is the x-coordinate of the point R.

We assume a stronger notion of unforgeability for ECDSA. In this notion we allow the attacker

to see the randomizer R before queriying the message m during a chosen-message attack.

We believe that this in practice is not an issue. This corresponds to assuming that ECDSA
is secure in the presence of what we may call a state compromise attack where the adversary is
allowed to see the internal state of the signer (but not its secret keys). This models the real-life
situation in which the signer pre-computes all the randomizers R’s in advance and stores them in
regular memory (while keeping the secret key x and the secret nonces k in a protected memory).
We assume that the adversary manages to read the regular memory contents (i.e. all the R’s) and
still will not be able to forge.

Jumping ahead, the reason we do this is that in our one-round protocol, the distributed players
will use pre-computed R which are known to all of them, including the corrupted ones, i.e. to the
adversary. We point out that this assumption is also used in [10] (and in there it is shown that
under certain reasonable conditions it is equivalent to the standard notion of unforgeability for
ECDSA)3.

[ECDSA unforgeability under state compromise] Consider a PPT adversary A who is given and

ECDSA public key y output by Key-Gen(λ). A has oracle access to

• to UG to obtain R a uniformly random element in G;

• to Sig’(sk, R, m) which returns (r, s) a valid signature for m with r = H (cid:48)(R), if R was queried

to UG, otherwise returns ⊥

Let M be the set of messages queried by A. We say that ECDSA is existentially unforgeable
under chosen message with state compromise attack if there is no such PPT adversary A that can
produce a signature on a message m /∈ M, except with negligible probability in λ.

In terms of the simulation of our protocol, this means that we are simulating a functionality
that outputs R (given to the simulator) during the online phase, and the matching s during the
online one.

2.8 Veriﬁable Secret Sharing (VSS)

Shamir Secret Sharing In Shamir’s secret sharing scheme [47], to share a secret σ ∈ Zq, the
dealer generates a random degree t polynomial p(·) over Zq such that p(0) = σ. The secret shares
are evaluations of the polynomial

p(x) = σ + a1x + a2x2 + · · · + atxt mod q

Each player Pi receives a share σi = p(i) mod q.
In a veriﬁable secret sharing scheme, auxiliary information is published that allows players to

check that their shares are consistent and deﬁne a unique secret.

Feldman’s VSS is an extension of Shamir secret sharing in which the dealer also publishes

vi = gai in G for all i ∈ [1, t] and v0 = gσ in G.

3This notion is not discussed in [15], yet it seems to be implicitly assumed, as they also have a one-round online

solution where the adversary is allowed access to the randomizers before the message is known.

10

Using this auxiliary information, each player Pi can check its share σi for consistency by veri-

fying:

gσi ?=

t
(cid:89)

j=0

vij
j

in G

If the check does not hold for any player, it raises a complaint and the protocol terminates.
Note that this is diﬀerent than the way Feldman VSS was originally presented as it assumed an
honest majority and could recover if a dishonest player raised a complaint. However, since we
assume dishonest majority in this paper, the protocol will abort if a complaint is raised.

While Feldman’s scheme does leak gσ, it can be shown via a simulation argument that nothing

else is leaked, but we omit the details here.

2.9 Assumptions

DDH. Let G be a cyclic group of prime order q, generated by g. The DDH Assumption states that
the following two distributions over G3 are computationally indistinguishable: DH = {(ga, gb, gab)
for a, b ∈R Zq} and R = {(ga, gb, gc) for a, b, c ∈R Zq}.
Strong-RSA. Let N be the product of two safe primes, N = pq, with p = 2p(cid:48) + 1 and q = 2q(cid:48) + 1
with p(cid:48), q(cid:48) primes. With φ(N ) we denote the Euler function of N , i.e. φ(N ) = (p − 1)(q − 1) = p(cid:48)q(cid:48).
With Z ∗
N we denote the set of integers between 0 and N − 1 and relatively prime to N .

Let e be an integer relatively prime to φ(N ). The RSA Assumption [45] states that it is
N it is hard to ﬁnd

N . That is, given a random element s ∈R Z ∗

infeasible to compute e-roots in Z ∗
x such that xe = s mod N .

The Strong RSA Assumption (introduced in [4]) states that given a random element s in Z ∗
N
it is hard to ﬁnd x, e (cid:54)= 1 such that xe = s mod N . The assumption diﬀers from the traditional
RSA assumption in that we allow the adversary to freely choose the exponent e for which she will
be able to compute e-roots.

We now give formal deﬁnitions. Let SRSA(n) be the set of integers N , such that N is the

product of two n/2-bit safe primes.

Assumption 1 We say that the Strong RSA Assumption holds, if for all probabilistic polynomial
time adversaries A the following probability

P rob[ N ← SRSA(n) ; s ← Z ∗

N : A(N, s) = (x, e) s.t. xe = s mod N ]

is negligible in n.

2.10 Multiplicative-to-additive share conversion protocol (MtA) of [28]

We now recall the Multiplicative-to-Additive share conversion MtA protocols as presented in [28],
which is a central building block in their protocol as well as ours. We present the protocol of [28],
but we note that a similar protocol is also used in [18, 38, 40, 41, 42].

The setting consists of two players, P1 and P2, who hold multiplicative shares of a secret x. In
particular, P1 holds a share a ∈ Zq, and P2 holds a secret share b ∈ Zq such that x = ab mod q. The
goal of the MtA protocol is to convert these multiplicative shares into additive shares. P1 receives
private output α ∈ Zq and P2 receives private output β ∈ Zq such that α + β = x = ab mod q.

11

MtAwc.
In the basic MtA protocol, the player’s inputs are not veriﬁed, and indeed the players
can cause the protocol to produce an incorrect output by inputting the wrong values ˆa, ˆb. In the
case that B = gb is public, the protocol can be enhanced to include an extra check that ensures
that P2 inputs the correct value b = logg(B). This enhanced protocol is denoted as MtAwc (for
MtA “with check”).

We assume that player P1 is associated with a public key E1 for an additively homomorphic

scheme E deﬁned over an integer N ≤ q8. We assume P2 checks that N is of the correct size.

1. P1 initiates the protocol:

• Compute cA = E1(a)
• Compute a zero knowledge range proof πA that {a : D1(cA) = a ∧ a < q3}
• Send (cA, πA) to P2

2. Upon receiving (cA, πA) from P1, P2 does the following:

• Veriﬁes πA, and aborts if it fails to verify
• Choose β(cid:48) $← Zq5
• Set output β = −β(cid:48) mod q
• Compute cB = b ×E cA +E E1(β(cid:48)) = E1(ab + β(cid:48))
•MtA

Compute a zero knowledge range proof π1
E1(β(cid:48))}

B of {b, β(cid:48) : b < q3 ∧ β(cid:48) < q7 ∧ cB = b ×E cA +E

MtAwc i.e.

if B = gb is public: Compute a zero knowledge proof of knowledge π2

B that he

knows {b, β(cid:48) : b < q3 ∧ β(cid:48) < q7 ∧ B = gb ∧ cB = b ×E cA +E E1(β(cid:48))}

3. Send (cB, π1

B, [π2

B]) to P1

Upon receiving (cB, π1

B, [π2

B]) from P2, P1 does the following:

• Veriﬁes π1

B (π2

B if they are running MtAwc), and aborts if either proof fails to verify

• Compute α(cid:48) = D1(cB)

• Set output α = α(cid:48) mod q

Correctness. Assume both players are honest and N > K 2q. Then note that Alice decrypts the
value α(cid:48) = ab + β(cid:48) mod N . Note that β(cid:48) < N − ab due to the range check, therefore the reduction
mod N is not executed so the above holds over the integers.

Simulation. As shown in [28], as a standalone protocol, we can prove security of MtA/MtAwc even
without the range proofs. We show this via a simulation argument, showing that if the adversary
corrupts player Pi, we can construct a simulator for P1−i, thus showing that P1−i leaks no useful
information.

If the adversary corrupts P1, then P2’s message can be simulated without knowl-
Simulating P1.
edge of its input b. Indeed a simulator can just choose a random b(cid:48) ∈ Zq and follow the rest of the
protocol as P2. The distribution of the message decrypted by P1 in this simulation is identical to
the message decrypted when P2 uses the real b, because the “noise” β(cid:48) is uniformly distributed in
ZN .

12

Simulating P2.
If the adversary corrupts P2, then P1’s message can be simulated without knowl-
edge of its input a. Indeed a simulator can just choose a random a(cid:48) ∈ Zq and act as Alice. In this
case the view of Bob is computationally indistinguishable from the real one due to the semantic
security of the encryption scheme E.

Although MtA is fully simulatable as a standalone protocol, if the range proofs are not used,
a malicious P1 or P2 can cause the protocol to “fail” by choosing large inputs that “overﬂow” the
Paillier modulus causing a reduction mod N . As a standalone protocol this is not an issue since
the parties are not even aware that the reduction mod N took place and no information is leaked
about the other party’s input. However, when used inside a threshold ECDSA protocol, this attack
will cause the signature veriﬁcation to fail, and this information is linked to the size of the other
party’s input.

Thus, in our setting, we need security in the presence of an oracle that tells the parties if the
reduction mod N happens or not, but due to the ZK “range proofs” such a reduction will only
happen with negligible probability (if the ZK proofs fail) and security holds.

Remark. On the ZK proofs and the size of the modulus N . For the ZK proofs required in the
protocol we use the proofs from [28], which are based on proofs from [42]. These are zero knowledge
arguments with security holding under the Strong RSA Assumption. We point out that for typical
choices of parameters, N is approximately q8 (since q is typically 256-bit long while N is a 2048-bit
RSA modulus), so this requirement is not problematic4.

We note that these proofs make use of Fujisaki-Okamoto commitments, and therefore the
appropriate setup procedure must be followed. In practice, it suﬃces for the veriﬁer to generate
the parameters, ˜N , h1, h2 and prove the the discrete log between h1 and h2 exist.
Note about the previous version: In our previous version we chose β(cid:48) uniformly at random
in ZN and did not impose any range check on it. This leads to a similar information leakage as
described above where if β(cid:48) is chosen close to N , a modular reduction (and therefore a failure of
the protocol) happens based on the distribution of the input a. The previous version also used the
ZK proofs from [27] which need to be adapted to the new bounds: this version refers to the ZK
proofs from [28].

3 One-Round Threshold ECDSA with identiﬁable abort

In this section we present our main result: a new protocol for threshold ECDSA that has two main
advantages over existing protocols:

• One round online. Unlike [22, 27, 41], our protocol does not require the distributed
veriﬁcation step of the validity of the signature. Removing this check makes the protocol
more round eﬃcient, but even more signiﬁcantly, we are able to remove any dependency on
the message from the multi-round interactive parts of the protocol. In particular, our protocol
allows the computation of the signature in a single round, after some message-independent
preprocessing.
It also has fewer rounds in total than all existing protocols that support
eﬃcient key generation [22, 27, 41], and thus is more eﬃcient even if run fully online without
pre-processing.

• Identifiable abort.Additionally the protocol improves on all existing protocols by en-

abling the eﬃcient identiﬁcation of misbehaving parties.

.

4For the simple range proof that a, b < K one could alternatively use a variation of Boudot’s proof [7] which
establish K ∼ q which sets N ∼ q3. This proof is less eﬃcient that the ones from [29, 42] which are anyway required
for Bob in the MtAwc protocol. Moreover as we said earlier, N > q8 in practice anyway so the improvement in the
size of N is irrelevant for ECDSA.

13

The players run on input {G, g} the cyclic group used by the ECDSA signature scheme. We
assume that each player Pi is associated with a public key Ei for an additively homomorphic
encryption scheme E.

3.1 Key generation protocol

The key generation protocol is largely the same as the protocol in [27], but we show how it can be
augmented to identify misbehaving parties. We now present the details of the protocol.

• Phase 1. Each Player Pi selects ui ∈R Zq; computes [KGCi, KGDi] = Com(gui) and broad-

casts KGCi. Each Player Pi broadcasts Ei the public key for Paillier’s cryptosystem.

• Phase 2. Each Player Pi broadcasts KGDi. Let yi be the value decommitted by Pi. The
player Pi performs a (t, n) Feldman-VSS of the value ui, with yi as the “free term in the
exponent”
The public key is set to y = (cid:81)
i yi. Each player adds the private shares received during the
n Feldman VSS protocols. The resulting values xi are a (t, n) Shamir’s secret sharing of the
secret key x = (cid:80)

i ui. Note that the values Xi = gxi are public.

• Phase 3 Let Ni = piqi be the RSA modulus associated with Ei. Each player Pi proves in
ZK that he knows xi using Schnorr’s protocol [46], that Ni is square-free using the proof of
Gennaro, Micciancio, and Rabin [32], and that h1 h2 generate the same group modulo Ni.

3.2 Signing protocol

We now describe the signing protocol, which is run on input m (the hash of the message M
being signed) and the output of the key generation protocol described above. We note that the
latter protocol is a t-out-of-n protocol (and thus the secret key x is shared using (t, n) Shamir
secret-sharing).

Let S ⊆ [1..n] be the set of players participating in the signature protocol. We assume that
|S| = t + 1. For the signing protocol we can share any ephemeral secrets using a (t, t + 1) secret
sharing scheme, and do not need to use the general (t, n) structure. We note that using the
appropriate Lagrangian coeﬃcients λi,S each player in S can locally map its own (t, n) share xi of
x into a (t, t + 1) share of x, wi = (λi,S)(xi), i.e. x = (cid:80)
i∈S wi. Since Xi = gxi and λi,S are public
values, all the players can compute Wi = gwi = X λi,S
.

i

• Phase 1. Each Player Pi selects ki, γi ∈R Zq; computes [Ci, Di] = Com(gγi) and broadcast

Ci.
Deﬁne k = (cid:80)

i∈S ki, γ = (cid:80)

i∈S γi. Note that
(cid:88)

kγ =

i,j∈S

(cid:88)

i,j∈S

kx =

kiγj mod q

kiwj mod q

• Phase 2. Every pair of players Pi, Pj engages in two multiplicative-to-additive share conver-
sion subprotocols. Note that the ﬁrst message for these protocols is the same and is only
sent once.

– Pi, Pj run MtA with shares ki, γj respectively. Let αij [resp. βij] be the share received

by player Pi [resp. Pj] at the end of this protocol, i.e.

kiγj = αij + βij

14

Player Pi sets δi = kiγi + (cid:80)
sharing of kγ = (cid:80)

i∈S δi

j(cid:54)=i αij + (cid:80)

j(cid:54)=i βji. Note that the δi are a (t, t + 1) additive

– Pi, Pj run MtAwc with shares ki, wj respectively. Let µij [resp. νij] be the share

received by player Pi [resp. Pj] at the end of this protocol, i.e.

kiwj = µij + νij

Player Pi sets σi = kiwi + (cid:80)
sharing of kx = (cid:80)

i∈S σi

j(cid:54)=i µij + (cid:80)

j(cid:54)=i νji. Note that the σi are a (t, t + 1) additive

• Phase 3. Every player Pi broadcasts

– δi and the players reconstruct δ = (cid:80)

i∈S δi = kγ. The players compute δ−1 mod q.

– Ti = gσih(cid:96)i with (cid:96)i ∈R Zq and proves in ZK that he knows σi, (cid:96)i.

• Phase 4. Each Player Pi broadcasts Di. Let Γi be the values decommitted by Pi.

The players compute Γ = (cid:81)

i∈S Γi, and
= g((cid:80)

R = Γδ−1

i∈S

γi)k−1γ−1

= gγk−1γ−1

= gk−1

as well as r = H (cid:48)(R).

• Phase 5. Each player Pi broadcasts ¯Ri = Rki as well as a zero-knowledge proof of consistency
between Ri and Ei(ki), which each player sent as the ﬁrst message of the MtA protocol in
Phase 2. If

g (cid:54)=

(cid:89)

¯Ri

the protocol aborts.

i∈S

• Phase 6. Each player Pi broadcasts Si = Rσi as well as a zero-knowledge proof of consistency

between Si and Ti, which each player sent in Phase 3. If

y (cid:54)=

(cid:89)

i∈S

Si

the protocol aborts.

• Phase 7. Each player Pi broadcasts si = mki + rσi and set s = (cid:80) si. If the signature (r, s)

is correct for m, the players accept, otherwise they abort.

3.3 The Zero-Knowledge Proofs

In this section we drop the indices for simplicity.

In Phase 3 a player P outputs T = gσh(cid:96) and must prove that he knows σ, (cid:96) satisfying the above

relationship. A classic (honest-veriﬁer) ZK argument for this task is as follows:

• The Prover chooses a, b ∈R Zq and sends α = gahb

• The Veriﬁer sends a random challenge c ∈R Zq

• The Prover answers with t = a + cσ mod q and u = b + c(cid:96) mod q.

• The Veriﬁer checks that gthu = αT c

15

In Phase 5 a player P outputs ¯R = Rk and has to prove that the exponent k is consistent with
a previously posted Paillier ciphertext C = E(k). A ZK proof for this statement is provided in
[42, 29, 40].

In phase (6) a player P outputs S = Rσ and must prove that he knows σ, (cid:96) such that S = Rσ

and T = gσh(cid:96). A (honest-veriﬁer) ZK argument for this task is as follows:

• The Prover chooses a, b ∈R Zq and sends α = Ra and β = gahb

• The Veriﬁer sends a random challenge c ∈R Zq

• The Prover answers with t = a + cσ mod q, u = b + c(cid:96) mod q

• The Veriﬁer checks that Rt = αSc and gthu = βT c

4

Identifying aborts

A key problem with all known threshold ECDSA protocols is that in the case of aborts, it is not
In this
possible to always identify which party is responsible for causing the signature to fail.
section, we will show how to identify aborts.

First of all we assume that all messages transferred between players are signed, so that it is

possible to determine their origin.

The protocol will abort in case any player deviates from the protocol in a clearly identiﬁable
way by not complying with the protocol instructions – e.g. not sending a message when required.
In this case the bad player is clearly identiﬁed and removed. Note that we assume a broadcast
channel so if a player behaves badly, everybody knows that. Note that this requires that every
message of the protocol has to be reliably broadcast (this includes the pair-wise MtA protocols,
which will enable the identiﬁcation procedure described below).

In the case a message from a player fails to appear, we apply a local timeout bound before

marking that player as corrupted, to account for possible delays in message delivery.

We focus our attention here on aborts that are not clearly identiﬁable as deviations from the
protocol – i.e. where the player sent a message of the correct form at the correct time, but the
contents of the message was crafted in a way that caused the protocol to fail.

4.1 Identifying aborts in the Key Generation protocol

In the key generation protocol, there are two possible places that an abort can occur:

• Phase 2. If a player complains that the Feldman share it received is inconsistent and therefore

does not verify correctly, the protocol will abort.

• Phase 3. When each player is proving knowledge of xi and proving the correctness of their

Paillier key, if one of these proofs fails to verify the protocol will abort.

If the protocol aborts in Phase 3 because a ZK proof fails, then we immediately know who the
bad player is. However, if the protocol aborts in Phase 2, it means that a player Pj complains
about a player Pi meaning that Pj claims the private share he received does not match the public
information of Pi’s Feldman VSS. In this case it might be useful to identify who the bad player is,
in order to remove it from the n players when the key generation protocol is re-run. Here there is
ambiguity as if the bad player is Pi (dealing a bad Feldman VSS) or Pj (trying to frame Pi).
A simple identification protocol. Notice that if the failure happens during the key generation
protocol, it is safe to abandon the protocol and publish the would-be private key since it has not
yet been established or used. Thus, if Pj raises a complaint about a share he received from Pi, the
simplest identiﬁcation protocol has him publish the share that he received from Pi in the clear,

16

and indeed anyone can now check whether the share that he received is consistent (recall that we
assume that all messages are signed, so the share can be authenticated and Pi cannot be framed
by publishing an incorrect share). After the misbehaving player is identiﬁed, the key generation
protocol will need to be re-run with fresh randomness to establish a secure key.

4.2 Identifying aborts in the signing protocol

In our signing protocol, aborts can occur in the following parts of the protocol:

1. Phase 2. If the range proofs of the MtA/MtAwc or zero knowledge proofs for MtAwc fail.

2. Phase 3. If the ZK proof about σi, (cid:96)i fails.

3. Phase 4. If the decommitment Di fails to verify.
4. Phase 5. If the ZK proof about ¯Ri fails to verify
5. Phase 5. If g (cid:54)= (cid:81) ¯Ri

6. Phase 6. If the ZK proof about Si fails to verify
7. Phase 6. If y (cid:54)= (cid:81) Si

8. Phase 7. If the signature (r, s) is not valid for the message m

For items 1,2,3,4,6, identiﬁcation of the cheating player is simple. In these steps, the aborts
result due to the failure of a commitment opening or zero knowledge proof to verify, and the abort
is thus attributable to the player who gave the faulty proof or the faulty opening.

For aborts of type 8, i.e. in Phase 7 when the signature (r, s) does not verify on message m, we
note that if we got to that point then g = (cid:81) ¯Ri (where ¯Ri = Rki) and y = (cid:81) Si where Si = Rσi.
Note at this phase player Pi should broadcast si = mki + rσi mod q. We can check if

Rsi = ¯Rm
i

· Sr
i

(1)

if all the above equations hold then the signature should verify. Indeed

Rs = R

(cid:80) si = [

(cid:89) ¯Ri]m · [

(cid:89)

Si]r = gmyr

which holds for correct signatures. So we can identify the malicious player by checking for which
player Equation 1 does not hold.

¯Ri (cid:54)= g or (cid:81)

The core diﬃculty is attributing aborts of type 5 or 7: when (cid:81)

i∈S Si (cid:54)= y. At
a high level, this means that the distributed values used to compute the signature are wrong, but
it gives no indication as to where things went wrong. Indeed, this could be caused by a failure of
the MtA protocol itself where a player sent an incorrect ciphertext to another player (Phase 2).
But even if the MtA protocols themselves succeeded, the failure could also be caused by players
later revealing wrong values that are not consistent with the values they received during the MtA
protocols. This could happen if a player reveals the wrong δi or Γi (Phase 3 or 4) which would
lead to an incorrect R and thus an invalid signature. It could also be caused by a player inputting
an incorrect value σi in either Phase 3 or Phase 6 (which would lead to an incorrect s). Previous
protocols such as [27, 41, 22] are not able to eﬃciently disentangle the identity of the bad players
from similar distributed veriﬁcation checks.

i∈S

In order to prove that the players indeed ran the protocol correctly, it is necessary and suﬃcient

to prove the following:

1. The values ki that were input to the MtA with ki and γj are consistent with the ki that is

input to the MtAwc protocol with ki and wj.

17

2. The value wj that was input to the MtAwc protocol is consistent with the public value

Wj = gwj that is associated with player Pj.

3. The value γj that was input to the MtA protocol is consistent with Γj that is decommited

to in Phase 4.

4. The value δi that is published in Phase 3 is consistent with the shares received during the

MtA protocol. In particular, the following should hold:

δi = kiγi +

(cid:88)

j(cid:54)=i

αij +

(cid:88)

j(cid:54)=i

βji

where αij and βji are the shares output by the MtA protocol for player Pi.

5. The value Si published in Phase 6 is consistent with the shares received during the MtAwc

protocol. In particular, recall that Si = Rσi and

σi = kiwi +

(cid:88)

j(cid:54)=i

µij +

(cid:88)

j(cid:54)=i

νji

where µij and νji are the shares output by the MtAwc protocol for player Pi.

Notice that Property 1 is already enforced by the protocol since indeed the ﬁrst message of
both the MtA and the MtAwc protocol are shared and only a single message is sent by each player.
Thus consistency is guaranteed. Moreover, Property 2 is also guaranteed by the protocol since we
run MtAwc which guarantees that the value input by Pj is indeed consistent with gwj .

Thus, in order to make our protocol identiﬁable, we need only consider the ﬁnal three properties

which are not immediately guaranteed by the protocol.

4.3 How Identiﬁcation Works

Recall that when a signature is public it is important that k be kept secret as given k and the a
signature using k, one can compute the secret key, x. Similarly, if a player published its values si
and ki, then this would leak its secret share xi. The problem stems from publishing both ki as
well as a signature share si in which ki was used. However, if si has not been published, ki has no
special signiﬁcance and indeed can be published without leaking any information about the key.
Consider now the abort in Phase 5 when g (cid:54)= (cid:81) ¯Ri (Type 5 from the list in Section 4.2). At
this point, the values si in the signature protocol have not been released. Indeed at this point,
it is completely acceptable for the players to reveal their values ki in the clear. And the same is
true for the ephemeral value γi. Absent the value si, the value γi need not be kept secret. This
means that the MtA protocol with ki and γj can be completely opened. This immediately enables
checking that Properties 3 and 4 are satisﬁed as all of the values that δi is comprised of are made
public.

Therefore the identiﬁcation protocol for failures of Type 5 in Phase 5 (g (cid:54)= (cid:81) ¯Ri) works as

follows:

• Each player Pi publishes its values ki, γi, αij, βji for all j as well as the randomness used to

encrypt these values during the MtA protocol.

• Every other player Pj can now verify the correctness of δi in the clear. If for any player they
do not hold, the abort is attributed to that player, and the identiﬁcation protocol terminates.

18

Let’s focus now on the abort of Type 7 in Phase 6 (y (cid:54)= (cid:81) Si). Here the players cannot
completely open the MtAwc protocol between ki and wj since wj is Pj’s long-term secret key and,
unlike the ephemeral values ki and γj, the value wi needs to be kept secret even if the signature
aborts. We show, however, that it is safe to reveal the value µij in the clear, and using these, we
can check the correctness of σi in the exponent, allowing us to identify the misbehaving player.
We now proceed with the details of the identiﬁcation protocol for failures of Type 7 (in Phase 6):

• Each player Pi publishes ki and µij as the decryption of the appropriate ciphertext in the
MtAwc protocol. Recall that in Paillier’s scheme, given a ciphertext and a private key, one
can decrypt the plaintext and also recover the randomness used to encrypt, allowing anybody
to verify the correctness of the claimed decrypted value by re-encryption.

• Every other player P(cid:96) can now verify that the value sent Pi to Pj was ki and the value sent

by Pj to Pi was µij.

Moreover, for all j, since gwj , ki, and µij are public, everyone can now compute gνji using
the equation

gµij = gwj ki g−νji

And now they can additionally compute

gσi = gwi ki (cid:89)

gµij (cid:89)

gνji

j(cid:54)=i

j(cid:54)=i

• Each player Pi proves in zero knowledge the consistency between gσi that was computed in
the previous step and Si = Rσi. If for any player this does not hold, the abort is attributed
to that player.

The ZK Proof above is a classic one by Chaum and Pedersen [13]. An honest-veriﬁer protocol is
described below for completeness. The Prover has two values Σ = gσ and S = Rσ. He sends α = ga
and β = Ra for a ∈R Zq. The Veriﬁer sends c ∈R Zq. The Prover answers with t = a + cσ mod q.
The Veriﬁer checks gt = αΣc and Rt = βSc.

5 Simpliﬁed one round online ECDSA with anonymous aborts

If one is not concerned with identiﬁable abort, we can simplify our protocol even further. While
our protocol in Section 3 is concretely eﬃcient and has a round-optimal online phase, the oﬄine
protocol can be further simpliﬁed if we can tolerate anonymous aborts. Although the protocols
are quite similar, we present it in its entirety for completeness.

The main diﬀerence is that in Phase 3 the players do not commit to the value σi using Ti. This
step, together with the correctness check in Phase 6 of the previous protocol, was necessary to make
sure that players are committed to the correct partial signature si, allowing the identiﬁcation
of players who misbehave in that ﬁnal step (a feature that is lost in this simpliﬁed protocol).
Consequently the check in Phase 6 of the previous protocol also disappear.

As before, the players run on input G, g the cyclic group used by the ECDSA signature scheme.
We assume that each player Pi is associated with a public key Ei for an additively homomorphic
encryption scheme E.

The Key Generation protocol is the same as the previous protocol.

19

5.1 Signature Generation

We now describe the signature generation protocol, which is run on input m (the hash of the
message M being signed) and the output of the key generation protocol described above. We note
that the latter protocol is a t-out-of-n protocol (and thus the secret key x is shared using (t, n)
Shamir secret-sharing).

Let S ⊆ [1..n] be the set of players participating in the signature protocol. We assume that
|S| = t + 1. For the signing protocol we can share any ephemeral secrets using a (t, t + 1) secret
sharing scheme, and do not need to use the general (t, n) structure. We note that using the
appropriate Lagrangian coeﬃcients λi,S each player in S can locally map its own (t, n) share xi of
x into a (t, t + 1) share of x, wi = (λi,S)(xi), i.e. x = (cid:80)
i∈S wi. Since Xi = gxi and λi,S are public
values, all the players can compute Wi = gwi = X λi,S
.

i

• Phase 1. Each Player Pi selects ki, γi ∈R Zq; computes [Ci, Di] = Com(gγi ) and broadcast

Ci.
Deﬁne k = (cid:80)

i∈S ki, γ = (cid:80)

i∈S γi. Note that

kγ =

kx =

(cid:88)

i,j∈S

(cid:88)

i,j∈S

kiγj mod q

kiwj mod q

• Phase 2. Every pair of players Pi, Pj engages in two multiplicative-to-additive share conver-
sion subprotocols. Note that the ﬁrst message for these protocols is the same and is only
sent once.

– Pi, Pj run MtA with shares ki, γj respectively. Let αij [resp. βij] be the share received

by player Pi [resp. Pj] at the end of this protocol, i.e.

kiγj = αij + βij

Player Pi sets δi = kiγi + (cid:80)
sharing of kγ = (cid:80)

i∈S δi

j(cid:54)=i αij + (cid:80)

j(cid:54)=i βji. Note that the δi are a (t, t + 1) additive

– Pi, Pj run MtAwc with shares ki, wj respectively. Let µij [resp. νij] be the share

received by player Pi [resp. Pj] at the end of this protocol, i.e.

kiwj = µij + νij

Player Pi sets σi = kiwi + (cid:80)
sharing of kx = (cid:80)

i∈S σi

j(cid:54)=i µij + (cid:80)

j(cid:54)=i νji. Note that the σi are a (t, t + 1) additive

• Phase 3. Every player Pi broadcasts δi and the players reconstruct δ = (cid:80)

i∈S δi = kγ. The

players compute δ−1 mod q.

• Phase 4. Each Player Pi broadcasts Di. Let Γi be the values decommitted by Pi.

The players compute Γ = (cid:81)

i∈S Γi, and
= g((cid:80)

i∈S

R = Γδ−1

as well as r = H (cid:48)(R).

γi)k−1γ−1

= gγk−1γ−1

= gk−1

20

# participants

[27]

Identiﬁable (Section 3) Anonymous (Section 5)

2
3
4
5
6
7
8
9
10

442
856
1322
1735
2133
2565
2997
3434
3849

487
960
1432
1900
2366
2834
3327
3826
4289

484
991
1418
1879
2355
2822
3306
3758
4257

Table 1: Comparing the running times of our protocols and [27] with number of participants
ranging from 2 to 10 players. Times are averaged over 50 runs and given in milliseconds.

• Phase 5. Each player Pi broadcasts Λi = Γki as well as a zero-knowledge proof of consistency
between Λi and Ei(ki), which each player sent as the ﬁrst message of the MtA protocol in
Phase 2.

• Phase 6. Each player computes

Λ =

(cid:89)

i∈S

Λi

If Λ = gδ, player Pi broadcasts si. Otherwise, they abort.

6

Implementation and Evaluation

We implemented our protocol in Go using Binance’s tss-lib [2] implementation of [27] as a starting
point. We note that the tss-lib library is high quality production-level code, and not heavily
optimized for speed. While tss-lib did not contain a benchmark facility, we added one to time the
computation time of the protocol on a single thread and used it to benchmark and compare both
of our protocola as well as the original protocol from [27].

Our benchmark machine was a 2018 Macbook Pro laptop with a 2.3 GHz Intel Core i5 processor
and 16GB of RAM (although our code is not memory intensive). For the sake of a fair comparison,
we ran all benchmarks using only a single core. It should be noted, however, that much of our
code is highly parallelizable and in practice the runtime could thus be signiﬁcantly reduced with
Indeed, the most computationally expensive part of our code is generating the
parallelization.
range proofs and Paillier consistency proofs. As these proofs must be generated separately for each
player, this is trivially parallelizable.

Following [27, 29, 40], we compare the raw computation time of the protocol without accounting
for network latency in Figure 1. In our setup, players were run as separate processes on a single
machine. All benchmarks were taken as averages over 50 runs using Go’s built-in benchmarks
facility, and we report our results in milliseconds. We show the raw data in Table 1.

As we can see, the running times of both of our protocols are quite similar, with the anonymous
protocol performing slightly better (although it has one fewer round in the oﬄine phase). The
oﬄine running time of both of our protocols is slightly slower than [27]. However, whereas their
protocol required online interactivity, the computation for the online phase of our protocol consists
of only a single elliptic curve multiplication and a single addition, and runs in 0.0008 milliseconds.
Our benchmarks account only for computation and not network latency. Thus, it’s important
to remember that our protocols 6 (5 oﬄine and one online) and 7 (6 oﬄine and one online)
rounds respectively, whereas [27] has 9 rounds. Thus even if our entire protocol is run online, it is

21

Figure 1: Comparing the signing time of our identiﬁable abort protocol with [27] for thresholds up
to size 10. Note that unlike [27], the expensive parts of our protocol can be run oﬄine. The x-axis
represents t + 1, the number of active participants in the signing protocol.

likely that requiring two fewer rounds of communication would compensate for the slightly higher
computational costs. In the ﬁnal version of this paper, we will include networked versions of our
benchmarks.

The benchmarks we obtain for [27] are higher than those reported in [27] which is due to the fact
that we include all of the expensive zero-knowledge range proofs in their protocol as well as in ours
in order to achieve full simulation security. In the benchmarks given in [27], the range proofs were
omitted based on a plausible, but unproven conjecture (and indeed if this conjecture is correct then
we can remove them from our protocol as well). Moreover, the code in [27] was heavily optimized
for speed, whereas our implementation builds on Binance’s tss-lib, which is higher quality but less
speed-optimized.

7 Acknowledgement

We thank Omer Shlomovits for pointing out a typo in the faulty player identiﬁcation protocol, and
for other useful comments about the paper.

We thank Ran Canetti, Nikolaos Makriyannis, and Udi Peled for useful discussions about

concrete eﬃciency.

References

[1] Elliptic

curve

digital

signature

algorithm

–

Wikipedia

entry,

https://en.wikipedia.org/wiki/Elliptic Curve Digital Signature Algorithm

[2] tss-lib: Threshold signature scheme, for ecdsa, https://github.com/binance-chain/tss-lib

22

[3] Bar-Ilan, J., Beaver, D.: Non-cryptographic fault-tolerant computing in constant number of
rounds of interaction. In: Proceedings of the eighth annual ACM Symposium on Principles of
distributed computing. pp. 201–209. ACM (1989)

[4] Bari´c, N., Pﬁtzmann, B.: Collision-free accumulators and fail-stop signature schemes with-
out trees. In: International Conference on the Theory and Applications of Cryptographic
Techniques. pp. 480–494. Springer (1997)

[5] Boneh, D.: Digital signature standard. In: Encyclopedia of cryptography and security, pp.

347–347. Springer (2011)

[6] Boneh, D., Gennaro, R., Goldfeder, S.: Using level-1 homomorphic encryption to improve

threshold dsa signatures for bitcoin wallet security. In: Latincrypt (2017)

[7] Boudot, F.: Eﬃcient proofs that a committed number lies in an interval. In: International Con-
ference on the Theory and Applications of Cryptographic Techniques. pp. 431–444. Springer
(2000)

[8] Canetti, R., Gennaro, R., Goldfeder, S., Makriyannis, N., Peled, U.: Uc non-interactive, proac-
tive, threshold ecdsa with identiﬁable aborts. Cryptology ePrint Archive, Report 2021/060
(2021), https://ia.cr/2021/060

[9] Canetti, R., Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Adaptive security for threshold
cryptosystems. In: Annual International Cryptology Conference. pp. 98–116. Springer (1999)

[10] Canetti, R., Makriyannis, N., Peled, U.: Uc non-interactive, proactive, threshold ecdsa,

https://eprint.iacr.org/2020/492

[11] Castagnos, G., Catalano, D., Laguillaumie, F., Savasta, F., Tucker, I.: Bandwidth-eﬃcient

threshold ec-dsa, https://eprint.iacr.org/2020/084

[12] Castagnos, G., Catalano, D., Laguillaumie, F., Savasta, F., Tucker, I.: Two-party ecdsa
from hash proof systems and eﬃcient instantiations. In: Annual International Cryptology
Conference. pp. 191–221. Springer (2019)

[13] Chaum, D., Pedersen, T.P.: Wallet databases with observers. In: Annual International Cryp-

tology Conference. pp. 89–105. Springer (1992)

[14] Chen, M., Hazay, C., Ishai, Y., Kashnikov, Y., Micciancio, D., Riviere, T., Shelat, A., Venki-
tasubramaniam, M., Wang, R.: Diogenes: Lightweight scalable RSA modulus generation with
a dishonest majority, https://eprint.iacr.org/2020/374

[15] Dalskov, A., Keller, M., Orlandi, C., Shrishak, K., Shulman, H.: Securing dnssec keys via

threshold ecdsa from generic mpc, https://eprint.iacr.org/2019/889

[16] Damgard, I., Groth, J.: Non-interactive and reusable non-malleable commitment schemes. In:
Proceedings of the thirty-ﬁfth annual ACM symposium on Theory of computing. pp. 426–437.
ACM (2003)

[17] Damg˚ard, I., Jakobsen, T.P., Nielsen, J.B., Pagter, J.I., Østergard, M.B.: Fast threshold ecdsa

with honest majority, https://eprint.iacr.org/2020/501

[18] Damg˚ard, I., Keller, M., Larraia, E., Miles, C., Smart, N.P.: Implementing aes via an ac-
tively/covertly secure dishonest-majority mpc protocol. In: International Conference on Se-
curity and Cryptography for Networks. pp. 241–263. Springer (2012)

[19] Desmedt, Y.G.: Threshold cryptography. Transactions on Emerging Telecommunications

Technologies 5(4), 449–458 (1994)

23

[20] Di Crescenzo, G., Ishai, Y., Ostrovsky, R.: Non-interactive and non-malleable commitment.
In: Proceedings of the thirtieth annual ACM symposium on Theory of computing. pp. 141–
150. ACM (1998)

[21] Di Crescenzo, G., Katz, J., Ostrovsky, R., Smith, A.: Eﬃcient and non-interactive non-
malleable commitment. In: International Conference on the Theory and Applications of Cryp-
tographic Techniques. pp. 40–59. Springer (2001)

[22] Doerner, J., Kondi, Y., Lee, E., abhi shelat: Threshold ecdsa from ecdsa assumptions: The

multiparty case. In: Oakland SP’2019 (2019)

[23] Doerner, J., Kondi, Y., Lee, E., et al.: Secure two-party threshold ecdsa from ecdsa assump-

tions. In: IEEE Symposium on Security and Privacy. p. 0. IEEE (2018)

[24] Dolev, D., Dwork, C., Naor, M.: Non-malleable cryptography,”. In: Proceedings of the 23rd

Annual Symposium on the Theory of Computing, ACM (1991)

[25] Gagol, A.,

Straszak, D.:

Threshold

ecdsa

for

decentralized

asset

custody,

https://eprint.iacr.org/2020/498

[26] Gennaro, R.: Multi-trapdoor commitments and their applications to proofs of knowledge se-
cure under concurrent man-in-the-middle attacks. In: Annual International Cryptology Con-
ference. pp. 220–236. Springer (2004)

[27] Gennaro, R., Goldfeder, S.: Fast multiparty threshold ecdsa with fast trustless setup. In: Pro-
ceedings of the 2018 ACM SIGSAC Conference on Computer and Communications Security.
pp. 1179–1194. ACM (2018)

[28] Gennaro, R., Goldfeder, S.: Fast multiparty threshold ecdsa with fast trustless setup. Cryp-

tology ePrint Archive, Report 2019/114 (2019), https://ia.cr/2019/114

[29] Gennaro, R., Goldfeder, S., Narayanan, A.: Threshold-optimal dsa/ecdsa signatures and an
application to bitcoin wallet security. In: International Conference on Applied Cryptography
and Network Security. pp. 156–174. Springer (2016)

[30] Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Robust threshold dss signatures. In:
International Conference on the Theory and Applications of Cryptographic Techniques. pp.
354–371. Springer (1996)

[31] Gennaro, R., Jarecki, S., Krawczyk, H., Rabin, T.: Robust threshold dss signatures. Informa-

tion and Computation 164(1), 54–84 (2001)

[32] Gennaro, R., Micciancio, D., Rabin, T.: An eﬃcient non-interactive statistical zero-knowledge
In Proc. of the 5th ACM Conference on

proof system for quasi-safe prime products. In:
Computer and Communications Security (CCS-98. Citeseer (1998)

[33] Gilboa, N.: Two party rsa key generation. In: Advances in Cryptology - CRYPTO ’99. pp.

116–129 (1999)

[34] Goldreich, O., Micali, S., Wigderson, A.: How to play any mental game or A completeness
theorem for protocols with honest majority. In: Aho, A.V. (ed.) Proceedings of the 19th
Annual ACM Symposium on Theory of Computing, 1987, New York, New York, USA. pp.
218–229. ACM (1987)

[35] Goldwasser, S., Micali, S., Rivest, R.L.: A digital signature scheme secure against adaptive

chosen-message attacks. SIAM Journal on Computing 17(2), 281–308 (1988)

24

[36] Ishai, Y., Ostrovsky, R., Zikas, V.: Secure multi-party computation with identiﬁable abort.
In: Garay, J.A., Gennaro, R. (eds.) Advances in Cryptology - CRYPTO 2014 - 34th Annual
Cryptology Conference, Santa Barbara, CA, USA, August 17-21, 2014, Proceedings, Part II.
Lecture Notes in Computer Science, vol. 8617, pp. 369–386. Springer (2014)

[37] Jarecki, S., Lysyanskaya, A.: Adaptively secure threshold cryptography: Introducing concur-
rency, removing erasures. In: International Conference on the Theory and Applications of
Cryptographic Techniques. pp. 221–242. Springer (2000)

[38] Keller, M., Pastro, V., Rotaru, D.: Overdrive: making spdz great again. In: Annual Interna-
tional Conference on the Theory and Applications of Cryptographic Techniques. pp. 158–189.
Springer (2018)

[39] Kravitz, D.W.: Digital signature algorithm (Jul 27 1993), uS Patent 5,231,668

[40] Lindell, Y.: Fast secure two-party ecdsa signing. In: Annual International Cryptology Con-

ference. pp. 613–644. Springer (2017)

[41] Lindell, Y., Nof, A.: Fast secure multiparty ecdsa with practical distributed key generation and
applications to cryptocurrency custody. In: Proceedings of the 2018 ACM SIGSAC Conference
on Computer and Communications Security. pp. 1837–1854. ACM (2018)

[42] MacKenzie, P., Reiter, M.K.: Two-party generation of dsa signatures. In: Annual Interna-

tional Cryptology Conference. pp. 137–154. Springer (2001)

[43] MacKenzie, P., Yang, K.: On simulation-sound trapdoor commitments. In: International Con-
ference on the Theory and Applications of Cryptographic Techniques. pp. 382–400. Springer
(2004)

[44] Paillier, P.: Public-key cryptosystems based on composite degree residuosity classes. In: In-
ternational Conference on the Theory and Applications of Cryptographic Techniques. pp.
223–238. Springer (1999)

[45] Rivest, R.L., Shamir, A., Adleman, L.: A method for obtaining digital signatures and public-

key cryptosystems. Communications of the ACM 21(2), 120–126 (1978)

[46] Schnorr, C.: Eﬃcient signature generation by smart cards. J. Cryptology 4(3), 161–174 (1991)

[47] Shamir, A.: How to share a secret. Communications of the ACM 22(11), 612–613 (1979)

A Security proof for the identiﬁable protocol (Section 3)

In this section we prove the following

Assuming that

• The Strong RSA Assumption holds;

• KG, Com, Ver, Equiv is a non-malleable equivocable commitment scheme;

• The encryption scheme used in the MtA protocols is semantically secure

then our threshold DSA schemes is simulatable.

Let A be an adversary who controls players P2, . . . , Pt+1 and that P1 is the honest player. We
point out that because we use concurrently non-malleable commitments (where the adversary can
see many commitments from the honest players) the proof also holds if the adversary controls less
than t players and we have more than 1 honest player. So the above assumption is without loss of
generality.

25

Because we are assuming a rushing adversary, P1 always speaks ﬁrst at each round. Our
simulator will act on behalf of P1 and interact with the adversary controlling P2, . . . , Pn. Recall
how A works: it ﬁrst participates in the key generation protocol to generate a public key y for the
threshold scheme. Then it requests the group of players to sign several messages m1, . . . , m(cid:96), and
the group engages in the signing protocol on those messages.

A.1 Simulating the key generation protocol

The simulation Sim-Key-Gen is described below. On input a public key y = gx for DSA the
simulator plays the role of P1 as follows. It runs on input a Paillier public key E for which he does
not know the matching secret key (this is necessary for when we have to make a reduction to the
semantic security of the Paillier encryption scheme).

Simulation:

• P1 selects a random value u1 ∈ Zq, computes [KGC1, KGD1]= Com(gu1 ) and broadcasts

KGC1. A broadcasts commitments KCGi for i > 1;

• Each player Pi broadcasts KGDi; let yi be the decommitted value and the accompanying

Feldman-VSS. Each player broadcasts Ei. P1 follows the protocol’s instructions.

• Let yi denote the revealed commitment values of each party. The simulator rewinds the

adversary to the decommitment step and

– changes the opening of P1 to
i=2 y−1

ˆy1 = y · (cid:81)n

.

i

ˆKGD1 so that the committed value revealed is now

– simulates the Feldman-VSS with free term ˆy1

• The adversary A broadcasts

ˆKGDi. Let ˆyi be the committed value revealed by A at this

point (this could be ⊥ if the adversary refused to decommit).

• The players compute ˆy = (cid:81)n

i=1 ˆyi (set to ⊥ if any of the ˆyi are set to ⊥ in the previous step).

We now prove a few lemmas about this simulation.
The simulation is indistinguishable from the real protocol, and it either outputs y or it aborts.
[Proof of Lemma A.1] The only diﬀerences between the real and the simulated views is that P1
runs a simulated Feldman-VSS with free term in the exponent ˆy1 for which it does not know the
discrete log. But we know (see Section 2.8) that this simulation is identically distributed from the
real Feldman-VSS. So the simulation of the protocol is perfect. Because of the rewinding step if
the simulation does not end in an abort, it will output y.

A.2 Simulating the signing protocol

After the key generation is over, the simulator must handle the signature queries issued by the
adversary A. Recall that A can issue two type of queries:

• to UG to obtain R a uniformly random element in G;

• to Sig’(sk, R, m) which returns (r, s) a valid signature for m with r = H (cid:48)(R), if R was queried

to UG, otherwise returns ⊥

The simulator will engage in a simulation of the threshold signature protocol running P1 and
on input R for the oﬄine phase (Phases 1-6), and a correct signature (r, s) for m under the public
key y for the online phase 7.

26

We point out that the simulator does not know the secret values associated with P1: its correct
share w1 of the secret key, and the secret key corresponding to its public key E1. The latter is
necessary in order to reduce unforgeability to the semantic security of the encryption scheme.

However the simulator does know the shares wj of all other players. It also knows the “public

key” of P1, W1 = gw1 from the simulation of the key generation protocol.

Finally the simulator aborts whenever in the protocol P1 is supposed to abort.

Simulation of Phases 1 to 4

• Phase 1. P1 runs the protocol correctly. That is, all the players execute the protocol by

broadcasting Ci .

• Phase 2. Recall that during the regular run of the protocol, P1 will engage in two MtA
protocols and two MtAwc protocols with each other player Pi>1. S runs the protocol for P1
as follows:

– Initiator for MtA with k1 and γj. S runs the protocol correctly for P1, as it knows k1.
However, since S does not know P1’s private key, it will be unable to decrypt α1j.
S extracts Pj’s values γj and βij from the range proofs and computes α1j = k1γj −
β1j mod q

– Respondent for MtA with kj and γ1. S runs the protocol correctly for P1, as it knows
γ1. From Pj’s range proof, S also extracts kj. It knows its own share βj1 and using
the value it extracts, it can compute Pj’s share as αj1 = kjγ1 − βj1 mod q.

– Initiator for MtAwc with k1 and wj. S runs the protocol correctly for P1, as it knows k1
and indeed this ﬁrst message is identical for all players in both MtA and MtAwc. Here
again, S will be unable to decrypt its share µij, but it learns it from extracting wj and
ν1j from Pj’s range proof and computing µ1j = k1wj − ν1j mod q.

– Respondent for MtAwc with kj and w1. Here, S does not know w1, so it simulates P1
according to the simulation described in Section 2.10. In particular, it chooses a random
ˆw1 and runs the protocol normally with the exception that it now simulates the zero
knowledge proof of consistency with gw1. S knows its own share νj1 and using the
value it extracts, it can compute Pj’s share as µj1 = kj ˆw1 − νj1 mod q.

Note that at this point S knows:

– Its own values k1, γ1 as well as all of its own shares from the MtA and MtAwc protocols:

α1j, βj1 for j > 1.

– The values kj, γj, wj belonging to every other players as well as their shares for the

MtA and MtAwc protocols that interacted with P1 : µj1, ν1j for j > 1.

Recall the deﬁnitions of δi and σi:

δi = kiγi +

(cid:88)

j(cid:54)=i

αij +

(cid:88)

j(cid:54)=i

βji mod q

σi = kiwi +

(cid:88)

j(cid:54)=i

µij +

(cid:88)

j(cid:54)=i

νji mod q

S can compute P1’s value δ1 using the above deﬁnition, but it cannot compute σ1 since it
doesn’t know w1.

27

Moreover, S does not know the internal values from the MtA and MtAwc protocols executed
by two players that are both controlled by the adversary.
Indeed, S does not see these
messages during the protocol, and even if it did see them, it could not force the adversary
to provide diﬀerent values that would enable extraction. Thus S is not able to compute the
individual values σj and δj for Pj>1.
Nevertheless, since S knows all shares ki, γi including its own, it can compute:

(cid:88)

δ =

(cid:88)

δi = (

(cid:88)

ki) · (

γi) mod q

i

i

i

Although S can compute δ, it cannot similarly compute σ = (cid:80)
i σi since it doesn’t know its
own value w1. Instead, we deﬁne σA as the summation of all the adversaries values. That is:

σA =

(cid:88)

j>1

σj mod q

Notice that we can express σA as a function of values that are known to S. In particular:

σA =

(cid:88)

i>1

σi =

(cid:88)

i,j>1

kiwj +

(cid:88)

j

µj1 +

(cid:88)

j

ν1j mod q

and S knows all the values on the right hand side of the equation.

• Phase 3. All the players execute the protocol by revealing δi. Let ˆδ = (cid:80)
protocol correctly for P1 as it knows all of its correct shares from Phase 2.
The simulator broadcasts T1 = gσ1 h(cid:96)1 for (cid:96)1 ∈R Zq. Note that the simulator does not know
an opening of this commitment (since it does not know σ1) so it simulates the ZK proof.
The simulator extracts the values the adversary committed to in Ti for i > 1 using the proof
of knowledge. Let ˆσi be those values and ˆσA = (cid:80)

i δi. S runs the

i>1 ˆσi.

• Phase 4. Each player reveals Di to decommit to Γi.

At this point the simulator can detect if the values so far published by the adversary are
. Then using the values ki extracted during the MtA

consistent. It ﬁrst computes ˜R = ((cid:81) Γi)δ−1
protocols, it checks if

(cid:89) ˜Rki = g

The simulator can also detect if the adversary produced commitments Si to the correct σi by
checking if ˆσA = σA.

We say that an execution is semi-correct if

(cid:89) ˜Rki = g and ˆσA = σA

Otherwise, this execution is not semi-correct.

At this point, the simulation will depend on whether or not this execution is semi-correct.

28

A.2.1 Finishing the simulation of the oﬄine phase

Semi-correct

– S retrieves the randomizer R.

Non semi-correct

– S rewinds A to the decommitment
step, and for P1 changes the decom-
mitment to ˆΓ1 = Rδ (cid:81)
. Note
that [ ˆΓ1
= R

i>1 Γ−1

i>1 Γi]δ−1

(cid:81)

i

• Phase 5 S has P1 publish

R1 = g

R−ki

(cid:89)

i>1

together with a simulated zkp of consistency
with E1(k1) (note that in this case the sim-
ulated R1 (cid:54)= Rk1 due to the rewinding).

• Phase 6 S has P1 publish

S1 = y

R−σi

(cid:89)

i>1

together with a simulated zkp of consistency
with T1 (again in this case the simulated
S1 (cid:54)= Rσ1 due to the rewinding).

A.2.2 Simulation of the online Phase 7

– Phase 5. S has P1 publish

R1 = Rk1

together with a zkp of consistency with
E1(k1) (S can produce a correct proof, does
not need to simulate it).
– Phase 6. S has P1 publish

S1 = Rσ1

together with a zkp of consistency with T1 (S
can produce a correct proof, does not need
to simulate it).

Since this execution is not semi-correct, we
know that at least one of the the adversary’s
proofs will fail at either one of these steps
and the protocol will abort.

Here S receives the correct signature (r, s) on m, where r = H(R) computed in one of the previous
oﬄine phases (in particular in one that was semi-correct, since it concluded successfully).

Note that at this point S knows sA = (cid:80)

j>1 sj (i.e., the summed value of all the sj held by the

bad players) since

where σA is as deﬁned in the simulation of Phase 2 and kA = (cid:80)
So S can compute the correct s1 held by P1 as s − sA.

j>1 kj.

sA = kAm + σAr

• Phase 7 S reveals s1 that it computed in the previous step as the share for P1.

A.2.3 Proof

We prove the following lemma about the simulation.

Assuming that

• E is a semantically secure encryption scheme

• The Strong RSA Assumption holds

• KG, Com, Ver, Equiv is a non-malleable equivocable commitment;

then the simulation has the following properties

• on input m it outputs a valid signature (r, s) or aborts.

• it is computationally indistinguishable from a real execution

29

[Proof of Lemma A.2.3]
Semi-Correct Executions. The only diﬀerences between the real and the simulated views
is the following: In the MtA protocol the values ci = Ei(ki) are published and in the real protocol
i ki, while in the simulated execution R = gˆk−1
for the ˆk chosen by the
R = gk−1
signature oracle. This is easily seen to be computationally indistinguishable under the semantic
security of Paillier’s encryption.

where k = (cid:80)

ˆk1+(cid:80)

Indeed, when S rewinds the adversary to “ﬁx” the value of R, it implicitly changes the value
i>1 ki. Note that Rˆk1
k1 that S contributes for P1 to R. If R = gˆk−1
ki. So to distinguish between the real
is known since R
execution and the simulated one, the adversary should detect if the ciphertext sent by S for P1
in the ﬁrst round of the MtAwc protocol contains a random k1 or the random ˆk1 determined as
logR(gR− (cid:80)
ki) which is infeasible under the semantic security of Paillier’s encryption (given
that all values are proven to be “small” and no wraparound mod N happens).

ki = g, therefore Rˆk1 = gR− (cid:80)

, let (implicitly) ˆk1 = ˆk − (cid:80)

i>1

i>1

i>1

Note that we are simulating a semi-correct execution with an execution which is not semi-

correct, but that’s okay because the two are indistinguishable.

However, because the real execution is a semi-correct one, we know that the correct shares of
k for the adversary are the ki that the simulator knows. Therefore the value s1 computed by the
simulator is consistent with a correct share for P1 for a valid signature (r, s), which makes Phase
7 indistinguishable from the real execution to the adversary.

Let (r, s) be the signature that S receives by its signature oracle in Step 2 of Phase 4. This
is a valid signature for m. We prove that if the protocol terminates, it does so with output (r, s).
This is a consequence of the non-malleability property of the commitment scheme. Indeed, if the
adversary correctly decommits, its openings must be the same except with negligible probability.

Non-Semi Correct Execution. In this case the protocol and the simulation both abort when
one of the ZK proofs of the bad players fails.

A.3 Simulation of the identiﬁcation protocol

Referring back to Section 4.2, aborts of any type except (5) or (7) happen when a well-deﬁned
player fails a step (either a decommitment or a ZK proof). In this case the player is immediately
identiﬁed and no additional steps have to be taken. In particular this event happens with the same
distribution in the simulation and therefore aborts of this type are easily simulated.

Aborts of types (5) and (7) are not immediately attributable because we only know that an
aggregate value is wrong. We note that in this case we already know that the simulation is
non-semi-correct, therefore the adversary has not been rewinded. In turn, this implies that the
simulator can open ciphertexts in a consistent way with the rest of the transcript of the protocol.
For aborts of type (5) we require players to open their randomness for the MtA protocol with

input ki and γj. As pointed out above, the simulator can do this without a problem.

For aborts of type (7) we also note that in a non-semi-correct simulation the simulator knows
the secret key of the Paillier’s Encryption of player P1. Therefore the simulator can decrypt µ1,j
and reveal it in a way that is consistent with the transcript.

B Security proof for the anonymous abort protocol (Section

5)

Note that Phases 1-4 are identical between the two protocols except for the broadcasting of the
commitments Ti + their associated zkps which are omitted in the anonymous abort protocol.

Therefore the simulation of Phases 1-4 of the the anonymous abort protocol is the same as the
simulation of Phases 1-4 of the identiﬁable abort protocol, except that we omit broadcasting the

30

commitments Ti + their associated zkps in the simulation as well.

At the end of Phase 4 we deﬁne a semi-correct execution one in which (cid:81)
ki are the values deﬁned by the encryptions sent by the players during Phase 2.

i Γki = gδ where the

B.1 Finishing the simulation of the oﬄine phase

Semi-correct

– S retrieves the randomizer R.

– S rewinds A to the decommitment
step, and for P1 changes the decom-
mitment to ˆΓ1 = Rδ (cid:81)
. Note
that [ ˆΓ1
= R

i>1 Γ−1

i>1 Γi]δ−1

(cid:81)

i

• Phase 5 S has P1 publish
Λ1 = gδ (cid:89)

Γki

i>1

together with a simulated zkp of consistency
with E1(k1) (note that in this case the sim-
ulated Λ1 (cid:54)= Γk1 due to the rewinding).

B.2 Simulation of the online Phase 6

Non semi-correct

– Phase 5. S has P1 publish

Λ1 = Γk1

together with a zkp of consistency with
E1(k1) (S can produce a correct proof, does
not need to simulate it).

Since this execution is not semi-correct, we
know that at least one of the the adversary’s
proofs will fail at either one of these steps
and the protocol will abort.

Here S receives the correct signature (r, s) on m, where r = H(R) computed in one of the previous
oﬄine phases (in particular in one that was semi-correct, since it concluded successfully).

Note that at this point S knows sA = (cid:80)

j>1 sj (i.e., the summed value of all the sj held by the

bad players) since

where σA is as deﬁned in the simulation of Phase 2 and kA = (cid:80)
So S can compute the correct s1 held by P1 as s − sA.

j>1 kj.

sA = kAm + σAr

• Phase 6 S reveals s1 that it computed in the previous step as the share for P1.

B.3 Proof

We prove the following lemmma about the simulation:

Assuming that

• E is a semantically secure encryption scheme

• The Strong RSA Assumption holds

• KG, Com, Ver, Equiv is a non-malleable equivocable commitment;

then the simulation has the following properties

• on input m it outputs a valid signature (r, s) or aborts.

• it is computationally indistinguishable from a real execution

31

[Proof of Lemma B.3]
Semi-Correct Executions. The only diﬀerences between the real and the simulated views
is the following: In the MtA protocol the values ci = Ei(ki) are published and in the real pro-
for the ˆk chosen
tocol R = gk−1
by the signature oracle. This is easily seen to be computationally indistinguishable under the
https://www.overleaf.com/project/5d600f66de7b0c16fa84e436 semantic security of Paillier’s en-
cryption.

i ki, while in the simulated execution R = gˆk−1

where k = (cid:80)

ˆk1+(cid:80)

Indeed, when S rewinds the adversary to “ﬁx” the value of R, it implicitly changes the value
i>1 ki. Note that Rˆk1
k1 that S contributes for P1 to R. If R = gˆk−1
ki. So to distinguish between the real
is known since R
execution and the simulated one, the adversary should detect if the ciphertext sent by S for P1
in the ﬁrst round of the MtAwc protocol contains a random k1 or the random ˆk1 determined as
logR(gR− (cid:80)
ki) which is infeasible under the semantic security of Paillier’s encryption (given
that all values are proven to be “small” and no wraparound mod N happens).

ki = g, therefore Rˆk1 = gR− (cid:80)

, let (implicitly) ˆk1 = ˆk − (cid:80)

i>1

i>1

i>1

Note that we are simulating a semi-correct execution with an execution which is not semi-

correct, but that’s okay because the two are indistinguishable.

However, because the real execution is a semi-correct one, we know that the correct shares of
k for the adversary are the ki that the simulator knows. Let (r, s) be the signature that S receives
by its signature oracle in Phase 6. This is a valid signature for m.

Therefore the value s1 computed by the simulator is consistent with a correct share for P1
for a valid signature (r, s), which makes Phase 6 indistinguishable from the real execution to the
adversary.

We prove that if the protocol terminates, it does so with output (r, s). This is a consequence
Indeed, if the adversary correctly

of the non-malleability property of the commitment scheme.
decommits, its openings must be the same except with negligible probability.

Non-Semi Correct Execution. In this case the protocol and the simulation both abort when
one of the ZK proofs of the bad players fails.

32



=== Content from github.com_9697470e_20250111_113510.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=fireblocks-labs%2Fmpc-ecdsa-attacks-23)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[fireblocks-labs](/fireblocks-labs)
/
**[mpc-ecdsa-attacks-23](/fireblocks-labs/mpc-ecdsa-attacks-23)**
Public

* [Notifications](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23) You must be signed in to change notification settings
* [Fork
  3](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)
* [Star
   17](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

[17
stars](/fireblocks-labs/mpc-ecdsa-attacks-23/stargazers) [3
forks](/fireblocks-labs/mpc-ecdsa-attacks-23/forks) [Branches](/fireblocks-labs/mpc-ecdsa-attacks-23/branches) [Tags](/fireblocks-labs/mpc-ecdsa-attacks-23/tags) [Activity](/fireblocks-labs/mpc-ecdsa-attacks-23/activity)
 [Star](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

 [Notifications](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23) You must be signed in to change notification settings

* [Code](/fireblocks-labs/mpc-ecdsa-attacks-23)
* [Issues
  1](/fireblocks-labs/mpc-ecdsa-attacks-23/issues)
* [Pull requests
  0](/fireblocks-labs/mpc-ecdsa-attacks-23/pulls)
* [Actions](/fireblocks-labs/mpc-ecdsa-attacks-23/actions)
* [Projects
  0](/fireblocks-labs/mpc-ecdsa-attacks-23/projects)
* [Security](/fireblocks-labs/mpc-ecdsa-attacks-23/security)
* [Insights](/fireblocks-labs/mpc-ecdsa-attacks-23/pulse)

Additional navigation options

* [Code](/fireblocks-labs/mpc-ecdsa-attacks-23)
* [Issues](/fireblocks-labs/mpc-ecdsa-attacks-23/issues)
* [Pull requests](/fireblocks-labs/mpc-ecdsa-attacks-23/pulls)
* [Actions](/fireblocks-labs/mpc-ecdsa-attacks-23/actions)
* [Projects](/fireblocks-labs/mpc-ecdsa-attacks-23/projects)
* [Security](/fireblocks-labs/mpc-ecdsa-attacks-23/security)
* [Insights](/fireblocks-labs/mpc-ecdsa-attacks-23/pulse)

# fireblocks-labs/mpc-ecdsa-attacks-23

    main[Branches](/fireblocks-labs/mpc-ecdsa-attacks-23/branches)[Tags](/fireblocks-labs/mpc-ecdsa-attacks-23/tags)Go to fileCode
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit History[3 Commits](/fireblocks-labs/mpc-ecdsa-attacks-23/commits/main/) | | |
| [2023-1234.pdf](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/2023-1234.pdf "2023-1234.pdf") | | [2023-1234.pdf](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/2023-1234.pdf "2023-1234.pdf") |  |  |
| [README.md](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/README.md "README.md") | | [README.md](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/README.md "README.md") |  |  |
| View all files | | |

## Repository files navigation

* README
# Practical Key-Extraction Attacks in Leading MPC Wallets (2023)

The most updated version of the paper can be found on eprint: <https://eprint.iacr.org/2023/1234>

An additional copy of the paper can be found in this repo: [2023-1234.pdf](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/2023-1234.pdf)

## About

No description, website, or topics provided.
### Resources

[Readme](#readme-ov-file)

[Activity](/fireblocks-labs/mpc-ecdsa-attacks-23/activity)
[Custom properties](/fireblocks-labs/mpc-ecdsa-attacks-23/custom-properties)
### Stars

[**17**
stars](/fireblocks-labs/mpc-ecdsa-attacks-23/stargazers)
### Watchers

[**0**
watching](/fireblocks-labs/mpc-ecdsa-attacks-23/watchers)
### Forks

[**3**
forks](/fireblocks-labs/mpc-ecdsa-attacks-23/forks)
[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23&report=fireblocks-labs+%28user%29)

## [Releases](/fireblocks-labs/mpc-ecdsa-attacks-23/releases)

No releases published

## [Packages 0](/orgs/fireblocks-labs/packages?repo_name=mpc-ecdsa-attacks-23)

No packages published

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_911d5953_20250111_113511.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=fireblocks-labs%2Fsafeheron-gg20-exploit-poc)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[fireblocks-labs](/fireblocks-labs)
/
**[safeheron-gg20-exploit-poc](/fireblocks-labs/safeheron-gg20-exploit-poc)**
Public

* [Notifications](/login?return_to=%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc) You must be signed in to change notification settings
* [Fork
  7](/login?return_to=%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc)
* [Star
   10](/login?return_to=%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc)

### License

[View license](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/LICENSE)

[10
stars](/fireblocks-labs/safeheron-gg20-exploit-poc/stargazers) [7
forks](/fireblocks-labs/safeheron-gg20-exploit-poc/forks) [Branches](/fireblocks-labs/safeheron-gg20-exploit-poc/branches) [Tags](/fireblocks-labs/safeheron-gg20-exploit-poc/tags) [Activity](/fireblocks-labs/safeheron-gg20-exploit-poc/activity)
 [Star](/login?return_to=%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc)

 [Notifications](/login?return_to=%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc) You must be signed in to change notification settings

* [Code](/fireblocks-labs/safeheron-gg20-exploit-poc)
* [Issues
  0](/fireblocks-labs/safeheron-gg20-exploit-poc/issues)
* [Pull requests
  0](/fireblocks-labs/safeheron-gg20-exploit-poc/pulls)
* [Actions](/fireblocks-labs/safeheron-gg20-exploit-poc/actions)
* [Projects
  0](/fireblocks-labs/safeheron-gg20-exploit-poc/projects)
* [Security](/fireblocks-labs/safeheron-gg20-exploit-poc/security)
* [Insights](/fireblocks-labs/safeheron-gg20-exploit-poc/pulse)

Additional navigation options

* [Code](/fireblocks-labs/safeheron-gg20-exploit-poc)
* [Issues](/fireblocks-labs/safeheron-gg20-exploit-poc/issues)
* [Pull requests](/fireblocks-labs/safeheron-gg20-exploit-poc/pulls)
* [Actions](/fireblocks-labs/safeheron-gg20-exploit-poc/actions)
* [Projects](/fireblocks-labs/safeheron-gg20-exploit-poc/projects)
* [Security](/fireblocks-labs/safeheron-gg20-exploit-poc/security)
* [Insights](/fireblocks-labs/safeheron-gg20-exploit-poc/pulse)

# fireblocks-labs/safeheron-gg20-exploit-poc

    main[Branches](/fireblocks-labs/safeheron-gg20-exploit-poc/branches)[Tags](/fireblocks-labs/safeheron-gg20-exploit-poc/tags)Go to fileCode
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit History[7 Commits](/fireblocks-labs/safeheron-gg20-exploit-poc/commits/main/) | | |
| [cmake](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/cmake "cmake") | | [cmake](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/cmake "cmake") |  |  |
| [proto](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/proto "proto") | | [proto](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/proto "proto") |  |  |
| [src](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/src "src") | | [src](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/src "src") |  |  |
| [test](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/test "test") | | [test](/fireblocks-labs/safeheron-gg20-exploit-poc/tree/main/test "test") |  |  |
| [.gitignore](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/.gitignore ".gitignore") | | [.gitignore](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/.gitignore ".gitignore") |  |  |
| [CMakeLists.txt](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/CMakeLists.txt "CMakeLists.txt") | | [CMakeLists.txt](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/CMakeLists.txt "CMakeLists.txt") |  |  |
| [GoogleTest-Installation.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/GoogleTest-Installation.md "GoogleTest-Installation.md") | | [GoogleTest-Installation.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/GoogleTest-Installation.md "GoogleTest-Installation.md") |  |  |
| [LICENSE](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/LICENSE "LICENSE") | | [LICENSE](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/LICENSE "LICENSE") |  |  |
| [Modify-MPC-CMP-as-a-Threshold-Signature-Scheme.pdf](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/Modify-MPC-CMP-as-a-Threshold-Signature-Scheme.pdf "Modify-MPC-CMP-as-a-Threshold-Signature-Scheme.pdf") | | [Modify-MPC-CMP-as-a-Threshold-Signature-Scheme.pdf](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/Modify-MPC-CMP-as-a-Threshold-Signature-Scheme.pdf "Modify-MPC-CMP-as-a-Threshold-Signature-Scheme.pdf") |  |  |
| [OpenSSL-Installation.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/OpenSSL-Installation.md "OpenSSL-Installation.md") | | [OpenSSL-Installation.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/OpenSSL-Installation.md "OpenSSL-Installation.md") |  |  |
| [Protocol-Buffers-Installation.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/Protocol-Buffers-Installation.md "Protocol-Buffers-Installation.md") | | [Protocol-Buffers-Installation.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/Protocol-Buffers-Installation.md "Protocol-Buffers-Installation.md") |  |  |
| [README.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/README.md "README.md") | | [README.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/README.md "README.md") |  |  |
| [README.original.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/README.original.md "README.original.md") | | [README.original.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/README.original.md "README.original.md") |  |  |
| [SafeHeron-GG20-Exploit-Development-Explainer.pdf](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/SafeHeron-GG20-Exploit-Development-Explainer.pdf "SafeHeron-GG20-Exploit-Development-Explainer.pdf") | | [SafeHeron-GG20-Exploit-Development-Explainer.pdf](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/SafeHeron-GG20-Exploit-Development-Explainer.pdf "SafeHeron-GG20-Exploit-Development-Explainer.pdf") |  |  |
| [preview.gif](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/preview.gif "preview.gif") | | [preview.gif](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/preview.gif "preview.gif") |  |  |
| View all files | | |

## Repository files navigation

* README
* License
# Safeheron GG20 Exploit PoC

This repo contains working exploit code that exfiltrates the private key share from a victim using the GG20 MPC protocol.

[![](/fireblocks-labs/safeheron-gg20-exploit-poc/raw/main/preview.gif)](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/preview.gif)

[SafeHeron-GG20-Exploit-Development-Explainer.pdf](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/SafeHeron-GG20-Exploit-Development-Explainer.pdf) contains a detailed explanation of the exploit development process.

## Build

Before you can run the exploit, you need to first install the prerequisites described below, and then compile the code by running the following commands:

```
git clone https://github.com/orenyomtov/safeheron-gg20-exploit-poc.git
cd safeheron-gg20-exploit-poc
git submodule update --recursive --init
mkdir build && cd build
cmake ..  -DENABLE_TESTS=ON
# Add the path to the LD_LIBRARY_PATH environment variable on Mac OS; Ignore it on Linux
export LIBRARY_PATH=$LIBRARY_PATH:/usr/local/lib/
make
```

## Run

```
ctest --verbose

```

## Affected Library

* <https://github.com/Safeheron/multi-party-ecdsa-cpp>

The library was patched :

* [Safeheron/multi-party-sig-cpp#7](https://github.com/Safeheron/multi-party-sig-cpp/pull/7)
* [Safeheron/multi-party-sig-cpp#10](https://github.com/Safeheron/multi-party-sig-cpp/pull/10)

**Note**: This repository includes a fork of the original library as part of the POC, so we include the original README.md of [the project](https://github.com/Safeheron/multi-party-ecdsa-cpp/tree/b75d125fa336f14d5ea2246b536994871c19215f) at [README.original.md](/fireblocks-labs/safeheron-gg20-exploit-poc/blob/main/README.original.md):

## About

No description, website, or topics provided.
### Resources

[Readme](#readme-ov-file)
### License

[View license](#License-1-ov-file)

[Activity](/fireblocks-labs/safeheron-gg20-exploit-poc/activity)
[Custom properties](/fireblocks-labs/safeheron-gg20-exploit-poc/custom-properties)
### Stars

[**10**
stars](/fireblocks-labs/safeheron-gg20-exploit-poc/stargazers)
### Watchers

[**1**
watching](/fireblocks-labs/safeheron-gg20-exploit-poc/watchers)
### Forks

[**7**
forks](/fireblocks-labs/safeheron-gg20-exploit-poc/forks)
[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fsafeheron-gg20-exploit-poc&report=fireblocks-labs+%28user%29)

## [Releases](/fireblocks-labs/safeheron-gg20-exploit-poc/releases)

No releases published

## [Packages 0](/orgs/fireblocks-labs/packages?repo_name=safeheron-gg20-exploit-poc)

No packages published

## [Contributors 2](/fireblocks-labs/safeheron-gg20-exploit-poc/graphs/contributors)

* [![@orenyomtov](https://avatars.githubusercontent.com/u/168856?s=64&v=4)](https://github.com/orenyomtov)
  [**orenyomtov**
  Oren](https://github.com/orenyomtov)
* [![@arikblocks](https://avatars.githubusercontent.com/u/106652082?s=64&v=4)](https://github.com/arikblocks)
  [**arikblocks**](https://github.com/arikblocks)

## Languages

* [C++
  99.4%](/fireblocks-labs/safeheron-gg20-exploit-poc/search?l=c%2B%2B)
* Other
  0.6%

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


