=== Content from huntr.com_9aee8016_20250111_055710.html ===


* [![logo](/horizontal-logo-wh.svg)](/)
* [Bounties](/bounties)
* [Partners](/partners)
* Community
* Info
[SUBMIT REPORT](/bounties/disclose)

Supported by [Protect AI](https://protectai.com/) and leading the way to [MLSecOps](https://mlsecops.com) and greater AI security.

© 2024

[Privacy Policy](/privacy)[Terms of Service](/terms)[Code of Conduct](/code-of-conduct)Cookie Preferences[Contact Us](/contact-us)

=== Content from github.com_e4fd9d71_20250111_055710.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F479619b340f197a8f24c5db45bc068fb8755f2c5)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F479619b340f197a8f24c5db45bc068fb8755f2c5)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=scrapy%2Fscrapy)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[scrapy](/scrapy)
/
**[scrapy](/scrapy/scrapy)**
Public

* [Notifications](/login?return_to=%2Fscrapy%2Fscrapy) You must be signed in to change notification settings
* [Fork
  10.6k](/login?return_to=%2Fscrapy%2Fscrapy)
* [Star
   53.8k](/login?return_to=%2Fscrapy%2Fscrapy)

* [Code](/scrapy/scrapy)
* [Issues
  429](/scrapy/scrapy/issues)
* [Pull requests
  182](/scrapy/scrapy/pulls)
* [Discussions](/scrapy/scrapy/discussions)
* [Actions](/scrapy/scrapy/actions)
* [Projects
  0](/scrapy/scrapy/projects)
* [Wiki](/scrapy/scrapy/wiki)
* [Security](/scrapy/scrapy/security)
* [Insights](/scrapy/scrapy/pulse)

Additional navigation options

* [Code](/scrapy/scrapy)
* [Issues](/scrapy/scrapy/issues)
* [Pull requests](/scrapy/scrapy/pulls)
* [Discussions](/scrapy/scrapy/discussions)
* [Actions](/scrapy/scrapy/actions)
* [Projects](/scrapy/scrapy/projects)
* [Wiki](/scrapy/scrapy/wiki)
* [Security](/scrapy/scrapy/security)
* [Insights](/scrapy/scrapy/pulse)

## Commit

[Permalink](/scrapy/scrapy/commit/479619b340f197a8f24c5db45bc068fb8755f2c5)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Merge branch '2.11-redos' into 2.11

[Browse files](/scrapy/scrapy/tree/479619b340f197a8f24c5db45bc068fb8755f2c5)
Browse the repository at this point in the history

* Loading branch information

[![@Gallaecio](https://avatars.githubusercontent.com/u/705211?s=40&v=4)](/Gallaecio)

[Gallaecio](/scrapy/scrapy/commits?author=Gallaecio "View all commits by Gallaecio")
committed
Feb 14, 2024

2 parents
[809bfac](/scrapy/scrapy/commit/809bfac4890f75fc73607318a04d2ccba71b3d9f)
+
[5e5a920](/scrapy/scrapy/commit/5e5a92026e43023b80f7733844a2703c3f966009)

commit 479619b

 Show file tree

 Hide file tree

Showing
**9 changed files**
with
**219 additions**
and
**41 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* docs

  + docs/faq.rst
    [faq.rst](#diff-55df9d2f8b8d40391d9d451a1e8155292465d48c52e78dd34655be834cd3dc9f)
  + docs/news.rst
    [news.rst](#diff-87f7a7bb7fe8dbed76e16b67b87f27bda7b779b56e7d93ed3350d77ee4a3f217)
  + topics

    - docs/topics/debug.rst
      [debug.rst](#diff-e71163edea1c109ecb3027fa88cd03d93546867ae925a4fb1c5e3989d26b4b35)
* scrapy

  + spiders

    - scrapy/spiders/feed.py
      [feed.py](#diff-0ad8acd915ed9e66d4658d373b2754893a0b86938b52e883cf139f1914bd0027)
  + utils

    - scrapy/utils/iterators.py
      [iterators.py](#diff-d72259f1af6758707641160617d6badd85b3959024efaeeb666e391c84163744)
    - scrapy/utils/response.py
      [response.py](#diff-7c2eaab025e62dca0eb428793eceffdce44d30685d04aadd2dffe3f6a86a0233)
* tests

  + tests/test\_spider.py
    [test\_spider.py](#diff-1c71b54fd4d3dfba5477740a7d0dd61ad8bc21b1a895c4144fd326d8773bf5dd)
  + tests/test\_utils\_iterators.py
    [test\_utils\_iterators.py](#diff-6f84efe1cfdacaf7f322d1efbb2cb2e75d0f176032ab060270be0956ee0cd322)
  + tests/test\_utils\_response.py
    [test\_utils\_response.py](#diff-b6f3e3a6b906bcaeb2e2a0f5c3eb510f52ffde94d8223fbcdd0f7bbd1e0dffe3)

## There are no files selected for viewing

10 changes: 7 additions & 3 deletions

10
[docs/faq.rst](#diff-55df9d2f8b8d40391d9d451a1e8155292465d48c52e78dd34655be834cd3dc9f "docs/faq.rst")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/docs/faq.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -297,9 +297,13 @@ build the DOM of the entire feed in memory, and this can be quite slow and |
|  |  | consume a lot of memory. |
|  |  |  |
|  |  | In order to avoid parsing all the entire feed at once in memory, you can use |
|  |  | the functions ``xmliter`` and ``csviter`` from ``scrapy.utils.iterators`` |
|  |  | module. In fact, this is what the feed spiders (see :ref:`topics-spiders`) use |
|  |  | under the cover. |
|  |  | the :func:`~scrapy.utils.iterators.xmliter\_lxml` and |
|  |  | :func:`~scrapy.utils.iterators.csviter` functions. In fact, this is what |
|  |  | :class:`~scrapy.spiders.XMLFeedSpider` uses. |
|  |  |  |
|  |  | .. autofunction:: scrapy.utils.iterators.xmliter\_lxml |
|  |  |  |
|  |  | .. autofunction:: scrapy.utils.iterators.csviter |
|  |  |  |
|  |  | Does Scrapy manage cookies automatically? |
|  |  | ----------------------------------------- |
| Expand Down | |  |

31 changes: 30 additions & 1 deletion

31
[docs/news.rst](#diff-87f7a7bb7fe8dbed76e16b67b87f27bda7b779b56e7d93ed3350d77ee4a3f217 "docs/news.rst")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/docs/news.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -19,6 +19,25 @@ Highlights: |
|  |  | Security bug fixes |
|  |  | ~~~~~~~~~~~~~~~~~~ |
|  |  |  |
|  |  | - Addressed `ReDoS vulnerabilities`\_: |
|  |  |  |
|  |  | - ``scrapy.utils.iterators.xmliter`` is now deprecated in favor of |
|  |  | :func:`~scrapy.utils.iterators.xmliter\_lxml`, which |
|  |  | :class:`~scrapy.spiders.XMLFeedSpider` now uses. |
|  |  |  |
|  |  | To minimize the impact of this change on existing code, |
|  |  | :func:`~scrapy.utils.iterators.xmliter\_lxml` now supports indicating |
|  |  | the node namespace with a prefix in the node name, and big files with |
|  |  | highly nested trees when using libxml2 2.7+. |
|  |  |  |
|  |  | - Fixed regular expressions in the implementation of the |
|  |  | :func:`~scrapy.utils.response.open\_in\_browser` function. |
|  |  |  |
|  |  | Please, see the `cc65-xxvf-f7r9 security advisory`\_ for more information. |
|  |  |  |
|  |  | .. \_ReDoS vulnerabilities: https://owasp.org/www-community/attacks/Regular\_expression\_Denial\_of\_Service\_-\_ReDoS |
|  |  | .. \_cc65-xxvf-f7r9 security advisory: https://github.com/scrapy/scrapy/security/advisories/GHSA-cc65-xxvf-f7r9 |
|  |  |  |
|  |  | - :setting:`DOWNLOAD\_MAXSIZE` and :setting:`DOWNLOAD\_WARNSIZE` now also apply |
|  |  | to the decompressed response body. Please, see the `7j7m-v7m3-jqm7 security |
|  |  | advisory`\_ for more information. |
| Expand Down  Expand Up | | @@ -2951,14 +2970,24 @@ affect subclasses: |
|  |  |  |
|  |  | (:issue:`3884`) |
|  |  |  |
|  |  |  |
|  |  | .. \_release-1.8.4: |
|  |  |  |
|  |  | Scrapy 1.8.4 (unreleased) |
|  |  | ------------------------- |
|  |  |  |
|  |  | \*\*Security bug fixes:\*\* |
|  |  |  |
|  |  | - Due to its `ReDoS vulnerabilities`\_, ``scrapy.utils.iterators.xmliter`` is |
|  |  | now deprecated in favor of :func:`~scrapy.utils.iterators.xmliter\_lxml`, |
|  |  | which :class:`~scrapy.spiders.XMLFeedSpider` now uses. |
|  |  |  |
|  |  | To minimize the impact of this change on existing code, |
|  |  | :func:`~scrapy.utils.iterators.xmliter\_lxml` now supports indicating |
|  |  | the node namespace as a prefix in the node name, and big files with highly |
|  |  | nested trees when using libxml2 2.7+. |
|  |  |  |
|  |  | Please, see the `cc65-xxvf-f7r9 security advisory`\_ for more information. |
|  |  |  |
|  |  | - :setting:`DOWNLOAD\_MAXSIZE` and :setting:`DOWNLOAD\_WARNSIZE` now also apply |
|  |  | to the decompressed response body. Please, see the `7j7m-v7m3-jqm7 security |
|  |  | advisory`\_ for more information. |
| Expand Down | |  |

18 changes: 3 additions & 15 deletions

18
[docs/topics/debug.rst](#diff-e71163edea1c109ecb3027fa88cd03d93546867ae925a4fb1c5e3989d26b4b35 "docs/topics/debug.rst")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/docs/topics/debug.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -125,26 +125,16 @@ Fortunately, the :command:`shell` is your bread and butter in this case (see |
|  |  |  |
|  |  | See also: :ref:`topics-shell-inspect-response`. |
|  |  |  |
|  |  |  |
|  |  | Open in browser |
|  |  | =============== |
|  |  |  |
|  |  | Sometimes you just want to see how a certain response looks in a browser, you |
|  |  | can use the ``open\_in\_browser`` function for that. Here is an example of how |
|  |  | you would use it: |
|  |  |  |
|  |  | .. code-block:: python |
|  |  | can use the :func:`~scrapy.utils.response.open\_in\_browser` function for that: |
|  |  |  |
|  |  | from scrapy.utils.response import open\_in\_browser |
|  |  | .. autofunction:: scrapy.utils.response.open\_in\_browser |
|  |  |  |
|  |  |  |
|  |  | def parse\_details(self, response): |
|  |  | if "item name" not in response.body: |
|  |  | open\_in\_browser(response) |
|  |  |  |
|  |  | ``open\_in\_browser`` will open a browser with the response received by Scrapy at |
|  |  | that point, adjusting the `base tag`\_ so that images and styles are displayed |
|  |  | properly. |
|  |  |  |
|  |  | Logging |
|  |  | ======= |
|  |  |  |
| Expand All | | @@ -163,8 +153,6 @@ available in all future runs should they be necessary again: |
|  |  |  |
|  |  | For more information, check the :ref:`topics-logging` section. |
|  |  |  |
|  |  | .. \_base tag: https://www.w3schools.com/tags/tag\_base.asp |
|  |  |  |
|  |  | .. \_debug-vscode: |
|  |  |  |
|  |  | Visual Studio Code |
| Expand Down | |  |

4 changes: 2 additions & 2 deletions

4
[scrapy/spiders/feed.py](#diff-0ad8acd915ed9e66d4658d373b2754893a0b86938b52e883cf139f1914bd0027 "scrapy/spiders/feed.py")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/scrapy/spiders/feed.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -7,7 +7,7 @@ |
|  |  | from scrapy.exceptions import NotConfigured, NotSupported |
|  |  | from scrapy.selector import Selector |
|  |  | from scrapy.spiders import Spider |
|  |  | from scrapy.utils.iterators import csviter, xmliter |
|  |  | from scrapy.utils.iterators import csviter, xmliter\_lxml |
|  |  | from scrapy.utils.spider import iterate\_spider\_output |
|  |  |  |
|  |  |  |
| Expand Down  Expand Up | | @@ -84,7 +84,7 @@ def \_parse(self, response, \*\*kwargs): |
|  |  | return self.parse\_nodes(response, nodes) |
|  |  |  |
|  |  | def \_iternodes(self, response): |
|  |  | for node in xmliter(response, self.itertag): |
|  |  | for node in xmliter\_lxml(response, self.itertag): |
|  |  | self.\_register\_namespaces(node) |
|  |  | yield node |
|  |  |  |
| Expand Down | |  |

41 changes: 37 additions & 4 deletions

41
[scrapy/utils/iterators.py](#diff-d72259f1af6758707641160617d6badd85b3959024efaeeb666e391c84163744 "scrapy/utils/iterators.py")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/scrapy/utils/iterators.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -16,7 +16,11 @@ |
|  |  | cast, |
|  |  | overload, |
|  |  | ) |
|  |  | from warnings import warn |
|  |  |  |
|  |  | from lxml import etree |
|  |  |  |
|  |  | from scrapy.exceptions import ScrapyDeprecationWarning |
|  |  | from scrapy.http import Response, TextResponse |
|  |  | from scrapy.selector import Selector |
|  |  | from scrapy.utils.python import re\_rsearch, to\_unicode |
| Expand All | | @@ -38,6 +42,16 @@ def xmliter( |
|  |  | - a unicode string |
|  |  | - a string encoded as utf-8 |
|  |  | """ |
|  |  | warn( |
|  |  | ( |
|  |  | "xmliter is deprecated and its use strongly discouraged because " |
|  |  | "it is vulnerable to ReDoS attacks. Use xmliter\_lxml instead. See " |
|  |  | "https://github.com/scrapy/scrapy/security/advisories/GHSA-cc65-xxvf-f7r9" |
|  |  | ), |
|  |  | ScrapyDeprecationWarning, |
|  |  | stacklevel=2, |
|  |  | ) |
|  |  |  |
|  |  | nodename\_patt = re.escape(nodename) |
|  |  |  |
|  |  | DOCUMENT\_HEADER\_RE = re.compile(r"<\?xml[^>]+>\s\*", re.S) |
| Expand Down  Expand Up | | @@ -81,15 +95,34 @@ def xmliter\_lxml( |
|  |  | namespace: Optional[str] = None, |
|  |  | prefix: str = "x", |
|  |  | ) -> Generator[Selector, Any, None]: |
|  |  | from lxml import etree |
|  |  |  |
|  |  | reader = \_StreamReader(obj) |
|  |  | tag = f"{{{namespace}}}{nodename}" if namespace else nodename |
|  |  | iterable = etree.iterparse( |
|  |  | cast("SupportsReadClose[bytes]", reader), tag=tag, encoding=reader.encoding |
|  |  | cast("SupportsReadClose[bytes]", reader), |
|  |  | encoding=reader.encoding, |
|  |  | events=("end", "start-ns"), |
|  |  | huge\_tree=True, |
|  |  | ) |
|  |  | selxpath = "//" + (f"{prefix}:{nodename}" if namespace else nodename) |
|  |  | for \_, node in iterable: |
|  |  | needs\_namespace\_resolution = not namespace and ":" in nodename |
|  |  | if needs\_namespace\_resolution: |
|  |  | prefix, nodename = nodename.split(":", maxsplit=1) |
|  |  | for event, data in iterable: |
|  |  | if event == "start-ns": |
|  |  | assert isinstance(data, tuple) |
|  |  | if needs\_namespace\_resolution: |
|  |  | \_prefix, \_namespace = data |
|  |  | if \_prefix != prefix: |
|  |  | continue |
|  |  | namespace = \_namespace |
|  |  | needs\_namespace\_resolution = False |
|  |  | selxpath = f"//{prefix}:{nodename}" |
|  |  | tag = f"{{{namespace}}}{nodename}" |
|  |  | continue |
|  |  | assert isinstance(data, etree.\_Element) |
|  |  | node = data |
|  |  | if node.tag != tag: |
|  |  | continue |
|  |  | nodetext = etree.tostring(node, encoding="unicode") |
|  |  | node.clear() |
|  |  | xs = Selector(text=nodetext, type="xml") |
| Expand Down | |  |

35 changes: 30 additions & 5 deletions

35
[scrapy/utils/response.py](#diff-7c2eaab025e62dca0eb428793eceffdce44d30685d04aadd2dffe3f6a86a0233 "scrapy/utils/response.py")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/scrapy/utils/response.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -74,25 +74,50 @@ def response\_httprepr(response: Response) -> bytes: |
|  |  | return b"".join(values) |
|  |  |  |
|  |  |  |
|  |  | def \_remove\_html\_comments(body): |
|  |  | start = body.find(b"<!--") |
|  |  | while start != -1: |
|  |  | end = body.find(b"-->", start + 1) |
|  |  | if end == -1: |
|  |  | return body[:start] |
|  |  | else: |
|  |  | body = body[:start] + body[end + 3 :] |
|  |  | start = body.find(b"<!--") |
|  |  | return body |
|  |  |  |
|  |  |  |
|  |  | def open\_in\_browser( |
|  |  | response: Union[ |
|  |  | "scrapy.http.response.html.HtmlResponse", |
|  |  | "scrapy.http.response.text.TextResponse", |
|  |  | ], |
|  |  | \_openfunc: Callable[[str], Any] = webbrowser.open, |
|  |  | ) -> Any: |
|  |  | """Open the given response in a local web browser, populating the <base> |
|  |  | tag for external links to work |
|  |  | """Open \*response\* in a local web browser, adjusting the `base tag`\_ for |
|  |  | external links to work, e.g. so that images and styles are displayed. |
|  |  |  |
|  |  | .. \_base tag: https://www.w3schools.com/tags/tag\_base.asp |
|  |  |  |
|  |  | For example: |
|  |  |  |
|  |  | .. code-block:: python |
|  |  |  |
|  |  | from scrapy.utils.response import open\_in\_browser |
|  |  |  |
|  |  |  |
|  |  | def parse\_details(self, response): |
|  |  | if "item name" not in response.body: |
|  |  | open\_in\_browser(response) |
|  |  | """ |
|  |  | from scrapy.http import HtmlResponse, TextResponse |
|  |  |  |
|  |  | # XXX: this implementation is a bit dirty and could be improved |
|  |  | body = response.body |
|  |  | if isinstance(response, HtmlResponse): |
|  |  | if b"<base" not in body: |
|  |  | repl = rf'\1<base href="{response.url}">' |
|  |  | body = re.sub(b"<!--.\*?-->", b"", body, flags=re.DOTALL) |
|  |  | body = re.sub(rb"(<head(?:>|\s.\*?>))", to\_bytes(repl), body) |
|  |  | \_remove\_html\_comments(body) |
|  |  | repl = rf'\0<base href="{response.url}">' |
|  |  | body = re.sub(rb"<head(?:[^<>]\*?>)", to\_bytes(repl), body, count=1) |
|  |  | ext = ".html" |
|  |  | elif isinstance(response, TextResponse): |
|  |  | ext = ".txt" |
| Expand Down | |  |

4 changes: 2 additions & 2 deletions

4
[tests/test\_spider.py](#diff-1c71b54fd4d3dfba5477740a7d0dd61ad8bc21b1a895c4144fd326d8773bf5dd "tests/test_spider.py")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/tests/test_spider.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -151,10 +151,10 @@ def test\_register\_namespace(self): |
|  |  | body = b"""<?xml version="1.0" encoding="UTF-8"?> |
|  |  | <urlset xmlns:x="http://www.google.com/schemas/sitemap/0.84" |
|  |  | xmlns:y="http://www.example.com/schemas/extras/1.0"> |
|  |  | <url><x:loc>http://www.example.com/Special-Offers.html</loc><y:updated>2009-08-16</updated> |
|  |  | <url><x:loc>http://www.example.com/Special-Offers.html</x:loc><y:updated>2009-08-16</y:updated> |
|  |  | <other value="bar" y:custom="fuu"/> |
|  |  | </url> |
|  |  | <url><loc>http://www.example.com/</loc><y:updated>2009-08-16</updated><other value="foo"/></url> |
|  |  | <url><loc>http://www.example.com/</loc><y:updated>2009-08-16</y:updated><other value="foo"/></url> |
|  |  | </urlset>""" |
|  |  | response = XmlResponse(url="http://example.com/sitemap.xml", body=body) |
|  |  |  |
| Expand Down | |  |

40 changes: 31 additions & 9 deletions

40
[tests/test\_utils\_iterators.py](#diff-6f84efe1cfdacaf7f322d1efbb2cb2e75d0f176032ab060270be0956ee0cd322 "tests/test_utils_iterators.py")

Show comments

[View file](/scrapy/scrapy/blob/479619b340f197a8f24c5db45bc068fb8755f2c5/tests/test_utils_iterators.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -1,14 +1,14 @@ |
|  |  | from pytest import mark |
|  |  | import pytest |
|  |  | from twisted.trial import unittest |
|  |  |  |
|  |  | from scrapy.exceptions import ScrapyDeprecationWarning |
|  |  | from scrapy.http import Response, TextResponse, XmlResponse |
|  |  | from scrapy.utils.iterators import \_body\_or\_str, csviter, xmliter, xmliter\_lxml |
|  |  | from tests import get\_testdata |
|  |  |  |
|  |  |  |
|  |  | class XmliterTestCase(unittest.TestCase): |
|  |  | xmliter = staticmethod(xmliter) |
|  |  |  |
|  |  | class XmliterBaseTestCase: |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter(self): |
|  |  | body = b""" |
|  |  | <?xml version="1.0" encoding="UTF-8"?> |
| Expand Down  Expand Up | | @@ -40,6 +40,7 @@ def test\_xmliter(self): |
|  |  | attrs, [("001", ["Name 1"], ["Type 1"]), ("002", ["Name 2"], ["Type 2"])] |
|  |  | ) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_unusual\_node(self): |
|  |  | body = b"""<?xml version="1.0" encoding="UTF-8"?> |
|  |  | <root> |
| Expand All | | @@ -53,6 +54,7 @@ def test\_xmliter\_unusual\_node(self): |
|  |  | ] |
|  |  | self.assertEqual(nodenames, [["matchme..."]]) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_unicode(self): |
|  |  | # example taken from https://github.com/scrapy/scrapy/issues/1665 |
|  |  | body = """<?xml version="1.0" encoding="UTF-8"?> |
| Expand Down  Expand Up | | @@ -112,6 +114,7 @@ def test\_xmliter\_unicode(self): |
|  |  | [("26", ["-"], ["80"]), ("21", ["Ab"], ["76"]), ("27", ["A"], ["27"])], |
|  |  | ) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_text(self): |
|  |  | body = ( |
|  |  | '<?xml version="1.0" encoding="UTF-8"?>' |
| Expand All | | @@ -123,6 +126,7 @@ def test\_xmliter\_text(self): |
|  |  | [["one"], ["two"]], |
|  |  | ) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_namespaces(self): |
|  |  | body = b""" |
|  |  | <?xml version="1.0" encoding="UTF-8"?> |
| Expand Down  Expand Up | | @@ -162,6 +166,7 @@ def test\_xmliter\_namespaces(self): |
|  |  | self.assertEqual(node.xpath("id/text()").getall(), []) |
|  |  | self.assertEqual(node.xpath("price/text()").getall(), []) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_namespaced\_nodename(self): |
|  |  | body = b""" |
|  |  | <?xml version="1.0" encoding="UTF-8"?> |
| Expand Down  Expand Up | | @@ -190,6 +195,7 @@ def test\_xmliter\_namespaced\_nodename(self): |
|  |  | ["http://www.mydummycompany.com/images/item1.jpg"], |
|  |  | ) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_namespaced\_nodename\_missing(self): |
|  |  | body = b""" |
|  |  | <?xml version="1.0" encoding="UTF-8"?> |
| Expand All | | @@ -214,6 +220,7 @@ def test\_xmliter\_namespaced\_nodename\_missing(self): |
|  |  | with self.assertRaises(StopIteration): |
|  |  | next(my\_iter) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_exception(self): |
|  |  | body = ( |
|  |  | '<?xml version="1.0" encoding="UTF-8"?>' |
| Expand All | | @@ -226,10 +233,12 @@ def test\_xmliter\_exception(self): |
|  |  |  |
|  |  | self.assertRaises(StopIteration, next, iter) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_objtype\_exception(self): |
|  |  | i = self.xmliter(42, "product") |
|  |  | self.assertRaises(TypeError, next, i) |
|  |  |  |
|  |  | @pytest.mark.filterwarnings("ignore::scrapy.exceptions.ScrapyDeprecationWarning") |
|  |  | def test\_xmliter\_encoding(self): |
|  |  | body = ( |
|  |  | b'<?xml version="1.0" encoding="ISO-8859-9"?>\n' |
| Expand All | | @@ -244,12 +253,25 @@ def test\_xmliter\_encoding(self): |
|  |  | ) |
|  |  |  |
|  |  |  |
|  |  | class LxmlXmliterTestCase(XmliterTestCase): |
|  |  | xmliter = staticmethod(xmliter\_lxml) |
|  |  | class XmliterTestCase(XmliterBaseTestCase, unittest.TestCase): |
|  |  | xmliter = staticmethod(xmliter) |
|  |  |  |
|  |  | @mark.xfail(reason="known bug of the current implementation") |
|  |  | def test\_xmliter\_namespaced\_nodename(self): |
|  |  | super().test\_xmliter\_namespaced\_nodename() |
|  |  | def test\_deprecation(self): |
|  |  | body = b""" |
|  |  | <?xml version="1.0" encoding="UTF-8"?> |
|  |  | <products> |
|  |  | <product></product> |
|  |  | </products> |
|  |  | """ |
|  |  | with pytest.warns( |
|  |  | ScrapyDeprecationWarning, |
|  |  | match="xmliter", |
|  |  | ): |
|  |  | next(self.xmliter(body, "product")) |
|  |  |  |
|  |  |  |
|  |  | class LxmlXmliterTestCase(XmliterBaseTestCase, unittest.TestCase): |
|  |  | xmliter = staticmethod(xmliter\_lxml) |
|  |  |  |
|  |  | def test\_xmliter\_iterate\_namespace(self): |
|  |  | body = b""" |
| Expand Down | |  |

 Loading

Oops, something went wrong.
 Retry

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `479619b`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F479619b340f197a8f24c5db45bc068fb8755f2c5) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


