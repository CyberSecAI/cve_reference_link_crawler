
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F809bfac4890f75fc73607318a04d2ccba71b3d9f)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F809bfac4890f75fc73607318a04d2ccba71b3d9f)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=scrapy%2Fscrapy)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[scrapy](/scrapy)
/
**[scrapy](/scrapy/scrapy)**
Public

* [Notifications](/login?return_to=%2Fscrapy%2Fscrapy) You must be signed in to change notification settings
* [Fork
  10.6k](/login?return_to=%2Fscrapy%2Fscrapy)
* [Star
   53.7k](/login?return_to=%2Fscrapy%2Fscrapy)

* [Code](/scrapy/scrapy)
* [Issues
  430](/scrapy/scrapy/issues)
* [Pull requests
  182](/scrapy/scrapy/pulls)
* [Discussions](/scrapy/scrapy/discussions)
* [Actions](/scrapy/scrapy/actions)
* [Projects
  0](/scrapy/scrapy/projects)
* [Wiki](/scrapy/scrapy/wiki)
* [Security](/scrapy/scrapy/security)
* [Insights](/scrapy/scrapy/pulse)

Additional navigation options

* [Code](/scrapy/scrapy)
* [Issues](/scrapy/scrapy/issues)
* [Pull requests](/scrapy/scrapy/pulls)
* [Discussions](/scrapy/scrapy/discussions)
* [Actions](/scrapy/scrapy/actions)
* [Projects](/scrapy/scrapy/projects)
* [Wiki](/scrapy/scrapy/wiki)
* [Security](/scrapy/scrapy/security)
* [Insights](/scrapy/scrapy/pulse)

## Commit

[Permalink](/scrapy/scrapy/commit/809bfac4890f75fc73607318a04d2ccba71b3d9f)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Merge branch '2.11-compression-bomb' into 2.11

[Browse files](/scrapy/scrapy/tree/809bfac4890f75fc73607318a04d2ccba71b3d9f)
Browse the repository at this point in the history

* Loading branch information

[![@Gallaecio](https://avatars.githubusercontent.com/u/705211?s=40&v=4)](/Gallaecio)

[Gallaecio](/scrapy/scrapy/commits?author=Gallaecio "View all commits by Gallaecio")
committed
Feb 14, 2024

2 parents
[5bcb8fd](/scrapy/scrapy/commit/5bcb8fd5019c72d05c4a96da78a7fcb6ecb55b75)
+
[12b10a7](/scrapy/scrapy/commit/12b10a7a6427c43968cc18d98a3ed3c6366eeabd)

commit 809bfac

 Show file tree

 Hide file tree

Showing
**15 changed files**
with
**613 additions**
and
**226 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* docs

  + docs/news.rst
    [news.rst](#diff-87f7a7bb7fe8dbed76e16b67b87f27bda7b779b56e7d93ed3350d77ee4a3f217)
  + topics

    - docs/topics/request-response.rst
      [request-response.rst](#diff-0d6bab03b89f5dfd22931d914d3575f837073213dc42d02c22ffa0b666e4c9d2)
    - docs/topics/settings.rst
      [settings.rst](#diff-5f9194e843e87dd4403ec5a11629ed97091f01b961c61dc21929f216635d35fe)
* scrapy

  + downloadermiddlewares

    - scrapy/downloadermiddlewares/decompression.py
      [decompression.py](#diff-444f813457d268fdb216929b9523660ac6490d15edc83eb0be513cc45d74941c)
    - scrapy/downloadermiddlewares/httpcompression.py
      [httpcompression.py](#diff-aa5861c8b7f588ce86a8a40003a670b7ae7c81a1abf3d2a133e2acfbd1cd9f56)
  + spiders

    - scrapy/spiders/sitemap.py
      [sitemap.py](#diff-9150d24bdf6134ba13f81a88f5202055e9559d7f999da6d514d46810bc3c6738)
  + utils

    - scrapy/utils/\_compression.py
      [\_compression.py](#diff-9a7e8881365f9729a862521202da6987d441abc7ea7c00d65bf8322b9122a7aa)
    - scrapy/utils/gz.py
      [gz.py](#diff-d4c93b506914598ec97e88a233af3402d1a3f6a3befb1c26ae28a5dd2a752fdf)
* tests

  + sample\_data/compressed

    - tests/sample\_data/compressed/bomb-br.bin
      [bomb-br.bin](#diff-d0d736f77455afb27522cc87af0682064eba2203e308f4d051bcf4cde574a810)
    - tests/sample\_data/compressed/bomb-deflate.bin
      [bomb-deflate.bin](#diff-78cc1fd2995c6e0db8293d70b9c5bbe03a8b5704c082824839e299f5691d217d)
    - tests/sample\_data/compressed/bomb-gzip.bin
      [bomb-gzip.bin](#diff-fe0ccab537c8f5f640bbf56f1ebde3b41cffa06aa1b6add5c319115af1e3032e)
    - tests/sample\_data/compressed/bomb-zstd.bin
      [bomb-zstd.bin](#diff-43fa55d0bdd38a7a6d53b1f2028973e9a67f5c98ed8595edb4bd88d0e9c4f1b5)
  + tests/test\_downloadermiddleware\_decompression.py
    [test\_downloadermiddleware\_decompression.py](#diff-123637431245650e06efd75c5360908d6904950c25c51104b36e8ecb39936e77)
  + tests/test\_downloadermiddleware\_httpcompression.py
    [test\_downloadermiddleware\_httpcompression.py](#diff-8eae536cdcfe2f71d4c09c06994c43ded296ec923a070439c0ca457c6011e2b9)
  + tests/test\_spider.py
    [test\_spider.py](#diff-1c71b54fd4d3dfba5477740a7d0dd61ad8bc21b1a895c4144fd326d8773bf5dd)

## There are no files selected for viewing

19 changes: 19 additions & 0 deletions

19
[docs/news.rst](#diff-87f7a7bb7fe8dbed76e16b67b87f27bda7b779b56e7d93ed3350d77ee4a3f217 "docs/news.rst")

Show comments

[View file](/scrapy/scrapy/blob/809bfac4890f75fc73607318a04d2ccba71b3d9f/docs/news.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -19,6 +19,16 @@ Highlights: |
|  |  | Security bug fixes |
|  |  | ~~~~~~~~~~~~~~~~~~ |
|  |  |  |
|  |  | - :setting:`DOWNLOAD\_MAXSIZE` and :setting:`DOWNLOAD\_WARNSIZE` now also apply |
|  |  | to the decompressed response body. Please, see the `7j7m-v7m3-jqm7 security |
|  |  | advisory`\_ for more information. |
|  |  |  |
|  |  | .. \_7j7m-v7m3-jqm7 security advisory: https://github.com/scrapy/scrapy/security/advisories/GHSA-7j7m-v7m3-jqm7 |
|  |  |  |
|  |  | - Also in relation with the `7j7m-v7m3-jqm7 security advisory`\_, the |
|  |  | deprecated ``scrapy.downloadermiddlewares.decompression`` module has been |
|  |  | removed. |
|  |  |  |
|  |  | - The ``Authorization`` header is now dropped on redirects to a different |
|  |  | domain. Please, see the `cw9j-q3vf-hrrv security advisory`\_ for more |
|  |  | information. |
| Expand Down  Expand Up | | @@ -2941,13 +2951,22 @@ affect subclasses: |
|  |  |  |
|  |  | (:issue:`3884`) |
|  |  |  |
|  |  |  |
|  |  | .. \_release-1.8.4: |
|  |  |  |
|  |  | Scrapy 1.8.4 (unreleased) |
|  |  | ------------------------- |
|  |  |  |
|  |  | \*\*Security bug fixes:\*\* |
|  |  |  |
|  |  | - :setting:`DOWNLOAD\_MAXSIZE` and :setting:`DOWNLOAD\_WARNSIZE` now also apply |
|  |  | to the decompressed response body. Please, see the `7j7m-v7m3-jqm7 security |
|  |  | advisory`\_ for more information. |
|  |  |  |
|  |  | - Also in relation with the `7j7m-v7m3-jqm7 security advisory`\_, use of the |
|  |  | ``scrapy.downloadermiddlewares.decompression`` module is discouraged and |
|  |  | will trigger a warning. |
|  |  |  |
|  |  | - The ``Authorization`` header is now dropped on redirects to a different |
|  |  | domain. Please, see the `cw9j-q3vf-hrrv security advisory`\_ for more |
|  |  | information. |
| Expand Down | |  |

1 change: 1 addition & 0 deletions

1
[docs/topics/request-response.rst](#diff-0d6bab03b89f5dfd22931d914d3575f837073213dc42d02c22ffa0b666e4c9d2 "docs/topics/request-response.rst")

Show comments

[View file](/scrapy/scrapy/blob/809bfac4890f75fc73607318a04d2ccba71b3d9f/docs/topics/request-response.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -731,6 +731,7 @@ Those are: |
|  |  | \* :reqmeta:`download\_fail\_on\_dataloss` |
|  |  | \* :reqmeta:`download\_latency` |
|  |  | \* :reqmeta:`download\_maxsize` |
|  |  | \* :reqmeta:`download\_warnsize` |
|  |  | \* :reqmeta:`download\_timeout` |
|  |  | \* ``ftp\_password`` (See :setting:`FTP\_PASSWORD` for more info) |
|  |  | \* ``ftp\_user`` (See :setting:`FTP\_USER` for more info) |
| Expand Down | |  |

36 changes: 19 additions & 17 deletions

36
[docs/topics/settings.rst](#diff-5f9194e843e87dd4403ec5a11629ed97091f01b961c61dc21929f216635d35fe "docs/topics/settings.rst")

Show comments

[View file](/scrapy/scrapy/blob/809bfac4890f75fc73607318a04d2ccba71b3d9f/docs/topics/settings.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -873,40 +873,42 @@ The amount of time (in secs) that the downloader will wait before timing out. |
|  |  | Request.meta key. |
|  |  |  |
|  |  | .. setting:: DOWNLOAD\_MAXSIZE |
|  |  | .. reqmeta:: download\_maxsize |
|  |  |  |
|  |  | DOWNLOAD\_MAXSIZE |
|  |  | ---------------- |
|  |  |  |
|  |  | Default: ``1073741824`` (1024MB) |
|  |  |  |
|  |  | The maximum response size (in bytes) that downloader will download. |
|  |  | Default: ``1073741824`` (1 GiB) |
|  |  |  |
|  |  | If you want to disable it set to 0. |
|  |  | The maximum response body size (in bytes) allowed. Bigger responses are |
|  |  | aborted and ignored. |
|  |  |  |
|  |  | .. reqmeta:: download\_maxsize |
|  |  | This applies both before and after compression. If decompressing a response |
|  |  | body would exceed this limit, decompression is aborted and the response is |
|  |  | ignored. |
|  |  |  |
|  |  | .. note:: |
|  |  | Use ``0`` to disable this limit. |
|  |  |  |
|  |  | This size can be set per spider using :attr:`download\_maxsize` |
|  |  | spider attribute and per-request using :reqmeta:`download\_maxsize` |
|  |  | Request.meta key. |
|  |  | This limit can be set per spider using the :attr:`download\_maxsize` spider |
|  |  | attribute and per request using the :reqmeta:`download\_maxsize` Request.meta |
|  |  | key. |
|  |  |  |
|  |  | .. setting:: DOWNLOAD\_WARNSIZE |
|  |  | .. reqmeta:: download\_warnsize |
|  |  |  |
|  |  | DOWNLOAD\_WARNSIZE |
|  |  | ----------------- |
|  |  |  |
|  |  | Default: ``33554432`` (32MB) |
|  |  |  |
|  |  | The response size (in bytes) that downloader will start to warn. |
|  |  | Default: ``33554432`` (32 MiB) |
|  |  |  |
|  |  | If you want to disable it set to 0. |
|  |  | If the size of a response exceeds this value, before or after compression, a |
|  |  | warning will be logged about it. |
|  |  |  |
|  |  | .. note:: |
|  |  | Use ``0`` to disable this limit. |
|  |  |  |
|  |  | This size can be set per spider using :attr:`download\_warnsize` |
|  |  | spider attribute and per-request using :reqmeta:`download\_warnsize` |
|  |  | Request.meta key. |
|  |  | This limit can be set per spider using the :attr:`download\_warnsize` spider |
|  |  | attribute and per request using the :reqmeta:`download\_warnsize` Request.meta |
|  |  | key. |
|  |  |  |
|  |  | .. setting:: DOWNLOAD\_FAIL\_ON\_DATALOSS |
|  |  |  |
| Expand Down | |  |

94 changes: 0 additions & 94 deletions

94
[scrapy/downloadermiddlewares/decompression.py](#diff-444f813457d268fdb216929b9523660ac6490d15edc83eb0be513cc45d74941c "scrapy/downloadermiddlewares/decompression.py")

Show comments

[View file](/scrapy/scrapy/blob/5bcb8fd5019c72d05c4a96da78a7fcb6ecb55b75/scrapy/downloadermiddlewares/decompression.py)
Edit file

Delete file

Load diff

This file was deleted.

Oops, something went wrong.

Retry

100 changes: 65 additions & 35 deletions

100
[scrapy/downloadermiddlewares/httpcompression.py](#diff-aa5861c8b7f588ce86a8a40003a670b7ae7c81a1abf3d2a133e2acfbd1cd9f56 "scrapy/downloadermiddlewares/httpcompression.py")

Show comments

[View file](/scrapy/scrapy/blob/809bfac4890f75fc73607318a04d2ccba71b3d9f/scrapy/downloadermiddlewares/httpcompression.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
|  |  | @@ -1,53 +1,78 @@ |
|  |  | import io |
|  |  | import warnings |
|  |  | import zlib |
|  |  | from logging import getLogger |
|  |  |  |
|  |  | from scrapy.exceptions import NotConfigured |
|  |  | from scrapy import signals |
|  |  | from scrapy.exceptions import IgnoreRequest, NotConfigured |
|  |  | from scrapy.http import Response, TextResponse |
|  |  | from scrapy.responsetypes import responsetypes |
|  |  | from scrapy.utils.\_compression import ( |
|  |  | \_DecompressionMaxSizeExceeded, |
|  |  | \_inflate, |
|  |  | \_unbrotli, |
|  |  | \_unzstd, |
|  |  | ) |
|  |  | from scrapy.utils.deprecate import ScrapyDeprecationWarning |
|  |  | from scrapy.utils.gz import gunzip |
|  |  |  |
|  |  | logger = getLogger(\_\_name\_\_) |
|  |  |  |
|  |  | ACCEPTED\_ENCODINGS = [b"gzip", b"deflate"] |
|  |  |  |
|  |  | try: |
|  |  | import brotli |
|  |  |  |
|  |  | ACCEPTED\_ENCODINGS.append(b"br") |
|  |  | import brotli # noqa: F401 |
|  |  | except ImportError: |
|  |  | pass |
|  |  | else: |
|  |  | ACCEPTED\_ENCODINGS.append(b"br") |
|  |  |  |
|  |  | try: |
|  |  | import zstandard |
|  |  |  |
|  |  | ACCEPTED\_ENCODINGS.append(b"zstd") |
|  |  | import zstandard # noqa: F401 |
|  |  | except ImportError: |
|  |  | pass |
|  |  | else: |
|  |  | ACCEPTED\_ENCODINGS.append(b"zstd") |
|  |  |  |
|  |  |  |
|  |  | class HttpCompressionMiddleware: |
|  |  | """This middleware allows compressed (gzip, deflate) traffic to be |
|  |  | sent/received from web sites""" |
|  |  |  |
|  |  | def \_\_init\_\_(self, stats=None): |
|  |  | self.stats = stats |
|  |  | def \_\_init\_\_(self, stats=None, \*, crawler=None): |
|  |  | if not crawler: |
|  |  | self.stats = stats |
|  |  | self.\_max\_size = 1073741824 |
|  |  | self.\_warn\_size = 33554432 |
|  |  | return |
|  |  | self.stats = crawler.stats |
|  |  | self.\_max\_size = crawler.settings.getint("DOWNLOAD\_MAXSIZE") |
|  |  | self.\_warn\_size = crawler.settings.getint("DOWNLOAD\_WARNSIZE") |
|  |  | crawler.signals.connect(self.open\_spider, signals.spider\_opened) |
|  |  |  |
|  |  | @classmethod |
|  |  | def from\_crawler(cls, crawler): |
|  |  | if not crawler.settings.getbool("COMPRESSION\_ENABLED"): |
|  |  | raise NotConfigured |
|  |  | try: |
|  |  | return cls(stats=crawler.stats) |
|  |  | return cls(crawler=crawler) |
|  |  | except TypeError: |
|  |  | warnings.warn( |
|  |  | "HttpCompressionMiddleware subclasses must either modify " |
|  |  | "their '\_\_init\_\_' method to support a 'stats' parameter or " |
|  |  | "reimplement the 'from\_crawler' method.", |
|  |  | "their '\_\_init\_\_' method to support a 'crawler' parameter or " |
|  |  | "reimplement their 'from\_crawler' method.", |
|  |  | ScrapyDeprecationWarning, |
|  |  | ) |
|  |  | result = cls() |
|  |  | result.stats = crawler.stats |
|  |  | return result |
|  |  | mw = cls() |
|  |  | mw.stats = crawler.stats |
|  |  | mw.\_max\_size = crawler.settings.getint("DOWNLOAD\_MAXSIZE") |
|  |  | mw.\_warn\_size = crawler.settings.getint("DOWNLOAD\_WARNSIZE") |
|  |  | crawler.signals.connect(mw.open\_spider, signals.spider\_opened) |
|  |  | return mw |
|  |  |  |
|  |  | def open\_spider(self, spider): |
|  |  | if hasattr(spider, "download\_maxsize"): |
|  |  | self.\_max\_size = spider.download\_maxsize |
|  |  | if hasattr(spider, "download\_warnsize"): |
|  |  | self.\_warn\_size = spider.download\_warnsize |
|  |  |  |
|  |  | def process\_request(self, request, spider): |
|  |  | request.headers.setdefault("Accept-Encoding", b", ".join(ACCEPTED\_ENCODINGS)) |
| Expand All | | @@ -59,7 +84,24 @@ def process\_response(self, request, response, spider): |
|  |  | content\_encoding = response.headers.getlist("Content-Encoding") |
|  |  | if content\_encoding: |
|  |  | encoding = content\_encoding.pop() |
|  |  | decoded\_body = self.\_decode(response.body, encoding.lower()) |
|  |  | max\_size = request.meta.get("download\_maxsize", self.\_max\_size) |
|  |  | warn\_size = request.meta.get("download\_warnsize", self.\_warn\_size) |
|  |  | try: |
|  |  | decoded\_body = self.\_decode( |
|  |  | response.body, encoding.lower(), max\_size |
|  |  | ) |
|  |  | except \_DecompressionMaxSizeExceeded: |
|  |  | raise IgnoreRequest( |
|  |  | f"Ignored response {response} because its body " |
|  |  | f"({len(response.body)} B) exceeded DOWNLOAD\_MAXSIZE " |
|  |  | f"({max\_size} B) during decompression." |
|  |  | ) |
|  |  | if len(response.body) < warn\_size <= len(decoded\_body): |
|  |  | logger.warning( |
|  |  | f"{response} body size after decompression " |
|  |  | f"({len(decoded\_body)} B) is larger than the " |
|  |  | f"download warning size ({warn\_size} B)." |
|  |  | ) |
|  |  | if self.stats: |
|  |  | self.stats.inc\_value( |
|  |  | "httpcompression/response\_bytes", |
| Expand All | | @@ -83,25 +125,13 @@ def process\_response(self, request, response, spider): |
|  |  |  |
|  |  | return response |
|  |  |  |
|  |  | def \_decode(self, body, encoding): |
|  |  | def \_decode(self, body, encoding, max\_size): |
|  |  | if encoding == b"gzip" or encoding == b"x-gzip": |
|  |  | body = gunzip(body) |
|  |  |  |
|  |  | return gunzip(body, max\_size=max\_size) |
|  |  | if encoding == b"deflate": |
|  |  | try: |
|  |  | body = zlib.decompress(body) |
|  |  | except zlib.error: |
|  |  | # ugly hack to work with raw deflate content that may |
|  |  | # be sent by microsoft servers. For more information, see: |
|  |  | # http://carsten.codimi.de/gzip.yaws/ |
|  |  | # http://www.port80software.com/200ok/archive/2005/10/31/868.aspx |
|  |  | # http://www.gzip.org/zlib/zlib\_faq.html#faq38 |
|  |  | body = zlib.decompress(body, -15) |
|  |  | return \_inflate(body, max\_size=max\_size) |
|  |  | if encoding == b"br" and b"br" in ACCEPTED\_ENCODINGS: |
|  |  | body = brotli.decompress(body) |
|  |  | return \_unbrotli(body, max\_size=max\_size) |
|  |  | if encoding == b"zstd" and b"zstd" in ACCEPTED\_ENCODINGS: |
|  |  | # Using its streaming API since its simple API could handle only cases |
|  |  | # where there is content size data embedded in the frame |
|  |  | reader = zstandard.ZstdDecompressor().stream\_reader(io.BytesIO(body)) |
|  |  | body = reader.read() |
|  |  | return \_unzstd(body, max\_size=max\_size) |
|  |  | return body |

 Loading

Oops, something went wrong.
 Retry

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `809bfac`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F809bfac4890f75fc73607318a04d2ccba71b3d9f) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

