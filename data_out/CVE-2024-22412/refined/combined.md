=== Content from github.com_40e5c772_20250111_031537.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fblob%2Fbd17ee769e337906c4b1f404861e042ad72fcbfc%2Fsrc%2FInterpreters%2FexecuteQuery.cpp)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fblob%2Fbd17ee769e337906c4b1f404861e042ad72fcbfc%2Fsrc%2FInterpreters%2FexecuteQuery.cpp)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=ClickHouse%2FClickHouse)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[ClickHouse](/ClickHouse)
/
**[ClickHouse](/ClickHouse/ClickHouse)**
Public

* [Notifications](/login?return_to=%2FClickHouse%2FClickHouse) You must be signed in to change notification settings
* [Fork
  7k](/login?return_to=%2FClickHouse%2FClickHouse)
* [Star
   38.4k](/login?return_to=%2FClickHouse%2FClickHouse)

* [Code](/ClickHouse/ClickHouse)
* [Issues
  3.7k](/ClickHouse/ClickHouse/issues)
* [Pull requests
  398](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects
  0](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

Additional navigation options

* [Code](/ClickHouse/ClickHouse)
* [Issues](/ClickHouse/ClickHouse/issues)
* [Pull requests](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

## Files

 bd17ee7
## Breadcrumbs

1. [ClickHouse](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc)
2. /[src](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src)
3. /[Interpreters](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters)
/
# executeQuery.cpp

Copy path Blame  Blame
## Latest commit

## History

[History](/ClickHouse/ClickHouse/commits/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp)1538 lines (1307 loc) · 63.9 KB bd17ee7
## Breadcrumbs

1. [ClickHouse](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc)
2. /[src](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src)
3. /[Interpreters](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters)
/
# executeQuery.cpp

Top
## File metadata and controls

* Code
* Blame

1538 lines (1307 loc) · 63.9 KB[Raw](https://github.com/ClickHouse/ClickHouse/raw/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000#include <Common/formatReadable.h>#include <Common/PODArray.h>#include <Common/typeid\_cast.h>#include <Common/ThreadProfileEvents.h>#include <Common/MemoryTrackerBlockerInThread.h>#include <Common/SensitiveDataMasker.h>
#include <Interpreters/AsynchronousInsertQueue.h>#include <Interpreters/Cache/QueryCache.h>#include <IO/WriteBufferFromFile.h>#include <IO/WriteBufferFromVector.h>#include <IO/LimitReadBuffer.h>#include <IO/copyData.h>
#include <QueryPipeline/BlockIO.h>#include <Processors/Transforms/CountingTransform.h>#include <Processors/Transforms/getSourceFromASTInsertQuery.h>
#include <Parsers/ASTIdentifier.h>#include <Parsers/ASTInsertQuery.h>#include <Parsers/ASTLiteral.h>#include <Parsers/ASTSelectQuery.h>#include <Parsers/ASTDropQuery.h>#include <Parsers/ASTCreateQuery.h>#include <Parsers/ASTRenameQuery.h>#include <Parsers/ASTAlterQuery.h>#include <Parsers/ASTSelectWithUnionQuery.h>#include <Parsers/ASTShowProcesslistQuery.h>#include <Parsers/ASTWatchQuery.h>#include <Parsers/ASTTransactionControl.h>#include <Parsers/ASTExplainQuery.h>#include <Parsers/Lexer.h>#include <Parsers/parseQuery.h>#include <Parsers/ParserQuery.h>#include <Parsers/queryNormalization.h>#include <Parsers/queryToString.h>#include <Parsers/formatAST.h>#include <Parsers/toOneLineQuery.h>#include <Parsers/Kusto/ParserKQLStatement.h>#include <Parsers/PRQL/ParserPRQLQuery.h>#include <Parsers/Kusto/parseKQLQuery.h>
#include <Formats/FormatFactory.h>#include <Storages/StorageInput.h>
#include <Access/EnabledQuota.h>#include <Interpreters/ApplyWithGlobalVisitor.h>#include <Interpreters/Context.h>#include <Interpreters/InterpreterFactory.h>#include <Interpreters/InterpreterInsertQuery.h>#include <Interpreters/InterpreterCreateQuery.h>#include <Interpreters/InterpreterSelectQueryAnalyzer.h>#include <Interpreters/InterpreterSetQuery.h>#include <Interpreters/InterpreterTransactionControlQuery.h>#include <Interpreters/NormalizeSelectWithUnionQueryVisitor.h>#include <Interpreters/OpenTelemetrySpanLog.h>#include <Interpreters/ProcessList.h>#include <Interpreters/ProcessorsProfileLog.h>#include <Interpreters/QueryLog.h>#include <Interpreters/ReplaceQueryParameterVisitor.h>#include <Interpreters/SelectIntersectExceptQueryVisitor.h>#include <Interpreters/SelectQueryOptions.h>#include <Interpreters/TransactionLog.h>#include <Interpreters/executeQuery.h>#include <Interpreters/DatabaseCatalog.h>#include <Common/ProfileEvents.h>
#include <IO/CompressionMethod.h>
#include <Processors/Transforms/LimitsCheckingTransform.h>#include <Processors/Transforms/MaterializingTransform.h>#include <Processors/Formats/IOutputFormat.h>#include <Processors/Executors/CompletedPipelineExecutor.h>#include <Processors/Sources/WaitForAsyncInsertSource.h>
#include <base/EnumReflection.h>#include <base/demangle.h>
#include <memory>#include <random>
namespace ProfileEvents{ extern const Event FailedQuery; extern const Event FailedInsertQuery; extern const Event FailedSelectQuery; extern const Event QueryTimeMicroseconds; extern const Event SelectQueryTimeMicroseconds; extern const Event InsertQueryTimeMicroseconds; extern const Event OtherQueryTimeMicroseconds;}
namespace DB{
namespace ErrorCodes{ extern const int QUERY\_CACHE\_USED\_WITH\_NONDETERMINISTIC\_FUNCTIONS; extern const int INTO\_OUTFILE\_NOT\_ALLOWED; extern const int INVALID\_TRANSACTION; extern const int LOGICAL\_ERROR; extern const int NOT\_IMPLEMENTED; extern const int QUERY\_WAS\_CANCELLED; extern const int INCORRECT\_DATA;}
static void checkASTSizeLimits(const IAST & ast, const Settings & settings){ if (settings.max\_ast\_depth) ast.checkDepth(settings.max\_ast\_depth); if (settings.max\_ast\_elements) ast.checkSize(settings.max\_ast\_elements);}
/// Log query into text log (not into system table).static void logQuery(const String & query, ContextPtr context, bool internal, QueryProcessingStage::Enum stage){ if (internal) { LOG\_DEBUG(&Poco::Logger::get("executeQuery"), "(internal) {} (stage: {})", toOneLineQuery(query), QueryProcessingStage::toString(stage)); } else { const auto & client\_info = context->getClientInfo();
 const auto & current\_query\_id = client\_info.current\_query\_id; const auto & initial\_query\_id = client\_info.initial\_query\_id; const auto & current\_user = client\_info.current\_user;
 String comment = context->getSettingsRef().log\_comment; size\_t max\_query\_size = context->getSettingsRef().max\_query\_size;
 if (comment.size() > max\_query\_size) comment.resize(max\_query\_size);
 if (!comment.empty()) comment = fmt::format(" (comment: {})", comment);
 String transaction\_info; if (auto txn = context->getCurrentTransaction()) transaction\_info = fmt::format(" (TID: {}, TIDH: {})", txn->tid, txn->tid.getHash());
 LOG\_DEBUG(&Poco::Logger::get("executeQuery"), "(from {}{}{}){}{} {} (stage: {})", client\_info.current\_address.toString(), (current\_user != "default" ? ", user: " + current\_user : ""), (!initial\_query\_id.empty() && current\_query\_id != initial\_query\_id ? ", initial\_query\_id: " + initial\_query\_id : std::string()), transaction\_info, comment, toOneLineQuery(query), QueryProcessingStage::toString(stage));
 if (client\_info.client\_trace\_context.trace\_id != UUID()) { LOG\_TRACE(&Poco::Logger::get("executeQuery"), "OpenTelemetry traceparent '{}'", client\_info.client\_trace\_context.composeTraceparentHeader()); } }}
/// Call this inside catch block.static void setExceptionStackTrace(QueryLogElement & elem){ /// Disable memory tracker for stack trace. /// Because if exception is "Memory limit (for query) exceed", then we probably can't allocate another one string.
 LockMemoryExceptionInThread lock(VariableContext::Global);
 try { throw; } catch (const std::exception & e) { elem.stack\_trace = getExceptionStackTraceString(e); } catch (...) {} // NOLINT(bugprone-empty-catch)}
/// Log exception (with query info) into text log (not into system table).static void logException(ContextPtr context, QueryLogElement & elem, bool log\_error = true){ String comment; if (!elem.log\_comment.empty()) comment = fmt::format(" (comment: {})", elem.log\_comment);
 /// Message patterns like "{} (from {}){} (in query: {})" are not really informative, /// so we pass elem.exception\_format\_string as format string instead. PreformattedMessage message; message.format\_string = elem.exception\_format\_string;
 if (elem.stack\_trace.empty() || !log\_error) message.text = fmt::format("{} (from {}){} (in query: {})", elem.exception, context->getClientInfo().current\_address.toString(), comment, toOneLineQuery(elem.query)); else message.text = fmt::format( "{} (from {}){} (in query: {}), Stack trace (when copying this message, always include the lines below):\n\n{}", elem.exception, context->getClientInfo().current\_address.toString(), comment, toOneLineQuery(elem.query), elem.stack\_trace);
 if (log\_error) LOG\_ERROR(&Poco::Logger::get("executeQuery"), message); else LOG\_INFO(&Poco::Logger::get("executeQuery"), message);}
static voidaddStatusInfoToQueryLogElement(QueryLogElement & element, const QueryStatusInfo & info, const ASTPtr query\_ast, const ContextPtr context\_ptr){ const auto time\_now = std::chrono::system\_clock::now(); UInt64 elapsed\_microseconds = info.elapsed\_microseconds; element.event\_time = timeInSeconds(time\_now); element.event\_time\_microseconds = timeInMicroseconds(time\_now); element.query\_duration\_ms = elapsed\_microseconds / 1000;
 ProfileEvents::increment(ProfileEvents::QueryTimeMicroseconds, elapsed\_microseconds); if (query\_ast->as<ASTSelectQuery>() || query\_ast->as<ASTSelectWithUnionQuery>()) { ProfileEvents::increment(ProfileEvents::SelectQueryTimeMicroseconds, elapsed\_microseconds); } else if (query\_ast->as<ASTInsertQuery>()) { ProfileEvents::increment(ProfileEvents::InsertQueryTimeMicroseconds, elapsed\_microseconds); } else { ProfileEvents::increment(ProfileEvents::OtherQueryTimeMicroseconds, elapsed\_microseconds); }
 element.read\_rows = info.read\_rows; element.read\_bytes = info.read\_bytes;
 element.written\_rows = info.written\_rows; element.written\_bytes = info.written\_bytes;
 element.memory\_usage = info.peak\_memory\_usage > 0 ? info.peak\_memory\_usage : 0;
 element.thread\_ids = info.thread\_ids; element.peak\_threads\_usage = info.peak\_threads\_usage; element.profile\_counters = info.profile\_counters;
 /// We need to refresh the access info since dependent views might have added extra information, either during /// creation of the view (PushingToViews chain) or while executing its internal SELECT const auto & access\_info = context\_ptr->getQueryAccessInfo(); element.query\_databases.insert(access\_info.databases.begin(), access\_info.databases.end()); element.query\_tables.insert(access\_info.tables.begin(), access\_info.tables.end()); element.query\_columns.insert(access\_info.columns.begin(), access\_info.columns.end()); element.query\_partitions.insert(access\_info.partitions.begin(), access\_info.partitions.end()); element.query\_projections.insert(access\_info.projections.begin(), access\_info.projections.end()); element.query\_views.insert(access\_info.views.begin(), access\_info.views.end());
 const auto & factories\_info = context\_ptr->getQueryFactoriesInfo(); element.used\_aggregate\_functions = factories\_info.aggregate\_functions; element.used\_aggregate\_function\_combinators = factories\_info.aggregate\_function\_combinators; element.used\_database\_engines = factories\_info.database\_engines; element.used\_data\_type\_families = factories\_info.data\_type\_families; element.used\_dictionaries = factories\_info.dictionaries; element.used\_formats = factories\_info.formats; element.used\_functions = factories\_info.functions; element.used\_storages = factories\_info.storages; element.used\_table\_functions = factories\_info.table\_functions;
 element.async\_read\_counters = context\_ptr->getAsyncReadCounters();}
QueryLogElement logQueryStart( const std::chrono::time\_point<std::chrono::system\_clock> & query\_start\_time, const ContextMutablePtr & context, const String & query\_for\_logging, const ASTPtr & query\_ast, const QueryPipeline & pipeline, const std::unique\_ptr<IInterpreter> & interpreter, bool internal, const String & query\_database, const String & query\_table, bool async\_insert){ const Settings & settings = context->getSettingsRef();
 QueryLogElement elem;
 elem.type = QueryLogElementType::QUERY\_START; elem.event\_time = timeInSeconds(query\_start\_time); elem.event\_time\_microseconds = timeInMicroseconds(query\_start\_time); elem.query\_start\_time = timeInSeconds(query\_start\_time); elem.query\_start\_time\_microseconds = timeInMicroseconds(query\_start\_time);
 elem.current\_database = context->getCurrentDatabase(); elem.query = query\_for\_logging; if (settings.log\_formatted\_queries) elem.formatted\_query = queryToString(query\_ast); elem.normalized\_query\_hash = normalizedQueryHash(query\_for\_logging, false); elem.query\_kind = query\_ast->getQueryKind();
 elem.client\_info = context->getClientInfo();
 if (auto txn = context->getCurrentTransaction()) elem.tid = txn->tid;
 bool log\_queries = settings.log\_queries && !internal;
 /// Log into system table start of query execution, if need. if (log\_queries) { /// This check is not obvious, but without it 01220\_scalar\_optimization\_in\_alter fails. if (pipeline.initialized()) { const auto & info = context->getQueryAccessInfo(); elem.query\_databases = info.databases; elem.query\_tables = info.tables; elem.query\_columns = info.columns; elem.query\_partitions = info.partitions; elem.query\_projections = info.projections; elem.query\_views = info.views; }
 if (async\_insert) InterpreterInsertQuery::extendQueryLogElemImpl(elem, context); else if (interpreter) interpreter->extendQueryLogElem(elem, query\_ast, context, query\_database, query\_table);
 if (settings.log\_query\_settings) elem.query\_settings = std::make\_shared<Settings>(context->getSettingsRef());
 elem.log\_comment = settings.log\_comment; if (elem.log\_comment.size() > settings.max\_query\_size) elem.log\_comment.resize(settings.max\_query\_size);
 if (elem.type >= settings.log\_queries\_min\_type && !settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds()) { if (auto query\_log = context->getQueryLog()) query\_log->add(elem); } }
 return elem;}
void logQueryFinish( QueryLogElement & elem, const ContextMutablePtr & context, const ASTPtr & query\_ast, const QueryPipeline & query\_pipeline, bool pulling\_pipeline, std::shared\_ptr<OpenTelemetry::SpanHolder> query\_span, QueryCache::Usage query\_cache\_usage, bool internal){ const Settings & settings = context->getSettingsRef(); auto log\_queries = settings.log\_queries && !internal; auto log\_queries\_min\_type = settings.log\_queries\_min\_type; auto log\_queries\_min\_query\_duration\_ms = settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds(); auto log\_processors\_profiles = settings.log\_processors\_profiles;
 QueryStatusPtr process\_list\_elem = context->getProcessListElement(); if (process\_list\_elem) { /// Update performance counters before logging to query\_log CurrentThread::finalizePerformanceCounters();
 QueryStatusInfo info = process\_list\_elem->getInfo(true, context->getSettingsRef().log\_profile\_events); elem.type = QueryLogElementType::QUERY\_FINISH;
 addStatusInfoToQueryLogElement(elem, info, query\_ast, context);
 if (pulling\_pipeline) { query\_pipeline.tryGetResultRowsAndBytes(elem.result\_rows, elem.result\_bytes); } else /// will be used only for ordinary INSERT queries { auto progress\_out = process\_list\_elem->getProgressOut(); elem.result\_rows = progress\_out.written\_rows; elem.result\_bytes = progress\_out.written\_bytes; }
 auto progress\_callback = context->getProgressCallback(); if (progress\_callback) { Progress p; p.incrementPiecewiseAtomically(Progress{ResultProgress{elem.result\_rows, elem.result\_bytes}}); progress\_callback(p); }
 if (elem.read\_rows != 0) { double elapsed\_seconds = static\_cast<double>(info.elapsed\_microseconds) / 1000000.0; double rows\_per\_second = static\_cast<double>(elem.read\_rows) / elapsed\_seconds; LOG\_DEBUG( &Poco::Logger::get("executeQuery"), "Read {} rows, {} in {} sec., {} rows/sec., {}/sec.", elem.read\_rows, ReadableSize(elem.read\_bytes), elapsed\_seconds, rows\_per\_second, ReadableSize(elem.read\_bytes / elapsed\_seconds)); }
 elem.query\_cache\_usage = query\_cache\_usage;
 if (log\_queries && elem.type >= log\_queries\_min\_type && static\_cast<Int64>(elem.query\_duration\_ms) >= log\_queries\_min\_query\_duration\_ms) { if (auto query\_log = context->getQueryLog()) query\_log->add(elem); } if (log\_processors\_profiles) { if (auto processors\_profile\_log = context->getProcessorsProfileLog()) { ProcessorProfileLogElement processor\_elem; processor\_elem.event\_time = elem.event\_time; processor\_elem.event\_time\_microseconds = elem.event\_time\_microseconds; processor\_elem.initial\_query\_id = elem.client\_info.initial\_query\_id; processor\_elem.query\_id = elem.client\_info.current\_query\_id;
 auto get\_proc\_id = [](const IProcessor & proc) -> UInt64 { return reinterpret\_cast<std::uintptr\_t>(&proc); };
 for (const auto & processor : query\_pipeline.getProcessors()) { std::vector<UInt64> parents; for (const auto & port : processor->getOutputs()) { if (!port.isConnected()) continue; const IProcessor & next = port.getInputPort().getProcessor(); parents.push\_back(get\_proc\_id(next)); }
 processor\_elem.id = get\_proc\_id(\*processor); processor\_elem.parent\_ids = std::move(parents);
 processor\_elem.plan\_step = reinterpret\_cast<std::uintptr\_t>(processor->getQueryPlanStep()); processor\_elem.plan\_group = processor->getQueryPlanStepGroup();
 processor\_elem.processor\_name = processor->getName();
 /// NOTE: convert this to UInt64 processor\_elem.elapsed\_us = static\_cast<UInt32>(processor->getElapsedUs()); processor\_elem.input\_wait\_elapsed\_us = static\_cast<UInt32>(processor->getInputWaitElapsedUs()); processor\_elem.output\_wait\_elapsed\_us = static\_cast<UInt32>(processor->getOutputWaitElapsedUs());
 auto stats = processor->getProcessorDataStats(); processor\_elem.input\_rows = stats.input\_rows; processor\_elem.input\_bytes = stats.input\_bytes; processor\_elem.output\_rows = stats.output\_rows; processor\_elem.output\_bytes = stats.output\_bytes;
 processors\_profile\_log->add(processor\_elem); } } } }
 if (query\_span) { query\_span->addAttribute("db.statement", elem.query); query\_span->addAttribute("clickhouse.query\_id", elem.client\_info.current\_query\_id); query\_span->addAttribute("clickhouse.query\_status", "QueryFinish"); query\_span->addAttributeIfNotEmpty("clickhouse.tracestate", OpenTelemetry::CurrentContext().tracestate); query\_span->addAttributeIfNotZero("clickhouse.read\_rows", elem.read\_rows); query\_span->addAttributeIfNotZero("clickhouse.read\_bytes", elem.read\_bytes); query\_span->addAttributeIfNotZero("clickhouse.written\_rows", elem.written\_rows); query\_span->addAttributeIfNotZero("clickhouse.written\_bytes", elem.written\_bytes); query\_span->addAttributeIfNotZero("clickhouse.memory\_usage", elem.memory\_usage); query\_span->finish(); }}
void logQueryException( QueryLogElement & elem, const ContextMutablePtr & context, const Stopwatch & start\_watch, const ASTPtr & query\_ast, std::shared\_ptr<OpenTelemetry::SpanHolder> query\_span, bool internal, bool log\_error){ const Settings & settings = context->getSettingsRef(); auto log\_queries = settings.log\_queries && !internal; auto log\_queries\_min\_type = settings.log\_queries\_min\_type; auto log\_queries\_min\_query\_duration\_ms = settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds();
 elem.type = QueryLogElementType::EXCEPTION\_WHILE\_PROCESSING; elem.exception\_code = getCurrentExceptionCode(); auto exception\_message = getCurrentExceptionMessageAndPattern(/\* with\_stacktrace \*/ false); elem.exception = std::move(exception\_message.text); elem.exception\_format\_string = exception\_message.format\_string;
 QueryStatusPtr process\_list\_elem = context->getProcessListElement();
 /// Update performance counters before logging to query\_log CurrentThread::finalizePerformanceCounters(); const auto time\_now = std::chrono::system\_clock::now(); elem.event\_time = timeInSeconds(time\_now); elem.event\_time\_microseconds = timeInMicroseconds(time\_now);
 if (process\_list\_elem) { QueryStatusInfo info = process\_list\_elem->getInfo(true, settings.log\_profile\_events, false); addStatusInfoToQueryLogElement(elem, info, query\_ast, context); } else { elem.query\_duration\_ms = start\_watch.elapsedMilliseconds(); }
 elem.query\_cache\_usage = QueryCache::Usage::None;
 if (settings.calculate\_text\_stack\_trace && log\_error) setExceptionStackTrace(elem); logException(context, elem, log\_error);
 /// In case of exception we log internal queries also if (log\_queries && elem.type >= log\_queries\_min\_type && static\_cast<Int64>(elem.query\_duration\_ms) >= log\_queries\_min\_query\_duration\_ms) { if (auto query\_log = context->getQueryLog()) query\_log->add(elem); }
 ProfileEvents::increment(ProfileEvents::FailedQuery); if (query\_ast->as<ASTSelectQuery>() || query\_ast->as<ASTSelectWithUnionQuery>()) ProfileEvents::increment(ProfileEvents::FailedSelectQuery); else if (query\_ast->as<ASTInsertQuery>()) ProfileEvents::increment(ProfileEvents::FailedInsertQuery);
 if (query\_span) { query\_span->addAttribute("db.statement", elem.query); query\_span->addAttribute("clickhouse.query\_id", elem.client\_info.current\_query\_id); query\_span->addAttribute("clickhouse.exception", elem.exception); query\_span->addAttribute("clickhouse.exception\_code", elem.exception\_code); query\_span->finish(); }}
void logExceptionBeforeStart( const String & query\_for\_logging, ContextPtr context, ASTPtr ast, const std::shared\_ptr<OpenTelemetry::SpanHolder> & query\_span, UInt64 elapsed\_millliseconds){ auto query\_end\_time = std::chrono::system\_clock::now();
 /// Exception before the query execution. if (auto quota = context->getQuota()) quota->used(QuotaType::ERRORS, 1, /\* check\_exceeded = \*/ false);
 const Settings & settings = context->getSettingsRef();
 const auto & client\_info = context->getClientInfo();
 /// Log the start of query execution into the table if necessary. QueryLogElement elem;
 elem.type = QueryLogElementType::EXCEPTION\_BEFORE\_START; elem.event\_time = timeInSeconds(query\_end\_time); elem.event\_time\_microseconds = timeInMicroseconds(query\_end\_time); elem.query\_start\_time = client\_info.initial\_query\_start\_time; elem.query\_start\_time\_microseconds = client\_info.initial\_query\_start\_time\_microseconds; elem.query\_duration\_ms = elapsed\_millliseconds;
 elem.current\_database = context->getCurrentDatabase(); elem.query = query\_for\_logging; elem.normalized\_query\_hash = normalizedQueryHash(query\_for\_logging, false);
 // Log query\_kind if ast is valid if (ast) { elem.query\_kind = ast->getQueryKind(); if (settings.log\_formatted\_queries) elem.formatted\_query = queryToString(ast); }
 // We don't calculate databases, tables and columns when the query isn't able to start
 elem.exception\_code = getCurrentExceptionCode(); auto exception\_message = getCurrentExceptionMessageAndPattern(/\* with\_stacktrace \*/ false); elem.exception = std::move(exception\_message.text); elem.exception\_format\_string = exception\_message.format\_string;
 elem.client\_info = context->getClientInfo();
 elem.log\_comment = settings.log\_comment; if (elem.log\_comment.size() > settings.max\_query\_size) elem.log\_comment.resize(settings.max\_query\_size);
 if (auto txn = context->getCurrentTransaction()) elem.tid = txn->tid;
 if (settings.calculate\_text\_stack\_trace) setExceptionStackTrace(elem); logException(context, elem);
 /// Update performance counters before logging to query\_log CurrentThread::finalizePerformanceCounters();
 if (settings.log\_queries && elem.type >= settings.log\_queries\_min\_type && !settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds()) if (auto query\_log = context->getQueryLog()) query\_log->add(elem);
 if (query\_span) { query\_span->addAttribute("clickhouse.exception\_code", elem.exception\_code); query\_span->addAttribute("clickhouse.exception", elem.exception); query\_span->addAttribute("db.statement", elem.query); query\_span->addAttribute("clickhouse.query\_id", elem.client\_info.current\_query\_id); query\_span->finish(); }
 ProfileEvents::increment(ProfileEvents::FailedQuery);
 if (ast) { if (ast->as<ASTSelectQuery>() || ast->as<ASTSelectWithUnionQuery>()) { ProfileEvents::increment(ProfileEvents::FailedSelectQuery); } else if (ast->as<ASTInsertQuery>()) { ProfileEvents::increment(ProfileEvents::FailedInsertQuery); } }}
static void setQuerySpecificSettings(ASTPtr & ast, ContextMutablePtr context){ if (auto \* ast\_insert\_into = ast->as<ASTInsertQuery>()) { if (ast\_insert\_into->watch) context->setSetting("output\_format\_enable\_streaming", 1); }}
static std::tuple<ASTPtr, BlockIO> executeQueryImpl( const char \* begin, const char \* end, ContextMutablePtr context, QueryFlags flags, QueryProcessingStage::Enum stage, ReadBuffer \* istr){ const bool internal = flags.internal;
 /// query\_span is a special span, when this function exits, it's lifetime is not ended, but ends when the query finishes. /// Some internal queries might call this function recursively by setting 'internal' parameter to 'true', /// to make sure SpanHolders in current stack ends in correct order, we disable this span for these internal queries /// /// This does not have impact on the final span logs, because these internal queries are issued by external queries, /// we still have enough span logs for the execution of external queries. std::shared\_ptr<OpenTelemetry::SpanHolder> query\_span = internal ? nullptr : std::make\_shared<OpenTelemetry::SpanHolder>("query"); if (query\_span && query\_span->trace\_id != UUID{}) LOG\_TRACE(&Poco::Logger::get("executeQuery"), "Query span trace\_id for opentelemetry log: {}", query\_span->trace\_id);
 auto query\_start\_time = std::chrono::system\_clock::now();
 /// Used to set the watch in QueryStatus and the output formats. It is not based on query\_start\_time as that might be based on /// the value passed by the client Stopwatch start\_watch{CLOCK\_MONOTONIC};
 const auto & client\_info = context->getClientInfo();
 if (!internal) { // If it's not an internal query and we don't see an initial\_query\_start\_time yet, initialize it // to current time. Internal queries are those executed without an independent client context, // thus should not set initial\_query\_start\_time, because it might introduce data race. It's also // possible to have unset initial\_query\_start\_time for non-internal and non-initial queries. For // example, the query is from an initiator that is running an old version of clickhouse. // On the other hand, if it's initialized then take it as the start of the query if (client\_info.initial\_query\_start\_time == 0) { context->setInitialQueryStartTime(query\_start\_time); } else { query\_start\_time = std::chrono::time\_point<std::chrono::system\_clock>( std::chrono::microseconds{client\_info.initial\_query\_start\_time\_microseconds}); } }
 assert(internal || CurrentThread::get().getQueryContext()); assert(internal || CurrentThread::get().getQueryContext()->getCurrentQueryId() == CurrentThread::getQueryId());
 const Settings & settings = context->getSettingsRef();
 size\_t max\_query\_size = settings.max\_query\_size; /// Don't limit the size of internal queries or distributed subquery. if (internal || client\_info.query\_kind == ClientInfo::QueryKind::SECONDARY\_QUERY) max\_query\_size = 0;
 ASTPtr ast; String query; String query\_for\_logging; size\_t log\_queries\_cut\_to\_length = context->getSettingsRef().log\_queries\_cut\_to\_length;
 /// Parse the query from string. try { if (settings.dialect == Dialect::kusto && !internal) { ParserKQLStatement parser(end, settings.allow\_settings\_after\_format\_in\_insert);
 /// TODO: parser should fail early when max\_query\_size limit is reached. ast = parseKQLQuery(parser, begin, end, "", max\_query\_size, settings.max\_parser\_depth); } else if (settings.dialect == Dialect::prql && !internal) { ParserPRQLQuery parser(max\_query\_size, settings.max\_parser\_depth); ast = parseQuery(parser, begin, end, "", max\_query\_size, settings.max\_parser\_depth); } else { ParserQuery parser(end, settings.allow\_settings\_after\_format\_in\_insert); /// TODO: parser should fail early when max\_query\_size limit is reached. ast = parseQuery(parser, begin, end, "", max\_query\_size, settings.max\_parser\_depth); }
 const char \* query\_end = end; if (const auto \* insert\_query = ast->as<ASTInsertQuery>(); insert\_query && insert\_query->data) query\_end = insert\_query->data;
 bool is\_create\_parameterized\_view = false; if (const auto \* create\_query = ast->as<ASTCreateQuery>()) is\_create\_parameterized\_view = create\_query->isParameterizedView(); else if (const auto \* explain\_query = ast->as<ASTExplainQuery>()) { assert(!explain\_query->children.empty()); if (const auto \* create\_of\_explain\_query = explain\_query->children[0]->as<ASTCreateQuery>()) is\_create\_parameterized\_view = create\_of\_explain\_query->isParameterizedView(); }
 /// Replace ASTQueryParameter with ASTLiteral for prepared statements. /// Even if we don't have parameters in query\_context, check that AST doesn't have unknown parameters bool probably\_has\_params = find\_first\_symbols<'{'>(begin, end) != end; if (!is\_create\_parameterized\_view && probably\_has\_params) { ReplaceQueryParameterVisitor visitor(context->getQueryParameters()); visitor.visit(ast); if (visitor.getNumberOfReplacedParameters()) query = serializeAST(\*ast); else query.assign(begin, query\_end); } else { /// Copy query into string. It will be written to log and presented in processlist. If an INSERT query, string will not include data to insertion. query.assign(begin, query\_end); }
 /// Wipe any sensitive information (e.g. passwords) from the query. /// MUST go before any modification (except for prepared statements, /// since it substitute parameters and without them query does not contain /// parameters), to keep query as-is in query\_log and server log. if (ast->hasSecretParts()) { /// IAST::formatForLogging() wipes secret parts in AST and then calls wipeSensitiveDataAndCutToLength(). query\_for\_logging = ast->formatForLogging(log\_queries\_cut\_to\_length); } else { query\_for\_logging = wipeSensitiveDataAndCutToLength(query, log\_queries\_cut\_to\_length); } } catch (...) { /// Anyway log the query. if (query.empty()) query.assign(begin, std::min(end - begin, static\_cast<ptrdiff\_t>(max\_query\_size)));
 query\_for\_logging = wipeSensitiveDataAndCutToLength(query, log\_queries\_cut\_to\_length); logQuery(query\_for\_logging, context, internal, stage);
 if (!internal) logExceptionBeforeStart(query\_for\_logging, context, ast, query\_span, start\_watch.elapsedMilliseconds()); throw; }
 /// Avoid early destruction of process\_list\_entry if it was not saved to `res` yet (in case of exception) ProcessList::EntryPtr process\_list\_entry; BlockIO res; auto implicit\_txn\_control = std::make\_shared<bool>(false); String query\_database; String query\_table;
 auto execute\_implicit\_tcl\_query = [implicit\_txn\_control](const ContextMutablePtr & query\_context, ASTTransactionControl::QueryType tcl\_type) { /// Unset the flag on COMMIT and ROLLBACK SCOPE\_EXIT({ if (tcl\_type != ASTTransactionControl::BEGIN) \*implicit\_txn\_control = false; });
 ASTPtr tcl\_ast = std::make\_shared<ASTTransactionControl>(tcl\_type); InterpreterTransactionControlQuery tc(tcl\_ast, query\_context); tc.execute();
 /// Set the flag after successful BIGIN if (tcl\_type == ASTTransactionControl::BEGIN) \*implicit\_txn\_control = true; };
 try { if (auto txn = context->getCurrentTransaction()) { chassert(txn->getState() != MergeTreeTransaction::COMMITTING); chassert(txn->getState() != MergeTreeTransaction::COMMITTED); if (txn->getState() == MergeTreeTransaction::ROLLED\_BACK && !ast->as<ASTTransactionControl>() && !ast->as<ASTExplainQuery>()) throw Exception( ErrorCodes::INVALID\_TRANSACTION, "Cannot execute query because current transaction failed. Expecting ROLLBACK statement"); }
 /// Interpret SETTINGS clauses as early as possible (before invoking the corresponding interpreter), /// to allow settings to take effect. InterpreterSetQuery::applySettingsFromQuery(ast, context);
 if (auto \* insert\_query = ast->as<ASTInsertQuery>()) insert\_query->tail = istr;
 setQuerySpecificSettings(ast, context);
 /// There is an option of probabilistic logging of queries. /// If it is used - do the random sampling and "collapse" the settings. /// It allows to consistently log queries with all the subqueries in distributed query processing /// (subqueries on remote nodes will receive these "collapsed" settings) if (!internal && settings.log\_queries && settings.log\_queries\_probability < 1.0) { std::bernoulli\_distribution should\_write\_log{settings.log\_queries\_probability};
 context->setSetting("log\_queries", should\_write\_log(thread\_local\_rng)); context->setSetting("log\_queries\_probability", 1.0); }
 if (const auto \* query\_with\_table\_output = dynamic\_cast<const ASTQueryWithTableAndOutput \*>(ast.get())) { query\_database = query\_with\_table\_output->getDatabase(); query\_table = query\_with\_table\_output->getTable(); }
 logQuery(query\_for\_logging, context, internal, stage);
 /// Propagate WITH statement to children ASTSelect. if (settings.enable\_global\_with\_statement) { ApplyWithGlobalVisitor().visit(ast); }
 { SelectIntersectExceptQueryVisitor::Data data{settings.intersect\_default\_mode, settings.except\_default\_mode}; SelectIntersectExceptQueryVisitor{data}.visit(ast); }
 { /// Normalize SelectWithUnionQuery NormalizeSelectWithUnionQueryVisitor::Data data{settings.union\_default\_mode}; NormalizeSelectWithUnionQueryVisitor{data}.visit(ast); }
 /// Check the limits. checkASTSizeLimits(\*ast, settings);
 /// Put query to process list. But don't put SHOW PROCESSLIST query itself. if (!internal && !ast->as<ASTShowProcesslistQuery>()) { /// processlist also has query masked now, to avoid secrets leaks though SHOW PROCESSLIST by other users. process\_list\_entry = context->getProcessList().insert(query\_for\_logging, ast.get(), context, start\_watch.getStart()); context->setProcessListElement(process\_list\_entry->getQueryStatus()); }
 /// Load external tables if they were provided context->initializeExternalTablesIfSet();
 auto \* insert\_query = ast->as<ASTInsertQuery>(); bool async\_insert\_enabled = settings.async\_insert;
 /// Resolve database before trying to use async insert feature - to properly hash the query. if (insert\_query) { if (insert\_query->table\_id) insert\_query->table\_id = context->resolveStorageID(insert\_query->table\_id); else if (auto table = insert\_query->getTable(); !table.empty()) insert\_query->table\_id = context->resolveStorageID(StorageID{insert\_query->getDatabase(), table});
 if (insert\_query->table\_id) if (auto table = DatabaseCatalog::instance().tryGetTable(insert\_query->table\_id, context)) async\_insert\_enabled |= table->areAsynchronousInsertsEnabled(); }
 if (insert\_query && insert\_query->select) { /// Prepare Input storage before executing interpreter if we already got a buffer with data. if (istr) { ASTPtr input\_function; insert\_query->tryFindInputFunction(input\_function); if (input\_function) { StoragePtr storage = context->executeTableFunction(input\_function, insert\_query->select->as<ASTSelectQuery>()); auto & input\_storage = dynamic\_cast<StorageInput &>(\*storage); auto input\_metadata\_snapshot = input\_storage.getInMemoryMetadataPtr(); auto pipe = getSourceFromASTInsertQuery( ast, true, input\_metadata\_snapshot->getSampleBlock(), context, input\_function); input\_storage.setPipe(std::move(pipe)); } } } else { /// reset Input callbacks if query is not INSERT SELECT context->resetInputCallbacks(); }
 StreamLocalLimits limits; std::shared\_ptr<const EnabledQuota> quota; std::unique\_ptr<IInterpreter> interpreter;
 bool async\_insert = false; auto \* queue = context->getAsynchronousInsertQueue(); auto \* logger = &Poco::Logger::get("executeQuery");
 if (insert\_query && async\_insert\_enabled) { String reason;
 if (!queue) reason = "asynchronous insert queue is not configured"; else if (insert\_query->select) reason = "insert query has select"; else if (insert\_query->hasInlinedData()) async\_insert = true;
 if (!reason.empty()) LOG\_DEBUG(logger, "Setting async\_insert=1, but INSERT query will be executed synchronously (reason: {})", reason); }
 bool quota\_checked = false; std::unique\_ptr<ReadBuffer> insert\_data\_buffer\_holder;
 if (async\_insert) { if (context->getCurrentTransaction() && settings.throw\_on\_unsupported\_query\_inside\_transaction) throw Exception(ErrorCodes::NOT\_IMPLEMENTED, "Async inserts inside transactions are not supported"); if (settings.implicit\_transaction && settings.throw\_on\_unsupported\_query\_inside\_transaction) throw Exception(ErrorCodes::NOT\_IMPLEMENTED, "Async inserts with 'implicit\_transaction' are not supported");
 quota = context->getQuota(); if (quota) { quota\_checked = true; quota->used(QuotaType::QUERY\_INSERTS, 1); quota->used(QuotaType::QUERIES, 1); quota->checkExceeded(QuotaType::ERRORS); }
 auto result = queue->pushQueryWithInlinedData(ast, context);
 if (result.status == AsynchronousInsertQueue::PushResult::OK) { if (settings.wait\_for\_async\_insert) { auto timeout = settings.wait\_for\_async\_insert\_timeout.totalMilliseconds(); auto source = std::make\_shared<WaitForAsyncInsertSource>(std::move(result.future), timeout); res.pipeline = QueryPipeline(Pipe(std::move(source))); }
 const auto & table\_id = insert\_query->table\_id; if (!table\_id.empty()) context->setInsertionTable(table\_id); } else if (result.status == AsynchronousInsertQueue::PushResult::TOO\_MUCH\_DATA) { async\_insert = false; insert\_data\_buffer\_holder = std::move(result.insert\_data\_buffer);
 if (insert\_query->data) { /// Reset inlined data because it will be /// available from tail read buffer. insert\_query->end = insert\_query->data; insert\_query->data = nullptr; }
 insert\_query->tail = insert\_data\_buffer\_holder.get(); LOG\_DEBUG(logger, "Setting async\_insert=1, but INSERT query will be executed synchronously because it has too much data"); } }
 QueryCachePtr query\_cache = context->getQueryCache(); const bool can\_use\_query\_cache = query\_cache != nullptr && settings.use\_query\_cache && !internal[View remainder of file in raw view](https://github.com/ClickHouse/ClickHouse/raw/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_2afd3f8e_20250111_031539.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fsecurity%2Fadvisories%2FGHSA-45h5-f7g3-gr8r)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fsecurity%2Fadvisories%2FGHSA-45h5-f7g3-gr8r)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=ClickHouse%2FClickHouse)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[ClickHouse](/ClickHouse)
/
**[ClickHouse](/ClickHouse/ClickHouse)**
Public

* [Notifications](/login?return_to=%2FClickHouse%2FClickHouse) You must be signed in to change notification settings
* [Fork
  7k](/login?return_to=%2FClickHouse%2FClickHouse)
* [Star
   38.4k](/login?return_to=%2FClickHouse%2FClickHouse)

* [Code](/ClickHouse/ClickHouse)
* [Issues
  3.7k](/ClickHouse/ClickHouse/issues)
* [Pull requests
  398](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects
  0](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

Additional navigation options

* [Code](/ClickHouse/ClickHouse)
* [Issues](/ClickHouse/ClickHouse/issues)
* [Pull requests](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

# Role-based Access Control is bypassed when query caching is enabled.

Low

[santrancisco](/santrancisco)
published
GHSA-45h5-f7g3-gr8r
Mar 18, 2024

## Package

ClickHouse
(clickhouse v24)

## Affected versions

< v24.1.1.2048

## Patched versions

>= v24.1.1.2048

ClickHouse
(clickhouse v23.12)

< v23.12.6.19

>= v23.12.6.19

ClickHouse
(clickhouse v23.8)

< v23.8.12.13

>= v23.8.12.13

ClickHouse
(clickhouse v23.3)

< v23.3.22.3

>= v23.3.22.3

ClickHouse Cloud
(clickhouse cloud)

< 24.0.2.54535

>= 24.0.2.54535

## Description

### Summary

The bug was fixed in this PR but reported to bugcrowd about a month ago. Here's what we submitted to bugcrowd:

[#58611](https://github.com/ClickHouse/ClickHouse/pull/58611)

This bug exists in the cloud clickhouse offering and likely exists in github.com/clickhouse/clickhouse but we're reporting for the cloud product because that's where the reproducing steps took place.

Query caching bypasses the role based access controls and the policies being enforced on roles. Currently, the query cache only respects separate users, however this is not documented and not expected behavior. Based on the documentation, role based access control should be enforced regardless if query caching is enabled or not.

### Details

It appears that this issue is caused by the cache key not incorporating the role name, only the user name. It uses the [AST and the userName](https://github.com/ClickHouse/ClickHouse/blob/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp#L1013-L1015)

```
QueryCache::Key key(ast, context->getUserName());

```

The context, though, appears to have information about the current role on the context's EnabledRolesInfo

```
context->getRolesInfo()->getCurrentRolesNames()

```

We aren't experts on this code base by any means, but it looks like incorporating the role names from getEnabledRolesNames or getCurrentRolesNames (whichever is most appropriate) might be a solution to this issue. But you probably need to include all of the role names.

It looks like this is a bug given this is [explicitly documented](https://clickhouse.com/docs/en/operations/query-cache) for users as a security risk but is handled differently for roles:

> Finally, entries in the query cache are not shared between users due to security reasons. For example, user A must not be able to bypass a row policy on a table by running the same query as another user B for whom no such policy exists. However, if necessary, cache entries can be marked accessible by other users (i.e. shared) by supplying setting query\_cache\_share\_between\_users.

### PoC

```
CREATE USER admin IDENTIFIED BY  'R~zo3PsI0RPhx';

GRANT CURRENT GRANTS ON *.* TO admin WITH GRANT OPTION;

-- Login as admin.  Could be done anytime after admin creation, but must be
-- done before table can be queried, after grants are given

-- 1. Create the table
CREATE TABLE user_data
(
    ID UInt32,
    userID UInt32
)
ENGINE = MergeTree
ORDER BY userID;

-- 2. Create roles with row-level security

-- Role for users with userID = 1

CREATE ROLE user_role_1;
GRANT SELECT ON user_data TO user_role_1;
CREATE ROW POLICY user_policy_1 ON user_data
    FOR SELECT USING userID = 1 TO user_role_1;

-- Role for users with userID = 2

CREATE ROLE user_role_2;
GRANT SELECT ON user_data TO user_role_2;
CREATE ROW POLICY user_policy_2 ON user_data
    FOR SELECT USING userID = 2 TO user_role_2;

-- 3. Grant roles to the admin user

GRANT user_role_1, user_role_2 TO admin;

INSERT INTO user_data (ID, userID) VALUES (1, 1), (2, 2), (3, 1), (4, 3), (5, 2), (6, 1), (7, 4), (8, 2);

-- Switch to admin if not already done so

-- Policy test

SET ROLE user_role_1;

-- only returns rows for user_role_1
SELECT * FROM user_data;

SET ROLE ALL;
SET ROLE user_role_2;

-- only returns rows for user_role_2
SELECT * FROM user_data;

SET ROLE ALL;
SET ROLE user_role_1;

-- only returns rows for user_role_1
SELECT * FROM user_data SETTINGS use_query_cache=1;

SET ROLE ALL;
SET ROLE user_role_2;

-- 🚨🚨🚨🚨 RETURNS ONLY user_role_1 ROWS 🚨🚨🚨🚨
SELECT * FROM user_data SETTINGS use_query_cache=1;

```
### Impact

Switching between different ClickHouse roles with a single user account to query data can lead to ACLs being circumvented when employing query caching. If attackers gain control of the user, they could potentially guess queries and gain access to data beyond their authorized scope.

The bug was fixed in this PR but reported to bugcrowd about a month ago.

[#58611](https://github.com/ClickHouse/ClickHouse/pull/58611)

### Recommendation & Workaround

ClickHouse advises users with vulnerable versions of ClickHouse not to use the query cache when their application dynamically switches between various roles. In order to use query cache, one workaround is to employ multiple users with distinct roles assigned to them, enabling access to various data with differing permissions.

### Severity

Low

2.4

# CVSS overall score

 This score calculates overall vulnerability severity from 0 to 10 and is based on the Common Vulnerability Scoring System (CVSS).

 / 10

#### CVSS v3 base metrics

Attack vector
Adjacent

Attack complexity
Low

Privileges required
High

User interaction
None

Scope
Unchanged

Confidentiality
Low

Integrity
None

Availability
None

Learn more about base metrics

# CVSS v3 base metrics

Attack vector:
More severe the more the remote (logically and physically) an attacker can be in order to exploit the vulnerability.

Attack complexity:
More severe for the least complex attacks.

Privileges required:
More severe if no privileges are required.

User interaction:
More severe when no user interaction is required.

Scope:
More severe when a scope change occurs, e.g. one vulnerable component impacts resources in components beyond its security scope.

Confidentiality:
More severe when loss of data confidentiality is highest, measuring the level of data access available to an unauthorized user.

Integrity:
More severe when loss of data integrity is the highest, measuring the consequence of data modification possible by an unauthorized user.

Availability:
More severe when the loss of impacted component availability is highest.

CVSS:3.1/AV:A/AC:L/PR:H/UI:N/S:U/C:L/I:N/A:N

### CVE ID

CVE-2024-22412

### Weaknesses

No CWEs

### Credits

* [![@ejcx](https://avatars.githubusercontent.com/u/2739058?s=40&v=4)](/ejcx)
  [ejcx](/ejcx)
  Finder
* [![@abraithwaite](https://avatars.githubusercontent.com/u/3791413?s=40&v=4)](/abraithwaite)
  [abraithwaite](/abraithwaite)
  Finder

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_eb975e52_20250111_031539.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fpull%2F58611)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fpull%2F58611)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fpull_requests_fragments%2Fpull_request_layout&source=header-repo&source_repo=ClickHouse%2FClickHouse)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[ClickHouse](/ClickHouse)
/
**[ClickHouse](/ClickHouse/ClickHouse)**
Public

* [Notifications](/login?return_to=%2FClickHouse%2FClickHouse) You must be signed in to change notification settings
* [Fork
  7k](/login?return_to=%2FClickHouse%2FClickHouse)
* [Star
   38.4k](/login?return_to=%2FClickHouse%2FClickHouse)

* [Code](/ClickHouse/ClickHouse)
* [Issues
  3.7k](/ClickHouse/ClickHouse/issues)
* [Pull requests
  398](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects
  0](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

Additional navigation options

* [Code](/ClickHouse/ClickHouse)
* [Issues](/ClickHouse/ClickHouse/issues)
* [Pull requests](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

New issue

**Have a question about this project?** Sign up for a free GitHub account to open an issue and contact its maintainers and the community.

 [Sign up for GitHub](/signup?return_to=%2FClickHouse%2FClickHouse%2Fissues%2Fnew%2Fchoose)

By clicking “Sign up for GitHub”, you agree to our [terms of service](https://docs.github.com/terms) and
[privacy statement](https://docs.github.com/privacy). We’ll occasionally send you account related emails.

Already on GitHub?
[Sign in](/login?return_to=%2FClickHouse%2FClickHouse%2Fissues%2Fnew%2Fchoose)
to your account

[Jump to bottom](#issue-comment-box)

# Improve isolation of query cache entries under re-created users or role switches #58611

 Merged

[rschu1ze](/rschu1ze)
merged 7 commits into
[ClickHouse:master](/ClickHouse/ClickHouse/tree/master "ClickHouse/ClickHouse:master")
from
[rschu1ze:qc-isolation](/rschu1ze/ClickHouse/tree/qc-isolation "rschu1ze/ClickHouse:qc-isolation")

Jan 11, 2024

 Merged

# [Improve isolation of query cache entries under re-created users or role switches](#top) #58611

[rschu1ze](/rschu1ze)
merged 7 commits into
[ClickHouse:master](/ClickHouse/ClickHouse/tree/master "ClickHouse/ClickHouse:master")
from
[rschu1ze:qc-isolation](/rschu1ze/ClickHouse/tree/qc-isolation "rschu1ze/ClickHouse:qc-isolation")

Jan 11, 2024

[Conversation
9](/ClickHouse/ClickHouse/pull/58611)
[Commits
7](/ClickHouse/ClickHouse/pull/58611/commits)
[Checks
146](/ClickHouse/ClickHouse/pull/58611/checks)
[Files changed](/ClickHouse/ClickHouse/pull/58611/files)

## Conversation

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

[![rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=60&v=4)](/rschu1ze)

Copy link

Member

### @rschu1ze **[rschu1ze](/rschu1ze)** commented [Jan 8, 2024](#issue-2071215809)

Fixes [#58054](https://github.com/ClickHouse/ClickHouse/issues/58054)

### Changelog category (leave one):

* Bug Fix (user-visible misbehavior in an official stable release)

### Changelog entry (a user-readable short description of the changes that goes to CHANGELOG.md):

The query cache now denies access to entries when the user is re-created or assumes another role. This improves prevents attacks where 1. an user with the same name as a dropped user may access the old user's cache entries or 2. a user with a different role may access cache entries of a role with a different row policy.

Sorry, something went wrong.

 👍
2
 qoega and jsc0218 reacted with thumbs up emoji

All reactions

* 👍
  2 reactions

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Improve isolation of query results in query cache](/ClickHouse/ClickHouse/pull/58611/commits/fabc06995e37d77d56bc505c814c43c49a9e3da5 "Improve isolation of query results in query cache

Fixes #58054")`
 …

`[fabc069](/ClickHouse/ClickHouse/pull/58611/commits/fabc06995e37d77d56bc505c814c43c49a9e3da5)`

```
Fixes [ClickHouse#58054](https://github.com/ClickHouse/ClickHouse/issues/58054)
```

[![@jsc0218](https://avatars.githubusercontent.com/u/3689455?s=40&v=4)](/jsc0218)
[jsc0218](/jsc0218)
self-assigned this
[Jan 8, 2024](#event-11422515148)

[![@robot-ch-test-poll](https://avatars.githubusercontent.com/u/45356221?s=40&v=4)](/robot-ch-test-poll)
[robot-ch-test-poll](/robot-ch-test-poll)
added
the
[pr-bugfix](/ClickHouse/ClickHouse/labels/pr-bugfix)
Pull request with bugfix, not backported by default
label
[Jan 8, 2024](#event-11422517703)

[![@robot-ch-test-poll](https://avatars.githubusercontent.com/u/45356221?s=80&v=4)](/robot-ch-test-poll)

Copy link

Contributor

### **[robot-ch-test-poll](/robot-ch-test-poll)** commented [Jan 8, 2024](#issuecomment-1881818903) • edited by robot-clickhouse-ci-1 Loading

|  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| *This is an automated comment for commit [bd9e38f](https://github.com/ClickHouse/ClickHouse/commit/bd9e38ff478540f1e31ee467fef0a58a709de811) with description of existing statuses. It's updated for the latest CI running*  [❌ Click here](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/ci_running.html) to open a full report in a separate page Successful checks  | Check name | Description | Status | | --- | --- | --- | | AST fuzzer | Runs randomly generated queries to catch program errors. The build type is optionally given in parenthesis. If it fails, ask a maintainer for help | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/fuzzer_astfuzzerasan/report.html) | | Bugfix validate check | Checks that either a new test (functional or integration) or there some changed tests that fail with the binary built on master branch | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/bugfix_validate_check.html) | | ClickBench | Runs [ClickBench](https://github.com/ClickHouse/ClickBench/) with instant-attach table | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/clickbench__aarch64_.html) | | ClickHouse build check | Builds ClickHouse in various configurations for use in further steps. You have to fix the builds that fail. Build logs often has enough information to fix the error, but you might have to reproduce the failure locally. The **cmake** options can be found in the build log, grepping for **cmake**. Use these options and follow the [general build process](https://clickhouse.com/docs/en/development/build) | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/clickhouse_build_check/report.html) | | Compatibility check | Checks that **clickhouse** binary runs on distributions with old libc versions. If it fails, ask a maintainer for help | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/compatibility_check__aarch64_.html) | | Docker image for servers | The check to build and optionally push the mentioned image to docker hub | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/docker_image_clickhouse_clickhouse-keeper_building_check.html) | | Docs Check | Builds and tests the documentation | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/docs_check.html) | | Fast test | Normally this is the first check that is ran for a PR. It builds ClickHouse and runs most of [stateless functional tests](https://clickhouse.com/docs/en/development/tests#functional-tests), omitting some. If it fails, further checks are not started until it is fixed. Look at the report to see which tests fail, then reproduce the failure locally as described [here](https://clickhouse.com/docs/en/development/tests#functional-test-locally) | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/fast_test.html) | | Flaky tests | Checks if new added or modified tests are flaky by running them repeatedly, in parallel, with more randomization. Functional tests are run 100 times with address sanitizer, and additional randomization of thread scheduling. Integrational tests are run up to 10 times. If at least once a new test has failed, or was too long, this check will be red. We don't allow flaky tests, read [the doc](https://clickhouse.com/blog/decorating-a-christmas-tree-with-the-help-of-flaky-tests/) | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/integration_tests_flaky_check__asan_.html) | | Install packages | Checks that the built packages are installable in a clear environment | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/install_packages__amd64_.html) | | Integration tests | The integration tests report. In parenthesis the package type is given, and in square brackets are the optional part/total tests | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/integration_tests__asan__%5B1_4%5D.html) | | Mergeable Check | Checks if all other necessary checks are successful | [✅ success](https://github.com/ClickHouse/ClickHouse/actions/runs/7489738509/job/20390308384) | | SQLTest | There's no description for the check yet, please add it to tests/ci/ci\_config.py:CHECK\_DESCRIPTIONS | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/sqltest_sqltest/report.html) | | SQLancer | Fuzzing tests that detect logical bugs with [SQLancer](https://github.com/sqlancer/sqlancer) tool | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/sqlancer__debug_.html) | | Sqllogic | Run clickhouse on the [sqllogic](https://www.sqlite.org/sqllogictest) test set against sqlite and checks that all statements are passed | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/sqllogic_test__release_.html) | | Stateful tests | Runs stateful functional tests for ClickHouse binaries built in various configurations -- release, debug, with sanitizers, etc | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/stateful_tests__aarch64_.html) | | Style Check | Runs a set of checks to keep the code style clean. If some of tests failed, see the related log from the report | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/style_check.html) | | Unit tests | Runs the unit tests for different release types | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/unit_tests__asan_.html) | | Upgrade check | Runs stress tests on server version from last release and then tries to upgrade it to the version from the PR. It checks if the new server can successfully startup without any errors, crashes or sanitizer asserts | [✅ success](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/upgrade_check__asan_.html) |    | Check name | Description | Status | | --- | --- | --- | | CI running | A meta-check that indicates the running CI. Normally, it's in **success** or **pending** state. The failed status indicates some problems with the PR | [⏳ pending](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/ci_running.html) | | Performance Comparison | Measure changes in query performance. The performance test report is described in detail [here](https://github.com/ClickHouse/ClickHouse/tree/master/docker/test/performance-comparison#how-to-read-the-report). In square brackets are the optional part/total tests | [❌ failure](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/performance_comparison_%5B4_4%5D/report.html) | | Stateless tests | Runs stateless functional tests for ClickHouse binaries built in various configurations -- release, debug, with sanitizers, etc | [❌ error](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/stateless_tests__debug__s3_storage__%5B3_6%5D.html) | | Stress test | Runs stateless functional tests concurrently from several clients to detect concurrency-related errors | [❌ failure](https://s3.amazonaws.com/clickhouse-test-reports/58611/bd9e38ff478540f1e31ee467fef0a58a709de811/stress_test__asan_.html) | |

All reactions

Sorry, something went wrong.

[![vitlibar](https://avatars.githubusercontent.com/u/45142681?s=60&v=4)](/vitlibar)

**[vitlibar](/vitlibar)**
reviewed
[Jan 8, 2024](#pullrequestreview-1810192468)

 [View reviewed changes](/ClickHouse/ClickHouse/pull/58611/files/fabc06995e37d77d56bc505c814c43c49a9e3da5)

[src/Interpreters/Cache/QueryCache.h](/ClickHouse/ClickHouse/pull/58611/files/fabc06995e37d77d56bc505c814c43c49a9e3da5#diff-0cf1739d516794657bf720f2c3a6dbb0a9621ba3aa8c2c94786a63a144cc22a4)
Outdated

|  |  | /// - after DROP USER, it must not be possible to create a new user with with the dropped user name and access the dropped user's |
| --- | --- | --- |
|  |  | /// query cache entries |
|  |  | /// - different roles of the same user may be tied to different row-level policies. It must not be possible to switch role and |
|  |  | /// access another role's cache entries |
|  |  | const String user\_name; |

Copy link

Member

### @vitlibar **[vitlibar](/vitlibar)** [Jan 8, 2024](#discussion_r1445472710) • edited Loading

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

Is `user_name` still used? It seems it's enough to compare only `user_id`.

Sorry, something went wrong.

All reactions

Copy link

Member

Author

### @rschu1ze **[rschu1ze](/rschu1ze)** [Jan 9, 2024](#discussion_r1445913972)

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

You are right. But before fixing this: do you know why the `user_id` / `getUserID()` in `Context` is an `std::optional`? When would the user id be not set?

Sorry, something went wrong.

All reactions

Copy link

Member

### @vitlibar **[vitlibar](/vitlibar)** [Jan 9, 2024](#discussion_r1445983209)

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

`user_id` can be nullopt only if it's the global context. Some internal queries are executed in the global context. For example `ATTACH TABLE` queries for existing tables when the server starts; or `INSERT` queries from a Buffer to its destination table. If `user_id` is nullopt then `user_name` is always empty anyway.

Sorry, something went wrong.

 👍
2
 rschu1ze and jsc0218 reacted with thumbs up emoji

All reactions

* 👍
  2 reactions

 [rschu1ze](/rschu1ze)
added 5 commits
[January 9, 2024 10:36](#commits-pushed-bca0f14)

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Fix style](/ClickHouse/ClickHouse/pull/58611/commits/bca0f144e283b8509a24910899e1f12c5b324c1c "Fix style")`

`[bca0f14](/ClickHouse/ClickHouse/pull/58611/commits/bca0f144e283b8509a24910899e1f12c5b324c1c)`

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Get rid of QueryCache::user_name](/ClickHouse/ClickHouse/pull/58611/commits/e9b6f413b8cb80bcae1577557f92cb8025da7219 "Get rid of QueryCache::user_name")`

`[e9b6f41](/ClickHouse/ClickHouse/pull/58611/commits/e9b6f413b8cb80bcae1577557f92cb8025da7219)`

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Merge remote-tracking branch 'rschu1ze/master' into qc-isolation](/ClickHouse/ClickHouse/pull/58611/commits/c04e4eb162ca64a83182c7e2fb9023e949d63e66 "Merge remote-tracking branch 'rschu1ze/master' into qc-isolation")`

`[c04e4eb](/ClickHouse/ClickHouse/pull/58611/commits/c04e4eb162ca64a83182c7e2fb9023e949d63e66)`

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Merge remote-tracking branch 'rschu1ze/master' into qc_isolation](/ClickHouse/ClickHouse/pull/58611/commits/36173bbb7b1404e195a5657f5e358564fd574c48 "Merge remote-tracking branch 'rschu1ze/master' into qc_isolation")`

`[36173bb](/ClickHouse/ClickHouse/pull/58611/commits/36173bbb7b1404e195a5657f5e358564fd574c48)`

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Try to fix test flakyness](/ClickHouse/ClickHouse/pull/58611/commits/9031c671f6e862edda8a1e96fb6668e8e6b3f0a1 "Try to fix test flakyness")`

`[9031c67](/ClickHouse/ClickHouse/pull/58611/commits/9031c671f6e862edda8a1e96fb6668e8e6b3f0a1)`

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=80&u=ae8472988266e2efd1ad0b54e50bef5c0879ad31&v=4)](/rschu1ze)

Copy link

Member

Author

### **[rschu1ze](/rschu1ze)** commented [Jan 10, 2024](#issuecomment-1885328666)

| [@vitlibar](https://github.com/vitlibar) Approve? Thanks! |
| --- |

 👀
1
 vitlibar reacted with eyes emoji

All reactions

* 👀
  1 reaction

Sorry, something went wrong.

[![@vitlibar](https://avatars.githubusercontent.com/u/45142681?s=40&u=a2fc017aa6c73c8633cdd3c6ff9e4247d8f7ea59&v=4)](/vitlibar)
[vitlibar](/vitlibar)
self-assigned this
[Jan 11, 2024](#event-11455097207)

[![vitlibar](https://avatars.githubusercontent.com/u/45142681?s=60&v=4)](/vitlibar)

**[vitlibar](/vitlibar)**
reviewed
[Jan 11, 2024](#pullrequestreview-1815455649)

 [View reviewed changes](/ClickHouse/ClickHouse/pull/58611/files/9031c671f6e862edda8a1e96fb6668e8e6b3f0a1)

[src/Common/TTLCachePolicy.h](/ClickHouse/ClickHouse/pull/58611/files/9031c671f6e862edda8a1e96fb6668e8e6b3f0a1#diff-5cd213febdcdb7e90e608816dca21217b5eadbb46f8da117cbe388e8c45e142a)
Outdated

|  |  | @@ -11,37 +13,47 @@ namespace DB | |
| --- | --- | --- | --- |
|  |  | class PerUserTTLCachePolicyUserQuota : public ICachePolicyUserQuota |
|  |  | { |
|  |  | public: |
|  |  | void setQuotaForUser(const String & user\_name, size\_t max\_size\_in\_bytes, size\_t max\_entries) override |
|  |  | void setQuotaForUser(std::optional<UUID> user\_id, size\_t max\_size\_in\_bytes, size\_t max\_entries) override |

Copy link

Member

### @vitlibar **[vitlibar](/vitlibar)** [Jan 11, 2024](#discussion_r1448782497)

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

`setQuotaForUser()` doesn't look good when its parameter is `std::optional<UUID>`. I mean logically `setQuotaForUser(nullopt, ...)` looks a bit pointless (you set something for an absent user). The function doesn't do anything useful anyway if this parameter is nullopt, so what I suggest is just moving this condition `if (!user_id)` outside of the function and turn the type of the parameter into a plain `const UUID & user_id`. And for other functions `increaseActual()`, `decreaseActual()`, `approveWrite()` it's the same.

Sorry, something went wrong.

All reactions

Copy link

Member

Author

### @rschu1ze **[rschu1ze](/rschu1ze)** [Jan 11, 2024](#discussion_r1448892517)

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

That's a good idea, the internal users would have `std::optional<UUID> = std::nullopt` and that can't be configured via settings anyways. Rewrote this the way you proposed.

Sorry, something went wrong.

 👍
1
 vitlibar reacted with thumbs up emoji

All reactions

* 👍
  1 reaction

[![vitlibar](https://avatars.githubusercontent.com/u/45142681?s=60&v=4)](/vitlibar)

**[vitlibar](/vitlibar)**
reviewed
[Jan 11, 2024](#pullrequestreview-1815461274)

 [View reviewed changes](/ClickHouse/ClickHouse/pull/58611/files/9031c671f6e862edda8a1e96fb6668e8e6b3f0a1)

[tests/queries/0\_stateless/02494\_query\_cache\_user\_isolation.sh](/ClickHouse/ClickHouse/pull/58611/files/9031c671f6e862edda8a1e96fb6668e8e6b3f0a1#diff-a1e08e0580d9cd05b165acd2358f662957522ba9fc00c7a876f5cb5946a03a17)
Outdated

|  |  | # - drop the user, recreate it with the same name |
| --- | --- | --- |
|  |  | # - test that the cache entry is inaccessible |
|  |  |  |
|  |  | ${CLICKHOUSE\_CLIENT} --query "SELECT 'Attack 1'" |

Copy link

Member

### @vitlibar **[vitlibar](/vitlibar)** [Jan 11, 2024](#discussion_r1448787795) • edited Loading

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

`echo "Attack 1"` is shorter (though it doesn't matter)

Sorry, something went wrong.

All reactions

Copy link

Member

Author

### @rschu1ze **[rschu1ze](/rschu1ze)** [Jan 11, 2024](#discussion_r1448889572)

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

Done

Sorry, something went wrong.

All reactions

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&v=4)](/rschu1ze)

`[Incorporate review feedback](/ClickHouse/ClickHouse/pull/58611/commits/bd9e38ff478540f1e31ee467fef0a58a709de811 "Incorporate review feedback")`

`[bd9e38f](/ClickHouse/ClickHouse/pull/58611/commits/bd9e38ff478540f1e31ee467fef0a58a709de811)`

[![vitlibar](https://avatars.githubusercontent.com/u/45142681?s=60&v=4)](/vitlibar)

**[vitlibar](/vitlibar)**
approved these changes
[Jan 11, 2024](#pullrequestreview-1815717770)

 [View reviewed changes](/ClickHouse/ClickHouse/pull/58611/files/bd9e38ff478540f1e31ee467fef0a58a709de811)

 Hide details
View details

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&u=ae8472988266e2efd1ad0b54e50bef5c0879ad31&v=4)](/rschu1ze)
[rschu1ze](/rschu1ze)
merged commit [`790f589`](/ClickHouse/ClickHouse/commit/790f5890a0d28e2f1c322d38d66bcf1f9ab5c096)
into
ClickHouse:master

[Jan 11, 2024](https://github.com/ClickHouse/ClickHouse/pull/58611#event-11458930227)
194 of 230 checks passed

[![@nikitamikhaylov](https://avatars.githubusercontent.com/u/25705399?s=40&u=269f7cb8ee393219f13008df117e5a312069595e&v=4)](/nikitamikhaylov)
[nikitamikhaylov](/nikitamikhaylov)
added
the
[pr-must-backport-cloud](/ClickHouse/ClickHouse/labels/pr-must-backport-cloud)
label
[Feb 5, 2024](#event-11702972512)

[![@robot-ch-test-poll4](https://avatars.githubusercontent.com/u/69306974?s=40&v=4)](/robot-ch-test-poll4)
[robot-ch-test-poll4](/robot-ch-test-poll4)
added
the
[pr-backports-created-cloud](/ClickHouse/ClickHouse/labels/pr-backports-created-cloud)
label
[Feb 5, 2024](#event-11704739443)

[![@alexey-milovidov](https://avatars.githubusercontent.com/u/18581488?s=40&v=4)](/alexey-milovidov)
[alexey-milovidov](/alexey-milovidov)
added
the
[pr-must-backport](/ClickHouse/ClickHouse/labels/pr-must-backport)
Pull request should be backported intentionally. Use this label with great care!
label
[Mar 15, 2024](#event-12127955160)

This was referenced Mar 15, 2024

[Cherry pick #58611 to 23.3: Improve isolation of query cache entries under re-created users or role switches
#61422](/ClickHouse/ClickHouse/pull/61422)
 Closed

[Cherry pick #58611 to 23.8: Improve isolation of query cache entries under re-created users or role switches
#61423](/ClickHouse/ClickHouse/pull/61423)
 Merged

[Cherry pick #58611 to 23.12: Improve isolation of query cache entries under re-created users or role switches
#61424](/ClickHouse/ClickHouse/pull/61424)
 Merged

[robot-clickhouse](/robot-clickhouse)
added a commit
that referenced
this pull request
[Mar 15, 2024](#ref-commit-378acd9)
[![@robot-clickhouse](https://avatars.githubusercontent.com/u/41385210?s=40&v=4)](/robot-clickhouse)

`[Backport](/ClickHouse/ClickHouse/commit/378acd9c0a458a6100d92efc851994154b452c5b "Backport #58611 to 23.12: Improve isolation of query cache entries under re-created users or role switches") [#58611](https://github.com/ClickHouse/ClickHouse/pull/58611) [to 23.12: Improve isolation of query cache entries un…](/ClickHouse/ClickHouse/commit/378acd9c0a458a6100d92efc851994154b452c5b "Backport #58611 to 23.12: Improve isolation of query cache entries under re-created users or role switches")`
…

`[378acd9](/ClickHouse/ClickHouse/commit/378acd9c0a458a6100d92efc851994154b452c5b)`

```
…der re-created users or role switches
```

[![@robot-clickhouse](https://avatars.githubusercontent.com/u/41385210?s=40&v=4)](/robot-clickhouse)
[robot-clickhouse](/robot-clickhouse)
mentioned this pull request
[Mar 15, 2024](#ref-pullrequest-2187943212)

[Backport #58611 to 23.12: Improve isolation of query cache entries under re-created users or role switches
#61425](/ClickHouse/ClickHouse/pull/61425)
 Merged

[rschu1ze](/rschu1ze)
added a commit
that referenced
this pull request
[Mar 15, 2024](#ref-commit-b176c0e)
[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&u=ae8472988266e2efd1ad0b54e50bef5c0879ad31&v=4)](/rschu1ze)

`[Merge pull request](/ClickHouse/ClickHouse/commit/b176c0e08116dd53ecdb7ff3c5802e48595e420d "Merge pull request #61425 from ClickHouse/backport/23.12/58611

Backport #58611 to 23.12: Improve isolation of query cache entries under re-created users or role switches") [#61425](https://github.com/ClickHouse/ClickHouse/pull/61425) [from ClickHouse/backport/23.12/58611](/ClickHouse/ClickHouse/commit/b176c0e08116dd53ecdb7ff3c5802e48595e420d "Merge pull request #61425 from ClickHouse/backport/23.12/58611

Backport #58611 to 23.12: Improve isolation of query cache entries under re-created users or role switches")`
…

`[b176c0e](/ClickHouse/ClickHouse/commit/b176c0e08116dd53ecdb7ff3c5802e48595e420d)`

```
Backport [#58611](https://github.com/ClickHouse/ClickHouse/pull/58611) to 23.12: Improve isolation of query cache entries under re-created users or role switches
```

[robot-clickhouse](/robot-clickhouse)
added a commit
that referenced
this pull request
[Mar 15, 2024](#ref-commit-86d73a8)
[![@robot-clickhouse](https://avatars.githubusercontent.com/u/41385210?s=40&v=4)](/robot-clickhouse)

`[Backport](/ClickHouse/ClickHouse/commit/86d73a8fbdd42d49560ecc6dd2a393e247c22e7a "Backport #58611 to 23.8: Improve isolation of query cache entries under re-created users or role switches") [#58611](https://github.com/ClickHouse/ClickHouse/pull/58611) [to 23.8: Improve isolation of query cache entries und…](/ClickHouse/ClickHouse/commit/86d73a8fbdd42d49560ecc6dd2a393e247c22e7a "Backport #58611 to 23.8: Improve isolation of query cache entries under re-created users or role switches")`
…

`[86d73a8](/ClickHouse/ClickHouse/commit/86d73a8fbdd42d49560ecc6dd2a393e247c22e7a)`

```
…er re-created users or role switches
```

[![@robot-clickhouse](https://avatars.githubusercontent.com/u/41385210?s=40&v=4)](/robot-clickhouse)
[robot-clickhouse](/robot-clickhouse)
mentioned this pull request
[Mar 15, 2024](#ref-pullrequest-2188364834)

[Backport #58611 to 23.8: Improve isolation of query cache entries under re-created users or role switches
#61439](/ClickHouse/ClickHouse/pull/61439)
 Merged

[![@robot-clickhouse](https://avatars.githubusercontent.com/u/41385210?s=40&v=4)](/robot-clickhouse)
[robot-clickhouse](/robot-clickhouse)
added
the
[pr-backports-created](/ClickHouse/ClickHouse/labels/pr-backports-created)
Backport PRs are successfully created, it won't be processed by CI script anymore
label
[Mar 15, 2024](#event-12130681427)

[rschu1ze](/rschu1ze)
added a commit
that referenced
this pull request
[Mar 18, 2024](#ref-commit-9bba341)
[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=40&u=ae8472988266e2efd1ad0b54e50bef5c0879ad31&v=4)](/rschu1ze)

`[Merge pull request](/ClickHouse/ClickHouse/commit/9bba341dde13327ca0c1e89f192b14d3299c787d "Merge pull request #61439 from ClickHouse/backport/23.8/58611

Backport #58611 to 23.8: Improve isolation of query cache entries under re-created users or role switches") [#61439](https://github.com/ClickHouse/ClickHouse/pull/61439) [from ClickHouse/backport/23.8/58611](/ClickHouse/ClickHouse/commit/9bba341dde13327ca0c1e89f192b14d3299c787d "Merge pull request #61439 from ClickHouse/backport/23.8/58611

Backport #58611 to 23.8: Improve isolation of query cache entries under re-created users or role switches")`
…

`[9bba341](/ClickHouse/ClickHouse/commit/9bba341dde13327ca0c1e89f192b14d3299c787d)`

```
Backport [#58611](https://github.com/ClickHouse/ClickHouse/pull/58611) to 23.8: Improve isolation of query cache entries under re-created users or role switches
```

[![@GoVulnBot](https://avatars.githubusercontent.com/u/96493708?s=40&v=4)](/GoVulnBot)
[GoVulnBot](/GoVulnBot)
mentioned this pull request
[Apr 3, 2024](#ref-issue-2222631757)

[x/vulndb: potential Go vuln in github.com/ClickHouse/ClickHouse: CVE-2024-22412
golang/vulndb#2673](/golang/vulndb/issues/2673)

Closed

[Sign up for free](/join?source=comment-repo)
**to join this conversation on GitHub**.
Already have an account?
[Sign in to comment](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fpull%2F58611)

Reviewers

[![@vitlibar](https://avatars.githubusercontent.com/u/45142681?s=40&v=4)](/vitlibar) [vitlibar](/vitlibar)

vitlibar approved these changes

Assignees

[![@jsc0218](https://avatars.githubusercontent.com/u/3689455?s=40&v=4)](/jsc0218) [jsc0218](/jsc0218)

[![@vitlibar](https://avatars.githubusercontent.com/u/45142681?s=40&v=4)](/vitlibar) [vitlibar](/vitlibar)

Labels

[pr-backports-created](/ClickHouse/ClickHouse/labels/pr-backports-created)
Backport PRs are successfully created, it won't be processed by CI script anymore
[pr-backports-created-cloud](/ClickHouse/ClickHouse/labels/pr-backports-created-cloud)
[pr-bugfix](/ClickHouse/ClickHouse/labels/pr-bugfix)
Pull request with bugfix, not backported by default
[pr-must-backport](/ClickHouse/ClickHouse/labels/pr-must-backport)
Pull request should be backported intentionally. Use this label with great care!
[pr-must-backport-cloud](/ClickHouse/ClickHouse/labels/pr-must-backport-cloud)

Projects

None yet

Milestone

No milestone

Development

Successfully merging this pull request may close these issues.

 [Flush cached result when user switch role](https://github.com/ClickHouse/ClickHouse/issues/58054)

8 participants

[![@rschu1ze](https://avatars.githubusercontent.com/u/100446237?s=52&v=4)](/rschu1ze) [![@robot-ch-test-poll](https://avatars.githubusercontent.com/u/45356221?s=52&v=4)](/robot-ch-test-poll) [![@vitlibar](https://avatars.githubusercontent.com/u/45142681?s=52&v=4)](/vitlibar) [![@jsc0218](https://avatars.githubusercontent.com/u/3689455?s=52&v=4)](/jsc0218) [![@alexey-milovidov](https://avatars.githubusercontent.com/u/18581488?s=52&v=4)](/alexey-milovidov) [![@nikitamikhaylov](https://avatars.githubusercontent.com/u/25705399?s=52&v=4)](/nikitamikhaylov) [![@robot-clickhouse](https://avatars.githubusercontent.com/u/41385210?s=52&v=4)](/robot-clickhouse) [![@robot-ch-test-poll4](https://avatars.githubusercontent.com/u/69306974?s=52&v=4)](/robot-ch-test-poll4)

Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Suggestions cannot be applied on multi-line comments.
Suggestions cannot be applied while the pull request is queued to merge.
Suggestion cannot be applied right now. Please check back later.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.


