
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fblob%2Fbd17ee769e337906c4b1f404861e042ad72fcbfc%2Fsrc%2FInterpreters%2FexecuteQuery.cpp)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FClickHouse%2FClickHouse%2Fblob%2Fbd17ee769e337906c4b1f404861e042ad72fcbfc%2Fsrc%2FInterpreters%2FexecuteQuery.cpp)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=ClickHouse%2FClickHouse)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[ClickHouse](/ClickHouse)
/
**[ClickHouse](/ClickHouse/ClickHouse)**
Public

* [Notifications](/login?return_to=%2FClickHouse%2FClickHouse) You must be signed in to change notification settings
* [Fork
  7k](/login?return_to=%2FClickHouse%2FClickHouse)
* [Star
   38.4k](/login?return_to=%2FClickHouse%2FClickHouse)

* [Code](/ClickHouse/ClickHouse)
* [Issues
  3.7k](/ClickHouse/ClickHouse/issues)
* [Pull requests
  398](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects
  0](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

Additional navigation options

* [Code](/ClickHouse/ClickHouse)
* [Issues](/ClickHouse/ClickHouse/issues)
* [Pull requests](/ClickHouse/ClickHouse/pulls)
* [Discussions](/ClickHouse/ClickHouse/discussions)
* [Actions](/ClickHouse/ClickHouse/actions)
* [Projects](/ClickHouse/ClickHouse/projects)
* [Wiki](/ClickHouse/ClickHouse/wiki)
* [Security](/ClickHouse/ClickHouse/security)
* [Insights](/ClickHouse/ClickHouse/pulse)

## Files

 bd17ee7
## Breadcrumbs

1. [ClickHouse](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc)
2. /[src](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src)
3. /[Interpreters](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters)
/
# executeQuery.cpp

Copy path Blame  Blame
## Latest commit

## History

[History](/ClickHouse/ClickHouse/commits/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp)1538 lines (1307 loc) · 63.9 KB bd17ee7
## Breadcrumbs

1. [ClickHouse](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc)
2. /[src](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src)
3. /[Interpreters](/ClickHouse/ClickHouse/tree/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters)
/
# executeQuery.cpp

Top
## File metadata and controls

* Code
* Blame

1538 lines (1307 loc) · 63.9 KB[Raw](https://github.com/ClickHouse/ClickHouse/raw/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000#include <Common/formatReadable.h>#include <Common/PODArray.h>#include <Common/typeid\_cast.h>#include <Common/ThreadProfileEvents.h>#include <Common/MemoryTrackerBlockerInThread.h>#include <Common/SensitiveDataMasker.h>
#include <Interpreters/AsynchronousInsertQueue.h>#include <Interpreters/Cache/QueryCache.h>#include <IO/WriteBufferFromFile.h>#include <IO/WriteBufferFromVector.h>#include <IO/LimitReadBuffer.h>#include <IO/copyData.h>
#include <QueryPipeline/BlockIO.h>#include <Processors/Transforms/CountingTransform.h>#include <Processors/Transforms/getSourceFromASTInsertQuery.h>
#include <Parsers/ASTIdentifier.h>#include <Parsers/ASTInsertQuery.h>#include <Parsers/ASTLiteral.h>#include <Parsers/ASTSelectQuery.h>#include <Parsers/ASTDropQuery.h>#include <Parsers/ASTCreateQuery.h>#include <Parsers/ASTRenameQuery.h>#include <Parsers/ASTAlterQuery.h>#include <Parsers/ASTSelectWithUnionQuery.h>#include <Parsers/ASTShowProcesslistQuery.h>#include <Parsers/ASTWatchQuery.h>#include <Parsers/ASTTransactionControl.h>#include <Parsers/ASTExplainQuery.h>#include <Parsers/Lexer.h>#include <Parsers/parseQuery.h>#include <Parsers/ParserQuery.h>#include <Parsers/queryNormalization.h>#include <Parsers/queryToString.h>#include <Parsers/formatAST.h>#include <Parsers/toOneLineQuery.h>#include <Parsers/Kusto/ParserKQLStatement.h>#include <Parsers/PRQL/ParserPRQLQuery.h>#include <Parsers/Kusto/parseKQLQuery.h>
#include <Formats/FormatFactory.h>#include <Storages/StorageInput.h>
#include <Access/EnabledQuota.h>#include <Interpreters/ApplyWithGlobalVisitor.h>#include <Interpreters/Context.h>#include <Interpreters/InterpreterFactory.h>#include <Interpreters/InterpreterInsertQuery.h>#include <Interpreters/InterpreterCreateQuery.h>#include <Interpreters/InterpreterSelectQueryAnalyzer.h>#include <Interpreters/InterpreterSetQuery.h>#include <Interpreters/InterpreterTransactionControlQuery.h>#include <Interpreters/NormalizeSelectWithUnionQueryVisitor.h>#include <Interpreters/OpenTelemetrySpanLog.h>#include <Interpreters/ProcessList.h>#include <Interpreters/ProcessorsProfileLog.h>#include <Interpreters/QueryLog.h>#include <Interpreters/ReplaceQueryParameterVisitor.h>#include <Interpreters/SelectIntersectExceptQueryVisitor.h>#include <Interpreters/SelectQueryOptions.h>#include <Interpreters/TransactionLog.h>#include <Interpreters/executeQuery.h>#include <Interpreters/DatabaseCatalog.h>#include <Common/ProfileEvents.h>
#include <IO/CompressionMethod.h>
#include <Processors/Transforms/LimitsCheckingTransform.h>#include <Processors/Transforms/MaterializingTransform.h>#include <Processors/Formats/IOutputFormat.h>#include <Processors/Executors/CompletedPipelineExecutor.h>#include <Processors/Sources/WaitForAsyncInsertSource.h>
#include <base/EnumReflection.h>#include <base/demangle.h>
#include <memory>#include <random>
namespace ProfileEvents{ extern const Event FailedQuery; extern const Event FailedInsertQuery; extern const Event FailedSelectQuery; extern const Event QueryTimeMicroseconds; extern const Event SelectQueryTimeMicroseconds; extern const Event InsertQueryTimeMicroseconds; extern const Event OtherQueryTimeMicroseconds;}
namespace DB{
namespace ErrorCodes{ extern const int QUERY\_CACHE\_USED\_WITH\_NONDETERMINISTIC\_FUNCTIONS; extern const int INTO\_OUTFILE\_NOT\_ALLOWED; extern const int INVALID\_TRANSACTION; extern const int LOGICAL\_ERROR; extern const int NOT\_IMPLEMENTED; extern const int QUERY\_WAS\_CANCELLED; extern const int INCORRECT\_DATA;}
static void checkASTSizeLimits(const IAST & ast, const Settings & settings){ if (settings.max\_ast\_depth) ast.checkDepth(settings.max\_ast\_depth); if (settings.max\_ast\_elements) ast.checkSize(settings.max\_ast\_elements);}
/// Log query into text log (not into system table).static void logQuery(const String & query, ContextPtr context, bool internal, QueryProcessingStage::Enum stage){ if (internal) { LOG\_DEBUG(&Poco::Logger::get("executeQuery"), "(internal) {} (stage: {})", toOneLineQuery(query), QueryProcessingStage::toString(stage)); } else { const auto & client\_info = context->getClientInfo();
 const auto & current\_query\_id = client\_info.current\_query\_id; const auto & initial\_query\_id = client\_info.initial\_query\_id; const auto & current\_user = client\_info.current\_user;
 String comment = context->getSettingsRef().log\_comment; size\_t max\_query\_size = context->getSettingsRef().max\_query\_size;
 if (comment.size() > max\_query\_size) comment.resize(max\_query\_size);
 if (!comment.empty()) comment = fmt::format(" (comment: {})", comment);
 String transaction\_info; if (auto txn = context->getCurrentTransaction()) transaction\_info = fmt::format(" (TID: {}, TIDH: {})", txn->tid, txn->tid.getHash());
 LOG\_DEBUG(&Poco::Logger::get("executeQuery"), "(from {}{}{}){}{} {} (stage: {})", client\_info.current\_address.toString(), (current\_user != "default" ? ", user: " + current\_user : ""), (!initial\_query\_id.empty() && current\_query\_id != initial\_query\_id ? ", initial\_query\_id: " + initial\_query\_id : std::string()), transaction\_info, comment, toOneLineQuery(query), QueryProcessingStage::toString(stage));
 if (client\_info.client\_trace\_context.trace\_id != UUID()) { LOG\_TRACE(&Poco::Logger::get("executeQuery"), "OpenTelemetry traceparent '{}'", client\_info.client\_trace\_context.composeTraceparentHeader()); } }}
/// Call this inside catch block.static void setExceptionStackTrace(QueryLogElement & elem){ /// Disable memory tracker for stack trace. /// Because if exception is "Memory limit (for query) exceed", then we probably can't allocate another one string.
 LockMemoryExceptionInThread lock(VariableContext::Global);
 try { throw; } catch (const std::exception & e) { elem.stack\_trace = getExceptionStackTraceString(e); } catch (...) {} // NOLINT(bugprone-empty-catch)}
/// Log exception (with query info) into text log (not into system table).static void logException(ContextPtr context, QueryLogElement & elem, bool log\_error = true){ String comment; if (!elem.log\_comment.empty()) comment = fmt::format(" (comment: {})", elem.log\_comment);
 /// Message patterns like "{} (from {}){} (in query: {})" are not really informative, /// so we pass elem.exception\_format\_string as format string instead. PreformattedMessage message; message.format\_string = elem.exception\_format\_string;
 if (elem.stack\_trace.empty() || !log\_error) message.text = fmt::format("{} (from {}){} (in query: {})", elem.exception, context->getClientInfo().current\_address.toString(), comment, toOneLineQuery(elem.query)); else message.text = fmt::format( "{} (from {}){} (in query: {}), Stack trace (when copying this message, always include the lines below):\n\n{}", elem.exception, context->getClientInfo().current\_address.toString(), comment, toOneLineQuery(elem.query), elem.stack\_trace);
 if (log\_error) LOG\_ERROR(&Poco::Logger::get("executeQuery"), message); else LOG\_INFO(&Poco::Logger::get("executeQuery"), message);}
static voidaddStatusInfoToQueryLogElement(QueryLogElement & element, const QueryStatusInfo & info, const ASTPtr query\_ast, const ContextPtr context\_ptr){ const auto time\_now = std::chrono::system\_clock::now(); UInt64 elapsed\_microseconds = info.elapsed\_microseconds; element.event\_time = timeInSeconds(time\_now); element.event\_time\_microseconds = timeInMicroseconds(time\_now); element.query\_duration\_ms = elapsed\_microseconds / 1000;
 ProfileEvents::increment(ProfileEvents::QueryTimeMicroseconds, elapsed\_microseconds); if (query\_ast->as<ASTSelectQuery>() || query\_ast->as<ASTSelectWithUnionQuery>()) { ProfileEvents::increment(ProfileEvents::SelectQueryTimeMicroseconds, elapsed\_microseconds); } else if (query\_ast->as<ASTInsertQuery>()) { ProfileEvents::increment(ProfileEvents::InsertQueryTimeMicroseconds, elapsed\_microseconds); } else { ProfileEvents::increment(ProfileEvents::OtherQueryTimeMicroseconds, elapsed\_microseconds); }
 element.read\_rows = info.read\_rows; element.read\_bytes = info.read\_bytes;
 element.written\_rows = info.written\_rows; element.written\_bytes = info.written\_bytes;
 element.memory\_usage = info.peak\_memory\_usage > 0 ? info.peak\_memory\_usage : 0;
 element.thread\_ids = info.thread\_ids; element.peak\_threads\_usage = info.peak\_threads\_usage; element.profile\_counters = info.profile\_counters;
 /// We need to refresh the access info since dependent views might have added extra information, either during /// creation of the view (PushingToViews chain) or while executing its internal SELECT const auto & access\_info = context\_ptr->getQueryAccessInfo(); element.query\_databases.insert(access\_info.databases.begin(), access\_info.databases.end()); element.query\_tables.insert(access\_info.tables.begin(), access\_info.tables.end()); element.query\_columns.insert(access\_info.columns.begin(), access\_info.columns.end()); element.query\_partitions.insert(access\_info.partitions.begin(), access\_info.partitions.end()); element.query\_projections.insert(access\_info.projections.begin(), access\_info.projections.end()); element.query\_views.insert(access\_info.views.begin(), access\_info.views.end());
 const auto & factories\_info = context\_ptr->getQueryFactoriesInfo(); element.used\_aggregate\_functions = factories\_info.aggregate\_functions; element.used\_aggregate\_function\_combinators = factories\_info.aggregate\_function\_combinators; element.used\_database\_engines = factories\_info.database\_engines; element.used\_data\_type\_families = factories\_info.data\_type\_families; element.used\_dictionaries = factories\_info.dictionaries; element.used\_formats = factories\_info.formats; element.used\_functions = factories\_info.functions; element.used\_storages = factories\_info.storages; element.used\_table\_functions = factories\_info.table\_functions;
 element.async\_read\_counters = context\_ptr->getAsyncReadCounters();}
QueryLogElement logQueryStart( const std::chrono::time\_point<std::chrono::system\_clock> & query\_start\_time, const ContextMutablePtr & context, const String & query\_for\_logging, const ASTPtr & query\_ast, const QueryPipeline & pipeline, const std::unique\_ptr<IInterpreter> & interpreter, bool internal, const String & query\_database, const String & query\_table, bool async\_insert){ const Settings & settings = context->getSettingsRef();
 QueryLogElement elem;
 elem.type = QueryLogElementType::QUERY\_START; elem.event\_time = timeInSeconds(query\_start\_time); elem.event\_time\_microseconds = timeInMicroseconds(query\_start\_time); elem.query\_start\_time = timeInSeconds(query\_start\_time); elem.query\_start\_time\_microseconds = timeInMicroseconds(query\_start\_time);
 elem.current\_database = context->getCurrentDatabase(); elem.query = query\_for\_logging; if (settings.log\_formatted\_queries) elem.formatted\_query = queryToString(query\_ast); elem.normalized\_query\_hash = normalizedQueryHash(query\_for\_logging, false); elem.query\_kind = query\_ast->getQueryKind();
 elem.client\_info = context->getClientInfo();
 if (auto txn = context->getCurrentTransaction()) elem.tid = txn->tid;
 bool log\_queries = settings.log\_queries && !internal;
 /// Log into system table start of query execution, if need. if (log\_queries) { /// This check is not obvious, but without it 01220\_scalar\_optimization\_in\_alter fails. if (pipeline.initialized()) { const auto & info = context->getQueryAccessInfo(); elem.query\_databases = info.databases; elem.query\_tables = info.tables; elem.query\_columns = info.columns; elem.query\_partitions = info.partitions; elem.query\_projections = info.projections; elem.query\_views = info.views; }
 if (async\_insert) InterpreterInsertQuery::extendQueryLogElemImpl(elem, context); else if (interpreter) interpreter->extendQueryLogElem(elem, query\_ast, context, query\_database, query\_table);
 if (settings.log\_query\_settings) elem.query\_settings = std::make\_shared<Settings>(context->getSettingsRef());
 elem.log\_comment = settings.log\_comment; if (elem.log\_comment.size() > settings.max\_query\_size) elem.log\_comment.resize(settings.max\_query\_size);
 if (elem.type >= settings.log\_queries\_min\_type && !settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds()) { if (auto query\_log = context->getQueryLog()) query\_log->add(elem); } }
 return elem;}
void logQueryFinish( QueryLogElement & elem, const ContextMutablePtr & context, const ASTPtr & query\_ast, const QueryPipeline & query\_pipeline, bool pulling\_pipeline, std::shared\_ptr<OpenTelemetry::SpanHolder> query\_span, QueryCache::Usage query\_cache\_usage, bool internal){ const Settings & settings = context->getSettingsRef(); auto log\_queries = settings.log\_queries && !internal; auto log\_queries\_min\_type = settings.log\_queries\_min\_type; auto log\_queries\_min\_query\_duration\_ms = settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds(); auto log\_processors\_profiles = settings.log\_processors\_profiles;
 QueryStatusPtr process\_list\_elem = context->getProcessListElement(); if (process\_list\_elem) { /// Update performance counters before logging to query\_log CurrentThread::finalizePerformanceCounters();
 QueryStatusInfo info = process\_list\_elem->getInfo(true, context->getSettingsRef().log\_profile\_events); elem.type = QueryLogElementType::QUERY\_FINISH;
 addStatusInfoToQueryLogElement(elem, info, query\_ast, context);
 if (pulling\_pipeline) { query\_pipeline.tryGetResultRowsAndBytes(elem.result\_rows, elem.result\_bytes); } else /// will be used only for ordinary INSERT queries { auto progress\_out = process\_list\_elem->getProgressOut(); elem.result\_rows = progress\_out.written\_rows; elem.result\_bytes = progress\_out.written\_bytes; }
 auto progress\_callback = context->getProgressCallback(); if (progress\_callback) { Progress p; p.incrementPiecewiseAtomically(Progress{ResultProgress{elem.result\_rows, elem.result\_bytes}}); progress\_callback(p); }
 if (elem.read\_rows != 0) { double elapsed\_seconds = static\_cast<double>(info.elapsed\_microseconds) / 1000000.0; double rows\_per\_second = static\_cast<double>(elem.read\_rows) / elapsed\_seconds; LOG\_DEBUG( &Poco::Logger::get("executeQuery"), "Read {} rows, {} in {} sec., {} rows/sec., {}/sec.", elem.read\_rows, ReadableSize(elem.read\_bytes), elapsed\_seconds, rows\_per\_second, ReadableSize(elem.read\_bytes / elapsed\_seconds)); }
 elem.query\_cache\_usage = query\_cache\_usage;
 if (log\_queries && elem.type >= log\_queries\_min\_type && static\_cast<Int64>(elem.query\_duration\_ms) >= log\_queries\_min\_query\_duration\_ms) { if (auto query\_log = context->getQueryLog()) query\_log->add(elem); } if (log\_processors\_profiles) { if (auto processors\_profile\_log = context->getProcessorsProfileLog()) { ProcessorProfileLogElement processor\_elem; processor\_elem.event\_time = elem.event\_time; processor\_elem.event\_time\_microseconds = elem.event\_time\_microseconds; processor\_elem.initial\_query\_id = elem.client\_info.initial\_query\_id; processor\_elem.query\_id = elem.client\_info.current\_query\_id;
 auto get\_proc\_id = [](const IProcessor & proc) -> UInt64 { return reinterpret\_cast<std::uintptr\_t>(&proc); };
 for (const auto & processor : query\_pipeline.getProcessors()) { std::vector<UInt64> parents; for (const auto & port : processor->getOutputs()) { if (!port.isConnected()) continue; const IProcessor & next = port.getInputPort().getProcessor(); parents.push\_back(get\_proc\_id(next)); }
 processor\_elem.id = get\_proc\_id(\*processor); processor\_elem.parent\_ids = std::move(parents);
 processor\_elem.plan\_step = reinterpret\_cast<std::uintptr\_t>(processor->getQueryPlanStep()); processor\_elem.plan\_group = processor->getQueryPlanStepGroup();
 processor\_elem.processor\_name = processor->getName();
 /// NOTE: convert this to UInt64 processor\_elem.elapsed\_us = static\_cast<UInt32>(processor->getElapsedUs()); processor\_elem.input\_wait\_elapsed\_us = static\_cast<UInt32>(processor->getInputWaitElapsedUs()); processor\_elem.output\_wait\_elapsed\_us = static\_cast<UInt32>(processor->getOutputWaitElapsedUs());
 auto stats = processor->getProcessorDataStats(); processor\_elem.input\_rows = stats.input\_rows; processor\_elem.input\_bytes = stats.input\_bytes; processor\_elem.output\_rows = stats.output\_rows; processor\_elem.output\_bytes = stats.output\_bytes;
 processors\_profile\_log->add(processor\_elem); } } } }
 if (query\_span) { query\_span->addAttribute("db.statement", elem.query); query\_span->addAttribute("clickhouse.query\_id", elem.client\_info.current\_query\_id); query\_span->addAttribute("clickhouse.query\_status", "QueryFinish"); query\_span->addAttributeIfNotEmpty("clickhouse.tracestate", OpenTelemetry::CurrentContext().tracestate); query\_span->addAttributeIfNotZero("clickhouse.read\_rows", elem.read\_rows); query\_span->addAttributeIfNotZero("clickhouse.read\_bytes", elem.read\_bytes); query\_span->addAttributeIfNotZero("clickhouse.written\_rows", elem.written\_rows); query\_span->addAttributeIfNotZero("clickhouse.written\_bytes", elem.written\_bytes); query\_span->addAttributeIfNotZero("clickhouse.memory\_usage", elem.memory\_usage); query\_span->finish(); }}
void logQueryException( QueryLogElement & elem, const ContextMutablePtr & context, const Stopwatch & start\_watch, const ASTPtr & query\_ast, std::shared\_ptr<OpenTelemetry::SpanHolder> query\_span, bool internal, bool log\_error){ const Settings & settings = context->getSettingsRef(); auto log\_queries = settings.log\_queries && !internal; auto log\_queries\_min\_type = settings.log\_queries\_min\_type; auto log\_queries\_min\_query\_duration\_ms = settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds();
 elem.type = QueryLogElementType::EXCEPTION\_WHILE\_PROCESSING; elem.exception\_code = getCurrentExceptionCode(); auto exception\_message = getCurrentExceptionMessageAndPattern(/\* with\_stacktrace \*/ false); elem.exception = std::move(exception\_message.text); elem.exception\_format\_string = exception\_message.format\_string;
 QueryStatusPtr process\_list\_elem = context->getProcessListElement();
 /// Update performance counters before logging to query\_log CurrentThread::finalizePerformanceCounters(); const auto time\_now = std::chrono::system\_clock::now(); elem.event\_time = timeInSeconds(time\_now); elem.event\_time\_microseconds = timeInMicroseconds(time\_now);
 if (process\_list\_elem) { QueryStatusInfo info = process\_list\_elem->getInfo(true, settings.log\_profile\_events, false); addStatusInfoToQueryLogElement(elem, info, query\_ast, context); } else { elem.query\_duration\_ms = start\_watch.elapsedMilliseconds(); }
 elem.query\_cache\_usage = QueryCache::Usage::None;
 if (settings.calculate\_text\_stack\_trace && log\_error) setExceptionStackTrace(elem); logException(context, elem, log\_error);
 /// In case of exception we log internal queries also if (log\_queries && elem.type >= log\_queries\_min\_type && static\_cast<Int64>(elem.query\_duration\_ms) >= log\_queries\_min\_query\_duration\_ms) { if (auto query\_log = context->getQueryLog()) query\_log->add(elem); }
 ProfileEvents::increment(ProfileEvents::FailedQuery); if (query\_ast->as<ASTSelectQuery>() || query\_ast->as<ASTSelectWithUnionQuery>()) ProfileEvents::increment(ProfileEvents::FailedSelectQuery); else if (query\_ast->as<ASTInsertQuery>()) ProfileEvents::increment(ProfileEvents::FailedInsertQuery);
 if (query\_span) { query\_span->addAttribute("db.statement", elem.query); query\_span->addAttribute("clickhouse.query\_id", elem.client\_info.current\_query\_id); query\_span->addAttribute("clickhouse.exception", elem.exception); query\_span->addAttribute("clickhouse.exception\_code", elem.exception\_code); query\_span->finish(); }}
void logExceptionBeforeStart( const String & query\_for\_logging, ContextPtr context, ASTPtr ast, const std::shared\_ptr<OpenTelemetry::SpanHolder> & query\_span, UInt64 elapsed\_millliseconds){ auto query\_end\_time = std::chrono::system\_clock::now();
 /// Exception before the query execution. if (auto quota = context->getQuota()) quota->used(QuotaType::ERRORS, 1, /\* check\_exceeded = \*/ false);
 const Settings & settings = context->getSettingsRef();
 const auto & client\_info = context->getClientInfo();
 /// Log the start of query execution into the table if necessary. QueryLogElement elem;
 elem.type = QueryLogElementType::EXCEPTION\_BEFORE\_START; elem.event\_time = timeInSeconds(query\_end\_time); elem.event\_time\_microseconds = timeInMicroseconds(query\_end\_time); elem.query\_start\_time = client\_info.initial\_query\_start\_time; elem.query\_start\_time\_microseconds = client\_info.initial\_query\_start\_time\_microseconds; elem.query\_duration\_ms = elapsed\_millliseconds;
 elem.current\_database = context->getCurrentDatabase(); elem.query = query\_for\_logging; elem.normalized\_query\_hash = normalizedQueryHash(query\_for\_logging, false);
 // Log query\_kind if ast is valid if (ast) { elem.query\_kind = ast->getQueryKind(); if (settings.log\_formatted\_queries) elem.formatted\_query = queryToString(ast); }
 // We don't calculate databases, tables and columns when the query isn't able to start
 elem.exception\_code = getCurrentExceptionCode(); auto exception\_message = getCurrentExceptionMessageAndPattern(/\* with\_stacktrace \*/ false); elem.exception = std::move(exception\_message.text); elem.exception\_format\_string = exception\_message.format\_string;
 elem.client\_info = context->getClientInfo();
 elem.log\_comment = settings.log\_comment; if (elem.log\_comment.size() > settings.max\_query\_size) elem.log\_comment.resize(settings.max\_query\_size);
 if (auto txn = context->getCurrentTransaction()) elem.tid = txn->tid;
 if (settings.calculate\_text\_stack\_trace) setExceptionStackTrace(elem); logException(context, elem);
 /// Update performance counters before logging to query\_log CurrentThread::finalizePerformanceCounters();
 if (settings.log\_queries && elem.type >= settings.log\_queries\_min\_type && !settings.log\_queries\_min\_query\_duration\_ms.totalMilliseconds()) if (auto query\_log = context->getQueryLog()) query\_log->add(elem);
 if (query\_span) { query\_span->addAttribute("clickhouse.exception\_code", elem.exception\_code); query\_span->addAttribute("clickhouse.exception", elem.exception); query\_span->addAttribute("db.statement", elem.query); query\_span->addAttribute("clickhouse.query\_id", elem.client\_info.current\_query\_id); query\_span->finish(); }
 ProfileEvents::increment(ProfileEvents::FailedQuery);
 if (ast) { if (ast->as<ASTSelectQuery>() || ast->as<ASTSelectWithUnionQuery>()) { ProfileEvents::increment(ProfileEvents::FailedSelectQuery); } else if (ast->as<ASTInsertQuery>()) { ProfileEvents::increment(ProfileEvents::FailedInsertQuery); } }}
static void setQuerySpecificSettings(ASTPtr & ast, ContextMutablePtr context){ if (auto \* ast\_insert\_into = ast->as<ASTInsertQuery>()) { if (ast\_insert\_into->watch) context->setSetting("output\_format\_enable\_streaming", 1); }}
static std::tuple<ASTPtr, BlockIO> executeQueryImpl( const char \* begin, const char \* end, ContextMutablePtr context, QueryFlags flags, QueryProcessingStage::Enum stage, ReadBuffer \* istr){ const bool internal = flags.internal;
 /// query\_span is a special span, when this function exits, it's lifetime is not ended, but ends when the query finishes. /// Some internal queries might call this function recursively by setting 'internal' parameter to 'true', /// to make sure SpanHolders in current stack ends in correct order, we disable this span for these internal queries /// /// This does not have impact on the final span logs, because these internal queries are issued by external queries, /// we still have enough span logs for the execution of external queries. std::shared\_ptr<OpenTelemetry::SpanHolder> query\_span = internal ? nullptr : std::make\_shared<OpenTelemetry::SpanHolder>("query"); if (query\_span && query\_span->trace\_id != UUID{}) LOG\_TRACE(&Poco::Logger::get("executeQuery"), "Query span trace\_id for opentelemetry log: {}", query\_span->trace\_id);
 auto query\_start\_time = std::chrono::system\_clock::now();
 /// Used to set the watch in QueryStatus and the output formats. It is not based on query\_start\_time as that might be based on /// the value passed by the client Stopwatch start\_watch{CLOCK\_MONOTONIC};
 const auto & client\_info = context->getClientInfo();
 if (!internal) { // If it's not an internal query and we don't see an initial\_query\_start\_time yet, initialize it // to current time. Internal queries are those executed without an independent client context, // thus should not set initial\_query\_start\_time, because it might introduce data race. It's also // possible to have unset initial\_query\_start\_time for non-internal and non-initial queries. For // example, the query is from an initiator that is running an old version of clickhouse. // On the other hand, if it's initialized then take it as the start of the query if (client\_info.initial\_query\_start\_time == 0) { context->setInitialQueryStartTime(query\_start\_time); } else { query\_start\_time = std::chrono::time\_point<std::chrono::system\_clock>( std::chrono::microseconds{client\_info.initial\_query\_start\_time\_microseconds}); } }
 assert(internal || CurrentThread::get().getQueryContext()); assert(internal || CurrentThread::get().getQueryContext()->getCurrentQueryId() == CurrentThread::getQueryId());
 const Settings & settings = context->getSettingsRef();
 size\_t max\_query\_size = settings.max\_query\_size; /// Don't limit the size of internal queries or distributed subquery. if (internal || client\_info.query\_kind == ClientInfo::QueryKind::SECONDARY\_QUERY) max\_query\_size = 0;
 ASTPtr ast; String query; String query\_for\_logging; size\_t log\_queries\_cut\_to\_length = context->getSettingsRef().log\_queries\_cut\_to\_length;
 /// Parse the query from string. try { if (settings.dialect == Dialect::kusto && !internal) { ParserKQLStatement parser(end, settings.allow\_settings\_after\_format\_in\_insert);
 /// TODO: parser should fail early when max\_query\_size limit is reached. ast = parseKQLQuery(parser, begin, end, "", max\_query\_size, settings.max\_parser\_depth); } else if (settings.dialect == Dialect::prql && !internal) { ParserPRQLQuery parser(max\_query\_size, settings.max\_parser\_depth); ast = parseQuery(parser, begin, end, "", max\_query\_size, settings.max\_parser\_depth); } else { ParserQuery parser(end, settings.allow\_settings\_after\_format\_in\_insert); /// TODO: parser should fail early when max\_query\_size limit is reached. ast = parseQuery(parser, begin, end, "", max\_query\_size, settings.max\_parser\_depth); }
 const char \* query\_end = end; if (const auto \* insert\_query = ast->as<ASTInsertQuery>(); insert\_query && insert\_query->data) query\_end = insert\_query->data;
 bool is\_create\_parameterized\_view = false; if (const auto \* create\_query = ast->as<ASTCreateQuery>()) is\_create\_parameterized\_view = create\_query->isParameterizedView(); else if (const auto \* explain\_query = ast->as<ASTExplainQuery>()) { assert(!explain\_query->children.empty()); if (const auto \* create\_of\_explain\_query = explain\_query->children[0]->as<ASTCreateQuery>()) is\_create\_parameterized\_view = create\_of\_explain\_query->isParameterizedView(); }
 /// Replace ASTQueryParameter with ASTLiteral for prepared statements. /// Even if we don't have parameters in query\_context, check that AST doesn't have unknown parameters bool probably\_has\_params = find\_first\_symbols<'{'>(begin, end) != end; if (!is\_create\_parameterized\_view && probably\_has\_params) { ReplaceQueryParameterVisitor visitor(context->getQueryParameters()); visitor.visit(ast); if (visitor.getNumberOfReplacedParameters()) query = serializeAST(\*ast); else query.assign(begin, query\_end); } else { /// Copy query into string. It will be written to log and presented in processlist. If an INSERT query, string will not include data to insertion. query.assign(begin, query\_end); }
 /// Wipe any sensitive information (e.g. passwords) from the query. /// MUST go before any modification (except for prepared statements, /// since it substitute parameters and without them query does not contain /// parameters), to keep query as-is in query\_log and server log. if (ast->hasSecretParts()) { /// IAST::formatForLogging() wipes secret parts in AST and then calls wipeSensitiveDataAndCutToLength(). query\_for\_logging = ast->formatForLogging(log\_queries\_cut\_to\_length); } else { query\_for\_logging = wipeSensitiveDataAndCutToLength(query, log\_queries\_cut\_to\_length); } } catch (...) { /// Anyway log the query. if (query.empty()) query.assign(begin, std::min(end - begin, static\_cast<ptrdiff\_t>(max\_query\_size)));
 query\_for\_logging = wipeSensitiveDataAndCutToLength(query, log\_queries\_cut\_to\_length); logQuery(query\_for\_logging, context, internal, stage);
 if (!internal) logExceptionBeforeStart(query\_for\_logging, context, ast, query\_span, start\_watch.elapsedMilliseconds()); throw; }
 /// Avoid early destruction of process\_list\_entry if it was not saved to `res` yet (in case of exception) ProcessList::EntryPtr process\_list\_entry; BlockIO res; auto implicit\_txn\_control = std::make\_shared<bool>(false); String query\_database; String query\_table;
 auto execute\_implicit\_tcl\_query = [implicit\_txn\_control](const ContextMutablePtr & query\_context, ASTTransactionControl::QueryType tcl\_type) { /// Unset the flag on COMMIT and ROLLBACK SCOPE\_EXIT({ if (tcl\_type != ASTTransactionControl::BEGIN) \*implicit\_txn\_control = false; });
 ASTPtr tcl\_ast = std::make\_shared<ASTTransactionControl>(tcl\_type); InterpreterTransactionControlQuery tc(tcl\_ast, query\_context); tc.execute();
 /// Set the flag after successful BIGIN if (tcl\_type == ASTTransactionControl::BEGIN) \*implicit\_txn\_control = true; };
 try { if (auto txn = context->getCurrentTransaction()) { chassert(txn->getState() != MergeTreeTransaction::COMMITTING); chassert(txn->getState() != MergeTreeTransaction::COMMITTED); if (txn->getState() == MergeTreeTransaction::ROLLED\_BACK && !ast->as<ASTTransactionControl>() && !ast->as<ASTExplainQuery>()) throw Exception( ErrorCodes::INVALID\_TRANSACTION, "Cannot execute query because current transaction failed. Expecting ROLLBACK statement"); }
 /// Interpret SETTINGS clauses as early as possible (before invoking the corresponding interpreter), /// to allow settings to take effect. InterpreterSetQuery::applySettingsFromQuery(ast, context);
 if (auto \* insert\_query = ast->as<ASTInsertQuery>()) insert\_query->tail = istr;
 setQuerySpecificSettings(ast, context);
 /// There is an option of probabilistic logging of queries. /// If it is used - do the random sampling and "collapse" the settings. /// It allows to consistently log queries with all the subqueries in distributed query processing /// (subqueries on remote nodes will receive these "collapsed" settings) if (!internal && settings.log\_queries && settings.log\_queries\_probability < 1.0) { std::bernoulli\_distribution should\_write\_log{settings.log\_queries\_probability};
 context->setSetting("log\_queries", should\_write\_log(thread\_local\_rng)); context->setSetting("log\_queries\_probability", 1.0); }
 if (const auto \* query\_with\_table\_output = dynamic\_cast<const ASTQueryWithTableAndOutput \*>(ast.get())) { query\_database = query\_with\_table\_output->getDatabase(); query\_table = query\_with\_table\_output->getTable(); }
 logQuery(query\_for\_logging, context, internal, stage);
 /// Propagate WITH statement to children ASTSelect. if (settings.enable\_global\_with\_statement) { ApplyWithGlobalVisitor().visit(ast); }
 { SelectIntersectExceptQueryVisitor::Data data{settings.intersect\_default\_mode, settings.except\_default\_mode}; SelectIntersectExceptQueryVisitor{data}.visit(ast); }
 { /// Normalize SelectWithUnionQuery NormalizeSelectWithUnionQueryVisitor::Data data{settings.union\_default\_mode}; NormalizeSelectWithUnionQueryVisitor{data}.visit(ast); }
 /// Check the limits. checkASTSizeLimits(\*ast, settings);
 /// Put query to process list. But don't put SHOW PROCESSLIST query itself. if (!internal && !ast->as<ASTShowProcesslistQuery>()) { /// processlist also has query masked now, to avoid secrets leaks though SHOW PROCESSLIST by other users. process\_list\_entry = context->getProcessList().insert(query\_for\_logging, ast.get(), context, start\_watch.getStart()); context->setProcessListElement(process\_list\_entry->getQueryStatus()); }
 /// Load external tables if they were provided context->initializeExternalTablesIfSet();
 auto \* insert\_query = ast->as<ASTInsertQuery>(); bool async\_insert\_enabled = settings.async\_insert;
 /// Resolve database before trying to use async insert feature - to properly hash the query. if (insert\_query) { if (insert\_query->table\_id) insert\_query->table\_id = context->resolveStorageID(insert\_query->table\_id); else if (auto table = insert\_query->getTable(); !table.empty()) insert\_query->table\_id = context->resolveStorageID(StorageID{insert\_query->getDatabase(), table});
 if (insert\_query->table\_id) if (auto table = DatabaseCatalog::instance().tryGetTable(insert\_query->table\_id, context)) async\_insert\_enabled |= table->areAsynchronousInsertsEnabled(); }
 if (insert\_query && insert\_query->select) { /// Prepare Input storage before executing interpreter if we already got a buffer with data. if (istr) { ASTPtr input\_function; insert\_query->tryFindInputFunction(input\_function); if (input\_function) { StoragePtr storage = context->executeTableFunction(input\_function, insert\_query->select->as<ASTSelectQuery>()); auto & input\_storage = dynamic\_cast<StorageInput &>(\*storage); auto input\_metadata\_snapshot = input\_storage.getInMemoryMetadataPtr(); auto pipe = getSourceFromASTInsertQuery( ast, true, input\_metadata\_snapshot->getSampleBlock(), context, input\_function); input\_storage.setPipe(std::move(pipe)); } } } else { /// reset Input callbacks if query is not INSERT SELECT context->resetInputCallbacks(); }
 StreamLocalLimits limits; std::shared\_ptr<const EnabledQuota> quota; std::unique\_ptr<IInterpreter> interpreter;
 bool async\_insert = false; auto \* queue = context->getAsynchronousInsertQueue(); auto \* logger = &Poco::Logger::get("executeQuery");
 if (insert\_query && async\_insert\_enabled) { String reason;
 if (!queue) reason = "asynchronous insert queue is not configured"; else if (insert\_query->select) reason = "insert query has select"; else if (insert\_query->hasInlinedData()) async\_insert = true;
 if (!reason.empty()) LOG\_DEBUG(logger, "Setting async\_insert=1, but INSERT query will be executed synchronously (reason: {})", reason); }
 bool quota\_checked = false; std::unique\_ptr<ReadBuffer> insert\_data\_buffer\_holder;
 if (async\_insert) { if (context->getCurrentTransaction() && settings.throw\_on\_unsupported\_query\_inside\_transaction) throw Exception(ErrorCodes::NOT\_IMPLEMENTED, "Async inserts inside transactions are not supported"); if (settings.implicit\_transaction && settings.throw\_on\_unsupported\_query\_inside\_transaction) throw Exception(ErrorCodes::NOT\_IMPLEMENTED, "Async inserts with 'implicit\_transaction' are not supported");
 quota = context->getQuota(); if (quota) { quota\_checked = true; quota->used(QuotaType::QUERY\_INSERTS, 1); quota->used(QuotaType::QUERIES, 1); quota->checkExceeded(QuotaType::ERRORS); }
 auto result = queue->pushQueryWithInlinedData(ast, context);
 if (result.status == AsynchronousInsertQueue::PushResult::OK) { if (settings.wait\_for\_async\_insert) { auto timeout = settings.wait\_for\_async\_insert\_timeout.totalMilliseconds(); auto source = std::make\_shared<WaitForAsyncInsertSource>(std::move(result.future), timeout); res.pipeline = QueryPipeline(Pipe(std::move(source))); }
 const auto & table\_id = insert\_query->table\_id; if (!table\_id.empty()) context->setInsertionTable(table\_id); } else if (result.status == AsynchronousInsertQueue::PushResult::TOO\_MUCH\_DATA) { async\_insert = false; insert\_data\_buffer\_holder = std::move(result.insert\_data\_buffer);
 if (insert\_query->data) { /// Reset inlined data because it will be /// available from tail read buffer. insert\_query->end = insert\_query->data; insert\_query->data = nullptr; }
 insert\_query->tail = insert\_data\_buffer\_holder.get(); LOG\_DEBUG(logger, "Setting async\_insert=1, but INSERT query will be executed synchronously because it has too much data"); } }
 QueryCachePtr query\_cache = context->getQueryCache(); const bool can\_use\_query\_cache = query\_cache != nullptr && settings.use\_query\_cache && !internal[View remainder of file in raw view](https://github.com/ClickHouse/ClickHouse/raw/bd17ee769e337906c4b1f404861e042ad72fcbfc/src/Interpreters/executeQuery.cpp)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

