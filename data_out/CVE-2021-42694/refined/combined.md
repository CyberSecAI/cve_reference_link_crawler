=== Content from www.unicode.org_349390cd_20250111_094136.html ===


| [[Unicode]](http://www.unicode.org)  [Technical Reports](http://www.unicode.org/reports/) |
| --- |
|  |

## Unicode Technical Report #36

# Unicode Security Considerations

| Editors | [Mark Davis](https://plus.google.com/114199149796022210033?rel=author) (markdavis@google.com), Michel Suignard (michel@suignard.com) |
| --- | --- |
| Date | 2014-09-19 |
| This Version | <http://www.unicode.org/reports/tr36/tr36-15.html> |
| Previous Version | <http://www.unicode.org/reports/tr36/tr36-13.html> |
| Latest Version | <http://www.unicode.org/reports/tr36/> |
| Latest Proposed Update | <http://www.unicode.org/reports/tr36/proposed.html> |
| Revision | [15](#Modifications) |

### *Summary*

*Because Unicode contains such a large number of characters and
incorporates the varied writing systems of the world, incorrect
usage can expose programs or systems to possible security attacks.
This is especially important as more and more products are
internationalized. This document describes some of the security
considerations that programmers, system analysts, standards
developers, and users should take into account, and provides
specific recommendations to reduce the risk of problems.*

### *Status*

*This document has been reviewed by Unicode members and other
interested parties, and has been approved for publication by the Unicode
Consortium. This is a stable document and may be used as reference
material or cited as a normative reference by other specifications.*

> ***A Unicode Technical Report (UTR)** contains informative
> material. Conformance to the Unicode Standard does not imply
> conformance to any UTR. Other specifications, however, are free to
> make normative references to a UTR.*

*Please submit corrigenda and other comments with the online
reporting form [[Feedback](#Feedback)]. Related
information that is useful in understanding this document is found
in the [References](#References). For the latest version
of the Unicode Standard see [[Unicode](#Unicode)]. For a
list of current Unicode Technical Reports see [[Reports](#Reports)].
For more information about versions of the Unicode Standard, see [[Versions](#Versions)].*

### *Contents*

* 1 [Introduction](#Introduction)
  + 1.1 [Structure](#Structure)
* 2 [Visual Security Issues](#visual_spoofing)
  + 2.1 [Internationalized
    Domain Names](#international_domain_names)
    - [Table 1. Safe Domain
      Names](#TableSafeDomainNames)
  + 2.2 [Mixed-Script
    Spoofing](#Mixed_Script_Spoofing)
    - [Table 2.
      Mixed-Script Spoofing](#TableMixedScriptSpoofing)
  + 2.3 [Single-Script
    Spoofing](#Single_Script_Spoofing)
    - [Table 3.
      Single-Script Spoofing](#TableSingleScriptSpoofing)
    - [Table 4.
      Combining Mark Order Spoofing](#TableCombiningMarkOrderSpoofing)
  + 2.4 [Inadequate
    Rendering Support](#Inadequate_Rendering_Support)
    - [Table 5.
      Inadequate Rendering Support](#TableInadequateRenderingSupport)
    - 2.4.1 [Malicious
      Rendering](#Malicious_Rendering)
  + 2.5 [Bidirectional
    Text Spoofing](#Bidirectional_Text_Spoofing)
    - [Table 6. Bidi Examples](#TableBidiExamples)
    - 2.5.1 [Glyphs in Complex
      Scripts](#Complex_Scripts)
      * [Table 7. Glyphs in
        Complex Scripts](#TableComplexScripts)
  + 2.6 [Syntax Spoofing](#Syntax_Spoofing)
    - [Table 8. Syntax
      Spoofing](#TableSyntaxSpoofing)
    - 2.6.1 [Missing Glyphs](#Missing_Glyphs)
  + 2.7 [Numeric Spoofs](#Numeric_Spoofs)
  + 2.8 [IDNA Ambiguity](#IDNA_Ambiguity)
    - 2.8.1 [Punycode Spoofs](#Punycode_Spoofs)
      * [Table 8a.
        Punycode Spoofing](#TablePunycodeSpoofing)
  + 2.9 [Techniques](#Techniques)
    - 2.9.1 [Casefolded
      Format](#Case_Folded_Format)
    - 2.9.2 [Mapping and
      Prohibition](#Mapping_and_Prohibition)
  + 2.10 [Restriction
    Levels and Alerts](#Security_Levels_and_Alerts)
    - 2.10.1 [Backward
      Compatibility](#Backwards_Compatibility)
  + 2.11 [Recommendations](#Visual_Spoofing_Recommendations)
    - 2.11.1 [Recommendations
      for End-Users](#User_Recommendations)
    - 2.11.2 [Recommendations
      for Programmers](#Recommendations_General)
    - 2.11.3 [Recommendations
      for User Agents](#Recommendations_User_Agents)
    - 2.11.4 [Recommendations
      for Registries](#Recommendations_Registries)
    - 2.11.5 [Registrar
      Recommendations](#Recommendations_Registrars)
* 3 [Non-Visual Security
  Issues](#Canonical_Represenation)
  + 3.1 [UTF-8 Exploits](#UTF-8_Exploit)
    - 3.1.1 [Ill-Formed
      Subsequences](#Ill-Formed_Subsequences)
    - 3.1.2 [Substituting
      for Ill-Formed Subsequences](#Substituting_for_Ill_Formed_Subsequences)
  + 3.2 [Text Comparison
    (Sorting, Searching, Matching)](#Text_Comparison)
  + 3.3 [Buffer Overflows](#Buffer_Overflows)
    - [Table 9.
      Maximum Expansion Factors](#TableMaximumExpansionFactors)
  + 3.4 [Property
    and Character Stability](#Property_and_Character_Stability)
  + 3.5 [Deletion of
    Code Points](#Deletion_of_Noncharacters)
  + 3.6 [Secure
    Encoding Conversion](#SecureEncodingConversion)
    - 3.6.1 [Illegal
      Input Byte Sequences](#Illegal_Input_Byte_Sequences)
    - 3.6.2 [Some
      Output For All Input](#Some_Output_For_All_Input)
  + 3.7 [Enabling
    Lossless Conversion](#EnablingLosslessConversion)
    - 3.7.1 [PEP 383
      Approach](#TOC-PEP-383-Approach)
    - 3.7.2 [Notation](#TOC-Notation)
    - 3.7.3 [Security](#TOC-Security)
    - 3.7.4 [Interoperability](#TOC-Interoperability)
    - 3.7.5 [Safely
      Converting to Bytes](#TOC-Safely-Converting-to-Bytes)
  + 3.8 [Idempotence](#TOC-Idempotence)
* [Appendix A Script Icons](#Missing_Glyph_Icons)
  + [Table 10. Sample
    Script Icons](#TableSampleScriptIcons)
* [Appendix B
  Language-Based Security](#Language_Based_Security)
  + [Table 11. CLDR
    Script Mappings](#TableCLDRScriptMappings)
* [Acknowledgments](#Acknowledgments)
* [References](#References)
* [Modifications](#Modifications)

---

## [1 Introduction](#Introduction)

The Unicode Standard represents a very significant advance over all
previous methods of encoding characters. For the first time, all of
the world's characters can be represented in a uniform manner,
making it feasible for the vast majority of programs to be *globalized:*
built to handle any language in the world.

In many ways, the use of Unicode makes programs much more
robust and secure. When systems used a hodge-podge of different
charsets for representing characters, there were security and
corruption problems that resulted from differences between those
charsets, or from the way in which programs converted to and from
them.

However, because Unicode contains such a large number of
characters, and incorporates the varied writing systems of the world,
incorrect usage can expose programs or systems to possible security
attacks. This document describes some of the security considerations
that programmers, system analysts, standards developers, and users
should take into account.

For example, consider visual spoofing, where a similarity in
visual appearance fools a user and causes him or her to take unsafe
actions.

> Suppose that the user gets an email notification about an apparent
> problem in their Citibank account. Security-savvy users realize that
> it might be a spoof; the HTML email might be presenting the URL http://citibank.com/...
> visually, but might be hiding the *real* URL. They realize that
> even what shows up in the status bar might be a lie, because clever
> Javascript or ActiveX can work around that. (And users are likely to
> have these turned on, unless they know to turn them off.) They click
> on the link, and carefully examine the browser's address box to
> make sure that it is actually going to http://citibank.com/....
> They see that it is, and use their password. However, what they saw
> was wrong—it is actually
> going to a spoof site with a fake "citibank.com", using
> the Cyrillic letter that looks precisely like a 'c'. They
> use the site without suspecting, and the password ends up
> compromised.

This problem is not new to Unicode: it was possible to spoof even
with ASCII characters alone. For example, "inteI.com" uses a capital I instead of
an L. The infamous example here involves "paypaI.com":

> ... Not only was "Paypai.com"
> very convincing, but the scam artist even goes one step further. He
> or she is apparently emailing PayPal customers, saying they have a
> large payment waiting for them in their account.
>
> The message then offers up a link, urging
> the recipient to claim the funds. However, the URL that is displayed
> for the unwitting victim uses a capital "i" (I), which
> looks just like a lowercase "L" (l), in many computer
> fonts. ...
>
> *(for details, see the [Unicode
> Security FAQ](http://www.unicode.org/faq/security.html))*

While some browsers prevent this spoof by lowercasing domain
names, others do not.

Thus to a certain extent, the new forms of visual spoofing
available with Unicode are a matter of degree and not kind. However,
because of the very large number of Unicode characters (over 107,000
in the current version), the number of opportunities for visual
spoofing is significantly larger than with a restricted character set
such as ASCII.

### 1.1 [Structure](#Structure)

This document is organized into two sections: visual security issues
and non-visual security issues. Each section presents background
information on the kinds of problems that can occur, and lists
specific recommendations for reducing the risk of such problems. For
background information, see the [References](#References)
and the Unicode FAQ on *Security Issues* [[FAQSec](#FAQSec)].

A URL is technically a type of uniform resource
identifier (URI). In many technical documents and verbal discussions,
however, URL is often used as a synonym for URI or IRI, and this is
not considered a problem. That practice is followed here.

## [2 Visual Security Issues](#visual_spoofing)

Visual spoofs depend on the use of *visually confusable*
strings: two different strings of Unicode characters whose appearance
in common fonts in small sizes at typical screen resolutions is
sufficiently close that people easily mistake one for the other.

There are no hard-and-fast rules for visual confusability: many
characters look like others when used with sufficiently small sizes.
"Small sizes at screen resolutions" means fonts whose
ascent plus descent is from 9 to 12 pixels for most scripts, and
somewhat larger for scripts, such as Japanese, where the users
typically have larger sizes. Confusability also depends on the style
of the font: with a traditional Hebrew style, many characters are
only distinguishable by fine differences which may be lost at small
sizes. In some cases sequences of characters can be used to spoof:
for example, "rn" ("r" followed by "n")
is visually confusable with "m" in many sans-serif fonts.

Where two different strings can always be represented by the same
sequence of glyphs, those strings are called *homographs*. For
example, "AB" in Latin and "AB" in Greek are
homographs. Spoofing is not dependent on just homographs; if the
visual appearance is close enough at small sizes or in the most
common fonts, that can be sufficient to cause problems. Some people
use the term *homograph* broadly, encompassing all visually
confusable strings.

Two characters with similar or identical glyph shapes are not
visually confusable if the positioning of the respective shapes is
sufficiently different. For example, foo·com (using the hyphenation point
instead of the period) should be distinguishable from foo.com by the
positioning of the dot.

It is important to be aware that identifiers are
special-purpose strings used for identification, strings that are
deliberately limited to particular repertoires for that purpose.
Exclusion of characters from identifiers does not affect the general
use of those characters, such as within documents.

The remainder of this section is concerned with identifiers that can
be confused by ordinary users at typical sizes and screen
resolutions. For examples of visually confusable characters, see *Section
4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

There is another kind of confusability, where the goal is not to
"fool the user", but rather to "slip by a
gatekeeper". For example, consider a spam email for
"Ⓥ\*ⓘ\*ⓐ\*ⓖ\*ⓡ\*ⓐ". In this case, the end user isn't fooled by
the characters into thinking that ⓐ is a regular "a". The
real goal is to fool mechanical gatekeepers, such as spam detectors,
while being recognizable to an end user. Collection of data for
detecting gatekeeper-confusable strings is not currently a goal for *UTS
#39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

It is also important to recognize that the use of visually confusable
characters in spoofing is often overstated. Moreover, confusable
characters account for a small proportion of phishing problems: most
are cases like "secure-wellsfargo.com". For more information, see the
[Unicode
Security FAQ](http://www.unicode.org/faq/security.html).

### 2.1 [Internationalized Domain Names](#international_domain_names)

Visual spoofing is an especially important subject given the
introduction in 2003 of Internationalized Domain Names (IDN) [[IDNA2003](#IDNA2003)]. There is a natural desire for people
to see domain names in their own languages and writing systems;
English speakers can understand this if they consider what it would
be like if they always had to type Web addresses with Japanese
characters. IDNs represent a very significant advance for most people
in the world. However, the larger repertoire of characters results in
more opportunities for spoofing. Proper implementation in browsers
and other programs is required to minimize security risks while still
allowing for effective use of non-ASCII characters.

Internationalized Domain Names are, of course, not the only cases
where visual spoofing can occur. One example is a message offering to
install software from "IBM", authenticated with a
certificate in which the "М" character
happens to be the Russian (Cyrillic) character that looks precisely
like the English "M". Wherever strings are used as
identifiers, this kind of spoofing is possible.

IDNs provide a good starting point for a discussion of visual
spoofing, and are the focus of the next part of this section. In
2010, there was a update to [[IDNA2003](#IDNA2003)] called
[[IDNA2008](#IDNA2008)]. Because the concepts and
recommendations discussed here can be generalized to the use of other
types of identifiers, both [[IDNA2003](#IDNA2003)] and [[IDNA2008](#IDNA2008)] will be used in examples. For
background information on identifiers, see UAX #31: *Identifier
and Pattern Syntax* [[UAX31](#UAX31)]. For more
information on how to handle international domain names in a
compatible fashion, see *UTS #46: Unicode IDNA Compatibility
Processing* [[UTS46](#UTS46)].

Fortunately the design of IDN prevents a huge number of spoofing
attacks. All conformant users of [[IDNA2003](#IDNA2003)]
are required to process domain names to convert what are called *[compatibility-equivalent](http://www.unicode.org/glossary/#compatibility_equivalent)* characters into a unique form using a process called compatibility
normalization (NFKC)—for more information on this, see [[UAX15](#UAX15)]. This processing eliminates most
possibilities for visual spoofing by mapping away a large number of
visually confusable characters and sequences. For example, characters
like the halfwidth Japanese *katakana* character ｶ are converted to the
regular character カ, and single ligature characters like  "ﬁ" to the
sequence of regular characters "fi". Unicode contains the
"ä"
(a-umlaut) character, but also contains a free-standing umlaut
("  ̈")
which can be used in combination with any character, including an
"a". The compatibility normalization will convert any
sequence of "a" plus "  ̈" into the
regular "ä".
([[IDNA2008](#IDNA2008)] disallows these compatibility
characters as output, but allows them to be mapped on input.)

Thus someone cannot spoof an *a-umlaut* with *a + umlaut*;
it simply results in the same domain name. See the example in *Table
1, [Safe Domain Names](#TableSafeDomainNames)*. The String column shows the actual characters; the UTF-16 column
shows the underlying encoding and the Punycode column shows the
internal format of the domain name. This is the result of applying
the ToASCII() operation [[RFC3490](#RFC3490)] to the
original IDN, which is the way this IDN is stored and queried in the
DNS (Domain Name System).

Table 1. [Safe Domain Names](#TableSafeDomainNames)

|  | String | UTF-16 | Punycode | Comments |
| 1a | ät.com | 0061 0308 0074 002E 0063 006F 006D | xn--t-zfa.com | Uses the decomposed form, a plus umlaut |
| 1b | ät.com | 00E4 0074 002E 0063 006F 006D | xn--t-zfa.com | The decomposed form ends up being identical to the composed form, in IDNA |

Similarly, for most
scripts, two accents that do not interact typographically are put
into a determinate order when the text is normalized. Thus the sequence
<x, dot\_above, dot\_below> is reordered as <x, dot\_below,
dot\_above>. This ensures that the two sequences that look identical
(ẋ̣ and ẋ̣̇) have the same representation.

**Note:** The demo at [[IDN-Demo](#IDN-Demo)] can be
used to demonstrate the results of processing different domain names.
That demo was also used to get the Punycode values shown in *Table
1, [Safe Domain Names](#TableSafeDomainNames)*.

The [[IDNA2003](#IDNA2003)] and[[UTS46](#UTS46)]
processing also removes case distinctions by performing a *casefolding*
to reduce characters to a lowercase form*.* This is helps avoid
spoofing problems, because characters are generally more distinctive
in their lowercase forms. That means that implementers can focus on
just dealing with the lowercase characters. There are some cases
where people will want to see certain special differences preserved
in display. For more information, and information about characters
allowed in IDN, see *UTS #46: Unicode IDNA Compatibility
Processing* [[UTS46](#UTS46)].

> **Note**: Users expect diacritical marks to distinguish domain
> names. For example, the domain names "resume.com" and
> "résumé.com" are (and should be) distinguished. In
> languages where the spelling may allow certain words with and
> without diacritics, registrants would have to register two or more
> domain names to cover user expectations (just as one may register
> both "analyze.com" and "analyse.com" to cover
> variant spellings). The registry can support this automatically by
> using a technique known as "bundling".

Although normalization and casefolding prevent many possible
spoofing attacks, visual spoofing can still occur with many IDNs.
This poses the question of which parts of the infrastructure using
and supporting domain names are best suited to minimize possible
spoofing attacks.

Some of the problems of visual spoofing can be best handled on the
registry side, while others can be best handled on the side of the *user
agent*: browsers, emailers, and other programs that display and
process URLs. The registry has the most data available about
alternative registered names, and can process that information the
most efficiently at the time of registration, using policies to
reduce visual spoofing. For example, given the method described in *Section
4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)], the registry can easily determine if a
proposed registration could be visually confused with an existing
one; that determination is much more difficult for user agents
because of the sheer number of combinations that they would have to
check.

However, there are certain issues much more easily addressed by
the user agent:

* the user agent has more control over the display of
  characters, which is crucial to spoofing
* there are legitimate cases of visually confusable characters
  that one may want to allow *after* alerting the user, such as
  single-script confusables discussed below
* one cannot depend on all registries being responsive to
  security issues
* due to the decentralized nature of DNS, a registry for a
  domain does not control subdomains: thus the registry for a
  top-level domain (TLD) like ".com" may not control the
  labels accepted by a subdomain like "blogspot.com".

Thus the problem of visual spoofing is most effectively
addressed by a combination of strategies involving user agents and
registries.

### **2.2 [Mixed-Script Spoofing](#Mixed_Script_Spoofing)**

Visually confusable characters are not usually unified across
scripts. Thus a Greek *omicron* is encoded as a different
character from the Latin "o", even though it is usually
identical or nearly identical in appearance. There are good reasons
for this: often the characters were separate in legacy encodings, and
preservation of those distinctions was necessary for data to be
converted to Unicode and back without loss. Moreover, the characters
generally have very different behavior: two visually confusable
characters may be different in casing behavior, in category (letter
versus number), or in numeric value. After all, ASCII does not unify
lowercase letter l and digit 1, even though those are visually
confusable. (Many fonts always distinguish them, but many others do
not.) Encoding the Cyrillic character б (corresponding to the letter
"b") by using the numeral 6, would clearly have been a
mistake, even though they are visually confusable.

However, the existence of visually confusable characters across
scripts offers numerous opportunities for spoofing. For example, a
domain name can be spoofed by using a Greek omicron instead of an
'o', as in example 1a in *Table 2, [Mixed-Script Spoofing](#TableMixedScriptSpoofing)*.

Table 2. [Mixed-Script Spoofing](#TableMixedScriptSpoofing)

|  | String | UTF-16 | Punycode | Comments |
| 1a | tοp.com | 0074 03BF 0070 002E 0063 006F 006D | xn--tp-jbc.com | Uses a Greek omicron in place of the o |
| 1b | tοp.com | 0074 006F 0070 002E 0063 006F 006D | top.com |  |

There are many legitimate uses of mixed scripts. For example, it is
quite common to mix English words (with Latin characters) in other
languages, including languages using non-Latin scripts. For example,
one could have XML-документы.com (which would be a site for "XML
documents" in Russian). Even in English, legitimate product or
organization names may contain non-Latin characters, such as Ωmega,
Teχ, Toys-Я-Us, or HλLF-LIFE. The lack of IDNs in the past has also
led to the usage in some registries (such as the .ru top-level
domain) where Latin characters have been used to create
pseudo-Cyrillic names in the .ru (Russian) top-level domain. For
example, see http://caxap.ru/ (сахар means sugar in Russian).

For information on detecting mixed scripts, see *Section 5, [Mixed
Script Detection](http://www.unicode.org/reports/tr39/#Mixed_Script_Detection)*of **UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].*

Cyrillic, Latin, and Greek represent special challenges, because the
number of common glyphs shared between them is so high, as can be
seen from *Section 4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)]. It may be possible to compose an entire
domain name (except the top-level domain) in Cyrillic using letters
that will be essentially always identical in form to Latin letters,
such as "scope.com": with "scope" in Cyrillic
looking just like "scope" in Latin. Such spoofs are called
*whole-script spoofs,* and the strings that cause the problem
are correspondingly called *whole-script confusables.*

### 2.3 [Single-Script Spoofing](#Single_Script_Spoofing)

Spoofing with characters entirely within one script, or using
characters that are common across scripts (such as numbers), is
called *single-script spoofing*, and the strings that cause it
are correspondingly called *single-script confusables*. While
compatibility normalization and mixed-script detection can handle the
majority of spoofing cases, they do not handle single-script
confusables. Especially at the smaller font sizes in the context of
an address bar, any visual confusables within a single script can be
used in spoofing. Importantly, these problems can be illustrated with
common, widely available fonts on widely available operating
systems—the problems are not specific to any single vendor.

Consider the examples in *Table 3, [Single-Script Spoofing](#TableSingleScriptSpoofing)*, all in
the same script. In each numbered case, the strings will look
identical or nearly identical in most browsers.

Table 3. [Single-Script Spoofing](#TableSingleScriptSpoofing)

|  | String | UTF-16 | Punycode | Comments |
| 1a | a‐b.com | 0061 2010 0062 002E 0063 006F 006D | xn--ab-v1t.com | Uses a real hyphen, instead of the ASCII hyphen-minus |
| 1b | a-b.com | 0061 002D 0062 002E 0063 006F 006D | a-b.com |  |
|  | | | | |
| 2a | so̷s.com | 0073 006F 0337 0073 002E 0063 006F 006D | xn--sos-rjc.com | Uses o + combining slash |
| 2b | søs.com | 0073 00F8 0073 002E 0063 006F 006D | xn--ss-lka.com |  |
|  | | | | |
| 3a | z̵o.com | 007A 0335 006F 002E 0063 006F 006D | xn--zo-pyb.com | Uses z + combining bar |
| 3b | ƶo.com | 01B6 006F 002E 0063 006F 006D | xn--o-zra.com |  |
|  | | | | |
| 4a | an͂o.com | 0061 006E 0342 006F 002E 0063 006F 006D | xn--ano-0kc.com | Uses n + greek perispomeni |
| 4b | año.com | 0061 00F1 006F 002E 0063 006F 006D | xn--ao-zja.com |  |
|  | | | | |
| 5a | ʣe.org | 02A3 0065 002E 006F 0072 0067 | xn--e-j5a.org | Uses d-z digraph |
| 5b | dze.org | 0064 007A 0065 002E 006F 0072 0067 | dze.org |  |

Examples exist in various scripts. For instance, 'rn' was
already mentioned above, and the sequence अ + ा typically looks
identical to आ.

In most cases two sequences of accents that have the same visual
appearance are put into a canonical order. This does not happen,
however, for certain scripts used in Southeast Asia, so reordering
characters may be used for spoofs in those cases. See *Table
4, [Combining Mark
Order Spoofing](#TableCombiningMarkOrderSpoofing).*

Table 4. [Combining Mark Order
Spoofing](#TableCombiningMarkOrderSpoofing)

|  | String | UTF-16 | Punycode | Comments |
| 1a | လို.com | 101C 102D 102F | xn--gjd8ag.com | Reorders two combining marks |
| 1b | လုိ.com | 101C 102F 102D | xn--gjd8af.com |  |

### 2.4 [Inadequate Rendering Support](#Inadequate_Rendering_Support)

An additional problem arises when a font or rendering engine has
inadequate support for characters or sequences of characters that
should be visually distinguishable, but do not appear that way. In *Table
5, [Inadequate
Rendering Support](#TableInadequateRenderingSupport)*, examples 1a and 1b show the cases of lowercase L and digit one,
mentioned above. While this depends on the font, on the computer used
to write this document, roughly 30% of the fonts display glyphs that
are essentially identical. In example 2a, the *a-umlaut* is
followed by another *umlaut*. The Unicode Standard guidelines
indicate that the second *umlaut* should be 'stacked'
above the first, producing a distinct visual difference. However, as
example 2a shows, common fonts will simply superimpose the second *umlaut*;
and if the positioning is close enough, the user will not see a
difference between 2a and 2b. Examples 3 a, b, and c show an even
worse case. The *underdot* character in 3a should appear under
the 'l', but as rendered with many fonts, it appears under
the 'e'. It is thus visually confusable with 3b (where the *underdot*
is under the e) or the equivalent normalized form 3c.

Table 5. [Inadequate Rendering
Support](#TableInadequateRenderingSupport)

|  | String | UTF-16 | Punycode | Comments |
| 1a | al.com | 0061 006C 002E 0063 006F 006D | al.com | 1 and l may appear alike, depending on font. |
| 1b | a1.com | 0061 0031 002E 0063 006F 006D | a1.com |  |
|  | | | | |
| 2a | ä̈t.com | 00E4 0308 0074 002E 0063 006F 006D | xn--t-zfa85n.com | a-umlaut + umlaut |
| 2b | ät.com | 00E4 0074 002E 0063 006F 006D | xn--t-zfa.com |  |
|  | | | | |
| 3a | eḷ.com | 0065 006C  0323 002E 0063 006F 006D | xn--e-zom.com | Has a dot under the l; may appear under the e |
| 3b | ẹl.com | 0065 0323 006C 002E 0063 006F 006D | xn--l-ewm.com |  |
| 3c | ẹl.com | 1EB9 006C 002E 0063 006F 006D | xn--l-ewm.com |  |

Certain Unicode characters are invisible, although they may affect
the rendering of the characters around them. An example is the *joiner*
character, used to request a cursive connection such as in Arabic.
Such characters may often be in positions where they have no visual
distinction, and are thus discouraged for use in identifiers except
in specific contexts. For more information, see *UTS #46:
Unicode IDNA Compatibility Processing* [[UTS46](#UTS46)].

A sequence of ideographic description characters may be
displayed as if it were a CJK character; thus they are also
discouraged.

#### 2.4.1 [Malicious Rendering](#Malicious_Rendering)

Font technologies such as TrueType/OpenType are extremely powerful. A
glyph in such a font actually may use a small programs to transform
the shape radically according to resolution, platform, or language.
This is used to chose an optimal shape for the character under
different conditions. However, it can also be used in a security
attack, because it is powerful enough to change the appearance of,
say "$**1**00.00" on the screen to "$**2**00.00"
when printed.

In addition Cascading Style Sheets (CSS) can change to a
different font for printing versus screen display, which can open up
the use of more confusable fonts.

These problems are not specific to Unicode. To reduce the risk
of this kind of exploit, programmers and users should only allow
trusted fonts in such circumstances.

### 2.5 [Bidirectional Text Spoofing](#Bidirectional_Text_Spoofing)

Some characters, such as those used in the Arabic and Hebrew script,
have an inherent right-to-left writing direction. When these
characters are mixed with characters of other scripts or symbol sets
which are displayed left-to-right, the resulting text is called
bidirectional (abbreviated as *bidi*). The relationship
between the memory representation of the text (logical order) and the
display appearance (visual order) of bidi text is governed by *UAX
#9: Unicode Bidirectional Algorithm* [[UAX9](#UAX9)].

 Because some characters have weak or neutral
directionalities, as opposed to strong left-to-right or
right-to-left, the Unicode Bidirectional Algorithm uses a precise set
of rules to determine the final visual rendering. However, presented
with arbitrary sequences of text, this may lead to text sequences
which may be impossible to read intelligibly, or which may be
visually confusable. To mitigate these issues, the [[IDNA2003](#IDNA2003)] specification requires that:

* each label of a host name must not use both right-to-left
  and left-to-right characters,
* a label using right-to-left character must start and end
  with right-to-left characters.

The [[IDNA2008](#IDNA2008)] specification improves these
rules, allowing some sequences that are incorrectly forbidden by the
above rules, and disallowing others that can cause visual confusion.

In addition, the IRI specification [[RFC3987](#RFC3987)]
extends those requirements to other components of an URL, not just
the host name labels. Not respecting them would result in
insurmountable visual confusion. A large part of the confusability in
reading an URL containing bidi
characters is created by the weak or neutral directionality property
of many URL delimiters such as
'/', '.', '?' which makes them change
directionality depending on their surrounding characters. This is
shown with the dots in *Table 6, [Bidi
Examples](#TableBidiExamples)* , where they are colored the same as the preceding label. Notice
that the placement of that following punctuation may vary.

Table 6. [Bidi
Examples](#TableBidiExamples)

|  | Samples |
| 1 | http://سلام.دائم.com |
| 2 | http://سلام.a.دائم.com |

Adding the left-to-right label "a"
between the two Arabic labels splits them up and reverses their
display order, as seen in example #2 in *Table 6, [Bidi Examples](#TableBidiExamples)*. The IRI specification [[RFC3987](#RFC3987)] provides more examples of valid and
invalid IRIs using various mixes of bidi text.

To minimize the opportunities for confusion, it is imperative that
the [[IDNA2008](#IDNA2008)] and IRI requirements
concerning bidi processing be fully implemented in the processing of
host names containing bidi characters. Nevertheless, even when these
requirements are met, reading IRIs correctly is not trivial. Because
of this, mixing right-to-left and left-to-right characters should be
done with great care when creating bidi IRIs.

**Recommendations:**

* Never allow bidi override characters.
* As much as possible, avoid mixing right-to-left and
  left-to-right characters in a single name.
* When right-to-left characters are used, limit the usage of
  left-to-right characters to well-known cases such as TLD names and URL scheme names (such as http, ftp, mailto,
  and so on).
* Minimize the use of digits in host names and other
  components of IRIs containing right-to-left characters.
* Keep IRIs containing bidi content simple to read.
* Use reverse-bidi (visual order -> storage order) to
  detect possible bidi spoofs. That is, one can apply bidi, then
  reverse bidi: if the result does not match the original storage
  order, then the visual reading is ambiguous and the string can be
  rejected. This is, however, subject to false positives, so this
  should probably be presented to users for confirmation.

#### 2.5.1 [Glyphs in Complex Scripts](#Complex_Scripts)

In complex scripts such as Arabic and South Asian scripts, characters
may change shape according to the surrounding characters, as shown in
*Table 7, [Glyphs in
Complex Scripts](#TableComplexScripts)*. Note that this also occurs in higher-end
typography in English, as illustrated by the "fi" ligature.
Two characters might be visually distinct in a stand-alone form, but
not be distinct in a particular context.

Table 7. [Glyphs in Complex Scripts](#TableComplexScripts)

| 1. | Glyphs may change shape depending on their surroundings: | ه | | ه | | ه | | → | ههه | | |
|  | | | | | | | | | |
| 2. | Multiple characters may produce a single glyph: | f | | | i | | | → | ﬁ | | |
| ل | | | ا | | | → | لا | | |
| image | | image | | image | | → | image | | |
|  | | | | | | | | | |
| 3. | A single character may produce multiple glyphs: | க | | | ொ | | | → | ெ | க | ா |

Some complex scripts are encoded with a so-called *font-encoding,* where non-private-use characters are misused as other characters or
parts of characters. These present special risks, because the
encodings are not identified, and the visual interpretation of the
characters depends entirely on the font, and is completely
disconnected from the underlying characters. Luckily such
font-encodings are seldom used, and their use is decreasing rapidly
with the growth of Unicode.

### 2.6 [Syntax Spoofing](#Syntax_Spoofing)

Spoofing syntax characters can be even worse than regular characters,
as illustrated in *Table 8, [Syntax
Spoofing](#TableSyntaxSpoofing)*. For example, U+2044 ( ⁄
) FRACTION SLASH can
look like a regular ASCII '/' in many fonts—ideally the
spacing and angle are sufficiently different to distinguish these
characters. However, this is not always the case. When this
character is allowed, the URL in line 1 may appear to be in the
domain **macchiato.com**, but is actually in a particular subzone
of the domain **bad.com**.

Table 8. [Syntax
Spoofing](#TableSyntaxSpoofing)

|  | URL | Subzone | Domain |
| 1 | http://macchiato.com/x.bad.com | macchiato.com/x | bad.com |
| 2 | http://macchiato.com?x.bad.com | macchiato.com?x | bad.com |
| 3 | http://macchiato.com.x.bad.com | macchiato.com.x | bad.com |
| 4 | http://macchiato.com#x.bad.com | macchiato.com#x | bad.com |

Where there are visual confusables other syntax characters can be
similarly spoofed, as in lines 2 through 4. Nameprep [[RFC3491](#RFC3491)] and [[UTS46](#UTS46)]
disallow many such cases, such as such as U+2024 (·) ONE DOT LEADER. However, not
all syntax spoofs are disallowed.

Of course, these types of spoofs do not require IDNs. For example, in
the following the real domain name, **bad.com**, is also
obscured for the casual user, who may not realize that "--"
does not terminate the domain name.

> http://macchiato.com--long-and-obscure-list-of-characters.bad.com?findid=12

In retrospect, it would have been much better if domain names
were customarily written with the most significant label first. The
following hypothetical display would be harder to spoof: it is easy
to see that the top level is "com.bad".

> http://**com.bad**.org/x.example?findid=12
>
> http://**com.bad**.org--long-and-obscure-list-of-characters.example?findid=12

However, that would be an impossible change at this point.
However, much the same effect can be produced by always visually
distinguishing the domain, for example:

> http://**macchiato.com**
>
> http://**bad.com**
>
> http://macchiato.com/**x.bad.com**
>
> http://**macchiato.com--long-and-obscure-list-of-characters.bad.com**?findid=12
>
> http://**220.135.25.171**/amazon/index.html

Such visual distinction could be in different ways, such as
highlighting in an address box as above, or extracting and displaying
the domain name in a noticeable place.

User agents already have to deal with syntax issues. For example,
Firefox gives something like the following alert when given the URL http://something@macchiato.com:

| warning | You are about to go to the site "macchiato.com" with the username "something", but the web site does not require authentication. This may be an attempt to trick you.  Is "macchiato.com" the site you want to visit? |
| --- | --- |

Such a mechanism can be used to alert the user to cases of
syntax spoofing.

#### 2.6.1 [Missing Glyphs](#Missing_Glyphs)

It is very important not to show a missing glyph or character with a
simple "?", because every such character is visually
confusable with a real question mark. Instead, follow the Unicode
guidelines for displaying missing glyphs using a rounded-rectangle,
as listed in *Appendix A [Script
Icons](#Missing_Glyph_Icons)* and described in **Section 5.3, Unknown and
Missing Characters** of [[Unicode](#Unicode)].

Private use characters must be avoided in identifiers, except in
closed environments. There is no predicting what either the visual
display or the programmatic interpretation will be on any given
machine, so this can obviously lead to security problems. This is not
a problem for IDNs, because private use characters are excluded in
all specifications: [[IDNA2003](#IDNA2003)], [[IDNA2008](#IDNA2008)], and[[UTS46](#UTS46)].

What is true for private use characters is doubly true of
unassigned code points. Secure systems will not use them: any future
Unicode Standard could assign those codepoints to any new character.
This is especially important in the case of certification.

### 2.7 [Numeric Spoofs](#Numeric_Spoofs)

Turning away from the focus on domain names for a moment, there is
another area where visual spoofs can be used. Many scripts have sets
of decimal digits that are different in shape from the typical
European digits. For example, Bengali has {০ ১ ২ ৩  ৪ ৫ ৬  ৭ ৮ ৯}, while Oriya has {୦ ୧ ୨ ୩  ୪ ୫ ୬  ୭ ୮  ୯}. Individual digits may
have the same shapes as digits from other scripts, even digits of
different values. For example, the Bengali string "**৪****୨****"** is visually
confusable with the European digits "**89"**, but
actually has the numeric value 42! If software interprets the
numeric value of a string of digits without detecting that the
digits are from different or inappropriate scripts, such spoofs can
be used.

### [2.8 IDNA Ambiguity](#IDNA_Ambiguity)

IDNA2008, just approved in 2010, opens up new opportunities for
spoofing. In the 2003 version of international domain names, a
correctly processed URL containing Unicode characters always resolved
to the same Punycode URL for lookup. IDNA2008, in certain cases, will
resolve to a different Punycode URL. Thus the same URL, whether typed
in by the user or present in data (such as in an href) will resolve
to two different locations, depending on whether the user is using a
browser on the pre-2010 international domain name specification or
the post-2010 specification. For more information on this topic, see
*UTS #46: Unicode IDNA Compatibility Processing* [[UTS46](#UTS46)] and [[IDN\_FAQ](#IDN_FAQ)].

#### 2.8.1 [Punycode Spoofs](#Punycode_Spoofs)

The Punycode transformation is relatively dense. That means that it
is fairly likely that arbitrary words after the "xn--" will result in
valid labels. For example, see *Table 8a. [Punycode Spoofing](#TablePunycodeSpoofing)*.

Table 8a. [Punycode Spoofing](#TablePunycodeSpoofing)

|  | URL | Punycode URL |
| 1 | http://䕮䕵䕶䕱.com | http://xn--google.com |
| 2 | http://䁾.com | http://xn--cnn.com |
| 3 | http://岍岊岊岅岉岎.com | http://xn--citibank.com |

These examples demonstrate that the common tactic of displaying
Punycode for suspicious URLs or for URLs with languages or scripts
not in the user's settings can actually backfire, producing display
results that are *more* likely to mislead the user. For example,
if a user is unfamiliar with Chinese but knows Latin characters, she
is more likely to be mislead by the Punycode URL “http://xn--cnn.com”
than by the corresponding Unicode URL “http://䁾.com”. More examples
can be created with the demo at [[IDN-Demo](#IDN-Demo)].

### [2.9 Techniques](#Techniques)

This section lists techniques for reducing the risks of visual
spoofing. These techniques are referenced by *Section 2.10, [Recommendations](#Visual_Spoofing_Recommendations).*

#### [2.9.1 Casefolded Format](#Case_Folded_Format)

Many opportunities for spoofing can be removed by using a *casefolded*
format. This format, defined by the Unicode Standard, produces a
string that only contains lowercase characters where possible.

However, four characters that require special handling in
casefolding, where the pure casefolded format of a string as defined
by the Unicode Standard is not desired. For example, the character
U+03A3 "Σ" *capital sigma* lowercases to U+03C3
"σ" *small sigma* if it is followed by another letter,
but lowercases to U+03C2 "ς" *small final sigma* if it
is not. Because both σ and ς have a case-insensitive match to Σ, and
the casefolding algorithm needs to map both of them together (so that
transitivity is maintained), only one of them appears in the
casefolded form.

> When σ comes after a cased letter, and not before a cased letter
> (where certain ignorable characters can come in between), it should
> be transformed into ς. For more details, see the test for
> Final\_Sigma as provided in Table 3-15 of [[Unicode](#Unicode)].

For more information, see *UTS #46: Unicode IDNA
Compatibility Processing* [[UTS46](#UTS46)]. For more
information on case mapping and folding, see the following: *Section
3.13, Default Case Operations*, *Section 4.2; Case Normative*;
and *Section 5.18, Case Mappings* of [[Unicode](#Unicode)].

#### [2.9.2 Mapping and Prohibition](#Mapping_and_Prohibition)

Mapping and prohibition are two useful techniques to reduce the risk
of spoofing that can be applied to identifiers. A number of
characters are included in Unicode for compatibility. *Compatibility
Normalization* (NFKC) can be used to map these characters to the
regular variants. For example, a halfwidth Japanese *katakana*
character ｶ is mapped to the regular
character カ. Additional mappings can be added beyond compatibility
mappings, for example, [[IDNA2003](#IDNA2003)]
 adds the following:

> `200D; ZERO WIDTH JOINER`
> maps to nothing (that is, is removed)
>
> `0041; 0061;`
> Case maps 'A' to 'a'
>
> `20A8; 0072 0073;`
> Additional folding, mapping ₨
> to "rs"

In addition, characters may be prohibited. For example, IDNA2003
prohibits *space* and *no-break
s**pace* (U+00A0).
Instead of removing a ZERO WIDTH JOINER, or mapping ₨ to "rs", one could
prohibit these characters. There are pluses and minuses to both
approaches. If compatibility characters are widely used in practice
in entering text, it is much more user-friendly to remap them. This
also extends to deletion; for example, the ZERO WIDTH JOINER is
commonly used to affect the presentation of characters in languages
such as Hindi or Arabic. In this case, text copied into the address
box may often contain the character.

Where this is not the case, however, it may be advisable to simply
prohibit the character. It is unlikely, for example, that ㋕ would be typed by a
Japanese user, nor that it would need to work in copied text.

Where both mapping and prohibition are used, the mapping should be
done before the prohibition, to ensure that characters do not
"sneak past". For example, the Greek character TONOS (΄) ends up being prohibited in [[IDNA2003](#IDNA2003)]
, because it normalizes to *space + acute*, and *space*
itself is prohibited.

Many languages have words whose correct spelling requires the
use of certain invisible characters, especially the Join\_Control
characters:

> `[200C](http://unicode.org/cldr/utility/character.jsp?a=200C)`
> ZERO WIDTH NON-JOINER
>
> `[200D](http://unicode.org/cldr/utility/character.jsp?a=200D)`
> ZERO WIDTH JOINER

For that reason, as of Version 5.1 of the Unicode Standard the
recommendations for identifiers were modified to allow these
characters in certain circumstances. (For more
information, see *UAX #31: Unicode Identifier and Pattern
Syntax* [[UAX31](#UAX31)].) There are very stringent
constraints on the use of these characters, so that they are only
allowed with certain scripts, and in certain circumscribed contexts.
In particular, in Indic scripts the ZWJ and ZWNJ may only be used in
combination with a *virama* character. This approach is adopted
in [[IDNA2008](#IDNA2008)] and[[UTS46](#UTS46)].

Even when the join controls are constrained to being next to a *virama*,
in some contexts they may not result in a different visual
appearance. For example, in roughly half of the possible pairs of
Malayalam consonants linked by a *virama*, the ZWNJ makes a
visual difference; in the remaining cases, the appearance is the same
as if only the virama were present, without a ZWNJ. Implementations
or standards may thus place further restrictions on invisible
characters. For join controls in Indic scripts, such restrictions
would typically consist of providing a table per script, containing
pairs of consonants which allow intervening *joiners*.

The Unicode property [[NFKC\_Casefold](#NFKC_CaseFold)] can
be used to get a combined casefolding, normalization, and removal of
default-ignorable code points. It is the basis for the mapping of
international domain names in *UTS #46: Unicode IDNA
Compatibility Processing* [[UTS46](#UTS46)]. For more
information, also see *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

### [2.10 Restriction Levels and Alerts](#Security_Levels_and_Alerts)

To help avoid problems with mixtures of scripts, *UTS #39:
Unicode Security Mechanisms* [[UTS39](#UTS39)] defines *Restriction
Levels*. An appropriate alert should be generated if an identifier
fails to satisfy the Restriction Level chosen by the user or set in
the browser. Depending on the circumstances and the level difference,
the form of such alerts could be minimal, such as special coloring or
icons (perhaps with a tool-tip for more information); or more
obvious, such as an alert dialog describing the issue and requiring
user confirmation before continuing; or even more stringent, such as
disallowing the use of the identifier. Where icons are used to
indicate the presence of characters from scripts, the glyphs in *Appendix
A [Script Icons](#Missing_Glyph_Icons)* can be used.

The UI for giving users choice among restriction levels may
vary considerably. In the case of domain names, only the middle three
levels are interesting. Level 1 turns IDNs completely off, while
Level 5 is not recommended for IDNs.

Note that the examples in Level 4 are chosen for their familiarity to
English speakers. For most languages that customarily use the Latin
script, there is probably little need to mix in other scripts. That
is not necessarily the case for languages that customarily use a
non-Latin script. Because of the widespread commercial use of English
and other Latin-based languages, it is quite common to have
Latin-script characters (especially ASCII) in text that principally
consists of other scripts, such as "[خدمة RSS](http://news.bbc.co.uk/hi/arabic/help/rss/newsid_3492000/3492193.stm?rss=http://newsrss.bbc.co.uk/rss/arabic/news/rss.xml)".

*Section 3, [Identifier
Characters](http://www.unicode.org/reports/tr39/#Identifier_Characters)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)] provides for two profiles of identifiers
that could be used in Restriction Levels 1 through 4. The strict
profile is recommended. If the lenient profile is used, the user
should have some way to choose the strict profile.

At all Restriction Levels, an appropriate alert should be generated
if the domain name contains a syntax character that might be used in
a spoof, as described in *Section 2.6, [Syntax Spoofing](#Syntax_Spoofing)*.

For example, an alert might be presented
for a syntax character spoof:

| warning | You are about to go to the site "bad.com", but part of the address contains a character which may have led you to think you were going to "macchiato.com". This may be an attempt to trick you.  Is "bad.com" the site you want to visit?    Remember my answer for future addresses with "bad.com" |
| --- | --- |

As another example, an alert might be
presented for a mixed-script spoof:

| warning | You are about to go to the site "goоgle.com", but the underlined character is a Cyrillic о. This may be an attempt to trick you.  Is "goоgle.com" the site you want to visit?    Remember my answer for future addresses with "google.com" |
| --- | --- |

This alert does not need to be presented in a dialog window;
there are a variety of ways to alert users, such as in an information
bar.

User agents should remember when the user has accepted an alert, for
say  *Ωmega.com*, and permit future access without bothering the
user again. This essentially builds up a whitelist of allowed values.
This whitelist should contain the "nameprepped" form of
each string. When used for visually confusable detection, each
element in the whitelist should also have an associated transformed
string as described in *Section 4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)*[[UTS39](#UTS39)]. If a system allows
uppercase and lowercase forms, then both transforms should be
available. The program should allow access to editing this whitelist
directly, in case the user wants to correct the values. The whitelist
may also include items known by the user agent to be 'safe'.

#### [2.10.1 Backward Compatibility](#Backwards_Compatibility)

The set of characters in the identifier profile and the results of
the confusable mappings may be refined over time, so implementations
should recognize and allow for that. Characters suitable for
identifiers are periodically added to the Unicode Standard, and thus
the data for *Section 4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)*[[UTS39](#UTS39)] is also periodically
updated.

There may also be cases where characters are no longer
recommended for inclusion in identifiers as more information becomes
available about them. Thus some characters may be removed from the
identifier profile in the future. Of course, once identifiers are
registered they cannot be withdrawn, but new proposed identifiers
that contain such characters can be denied.

### [2.11 Recommendations](#Visual_Spoofing_Recommendations)

The Unicode Consortium recommends a somewhat conservative
approach at this point, because is always easier to widen
restrictions than narrow them.

Some have proposed restricting domain names according to language, to
prevent spoofing. In practice, that is very problematic: it is very
difficult to determine the intended language of many terms,
especially product or company names, which are often constructed to
be neutral regarding language. Moreover, languages tend to be quite
fluid; foreign words are continually being adopted. Except for
registries with very special policies (such as the blocking used by
some East Asian registries as described in [[RFC3743](#RFC3743)]),
the language association does not make too much sense. For more
information, see *Appendix B, [Language-Based Security](#Language_Based_Security)*.

Instead, the Consortium recommends processing strings to remove basic
equivalences, promoting adequate rendering support, and putting
restrictions in place according to script, and restricting by
confusable characters. While the ICANN guidelines say "top-level
domain registries will [...] associate each registered
internationalized domain name with one language or set of
languages" [[ICANN](#ICANN)], that guidance is better
interpreted as limiting to *script* rather than *language*.

Also see the security discussions in IRI [[RFC3987](#RFC3987)],
URI [[RFC3986](#RFC3986)], and Nameprep [[RFC3491](#RFC3491)].

#### [2.11.1 Recommendations for End-Users](#User_Recommendations)

1. Use browsers, mail clients, and other software that have put
   user-agent guidelines into place to detect spoofing.
2. If registering domain names, verify that the registry
   follows appropriate guidelines for preventing spoofing.
3. If the desired domain name can have any whole-script or
   single-script confusables (such as "scope" in Latin and
   Cyrillic), register those as well, if "bundling" is not
   automatically provided by the registry.
4. Where there are alternative domain names, choose those that
   are less spoofable.
5. When using bidi IRIs, follow the recommendations in *Section
   2.5, [Bidirectional Text
   Spoofing](#Bidirectional_Text_Spoofing)*.
6. Be aware that fonts can be used in spoofing, as discussed in
   *Section 2.4.1, [Malicious
   Rendering](#Malicious_Rendering)*. With documents having embedded fonts (web fonts), be
   aware that the content on a printed form can be different than is on
   the screen.

#### [2.11.2 Recommendations for Programmers](#Recommendations_General)

1. When parsing numbers, detect digits of mixed scripts and
   unexpected scripts and alert the user.
2. When defining identifiers in programming languages,
   protocols, and other environments:
   1. Use the general security profile for identifiers from *Section
      3, [Identifier
      Characters](http://www.unicode.org/reports/tr39/#Identifier_Characters)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)]*.*
      * Note that the general security profile
        allows characters from [*Table
        3, Candidate Characters for Inclusion in Identifiers*](http://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Inclusion_in_Identifiers) in [[UAX31](#UAX31)], such as U+00B7 (·) MIDDLE DOT used in
        Catalan.
   2. For equivalence of identifiers, preprocess both strings by
      applying NFKC and case folding. Display all such identifiers to
      users in their processed form. (There may be two displays: one in
      the original and one in the processed form.) An example of this
      methodology is Nameprep [[RFC3491](#RFC3491)]. Although
      Nameprep is currently limited to Unicode 3.2, the same methodology
      can be applied by implementations that need to support more
      up-to-date versions of Unicode.
3. In choosing or deploying fonts:
   1. If there is no available glyph for a character, *never*
      show a simple "?" or omit the character.
   2. Use distinctive fonts, where possible.
   3. Use a size that makes it easier to see the differences in
      characters. Disallow the use of font sizes that are so small as to
      cause even more characters to be visually confusable. Use larger
      sizes for East/South/South East Asian scripts, such as for
      Japanese and Thai.
   4. Watch for clipping, vertically and horizontally. That is,
      make sure that the visible area extends outside of the text width
      and height, to the character bounding box: the maximum extent of
      the shape of the glyph.
   5. Assess the font support of the OS/platform according to
      recommendations D1-D3 below (see also the W3C [[CharMod](#CharMod)]).
      If it is inadequate, work with the OS/platform vendor to address
      those problems, or implement special handling of problematic
      cases.
4. In developing rendering systems or fonts:
   1. Verify that accents do not appear to apply to the wrong
      characters.
   2. Follow [UTN
      #2: *Rendering Combining Marks*](http://www.unicode.org/notes/tn2/) in providing layout of nonspacing marks that would otherwise
      collide. If this is not done, follow the "Show Hidden"
      option of *Section 5.13,* [*Rendering
      Nonspacing Marks*](http://www.unicode.org/versions/Unicode5.0.0/ch05.pdf#G1095) of [[Unicode](#Unicode)] for the
      display of nonspacing marks.
   3. Follow the Unicode guidelines for displaying missing
      glyphs using a rounded-rectangle, as described in *Section
      5.3, [Unknown
      and Missing Characters](http://www.unicode.org/versions/Unicode5.0.0/ch05.pdf#G7730)* of [[Unicode](#Unicode)]. The recommended glyphs
      according to scripts are shown in *Appendix A*  *[Script Icons](#Missing_Glyph_Icons)*.

#### [2.11.3 Recommendations for User Agents](#Recommendations_User_Agents)

The following recommendations are for user agents in handling
domain names. The term "user agent" is interpreted broadly
to mean any program that displays Internationalized Domain Names to a
user, including browsers and emailers.

For information on the confusable tests mentioned below, see *Section
4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)]*.* If the user can see the casefolded
form, use the lowercase-only confusable mappings; otherwise use the
broader mappings.

1. Follow *Section 2.10.2, [Recommendations for Programmers](#Recommendations_General)*.
2. Display
   1. Either always show the domain name in nameprepped form [[RFC3491](#RFC3491)], or make it very easy for the user to
      see it (see *Section 2.8.1, [Casefolded Format](#Case_Folded_Format)*). For example,
      this could be a tooltip interface, or a separate box.
   2. Always display the domain name with a visually highlighted
      domain name, to prevent syntax spoofs (see *Section 2.6, [Syntax Spoofing](#Syntax_Spoofing)*).
   3. Always display IRIs with bidi content according to the IRI
      specification [[RFC3987](#RFC3987)].
3. Preferences
   1. In preferences, allow the user to select the desired
      Restriction Level to apply to domain names. Set the default to
      Restriction Level 2.
   2. In preferences, allow the user to select among additional
      scripts that can be used without alerting. The default can be
      based on the user's locale.
   3. In preferences, allow the user to choose a backward
      compatibility setting; see *Section 2.9.1, [Backward Compatibility](#Backwards_Compatibility)*.
4. Alerts
   1. If the user agent maintains a domain whitelist for the
      user, and the domain name is in the whitelist, allow it and skip
      the remaining items in this section. (The domain whitelist can
      take into account the documented policies of the registry as per *Section
      2.10.4, [Recommendations
      for Registries](#Recommendations_Registries)*.)
   2. If the visual appearance of a link does not match the end
      location, alert the user.
   3. If the domain name does not satisfy the requirements of
      the user preferences (such as the Restriction Level), alert the
      user.
   4. If the domain name contains any letters confusable with
      syntax characters, alert the user.
   5. If there is a whitelist, and the domain name is visually
      confusable with a whitelist domain name, but not identical to it
      (after nameprep), alert the user.
   6. If any label in the domain name is a whole-script or a
      mixed-script confusable, alert the user.

#### [2.11.4 Recommendations for Registries](#Recommendations_Registries)

The following recommendations are for registries in dealing
with identifiers such as domain names. The term "Registry"
is to be interpreted broadly, as any agency that sets the policy for
which identifiers are accepted.

Thus the .com operator can impose restrictions on the 2nd level
domain label, but if someone registers *foo.com*, then it is up
to them to decide what will be allowed at the 3rd level (for example,
*bar.foo.com*). So for that purpose, the owner of *foo.com*
is treated as the "Registry" for the 3rd level (the *bar*).
Similarly, the owner of a domain name is acting as an internal
registry in terms of the policies for the non-domain name portions of
a URL, such as *banking*  in *http://bar.foo.com/banking.*
Thus the following recommendations still apply.

For information on the confusable tests mentioned below, see *Section
4,*  *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

1. Publicly document the Restriction Level being enforced. For
   IDN, the Restriction Level is not to be higher than Level 4: that
   is, no characters can be outside of the *General Security
   Profiles for Identifiers* in *Section 3, [Identifier
   Characters](http://www.unicode.org/reports/tr39/#Identifier_Characters)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].
2. Publicly document the enforcement policy on confusables:
   whether two domain names are allowed to be single-script or mixed
   script confusables.
3. If there are any pre-existing exceptions to A or B, then
   document them also.
4. Define an IDN registration in terms of both its
   Nameprep-Normalized Unicode representation (the *output format*)
   and its Punycode representation.

#### [2.11.5 Registrar Recommendations](#Recommendations_Registrars)

The following recommendations are for registrars in dealing
with domain names. The term "Registrar" is to be
interpreted broadly, as any agency that presents a UI for registering
domain names, and allows users to see whether a name is registered.
The same entity may be both a Registrar and Registry.

1. When a user's name is (or would be) rejected by the
   registry for security reasons, show the user the reason for
   rejection (such as the existence of an already-registered
   confusable).

## 3 [Non-Visual Security Issues](#Canonical_Represenation)

There are a number of exploits based on misuse of character
encodings. Some of these are fairly well-known, such as buffer
overflows in conversion, while others are not. Many are involved in
the common practice of having a 'gatekeeper' for a system.
That gatekeeper checks incoming data to ensure that it is safe, and
passes only safe data through. Once in the system, the other
components assume that the data is safe. A problem arises when a
component treats two pieces of text as identical—typically by
canonicalizing them to the same form—but the gatekeeper only detected
that one of them was unsafe.

For example, suppose that strings containing the letters
"delete" are sensitive internally, and that therefore a
gatekeeper checks for them. If some process casefolds
"DELETE" *after* the gatekeeper has checked, then
the sensitive string can sneak through. While many programmers are
aware of this, they may not be aware that the same thing can happen
with other transformations, such as an NFKC transformation of
"Ⓓⓔⓛⓔⓣⓔ" into "delete".

These gatekeeper problems can also happen with charset
converters. Where a character in a source string cannot be expressed
in a target string, it is quite common for charset converters to have
a "fallback conversion", picking the next best conversion.
For example, when converting from Unicode to Latin-1, the character
"ⓔ" cannot be expressed exactly, and the converter may fall
back to "e". This can be used for the same kind of exploit.
Unfortunately, some charset converter APIs, such as in Java, do not
allow such fallbacks to be turned off. This is not only a problem for
security, but also for other kinds of processing. For example, when
converting an XML or HTML page, a character such as "ⓔ"
missing from the target charset must be represented by an NCR such as
&#x24D4; instead of using a lossy converter. Where possible,
using Unicode instead of other charsets avoids many of these kinds of
problems.

### 3.1 [UTF-8 Exploit](#UTF-8_Exploit)s

There are three equivalent encoding forms for Unicode: UTF-8,
UTF-16, and UTF-32. UTF-8 is commonly used in XML and HTML; UTF-16 is
the most common in program APIs; and UTF-32 is the best for
representing single characters. While these forms are all equivalent
in terms of the ability to express Unicode, the original usage of
UTF-8 was open to a canonicalization exploit.

Originally, Unicode forbade the *generation* of
"non-shortest form" UTF-8, but not the *interpretation*
of "non-shortest form" UTF-8. This was fixed in Unicode
3.0, because security issues can arise when software does interpret
the non-shortest forms. For example:

* Process *A* performs security checks, but does not
  check for non-shortest forms.
* Process *B* accepts the byte sequence from process *A*,
  and transforms it into UTF-16 while interpreting non-shortest forms.
* The UTF-16 text may then contain characters that should have
  been filtered out by process *A*.

For example, the backslash character "\" can often be
a dangerous character to let through a gatekeeper, because it can be
used to access different directories. Thus a gatekeeper might
specifically prevent it from getting through. The backslash is
represented in UTF-8 as the byte sequence <5C>. However, as a
non-shortest form, backslash could also be represented as the byte
sequence<C1 9C>. When a gatekeeper does not check for
non-shortest form, this situation can lead to a severe security
breach.

To address this issue, the Unicode Technical Committee modified the
definition of UTF-8 in [Unicode
3.1](http://www.unicode.org/reports/tr27/) to forbid conformant implementations from interpreting
non-shortest forms for [BMP
characters](http://www.unicode.org/glossary/#BMP_character), and clarified some of the conformance clauses.

#### 3.1.1 [Ill-Formed Subsequences](#Ill-Formed_Subsequences)

Suppose that a UTF-8 converter is iterating through input UTF-8
bytes, converting to an output character encoding. If the converter
encounters an ill-formed UTF-8 sequence it can treat it as an error
in a number of different ways, including substituting a character
like U+FFFD, SUB, "?", or SPACE. However, it *must
not* consume any valid successor bytes. For example, suppose we have
the following sequence:

> X = <... 41 **C2** 3E 42 ... >

This sequence overall is ill-formed, because it contains an
ill-formed substring, namely the <**C2**>. That is, there is
no substring of X containing the **C2** byte which matches the
specification for UTF-8 in Table 3-7 of Unicode 5.2 [[Unicode](#Unicode)]. The UTF-8 converter can stop at the **C2**
byte, or substitute a character or sequence like U+FFFD and continue.
However, it must not consume the **3E** byte if it continues. That
is, it is acceptable to convert X to “...**A >B**...”, but not
acceptable to convert X to **“...A B...”** (that is, deleting the
>).

Consuming a subsequent byte (such as **3E** above) is
not only non-conformant; it can lead to security breaches. For
example, suppose that a web page is constructed with user input. The
user input is filtered to catch problem attributes such as
onMouseOver. However, incorrect conversion can defeat that filtering
by removing important syntax characters like > in HTML attribute
values. Take the following string, where “✘” indicates a bare **C2**
byte:

> <span style=width:100%✘> onMouseOver=doBadStuff()...

When this is converted with a bad UTF-8 converter, the **C2**
would cause the > character to be consumed, and the HTML served up
would be of the following form, allowing for a cross-site scripting
attack:

> <span style=width:100% onMouseOver=doBadStuff()...

For more information on how to handle ill-formed subsequences, see
"Constraints on Conversion Processes" in *Section
3.9, Unicode Encoding Forms* in Unicode 5.2 [[Unicode](#Unicode)].

#### 3.1.2 [Substituting for Ill-Formed Subsequences](#Substituting_for_Ill_Formed_Subsequences)

If characters *are* to be substituted for ill-formed
subsequences, it is important that those characters be relatively
safe.

* Deletion (substituting the empty string) can be quite nasty,
  because it joins characters that would have been separate (such as
  on MouseOver).
* Substituting characters that are valid syntax for constructs
  such as file names has similar problems. For example, the
  '.' can be very problematic.
  + U+FFFD is usually unproblematic, because it is designed
    expressly for this kind of purpose. That is, because it does not
    have syntactic meaning in programming languages or structured
    data, it will typically just cause a failure in parsing. Where the
    output character set is not Unicode, though, this character may
    not be available.
  + Where U+FFFD is not available, a common alternative is
    "?". While this character may occur syntactically, it
    appears to be less subject to attack than most others.

UTF-16 converters that do not handle isolated surrogates
correctly are subject to the same type of attack, although
historically UTF-16 converters have generally handled these well.

### 3.2 [Text Comparison](#Text_Comparison) (Sorting, Searching, Matching)

The UTF-8 exploit is a special case of a general problem. Security
problems may arise where a user and a system (or two systems) compare
text differently. For example, this happens where text does not
compare as users expect. See the discussions in *UTS#10:
Unicode Collation Algorithm* [[UTS10](#UTS10)], especially
Section 1.

A system is particularly vulnerable when two
different implementations of the same protocol use different
mechanisms for text comparison, such as the comparison as to whether
two identifiers are equivalent or not.

Assume a system consists of two modules: a user
registry and the access control. Suppose that the user registry does
not use NamePrep, while the access control module does. Two
situations can arise:

1. The user with valid access rights to a certain
   resource actually cannot access it, because the binary
   representation of user ID used for the user registry differs from
   the one specified in the access control list. This situation is not
   a major security concern—because the person in this situation
   cannot access the protected resource.
2. The opposite case creates a security hole: a new
   user whose ID is NamePrep-equivalent to another user's in the
   directory system can get the access right to a protected resource.

For example, a fundamental standard, [[LDAP](#LDAP)], used
to be subject to this problem; thus steps were taken to remedy this
in later versions.

There are some other areas to watch for. Where these
are overlooked, it may leave a system open to the text comparison
security problems.

1. Normalization is context dependent; do not assume
   NFC(x + y) = NFC(x) + NFC(y).
2. There are ***two*** binary Unicode orders: code
   point/UTF-8/UTF-32 and UTF-16 order. In the latter, U+10000 **<**
   U+E000 (because U+10000 = D800 DC00).
3. Avoid using non-Unicode charsets where possible. IANA / MIME
   charset names are ill-defined: vendors often convert the same
   charset different ways. For example, in Shift-JIS the value 0x5C
   converts to ***either***U+005C ***or*** U+00A5 depending on the vendor, resulting in
   different, unrelated characters with unrelated glyphs. See:
   * <http://www.w3.org/TR/japanese-xml/>
   * <http://icu.sourceforge.net/charts/charset/>
4. When converting charsets, *never* simply omit
   characters that cannot be converted; at least substitute U+FFFD
   (when converting to Unicode) or 0x1A (when converting to bytes) to
   reduce security problems. See also [[UTS22](#UTS22)].
5. Regular expression engines use character properties in
   matching. They may vary in how they match, depending on the
   interpretation of those properties. Where regex matching is
   important to security, ensure that the regular expression engine
   conforms to the requirements of [[UTS18](#UTS18)], and
   uses an up-to-date version of the Unicode Standard for its
   properties.

Transitivity is crucial to correct functioning of sorting
algorithms. Transitivity means that if a < b and b < c then a
< c. It means that there cannot be any cycles: a < b < c
< a.

A lack of transitivity in string comparisons may cause security
problems, including denial-of-service attacks. As an example of a
failure of transitivity, consider the following pseudocode:

```
int compare(a,b) {
  if (isNumber(a) && isNumber(b)) {
    return numberComparison(a,b);
  } else {
    return textComparison(a,b);
  }
}
```

The code seems straightforward, but produces the following
non-transitive result:

"12" < "12a" < "2" <
"12"

For the first two comparisons, one of the values is not a
number, therefore both values are compared as text. For the last two,
both are numbers, and compared numerically. This breaks transitivity
because a cycle is introduced.

The following pseudocode illustrates one way to repair the
code, by sorting all numbers before all non-numbers:

```
int compare(a,b) {
  if (isNumber(a)) {
    if (isNumber(b)) {
      return numberComparison(a,b);
    } else {
      return -1; // a is less than b, since a is a number and b isn't
    }
  } else if (isNumber(b)) {
    return 1;    // b is less than a, since b is a number and a isn't
  } else {
    return textComparison(a,b);
  }
}

```

Therefore, for complex comparisons, such as language-sensitive
comparison, it is important to test for transitivity thoroughly.

### 3.3 [Buffer Overflows](#Buffer_Overflows)

Some programmers may rely on limitations that are
true of ASCII or Latin-1, but fail with general Unicode text. These
can cause failures such as buffer overruns if the length of text
grows. In particular:

1. Strings may
   expand in casing: Fluß → FLUSS → fluss.
   The expansion factor may change depending on the UTF as well.
2. Programmers
   assume that NFC always composes, and thus is the same or shorter
   length than the original source. However, some characters *decompose*
   in NFC. The expansion factor may change depending on the UTF as
   well.
3. *Table 9, [Maximum
   Expansion Factors](#TableMaximumExpansionFactors)* illustrates the expansions for case operations
   and normalization. These factors are for a particular version of
   Unicode: they should be recomputed for the particular version of
   Unicode being used.
   * The very large factors in the case of NFKC and NFKD are
     due to some extremely rare characters. Thus algorithms can use
     much smaller expansion factors for the typical cases as long as
     they have a fallback process that accounts for the possibility of
     these characters in data.
   * As of Unicode 5.0, a *Stream-Safe Text Format* was
     added to *UAX #15: Unicode Normalization Forms [[UAX15](#UAX15)]*. This format allows protocols to limit the number of characters
     that they need to buffer in handling normalization.
4. When performing character conversion, text may grow or
   shrink, sometimes substantially. Always account for that possibility
   in processing.

Table 9.
 [Maximum Expansion
Factors](#TableMaximumExpansionFactors)

| Operation | UTF | Factor | Sample | |
| Lower | 8 | 1.5X | Ⱥ | U+023A |
| 16, 32 | 1X | A | U+0041 |
| Upper/Title/Fold | 8, 16, 32 | 3X | ΐ | U+0390 |
| Operation | UTF | Factor | Sample | |
| NFC | 8 | 3X | 𝅘𝅥𝅮 | U+1D160 |
| 16, 32 | 3X | שּׁ | U+FB2C |
| NFD | 8 | 3X | ΐ | U+0390 |
| 16, 32 | 4X | ᾂ | U+1F82 |
| NFKC/NFKD | 8 | 11X | ﷺ | U+FDFA |
| 16, 32 | 18X |

### 3.4 [Property and Character Stability](#Property_and_Character_Stability)

The Unicode Consortium Stability Policies [[Stability](#Stability)]
limit the ways in which the standards developed by the Unicode
Consortium can change. These policies are intended to ensure that
text encoded in one version of the Unicode Standard remains valid and
unchanged in later versions. In many cases, the constraints imposed
by these stability policies allow implementers to simplify support
for particular features of Unicode, with the assurance that their
implementations will not be invalidated by a later update to Unicode.

Implementations should not make assumptions beyond what is documented
in the Stability Policies. For example, some implementations assumed
that no new decomposable characters would be added to Unicode. The
actual restriction is slightly looser: that decomposable characters
will not be added if their decompositions were already in Unicode. It
is therefore possible to add a decomposable character *if* one
of the characters in its decomposition is also new in that version of
Unicode. For example, decomposable Balinese characters were added to
the standard in Version 5.0, which caused some implementations to
break.

Similarly, some applications assumed that all Chinese
characters were three bytes in UTF-8. Thus once a string was known to
be all Chinese, iteration through the string could take the form of
simply advancing an offset or pointer by three bytes. This assumption
proved incorrect and caused implementations to break when Chinese
characters were added on Plane 2, requiring 4-byte representations in
UTF-8.

Making such unwarranted assumptions can lead to security problems.
For example, advancing uniformly by three bytes for Chinese will
corrupt the interpretation of text, leading to problems like those
mentioned in *Section 3.1.1,  [Ill-Formed\_Subsequences](#Ill-Formed_Subsequences)*.
Implementers should thus be careful to only depend on the documented
stability policies.

An implementation may need to make certain assumptions for
performance—assumptions that are not guaranteed by the policies. In
such a case, it is recommended to at least have unit tests that
detect whether those assumptions have become invalid when the
implementation is upgraded to a new version of Unicode. That allows
the problem to be detected and code to be revised if the assumption
is invalidated.

### 3.5 [Deletion of Code Points](#Deletion_of_Noncharacters)

In some versions prior to Unicode 5.2, conformance clause C7
allowed the deletion of noncharacter code points:

> C7. When a process purports not to modify the interpretation of a
> valid coded character sequence, it shall make no change to that coded
> character sequence other than the possible replacement of character
> sequences by their canonical-equivalent sequences ***or
> the deletion of noncharacter code points*****.**

Whenever a character is invisibly deleted (instead of
replaced), such as in this older version of C7, it may cause a
security problem. The issue is the following: A gateway might be
checking for a sensitive sequence of characters, say "delete". If
what is passed in is "deXlete", where X is a noncharacter, the
gateway lets it through: the sequence "deXlete" may be in and of
itself harmless. However, suppose that later on, past the gateway, an
internal process invisibly deletes the X. In that case, the sensitive
sequence of characters is formed, and can lead to a security breach.

The following is an example of how this can be used for
malicious purposes.

> <a href=“java**\uFEFF**script:alert("XSS")>

### 3.6 [Secure Encoding Conversion](#SecureEncodingConversion)

In addition to handling Unicode text safely, character encoding
conversion also needs to be designed and implemented carefully in
order to avoid security issues.

#### [3.6.1 Illegal Input Byte Sequences](#Illegal_Input_Byte_Sequences)

When converting from a multi-byte encoding, a byte value may
not be a valid trailing byte, in a context where it follows a
particular leading byte. For example, when converting UTF-8 input,
the byte sequence E3 80 22 is malformed because 0x22 is not a valid
second trailing byte following the leading byte 0xE3. Some conversion
code may report the three-byte sequence E3 80 22 as one illegal
sequence and continue converting the rest, while other conversion
code may report only the two-byte sequence E3 80 as an illegal
sequence and continue converting with the 0x22 byte which is a syntax
character in HTML and XML (U+0022 double quote). Implementations that
report the 0x22 byte as part of the illegal sequence can be exploited
for cross-site-scripting (XSS) attacks.

Therefore, an illegal byte sequence must not include bytes that
encode valid characters or are leading bytes for valid characters.

The following are safe error handling strategies for conversion
code dealing with illegal multi-byte sequences. (An illegal
single/leading byte does not pose this problem.)

1. Stop with an error. Do not continue converting the rest of
   the text.
2. In a reported illegal byte sequence, do not include any
   non-initial byte that encodes a valid character or is a leading byte
   for a valid sequence.
3. Report the first byte of the illegal sequence as an error
   and continue with the second byte.

Strategy 1 is the simplest, but in many cases it is desirable
to convert as much of the text as possible. For example, a web
browser will usually replace a small number of illegal byte sequences
with U+FFFD each and display the page as best it can. Strategy 3 is
the next simplest but can lead to multiple U+FFFD or other error
handling artifacts for what is a single-byte error.

Strategy 2 is the most natural and fits well with an assumption
that most errors are not due to physical transmission corruption but
due to truncated multi-byte sequences from improper string handling.
It also avoids going back to an earlier byte stream position in most
cases.

Converters for single-byte encodings are unaffected by any of these
issues. Nor are converters for the Character Encoding Schemes
UTF-16 and UTF-32 and their variants affected, because they are not
really byte-based encodings: they are often "converted" via memcpy(),
at most with a byte swap, so a converter needs to always deliver
pairs or quads of bytes.

#### [3.6.2 Some Output For All Input](#Some_Output_For_All_Input)

Character encoding conversion must also not simply skip an illegal
input byte sequence. Instead, it must stop with an error or
substitute a replacement character (such as [U+FFFD](http://unicode.org/cldr/utility/character.jsp?a=FFFD) ( � )
REPLACEMENT CHARACTER) or an escape sequence in the output. (See also
*Section 3.5 [Deletion
of Code Points](#Deletion_of_Noncharacters)*.) It is important to do this not only for byte
sequences that encode characters, but also for unrecognized or
"empty" state-change sequences. For example:

* An illegal or unrecognized ISO-2022 designation or escape
  sequence.
* Pairs of SI/SO without text characters between them.
* ISO-2022 shift sequences without text characters before the
  next shift sequence. The formal syntaxes for HZ and most CJK
  ISO-2022 variants require at least one character in a text segment
  between shift sequences. Security software written to the formal
  specification may not detect malicious text  (for example, "delete"
  with a shift-to-double-byte then an immediate shift-to-ASCII in the
  middle).

### 3.7 [Enabling Lossless Conversion](#EnablingLosslessConversion)

There is a known problem with file systems that use a legacy
charset. When a Unicode API is used to find the files in a directory,
the return value is a list Unicode file names. Those names are used
to access the files through some other API. There are two possible
problems:

* One of the file names is invalid according to the legacy
  charset converter. For example, it is an [SJIS](http://demo.icu-project.org/icu-bin/convexp?conv=ibm-943_P15A-2003) string consisting of bytes <E0 30>.
* Two of the file names are mapped to the same Unicode string
  by the legacy charset converter.

These problems come up in other situations besides file systems
as well. One common source of the problem is a byte string valid in
one charset that is converted according to a different charset. For
example, the byte string <E0 30> is invalid in SJIS, but is
perfectly meaningful in Latin-1, representing "à0".

One possible solution is to enable all charset converters to
losslessly (reversibly) convert to Unicode. That is, any sequence of
bytes can be converted by each charset converter to a Unicode string,
and that Unicode string would be converted back to exactly that
original sequence of bytes by the converter. This precludes, for
example, the charset converter's mapping two different [unmappable](http://unicode.org/reports/tr22/#Illegal_and_Unassigned) byte sequences to
`[U+FFFD](http://unicode.org/cldr/utility/character.jsp?a=FFFD)`
( � ) REPLACEMENT CHARACTER, because the original bytes
could not be recovered. It also precludes having "fallbacks" (see <http://unicode.org/reports/tr22/>): cases where two different byte
sequences map to the same Unicode sequence.

#### 3.7.1 [PEP 383 Approach](#TOC-PEP-383-Approach)

[PEP 383](http://www.python.org/dev/peps/pep-0383/) takes
this approach. It enables lossless conversion to Unicode by
converting all "unmappable" sequences to a sequence of one or more
isolated surrogate code points. That is, each unmappable byte's value
is a code point whose value is 0xDC00 plus byte value. With this
mechanism, every maximal subsequence of bytes that can be reversibly
mapped to Unicode by the charset converter is so mapped; any
intervening subsequences are converted to a sequence of high
surrogates. The result is a [Unicode
String](http://unicode.org/glossary/#unicode_string), but not a well-formed UTF sequence.

For example, suppose that the byte 81 is illegal in charset *n*.
When converted to Unicode, PEP 383 represents this as U+D881. When
mapped back to bytes for charset *n*, it turns back into the
byte 81. This allows the source byte sequence to be reversibly
represented in a [Unicode
String](http://unicode.org/glossary/#unicode_string), no matter what the contents. If this mechanism is applied to
a charset converter that has no fallbacks from bytes to Unicode, then
the charset converter becomes reversible (from bytes to Unicode to
bytes).

This only works when the [Unicode
String](http://unicode.org/glossary/#unicode_string) is converted back with the very same charset converter that
was used to convert from bytes. For more information on PEP 383, see
<http://python.org/dev/peps/pep-0383/>.

#### 3.7.2 [Notation](#TOC-Notation)

The following notation is used in the rest of this section:

* B2Un is the bytes-to-Unicode converter for charset n
* U2Bn is the Unicode-to-bytes converter for charset n
* An *invalid* byte is one that would be mapped by a PEP
  to a high surrogate, because it is part of a sequence that is not
  reversibly mappable. The context of the byte is important: for
  example, the byte 81 alone might be unmappable, while an 81 followed
  by a 40 is valid.

#### 3.7.3 [Security](#TOC-Security)

Unicode implementations have been subject to a number of security
exploits centered around ill-formed encoding, such as <http://blogs.technet.com/srd/archive/2009/05/18/more-information-about-the-iis-authentication-bypass.aspx>.
Systems making incorrect use of a PEP 383-style mechanism are subject
to such an attack.

Suppose that the source byte stream is <A B X D>, and
that according to the charset converter being used (n), X is an
invalid byte. B2Un transforms the byte stream into Unicode as <G Y
H>, where Y is an isolated surrogate. U2Bn maps back to the
correct original <A B X D>. This is the intended usage of PEP
383.

The problem comes when that Unicode sequence is converted back to
bytes by a different charset converter *m*. Suppose that U2Bm
maps Y into a valid byte representing "/", or any one of a number of
other security-sensitive characters. That means that converting <G
Y H> via U2Bm to bytes, and back to Unicode results in the string
"G/Y", where the "/" did not exist in the original.

This violates one of the cardinal security rules for
transformations of Unicode strings: creating a character where no
valid character previously existed. This was at the heart of the
"non-shortest form" security exploits. A gatekeeper watches for
suspicious characters. It does not see Y as one of them, but past the
gatekeeper, a conversion of U2Bm followed by B2Um results in a
suspicious character where none previously existed.

There is a suggested solution for this. A converter would map an
isolated surrogate Y onto a byte stream only when the resulting byte
would be an *illegal* byte. If not, then an exception would be
thrown, or a replacement byte or byte sequence must be used instead
(such as the SUB character). For details, see *Section 3.7.5
 [Safely Converting to
Bytes](#TOC-Safely-Converting-to-Bytes)*. This replacement would be similar to what is used when trying to
convert a Unicode character that cannot be represented in the target
encoding. This strategy preserves the ability to round-trip when the
same encoding is used, but prevents security attacks. *Note
that simply deleting Y in the output is not an option, because that
is also open to security exploits.*

When used as intended in Python, PEP 383 appears unlikely to
present security problems. According to information from the author:

* PEP 383 is only intended for use with ASCII-based charsets.
* Only bytes >= 128 will be transformed to D8xx or back.
* The combination of these factors means that no
  ASCII-repertoire characters (which represent the most serious
  problems for security) would ever be generated.
* The primary use of PEP 383 is in file systems, where the [Unicode
  String](http://unicode.org/glossary/#unicode_string) resulting from PEP 383 is only converted back to bytes on
  the same system, using the same charset converter.

However, if PEP 383 is used more generally by applications, or
similar systems are used more generally, security exploits are
possible.

#### 3.7.4 [Interoperability](#TOC-Interoperability)

Using isolated surrogates (D8xx) as the way to represent the
unconvertible bytes appears harmless at first glance. However, it
presents certain interoperability and security issues. Such isolated
surrogates are not well-formed. Although they can be represented in a
[Unicode
String](http://unicode.org/glossary/#unicode_string), they are not supported by conformant UTF-8, UTF-16, or
UTF-32 converters or implementations. This may cause interoperability
problems, because many systems replace incoming ill-formed Unicode
sequences by replacement characters. It may also cause security
problems. Although strongly discouraged for security reasons, some
implementations may delete the isolated surrogates, which can cause a
security problem when two separated substrings become adjacent.

There are different alternatives:

1. Use 256 private-use code points, somewhere in the ranges
   F0000..FFFFD or 100000..10FFFD. This would probably cause the fewest
   security and interoperability problems. There is, however, some
   possibility of collision with other uses of private-use characters.
2. Use pairs of noncharacter code points in the range
   FDD0..FDEF. These are "super" private-use characters, and are
   discouraged for general interchange. The transformation would take
   each nibble of a byte Y, and add to FDD0 and FDE0, respectively.
   However, noncharacter code points may be replaced by `[U+FFFD](http://unicode.org/cldr/utility/character.jsp?a=FFFD)` ( � ) REPLACEMENT CHARACTER by some implementations,
   especially when they use them internally. *(Again, incoming
   characters must never be deleted, because that can cause security
   problems.)*

#### 3.7.5 [Safely Converting to Bytes](#TOC-Safely-Converting-to-Bytes)

The following describes how to safely convert a Unicode buffer
U1 to a byte buffer B1 when the D8xx convention is used.

* Convert from Unicode buffer U1 to byte buffer B1.
* If there were any D8XX's in U1
  + Convert back to Unicode buffer U2 (according to the same
    Charset C1)
  + If U1 != U2, throw an exception.

This approach is simple, and sufficient for the vast majority
of implementations because the frequency of D8xx's will be extremely
low. Where necessary, there are a number of different optimizations
that can be used to increase performance.

### [3.8 Idempotence](#TOC-Idempotence)

idempotence is a property of a function, whereby repeated
application of that function produces the same result. That is:
f(f(x)) = f(x). Some functions have this property, such as f(x) :=
|x|, while others do not, such as f(x) := x+1.

Properties that are expected to be idempotent—but actually aren't—can
represent severe problems for security. For more information, see the
[Unicode
Security FAQ](http://www.unicode.org/faq/security.html).

---

## Appendix A [Script Icons](#Missing_Glyph_Icons)

*Table 10, [Sample
Script Icons](#TableSampleScriptIcons)* shows sample icons that can be used to represent
scripts in user interfaces. They are derived from from the *Last
Resort Font*, which is available on the Unicode site [[LastResort](#LastResort)]. While the Last Resort Font is
organized by Unicode block instead of by script, the glyphs from that
font can also be used to represent scripts. This is done by picking
one of the possible glyphs whenever a script spans multiple blocks.

Table 10. [Sample Script Icons](#TableSampleScriptIcons)

| X Arabic | X Armenian | X Bengali |
| X Bopomofo | X Braille | X Buginese |
| X Buhid | X Canadian Aboriginal | X Cherokee |
| X Coptic | X Cypriot | X Cyrillic |
| X Deseret | X Devanagari | X Ethiopic |
| X Georgian | X Glagolitic | X Gothic |
| X Greek | X Gujarati | X Gurmukhi |
| X Hangul | X Han | X Hanunoo |
| X Hebrew | X Hiragana | X Latin |
| X Lao | X Limbu | X Linear B |
| X Kannada | X Katakana | X Kharoshthi |
| X Khmer | X Mongolian | X Myanmar |
| X Malayalam | X Ogham | X Old Italic |
| X Old Persian | X Oriya | X Osmanya |
| X New Tai Lue | X Runic | X Shavian |
| X Sinhala | X Syloti Nagri | X Syriac |
| X Tagalog | X Tagbanwa | X Tai Le |
| X Tamil | X Telugu | X Thaana |
| X Thai | X Tibetan | X Tifinagh |
| X Ugaritic | X Yi |  |
| Special cases | | |
| X Common | X Inherited |  |

## Appendix B [Language-Based Security](#Language_Based_Security)

It is very hard to determine exactly which characters are used
by a language. For example, English is commonly thought of as having
letters A-Z, but in customary practice many other letters appear as
well. For examples, consider proper names such as "Zoë",
words from the Oxford English Dictionary such as
"coöperate", and many foreign words in common use:
"René", ‘naïve’, ‘déjà vu’, ‘résumé’, and so on.Thus the
problem with restricting identifiers by language is the difficulty in
defining exactly what that implies. See the following definitions:

> **Language**: Communication of thoughts and feelings through a
> system of arbitrary signals, such as voice sounds, gestures, or
> written symbols. Such a system including its rules for combining its
> components, such as words. Such a system as used by a nation,
> people, or other distinct community; often contrasted with dialect.
> *(From American Heritage, Web search)*

> **Language**: The systematic, conventional use of sounds, signs,
> or written symbols in a human society for communication and
> self-expression. Within this broad definition, it is possible to
> distinguish several uses, operating at different levels of
> abstraction. In particular, linguists distinguish between language
> viewed as an act of speaking, writing, or signing, in a given
> situation […], the linguistic system underlying an individual’s use
> of speech, writing, or sign […], and the abstract system underlying
> the spoken, written, or signed behaviour of a whole community. *(David
> Crystal, An Encyclopedia of Language and Languages)*

> **Language** is a finite system of arbitrary symbols combined
> according to rules of grammar for the purpose of communication.
> Individual languages use sounds, gestures, and other symbols to
> represent objects, concepts, emotions, ideas, and thoughts…
>
> Making a principled distinction between one language and
> another is usually impossible. For example, the boundaries between
> named language groups are in effect arbitrary due to blending
> between populations (the dialect continuum). For instance, there are
> dialects of German very similar to Dutch which are not mutually
> intelligible with other dialects of (what Germans call) German.
>
> Some like to make parallels with biology, where it is not always
> possible to make a well-defined distinction between one species and
> the next. In either case, the ultimate difficulty may stem from the
> interactions between languages and populations.  *<http://en.wikipedia.org/wiki/Language>, September 2005*

The Unicode Common Locale Data
Repository (CLDR) supplies a set of exemplar characters per language,
the characters used to write that language. Originally, there was a
single set per language. However, it became clear that a single set
per language was far too restrictive, and the structure was revised
to provide auxiliary characters, other characters that are in more or
less common use in newspapers, product and company names, and so on.
For example, auxiliary set provided for English is: [áà éè íì óò úù
âêîôû æœ äëïöüÿ āēīōū ăĕĭŏŭ åø çñß]. As this set makes clear, the
frequency of occurrence of a given character may depend greatly on
the domain of discourse, and it is difficult to draw a precise line;
instead there is a trailing off of frequency of occurrence.

In contrast, the definitions of writing systems and scripts are
much simpler:

> **Writing system**: A determined collection of characters or
> signs together with an associated conventional spelling of texts,
> and the principle therefore. *(extrapolated from
> Daniels/Bright: The World's Writing Systems)*
>
> **Script**: A collection of symbols used to represent textual
> information in one or more writing systems.

Writing systems and scripts only relate to the written form of
the language and do not require judgment calls concerning language
boundaries. Therefore security considerations that relate to written
form of languages are often better served by using the concept of
writing system and/or script.

**Note:** A writing system uses one or more scripts, plus
additional symbols such as punctuation. For example, the Japanese
writing system uses the scripts Hiragana, Katakana, Kanji (Han
ideographs), and sometimes Latin.

Nevertheless, language identifiers
are extremely useful in other contexts. They allow cultural tailoring
for all sorts of processing such as sorting, line breaking, and text
formatting.

**Note:** As mentioned below, language identifiers (called
language tags), may contain information about the writing system and
can help to determine an appropriate script.

As explained in the *Section 6.1, Writing Systems* of [[Unicode](#Unicode)], scripts can be classified in various
groups: Alphabets, Abjads, Abugidas, Logosyllabaries, Simple or
Featural Syllabaries. Those classifications, in addition to historic
evidence, makes it reasonably easy to arrange encoded characters into
script classes.

The set of characters sharing the same script value determines a
script set. The script value can be easily determined by using the
information available in *UAX #24: Unicode Script Property*.
No such concept exists for languages. It is generally not possible to
attach a single language property value to a given character.
Similarly, it is not possible to determine the exact repertoire of
characters used for the written expression of most common languages.

Creating "safe character
sets" is an important goal in a security context, and it would
appear that the characters used in a language is an obvious choice.
However, because of the indeterminate set of characters used for a
language, it is typically more effective to move to the higher level,
the script, which can be more easily specified and tested.

Customarily, languages are written in a small number of scripts. This
is reflected in the structure of language tags, as defined by BCP47
"Tags for the Identification of Languages", which are the
industry standard for the identification of languages. Languages that
require more than one script are given separate language tags. See <http://www.iana.org/assignments/language-subtag-registry>.

The CLDR also provides a mapping from languages to scripts which is
being extended over time to more languages. *Table 11, [CLDR Script Mappings](#TableCLDRScriptMappings)* provides
examples of the association between language tags and default
scripts. (CLDR also provides other information about scripts, such as
the most likely language for each script, and the most likely script
for each language, plus script metadata.)

Table 11. [CLDR Script Mappings](#TableCLDRScriptMappings)

| Language tag | Script(s) | Comment |
| en | Latin | Content in ‘en’ is presumed to be in Latin script, unless where explicitly marked |
| az- | Cyrillic | Azeri in Cyrillic script used in Azerbaijan |
| az-Latn-AZ | Latin | Azeri in Latin script used in Azerbaijan |
| az | Latin, | Azeri as used generically, can be Latin or Cyrillic |
| ja | Han, | Japanese as used in Japan or elsewhere |

The strategy of using scripts works extremely well for most of
the encoded scripts because users are either familiar with the
entirety of the script content, or the outlying characters are not
very confusable. There are however a few important exceptions, such
as the Latin and Han scripts. In those cases, it is recommended to
exclude certain technical and historic characters except where there
is a clear requirement for them in a language.

Lastly, text confusability is an inherent attribute of many writing
systems. However, if the character collection is restricted to the
set familiar to a culture, it is expected by the user, and he or she
can therefore weigh the accuracy of the written or displayed text.
The key is to (normally) restrict identifiers to a single script,
thus vastly reducing the problems with confusability. For example, in
Devanagari, the letter *aa*: आ can be confused with the
sequence consisting of the letter a अ followed by the vowel sign aa
ा. However, this is a confusability a Hindi speaking user may be
familiar with, as it relates to the structure of the Devanagari
script.

In contrast, text confusability that crosses script boundary is
completely unexpected by users within a culture, and unless some
mitigation is in place, it will create significant security risk. For
example, the Cyrillic small letter п ("pe") is
undistinguishable from the Greek letter π in at least some fonts, and
the confusion is likely to be unknown to users in cultural context
using either script. Restricting the identifier to either wholy Greek
or wholy Cyrillic will usually avoid this issue.

## [Acknowledgments](#Acknowledgments)

Mark Davis and Michel Suignard authored the bulk of the text,
under the direction of the Unicode Technical Committee. Steven Loomis
and other people on the ICU team were very helpful in developing the
original proposal for this technical report. Thanks also to the
following people for their feedback or contributions to this document
or earlier versions of it: Julie Allen, Stéphane Bortzmeyer, Roger
Costello, Douglas Davidson, Martin Dürst, Peter Edberg, Asmus
Freytag, Deborah Goldsmith, Paul Hoffman, Patrick L. Jones, Peter
Karlsson, Gervase Markham, Eric Muller, Erik van der Poel, Michael
van Riper, Marcos Sanz, Alexander Savenkov, Markus Scherer, Dominikus
Scherkl, Dave Thompson, Kenneth Whistler, and Yoshito Umaoka.

## [References](#References)

| [[CharMod](#CharMod)] | Character Model for the World Wide Web 1.0: Fundamentals <http://www.w3.org/TR/charmod/> |
| --- | --- |
| [[DCore](#DCore)] | Derived Core Properties <http://www.unicode.org/Public/UNIDATA/DerivedCoreProperties.txt> |
| [[DemoConf](#DemoConf)] | <http://unicode.org/cldr/utility/confusables.jsp> |
| [[DemoIDN](#DemoIDN)] | <http://unicode.org/cldr/utility/idna.jsp> |
| [[DemoIDNChars](#DemoIDNChars)] | <http://unicode.org/cldr/utility/list-unicodeset.jsp?a=\p{age%3D3.2}-\p{cn}-\p{cs}-\p{co}&abb=on&g=uts46+idna+idna2008> |
| [[Display](#Display)] | Display Problems? <http://www.unicode.org/help/display_problems.html> |
| [[FAQSec](#FAQSec)] | Unicode FAQ on Security Issues <http://www.unicode.org/faq/security.html> |
| [[ICANN](#ICANN)] | ICANN Documents:  Internationalized Domain Names <http://www.icann.org/en/topics/idn/>The IDN Variant Issues Project <http://www.icann.org/en/topics/new-gtlds/idn-vip-integrated-issues-23dec11-en.pdf> |
| [[IDNA2003](#IDNA2003)] | The IDNA2003 specification is defined by a cluster of IETF RFCs:  * IDNA [[RFC3490](#RFC3490)] * Nameprep [[RFC3491](#RFC3491)] * Punycode [[RFC3492](#RFC3492)] * Stringprep [[RFC3454](#RFC3454)]. |
| [[IDNA2008](#IDNA2008)] | The IDNA2008 specification is defined by a cluster of IETF RFCs:  * Internationalized Domain Names for Applications (IDNA):   Definitions and Document Framework <http://tools.ietf.org/html/rfc5890> * Internationalized Domain Names in Applications (IDNA)   Protocol <http://tools.ietf.org/html/rfc5891> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) <http://tools.ietf.org/html/rfc5892> * Right-to-Left Scripts for Internationalized Domain Names   for Applications (IDNA) <http://tools.ietf.org/html/rfc5893>  There are also informative documents:  * Internationalized Domain Names for Applications (IDNA):   Background, Explanation, and Rationale <http://tools.ietf.org/html/rfc5894> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) - Unicode 6.0 <http://tools.ietf.org/html/rfc6452> |
| [[IDN-Demo]](#IDN_Demo) | <http://unicode.org/cldr/utility/idna.jsp> |
| [[IDN-FAQ](#IDN_FAQ)] | <http://www.unicode.org/faq/idn.html> |
| [[IDN-Demo](#IDN-Demo)] | ICU (International Components for Unicode) IDN Demo <http://demo.icu-project.org/icu-bin/icudemos> |
| [[Feedback](#Feedback)] | Reporting Form<http://www.unicode.org/reporting.html>*For reporting errors and requesting information online.* |
| [[LastResort](#LastResort)] | Last Resort Font <http://unicode.org/policies/lastresortfont_eula.html> (See also <http://www.unicode.org/charts/lastresort.html>) |
| [[LDAP](#LDAP)] | Lightweight Directory Access Protocol (LDAP): Internationalized String Preparation <http://www.rfc-editor.org/rfc/rfc4518.txt> |
| [[NFKC\_Casefold](#NFKC_CaseFold)] | The Unicode property specified in [[UAX44](#UAX44)], and defined by the data in [DerivedNormalizationProps.txt](http://www.unicode.org/Public/UNIDATA/DerivedNormalizationProps.txt) (search for "NFKC\_Casefold"). |
| [[Reports](#Reports)] | Unicode Technical Reports <http://www.unicode.org/reports/>*For information on the status and development process for technical reports, and for a list of technical reports.* |
| [[RFC1034](#RFC1034)] | P. Mockapetris. "DOMAIN NAMES - CONCEPTS AND FACILITIES", RFC 1034, November 1987. <http://ietf.org/rfc/rfc1034.txt> |
| [[RFC1035](#RFC1035)] | P. Mockapetris. "DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION", RFC 1034, November 1987. <http://ietf.org/rfc/rfc1035.txt> |
| [[RFC1535](#RFC1535)] | E. Gavron. "A Security Problem and Proposed Correction With Widely Deployed DNS Software", RFC 1535, October 1993 <http://ietf.org/rfc/rfc1535.txt> |
| [[RFC3454](#RFC3454)] | P. Hoffman, M. Blanchet. "Preparation of Internationalized Strings ("stringprep")", RFC 3454, December 2002. <http://ietf.org/rfc/rfc3454.txt> |
| [[RFC3490](#RFC3490)] | Faltstrom, P., Hoffman, P. and A. Costello, "Internationalizing Domain Names in Applications (IDNA)", RFC 3490, March 2003. <http://ietf.org/rfc/rfc3490.txt> |
| [[RFC3491](#RFC3491)] | Hoffman, P. and M. Blanchet, "Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)", RFC 3491, March 2003. <http://ietf.org/rfc/rfc3491.txt> |
| [[RFC3492](#RFC3492)] | Costello, A., "Punycode: A Bootstring encoding of Unicode for Internationalized Domain Names in Applications (IDNA)", RFC 3492, March 2003. <http://ietf.org/rfc/rfc3492.txt> |
| [[RFC3743](#RFC3743)] | Konishi, K., Huang, K., Qian, H. and Y. Ko, "Joint Engineering Team (JET) Guidelines for Internationalized Domain Names (IDN) Registration and Administration for Chinese, Japanese, and Korean", RFC 3743, April 2004. <http://ietf.org/rfc/rfc3743.txt> |
| [[RFC3986](#RFC3986)] | T. Berners-Lee, R. Fielding, L. Masinter. "Uniform Resource Identifier (URI): Generic Syntax", RFC 3986, January 2005. <http://ietf.org/rfc/rfc3986.txt> |
| [[RFC3987](#RFC3987)] | M. Duerst, M. Suignard. "Internationalized Resource Identifiers (IRIs)", RFC 3987, January 2005. <http://ietf.org/rfc/rfc3987.txt> |
| [[Stability](#Stability)] | Unicode Character Encoding Stability Policy <http://www.unicode.org/standard/stability_policy.html> |
| [[UCD](#UCD)] | Unicode Character Database. <http://www.unicode.org/ucd/> *For an overview of the Unicode Character Database and a list of its associated files.* |
| [[UCDFormat](#UCDFormat)] | UCD File Format <http://www.unicode.org/reports/tr44/#Format_Conventions> |
| [[UAX9](#UAX9)] | UAX #9: The Bidirectional Algorithm <http://www.unicode.org/reports/tr9/> |
| [[UAX15](#UAX15)] | UAX #15: Unicode Normalization Forms <http://www.unicode.org/reports/tr15/> |
| [[UAX24](#UAX24)] | UAX #24: Unicode Script Property <http://www.unicode.org/reports/tr24/> |
| [[UAX31](#UAX31)] | UAX #31, Identifier and Pattern Syntax <http://www.unicode.org/reports/tr31/> |
| [[UAX44](#UAX44)] | UAX #44:*Unicode Character Database* <http://www.unicode.org/reports/tr44/> |
| [[Unicode](#Unicode)] | The Unicode Standard*For the latest version, see:* <http://www.unicode.org/versions/latest/> |
| [[UTS10](#UTS10)] | UTS #10: Unicode Collation Algorithm <http://www.unicode.org/reports/tr10/> |
| [[UTS18](#UTS18)] | UTS #18: Unicode Regular Expressions <http://www.unicode.org/reports/tr18/> |
| [[UTS22](#UTS22)] | UTS #22: Character Mapping Markup Language (CharMapML) <http://www.unicode.org/reports/tr22/> |
| [[UTS39](#UTS39)] | UTS #39: Unicode Security Mechanisms <http://www.unicode.org/reports/tr39/> |
| [[UTS46](#UTS46)] | Unicode IDNA Compatibility Processing [http://www.unicode.org/reports/tr46/](http://www.unicode.org/reports/tr46/%20) |
| [[Versions](#Versions)] | Versions of the Unicode Standard <http://www.unicode.org/standard/versions/> *For information on version numbering, and citing and referencing the Unicode Standard, the Unicode Character Database, and Unicode Technical Reports.* |

## [Modifications](#Modifications)

The following summarizes modifications from the previous
revisions of this document.

### Revision 15

* *Section 1.1 [Structure](#Structure)*
  + Added a note on the broad use of the term “URL”, and
    replaced some instances elsewhere of URI and IRI.
* *Section 2 [Visual
  Security Issues](#visual_spoofing)*
  + Added description of *gatekeeper-confusable*
    strings.
* *Section 2.8.1 [Punycode
  Spoofs](#Punycode_Spoofs)*
  + Added a description of how the display of Punycode URLs
    instead of Unicode can be worse for spoofing.
* *Section 2.10 [Restriction
  Levels and Alerts](#Security_Levels_and_Alerts)*
  + Add a second example of an alert, for mixed scripts.
* *Section 2.11.2 [Recommendations for
  Programmers](#Recommendations_General)*
  + Added note on the use of Catalan in identifiers.
* Copyediting
  + Added Tables to TOC

Revision 14 being a proposed update, only changes between
revisions 13 and 15 are noted here.

### Revision 13

* *Section 3.1.1 [Ill-Formed
  Subsequences](#Ill-Formed_Subsequences)*
  + Fixed various typos.
* *Section 3.2 [Text
  Comparison (Sorting, Searching, Matching)](#Text_Comparison)*
  + Added description of issues with transitivity
* *Section 3.7.1 [PEP
  383 Approach](#TOC-PEP-383-Approach)*
  + Removed the incorrect term 'high' on 'surrogate'.
* *Section 3.8 [Idempotence](#TOC-Idempotence)*
  + Added pointer to article about idempotence.
* Fleshed out table of contents, fixed links, and incorrect
  numbering of sections in 2.9-2.10.
* Changed references to point to the <http://www.unicode.org/faq/security.html>
  for links that might change.

Revision 12 being a proposed update, only changes between
revisions 11 and 13 are noted here.

### Revision 11

* Moved definition of Restriction Levels to UTS #39
* Fixed reported typos, and updated references.

Revision 10 being a proposed update, only changes between
revisions 9 and 11 are noted here.

### Revision 9

* Added table numbers and explicit references to tables in the
  text.
* Expanded the introduction to Section 3 somewhat.
* Removed Appendices A, B, D, E, and F, and renumbered the
  other Appendices.
* Moved external references to the FAQ
* Cleaned up references to UTS39 and UTS46
* Removed former Appendix F.
* Added Section 3.6, Secure Encoding Conversion.
* Added Section 3.7, Enabling Lossless Conversion.
* Removed old Section 3.6, [Recommendations](#Non_Visual_Recommendations)
* Clarified *Section 3.5, [Deletion of Code Points](#Deletion_of_Noncharacters)*
* Miscellaneous other editorial changes.

Revision 8 being a proposed update, only changes between
revisions 7 and 9 are noted here.

### Revision 7

* Added explanation of UTF-8 over-consumption attack in 3.1 [UTF-8 Exploits](#UTF-8_Exploit)
* Added subsection of 2.8.2 [Mapping
  and Prohibition](#Mapping_and_Prohibition) describing the Unicode 5.1 changes in identifiers.
* Added 3.4 [Property
  and Character Stability](#Property_and_Character_Stability)
* Updated Unicode reference.
* Broke 3.1.1 into two sections, adding header 3.1.2: [Substituting
  for Ill-Formed Subsequences](#Substituting_for_Ill_Formed_Subsequences), with some small wording changes around
  it. In particular, pointed to *Appendix E. Conformance Changes
  to the Standard* in Unicode 5.1.
* Added 3.5 [Deletion
  of Noncharacters](#Deletion_of_Noncharacters)
* Added before Sample Country Registries: "These are only
  for illustration: the exact sets may change over time, so the
  particular authorities should be consulted rather than relying on
  these contents. Some registrars now also offer machine-readable
  formats."
* Minor editing

Revision 6 being a proposed update, only changes between
revisions 4 and 7 are noted here.

### Revision 4

* Moved the contents of *Appendix A Identifier
  Characters*, *Appendix B, Confusable Detection*, and *Appendix
  D Mixed Script Detection* to the new [[UTS39](#UTS39)].
  The appendices remain (to avoid renumbering), but simply point to
  the new locations. Changed references to point to the new sections
  in [[UTS39](#UTS39)].
* Alphabetized *Appendix C. [Script Icons](#Missing_Glyph_Icons).*
* Added *Appendix G. [Language-Based Security](#Language_Based_Security).*
* Changed the "highlighting" of the core domain name
  to the whole domain name in Section 2.6, [Syntax
  Spoofing](#Syntax_Spoofing).
* Replaced *Section 2.9.4  [Recommendations for
  Registries](#Recommendations_Registries)* based on the UTC decisions.
* Removed the contents of *Appendix E. Future Topics*,
  incorporating material to address the issues in *Section 3.2,
  [Text Comparison](#Text_Comparison), Section 3.3, [Buffer Overflows](#Buffer_Overflows)*, and a few other places in the document.
* Minor editing

### **Revision 3**

* Cleaned up references
* Added Related Material section
* Add section on [Casefolded
  Format](#Case_Folded_Format)
* Refined recommendations on single-script confusables
* Reorganized introduction, and reversed the order of the main
  sections.
* Retitled the main sections
* Restructured the recommendations for Visual Security
* Added more examples
* Incorporated changes for user feedback
* Major restructuring, especially appendices. Moved data files
  and other references into the references, added section on
  confusables, scripts, future topics, revised the identifiers section
  to point at the newer data file.
* Incorporated changes for all the editorial notes: shifted
  some sections.
* Added sections on bidi, appendix F.
* Revised data files

### **Revision 2**

* Moved recommendations to separate section.
* Added new descriptions, recommendations.
* Pointed to draft data files.

### **Revision 1**

* Initial version, following proposal to UTC.
* Incorporated comments, restructured, added To Do items.

---

Copyright © 2004-2014 Unicode, Inc. All
Rights Reserved. The Unicode Consortium makes no expressed or implied
warranty of any kind, and assumes no liability for errors or
omissions. No liability is assumed for incidental and consequential
damages in connection with or arising out of the use of the
information or programs contained or accompanying this technical
report. The Unicode [Terms
of Use](http://www.unicode.org/copyright.html) apply.

Unicode and the Unicode logo are trademarks
of Unicode, Inc., and are registered in some jurisdictions.



=== Content from www.openwall.com_73f7b514_20250111_094133.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Hash Suite - Windows password security audit tool. GUI, reports in PDF.](https://hashsuite.openwall.net) | | --- | |
| --- | --- |

[[<prev]](../../../2021/10/31/1) [[next>]](2) [[thread-next>]](4) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <aa5e1a0e-daba-41f2-1f98-91d36584f119@pietroalbini.org>
Date: Mon, 1 Nov 2021 01:01:46 +0100
From: Pietro Albini <pietro@...troalbini.org>
To: oss-security@...ts.openwall.com
Subject: CVE-2021-42574: rustc 1.56.0 and bidirectional-override codepoints in
 source code

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

The Rust Security Response WG was notified of a security concern affecting
source code containing "bidirectional override" Unicode codepoints: in some
cases the use of those codepoints could lead to the reviewed code being
different than the compiled code.

This is a vulnerability in the Unicode specification, and its assigned
identifier is CVE-2021-42574. While the vulnerability itself is not a rustc
flaw, we're taking proactive measures to mitigate its impact on Rust
developers.

## Overview

Unicode has support for both left-to-right and right-to-left languages, and to
aid writing left-to-right words inside a right-to-left sentence (or vice versa)
it also features invisible codepoints called "bidirectional override".

These codepoints are normally used across the Internet to embed a word inside a
sentence of another language (with a different text direction), but it was
reported to us that they could be used to manipulate how source code is
displayed in some editors and code review tools, leading to the reviewed code
being different than the compiled code. This is especially bad if the whole
team relies on bidirectional-aware tooling.

As an example, the following snippet (with `{U+NNNN}` replaced with the Unicode
codepoint `NNNN`):

```rust
if access_level != "user{U+202E} {U+2066}// Check if admin{U+2069} {U+2066}" {
```

...would be rendered by bidirectional-aware tools as:

```rust
if access_level != "user" { // Check if admin
```

## Affected Versions

Rust 1.56.1 introduces two new lints to detect and reject code containing the
affected codepoints. Rust 1.0.0 through Rust 1.56.0 do not include such lints,
leaving your source code vulnerable to this attack if you do not perform
out-of-band checks for the presence of those codepoints.

To assess the security of the ecosystem we analyzed all crate versions ever
published on crates.io (as of 2021-10-17), and only 5 crates have the affected
codepoints in their source code, with none of the occurrences being malicious.

## Mitigations

We will be releasing Rust 1.56.1 today, 2021-11-01, with two new
deny-by-default lints detecting the affected codepoints, respectively in string
literals and in comments. The lints will prevent source code files containing
those codepoints from being compiled, protecting you from the attack.

If your code has legitimate uses for the codepoints we recommend replacing them
with the related escape sequence. The error messages will suggest the right
escapes to use.

If you can't upgrade your compiler version, or your codebase also includes
non-Rust source code files, we recommend periodically checking that the
following codepoints are not present in your repository and your dependencies:
U+202A, U+202B, U+202C, U+202D, U+202E, U+2066, U+2067, U+2068, U+2069.

## Timeline of events

* 2021-07-25: we received the report and started working on a fix.
* 2021-09-14: the date for the embargo lift (2021-11-01) is communicated to us.
* 2021-10-17: performed an analysis of all the source code ever published to
   crates.io to check for the presence of this attack.
* 2021-11-01: embargo lifts, the vulnerability is disclosed and Rust 1.56.1 is
   released.

## Acknowledgments

Thanks to Nicholas Boucher [1] and Ross Anderson [2] from the University of
Cambridge for disclosing this to us according to our security policy [3]!

We also want to thank the members of the Rust project who contributed to the
mitigations for this issue. Thanks to Esteban Küber for developing the lints,
Pietro Albini for leading the security response, and many others for their
involvement, insights and feedback: Josh Stone, Josh Triplett, Manish
Goregaokar, Mara Bos, Mark Rousskov, Niko Matsakis, and Steve Klabnik.

## Appendix: Homoglyph attacks

As part of their research, Nicholas Boucher and Ross Anderson also uncovered a
similar security issue identified as CVE-2021-42694 involving homoglyphs inside
identifiers. Rust already includes mitigations for that attack since Rust
1.53.0. Rust 1.0.0 through Rust 1.52.1 is not affected due to the lack of
support for non-ASCII identifiers in those releases.

[1] <https://github.com/nickboucher>
[2] <https://www.cl.cam.ac.uk/~rja14>
[3] <https://www.rust-lang.org/policies/security>
-----BEGIN PGP SIGNATURE-----

iQIzBAEBCgAdFiEEV2nIi/XdPRSiNKes77mGCudSDawFAmF+hJkACgkQ77mGCudS
DaxljBAAtBlcz3g8h8lZvzOfOb8zRNfgw7mvBxr1fNyjNkV6n/xJA5yO6DC7K5ra
qqHXVdn7yfN5PvCBB7+vqQMDbM3X+m0Ui1eSIW09hGuyqBEc2+3UXlcWe0RVFBjT
ZiGb0TvHqaCZT9z+fRWtkbUia/vnZfTfJkQ0Xj4SE325I0k3uimBpJ+jZFLl98kR
1fnQtDkPQHK+VG5PdlYrZiGB+CibwlJWSqi7qyedPE7BVyFxSn2fHuFmQ4rUpBQc
fAMWI83B+HuQ650vJY2mGCq2qedsTaUDK9S9oF+7pl7FtSjlsBdmJ9ikGB1FFlVP
/6l0DZBRx2o3dp0KlD7k/MsXWZdo2Wg3wRamCltA/9f+uZBxLsdwJ+z1mvZB+wah
jDkrDMOXdacZA5Yr69swY5UnTDyM5oZixT6LQTDCTQTBGMOLFsWTc3kNk7v4r+vj
CR6pVj/2+jqy3hI/IrAWm129KVpyp8XM4KQbMenOBN32eBbDOtIZBn7cjqizfamU
mP5dvUaIfUzOkHcr1Bcx5WJSSTgON8pVTb6AsreCY7rSG2fiHT2beb6W5yZFhdm2
vWefxdcsL/h5WF0NHO5Hgj5o5a29sCpKOuSLfyW6GsA8waSRPkZBs2YWyzidhFr3
A9hmwxWAyDQv8NZZcThepdMjFT8zoDq6cb/aDX28OOjIfJAFQWQ=
=IsMc
-----END PGP SIGNATURE-----

View attachment "[rust-1.56.0-fix.patch](1/1)" of type "text/x-patch" (34016 bytes)

View attachment "[rust-1.56.0-fix.patch.asc](1/2)" of type "text/plain" (833 bytes)

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from www.kb.cert.org_06a463ed_20250111_094135.html ===


search

menu

icon-carat-right

cmu-wordmark

* ×
* [Home](/vuls/)
* [Notes](/vuls/bypublished/desc/)
* [Search](/vuls/search/)
* [Report a Vulnerability](/vuls/report/)
* [Disclosure Guidance](/vuls/guidance/)
* [VINCE](/vince/)

[[Carnegie Mellon University](https://www.cmu.edu)](https://www.cmu.edu/)

# [Software Engineering Institute](https://www.sei.cmu.edu/)

## CERT Coordination Center

* [Home](/vuls/)
* [Notes](/vuls/bypublished/desc/)
* [Search](/vuls/search/)
* [Report a Vulnerability](/vuls/report/)
* [Disclosure Guidance](/vuls/guidance/)
* [VINCE](/vince/)

* [Home](/vuls/)
* [Notes](/vuls/bypublished/desc/)
* Current:  VU#999008

## Compilers permit Unicode control and homoglyph characters

#### Vulnerability Note VU#999008

Original Release Date: 2021-11-09 | Last Revised: 2024-12-10

---

### Overview

Attacks that allow for unintended control of Unicode and homoglyphic characters, described by the researchers in this [report](https://www.trojansource.codes/trojan-source.pdf) leverage text encoding that may cause source code to be interpreted differently by a compiler than it appears visually to a human reviewer. Source code compilers, interpreters, and other development tools may permit Unicode control and homoglyph characters, changing the visually apparent meaning of source code.

### Description

Internationalized text encodings require support for both left-to-right languages and also right-to-left languages. Unicode has built-in functions to allow for encoding of characters to account for bi-directional, or Bidi ordering. Included in these functions are characters that represent non-visual functions. These characters, as well as characters from other human language sets (i.e., English vs. Cyrillic) can also introduce ambiguities into the code base if improperly used.

This type of attack could potentially be used to compromise a code base by capitalizing on a gap in visually rendered source code as a human reviewer would see and the raw code that the compiler would evaluate.

### Impact

The use of attacks that incorporate maliciously encoded source code may go undetected by human developers and by many automated coding tools. These attacks also work against many of the compilers currently in use. An attacker with the ability to influence source code could introduce undetected ambiguity into source code using this type of attack.

### Solution

The simplest defense is to ban the use of text directionality control characters both in language specifications and in compilers implementing these languages.

Two CVEs were assigned to address the two types of attacks described in this report.

CVE-2021-42574 was created for tracking the Bidi attack.
CVE-2021-42694 was created for tracking the homoglyph attack.

### Acknowledgements

Thanks to the reporters, Nicholas Boucher and Ross Anderson of The University of Cambridge (UK).

This document was written by Chuck Yarbrough.

### Vendor Information

999008
Filter by status:
All
Affected
Not Affected
Unknown

Filter by content:
 Additional information available

 Sort by:
Status
Alphabetical

Expand all

### [Atlassian](#Atlassian) Affected

Notified:  2021-09-27
Updated: 2021-11-09

**Statement Date:   November 03, 2021**

| **CVE-2021-42574** | Affected |
| --- | --- |
| **CVE-2021-42694** | Affected |
| **VU#999008.1** | Affected |

#### Vendor Statement

We have not received a statement from the vendor.

#### References

* <https://confluence.atlassian.com/security/cve-2021-42574-unrendered-unicode-bidirectional-override-characters-in-cloud-sites-1086420599.html>
* <https://confluence.atlassian.com/security/multiple-products-security-advisory-unrendered-unicode-bidirectional-override-characters-cve-2021-42574-1086419475.html>

### [Rust Security Response WG](#Rust%20Security%20Response%20WG) Affected

Notified:  2021-10-26
Updated: 2021-11-09

**Statement Date:   November 04, 2021**

| **CVE-2021-42574** | Affected |
| --- | --- |
| **CVE-2021-42694** | Not Affected |
| **VU#999008.1** | Affected |

#### Vendor Statement

Regarding CVE-2021-42574, the Rust project released Rust 1.56.1, featuring new lints to alert developers about the presence of bidirectional-override codepoints in their source code. No builtin mitigation is present in Rust 1.0.0 to Rust 1.56.0: we recommend users of those compiler versions to either upgrade to a newer compiler, or to perform out-of-band checks for the presence of those codepoints in their codebase.

Regarding CVE-2021-42694, Rust already includes protection from homoglyphs in identifiers. Rust 1.0.0 to Rust 1.52.1 doesn't support non-ASCII identifiers, which prevents the issue completely. Rust 1.53.0 and later versions do support non-ASCII identifiers, but include lints to alert developers about the presence of homoglyphs or similar issues.

#### References

* <https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html>

### [The LLVM Security Group](#The%20LLVM%20Security%20Group) Affected

Notified:  2021-09-27
Updated: 2021-11-09

**Statement Date:   October 30, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Affected |

#### Vendor Statement

In a future release the LLVM project will include new checkers as part of clang-tidy to detect occurences of both CVE-2021-42574 and CVE-2021-42694. In the meantime we recommend clang users to perform out-of-band checks for the presence of these security issues in their codebases.

#### References

* <https://bugs.chromium.org/p/llvm/issues/detail?id=11>

### [Meta](#Meta) Not Affected

Notified:  2021-09-27
Updated: 2021-11-09

**Statement Date:   October 18, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Not Affected |

#### Vendor Statement

We have not received a statement from the vendor.

### [Veracode](#Veracode) Not Affected

Notified:  2021-10-26
Updated: 2021-11-09

**Statement Date:   November 02, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Not Affected |

#### Vendor Statement

We have not received a statement from the vendor.

### [Node.js](#Node.js) Unknown

Notified:  2021-10-19
Updated: 2024-12-10

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

#### References

* <https://groups.google.com/g/nodejs-sec/c/_w6hoamG14E/m/MrmeX2WMBQAJ>

#### CERT Addendum

Per the node.js statement published Nov 1, 2021, 1:29:33â¯PM:

> You may have read the announcement today about the potential for supply chain attacks using characters within source files that are not visible to human code reviewers: https://www.trojansource.codes/.
>
> The ECMAScript specification requires support for these characters (see section 12.1 at https://tc39.es/ecma262/#sec-unicode-format-control-characters). Node.js or any ECMAScript-compliant engine must allow these characters, which have valid uses in source code.
>
> Due diligence including code scans (for example for licenses) should already be part of your processes both for the code you write and dependencies that you use within your application. The script provided by Red Hat [at] https://access.redhat.com/sites/default/files/find\_unicode\_control2--2021-11-01-1136.zip is a good way to scan and identify files that you may want to review with respect to usage of the special characters identified.
>
> For some statically compiled languages, it may make sense to incorporate a check into the compiler instead of using an external script. However, for dynamic languages such as JavaScript, there are potential issues with that approach. These include:
>
> \*\* Finding out too late that there is usage of these characters. Dynamic languages may load a source file in the middle of their execution. At this point the application is already deployed and you don't necessarily want to block it from running and non-blocking warnings may not be noticed. It is more effective to scan all files that make up the application before it is run.
>
> \*\* The runtime overhead of the scan will be incurred unnecessarily every time the application is run. It is better to scan as part of your development/build/release processes as it will not add any additional runtime overhead once the application is deployed.
>
> At this time, we do not plan to provide an option to scan at runtime. We recommend that external scripts/processes be used instead

### [Red Hat](#Red%20Hat) Unknown

Notified:  2021-09-27
Updated: 2024-12-10

**Statement Date:   December 17, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

Red Hat's guidance for this issue can be found at Security Bulletin RHSB-2021-007

#### References

* <https://access.redhat.com/security/vulnerabilities/RHSB-2021-007>

### [Amazon](#Amazon) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Apple](#Apple) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [GitLab Inc.](#GitLab%20Inc.) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [GNU Compiler Collection](#GNU%20Compiler%20Collection) Unknown

Notified:  2021-10-19
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Google](#Google) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Micro Focus](#Micro%20Focus) Unknown

Notified:  2021-10-26
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Microsoft](#Microsoft) Unknown

Notified:  2021-10-19
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Oracle Corporation](#Oracle%20Corporation) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Snyk](#Snyk) Unknown

Notified:  2021-11-02
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

View all 16 vendorsView less vendors

### References

* <https://www.trojansource.codes/trojan-source.pdf>

### Other Information

| **CVE IDs:** | [CVE-2021-42574](https://www.cve.org/CVERecord?id=CVE-2021-42574)  [CVE-2021-42694](https://www.cve.org/CVERecord?id=CVE-2021-42694) |
| --- | --- |
| **API URL:** | [VINCE JSON](/vuls/api/999008/) | [CSAF](/vuls/api/999008/csaf/) |
| **Date Public:** | 2021-11-09 |
| **Date First Published:** | 2021-11-09 |
| **Date Last Updated:** | 2024-12-10 02:09 UTC |
| **Document Revision:** | 3 |

* [About vulnerability notes](https://vuls.cert.org/confluence/display/VIN/Vulnerability%2BNote%2BHelp)
* Contact us about this vulnerability
* [Provide a vendor statement](https://vuls.cert.org/confluence/display/VIN/Case%2BHandling#CaseHandling-Givingavendorstatusandstatement)

Sponsored by [CISA.](https://www.cisa.gov/cybersecurity)

 [Download PGP Key](https://vuls.cert.org/confluence/pages/viewpage.action?pageId=25985026)

[Read CERT/CC Blog](https://insights.sei.cmu.edu/cert/)

[Learn about Vulnerability Analysis](https://www.sei.cmu.edu/research-capabilities/all-work/display.cfm?customel_datapageid_4050=21304)

Carnegie Mellon University

Software Engineering Institute

4500 Fifth Avenue

Pittsburgh, PA 15213-2612

412-268-5800

[Office Locations](http://www.sei.cmu.edu/locations/index.cfm) | [Additional Sites Directory](http://www.sei.cmu.edu/additional-sites-directory/index.cfm) | [Legal](https://vuls.cert.org/confluence/display/VIN/VINCE%2BCode%2Bof%2BConduct#VINCECodeofConduct-TermsofUse) | [Privacy Notice](https://www.sei.cmu.edu/legal/privacy-notice/index.cfm) | [CMU Ethics Hotline](https://www.cmu.edu/hr/ethics-hotline/) | [www.sei.cmu.edu](http://www.sei.cmu.edu)

Â©2024 Carnegie Mellon University

[Contact SEI](https://www.sei.cmu.edu/contact-us/)
#### Contact CERT/CC

 412-268-5800



=== Content from www.openwall.com_11da79da_20250111_094133.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

[[<prev]](5) [[next>]](7) [[thread-next>]](7) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <c2d12374-0ed6-d6d4-60ea-799934b6f173@cl.cam.ac.uk>
Date: Mon, 1 Nov 2021 17:27:53 +0000
From: Nicholas Boucher <nicholas.boucher@...cam.ac.uk>
To: oss-security@...ts.openwall.com
Subject: Trojan Source Attacks

OSS Security teams,

We have identified an issue affecting all compilers and interpreters
that support Unicode. We believe that the techniques described hereafter
can be used to generate adversarial encodings of source code files that
can be used to craft targeted attacks against source code that cannot be
seen by human reviewers in rendered text. This is of concern to the open
source community because, absent defenses, supply chain attacks can be
imperceptibly mounted against the ecosystem.

This vulnerability has undergone a coordinated disclosure process that
has concluded today. The security advisory can be found at
<https://trojansource.codes>.

Multiple organizations will be releasing parallel security advisories,
such as Rust's advisory at
<https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html>, Red Hat's
advisory at
<https://access.redhat.com/security/vulnerabilities/RHSB-2021-007>
<<https://access.redhat.com/security/vulnerabilities/RHSB-2021-007>>, and
GitHub's advisory at
<https://github.blog/changelog/2021-10-31-warning-about-bidirectional-unicode-text/>
<<https://github.blog/changelog/2021-10-31-warning-about-bidirectional-unicode-text/>>.

The attached paper describes an attack paradigm -- which we believe to
be novel -- discovered by security researchers at the University of
Cambridge. There are two techniques for attack, both of which exploit
Unicode's high expressiveness to craft source code files for which
rendered text displays divergent logic from the underlying encoded bytes
seen by compilers.

The first and primary technique, which we dub the Trojan Source attack,
uses Unicode Bidirectional (Bidi) control characters embedded in
comments and string literals to produce visually deceptive source code
files. This technique enables an adversary to encode constructs that
visually appear to be comments or string literals but execute as code,
or vice versa. Complete details, as well as recommended mitigations, can
be found in the attachment 001 Trojan Source.pdf. This vulnerability is
tracked under CVE-2021-42574.

The second technique, to which we refer as the homoglyph variant, uses
homoglyphs (characters that render to the same glyph but are represented
by different Unicode values) to define adversarial identifiers. In this
technique, an adversary defines an identifier such as a function name
that appears visually identical to a target function, but is defined
using Unicode homoglyphs. This adversarial function then performs some
malicious action, then optionally calls the original function it is
impersonating. When defined in upstream dependencies such as open source
software, these adversarial functions can be imported into downstream
software and invoked without visual indication of malicious code.
Complete details, as well as recommended mitigations, can also be found
in the attachment 001 Trojan Source.pdf. This vulnerability is tracked
under CVE-2021-42694.

Proofs-of-concept can be found at
<https://github.com/nickboucher/trojan-source>.

We hope that this information proves useful in building and applying
defenses where applicable.

Best,
Nicholas Boucher
University of Cambridge

Content of type "text/html" skipped

Download attachment "[001 Trojan Source.pdf](6/1)" of type "application/pdf" (737637 bytes)

Download attachment "[OpenPGP_0x5662BCEC5F1D2BEA.asc](6/2)" of type "application/pgp-keys" (3160 bytes)

Download attachment "[OpenPGP_signature](6/3)" of type "application/pgp-signature" (841 bytes)

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from www.unicode.org_f2580a57_20250111_094134.html ===


| | [[Unicode]](https://www.unicode.org/) | [Unicode 14.0.0](https://www.unicode.org/versions/Unicode14.0.0/) | [Tech Site](https://www.unicode.org/main.html) | [Site Map](https://www.unicode.org/sitemap/) | [Search](https://www.unicode.org/search) | | --- | --- | --- | | |
|  | |
| | 14.0.0 Core Specification | | | --- | --- | | All Chapters and Appendices Together: | |   | • | [Full Text pdf for Viewing](https://www.unicode.org/versions/Unicode14.0.0/UnicodeStandard-14.0.pdf) (14 MB) | | • | Print-on-Demand (POD) for purchase: [Volume 1](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-1/paperback/product-p8674j.html) and [Volume 2](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-2/paperback/product-q46246.html) | | 14.0.0 Front Matter | |   |  | [Title and Copyright](https://www.unicode.org/versions/Unicode14.0.0/Title.pdf) | |  | [Contents](https://www.unicode.org/versions/Unicode14.0.0/UnicodeBookTOC.pdf) | |  | [Unicode 14.0 Web Bookmarks](https://www.unicode.org/versions/Unicode14.0.0/bookmarks.html) | |  | [Preface](https://www.unicode.org/versions/Unicode14.0.0/Preface.pdf) | | 14.0.0 Chapters | |   | 1 | [Introduction](https://www.unicode.org/versions/Unicode14.0.0/ch01.pdf) | | 2 | [General Structure](https://www.unicode.org/versions/Unicode14.0.0/ch02.pdf) | | 3 | [Conformance](https://www.unicode.org/versions/Unicode14.0.0/ch03.pdf) | | 4 | [Character Properties](https://www.unicode.org/versions/Unicode14.0.0/ch04.pdf) | | 5 | [Implementation Guidelines](https://www.unicode.org/versions/Unicode14.0.0/ch05.pdf) | | 6 | [Writing Systems and Punctuation](https://www.unicode.org/versions/Unicode14.0.0/ch06.pdf) | | 7 | [Europe-I](https://www.unicode.org/versions/Unicode14.0.0/ch07.pdf) | | 8 | [Europe-II](https://www.unicode.org/versions/Unicode14.0.0/ch08.pdf) | | 9 | [Middle East-I](https://www.unicode.org/versions/Unicode14.0.0/ch09.pdf) | | 10 | [Middle East-II](https://www.unicode.org/versions/Unicode14.0.0/ch10.pdf) | | 11 | [Cuneiform and Hieroglyphs](https://www.unicode.org/versions/Unicode14.0.0/ch11.pdf) | | 12 | [South and Central Asia-I](https://www.unicode.org/versions/Unicode14.0.0/ch12.pdf) | | 13 | [South and Central Asia-II](https://www.unicode.org/versions/Unicode14.0.0/ch13.pdf) | | 14 | [South and Central Asia-III](https://www.unicode.org/versions/Unicode14.0.0/ch14.pdf) | | 15 | [South and Central Asia-IV](https://www.unicode.org/versions/Unicode14.0.0/ch15.pdf) | | 16 | [Southeast Asia](https://www.unicode.org/versions/Unicode14.0.0/ch16.pdf) | | 17 | [Indonesia and Oceania](https://www.unicode.org/versions/Unicode14.0.0/ch17.pdf) | | 18 | [East Asia](https://www.unicode.org/versions/Unicode14.0.0/ch18.pdf) | | 19 | [Africa](https://www.unicode.org/versions/Unicode14.0.0/ch19.pdf) | | 20 | [Americas](https://www.unicode.org/versions/Unicode14.0.0/ch20.pdf) | | 21 | [Notational Systems](https://www.unicode.org/versions/Unicode14.0.0/ch21.pdf) | | 22 | [Symbols](https://www.unicode.org/versions/Unicode14.0.0/ch22.pdf) | | 23 | [Special Areas and Format Characters](https://www.unicode.org/versions/Unicode14.0.0/ch23.pdf) | | 24 | [About the Code Charts](https://www.unicode.org/versions/Unicode14.0.0/ch24.pdf) | | 14.0.0 Appendices and Back Matter | |   | A | [Notational Conventions](https://www.unicode.org/versions/Unicode14.0.0/appA.pdf) | | B | [Unicode Publications and Resources](https://www.unicode.org/versions/Unicode14.0.0/appB.pdf) | | C | [Relationship to ISO/IEC 10646](https://www.unicode.org/versions/Unicode14.0.0/appC.pdf) | | D | [Version History of the Standard](https://www.unicode.org/versions/Unicode14.0.0/appD.pdf) | | E | [Han Unification History](https://www.unicode.org/versions/Unicode14.0.0/appE.pdf) | | F | [Documentation of CJK Strokes](https://www.unicode.org/versions/Unicode14.0.0/appF.pdf) | |  | [Index](https://www.unicode.org/versions/Unicode14.0.0/UnicodeBookIX.pdf) | |  | [Colophon](https://www.unicode.org/versions/Unicode14.0.0/Colophon.pdf) | | Code Charts | | | • | [Latest Code Charts](https://www.unicode.org/charts/) ([Tableaux des caractères](https://www.unicode.org/charts/fr/)) | | • | [Delta Code Charts](https://www.unicode.org/charts/PDF/Unicode-14.0/) (additions to 14.0.0 highlighted) | | • | [Archival Code Charts](https://www.unicode.org/Public/14.0.0/charts/) (14.0.0) ([French](https://www.unicode.org/Public/14.0.0/charts/fr/)) | | Han Radical-Stroke Indices | | | • | [Interactive Han Radical-Stroke Index](https://www.unicode.org/charts/unihanrsindex.html) | | • | [IICore Radical-Stroke Index](https://www.unicode.org/versions/IICoreRSIndex.pdf) (3.8 MB) | | • | [Unihan Core 2020 Radical-Stroke Index](https://www.unicode.org/versions/UnihanCore2020RSIndex.pdf) (8.2 MB) | | • | [Full Han Radical-Stroke Index](https://www.unicode.org/Public/14.0.0/charts/RSIndex.pdf) (41 MB) | | 14.0.0 Unicode Standard Annexes | | | [UAX #9, The Unicode Bidirectional Algorithm](https://www.unicode.org/reports/tr9/tr9-44.html) | | | [UAX #11, East Asian Width](https://www.unicode.org/reports/tr11/tr11-39.html) | | | [UAX #14, Unicode Line Breaking Algorithm](https://www.unicode.org/reports/tr14/tr14-47.html) | | | [UAX #15, Unicode Normalization Forms](https://www.unicode.org/reports/tr15/tr15-51.html) | | | [UAX #24, Unicode Script Property](https://www.unicode.org/reports/tr24/tr24-32.html) | | | [UAX #29, Unicode Text Segmentation](https://www.unicode.org/reports/tr29/tr29-39.html) | | | [UAX #31, Unicode Identifier and Pattern Syntax](https://www.unicode.org/reports/tr31/tr31-35.html) | | | [UAX #34, Unicode Named Character Sequences](https://www.unicode.org/reports/tr34/tr34-27.html) | | | [UAX #38, Unicode Han Database (Unihan)](https://www.unicode.org/reports/tr38/tr38-31.html) | | | [UAX #41, Common References for Unicode Standard Annexes](https://www.unicode.org/reports/tr41/tr41-28.html) | | | [UAX #42, Unicode Character Database in XML](https://www.unicode.org/reports/tr42/tr42-30.html) | | | [UAX #44, Unicode Character Database](https://www.unicode.org/reports/tr44/tr44-28.html) | | | [UAX #45, U-Source Ideographs](https://www.unicode.org/reports/tr45/tr45-25.html) | | | [UAX #50, Unicode Vertical Text Layout](https://www.unicode.org/reports/tr50/tr50-26.html) | | | 14.0.0 UCD | | | 14.0.0 ([files](https://www.unicode.org/Public/14.0.0/)) ([about](https://www.unicode.org/reports/tr44/tr44-28.html)) | | | 14.0.0 [Zipped files](https://www.unicode.org/Public/zipped/14.0.0/) (for bulk download) | | | Related Links | | | [Unicode Acknowledgements](https://www.unicode.org/acknowledgements/) | | | [Archive of Unicode Versions](https://www.unicode.org/versions/enumeratedversions.html) | | | [About Versions](https://www.unicode.org/versions/index.html) | | | [Updates and Errata](https://www.unicode.org/errata/) | | | [Glossary of Unicode Terms](https://www.unicode.org/glossary/) | | | [References for the Unicode Standard](https://www.unicode.org/references/) | | | [Unicode Character Name Index](https://www.unicode.org/charts/charindex.html) | | | [Technical Reports](https://www.unicode.org/reports/) | | | [Unicode Emoji](https://www.unicode.org/emoji/) | | | | Unicode® 14.0.02021 September 14 ([Announcement](http://blog.unicode.org/2021/09/announcing-unicode-standard-version-140.html)) *Version 14.0.0 has been superseded by the [latest version](http://www.unicode.org/versions/latest/) of the Unicode Standard.*  This page summarizes the important changes for the Unicode Standard, Version 14.0.0. This version supersedes all previous versions of the Unicode Standard.  A. [Summary](#Summary) B. [Technical Overview](#Technical_Overview) C. [Stability Policy Update](#Stability_Policy) D. [Textual Changes and Character Additions](#Character_Additions) E. [Conformance Changes](#Conformance_Changes) F. [Changes in the Unicode Character Database](#Database_Changes) G. [Changes in the Unicode Standard Annexes](#UAX_Changes) H. [Changes in Synchronized Unicode Technical Standards](#UTS_Changes) M. [Implications for Migration](#Migration) A. Summary Unicode 14.0 adds 838 characters, for a total of 144,697 characters. These additions include [5 new scripts](#New_Scripts), for a total of 159 scripts, as well as 37 new emoji characters.  The new scripts and characters in Version 14.0 add support for lesser-used languages and unique written requirements worldwide, including numerous symbols additions. Funds from the [Adopt-a-Character](https://www.unicode.org/consortium/adopt-a-character.html) program provided support for some of these additions. The new scripts and characters include:   * Toto, used to write the Toto language in northeast India * Cypro-Minoan, an undeciphered historical script primarily used on the island of Cyprus * Vithkuqi, an historic script used to write Albanian, and undergoing a modern revival * Old Uyghur, an historic script used in Central Asia and elsewhere to write Turkic, Chinese, Mongolian, Tibetan, and Arabic languages * Tangsa, a modern script used to write the Tangsa language, which is spoken in India and Myanmar * Many Latin additions for extended IPA * Arabic script additions used to write languages across Africa and in Iran,   Pakistan, Malaysia, Indonesia, Java, and Bosnia, and to write honorifics,   and additions for Quranic use * Other character additions support languages of North America and of the Philippines, India, and Mongolia   Popular symbol additions:   * 37 emoji characters. For complete statistics regarding all emoji as of   Unicode 14.0, see   [Emoji Counts](https://www.unicode.org/emoji/charts-14.0/emoji-counts.html).   For more information about emoji additions in version 14.0, including new   emoji ZWJ sequences and emoji modifier sequences, see   [Emoji Recently Added, v14.0](https://unicode.org/emoji/charts-14.0/emoji-released.html).   Other symbol and notational additions include:   * The som currency sign used in the Kyrgyz Republic * Znamenny musical notation used to write Znamenny Chant, a form of liturgical singing that developed in Russia in the 11th century CE. It is derived from early Byzantine musical notation and is mainly of scholarly interest.   Support for CJK unified ideographs was enhanced in Version 14.0 by significant corrections and improvements to the Unihan database. Changes to the Unihan database include updated source lists, regular expressions, and new and updated fields. See [UAX #38, Unicode Han Database (Unihan)](https://www.unicode.org/reports/tr38/tr38-31.html) for more information on the updates.  Additional support for lesser-used languages and scholarly work was extended, including:   * Ahom, Balinese, Brahmi, Canadian aboriginal languages (UCAS), Glagolitic, Kaithi, Kannada, Mongolian, Tagalog, Takri, and Telugu * Arabic support for Hausa, Wolof, Hindko, and Punjabi, and Ethiopic support for Gurage   Important chart font updates, including:   * CJK auxiliary blocks and enclosed alphanumerics. See the [delta charts](https://www.unicode.org/charts/PDF/Unicode-14.0/) for detailed information on significant chart font changes.  Synchronization Several other important Unicode specifications have been updated for Version 14.0. The following four Unicode Technical Standards are versioned in synchrony with the Unicode Standard, because their data files cover the same repertoire. All have been updated to Version 14.0:   * [UTS #10, Unicode Collation Algorithm](https://www.unicode.org/reports/tr10/tr10-45.html) — sorting Unicode text * [UTS #39, Unicode Security Mechanisms](https://www.unicode.org/reports/tr39/tr39-24.html) — reducing Unicode spoofing * [UTS #46, Unicode IDNA Compatibility Processing](https://www.unicode.org/reports/tr46/tr46-27.html) — compatible processing of non-ASCII URLs * [UTS #51, Unicode Emoji](https://www.unicode.org/reports/tr51/tr51-21.html) — emoji-related data and behavior   Some of the changes in Version 14.0 and associated Unicode Technical Standards may require modifications to implementations. For more information, see the migration and modification sections of UTS #10, UTS #39, UTS #46, and UTS #51.  See Sections D through H below for additional details regarding the changes in this version of the Unicode Standard, its associated annexes, and the other synchronized Unicode specifications. B. Technical Overview Version 14.0 of the Unicode Standard consists of:   * The core specification * The code charts (delta and archival) for this version * The Unicode Standard Annexes * The Unicode Character Database (UCD)   The core specification gives the general principles, requirements for conformance, and guidelines for implementers. The code charts show representative glyphs for all the Unicode characters. The Unicode Standard Annexes supply detailed normative information about particular aspects of the standard. The Unicode Character Database supplies normative and informative data for implementers to allow them to implement the Unicode Standard. Core Specification The core specification is available as a [single pdf for viewing](https://www.unicode.org/versions/Unicode14.0.0/UnicodeStandard-14.0.pdf). (14 MB) Links are also available in the navigation bar on the left of this page to access [individual chapters](#Chapters_nb) and [appendices](#Appendices_nb) of the core specification. It is also available as Print-on-Demand (POD) for purchase: [Volume 1](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-1/paperback/product-p8674j.html%20) and [Volume 2](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-2/paperback/product-q46246.html). Code Charts Several sets of code charts are available. They serve different purposes:   * The [latest set of code charts](https://www.unicode.org/charts/) for   the Unicode Standard is available online. Those charts are always the most current   code charts available, and may be updated at any time. The charts are organized by   scripts and blocks for easy reference.   An online [index by character name](https://www.unicode.org/charts/charindex.html)   is also provided. The [Tableaux des caractères](https://www.unicode.org/charts/fr/)   provides a French translation of these latest code charts.   For Unicode 14.0.0 in particular two additional sets of code chart pages are provided:   * A [set of delta code charts](https://www.unicode.org/charts/PDF/Unicode-14.0/) showing the   new blocks and any blocks in which characters were added for Unicode 14.0.0. The new characters are visually highlighted in the charts. * A [set of archival code charts](https://www.unicode.org/Public/14.0.0/charts/) that represents   the entire set of characters, names and representative glyphs at the time of publication of Unicode 14.0.0.   A [French translation](https://www.unicode.org/Public/14.0.0/charts/fr/) of the archival code charts is also available for this version.   The delta and archival code charts are a stable part of this release of the Unicode Standard. They will never be updated.  The old, frozen UCS2003 source column has been removed from the multi-column display for CJK Unified Ideographs Extension B for Version 14.0.0. For permanent reference, a [single source display of UCS2003](https://www.unicode.org/Public/13.0.0/charts/UCS2003.pdf) (8.7 MB) for the CJK Unified Ideographs Extension B has been provided as part of the Version 13.0.0 archival charts. Unicode Standard Annexes Links to the individual [Unicode Standard Annexes](#Unicode_Standard_Annexes_nb) are available in the navigation bar on the left of this page. The list of significant changes in the content of the Unicode Standard Annexes for Version 14.0 can be found in [Section G](#UAX_Changes) below. Unicode Character Database [Data files](https://www.unicode.org/Public/14.0.0/) for Version 14.0 of the Unicode Character Database are available. The ReadMe.txt in that directory provides a roadmap to the functions of the various subdirectories. [Zipped versions](https://www.unicode.org/Public/zipped/14.0.0/) of the UCD for bulk download are available, as well. Version References Version 14.0.0 of the Unicode Standard should be referenced as:  The Unicode Consortium. *The Unicode Standard, Version 14.0.0*, (Mountain View, CA: The Unicode Consortium, 2021. ISBN 978-1-936213-29-0) [http://www.unicode.org/versions/Unicode14.0.0/](https://www.unicode.org/versions/Unicode14.0.0/)  The terms “Version 14.0” or “Unicode 14.0” are abbreviations for the full version reference, Version 14.0.0.  The citation and permalink for the latest published version of the Unicode Standard is:  The Unicode Consortium. *The Unicode Standard*. [http://www.unicode.org/versions/latest/](https://www.unicode.org/versions/latest/)  A complete specification of the contributory files for Unicode 14.0 is found on the page [Components for 14.0.0](https://www.unicode.org/versions/components-14.0.0.html). That page also provides the recommended reference format for Unicode Standard Annexes. For examples of how to cite particular portions of the Unicode Standard, see also the [Reference Examples](https://www.unicode.org/versions/#References). Errata Errata incorporated into Unicode 14.0 are listed by date in a [separate table](erratafixed.html). For corrigenda and errata after the release of Unicode 14.0, see the list of current [Updates and Errata](https://www.unicode.org/errata/). C. Stability Policy Update There were no significant changes to the Stability Policy of the core specification between Unicode 13.0 and Unicode 14.0. D. Textual Changes and Character Additions Five new scripts were added with accompanying new block descriptions:   | Script | Number ofCharacters | | --- | --- | | Vithkuqi | 70 | | Old Uyghur | 26 | | Cypro-Minoan | 99 | | Tangsa | 89 | | Toto | 31 |   Changes in the Unicode Standard Annexes are listed in [Section G](#UAX_Changes). Character Assignment Overview 838 characters have been added. Most character additions are in new blocks, but there are also character additions to a number of existing blocks. For details, see [delta code charts](https://www.unicode.org/charts/PDF/Unicode-14.0/). E. Conformance Changes There are no significant new conformance requirements in Unicode 14.0. F. Changes in the Unicode Character Database The detailed listing of all changes to the contributory data files of the Unicode Character Database for Version 14.0 can be found in [UAX #44, Unicode Character Database](https://www.unicode.org/reports/tr44/tr44-28.html#Unicode_14.0.0). The changes listed there include character additions and property revisions to existing characters that will affect implementations. Some of the important impacts on implementations migrating from earlier versions of the standard are highlighted in [Section M](#Migration). G. Changes in the Unicode Standard Annexes In Version 14.0, some of the Unicode Standard Annexes have had significant revisions. The most important of these changes are listed below. For the full details of all changes, see the Modifications section of each UAX, linked directly from the following list of UAXes.  Note that for Unicode 14.0, all pertinent links to URLs on the Unicode website in these Unicode Standard Annexes were updated to use the https protocol.   | Unicode Standard Annex | Changes | | --- | --- | | [UAX #9](https://www.unicode.org/reports/tr9/tr9-44.html#Modifications)Unicode Bidirectional Algorithm | Section 6.2, Vertical Text was clarified to indicate how the Bidirectional Algorithm is (or is not) used when text is laid out in vertical orientation. | | [UAX #11](https://www.unicode.org/reports/tr11/tr11-39.html#Modifications)East Asian Width | No significant changes in this version. | | [UAX #14](https://www.unicode.org/reports/tr14/tr14-47.html#Modifications)Unicode Line Breaking Algorithm | One redundant rule part was removed from LB27 in Section 6.1, Non-tailorable Line Breaking Rules. Also, LB30b was updated to include potential emoji. | | [UAX #15](https://www.unicode.org/reports/tr15/tr15-51.html#Modifications)Unicode Normalization Forms | No significant changes in this version. | | [UAX #24](https://www.unicode.org/reports/tr24/tr24-32.html#Modifications)Unicode Script Property | No significant changes in this version. | | [UAX #29](https://www.unicode.org/reports/tr29/tr29-39.html#Modifications)Unicode Text Segmentation | A Swedish "AIK:are" example was added to the word boundary discussion. The description of the charts in the auxiliary data files was updated, to make it more accurate. Other small editorial fixes were applied to the text. | | [UAX #31](https://www.unicode.org/reports/tr31/tr31-35.html#Modifications)Unicode Identifier and Pattern Syntax | Scripts new to Unicode 14.0 were added to the appropriate tables. A new Section 1.5, Notation, was added, referring to the LDML for the UnicodeSet notation used in this annex. | | [UAX #34](https://www.unicode.org/reports/tr34/tr34-27.html#Modifications)Unicode Named Character Sequences | No significant changes in this version. | | [UAX #38](https://www.unicode.org/reports/tr38/tr38-31.html#Modifications)Unicode Han Database (Unihan) | The kCantonese field was redefined, and its description was updated accordingly. The new kStrange field was added. Regular expressions, source lists, and descriptions were updated for many other fields. | | [UAX #41](https://www.unicode.org/reports/tr41/tr41-28.html)Common References for Unicode Standard Annexes | All references were updated for Unicode 14.0. | | [UAX #42](https://www.unicode.org/reports/tr42/tr42-30.html#Modifications)Unicode Character Database in XML | New code point attributes, values, and patterns were added for Unicode 14.0. | | [UAX #44](https://www.unicode.org/reports/tr44/tr44-28.html#Modifications) Unicode Character Database | The documentation was updated to describe the changes to the UCD for Version 14.0. The distinction between properties of strings and string-valued properties was clarified. A note was added clarifying that Vertical\_Orientation defaults to U in some blocks associated with notational systems. An erroneous statement about which General\_Category values can be associated with ccc≠0 was corrected. | | [UAX #45](https://www.unicode.org/reports/tr45/tr45-25.html#Modifications) U-Source Ideographs | Descriptions were added for new data fields (total strokes and first residual stroke) in the data file associated with UAX #45. The KangXi dictionary index field was obsoleted. New information was added about the submission process. | | [UAX #50](https://www.unicode.org/reports/tr50/tr50-26.html#Modifications) Unicode Vertical Text Layout | No significant changes in this version. |   H. Changes in Synchronized Unicode Technical Standards There are also significant revisions in the Unicode Technical Standards whose versions are synchronized with the Unicode Standard. The most important of these changes are listed below. For the full details of all changes, see the Modifications section of each UTS, linked directly from the following list of UTSes.   | Unicode Technical Standard | Changes | | --- | --- | | [UTS #10](https://www.unicode.org/reports/tr10/tr10-45.html#Modifications)Unicode Collation Algorithm | No significant changes in this version. | | [UTS #39](https://www.unicode.org/reports/tr39/tr39-24.html#Modifications)Unicode Security Mechanisms | Section 3, Identifier Characters was adjusted to better introduce the topic of identifiers. The text in Section 3.1, General Security Profile for Identifiers was clarified regarding the rationales for restricting a character. The descriptions of identifier types in Table 1 were clarified. | | [UTS #46](https://www.unicode.org/reports/tr46/tr46-27.html#Modifications)Unicode IDNA Compatibility Processing | No significant changes in this version. | | [UTS #51](https://www.unicode.org/reports/tr51/tr51-21.html#Modifications)Unicode Emoji | The introduction was reworded. The definition of Basic\_Emoji was clarified, and it was noted that emoji sets are binary properties of strings. In Section 2.6.2, Multi-Person Skin Tones, the *handshake* was added to the list of emoji with RGI skin tones. |   M. Implications for Migration There are a significant number of changes in Unicode 14.0 which may impact implementations upgrading to Version 14.0 from earlier versions of the standard. The most important of these are listed and explained here, to help focus on the issues most likely to cause unexpected trouble during upgrades. Script-related Changes Five new scripts have been added in Unicode 14.0.0. Some of these scripts have particular attributes which may cause issues for implementations. The more important of these attributes are summarized here.   * Old Uyghur is an abjad, historically related to Sogdian. Representation   of Old Uyghur text poses many significant issues. See the original proposal   documentation in [L2/20-191](https://www.unicode.org/L2/L2020/20191-old-uyghur.pdf)   for an extensive discussion.  Casing Issues  * Four new Latin case pairs and one new Glagolitic case pair have been added   in Version 14.0.0. In addition, one of the newly added scripts, Vithkuqi,   is a bicameral script with casing. Implementations   of case mapping and case folding should be checked to ensure they account   correctly for the new case pairs.  Numeric Property Issues  * A new set of decimal digits has been added for the Tangsa script.   See U+16AC0..U+16AC9. Implementations of digits will need to take those   into account.  CJK/Unihan Changes  * A new provisional property, kStrange, has been added to Unihan.   This property is documented in detail in a new Unicode Technical   Note, [UTN #43](https://www.unicode.org/notes/tn43/). * The provisional kCantonese property was extensively refined.   This work included 6,000 additional property values, as well as changing the property   values for nearly 5,000 existing ideographs to reflect only one reading. * Over 1,000 kIRG\_VSource property values with "VU-"" prefix were changed   to use the "VN-" prefix. * WARNING: There are changes to the ends of three existing   CJK unified ideograph ranges in Unicode 14.0.0. Because implementations often hard-code   ideographic ranges to short-cut lookups and reduce table sizes, it is   especially important that implementers pay close attention to the   implications of range changes for Version 14.0.0. These extensions bump up the end   ranges of the encoded ideographs by a few code points within each block:    + 3 code points for the [URO](https://www.unicode.org/glossary/#URO):     ending at U+9FFF [fills the block]   + 2 code points for Extension B: ending at U+2A6DF [fills the block]   + 4 code points for Extension C: ending at U+2B738 See [Section 4.4,   *Listing of Characters Covered by the Unihan Database*](https://www.unicode.org/reports/tr38/tr38-31.html#BlockListing)   in UAX #38   for the version history of all these small CJK unified ideograph additions   inside existing blocks.   See [UAX #38](https://www.unicode.org/reports/tr38/tr38-31.html), Unicode Han Database (Unihan) for further details on these changes, especially Section 4.2, *Listing by Date of Addition to the Unicode Standard*, and Section 4.3, *Listing by Location within Unihan.zip*. UAX #38 also has updated regex values for numerous Unihan properties. Emoji Changes  * 37 new emoji characters have been added. However, in addition   to those individual characters, many new emoji sequences have been   recognized, as well. Implementations supporting emoji should be   checked to reflect changes in   [UTS #51, Unicode Emoji](https://www.unicode.org/reports/tr51/tr51-21.html)   and all of its associated data files.  Code Charts  * There was a significant update in the fonts used for many CJK auxiliary blocks,   to improve the design and consistency of glyphs. Details of the affected ranges   of glyphs can be found in the Glyph and Variation Sequence Changes table   on the   [single block delta charts page](https://www.unicode.org/charts/PDF/Unicode-14.0/). * There have also been systematic updates to many glyphs in the   [Egyptian Hieroglyphs](https://www.unicode.org/charts/PDF/Unicode-14.0/U140-13000.pdf)   block, to more accurately reflect current practice.   The old, frozen UCS2003 source column has been removed from the multi-column display for CJK Unified Ideographs Extension B for Version 14.0.0. For permanent reference, a [single source display of UCS2003](https://www.unicode.org/Public/13.0.0/charts/UCS2003.pdf) (8.7 MB) for the CJK Unified Ideographs Extension B has been provided as part of the Version 13.0.0 archival charts. The rationale for this change is that the UCS2003 source was the source corresponding to the single column chart first printed in Unicode 4.0 in 2003. The glyphs for that single source had not tracked the extensive updates for characters in Extension B over the intervening years, and so in some cases were becoming misleading about the identity of some of the corrected characters in Extension B.   ---   | [Access to Copyright and terms of use](https://www.unicode.org/copyright.html) | | --- | | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | |



=== Content from www.unicode.org_70dca9b0_20250111_094137.html ===


| [[Unicode]](https://www.unicode.org/) | [Technical Reports](https://www.unicode.org/reports/) |
| --- | --- |
|  | |

## Unicode® Technical Standard #39

# Unicode Security Mechanisms

| Version | 16.0.0 |
| --- | --- |
| Editors | Mark Davis (markdavis@google.com), Michel Suignard (michel@suignard.com) |
| Date | 2024-09-03 |
| This Version | <https://www.unicode.org/reports/tr39/tr39-30.html> |
| Previous Version | <https://www.unicode.org/reports/tr39/tr39-28.html> |
| Latest Version | <https://www.unicode.org/reports/tr39/> |
| Latest Proposed Update | <https://www.unicode.org/reports/tr39/proposed.html> |
| Revision | [30](#Modifications) |

### *Summary*

*Because Unicode contains such a large number of characters and
incorporates the varied writing systems of the world, incorrect
usage can expose programs or systems to possible security attacks.
This document specifies mechanisms that can be used to detect
possible security problems.*

### *Status*

*This document has been reviewed by Unicode members and other
interested parties, and has been approved for publication by the Unicode
Consortium. This is a stable document and may be used as reference
material or cited as a normative reference by other specifications.*

> ***A Unicode Technical Standard (UTS)** is an independent
> specification. Conformance to the Unicode Standard does not imply
> conformance to any UTS.*

*Please submit corrigenda and other comments with the online
reporting form [[Feedback](https://www.unicode.org/reporting.html)].
Related information that is useful in understanding this document is
found in the [References](#References). For the latest
version of the Unicode Standard, see [[Unicode](https://www.unicode.org/versions/latest/)]. For a
list of current Unicode Technical Reports, see [[Reports](https://www.unicode.org/reports/)]. For more
information about versions of the Unicode Standard, see [[Versions](https://www.unicode.org/versions/)].*

### *Contents*

* 1 [Introduction](#Introduction)
* 2 [Conformance](#Conformance)
* 3 [Identifier Characters](#Identifier_Characters)
  + 3.1 [General
    Security Profile for Identifiers](#General_Security_Profile)
    - Table 1. [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)
    - 3.1.1 [Joining Controls](#Joining_Controls)
      * 3.1.1.1 [Limited Contexts for Joining Controls](#Limited_Contexts_for_Joining_Controls)
      * 3.1.1.2 [Limitations](#Limitations)
  + 3.2 [IDN Security
    Profiles for Identifiers](#IDN_Security_Profiles)
  + 3.3 [Email
    Security Profiles for Identifiers](#Email_Security_Profiles)
* 4 [Confusable Detection](#Confusable_Detection)
  + 4.1 [Whole-Script
    Confusables](#Whole_Script_Confusables)
  + 4.2 [Mixed-Script
    Confusables](#Mixed_Script_Confusables)
* 5 [Detection Mechanisms](#Detection_Mechanisms)
  + 5.1 [Mixed-Script
    Detection](#Mixed_Script_Detection)
    - Table 1a. [Mixed Script Examples](#Mixed_Script_Examples)
  + 5.2 [Restriction-Level
    Detection](#Restriction_Level_Detection)
  + 5.3 [Mixed-Number
    Detection](#Mixed_Number_Detection)
  + 5.4 [Optional Detection](#Optional_Detection)
* 6 [Development Process](#Development_Process)
  + 6.1 [Confusables Data
    Collection](#Data_Collection)
  + 6.2 [Identifier
    Modification Data Collection](#IDMOD_Data_Collection)
* 7 [Data Files](#Data_Files)
  + Table 2. [Data File List](#Data_File_List)
* [Migration](#Migration)
  + Table 3. [Version
    Correspondence](#Version_Correspondance)
  + [Migrating
    Persistent Data](#Migrating_Persistent_Data)
  + [Version 8.0 Migration](#Version_8_Migration)
  + [Version 7.0 Migration](#Version_7_Migration)
* [Acknowledgments](#Acknowledgments)
* [References](#References)
* [Modifications](#Modifications)

---

## 1 [Introduction](#Introduction)

*Unicode Technical Report #36, "Unicode Security
Considerations"* [[UTR36](#UTR36)]
provides guidelines for detecting and avoiding security problems
connected with the use of Unicode. This document specifies mechanisms
that are used in that document, and can be used elsewhere. Readers
should be familiar with [[UTR36](#UTR36)] before
continuing. See also the Unicode FAQ on *Security
Issues* [[FAQSec](#FAQSec)].

## 2 [Conformance](#Conformance)

An implementation claiming conformance to this specification
must do so in conformance to the following clauses:

**[UTS-39-C1](#UTS-39-C1)**.
*An implementation claiming to implement
the **General Profile for Identifiers** shall do so by conforming to either [UTS-39-C1-1](#UTS-39-C1-1) or [UTS-39-C1-2](#UTS-39-C1-2).*

> **[UTS-39-C1-1](#UTS-39-C1-1)**. *The Implementation shall be in accordance with the specifications in Section 3.1, [General Security Profile for Identifiers](#General_Security_Profile), without change.*
>
> **[UTS-39-C1-2](#UTS-39-C1-2)**. *The implementation shall provide a precise list of characters that are added to or removed from the profile, but otherwise be in accordance with the specifications in Section 3.1, [General Security Profile for Identifiers](#General_Security_Profile).*

**[UTS-39-C1.1](#UTS-39-C1.1)**.
*An implementation claiming to implement
the **IDN Security Profiles for Identifiers** shall do so by conforming to either [UTS-39-C1.1-1](#UTS-39-C1.1-1) or [UTS-39-C1.1-2](#UTS-39-C1.1-2).*

> **[UTS-39-C1.1-1](#UTS-39-C1.1-1)**. *The implementation shall be in accordance with the specifications in Section 3.2, [IDN Security Profiles for Identifiers](#IDN_Security_Profiles) for Identifiers, without change.*
>
> **[UTS-39-C1.1-2](#UTS-39-C1.1-2)**. *The implementation shall provide a precise list of characters that are added to or removed from the profile, but otherwise be in accordance with the specifications in Section 3.2, [IDN Security Profiles for Identifiers](#IDN_Security_Profiles).*

**[UTS-39-C1.2](#UTS-39-C1.2)**. *An implementation claiming to implement the **Email Security Profiles for Identifiers** shall do so by conforming to either [UTS-39-C1.2-1](#UTS-39-C1.2-1) or [UTS-39-C1.2-2](#UTS-39-C1.2-2).*

> **[UTS-39-C1.2-1](#UTS-39-C1.2-1)**. *The implementation shall be in accordance with the specifications in Section 3.3, [Email Security Profiles for Identifiers](#Email_Security_Profiles), without change.*
>
> **[UTS-39-C1.2-2](#UTS-39-C1.2-2)**. *The implementation shall provide a precise list of characters that are added to or removed from the profile, but otherwise be in accordance with the specifications in Section 3.3, [Email Security Profiles for Identifiers](#Email_Security_Profiles).*

**[UTS-39-C2](#UTS-39-C2)**. *An implementation claiming to implement any of the following confusable-detection functions for Identifiers defined in Section 4,
[Confusable Detection](#Confusable_Detection) shall do so by conforming to either [UTS-39-C2-1](#UTS-39-C2-1) or [UTS-39-C2-2](#UTS-39-C2-2)*.

1. X and Y are single-script confusables
2. X and Y are mixed-script confusables
3. X and Y are whole-script confusables
4. X has whole-script confusables in set of scripts S

> **[UTS-39-C2-1](#UTS-39-C2-1)**. *The implementation of the function shall be in accordance with the specifications in Section 4,
> [Confusable Detection](#Confusable_Detection), without change.*
>
> **[UTS-39-C2-2](#UTS-39-C2-2)**. *The implementation shall provide a precise list of character mappings that are added to or removed from those provided, but otherwise be in accordance with the specifications in Section 4,
> [Confusable Detection](#Confusable_Detection).*

**[UTS-39-C3](#UTS-39-C3)**. *An implementation claiming to detect mixed scripts shall do so by conforming to either [UTS-39-C3-1](#UTS-39-C3-1) or [UTS-39-C3-2](#UTS-39-C3-2).*

> **[UTS-39-C3-1](#UTS-39-C3-1)**. *The implementation shall be in accordance with the specifications in Section 5.1, [Mixed-script Detection](#Mixed_Script_Detection), without change.*
>
> **[UTS-39-C3-2](#UTS-39-C3-2)**. *The implementation shall provide a precise description of changes in behavior, but otherwise be in accordance with the specifications in Section 5.1, [Mixed-Script Detection](#Mixed_Script_Detection).*

**[UTS-39-C4](#UTS-39-C4)**. *An implementation claiming to detect Restriction-Levels shall do so by conforming to either [UTS-39-C4-1](#UTS-39-C4-1) or [UTS-39-C4-2](#UTS-39-C4-2).*

> **[UTS-39-C4-1](#UTS-39-C4-1)**. *The implementation shall be in accordance with the specifications in Section 5.2, [Restriction-Level Detection](#Restriction_Level_Detection), without change.*
>
> **[UTS-39-C4-2](#UTS-39-C4-2)**. *The implementation shall provide a precise description of changes in behavior, but otherwise be in accordance with the specifications in Section 5.2, [Restriction-Level Detection](#Restriction_Level_Detection).*

**[UTS-39-C5](#UTS-39-C5)**. *An implementation claiming to detect mixed numbers shall do so by conforming to either [UTS-39-C5-1](#UTS-39-C5-1) or [UTS-39-C5-2](#UTS-39-C5-2).*

> **[UTS-39-C5-1](#UTS-39-C5-1)**. *The implementation shall be in accordance with the specifications in Section 5.3, [Mixed-Number Detection](#Mixed_Number_Detection), without change.*
>
> **[UTS-39-C5-2](#UTS-39-C5-2)**. *The implementation shall provide a precise description of changes in behavior, but otherwise be in accordance with the specifications in Section 5.3, [Mixed-Number Detection](#Mixed_Number_Detection).*

## 3 [Identifier Characters](#Identifier_Characters)

Identifiers ("IDs") are strings used in application contexts
to refer to specific entities of certain significance in the given application. In a
given application, an identifier will map to at most one specific entity.
Many applications have security requirements related to identifiers.
A common example is URLs referring to pages
or other resources on the Internet: when a user wishes to access a
resource, it is important that the user can be certain what resource they
are interacting with. For example, they need to know that they are interacting with a
particular financial service and not some other entity that is spoofing the
intended service for malicious purposes. This illustrates a
general security concern for identifiers: potential ambiguity of strings.
While a machine has no difficulty distinguishing between any two different
character sequences, it could be very difficult for humans to
recognize and distinguish identifiers if an application did not limit which
Unicode characters could be in identifiers.
The focus of this specification is mitigation of such issues related
to the security of identifiers.

Deliberately restricting the characters that can be used in identifiers
is an important security technique.
The exclusion of characters from identifiers does not affect the general
use of those characters for other purposes, such as for general text in documents.
Unicode Standard Annex #31,
"Unicode Identifier and Pattern Syntax" [[UAX31](#UAX31)]
provides a recommended method of determining which strings should
qualify as identifiers. The UAX #31 specification extends the common
practice of defining identifiers in terms of letters and numbers to
the Unicode repertoire.

That specification also permits other protocols to use that method as
a base, and to define a  *profile* that adds or removes
characters. For example, identifiers for specific programming
languages typically add some characters like "$", and
remove others like "-" (because of the use as *minus*),
while IDNA removes "\_" (among others)—see Unicode
Technical Standard #46, "Unicode IDNA Compatibility
Processing" [[UTS46](#UTS46)], as well as [[IDNA2003](#IDNA2003)], and [[IDNA2008](#IDNA2008)].

This document provides for additional identifier profiles for
environments where security is an issue. These are profiles of the
extended identifiers based on properties and specifications of the
Unicode Standard [[Unicode](#Unicode)], including:

* The XID\_Start and XID\_Continue properties defined in the
  Unicode Character Database (see [[DCore](#DCore)])
* The toCasefold(X) operation defined in *Chapter
  3, Conformance* of [[Unicode](#Unicode)]
* The NFKC and NFKD normalizations defined in *Chapter
  3, Conformance* of [[Unicode](#Unicode)]

The data files used in defining these profiles follow the UCD File
Format, which has a semicolon-delimited list of data fields
associated with given characters, with each field referenced by
number. For more details, see [[UCDFormat](#UCDFormat)].

### 3.1 [General Security Profile for Identifiers](#General_Security_Profile)

The files under [[idmod](#idmod)] provide data for a profile of
identifiers in environments where security is at issue. The files
contain a set of characters recommended to be restricted from use.
They also contain a small set of characters that are recommended as
additions to the list of characters defined by the XID\_Start and
XID\_Continue properties, because they may be used in identifiers in a
broader context than programming identifiers.

The Restricted characters are characters not in common use, and
they can be blocked to further reduce the possibilities for visual
confusion. They include the following:

* characters not in modern use
* characters only used in specialized fields, such as
  liturgical characters, phonetic letters, and mathematical
  letter-like symbols
* characters in limited use by very small communities

The choice of which characters to specify as Restricted starts conservatively, but allows additions
in the future as requirements for characters are refined.
For information on handling modifications
over time, see *2.10.1, Backward
Compatibility* in *Unicode Technical Report #36,
"Unicode Security Considerations"* [[UTR36](#UTR36)].

An implementation following the General Security Profile does not
permit any characters in \p{Identifier\_Status=Restricted}, unless it documents the
additional characters that it does allow. Such documentation can specify characters via properties, such as \p{Identifier\_Type=Technical}, or by explicit lists, or by combinations of these. Implementations may also specify that fewer characters are allowed than implied by \p{Identifier\_Status=Allowed}; for example, they can allow only characters permitted by [[IDNA2008](#IDNA2008)].

Common candidates for such
additions include characters for scripts listed in *Table 7,
[Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* of [[UAX31](#UAX31)]. However,
characters from these scripts have not been a priority for
examination for confusables or to determine specialized, non-modern,
or uncommon-use characters.

Canonical equivalence is applied when testing candidate identifiers
for inclusion of *Allowed* characters. For example, suppose
the candidate string is the sequence

<u, *combining-diaeresis*>

The target string would be Allowed in *either* of the
following 2 situations:

1. u is Allowed and ¨ is Allowed, or
2. ü is Allowed

For details of the format for the [[idmod](#idmod)] files, see *Section 7, [Data Files](#Data_Files)*.

Table 1. [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)

| Identifier\_Status | Identifier\_Type | Description |
| --- | --- | --- |
| [Restricted](#restricted) | Not\_Character | Unassigned characters, private use characters, surrogates, non-whitespace control characters. |
| Deprecated | Characters with the Unicode property *Deprecated=Yes*. |
| Default\_Ignorable | Characters with the Unicode property *Default\_Ignorable\_Code\_Point=Yes*. |
| Not\_NFKC | Characters that cannot occur in strings normalized to NFKC. |
| Not\_XID | Characters that do not qualify as default Unicode identifiers; that is, they do not have the Unicode property *XID\_Continue=True*. |
| Exclusion | Characters with Script\_Extensions values containing a script in *Table 4, [Excluded Scripts](https://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*from [[UAX31](#UAX31)], and no script from *Table 7, [Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* or *Table 5, [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*, other than “Common” or “Inherited”. |
| Obsolete | Characters that are no longer in modern use, or that are not commonly used in modern text. |
| Technical | Specialized usage: technical, liturgical, etc. |
| Uncommon\_Use | Characters that are uncommon, or are limited in use (even though they are in scripts that are not "Limited\_Use"), or whose usage is uncertain.  May be combined with Exclusion or Limited\_Use for characters that are less common than the main characters of their scripts. |
| Limited\_Use | Characters from scripts that are in limited use: with Script\_Extensions values containing a script in *Table 7, [Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* in [[UAX31](#UAX31)], and no script from *Table 5, [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*, other than “Common” or “Inherited”. |
| [Allowed](#allowed) | **Inclusion** | Exceptionally allowed characters, including *Table 3a, [Optional Characters for Medial](https://www.unicode.org/reports/tr31/#Table_Optional_Medial)* and *Table 3b, [Optional Characters for Continue](https://www.unicode.org/reports/tr31/#Table_Optional_Continue)* in [[UAX31](#UAX31)], and some characters for [[IDNA2008](#IDNA2008)], except for certain characters that are Restricted above. |
| **Recommended** | Characters from scripts that are in widespread everyday common use: with Script\_Extensions values containing a script in *Table 5, [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)* in [[UAX31](#UAX31)], except for those characters that are Restricted above. |

> **Note:** In Unicode 15.0, the Joiner\_Control characters (ZWJ/ZWNJ) have been removed from
> Identifier\_Type=[Inclusion](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=[:Identifier_Type=Inclusion:]).
> They thereby have the properties
> Identifier\_Type=[Default\_Ignorable](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=[:Identifier_Type=Default_Ignorable:]) and
> Identifier\_Status=[Restricted](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=[:Identifier_Status=Restricted:]).
> Their inclusion in programming language identifier profiles has usability and security implications.
>
> Implementations of the General Profile for Identifiers that wish to retain ZWJ and ZWNJ should declare that they use a modification of the profile per
> *[Section 2, Conformance](#Conformance)*,
> and should ensure that they implement the restrictions described in
> *[Section 3.1.1, Joining Controls](#Joining_Controls)*.

Identifier\_Status and Identifier\_Type are properties of characters (code points).
See *UTS #18: Unicode Regular Expressions* [[UTS18](#UTS18)]
and *UTR #23: The Unicode Character Property Model* [[UTR23](#UTR23)] for
more discussion.
For the purpose of regular expressions,
the long and short names of these properties and their values
are documented in their respective data files;
see *Section 7, [Data Files](#Data_Files)*.

For stability considerations, see [Migrating
Persistent Data](#Migrating_Persistent_Data).

There may be multiple reasons for restricting a character; therefore,
the Identifier\_Type property allows multiple values that correspond with
Restricted. For example, some characters have Identifier\_Type values of
Limited\_Use and Technical. Multiple values are not assigned to characters with strong restrictions: Not\_Character, Deprecated, Default\_Ignorable, Not\_NFKC. For
example, if a character is Deprecated, there is little value in also
marking it as Uncommon\_Use. For the qualifiers on usage, Obsolete,
Uncommon\_Use and Technical, the distinctions among the Identifier\_Type values is not strict and
only one might be given. The important characteristic is the Identifier\_Status:
whether or not the character is Restricted.

The default Identifier\_Type property value should be Uncommon\_Use if no other categories apply.

*As more
information is gathered about characters, this data may change in
successive versions.* That can cause either the Identifier\_Status
or Identifier\_Type to change for a particular character. Thus users of
this data should be prepared for changes in successive versions, such
as by having a grandfathering policy in place for previously
supported characters or registrations. Both Identifier\_Status
and Identifier\_Type values are to be compared
case-insensitively and ignoring hyphens and underbars.

Restricted characters should be treated with caution when considering possible use in identifiers,
and should be disallowed unless there is good reason to allow them in the
environment in question. However, the set of Identifier\_Status=Allowed
characters are not typically used as is by implementations. Instead,
they are applied as filters to the set of characters C that are
supported by the identifier syntax, generating a new set C′.
Typically there are also particular characters or classes of
characters from C that are retained as **Exception**
characters.

C′ = (C ∩ {Identifier\_Status=Allowed}) ∪ **Exception**

The implementation may simply restrict use of new identifiers to C′,
or may apply some other strategy. For example, there might be an
appeal process for registrations of ids that contain characters
outside of C′ (but still inside of C), or in user interfaces for
lookup of identifiers, warnings of some kind may be appropriate. For
more information, see [[UTR36](#UTR36)].

The **Exception** characters would be
implementation-specific. For example, a particular implementation
might extend the default Unicode identifier syntax by adding **Exception**
characters with the Unicode property *XID\_Continue=False*,
such as “$”, “-”, and “.”. Those characters are specific to that
identifier syntax, and would be retained even though they are not in
the Identifier\_Status=Allowed set. Some
implementations may also wish to add some [[CLDR](#CLDR)]
exemplar characters for particular supported languages that have
unusual characters.

The Identifier\_Type=Inclusion characters already
contain some characters that are not letters or numbers, but that are
used within words in some languages. For example, it is recommended
that U+00B7 (·) MIDDLE DOT be allowed in identifiers, because it is
required for Catalan.

The implementation may also apply other restrictions discussed
in this document, such as checking for confusable characters or doing
mixed-script detection.

### 3.1.1 [Joining Controls](#Joining_Controls)

Visible distinctions
created by certain characters excluded by the
General Security Profile because their Identifier\_Type is Default\_Ignorable (particularly the *Join\_Control
characters*) are necessary in certain languages. A blanket exclusion
of these characters makes it impossible to create identifiers with
the correct visual appearance for common words or phrases in those
languages.

Identifier systems that attempt to provide more natural
representations of terms in "modern, customary usage"
should allow these characters in input and display, but limit them to
contexts in which they are necessary. The term *modern
customary usage* includes characters that are in common use in
newspapers, journals, lay publications; on street signs; in
commercial signage; and as part of common geographic names and
company names, and so on. It does not include technical or academic
usage such as in mathematical expressions, using archaic scripts or
words, or pedagogical use (such as illustration of half-forms or
joining forms in isolation), or liturgical use.

The goals for such a restriction of format characters to
particular contexts are to:

* Allow the use of these characters where required in normal
  text
* Exclude as many cases as possible where no visible
  distinction results
* Be simple enough to be easily implemented with standard
  mechanisms such as regular expressions

An implementation following the General Security Profile that allows the additional characters ZWJ and ZWNJ shall only permit them where they
satisfy the conditions A1, A2, and B in *Section 3.1.1.1, [Limited Contexts for Joiner Controls](#Limited_Contexts_for_Joining_Controls)*, unless it documents the
additional contexts where it allows them.

More advanced implementations may use script-specific information for more detailed testing. In particular, they can:

1. *Disallow joining controls* in sequences that meet the conditions of A1, A2, and B, where in common fonts the resulting appearance of the sequence is normally not distinct from appearance in the same sequences with the joining controls removed.

2. *Allow joining controls* in sequences that don't meet the conditions of A1, A2, and B, where in common fonts the resulting appearance of the sequence is normally distinct from the appearance in the same sequences with the joining controls removed. The following regular expressions describe sequences that typically result in distinct rendering. They use the notation explained below in [A1](#A1).

> /$L ZWNJ $V $L/
>
> /$L ZWJ $V $L/

#### 3.1.1.1 [Limited Contexts for Joining Controls](#Limited_Contexts_for_Joining_Controls)

An implementation that
attempts to provide more natural representations of terms in "modern, customary usage" should allow the
following Join\_Control characters in the limited contexts specified
in [A1](#A1), [A2](#A2), and [B](#B) below.

> U+200C ZERO WIDTH NON-JOINER (ZWNJ)
>  U+200D ZERO WIDTH JOINER
> (ZWJ)

There are also two global conditions incorporated in each of [A1](#A1), [A2](#A2), and [B](#B):

* **Script Restriction.** In each of the following cases,
  the specified sequence must only consist of characters from a single
  script (after ignoring *Common* and *Inherited* script
  characters).
* **Normalization.** In each of the following cases, the
  specified sequence must be in NFC format. (To test an identifier
  that is not required to be in NFC, first transform into NFC format
  and then test the condition.)

Implementations may also impose tighter restrictions than provided below, in order to eliminate some other circumstances where the characters either have no visual effect or the effect has no semantic importance.

**[A1](#A1). Allow ZWNJ in the
following context:**

**Breaking a cursive connection.**  That is, in the context based
on the Joining\_Type property, consisting of:

* A Left-Joining or Dual-Joining character, followed by zero
  or more Transparent characters, followed by a ZWNJ, followed by zero
  or more Transparent characters, followed by a Right-Joining or
  Dual-Joining character

This corresponds to the following regular expression (in Perl-style
syntax): **/$LJ $T\* ZWNJ $T\* $RJ/**

Where the character classes like $T could be
defined with Unicode properties
(similar to UnicodeSet notation) like this:

> $T = \p{Joining\_Type=Transparent}
>  $RJ =
> [\p{Joining\_Type=Dual\_Joining}\p{Joining\_Type=Right\_Joining}]
>
> $LJ = [\p{Joining\_Type=Dual\_Joining}\p{Joining\_Type=Left\_Joining}]

For example, consider Farsi <*Noon, Alef, Meem, Heh, Alef,
Farsi Yeh*>. Without a ZWNJ, it translates to "names",
as shown in the first row; with a ZWNJ between Heh and Alef, it means
"a letter", as shown in the second row of *Figure 1*.

Figure 1. [Persian Example with
ZWNJ](#Figure_Farsi_Example_with_ZWNJ)

| Appearance | Code Points | Abbreviated Names |
| --- | --- | --- |
| diagram1 | 0646 + 0627 + 0645 + 0647 + 0627 + 06CC | NOON + ALEF + MEEM + HEH + ALEF + FARSI YEH |
| diagram2 | 0646 + 0627 + 0645 + 0647 + 200C + 0627 + 06CC | NOON + ALEF + MEEM + HEH + ZWNJ + ALEF + FARSI YEH |

**[A2](#A2). Allow ZWNJ in the
following context:**

**In a conjunct context.** That is, a sequence of the form:

* A Letter, followed by a Virama, followed by a ZWNJ (optionally preceded or followed by certain nonspacing marks), followed by a Letter.

This corresponds to the following regular expression (in Perl-style
syntax): **/$L $M\* $V $M₁\* ZWNJ $M₁\* $L/**

Where:

> $L = \p{General\_Category=Letter}
>
> $V =
> \p{Canonical\_Combining\_Class=Virama}
>
> $M = \p{General\_Category=Mn}
>
> $M₁ = [\p{General\_Category=Mn}&\p{CCC≠0}]

For example, the Malayalam word for *eyewitness* is shown in *Figure
2*. The form without the ZWNJ in the second row is incorrect in this
case.

Figure 2. [Malayalam Example
with ZWNJ](#Figure_Malayalam_Example_with_ZWNJ)

| Appearance | Code Points | Abbreviated Names |
| --- | --- | --- |
| diagram3 | 0D26 + 0D43 + 0D15 + 0D4D + 200C + 0D38 + 0D3E + 0D15 + 0D4D + 0D37 + 0D3F | DA + VOWEL SIGN VOCALIC R + KA + VIRAMA + ZWNJ + SA + VOWEL SIGN AA + KA + VIRAMA + SSA + VOWEL SIGN I |
| diagram4 | 0D26 + 0D43 + 0D15 + 0D4D + 0D38 + 0D3E + 0D15 + 0D4D + 0D37 + 0D3F | DA + VOWEL SIGN VOCALIC R + KA + VIRAMA + SA + VOWEL SIGN AA + KA + VIRAMA + SSA + VOWEL SIGN I |

**[B](#B). Allow ZWJ in the
following context:**

**In a conjunct context.** That is, a sequence of the form:

* A Letter, followed by a Virama, followed by a ZWJ (optionally preceded or followed by certain nonspacing marks), and not followed by a character of type Indic\_Syllabic\_Category=Vowel\_Dependent

This corresponds to the following regular expression (in Perl-style
syntax):  **/$L $M\* $V $M₁\* ZWJ (?!$D)/**

Where:

> $L= \p{General\_Category=Letter}
>
> $V =
> \p{Canonical\_Combining\_Class=Virama}
>
> $M = \p{General\_Category=Mn}
>
> $M₁ = [\p{General\_Category=Mn}&\p{CCC≠0}]
>
> $D = \p{Indic\_Syllabic\_Category=Vowel\_Dependent}

For example, the Sinhala word for the country 'Sri Lanka' is
shown in the first row of *Figure 3*, which uses both a space
character and a ZWJ. Removing the space results in the text shown in
the second row of *Figure 3*, which is still legible, but
removing the ZWJ completely modifies the appearance of the
'Sri' cluster and results in the unacceptable text appearance
shown in the third row of *Figure 3*.

Figure 3. [Sinhala Example with
ZWJ](#Figure_Sinhala_Example_with_ZWJ)

| Appearance | Code Points | Abbreviated Names |
| --- | --- | --- |
| diagram5 | 0DC1 + 0DCA + 200D + 0DBB + 0DD3 + 0020 + 0DBD + 0D82 + 0D9A + 0DCF | SHA + VIRAMA + ZWJ + RA + VOWEL SIGN II + SPACE + LA + ANUSVARA + KA + VOWEL SIGN AA |
| diagram6 | 0DC1 + 0DCA + 200D + 0DBB + 0DD3 + 0DBD + 0D82 + 0D9A + 0DCF | SHA + VIRAMA + ZWJ + RA + VOWEL SIGN II + LA + ANUSVARA + KA + VOWEL SIGN AA |
| diagram7 | 0DC1 + 0DCA + 0DBB + 0DD3 + 0020 + 0DBD + 0D82 + 0D9A + 0DCF | SHA + VIRAMA + RA + VOWEL SIGN II + SPACE + LA + ANUSVARA + KA + VOWEL SIGN AA |

> **Note:** The restrictions in [A1](#A1),
> [A2](#A2), and [B](#B)
> are similar to the CONTEXTJ rules defined in *Appendix A, Contextual Rules Registry*,
> in *The Unicode Code Points and Internationalized Domain Names for Applications (IDNA)*
> [[IDNA2008](#IDNA2008)].

#### 3.1.1.2 [Limitations](#Limitations)

While the restrictions in [A1](#A1), [A2](#A2), and [B](#B) greatly
limit visual confusability, they do not prevent it. For example,
because Tamil only uses a Join\_Control character in one specific
case, most of the sequences these rules allow in Tamil are, in fact,
visually confusable. Therefore based on their knowledge of the script
concerned, implementations may choose to have tighter restrictions
than specified in *Section 3.1.1.2, [Limited Contexts for Joining Controls](#Limited_Contexts_for_Joining_Controls)*—for example, by explicitly providing for the exceptional sequence, while otherwise disallowing the joiner in context.

There are also cases where a joiner preceding a
virama makes a visual distinction in some scripts. It is currently
unclear whether this distinction is important enough in identifiers
to warrant retention of a joiner. For more information, see UTR #36: *Unicode Security Considerations* [[UTR36](#UTR36)].

***Performance.*** Parsing identifiers can be a
performance-sensitive task. However, these characters are quite rare
in practice, thus the regular expressions (or equivalent processing)
only rarely would need to be invoked. Thus these tests should not add
any significant performance cost overall.

### 3.2 [IDN Security Profiles for Identifiers](#IDN_Security_Profiles)

Version 1 of this document defined operations and data that apply to
[[IDNA2003](#IDNA2003)], which has been superseded by [[IDNA2008](#IDNA2008)] and Unicode Technical
Standard #46, "Unicode IDNA Compatibility
Processing" [[UTS46](#UTS46)]. The identifier
modification data can be applied to whichever specification of IDNA
is being used. For more information, see the [[IDN
FAQ](#IDN_FAQ)].

However, implementations can claim conformance to other features of
this document as applied to domain names, such as [Restriction Levels](#Restriction_Level_Detection).

### 3.3 [Email Security Profiles for Identifiers](#Email_Security_Profiles)

The *SMTP Extension for Internationalized Email* provides for specifications of internationalized email addresses [[EAI](#EAI)]. However, it does not provide for testing those addresses for security issues. This section provides an email security profile that may be used for that. It can be applied for different purposes, such as:

1. When an email address is registered, flag anything that
   does not meet the profile:
   * Either forbid the registration, or
   * Allow for an appeals process.
2. When an email address is detected in linkification of plain
   text:
   * Do not linkify if the identifier does not meet
     the profile.
3. When an email address is displayed in incoming email:
   * Flag it as suspicious with a wavy underline, if it
     does not meet the profile.
   * Filter characters from the quoted-string-part to prevent
     display problems.

This profile does not exclude characters from
EAI. Instead, it provides a profile that can be used for registration, linkification,
and notification. The goal is to flag
addresses that are structurally unsound or contain unexpected detritus.

An email address is formed from three main parts. (There are more elements of an email address, but these are the ones for which Unicode security is important.) For example:

> "Joey" <joe31834@gmail.com>
>
> * The **domain-part** is "gmail.com"
> * The **local-part** is "joe31834"
> * The **quoted-string-part** is "Joey"

To meet the requirements of the **Email Security Profiles for Identifiers** section of this specification, an identifier must satisfy the following
conditions for the specified <restriction level>.

#### Domain-Part

The domain-part of an email address must satisfy *Section 3.2, [IDN
Security Profiles for Identifiers](#IDN_Security_Profiles)*, and satisfy the conformance
clauses of [[UTS46](#UTS46)].

#### Local-Part

The local-part of an email address must satisfy all the following conditions:

1. It must be in NFKC format
2. It must have level = <restriction level> or less,
   from [Restriction\_Level\_Detection](#Restriction_Level_Detection)
3. It must not have mixed number systems according to [Mixed\_Number\_Detection](#Mixed_Number_Detection)
4. It must satisfy *dot-atom-text* from [RFC
   5322 §3.2.3](https://www.rfc-editor.org/rfc/rfc5322.html#section-3.2.3), where *atext* is extended as follows:

> Where C ≤ U+007F, C is defined as in
> [§3.2.3](https://www.rfc-editor.org/rfc/rfc5322.html#section-3.2.3).
> (That is, C ∈ [[!#-'\*+\-/-9=?A-Z\^-~](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=%5B%21%23-%27*%2B%5C-%2F-9%3D%3FA-Z%5C%5E-~%5D&abb=on&g=)].
> This list copies what is already in §3.2.3,
> and follows [HTML5](https://html.spec.whatwg.org/multipage/input.html#email-state-(type=email))
> for ASCII.)
>
> Where C > U+007F, both of the following conditions
> are true:
>
> 1. C has Identifier\_Status=Allowed from [General Security Profile](#General_Security_Profile)
> 2. If C is the first character, it must be XID\_Start from
>    [Default Identifier\_Syntax](https://www.unicode.org/reports/tr31/#Default_Identifier_Syntax) in [[UAX31](#UAX31)]

Note that in [RFC
5322 §3.2.3](https://www.rfc-editor.org/rfc/rfc5322.html#section-3.2.3):

> `dot-atom-text   =
>   1*atext *("." 1*atext)`

That is, dots can also occur in the local-part, but
not leading, trailing, or two in a row. In more conventional regex syntax, this would be:

> `dot-atom-text   =
>   atext+ ("." atext+)*`

Note that bidirectional controls and other format characters are
specifically disallowed in the local-part, according to the
above.

#### Quoted-String-Part

The quoted-string-part of an email address must
satisfy the following conditions:

1. It must be in NFC.
2. It must not contain any stateful bidirectional format characters.
   * That is, no [:bidicontrol:] except for the LRM, RLM, and ALM, since the bidirectional controls could influence the ordering of characters outside
     the quotes.
3. It must not contain more than four nonspacing marks in a row, and no
   sequence of two of the same nonspacing marks.
4. It may contain mixed scripts, symbols (including emoji),
   and so on.

#### Other Issues

The restrictions above are insufficient to
prevent bidirectional-reordering that could intermix the quoted-string-part
with the local-part or the domain-part in display. To prevent that,
implementations could use bidirectional isolates (or equivalent) around the
each of these parts in display.

Implementations may also want to use other checks, such as for confusability, or services such as Safe Browsing.

A serious practical issue is that clients do not know what the
identity rules are for any particular email server: that is, when two
email addresses are considered equivalent. For example, are *mark@macchiato.com*
and *Mark@macchiato.com* treated the same by the server?
Unfortunately, there is no way to query a server to see
what identity rules it follows. One of the techniques used to deal with
this problem is having whitelists of email providers indicating which of them are case-insensitive, dot-insensitive, or both.

## 4 [Confusable Detection](#Confusable_Detection)

The data in [[confusables](#confusables)] provide a
mechanism for determining when two strings are visually confusable.
The data in these files may be refined and extended over time. For
information on handling modifications over time, see *Section
2.10.1, Backward Compatibility* in Unicode Technical Report #36,
"Unicode Security Considerations" [[UTR36](#UTR36)]
and the [Migration](#Migration) section of this document.

Collection of data for detecting gatekeeper-confusable strings is not
currently a goal for the confusable detection mechanism in this
document. For more information, see *Section 2, Visual
Security Issues* in [[UTR36](#UTR36)].

The data provides a mapping from source characters to their prototypes. A prototype should be thought of as a sequence of one or more classes of symbols, where each class has an exemplar character. For example, the character U+0153 (œ), LATIN SMALL LIGATURE OE, has a prototype consisting of two symbol classes: the one with exemplar character U+006F (o), and the one with exemplar character U+0065 (e). If an input character does not have a prototype explicitly defined in the data file, the prototype is assumed to consist of the class of symbols with the input character as the exemplar character.

For an input string X, define [internalSkeleton](#def-internalSkeleton)(X) to be the following transformation on the string:

1. Convert X to NFD format, as described in [[UAX15](#UAX15)].
2. Remove any characters in X that have the property Default\_Ignorable\_Code\_Point.
3. Concatenate the prototypes for each character in X according to the specified data, producing a string of exemplar characters.
4. Reapply NFD.

For an input string X and a direction 𝑑 ∈ {RTL, LTR, FS}, define bidiSkeleton(𝑑, X) to be the following transformation on the string:

1. Reorder the code points in X for display by applying the rules of the Unicode Bidirectional Algorithm [[UAX9](#UAX9)] up to and including L2, treating X in isolation; if 𝑑≠FS, apply protocol HL1 to set the paragraph level to 1 if 𝑑=RTL, and to 0 if 𝑑=LTR; this yields the reordered sequence of characters R.
2. Apply rule L3 of the UBA: move combining marks after their base in R; this yields the sequence R′.
3. Replace any character whose glyph would be mirrored by rule L4 of the UBA by the value of its Bidi\_Mirroring\_Glyph property, yielding R″.
4. bidiSkeleton(𝑑, X) is then internalSkeleton(R″).

The strings X and Y are defined to be 𝑑-confusable if and only if bidiSkeleton(𝑑, X) = bidiSkeleton(𝑑, Y). This is abbreviated as X ≒ Y (𝑑).

This mechanism imposes transitivity on the data, so if X ≒ Y (𝑑) and Y ≒ Z (𝑑), then X ≒ Z (𝑑). It is possible to provide a more sophisticated confusable detection, by providing a metric between given characters, indicating their "closeness." However, that is computationally much more expensive, and requires more sophisticated data, so at this point in time the simpler mechanism has been chosen. That means that in some cases the test may be overly inclusive.

> **Note:** The operation *internalSkeleton* may change the Bidi\_Class of characters, so it does not commute with the reordering and mirroring steps, and needs to be performed after them.

> **Example:** The sequences of code points S₁ and S₂ are LTR-confusable:
>
> > S₁ ≔ "A1<שׂ" = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT SIN DOT)
> >
> > S₂ ≔ "Αשֺ>1" = (GREEK CAPITAL LETTER ALPHA, HEBREW LETTER SHIN, HEBREW POINT HOLAM HASER FOR VAV, GREATER-THAN SIGN, DIGIT ONE)
>
> Computation of bidiSkeleton(LTR, S₁):
>
> R₁ = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW POINT SIN DOT, HEBREW LETTER SHIN)
>
> R′₁ = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT SIN DOT)
>
> R″₁ = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT SIN DOT)
>
> bidiskeleton(LTR, S₁) = internalSkeleton(R″₁) = (LATIN CAPITAL LETTER A, LATIN SMALL LETTER L, LESS-THAN SIGN, HEBREW LETTER SHIN, COMBINING DOT ABOVE)
>
> Computation of bidiSkeleton(LTR, S₂):
>
> R₂ = (GREEK CAPITAL LETTER ALPHA, DIGIT ONE, GREATER-THAN SIGN, HEBREW POINT HOLAM HASER FOR VAV, HEBREW LETTER SHIN)
>
> R′₂ = (GREEK CAPITAL LETTER ALPHA, DIGIT ONE, GREATER-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT HOLAM HASER FOR VAV)
>
> R″₂ = (GREEK CAPITAL LETTER ALPHA, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT HOLAM HASER FOR VAV)
>
> bidiskeleton(LTR, S₂) = internalSkeleton(R″₂) = (LATIN CAPITAL LETTER A, LATIN SMALL LETTER L, LESS-THAN SIGN, HEBREW LETTER SHIN, COMBINING DOT ABOVE)
>
> Note that these sequences are not RTL-confusable; indeed in a right-to-left paragraph, the strings look distinct:
>
> > S₁ = "A1<שׂ"
> >
> > S₂ = "Αשֺ>1"

LTR, and RTL, and FS confusability should be used when it is inappropriate to enforce that strings be single-script,
or at least single-directionality; this is the case in programming language identifiers.
See *Section 5.1, Confusability Mitigation Diagnostics*, in
*Unicode Technical Standard #55, Unicode Source Code Handling* [[UTS55](#UTS55)].

The bidiSkeleton is costlier to compute than the internalSkeleton, as the bidirectional algorithm must be applied.
However, a fast path can be used: if 𝑑=LTR and X has no characters with bidi classes R or AL, bidiSkeleton(𝑑, X) = internalSkeleton(X).

Further, if the strings are known not to contain explicit directional formatting characters (as is the case for UAX31-R1 Default Identifiers
defined in *Unicode Standard Annex #31, Identifiers and Syntax* [[UAX31](#UAX31)]), the algorithm can be drastically simplified,
as the X rules are trivial, obviating the need for the directional status stack of the Unicode Bidirectional Algorithm.
The highest possible resolved level is then 2; see *Table 5, Resolving Implicit Levels*,
in *Unicode Standard Annex #9, Unicode Bidirectional Algorithm* [[UAX9](#UAX9)].

> **Note:** The strings *bidiSkeleton*(𝑑, X) and *bidiSkeleton*(𝑑, Y)
> are ***not*** intended for display.
> Further, they are not stable across versions of Unicode, so that
> they can only be interchanged between systems that use the same version of Unicode to compute *bidiSkeleton*.
> If they are stored, they must be recomputed when updating the version of Unicode used to compute *bidiSkeleton*.
> They should be thought of as an intermediate processing form,
> similar to a hashcode. The exemplar characters are ***not*** guaranteed to be identifier characters.

The use of bidirectional confusability with an appropriate direction is preferable when possible.
However, for cases where the direction with which identifiers will be displayed is unknown,
and for compatibility with earlier definitions of confusability which did not take bidirectional reordering into account,
the operation [skeleton](#def-skeleton) is
defined as skeleton(X) = bidiSkeleton(LTR, X). The strings X and Y are then
defined to be [confusable](#def-confusable) if and only if skeleton(X) = skeleton(Y). This is abbreviated as X ≅ Y.

> **Note:** Some implementations of confusable detection outside Unicode use different terminology.
> In particular, in the ICANN Root Zone Label Generation Rules [[RZLGR5](#RZLGR5)], the term
> *variant of X* is used for a property similar to *confusable with X*, and the term
> *index variant* is used for the equivalent of *skeleton*.

**Definitions**

Confusables are divided into three classes: single-script confusables, mixed-script confusables, and whole-script confusables, defined below. All confusables are either a single-script confusable or a mixed-script confusable, but not both. All whole-script confusables are also mixed-script confusables.

The definitions of these three classes of confusables depend on the definitions of *resolved script set* and *single-script*, which are provided in *Section 5, [Mixed-Script
Detection](#Mixed_Script_Detection)*.

X and Y are *[single-script confusables](#single_script_confusables)* if
and only if they are confusable, and their resolved script sets have at least one element in common.

> Examples: “ǉeto” and “ljeto” in Latin (the Croatian word for “summer”), where the first word uses only four codepoints, the first of which is U+01C9 (ǉ) LATIN SMALL LETTER LJ.

X and Y are *[mixed-script confusables](#mixed_script_confusables)* if
and only if they are confusable but their resolved script sets have no elements in common.

> Examples: "paypal" and "pаypаl", where the
> second word has the character [U+0430](https://util.unicode.org/UnicodeJsps/character.jsp?a=0430) ( а )
> CYRILLIC SMALL LETTER A.

X and Y are *[whole-script confusables](#def_whole_script_confusables)* if
and only if they are *mixed-script confusables,* and each of them is a
single-script string.

> Example: "scope" in Latin and "ѕсоре" in Cyrillic.

As noted in Section 5, the resolved script set ignores characters with Script\_Extensions {Common} and {Inherited} and augments characters with CJK scripts with their respective writing systems. Characters with the Script\_Extension property values COMMON or
INHERITED are ignored when testing for differences in script.

### Data File Format

Each line in the data file has the following format: Field 1 is
the source, Field 2 is the target, and Field 3 is obsolete, always containing the letters “MA” for backwards compatibility. For example:

> 0441 ; 0063 ; MA # ( с → c ) CYRILLIC SMALL LETTER ES → LATIN SMALL
> LETTER C #
>
> 2CA5 ; 0063 ; MA # ( ⲥ → c ) COPTIC SMALL LETTER SIMA → LATIN
> SMALL LETTER C # →ϲ→

Everything after the # is a comment and is purely informative. A
asterisk after the comment indicates that the character is not an XID
character [[UAX31](#UAX31)]. The comments provide the
character names.

Implementations that use the confusable data do not have to
recursively apply the mappings, because the transforms are
idempotent. That is,

*skeleton(skeleton(X)) = skeleton(X)*

If the data was derived via transitivity, there is
an extra comment at the end. For instance, in the above example the
derivation was:

1. ⲥ (U+2CA5 COPTIC SMALL LETTER SIMA)
2. → ϲ (U+03F2 GREEK LUNATE SIGMA SYMBOL)
3. → c (U+0063 LATIN SMALL LETTER C)

To reduce security risks, it is advised that identifiers use
casefolded forms, thus eliminating uppercase variants where possible.

The data may change between versions. Even where the data is the
same, the order of lines in the files may change between versions.
For more information, see [Migration](#Migration).

> **Note:** Due to production problems, versions
> before 7.0 did not maintain idempotency in all cases. For more
> information, see [Migration](#Migration).

### 4.1 [Whole-Script Confusables](#Whole_Script_Confusables)

For some applications, it is useful to determine if a given input string has any whole-script confusable. For example, the identifier "ѕсоре" using Cyrillic characters would pass the single-script test described in *Section 5.2, [Restriction-Level Detection](#Restriction_Level_Detection)*, even though it is likely to be a spoof attempt.

It is possible to determine whether a single-script string X has a whole-script confusable:

1. Consider Q, the set of all strings that are confusable with X.
2. Remove all strings from Q whose resolved script set intersects with the resolved script set of X.
3. If Q is nonempty and contains any single-script string, return TRUE.
4. Otherwise, return FALSE.

The logical description above can be used for a reference implementation for testing, but is not particularly efficient. A production implementation can be optimized as long as it produces the same results.

Note that the confusables data include a large number of mappings between Latin and Cyrillic text. For this reason, the above algorithm is likely to flag a large number of legitimate strings written in Latin or Cyrillic as potential whole-script confusables. To effectively use whole-script confusables, it is often useful to determine both whether a string has a whole-script confusable, and *which* scripts those whole-script confusables have.

This information can be used, for example, to distinguish between reasonable versus suspect whole-script confusables. Consider the Latin-script domain-name label “circle”. It would be appropriate to have that in the domain name “circle.com”. It would also be appropriate to have the Cyrillic confusable “сігсӀе” in the Cyrillic domain name “сігсӀе.рф”. However, a browser may want to alert the user to possible spoofs if the Cyrillic “сігсӀе” is used with .com or the Latin “circle” is used with .рф.

The process of determining suspect usage of whole-script confusables is more complicated than simply looking at the scripts of the labels in a domain name. For example, it can be perfectly legitimate to have scripts in a SLD (second level domain) not be the same as scripts in a TLD (top-level domain), such as:

* Cyrillic labels in a domain name with a TLD of .ru or .рф
* Chinese labels in a domain name with a TLD of .com.au or .com
* Cyrillic labels *that aren’t confusable* with Latin with a TLD of .com.au or .com

The following high-level algorithm can be used to determine all scripts that contain a whole-script confusable with a string X:

1. Consider Q, the set of all strings confusable with X.
2. Remove all strings from Q whose resolved script set is ∅ or **ALL** (that is, keep only single-script strings plus those with characters only in Common).
3. Take the union of the resolved script sets of all strings remaining in Q.

As usual, this algorithm is intended only as a definition; implementations should use an optimized routine that produces the same result.

### 4.2 [Mixed-Script Confusables](#Mixed_Script_Confusables)

To determine the existence of a mixed-script confusable, a similar process could be used:

1. Consider Q, the set of all strings that are confusable with X.
2. Remove all strings from Q whose resolved script set intersects with the resolved script set of X.
3. If Q is nonempty, return TRUE.
4. Otherwise, return FALSE.

The logical description above can be used for a reference implementation for testing, but is not particularly efficient. A production implementation can be optimized as long as it produces the same results.

Note that due to the number of mappings provided by the confusables data, the above algorithm is likely to flag a large number of legitimate strings as potential mixed-script confusables.

## 5 [Detection Mechanisms](#Detection_Mechanisms)

### 5.1 [Mixed-Script Detection](#Mixed_Script_Detection)

The Unicode Standard supplies information that can be used for
determining the script of characters and detecting mixed-script text.
The determination of script is according to the *UAX #24, Unicode Script Property* [[UAX24](#UAX24)], using data from the Unicode Character Database [[UCD](#UCD)].

Define a character's [augmented script set](#def-augmented-script-set) to be a character's Script\_Extensions with the following two modifications.

1. Entries for the writing systems containing multiple scripts — Hanb (Han with Bopomofo), Jpan (Japanese), and Kore (Korean) — are added according to the following rules.
   1. If Script\_Extensions contains Hani (Han), add Hanb, Jpan, and Kore.
   2. If Script\_Extensions contains Hira (Hiragana), add Jpan.
   3. If Script\_Extensions contains Kana (Katakana), add Jpan.
   4. If Script\_Extensions contains Hang (Hangul), add Kore.
   5. If Script\_Extensions contains Bopo (Bopomofo), add Hanb.
2. Sets containing Zyyy (Common) or Zinh (Inherited) are treated as **ALL**, the set of all script values.

The Script\_Extensions data is from the Unicode Character Database [[UCD](#UCD)]. For more information on the Script\_Extensions property and Jpan, Kore, and Hanb, see *UAX #24, Unicode Script Property* [[UAX24](#UAX24)].

Define the [resolved script set](#def-resolved-script-set) for a string to be the intersection of the augmented script sets over all characters in the string.

A string is defined to be [mixed-script](#def-mixed-script) if its resolved script set is empty and defined to be [single-script](#def-single-script) if its resolved script set is nonempty.
> **Note:** The term “*single*-script string” may be confusing. It means that there is *at least one* script in the resolved script set, not that there is *only one*. For example, the string “〆切” is single-script, because it has *four* scripts {Hani, Hanb, Jpan, Kore} in its resolved script set.

As well as providing an API to detect whether a string *has* mixed-scripts, is also useful to offer an API that returns those scripts.
Look at the examples below.

Table 1a. [Mixed Script Examples](#Mixed_Script_Examples)

| String | Code Point | Script\_Extensions | Augmented Script Sets | Resolved Script Set | Single-Script? |
| --- | --- | --- | --- | --- | --- |
| Circle | U+0043U+0069U+0072U+0063U+006CU+0065 | {Latn}{Latn}{Latn}{Latn}{Latn}{Latn} | {Latn}{Latn}{Latn}{Latn}{Latn}{Latn} | {Latn} | Yes |
| СігсӀе | U+0421U+0456U+0433U+0441U+04C0U+0435 | {Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl} | {Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl} | {Cyrl} | Yes |
| Сirсlе | U+0421U+0069U+0072U+0441U+006CU+0435 | {Cyrl}{Latn}{Latn}{Cyrl}{Latn}{Cyrl} | {Cyrl}{Latn}{Latn}{Cyrl}{Latn}{Cyrl} | ∅ | No |
| Circ1e | U+0043U+0069U+0072U+0063U+0031U+0065 | {Latn}{Latn}{Latn}{Latn}{Zyyy}{Latn} | {Latn}{Latn}{Latn}{Latn} **ALL**{Latn} | {Latn} | Yes |
| C𝗂𝗋𝖼𝗅𝖾 | U+0043U+1D5C2U+1D5CBU+1D5BCU+1D5C5U+1D5BE | {Latn}{Zyyy}{Zyyy}{Zyyy}{Zyyy}{Zyyy} | {Latn} **ALL** **ALL** **ALL** **ALL** **ALL** | {Latn} | Yes |
| 𝖢𝗂𝗋𝖼𝗅𝖾 | U+1D5A2U+1D5C2U+1D5CBU+1D5BCU+1D5C5U+1D5BE | {Zyyy}{Zyyy}{Zyyy}{Zyyy}{Zyyy}{Zyyy} | **ALL** **ALL** **ALL** **ALL** **ALL****ALL** | **ALL** | Yes |
| 〆切 | U+3006U+5207 | {Hani, Hira, Kana}{Hani} | {Hani, Hira, Kana, Hanb, Jpan, Kore}{Hani, Hanb, Jpan, Kore} | {Hani, Hanb, Jpan, Kore} | Yes |
| ねガ | U+306DU+30AC | {Hira}{Kana} | {Hira, Jpan}{Kana, Jpan} | {Jpan} | Yes |

A set of scripts is defined to [cover](#def-cover) a string if the intersection of that set with the augmented script sets of all characters in the string is nonempty; in other words, if every character in the string shares at least one script with the cover set. For example, {Latn, Cyrl} covers "Сirсlе", the third example in [Table 1a](#Mixed_Script_Examples).

A cover set is defined to be [minimal](#def-minimal) if there is no smaller cover set. For example, {Hira, Hani} covers "〆切", the seventh example in [Table 1a](#Mixed_Script_Examples), but it is not minimal, since {Hira} also covers the string, and {Hira} is smaller than {Hira, Hani}. Note that minimal cover sets are not unique: a string may have different minimal cover sets.

Typically an API that returns the scripts in a string will return one of the minimal cover sets.

For computational efficiency, a set of script sets (SOSS) can be computed, where the augmented script sets for each character in the string map to one entry in the SOSS. For example, { {Latn}, {Cyrl} } would be the SOSS for "Сirсlе". A set of scripts that covers the SOSS also covers the input string. Likewise, the intersection of all entries of the SOSS will be the input string's resolved script set.

### 5.2 [Restriction-Level Detection](#Restriction_Level_Detection)

Restriction Levels 1-5 are defined here for use in implementations.
These place restrictions on the use of identifiers according to the
appropriate *identifier profile* as specified in *Section 3, [Identifier
Characters](https://www.unicode.org/reports/tr39/#Identifier_Characters)*. The lists of Recommended scripts are
taken from *[Table
5, Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)* of [[UAX31](#UAX31)]. For
more information on the use of Restriction Levels, see *Section
2.9, Restriction Levels and Alerts* in [[UTR36](#UTR36)].

For each of the Restriction Levels 1-6, the identifier must be well-formed according to whatever general syntactic constraints are in force, such as the Default Identifier Syntax in [[UAX31](#UAX31)].

In addition, an application may provide an *identifier profile* such as the [General Security Profile for Identifiers](#General_Security_Profile), which restricts the allowed characters further. For each of the Restriction Levels 1-5, characters in the string must also be in the *identifier profile*. Where there is no such *identifier profile*, Levels 5 and 6 are identical.

1. **[ASCII-Only](#ascii_only)**
   * All characters in the string are in the ASCII range.
2. **[Single Script](#single_script)**
   * The string qualifies as ASCII-Only, or
   * The string is [single-script](#def-single-script), according to the definition in Section 5.1.
3. **[Highly Restrictive](#highly_restrictive)**
   * The string qualifies as Single Script, or
   * The string is [covered](#def-cover) by any of the following sets of scripts, according to the definition in Section 5.1:
     + *Latin + Han + Hiragana + Katakana*; or equivalently: Latn + Jpan
     + *Latin + Han + Bopomofo*; or equivalently: Latn + Hanb
     + *Latin + Han + Hangul;* or equivalently: Latn + Kore
4. **[Moderately Restrictive](#moderately_restrictive)**
   * The string qualifies as Highly Restrictive, or
   * The string is [covered](#def-cover) by Latin and any one other Recommended script, except Cyrillic, Greek
5. **[Minimally Restrictive](#minimally_restrictive)**
   * There are no restrictions on the set of scripts that [cover](#def-cover) the string.
   * The only restrictions are the identifier well-formedness criteria and *identifier profile*, allowing arbitrary mixtures of scripts such as Ωmega, Teχ,
     HλLF-LIFE, Toys-Я-Us.
6. **[Unrestricted](#unrestricted)**
   * There are no restrictions on the script coverage of the string.
   * The only restrictions are the criteria on identifier well-formedness. Characters may be outside of the
     *identifier profile*.
   * This level is primarily for use in detection APIs, providing return value indicating that the string does not match any of the levels 1-5.

Note that in all levels except ASCII-Only, any character having Script\_Extensions {Common} or {Inherited} are allowed in the identifier, as long as those characters meet the *identifier profile* requirements.

These levels can be detected by reusing some of the mechanisms
of Section 5.1. For a given input string, the Restriction Level is
determined by the following logical process:

1. If the string contains any characters outside of the
   Identifier Profile, return **Unrestricted**.
2. If no character in the string is above 0x7F, return **ASCII-Only**.
3. Compute the string's SOSS according to Section 5.1.
4. If the SOSS is empty or the intersection of all entries in the SOSS is nonempty, return **Single Script**.
5. Remove all the entries from the SOSS that contain Latin.
6. If any of the following sets cover SOSS, return **Highly
   Restrictive.**
   * {*Kore*}
   * {*Hanb*}
   * {*Japn*}
7. If the intersection of all entries in the SOSS contains any single **Recommended**
   script except *Cyrillic* *or Greek*, return **Moderately
   Restrictive**.
8. Otherwise, return **Minimally Restrictive**.

The actual implementation of this algorithm can be optimized;
as usual, the specification only depends on the results.

### 5.3 [Mixed-Number Detection](#Mixed_Number_Detection)

There are three different types of numbers in Unicode. Only numbers
with General\_Category = Decimal\_Numbers (Nd) should be allowed in
identifiers. However, characters from different decimal number
systems can be easily confused. For example, [U+0660](https://util.unicode.org/UnicodeJsps/character.jsp?a=0660) ( ٠ )
ARABIC-INDIC DIGIT ZERO can be confused with [U+06F0](https://util.unicode.org/UnicodeJsps/character.jsp?a=06F0) ( ۰ )
EXTENDED ARABIC-INDIC DIGIT ZERO, and [U+09EA](https://util.unicode.org/UnicodeJsps/character.jsp?a=09EA) ( ৪ )
BENGALI DIGIT FOUR can be confused with [U+0038](https://util.unicode.org/UnicodeJsps/character.jsp?a=0038) ( 8 )
DIGIT EIGHT. There are other reasons for disallowing mixed number systems in identifiers, just as there are for mixing scripts.

For a given input string which does not contain non-decimal
numbers, the logical process of detecting mixed numbers is the
following:

For each character in the string:

1. Find the decimal number value for that character, if any.
2. Map the value to the unique zero character for that number
   system.

If there is more than one such zero character, then the string
contains multiple decimal number systems.

The actual implementation of this algorithm can be optimized; as
usual, the specification only depends on the results. The following
Java sample using [[ICU](#ICU)] shows how this can be done
:

```

    public UnicodeSet getNumberRepresentatives(String identifier) {
        int cp;
        UnicodeSet numerics = new UnicodeSet();
        for (int i = 0; i < identifier.length(); i += Character.charCount(i)) {
            cp = Character.codePointAt(identifier, i);
            // Store a representative character for each kind of decimal digit
            switch (UCharacter.getType(cp)) {
            case UCharacterCategory.DECIMAL_DIGIT_NUMBER:
                // Just store the zero character as a representative for comparison.
                // Unicode guarantees it is cp - value.
                numerics.add(cp - UCharacter.getNumericValue(cp));
                break;
            case UCharacterCategory.OTHER_NUMBER:
            case UCharacterCategory.LETTER_NUMBER:
                throw new IllegalArgumentException("Should not be in identifiers.");
            }
        }
        return numerics;
    }
...
    UnicodeSet numerics = getMixedNumbers(String identifier);
    if (numerics.size() > 1) reject(identifier, numerics);
```
### 5.4 [Optional Detection](#Optional_Detection)

There are additional enhancements that may be useful in spoof
detection, such as:

1. Check to see that all the characters are in the sets of
   exemplar characters for at least one language in the Unicode Common
   Locale Data Repository [[CLDR](#CLDR)].
2. Check for unlikely sequences of combining marks:
   1. Forbid sequences of the same nonspacing mark.
   2. Forbid sequences of more than 4 nonspacing marks (gc=Mn or gc=Me).
   3. Forbid sequences of base character + nonspacing mark that look the same as or confusingly similar to the base character alone (because the nonspacing mark overlays a portion of the base character). An example is U+0069 LOWERCASE LETTER I + U+0307 COMBINING DOT ABOVE.
3. Add support for detecting two distinct *sequences* that have identical representations. The current data files only handle cases where a single code point is confusable with another code point or sequence. It does not handle cases like *shri*, as below.

The characters U+0BB6 TAMIL LETTER SHA and U+0BB8 TAMIL LETTER SA are normally quite distinct. However, they can both be used in the representation of the Tamil word *shri*. On some very common platforms, the following sequences result in exactly the same visual appearance:

| U+0BB6 | U+0BCD | U+0BB0 | U+0BC0 |
| --- | --- | --- | --- |
| SHA | VIRAMA | RA | II |
| ஶ | ் | ர | ◌ீ | ``` = ஶ்ரீ ``` |

| U+0BB8 | U+0BCD | U+0BB0 | U+0BC0 |
| --- | --- | --- | --- |
| SA | VIRAMA | RA | II |
| ஸ | ் | ர | ◌ீ | ``` = ஸ்ரீ ``` |

## 6 [Development Process](#Development_Process)

As discussed in Unicode Technical
Report #36, "Unicode Security Considerations" [[UTR36](#UTR36)], confusability among characters cannot be
an exact science. There are many factors that make confusability a
matter of degree:

* Shapes of characters vary greatly among fonts used to
  represent them. The Unicode Standard uses representative glyphs in
  the code charts, but font designers are free to create their own
  glyphs. Because fonts can easily be created using an arbitrary glyph
  to represent any Unicode code point, character confusability with
  arbitrary fonts can never be avoided. For example, one could design
  a font where the ‘a’ looks like a ‘b’ , ‘c’ like a ‘d’, and so on.
* Writing systems using contextual shaping (such as Arabic and many South Asian systems) introduce even more variation in text
  rendering. Characters do not really have an abstract shape in
  isolation and are only rendered as part of cluster of characters
  making words, expressions, and sentences. It is a fairly common
  occurrence to find the same visual text representation corresponding
  to very different logical words that can only be recognized by
  context, if at all.
* Font style variants such as italics may introduce a
  confusability which does not exist in another style. For example, in
  the Cyrillic script, the [U+0442](https://util.unicode.org/UnicodeJsps/character.jsp?a=0442) ( т )
  CYRILLIC SMALL LETTER TE looks like a small caps Latin ‘T’ in normal
  style, while it looks like a small Latin ‘m’ in italic style.

In-script confusability is extremely user-dependent. For example, in
the Latin script, characters with accents or appendices may look
similar to the unadorned characters for some users, especially if
they are not familiar with their meaning in a particular language.
However, most users will have at least a minimum understanding of the
range of characters in their own script, and there are separate
mechanisms available to deal with other scripts, as discussed in [[UTR36](#UTR36)].

As described elsewhere, there are cases where the confusable data may
be different than expected. Sometimes this is because two characters
or two strings may only be confusable in some fonts. In other cases,
it is because of transitivity. For example, the dotless and dotted I
are considered equivalent (ı ↔ i), because they look the same when
accents such as an *acute* are applied to each. However, for
practical implementation usage, transitivity is sufficiently
important that some oddities are accepted.

The data may be enhanced in future versions of this
specification. For information on handling changes in data over
time, see *2.10.1, Backward Compatibility* of [[UTR36](#UTR36)].

### 6.1 [Confusables Data Collection](#Data_Collection)

The confusability data was created by collecting a number of
prospective confusables, examining those confusables according to a
set of common fonts, and processing the result for transitive
closure.

The primary goal is to include characters that would be Identifier\_Status=Allowed
as in *Table 1, [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)*. Other characters, such as NFKC
variants, are not a primary focus for data collection. However, such
variants may certainly be included in the data, and may be submitted
using the online forms at [[Feedback](#Feedback)].

The prospective confusables were gathered from a number of
sources. Erik van der Poel contributed a list derived from running a
program over a large number of fonts to catch characters that shared
identical glyphs within a font, and Mark Davis did the same more
recently for fonts on Windows and the Macintosh. Volunteers from
Google, IBM, Microsoft and other companies gathered other lists of
characters. These included native speakers for languages with
different writing systems. The Unicode compatibility mappings were
also used as a source. The process of gathering visual confusables is
ongoing: the Unicode Consortium welcomes submission of additional
mappings. The complex scripts of South and Southeast Asia need
special attention. The focus is on characters that have Identifier\_Status=Allowed, because they are of most
concern.

The fonts used to assess the confusables included those used by
the major operating systems in user interfaces. In addition, the
representative glyphs used in the Unicode Standard were also
considered. Fonts used for the user interface in operating systems
are an important source, because they are the ones that will usually
be seen by users in circumstances where confusability is important,
such such as when using IRIS (Internationalized Resource Identifiers)
and their sub-elements (such as domain names). These fonts have a
number of other relevant characteristics:

* They rarely changed in updates to operating systems and
  applications; changes brought by system upgrades tend to be gradual
  to avoid usability disruption.
* Because user interface elements need to be legible at low
  screen resolution (implying a low number of pixels per EM), fonts
  used in these contexts tend to be designed in sans-serif style,
  which has the tendency to increase the possibility of confusables.
  There are, however, some languages such as Chinese where a serif
  style is in common use.
* Strict bounding box requirements create even more
  constraints for scripts which use relatively large ascenders and
  descenders. This also limits space allocated for accent or tone
  marks, and can also create more opportunities for confusability.

Pairs of prospective confusables were removed if they were always
visually distinct at common sizes, both within and across fonts. The
data was then closed under transitivity, so that if X≅Y and Y≅Z, then
X≅Z. In addition, the data was closed under substring operations, so
that if X≅Y then AXB≅AYB. It was then processed to produce the
in-script and cross-script data, so that a single data table can be
used to map an input string to a resulting *skeleton*.

A skeleton is intended *only* for internal use for testing
confusability of strings; the resulting text is not suitable for
display to users, because it will appear to be a hodgepodge of
different scripts. In particular, the result of mapping an identifier
will not necessary be an identifier. Thus the confusability mappings
can be used to test whether two identifiers are confusable (if their
skeletons are the same), but should definitely not be used as a
"normalization" of identifiers.

### 6.2 [Identifier Modification Data Collection](#IDMOD_Data_Collection)

The **idmod** data is gathered in the following way. The
basic assignments are derived based on UCD character properties,
information in [[UAX31](#UAX31)], and a curated list of
exceptions based on information from various sources, including the
core specification of the Unicode Standard, annotations in the code
charts, information regarding CLDR exemplar characters, and external
feedback.

The first condition that matches in the order of the items from top
to bottom in [Table 1.
Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type) is used, with a few exceptions:

1. When a character is in
   *Table 3a, [Optional Characters for Medial](https://www.unicode.org/reports/tr31/#Table_Optional_Medial)*
   or *Table 3b, [Optional Characters for Continue](https://www.unicode.org/reports/tr31/#Table_Optional_Continue)* in [[UAX31](#UAX31)], then it is given the Identifier\_Type=Inclusion,
   regardless of other properties.
2. When the Script\_Extensions property value for a character
   contains multiple Script property values, the Script used for the
   derivation is the first in the following list:
   1. *Table 5,
      [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*
   2. *Table 7,
      [Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)*
   3. *Table 4,
      [Excluded Scripts](https://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*

The script information in *[Table
4](https://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*, *[Table
5](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*, and *[Table
7](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* is in machine-readable form in CLDR, as scriptMetadata.txt.

## 7 [Data Files](#Data_Files)

The following files provide data used to implement the
recommendations in this document. The data may be refined in future
versions of this specification. For more information,
see *2.10.1, Backward Compatibility* of [[UTR36](#UTR36)].
For illustration, this UTS shows sample data values, but for the
actual data for the current version of Unicode always refer to the data files.

> *The Unicode Consortium welcomes feedback
> on additional confusables or identifier restrictions. There are
> online forms at [[Feedback](#Feedback)] where you can
> suggest additional characters or corrections.*

The files are in <https://www.unicode.org/Public/security/>.
The directories there contain data files associated with a given
version. The directory for *this* version is:

> <https://www.unicode.org/Public/security/16.0/>

The data files for the latest approved version are also in the
directory:

> [https://www.unicode.org/Public/security/latest](https://www.unicode.org/Public/security/latest%20)

The format for IdentifierStatus.txt follows the normal conventions for
UCD data files, and is described in the header of that file.
All characters not listed in the file default to Identifier\_Status=Restricted.
Thus the file only lists characters with Identifier\_Status=Allowed.
For example:

`002D..002E ; Allowed # 1.1 HYPHEN-MINUS..FULL STOP`

The format for IdentifierType.txt follows the normal conventions for UCD
data files, and is described in the header of that file. The value is a
set whose elements are delimited by spaces. This format is identical to
that used for ScriptExtensions.txt. This differs from prior versions
which only listed the strongest reason for exclusion. This new convention
allows the values to be used for more nuanced filtering. For example,
if an implementation wants to allow an Exclusion script, it could still
exclude Obsolete and Not\_XID characters in that script.
All characters not listed in the file default to Identifier\_Type=Not\_Character.
For example:

`2460..24EA ; Technical Not_XID Not_NFKC # 1.1 CIRCLED DIGIT ONE..CIRCLED DIGIT ZERO`

Both of these files have machine-readable `# @missing` lines
for the default property values, as in many UCD files.
For details about this syntax see
*Section 4.2.10, [@missing Conventions](https://www.unicode.org/reports/tr44/#Missing_Conventions)*
in [[UAX44](#UAX44)].

Table 2. [Data File List](#Data_File_List)

| Reference | File Name(s) | Contents |
| --- | --- | --- |
| [[idmod](#idmod)] | IdentifierStatus.txt IdentifierType.txt | **Identifier\_Type** and **Identifier\_Status:** Provides the list of additions and restrictions recommended for building a profile of identifiers for environments where security is at issue. |
| [[confusables](#confusables)] | confusables.txt | **Visually Confusable Characters:** Provides a mapping for visual confusables for use in detecting possible security problems. The usage of the file is described in *Section 4, [Confusable Detection](#Confusable_Detection).* |
| [[confusablesSummary](#confusablesSummary)] | confusablesSummary.txt | **A summary view of the confusables:** Groups each set of confusables together, listing them first on a line starting with #, then individually with names and code points. See *Section 4, [Confusable Detection](#Confusable_Detection)* |
| [[intentional](#intentional)] | intentional.txt | **Intentional Confusable Mappings:** A selection of characters whose glyphs in any particular typeface would probably be designed to be identical in shape when using a harmonized typeface design. |

## [Migration](#Migration)

Beginning with version 6.3.0, the version numbering of this
document has been changed to indicate the version of the UCD that the
data is based on. For versions up to and including 6.3.0, the
following table shows the correspondence between the versions of this
document and UCD versions that they were based on.

Table 3. [Version Correspondence](#Version_Correspondance)

| Version | Release Date | Data File Directory | UCD Version | UCD Date |
| --- | --- | --- | --- | --- |
| Version 1 | 2006-08-15 | /Public/security/revision-02/ | 5.1.0 | 2008-04 |
| *draft only* | 2010-04-12 | /Public/security/revision-03/ | *n/a* | *n/a* |
| Version 2 | 2010-08-05 | /Public/security/revision-04/ | 6.0.0 | 2010-10 |
| Version 3 | 2012-07-23 | /Public/security/revision-05/ | 6.1.0 | 2012-01 |
| 6.3.0 | 2013-11-11 | /Public/security/6.3.0/ | 6.3.0 | 2013-09 |

 If an update version of this standard is required between
the associated UCD versions, the version numbering will include an
update number in the 3rd field. For example, if a version of this
document and its associated data is needed between UCD 6.3.0 and UCD
7.0.0, then a version 6.3.**1** could be used.

### [Migrating Persistent Data](#Migrating_Persistent_Data)

Implementations must migrate their persistent data stores (such
as database indexes) whenever those implementations update to use the
data files from a new version of this specification.

Stability is never guaranteed between versions, although it is
maintained where feasible. In particular, an updated version of
confusable mapping data may use a mapping for a particular character
that is different from the mapping used for that character in an
earlier version. Thus there may be cases where X → Y in Version N,
and X → Z in Version N+1, where Z may or may not have mapped to Y in
Version N. Even in cases where the logical data has not changed
between versions, the order of lines in the data files may have been
changed.

The Identifier\_Status does not have stability guarantees (such as “Once a character is Allowed, it will not become Restricted in future versions”), because the data is changing over time as we find out more about character usage. Certain of the Identifier\_Type values, such as Not\_XID, are backward compatible but most may change as new data becomes available. The identifier data may also not appear to be completely consistent when just viewed from the perspective of script and general category. For example, it may well be that one character out of a set of nonspacing marks in a script is Restricted, while others are not. But that can be just a reflection of the fact that that character is obsolete and the others are not.

For identifier lookup, the data is aimed more at flagging possibly questionable characters, thus serving as one factor (among perhaps many, like using the "Safe Browsing" service) in determining whether the user should be notified in some way. For registration, flagged characters can result in a "soft no", that is, require the user to appeal a denial with more information.

For dealing with characters whose status changes to Restricted, implementations can use a grandfathering mechanism to maintain backwards compatibility.

Implementations should therefore have a strategy for migrating
their persistent data stores (such as database indexes) that use any
of the confusable mapping data or other data files.

### [Version 13.0 Migration](#Version_13_Migration)

As of Unicode 13.0, the Identifier\_Status and Identifier\_Type are consistently written with underbars. This may cause parsers to malfunction, those that do not follow Unicode conventions for matching of property names.

### [Version 10.0 Migration](#Version_10_Migration)

As of Unicode 10.0, Identifier\_Type=Aspirational is now empty; for more information, see [[UAX31](#UAX31)].

### [Version 9.0 Migration](#Version_9_Migration)

There is an important data format change between versions 8.0 and 9.0. In particular, the xidmodifications.txt file from Version 8.0 has been split into two files for Version 9.0: IdentifierStatus.txt and IdentifierType.txt.

| Version 9.0 | Version 8.0 |
| --- | --- |
| Field 1 of IdentifierStatus.txt | Field 1 of xidmodifications.txt |
| Field 1 of IdentifierType.txt | Field 2 of xidmodifications.txt |

Multiple values are listed in field 1 of IdentifierType.txt. To convert to the old format of xidmodifications.txt, use the *last* value of that field. For example, the following values would correspond:

| File | Field | Content |
| --- | --- | --- |
| IdentifierType.txt | 1 | `180A ; Limited_Use Exclusion Not_XID` |
| xidmodifications.txt | 2 | `180A ; Restricted ; Not_XID` |

### [Version 8.0 Migration](#Version_8_Migration)

In Version 8.0, the following changes were made to the
Identifier\_Status and Identifier\_Type:

* Changed to the standard UCD formatting. For example, *limited-use*
  → *Limited\_Use*.
  + Usually this was simply changing the case and hyphen, but
    *not-chars* changed to *Not\_Character*.
* Aligned the Identifier\_Type better with UAX 31 and Unicode
  properties
  + historic
    - → Exclusion, where from *Table 4,
      [Candidate Characters for Exclusion from Identifiers](https://www.unicode.org/reports/tr31/tr31-23.html#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*,
    - → Obsolete, otherwise
  + limited-use
    - → Limited\_Use, where from *Table 7,
      [Limited Use Scripts](https://www.unicode.org/reports/tr31/tr31-23.html#Table_Limited_Use_Scripts)*,
    - → Aspirational, where from *Table 6,
      [Aspirational Use Scripts](https://www.unicode.org/reports/tr31/tr31-23.html#Aspirational_Use_Scripts)* (later incorporated into Limited\_Use
      in Version 10.0)
    - → Uncommon-Use, otherwise
  + obsolete
    - → Deprecated, where matching the Unicode property

### [Version 7.0 Migration](#Version_7_Migration)

Due to production problems, versions of the confusable mapping
tables before 7.0 did not maintain idempotency in all cases, so
updating to version 8.0 is strongly advised.

Anyone using the skeleton mappings needs to rebuild any
persistent uses of skeletons, such as in database indexes.

The SL, SA, and ML mappings in 7.0 were significantly changed
to address the idempotency problem. However, the tables SL, SA, and
ML were still problematic, and discouraged from use in 7.0. They were
thus removed from version 8.0.

All of the data necessary for an implementation to recreate the
removed tables is available in the remaining data (MA) plus the
Unicode Character Database properties (script, casing, etc.). Such a
recreation would examine each of the equivalence classes from the MA
data, and filter out instances that did not fit the constraints (of
script or casing). For the target character, it would choose the most
neutral character, typically a symbol. However, the reasons for
deprecating them still stand, so it is not recommended that
implementations recreate them.

Note also that as the Script\_Extensions data is made more complete,
it may cause characters in the whole-script confusables data file to
no longer match. For more information, see *Section 4, [Confusable Detection](#Confusable_Detection)*.

## [Acknowledgments](#Acknowledgments)

Mark Davis and Michel Suignard authored the bulk of the
text, under direction from the Unicode Technical Committee. Steven
Loomis and other people on the ICU team were very helpful in
developing the original proposal for this technical report. Shane Carr analyzed the algorithms and supplied the source text for the rewrite of Sections 4 and 5 in version 10.

The attendees of the Source Code Working Group meetings assisted with the substantial changes made in Versions 15.0 and 15.1:
Peter Constable,
Elnar Dakeshov,
Mark Davis,
Barry Dorrans,
Steve Dower,
Michael Fanning,
Asmus Freytag,
Dante Gagne,
Rich Gillam,
Manish Goregaokar,
Tom Honermann,
Jan Lahoda,
Nathan Lawrence,
Robin Leroy,
Chris Ries,
Markus Scherer,
Richard Smith.

Thanks
also to the following people for their feedback or contributions to
this document or earlier versions of it, or to the source data for
confusables or idmod: Julie Allen, Andrew Arnold, Vernon Cole, David Corbett (specal thanks for the many contributions),
Douglas Davidson, Rob Dawson, Alex Dejarnatt, Chris Fynn, Martin Dürst, Asmus Freytag, Deborah
Goldsmith, Manish Goregaokar, Paul Hoffman, Ned Holbrook, Denis Jacquerye, Cibu Johny, Patrick L.
Jones, Peter Karlsson, Robin Leroy, Mike Kaplinskiy, Gervase Markham, Eric Muller,
David Patterson, Erik van der Poel, Roozbeh Pournader, Michael van Riper, Marcos Sanz,
Alexander Savenkov, Markus Scherer, Dominikus Scherkl, Manuel Strehl, Chris Weber, Ken Whistler,
and Waïl Yahyaoui. Thanks to Peter Peng for his assistance with font
confusables.

## [References](#References)

| [[CLDR](#CLDR)] | Unicode Locales Project (Unicode Common Locale Data Repository) <http://cldr.unicode.org/> |
| --- | --- |
| [[DCore](#DCore)] | Derived Core Properties <https://www.unicode.org/Public/UCD/latest/ucd/DerivedCoreProperties.txt> |
| [[DemoConf](#DemoConf)] | <https://util.unicode.org/UnicodeJsps/confusables.jsp> |
| [[DemoIDN](#DemoIDN)] | <https://util.unicode.org/UnicodeJsps/idna.jsp> |
| [[DemoIDNChars](#DemoIDNChars)] | [https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=\p{age%3D3.2}-\p{cn}-\p{cs}-\p{co}&abb=on&uts46+idna+idna2008](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=\p{age%3D3.2}-\p{cn}-\p{cs}-\p{co}&abb=on&g=uts46+idna+idna2008) |
| [[EAI](#EAI)] | <https://www.rfc-editor.org/info/rfc6531> |
| [[FAQSec](#FAQSec)] | Unicode FAQ on Security Issues <https://www.unicode.org/faq/security.html> |
| [[Feedback](#Feedback)] | *To suggest additions or changes to confusables or identifier restriction data, please see:* <https://www.unicode.org/reports/tr39/suggestions.html>   *For issues in the text, please see:* Reporting Errors and Requesting Information Online<https://www.unicode.org/reporting.html> |
| [[ICANN](#ICANN)] | ICANN Documents: Internationalized Domain Names <https://www.icann.org/en/topics/idn/> The IDN Variant Issues Project <https://www.icann.org/en/topics/new-gtlds/idn-vip-integrated-issues-23dec11-en.pdf> Maximal Starting Repertoire Version 2 (MSR-2) <https://www.icann.org/news/announcement-2-2015-04-27-en> |
| [[ICU](#ICU)] | International Components for Unicode <http://site.icu-project.org/> |
| [[IDNA2003](#IDNA2003)] | The IDNA2003 specification is defined by a cluster of IETF RFCs:  * IDNA [[RFC3490](#RFC3490)] * Nameprep [[RFC3491](#RFC3491)] * Punycode [[RFC3492](#RFC3492)] * Stringprep [[RFC3454](#RFC3454)]. |
| [[IDNA2008](#IDNA2008)] | The IDNA2008 specification is defined by a cluster of IETF RFCs:  * Internationalized Domain Names for Applications (IDNA):   Definitions and Document Framework <https://www.rfc-editor.org/info/rfc5890> * Internationalized Domain Names in Applications (IDNA)   Protocol <https://www.rfc-editor.org/info/rfc5891> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) <https://www.rfc-editor.org/info/rfc5892> * Right-to-Left Scripts for Internationalized Domain Names   for Applications (IDNA) <https://www.rfc-editor.org/info/rfc5893>  There are also informative documents:  * Internationalized Domain Names for Applications (IDNA):   Background, Explanation, and Rationale <https://www.rfc-editor.org/info/rfc5894> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) - Unicode 6.0 <https://www.rfc-editor.org/info/rfc6452> |
| [[IDN-FAQ](#IDN_FAQ)] | <https://www.unicode.org/faq/idn.html> |
| [[Reports](#Reports)] | Unicode Technical Reports <https://www.unicode.org/reports/>*For information on the status and development process for technical reports, and for a list of technical reports.* |
| [[RFC3454](#RFC3454)] | P. Hoffman, M. Blanchet. "Preparation of Internationalized Strings ("stringprep")", RFC 3454, December 2002. <https://www.rfc-editor.org/info/rfc3454> |
| [[RFC3490](#RFC3490)] | Faltstrom, P., Hoffman, P. and A. Costello, "Internationalizing Domain Names in Applications (IDNA)", RFC 3490, March 2003. <https://www.rfc-editor.org/info/rfc3490> |
| [[RFC3491](#RFC3491)] | Hoffman, P. and M. Blanchet, "Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)", RFC 3491, March 2003. <https://www.rfc-editor.org/info/rfc3491> |
| [[RFC3492](#RFC3492)] | Costello, A., "Punycode: A Bootstring encoding of Unicode for Internationalized Domain Names in Applications (IDNA)", RFC 3492, March 2003. <https://www.rfc-editor.org/info/rfc3492> |
| [[RZLGR5](#RZLGR5)] | Integration Panel, “Integration Panel: Root Zone Label Generation Rules — LGR-5”, 22 May 2022 <https://www.icann.org/sites/default/files/lgr/rz-lgr-5-overview-26may22-en.pdf> |
| [[Security-FAQ](#Security-FAQ)] | <https://www.unicode.org/faq/security.html> |
| [[UCD](#UCD)] | Unicode Character Database. <https://www.unicode.org/ucd/> *For an overview of the Unicode Character Database and a list of its associated files.* |
| [[UCDFormat](#UCDFormat)] | UCD File Format <https://www.unicode.org/reports/tr44/#Format_Conventions> |
| [[UAX9](#UAX9)] | UAX #9: *Unicode Bidirectional Algorithm* <https://www.unicode.org/reports/tr9/> |
| [[UAX15](#UAX15)] | UAX #15: *Unicode Normalization Forms* <https://www.unicode.org/reports/tr15/> |
| [[UAX24](#UAX24)] | UAX #24: Unicode Script Property <https://www.unicode.org/reports/tr24/> |
| [[UAX29](#UAX29)] | UAX #29: *Unicode Text Segmentation* <https://www.unicode.org/reports/tr29/> |
| [[UAX31](#UAX31)] | UAX #31: *Unicode Identifier and Pattern Syntax* <https://www.unicode.org/reports/tr31/> |
| [[UAX44](#UAX44)] | UAX #44: *Unicode Character Database* <https://www.unicode.org/reports/tr44/> |
| [[Unicode](#Unicode)] | The Unicode Standard*For the latest version, see:* <https://www.unicode.org/versions/latest/> |
| [[UTR23](#UTR23)] | UTR #23: *The Unicode Character Property Model* <https://www.unicode.org/reports/tr23/> |
| [[UTR36](#UTR36)] | UTR #36: *Unicode Security Considerations* <https://www.unicode.org/reports/tr36/> |
| [[UTS18](#UTS18)] | UTS #18: *Unicode Regular Expressions* <https://www.unicode.org/reports/tr18/> |
| [[UTS39](#UTS39)] | UTS #39: Unicode Security Mechanisms <https://www.unicode.org/reports/tr39/> |
| [[UTS46](#UTS46)] | Unicode IDNA Compatibility Processing <https://www.unicode.org/reports/tr46/> |
| [[UTS55](#UTS55)] | Unicode Source Code Handling <https://www.unicode.org/reports/tr55/> |
| [[Versions](#Versions)] | Versions of the Unicode Standard <https://www.unicode.org/standard/versions/> *For information on version numbering, and citing and referencing the Unicode Standard, the Unicode Character Database, and Unicode Technical Reports.* |

## [Modifications](#Modifications)

The following summarizes modifications from the previous
published version of this document.

**Revision 30**

* **Reissued** for Unicode 16.0
* **Section 3, Table 1. [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)**:
  Noted that Uncommon\_Use may be combined with Exclusion or Limited\_Use.
* **Section 4 [Confusable Detection](#Confusable_Detection)**: Updated the definitions of *skeleton* and *confusable* to be aliases for *bidiSkeleton(LTR, -)* and *LTR-confusable*.
* **Section 7 [Data Files](#Data_Files)**: Fixed various typos.

Modifications for previous versions are listed in those respective versions.

---

© 2006–2024 Unicode, Inc. This publication is protected by copyright, and permission must be obtained from Unicode, Inc. prior to any reproduction, modification, or other use not permitted by the [Terms of Use](https://www.unicode.org/copyright.html). Specifically, you may make copies of this publication and may annotate and translate it solely for personal or internal business purposes and not for public distribution, provided that any such permitted copies and modifications fully reproduce all copyright and other legal notices contained in the original. You may not make copies of or modifications to this publication for public distribution, or incorporate it in whole or in part into any product or publication without the express written permission of Unicode.

Use of all Unicode Products, including this publication, is governed by the Unicode [Terms of Use](https://www.unicode.org/copyright.html). The authors, contributors, and publishers have taken care in the preparation of this publication, but make no express or implied representation or warranty of any kind and assume no responsibility or liability for errors or omissions or for consequential or incidental damages that may arise therefrom. This publication is provided “AS-IS” without charge as a convenience to users.

Unicode and the Unicode Logo are registered trademarks of Unicode, Inc., in the United States and other countries.



=== Content from security.gentoo.org_8d9f0d19_20250111_094134.html ===

[![Gentoo](https://assets.gentoo.org/tyrian/v2/site-logo.png)](/ "Back to the homepage")
Security

[**Get Gentoo!**](https://get.gentoo.org/)
gentoo.org sites
[gentoo.org](https://www.gentoo.org/ "Main Gentoo website")
[Wiki](https://wiki.gentoo.org/ "Find and contribute documentation")
[Bugs](https://bugs.gentoo.org/ "Report issues and find common issues")
[Forums](https://forums.gentoo.org/ "Discuss with the community")
[Packages](https://packages.gentoo.org/ "Find software for your Gentoo")

[Planet](https://planet.gentoo.org/ "Find out what's going on in the developer community")
[Archives](https://archives.gentoo.org/ "Read up on past discussions")
[Sources](https://sources.gentoo.org/ "Browse our source code")

[Infra Status](https://infra-status.gentoo.org/ "Get updates on the services provided by Gentoo")

* [Home](/)
* [Stay informed](/subscribe)
* [Advisories](/glsa)

# Rust: Multiple Vulnerabilities — GLSA **202210-09**

Multiple vulnerabilities have been discovered in Rust, the worst of which could result in denial of service.

### Affected packages

| Package | **dev-lang/rust** on all architectures |
| --- | --- |
| Affected versions | < **1.63.0-r1** |
| Unaffected versions | >= **1.63.0-r1** |

| Package | **dev-lang/rust-bin** on all architectures |
| --- | --- |
| Affected versions | < **1.64.0** |
| Unaffected versions | >= **1.64.0** |

### Background

A systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety.

### Description

Multiple vulnerabilities have been discovered in Rust. Please review the CVE identifiers referenced below for details.

### Impact

Please review the referenced CVE identifiers for details.

### Workaround

There is no known workaround at this time.

### Resolution

All Rust users should upgrade to the latest version:

```
 # emerge --sync
 # emerge --ask --oneshot --verbose ">=dev-lang/rust-1.63.0-r1"

```

All Rust binary users should upgrade to the latest version:

```
 # emerge --sync
 # emerge --ask --oneshot --verbose ">=dev-lang/rust-bin-1.64.0"

```

In addition, users using Portage 3.0.38 or later should ensure that packages with Rust binaries have no vulnerable code statically linked into their binaries by rebuilding the @rust-rebuild set:

```
 # emerge --ask --oneshot --verbose @rust-rebuild

```
### References

* [CVE-2021-28875](https://nvd.nist.gov/vuln/detail/CVE-2021-28875)
* [CVE-2021-28876](https://nvd.nist.gov/vuln/detail/CVE-2021-28876)
* [CVE-2021-28877](https://nvd.nist.gov/vuln/detail/CVE-2021-28877)
* [CVE-2021-28878](https://nvd.nist.gov/vuln/detail/CVE-2021-28878)
* [CVE-2021-28879](https://nvd.nist.gov/vuln/detail/CVE-2021-28879)
* [CVE-2021-29922](https://nvd.nist.gov/vuln/detail/CVE-2021-29922)
* [CVE-2021-31162](https://nvd.nist.gov/vuln/detail/CVE-2021-31162)
* [CVE-2021-36317](https://nvd.nist.gov/vuln/detail/CVE-2021-36317)
* [CVE-2021-36318](https://nvd.nist.gov/vuln/detail/CVE-2021-36318)
* [CVE-2021-42574](https://nvd.nist.gov/vuln/detail/CVE-2021-42574)
* [CVE-2021-42694](https://nvd.nist.gov/vuln/detail/CVE-2021-42694)
* [CVE-2022-21658](https://nvd.nist.gov/vuln/detail/CVE-2022-21658)
* [CVE-2022-36113](https://nvd.nist.gov/vuln/detail/CVE-2022-36113)
* [CVE-2022-36114](https://nvd.nist.gov/vuln/detail/CVE-2022-36114)

**Release date**

October 16, 2022

**Latest revision**

October 16, 2022: 1

**Severity**

normal

**Exploitable**

remote

**Bugzilla entries**

* [870166](https://bugs.gentoo.org/show_bug.cgi?id=870166)
* [831638](https://bugs.gentoo.org/show_bug.cgi?id=831638)
* [821157](https://bugs.gentoo.org/show_bug.cgi?id=821157)
* [807052](https://bugs.gentoo.org/show_bug.cgi?id=807052)
* [782367](https://bugs.gentoo.org/show_bug.cgi?id=782367)

### Questions or comments?

Please feel free to contact us.

**© 2001–2020 Gentoo Foundation, Inc.**



=== Content from trojansource.codes_028e4e24_20250111_094134.html ===
You need to enable JavaScript to run this app.[Trojan Source](/index "Trojan Source")

* [GitHub](https://github.com/nickboucher/trojan-source "Star on GitHub")
* [Read Paper](/trojan-source.pdf)
# Trojan Source

![...](/static/media/fog-low.965eab52.png)![...](/static/media/fog-low.965eab52.png)
## Invisible Source Code Vulnerabilities

## Some Vulnerabilities are Invisible

#### Rather than inserting logical bugs, adversaries can attack the encoding of source code files to inject vulnerabilities.

### These adversarial encodings produce no visual artifacts.

`#include <stdio.h>
#include <stdbool.h>

int main() {
bool isAdmin = false;
/* begin admins only */ if (isAdmin) {
printf("You are an admin.\n");
/* end admins only */ }
return 0;
}`

---

# The trick

#### The trick is to use Unicode control characters to reorder tokens in source code at the encoding level.

#### These visually reordered tokens can be used to display logic that, while semantically correct, diverges from the logic presented by the logical ordering of source code tokens.

#### Compilers and interpreters adhere to the logical ordering of source code, not the visual order.

# The attack

#### The attack is to use control characters embedded in comments and strings to reorder source code characters in a way that changes its logic.

#### The previous example, for instance, works by making a comment appear as if it were code:

## /\*Â if (isAdmin) {Â begin admins only \*/Â

#### Adversaries can leverage this deception to commit vulnerabilities into code that will not be seen by human reviewers.

#### This attack pattern is tracked as CVE-2021-42574.

# The supply chain

#### This attack is particularly powerful within the context of software supply chains.

#### If an adversary successfully commits targeted vulnerabilities into open source code by deceiving human reviewers, downstream software will likely inherit the vulnerability.

# The technique

#### There are multiple techniques that can be used to exploit the visual reordering of source code tokens:

#### **Early Returns** cause a function to short circuit by executing a `return` statement that visually appears to be within a comment.

#### **Commenting-Out** causes a comment to visually appear as code, which in turn is not executed.

#### **Stretched Strings** cause portions of string literals to visually appear as code, which has the same effect as commenting-out and causes string comparisons to fail.

# The variant

#### A similar attack exists which uses homoglyphs, or characters that appear near identical.

`#include <iostream>

void sayHello() {
std::cout << "Hello, World!\n";
}` `void sayÐello() {
std::cout << "Bye, World!\n";
}`
#### The above example defines two distinct functions with near indistinguishable visual differences highlighted for reference.

#### An attacker can define such homoglyph functions in an upstream package imported into the global namespace of the target, which they then call from the victim code.

#### This attack variant is tracked as CVE-2021-42694.

# The defense

#### Compilers, interpreters, and build pipelines supporting Unicode should throw errors or warnings for unterminated bidirectional control characters in comments or string literals, and for identifiers with mixed-script confusable characters.

#### Language specifications should formally disallow unterminated bidirectional control characters in comments and string literals.

#### Code editors and repository frontends should make bidirectional control characters and mixed-script confusable characters perceptible with visual symbols or warnings.

# The paper

#### Complete details can be found in the related [paper](/trojan-source.pdf).

#### If you use the paper or anything on this site in your own work, please cite the following:

`@inproceedings{boucher_trojansource_2023,
Â Â Â Â title = {Trojan {Source}: {Invisible} {Vulnerabilities}},
Â Â Â Â author = {Nicholas Boucher and Ross Anderson},
Â Â Â Â booktitle = {32nd USENIX Security Symposium (USENIX Security 23)},
Â Â Â Â year = {2023},
Â Â Â Â address = {Anaheim, CA},
Â Â Â Â publisher = {USENIX Association},
Â Â Â Â month = aug,
Â Â Â Â url = {https://arxiv.org/abs/2111.00169}
}`Produced by researchers at the University of Cambridge.Â© 2023 [Nicholas Boucher](https://www.cl.cam.ac.uk/~ndb40) with thanks to [Paper Kit React](https://github.com/creativetimofficial/paper-kit-react) and [SRCF](https://www.srcf.net).
![](https://sa.trojansource.codes/noscript.gif?collect-dnt=true)

=== Content from www.scyon.nl_e692e13a_20250111_094135.html ===


top of page

* [Home](https://www.scyon.nl)
* [Contact](https://www.scyon.nl)
* [Werken bij](https://www.scyon.nl/werken-bij)
* [Blog](https://www.scyon.nl/blog)
* More

Use tab to navigate through the menu items.

* [![LinkedIn]()](https://www.linkedin.com/company/scyon)
* [![Twitter]()](https://twitter.com/ScyonSecurity)
![Foto van schrijver]()Coen Goedegebure11 nov 20214 minuten om te lezen
# Trojans in your source code

Bijgewerkt op: 12 nov 2021

As part of my work I frequently perform source code reviews for security issues. Looking for vulnerabilities in the logic of the source code is not easy, but when the encoding of that code is attacked, things get unreal pretty fast. Especially when you realise how often code is copy-pasted from sites like [StackOverflow](https://stackoverflow.com/).

This article describes the dangers of hidden Unicode control characters and how they can make your source code appear differently than it is executed.

## **The vulnerability**

Consider the following piece of Javascript:

![](https://static.wixstatic.com/media/2b3606_7578a4064e584240839195db7c3d8667~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_7578a4064e584240839195db7c3d8667~mv2.png)

This code contains a simple "demo"-function that starts by setting the "isAdmin" variable to "false" in line 2. Line 4 starts with a comment and checks whether "isAdmin" is set to "true" in which case the message *"You are an admin"* would be printed in line 5. Logically, this message will never be printed since "isAdmin" is explicitly set to "false".
However, when executing this script, the following output is generated:

```
You are an admin
```

## **How does this work?**

Using Unicode control characters we can reorder the tokens of the source code. By doing this, the way the source code is rendered to screen no longer matches the actual logic of the source code itself.
In other words, by carefully placing these control characters, we can visually reorder the source code so that it is displayed differently than how it is processed by the compiler or interpreter.

## **Modifying the code**

The table below lists the abbreviations of the special Unicode control characters that are used to create the examples in this chapter.

| Abbreviation | Unicode | Name | Description |
| --- | --- | --- | --- |
| RLO | U+202E | Right-to-Left Override | Treat following text as right-to-left |
| LRI | U+2066 | Left-to-Right Isolate | Treat following text as left-to-right without affecting adjacent text |
| PDI | U+2069 | Pop Directional Isolate | Terminate the nearest LRI or RLI |

The example mentioned at the beginning of the article, works by making a comment appear as if it were code. Let's again take a look at how the IDE displays the Javascript code:

![](https://static.wixstatic.com/media/2b3606_7578a4064e584240839195db7c3d8667~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_7578a4064e584240839195db7c3d8667~mv2.png)

Now compare it to the way the code is handled by the Javascript interpreter. In the figure below the Unicode control characters are made visible:

![](https://static.wixstatic.com/media/2b3606_80bf1f3c6b904ce1a753f08035f20ddd~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_80bf1f3c6b904ce1a753f08035f20ddd~mv2.png)

As you can see, line 4 is processed as a normal comment section with some special characters in it. However, when the line is displayed on screen in the IDE, the special characters inside the comment manipulate the text so that it is rendered in a different order. This vulnerability is tracked as [CVE-2021-42574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-42574). The sample code can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/comment_out.html).

## **Impact**

Adversaries can use this vulnerability, the difference between handling and rendering of these Unicode control characters, to hide malicious behaviour from human reviewers.
The impact of this kind of an attack lies within the context of software supply chains; open source projects used by other applications. When a vulnerability like this slips through the code review and ends up unnoticed in an open source library, it is likely to be inherited downstream by the software using that library.

## **Exploits**

Visually reordering the source code can be done in different ways:

### **Commenting-Out**

This is the example explained above. Comments visually appear as executable code, which are not executed by compiler or interpreter.

### **Commenting-In**

In this case, executable code visually appears to be a comment, but is actually executed. For example, in the python code below, the code "amount -= 70" in line 3 appears to be part of a comment section:

![](https://static.wixstatic.com/media/2b3606_5ad22d74f48c4614841b2378eed381f0~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_5ad22d74f48c4614841b2378eed381f0~mv2.png)

However, after running the script, we see it is actually executed:

```
Amount: 30
done
```

Below is the actual code, with Unicode control characters made visible, as it would be processed by the python interpreter:

![](https://static.wixstatic.com/media/2b3606_b412703bbb7d4b33b15c89f072d58ede~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_b412703bbb7d4b33b15c89f072d58ede~mv2.png)

The sample code can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/comment_in.py).

### **Early returns**

This technique is a variation on the commenting-in technique. It executes a return statement that appears to be part of a comment, to exit a function early. In the python example below, the "return" command in line 3 appears to be included in the comment, but is actually executed.

![](https://static.wixstatic.com/media/2b3606_dc7d04b303464f72bb5cc610d2daa9bb~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_dc7d04b303464f72bb5cc610d2daa9bb~mv2.png)

Output:

```
first comment
done
```

The figure below shows the code as it is processed by the python interpreter:

![](https://static.wixstatic.com/media/2b3606_681ba800b0ee4c1da0757b444ba94ed8~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_681ba800b0ee4c1da0757b444ba94ed8~mv2.png)

The early returns example can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/early_returns.py).

### **Stretched strings**

Another way to exploit this vulnerability, is to have pieces of string literals render as code. This could break equality checks like the one in the bash script below:

![](https://static.wixstatic.com/media/2b3606_a6931a8af4704d8faa38971727f5825f~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_a6931a8af4704d8faa38971727f5825f~mv2.png)

Line 2 assigns the value "user" to the ACCESS\_LEVEL variable. If the ACCESS\_LEVEL is **not** equal to "user" (line 4), the message *"You are an admin"* is displayed, otherwise the output is *"You are a user"*. Since the ACCESS\_LEVEL has been explicitly set to "user", we would expect the output is the latter. The output however is the following:

```
You are an admin
```

The figure below shows the source code as it is processed by the bash interpreter:

![](https://static.wixstatic.com/media/2b3606_0ebde09aac9448aa9fb774ebfdf1b835~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_0ebde09aac9448aa9fb774ebfdf1b835~mv2.png)

Notice the string literal in line 4 is not "user", but rather contains other characters as well. This way, given the explicit assignment in line 2, the comparison in line 4 always yields true (i.e. ACCESS\_LEVEL is **never** equal to "user") and the message *"You are an admin"* is output.

The sample code for stretched strings can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/stretched_strings.sh).

### **Homoglyphs**

A [homoglyph](https://en.wikipedia.org/wiki/Homoglyph) attack exploits the fact that two characters look alike. For example, it is hard to see the difference between the Cyrillic letter "a" (U+0430) and the letter "a" from the latin alphabet. This is a similar to the [IDN homograph attack](https://en.wikipedia.org/wiki/IDN_homograph_attack) in which domain names are spoofed using the same principle.

In the following Javascript snippet an extra, evil function 'demo' was created in which the letter "e" is replaced by the Cyrillic letter "e" (U+0435, marked in red).

![](https://static.wixstatic.com/media/2b3606_56b48c54bc3d4bca9e8f31df68f92b03~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_56b48c54bc3d4bca9e8f31df68f92b03~mv2.png)

It would be very difficult for a reviewer to visually make a distinction between the function call to the good and the evil demo function in line 8. This vulnerability is tracked as [CVE-2021-42694](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-42694).

## **Mitigation**

The issues mentioned in this article can be mitigated by limiting the way the bidirectional Unicode control characters are processed. Either by making these clearly visible, or producing errors or warnings when these characters are encountered:

##### **GUI**

IDE's and other code editors should provide visual feedback for these characters. Either by making them clearly visible, or notifying the user with a warning. The figure below depicts how IntelliJ handles the visual representation of Unicode control characters for example:

![](https://static.wixstatic.com/media/2b3606_b97c2fb4c938403baa4bcd49ed3a7efa~mv2.png/v1/fill/w_49,h_17,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_b97c2fb4c938403baa4bcd49ed3a7efa~mv2.png)

The example below shows how GitHub handles the issue in [comment\_in.py](https://github.com/CoenGoedegebure/trojansource/blob/master/comment_in.py):

![](https://static.wixstatic.com/media/2b3606_081e45ab1689440fb869f74033b38171~mv2.png/v1/fill/w_49,h_16,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_081e45ab1689440fb869f74033b38171~mv2.png)
##### **Automated systems and software**

Systems and software that process source code, like compilers, interpreters, build pipelines, etc. should throw exceptions or generate warnings whenever special characters are encountered.

##### **Language specifications**

Unterminated bidirectional control characters in comments and string literals should be disallowed by means of language specifications.

Reference:
Paper: *"Trojan Source: Invisible Vulnerabilities"* by Nicholas Boucher and Ross Anderson, 2021 [[link](https://trojansource.codes/trojan-source.pdf) (pdf)]

* [Secure Coding](https://www.scyon.nl/blog/categories/securecoding)
* •
* [Cyber Security](https://www.scyon.nl/blog/categories/cyber-security)
0 opmerkingen11 Likes. Post is niet als leuk gemarkeerd11
## Recente blogposts

[Alles weergeven](https://www.scyon.nl/blog)[![]()](https://www.scyon.nl/post/kopie-van-the-best-resources-to-get-your-cissp)

[The best resources to get your CISSP](https://www.scyon.nl/post/kopie-van-the-best-resources-to-get-your-cissp)

0 opmerkingen0Post is niet als leuk gemarkeerd[![]()](https://www.scyon.nl/post/surviving-a-cyber-security-job-interview-cryptography-1)

[Surviving a cyber security job interview (Cryptography)](https://www.scyon.nl/post/surviving-a-cyber-security-job-interview-cryptography-1)

0 opmerkingen01 like. Post is niet als leuk gemarkeerd1[![]()](https://www.scyon.nl/post/5-ways-to-improve-your-cyber-security-now-software-developer-edition-1)

[5 ways to improve your cyber security now - Software Developer edition](https://www.scyon.nl/post/5-ways-to-improve-your-cyber-security-now-software-developer-edition-1)

0 opmerkingen05 Likes. Post is niet als leuk gemarkeerd5xml version="1.0" encoding="UTF-8"?

[privacy statement](https://www.scyon.nl/privacy)

info@scyon.nl

+31 (0) 30 22 715 88

Europalaan 93, Utrecht

* [![LinkedIn]()](https://www.linkedin.com/company/scyon)
* [![Twitter]()](https://twitter.com/ScyonSecurity)

©2025 Scyon B.V.

bottom of page


