

| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Steven Rostedt (VMware) <rostedt@goodmis.org> | 2021-04-30 12:17:58 -0400 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2021-05-12 08:40:04 +0200 |
| commit | [2a1bd74b8186d7938bf004f5603f25b84785f63e](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)) | |
| tree | [2cf70b898b78773d23f0c2f46be74f6a5a16478b](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e) | |
| parent | [7bc6bc25a1a80554e9dab1578ef0864a5bcfe552](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=7bc6bc25a1a80554e9dab1578ef0864a5bcfe552) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e&id2=7bc6bc25a1a80554e9dab1578ef0864a5bcfe552)) | |
| download | [linux-2a1bd74b8186d7938bf004f5603f25b84785f63e.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-2a1bd74b8186d7938bf004f5603f25b84785f63e.tar.gz) | |

tracing: Restructure trace\_clock\_global() to never blockcommit aafe104aa9096827a429bc1358f8260ee565b7cc upstream.
It was reported that a fix to the ring buffer recursion detection would
cause a hung machine when performing suspend / resume testing. The
following backtrace was extracted from debugging that case:
Call Trace:
trace\_clock\_global+0x91/0xa0
\_\_rb\_reserve\_next+0x237/0x460
ring\_buffer\_lock\_reserve+0x12a/0x3f0
trace\_buffer\_lock\_reserve+0x10/0x50
\_\_trace\_graph\_return+0x1f/0x80
trace\_graph\_return+0xb7/0xf0
? trace\_clock\_global+0x91/0xa0
ftrace\_return\_to\_handler+0x8b/0xf0
? pv\_hash+0xa0/0xa0
return\_to\_handler+0x15/0x30
? ftrace\_graph\_caller+0xa0/0xa0
? trace\_clock\_global+0x91/0xa0
? \_\_rb\_reserve\_next+0x237/0x460
? ring\_buffer\_lock\_reserve+0x12a/0x3f0
? trace\_event\_buffer\_lock\_reserve+0x3c/0x120
? trace\_event\_buffer\_reserve+0x6b/0xc0
? trace\_event\_raw\_event\_device\_pm\_callback\_start+0x125/0x2d0
? dpm\_run\_callback+0x3b/0xc0
? pm\_ops\_is\_empty+0x50/0x50
? platform\_get\_irq\_byname\_optional+0x90/0x90
? trace\_device\_pm\_callback\_start+0x82/0xd0
? dpm\_run\_callback+0x49/0xc0
With the following RIP:
RIP: 0010:native\_queued\_spin\_lock\_slowpath+0x69/0x200
Since the fix to the recursion detection would allow a single recursion to
happen while tracing, this lead to the trace\_clock\_global() taking a spin
lock and then trying to take it again:
ring\_buffer\_lock\_reserve() {
trace\_clock\_global() {
arch\_spin\_lock() {
queued\_spin\_lock\_slowpath() {
/\* lock taken \*/
(something else gets traced by function graph tracer)
ring\_buffer\_lock\_reserve() {
trace\_clock\_global() {
arch\_spin\_lock() {
queued\_spin\_lock\_slowpath() {
/\* DEAD LOCK! \*/
Tracing should \*never\* block, as it can lead to strange lockups like the
above.
Restructure the trace\_clock\_global() code to instead of simply taking a
lock to update the recorded "prev\_time" simply use it, as two events
happening on two different CPUs that calls this at the same time, really
doesn't matter which one goes first. Use a trylock to grab the lock for
updating the prev\_time, and if it fails, simply try again the next time.
If it failed to be taken, that means something else is already updating
it.
Link: [https://lkml.kernel.org/r/20210430121758.650b6e8a@gandalf.local.home](https://lkml.kernel.org/r/20210430121758.650b6e8a%40gandalf.local.home)
Cc: stable@vger.kernel.org
Tested-by: Konstantin Kharlamov <hi-angel@yandex.ru>
Tested-by: Todd Brandt <todd.e.brandt@linux.intel.com>
Fixes: b02414c8f045 ("ring-buffer: Fix recursion protection transitions between interrupt context") # started showing the problem
Fixes: 14131f2f98ac3 ("tracing: implement trace\_clock\_\*() APIs") # where the bug happened
Bugzilla: https://bugzilla.kernel.org/show\_bug.cgi?id=212761
Signed-off-by: Steven Rostedt (VMware) <rostedt@goodmis.org>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)

| -rw-r--r-- | [kernel/trace/trace\_clock.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/trace/trace_clock.c?id=2a1bd74b8186d7938bf004f5603f25b84785f63e) | 44 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 30 insertions, 14 deletions

| diff --git a/kernel/trace/trace\_clock.c b/kernel/trace/trace\_clock.cindex aaf6793ededaa2..c1637f90c8a38b 100644--- a/[kernel/trace/trace\_clock.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/trace/trace_clock.c?id=7bc6bc25a1a80554e9dab1578ef0864a5bcfe552)+++ b/[kernel/trace/trace\_clock.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/trace/trace_clock.c?id=2a1bd74b8186d7938bf004f5603f25b84785f63e)@@ -95,33 +95,49 @@ u64 notrace trace\_clock\_global(void) { unsigned long flags; int this\_cpu;- u64 now;+ u64 now, prev\_time;  raw\_local\_irq\_save(flags);  this\_cpu = raw\_smp\_processor\_id();- now = sched\_clock\_cpu(this\_cpu);+ /\*- \* If in an NMI context then dont risk lockups and return the- \* cpu\_clock() time:+ \* The global clock "guarantees" that the events are ordered+ \* between CPUs. But if two events on two different CPUS call+ \* trace\_clock\_global at roughly the same time, it really does+ \* not matter which one gets the earlier time. Just make sure+ \* that the same CPU will always show a monotonic clock.+ \*+ \* Use a read memory barrier to get the latest written+ \* time that was recorded. \*/- if (unlikely(in\_nmi()))- goto out;+ smp\_rmb();+ prev\_time = READ\_ONCE(trace\_clock\_struct.prev\_time);+ now = sched\_clock\_cpu(this\_cpu); - arch\_spin\_lock(&trace\_clock\_struct.lock);+ /\* Make sure that now is always greater than prev\_time \*/+ if ((s64)(now - prev\_time) < 0)+ now = prev\_time + 1;  /\*- \* TODO: if this happens often then maybe we should reset- \* my\_scd->clock to prev\_time+1, to make sure- \* we start ticking with the local clock from now on?+ \* If in an NMI context then dont risk lockups and simply return+ \* the current time. \*/- if ((s64)(now - trace\_clock\_struct.prev\_time) < 0)- now = trace\_clock\_struct.prev\_time + 1;+ if (unlikely(in\_nmi()))+ goto out; - trace\_clock\_struct.prev\_time = now;+ /\* Tracing can cause strange recursion, always use a try lock \*/+ if (arch\_spin\_trylock(&trace\_clock\_struct.lock)) {+ /\* Reread prev\_time in case it was already updated \*/+ prev\_time = READ\_ONCE(trace\_clock\_struct.prev\_time);+ if ((s64)(now - prev\_time) < 0)+ now = prev\_time + 1; - arch\_spin\_unlock(&trace\_clock\_struct.lock);+ trace\_clock\_struct.prev\_time = now; + /\* The unlock acts as the wmb for the above rmb \*/+ arch\_spin\_unlock(&trace\_clock\_struct.lock);+ } out: raw\_local\_irq\_restore(flags); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 16:39:38 +0000

