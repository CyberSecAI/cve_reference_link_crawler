
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscikit-learn%2Fscikit-learn%2Fcommit%2F70ca21f106b603b611da73012c9ade7cd8e438b8)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscikit-learn%2Fscikit-learn%2Fcommit%2F70ca21f106b603b611da73012c9ade7cd8e438b8)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=scikit-learn%2Fscikit-learn)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[scikit-learn](/scikit-learn)
/
**[scikit-learn](/scikit-learn/scikit-learn)**
Public

* [Notifications](/login?return_to=%2Fscikit-learn%2Fscikit-learn) You must be signed in to change notification settings
* [Fork
  25.5k](/login?return_to=%2Fscikit-learn%2Fscikit-learn)
* [Star
   60.7k](/login?return_to=%2Fscikit-learn%2Fscikit-learn)

* [Code](/scikit-learn/scikit-learn)
* [Issues
  1.6k](/scikit-learn/scikit-learn/issues)
* [Pull requests
  559](/scikit-learn/scikit-learn/pulls)
* [Discussions](/scikit-learn/scikit-learn/discussions)
* [Actions](/scikit-learn/scikit-learn/actions)
* [Projects
  15](/scikit-learn/scikit-learn/projects)
* [Wiki](/scikit-learn/scikit-learn/wiki)
* [Security](/scikit-learn/scikit-learn/security)
* [Insights](/scikit-learn/scikit-learn/pulse)

Additional navigation options

* [Code](/scikit-learn/scikit-learn)
* [Issues](/scikit-learn/scikit-learn/issues)
* [Pull requests](/scikit-learn/scikit-learn/pulls)
* [Discussions](/scikit-learn/scikit-learn/discussions)
* [Actions](/scikit-learn/scikit-learn/actions)
* [Projects](/scikit-learn/scikit-learn/projects)
* [Wiki](/scikit-learn/scikit-learn/wiki)
* [Security](/scikit-learn/scikit-learn/security)
* [Insights](/scikit-learn/scikit-learn/pulse)

## Commit

[Permalink](/scikit-learn/scikit-learn/commit/70ca21f106b603b611da73012c9ade7cd8e438b8)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

FIX remove the computed stop\_words\_ attribute of text vectorizer ([#28823](https://github.com/scikit-learn/scikit-learn/pull/28823)

[Browse files](/scikit-learn/scikit-learn/tree/70ca21f106b603b611da73012c9ade7cd8e438b8)
Browse the repository at this point in the history

```
)
```

* Loading branch information

[![@ogrisel](https://avatars.githubusercontent.com/u/89061?s=40&v=4)](/ogrisel)

[ogrisel](/scikit-learn/scikit-learn/commits?author=ogrisel "View all commits by ogrisel")
authored
Apr 22, 2024

1 parent
[1210b06](/scikit-learn/scikit-learn/commit/1210b0685b4b321ecee34a9a0fb449dd9d9bafb1)

commit 70ca21f

 Show file tree

 Hide file tree

Showing
**3 changed files**
with
**20 additions**
and
**76 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* doc/whats\_new

  + doc/whats\_new/v1.5.rst
    [v1.5.rst](#diff-6b769314adb7bd48abac55342282c74675c8f1be9b03b6d9b27547a5908ba959)
* sklearn/feature\_extraction

  + tests

    - sklearn/feature\_extraction/tests/test\_text.py
      [test\_text.py](#diff-182536c81191c059f2752f04556c0506c9e44a90679f2e5d1dd1ecd00cc00047)
  + sklearn/feature\_extraction/text.py
    [text.py](#diff-d6cf7bedd56799ad9699cb344de36f4d79a1e7fa32330e37476f4d236f272358)

## There are no files selected for viewing

18 changes: 18 additions & 0 deletions

18
[doc/whats\_new/v1.5.rst](#diff-6b769314adb7bd48abac55342282c74675c8f1be9b03b6d9b27547a5908ba959 "doc/whats_new/v1.5.rst")

Show comments

[View file](/scikit-learn/scikit-learn/blob/70ca21f106b603b611da73012c9ade7cd8e438b8/doc/whats_new/v1.5.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -22,6 +22,24 @@ Version 1.5.0 |
|  |  |  |
|  |  | \*\*In Development\*\* |
|  |  |  |
|  |  | Security |
|  |  | -------- |
|  |  |  |
|  |  | - |Fix| :class:`feature\_extraction.text.CountVectorizer` and |
|  |  | :class:`feature\_extraction.text.TfidfVectorizer` no longer store discarded |
|  |  | tokens from the training set in their `stop\_words\_` attribute. This attribute |
|  |  | would hold too frequent (above `max\_df`) but also too rare tokens (below |
|  |  | `min\_df`). This fixes a potential security issue (data leak) if the discarded |
|  |  | rare tokens hold sensitive information from the training set without the |
|  |  | model developer's knowledge. |
|  |  |  |
|  |  | Note: users of those classes are encouraged to either retrain their pipelines |
|  |  | with the new scikit-learn version or to manually clear the `stop\_words\_` |
|  |  | attribute from previously trained instances of those transformers. This |
|  |  | attribute was designed only for model inspection purposes and has no impact |
|  |  | on the behavior of the transformers. |
|  |  | :pr:`28823` by :user:`Olivier Grisel <ogrisel>`. |
|  |  |  |
|  |  | Changed models |
|  |  | -------------- |
|  |  |  |
| Expand Down | |  |

42 changes: 0 additions & 42 deletions

42
[sklearn/feature\_extraction/tests/test\_text.py](#diff-182536c81191c059f2752f04556c0506c9e44a90679f2e5d1dd1ecd00cc00047 "sklearn/feature_extraction/tests/test_text.py")

Show comments

[View file](/scikit-learn/scikit-learn/blob/70ca21f106b603b611da73012c9ade7cd8e438b8/sklearn/feature_extraction/tests/test_text.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -756,21 +756,11 @@ def test\_feature\_names(): |
|  |  | @pytest.mark.parametrize("Vectorizer", (CountVectorizer, TfidfVectorizer)) |
|  |  | def test\_vectorizer\_max\_features(Vectorizer): |
|  |  | expected\_vocabulary = {"burger", "beer", "salad", "pizza"} |
|  |  | expected\_stop\_words = { |
|  |  | "celeri", |
|  |  | "tomato", |
|  |  | "copyright", |
|  |  | "coke", |
|  |  | "sparkling", |
|  |  | "water", |
|  |  | "the", |
|  |  | } |
|  |  |  |
|  |  | # test bounded number of extracted features |
|  |  | vectorizer = Vectorizer(max\_df=0.6, max\_features=4) |
|  |  | vectorizer.fit(ALL\_FOOD\_DOCS) |
|  |  | assert set(vectorizer.vocabulary\_) == expected\_vocabulary |
|  |  | assert vectorizer.stop\_words\_ == expected\_stop\_words |
|  |  |  |
|  |  |  |
|  |  | def test\_count\_vectorizer\_max\_features(): |
| Expand Down  Expand Up | | @@ -805,21 +795,16 @@ def test\_vectorizer\_max\_df(): |
|  |  | vect.fit(test\_data) |
|  |  | assert "a" in vect.vocabulary\_.keys() |
|  |  | assert len(vect.vocabulary\_.keys()) == 6 |
|  |  | assert len(vect.stop\_words\_) == 0 |
|  |  |  |
|  |  | vect.max\_df = 0.5 # 0.5 \* 3 documents -> max\_doc\_count == 1.5 |
|  |  | vect.fit(test\_data) |
|  |  | assert "a" not in vect.vocabulary\_.keys() # {ae} ignored |
|  |  | assert len(vect.vocabulary\_.keys()) == 4 # {bcdt} remain |
|  |  | assert "a" in vect.stop\_words\_ |
|  |  | assert len(vect.stop\_words\_) == 2 |
|  |  |  |
|  |  | vect.max\_df = 1 |
|  |  | vect.fit(test\_data) |
|  |  | assert "a" not in vect.vocabulary\_.keys() # {ae} ignored |
|  |  | assert len(vect.vocabulary\_.keys()) == 4 # {bcdt} remain |
|  |  | assert "a" in vect.stop\_words\_ |
|  |  | assert len(vect.stop\_words\_) == 2 |
|  |  |  |
|  |  |  |
|  |  | def test\_vectorizer\_min\_df(): |
| Expand All | | @@ -828,21 +813,16 @@ def test\_vectorizer\_min\_df(): |
|  |  | vect.fit(test\_data) |
|  |  | assert "a" in vect.vocabulary\_.keys() |
|  |  | assert len(vect.vocabulary\_.keys()) == 6 |
|  |  | assert len(vect.stop\_words\_) == 0 |
|  |  |  |
|  |  | vect.min\_df = 2 |
|  |  | vect.fit(test\_data) |
|  |  | assert "c" not in vect.vocabulary\_.keys() # {bcdt} ignored |
|  |  | assert len(vect.vocabulary\_.keys()) == 2 # {ae} remain |
|  |  | assert "c" in vect.stop\_words\_ |
|  |  | assert len(vect.stop\_words\_) == 4 |
|  |  |  |
|  |  | vect.min\_df = 0.8 # 0.8 \* 3 documents -> min\_doc\_count == 2.4 |
|  |  | vect.fit(test\_data) |
|  |  | assert "c" not in vect.vocabulary\_.keys() # {bcdet} ignored |
|  |  | assert len(vect.vocabulary\_.keys()) == 1 # {a} remains |
|  |  | assert "c" in vect.stop\_words\_ |
|  |  | assert len(vect.stop\_words\_) == 5 |
|  |  |  |
|  |  |  |
|  |  | def test\_count\_binary\_occurrences(): |
| Expand Down  Expand Up | | @@ -1155,28 +1135,6 @@ def test\_countvectorizer\_vocab\_dicts\_when\_pickling(): |
|  |  | ) |
|  |  |  |
|  |  |  |
|  |  | def test\_stop\_words\_removal(): |
|  |  | # Ensure that deleting the stop\_words\_ attribute doesn't affect transform |
|  |  |  |
|  |  | fitted\_vectorizers = ( |
|  |  | TfidfVectorizer().fit(JUNK\_FOOD\_DOCS), |
|  |  | CountVectorizer(preprocessor=strip\_tags).fit(JUNK\_FOOD\_DOCS), |
|  |  | CountVectorizer(strip\_accents=strip\_eacute).fit(JUNK\_FOOD\_DOCS), |
|  |  | ) |
|  |  |  |
|  |  | for vect in fitted\_vectorizers: |
|  |  | vect\_transform = vect.transform(JUNK\_FOOD\_DOCS).toarray() |
|  |  |  |
|  |  | vect.stop\_words\_ = None |
|  |  | stop\_None\_transform = vect.transform(JUNK\_FOOD\_DOCS).toarray() |
|  |  |  |
|  |  | delattr(vect, "stop\_words\_") |
|  |  | stop\_del\_transform = vect.transform(JUNK\_FOOD\_DOCS).toarray() |
|  |  |  |
|  |  | assert\_array\_equal(stop\_None\_transform, vect\_transform) |
|  |  | assert\_array\_equal(stop\_del\_transform, vect\_transform) |
|  |  |  |
|  |  |  |
|  |  | def test\_pickling\_transformer(): |
|  |  | X = CountVectorizer().fit\_transform(JUNK\_FOOD\_DOCS) |
|  |  | orig = TfidfTransformer().fit(X) |
| Expand Down | |  |

36 changes: 2 additions & 34 deletions

36
[sklearn/feature\_extraction/text.py](#diff-d6cf7bedd56799ad9699cb344de36f4d79a1e7fa32330e37476f4d236f272358 "sklearn/feature_extraction/text.py")

Show comments

[View file](/scikit-learn/scikit-learn/blob/70ca21f106b603b611da73012c9ade7cd8e438b8/sklearn/feature_extraction/text.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -1079,15 +1079,6 @@ class CountVectorizer(\_VectorizerMixin, BaseEstimator): |
|  |  | True if a fixed vocabulary of term to indices mapping |
|  |  | is provided by the user. |
|  |  |  |
|  |  | stop\_words\_ : set |
|  |  | Terms that were ignored because they either: |
|  |  |  |
|  |  | - occurred in too many documents (`max\_df`) |
|  |  | - occurred in too few documents (`min\_df`) |
|  |  | - were cut off by feature selection (`max\_features`). |
|  |  |  |
|  |  | This is only available if no vocabulary was given. |
|  |  |  |
|  |  | See Also |
|  |  | -------- |
|  |  | HashingVectorizer : Convert a collection of text documents to a |
| Expand All | | @@ -1096,12 +1087,6 @@ class CountVectorizer(\_VectorizerMixin, BaseEstimator): |
|  |  | TfidfVectorizer : Convert a collection of raw documents to a matrix |
|  |  | of TF-IDF features. |
|  |  |  |
|  |  | Notes |
|  |  | ----- |
|  |  | The ``stop\_words\_`` attribute can get large and increase the model size |
|  |  | when pickling. This attribute is provided only for introspection and can |
|  |  | be safely removed using delattr or set to None before pickling. |
|  |  |  |
|  |  | Examples |
|  |  | -------- |
|  |  | >>> from sklearn.feature\_extraction.text import CountVectorizer |
| Expand Down  Expand Up | | @@ -1240,19 +1225,17 @@ def \_limit\_features(self, X, vocabulary, high=None, low=None, limit=None): |
|  |  | mask = new\_mask |
|  |  |  |
|  |  | new\_indices = np.cumsum(mask) - 1 # maps old indices to new |
|  |  | removed\_terms = set() |
|  |  | for term, old\_index in list(vocabulary.items()): |
|  |  | if mask[old\_index]: |
|  |  | vocabulary[term] = new\_indices[old\_index] |
|  |  | else: |
|  |  | del vocabulary[term] |
|  |  | removed\_terms.add(term) |
|  |  | kept\_indices = np.where(mask)[0] |
|  |  | if len(kept\_indices) == 0: |
|  |  | raise ValueError( |
|  |  | "After pruning, no terms remain. Try a lower min\_df or a higher max\_df." |
|  |  | ) |
|  |  | return X[:, kept\_indices], removed\_terms |
|  |  | return X[:, kept\_indices] |
|  |  |  |
|  |  | def \_count\_vocab(self, raw\_documents, fixed\_vocab): |
|  |  | """Create sparse feature matrix, and vocabulary where fixed\_vocab=False""" |
| Expand Down  Expand Up | | @@ -1397,7 +1380,7 @@ def fit\_transform(self, raw\_documents, y=None): |
|  |  | raise ValueError("max\_df corresponds to < documents than min\_df") |
|  |  | if max\_features is not None: |
|  |  | X = self.\_sort\_features(X, vocabulary) |
|  |  | X, self.stop\_words\_ = self.\_limit\_features( |
|  |  | X = self.\_limit\_features( |
|  |  | X, vocabulary, max\_doc\_count, min\_doc\_count, max\_features |
|  |  | ) |
|  |  | if max\_features is None: |
| Expand Down  Expand Up | | @@ -1911,28 +1894,13 @@ class TfidfVectorizer(CountVectorizer): |
|  |  | The inverse document frequency (IDF) vector; only defined |
|  |  | if ``use\_idf`` is True. |
|  |  |  |
|  |  | stop\_words\_ : set |
|  |  | Terms that were ignored because they either: |
|  |  |  |
|  |  | - occurred in too many documents (`max\_df`) |
|  |  | - occurred in too few documents (`min\_df`) |
|  |  | - were cut off by feature selection (`max\_features`). |
|  |  |  |
|  |  | This is only available if no vocabulary was given. |
|  |  |  |
|  |  | See Also |
|  |  | -------- |
|  |  | CountVectorizer : Transforms text into a sparse matrix of n-gram counts. |
|  |  |  |
|  |  | TfidfTransformer : Performs the TF-IDF transformation from a provided |
|  |  | matrix of counts. |
|  |  |  |
|  |  | Notes |
|  |  | ----- |
|  |  | The ``stop\_words\_`` attribute can get large and increase the model size |
|  |  | when pickling. This attribute is provided only for introspection and can |
|  |  | be safely removed using delattr or set to None before pickling. |
|  |  |  |
|  |  | Examples |
|  |  | -------- |
|  |  | >>> from sklearn.feature\_extraction.text import TfidfVectorizer |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `70ca21f`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscikit-learn%2Fscikit-learn%2Fcommit%2F70ca21f106b603b611da73012c9ade7cd8e438b8) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

