=== Content from eprint.iacr.org_50e36437_20250110_165741.html ===
Fast Secure Two-Party ECDSA Signing⋆

Yehuda Lindell⋆⋆

Dept. of Computer Science
Bar-Ilan University, Israel
yehuda.lindell@gmail.com

Abstract. ECDSA is a standard digital signature schemes that is widely
used in TLS, Bitcoin and elsewhere. Unlike other schemes like RSA,
Schnorr signatures and more, it is particularly hard to construct efficient
threshold signature protocols for ECDSA (and DSA). As a result, the
best-known protocols today for secure distributed ECDSA require run-
ning heavy zero-knowledge proofs and computing many large-modulus
exponentiations for every signing operation. In this paper, we consider
the specific case of two parties (and thus no honest majority) and con-
struct a protocol that is approximately two orders of magnitude faster
than the previous best. Concretely, our protocol achieves good perfor-
mance, with a single signing operation for curve P-256 taking approxi-
mately 37ms between two standard machine types in Azure (utilizing a
single core only). Our protocol is proven secure for sequential composition
under standard assumptions using a game-based definition. In addition,
we prove security by simulation under a plausible yet non-standard as-
sumption regarding Paillier. We show that partial concurrency (where if
one execution aborts then all need to abort) can also be achieved.

1

Introduction

1.1 Background

In the late 1980s and the 1990s, a large body of research emerged around the
problem of threshold cryptography; cf. [5,10,12,13,17,31,29,26]. In its most general
form, this problem considers the setting of a private key shared between n parties
with the property that any subset of t parties may be able to decrypt or sign,
but any set of less than t parties can do nothing. This is a specific example
of secure multiparty computation, where the functionality being computed is
either decryption or signing. Note that trivial solutions like secret sharing the
private key and reconstructing to decrypt or sign do not work since after the
first operation the key is reconstructed, and any single party can decrypt or sign
by itself from that point on. Rather, the requirement is that a subset of t parties
is needed for every private-key operation.

⋆ An extended abstract of this work appeared at CRYPTO 2017, and a full version
appeared in the Journal of Cryptology, 2021. This version fixes a small error regarding
the zero-knowledge range proof in the journal version.
⋆⋆ Much of this work was done for Unbound Security Ltd.

1

Threshold cryptography can be used in applications where multiple signators
are needed to generate a signature, and likewise where highly confidential docu-
ments should only be decrypted and viewed by a quorum. Furthermore, thresh-
old cryptography can be used to provide a high level of key protection. This is
achieved by sharing the key on multiple devices (or between multiple users) and
carrying out private-key operations via a secure protocol that reveals nothing
but the output. This provides key protection since an adversary needs to breach
multiple devices in order to obtain the key. After intensive research on the topic
in the 1990s and early 2000s, threshold cryptography received considerably less
interest in the past decade. However, interest has recently been renewed. This
can be seen by the fact that a number of startup companies are now deploying
threshold cryptography for the purpose of key protection [32,33,34]. Another
reason is due to the fact that ECDSA signing is used in bitcoin, and the theft of
a signing key can immediately be translated into concrete financial loss. Bitcoin
has a multisignature solution built in, which is based on using multiple distinct
signing keys rather than a threshold signing scheme. Nevertheless, a more gen-
eral solution may be obtained via threshold cryptography (for the more general
t-out-of-n threshold case).

Fast threshold cryptography protocols exist for a wide variety of problems,
including RSA signing and decryption, ElGamal and ECIES encryption, Schnorr
signatures, Cramer-Shoup, and more. Despite the above successes, and despite
the fact that DSA/ECDSA is a widely-used standard, DSA/ECDSA has resisted
attempts at constructing efficient protocols for threshold signing. This seems to
be due to the need to compute k and k−1 without knowing k. We explain this
by comparing ECDSA signing to EC-Schnorr signing. In both cases, the public
verification key is an elliptic curve point Q and the private signing key is x such
that Q = x · G, where G is the generator point of an EC group of order q.

EC-Schnorr signing
Choose a random k ← Zq
Compute R = k · G
Compute e = H(m∥R)
Compute s = k − x · e mod q
Output (s, e)

ECDSA signing
Choose a random k ← Zq
Compute R = k · G
Compute r = rx mod q where R = (rx, ry)
Compute s = k−1 · (H(m) + r · x) mod q
Output (r, s)

Observe that Schnorr signing can be easily distributed since the private key x
and the value k are both used in a linear equation. Thus, two parties with
shares x1, x2 such that Q = (x1 + x2) · G can each locally choose k1, k2, and
set R = k1 · G + k2 · G = (k1 + k2) · G. Then, each can locally compute e
and si = ki − xi · e mod q and send to each other, and each party can sum
s = s1 + s2 mod q and output a valid signature (s, e). In the case of malicious
adversaries, some zero knowledge proofs are needed to ensure that R is uniformly
distributed, but these are highly efficient proofs of knowledge of discrete log. In
contrast, in ECDSA signing, the equation for computing s includes k−1. Now,
given shares k1, k2 such that k1 + k2 = k mod q it is very difficult to compute
1, k′
k′

2 = k−1 mod q.

2 such that k′

1 + k′

2

As a result, beginning with [26] and more lately in [18], two-party proto-
cols for ECDSA signing use multiplicative sharing of x and of k. That is, the
parties hold x1, x2 such that x1 · x2 = x mod q, and in each signing operation
they generate k1, k2 such that k1 · k2 = k mod q. This enables them to easily
compute k−1 since each party can locally compute k′
i mod q, and then
2 are multiplicative shares of k−1. The parties can then use additively homo-
1, k′
k′
morphic encryption – specifically Paillier encryption [27] – in order to combine
their equations. For example, P1 can compute c1 = Encpk(k−1
· H(m)) and
c2 = Encpk(k−1
· x1 · r). Then, using scalar multiplication (denoted ⊙) and ho-
momorphic addition (denoted ⊕), P2 can compute (k−1
· x2) ⊙ c2]
which will be an encryption of

2 ⊙ c1) ⊕ [(k−1
2

i = k−1

1

1

k−1
2

· (k−1
1

· H(m)) + k−1

2

· x2 · (k−1

1

· x1 · r) = k−1 · (H(m) + r · x),

as required. However, proving that each party worked correctly is extremely
difficult. For example, the first party must prove that the Paillier encryption
includes k−1
1 when the second party only has R1 = k1 · G, it must prove that the
Paillier encryptions are to values in the expected range, and more. This can be
done, but it results in a protocol that is very expensive.

1.2 Our Results

2

2

As in previous protocols, we use Paillier homomorphic encryption (with a key
generated by P1), and multiplicative sharing of both the private key x and the
random value k. However, we make the novel observation that if P2 already
holds a Paillier encryption ckey of P1’s share of the private key x1, then P1 need
not do anything except participate in the generation of R = k · G. Specifically,
assume that the parties P1 and P2 begin by generating R = k1 · k2 · G (this
is essentially accomplished by just running a Diffie-Hellman key exchange with
basic knowledge-of-discrete-log proofs which are highly efficient). Then, given
ckey = Encpk(x1), R and k2, x2, party P2 can singlehandedly compute an en-
cryption of k−1
· r · x2 · x1 using the homomorphic properties of
Paillier encryption. This ciphertext can be sent to P1 who decrypts and multi-
plies the result by k−1

1 . If P2 is honest, then the result is a valid signature.

· H(m) + k−1

The crucial issue that must be dealt with is what happens when P1 or P2
is corrupted. If P1 is corrupted, it cannot do anything since the only message
that it sends P2 is in the generation of R which is protected by an efficient zero-
knowledge proof. Thus, no expensive proofs are needed. Furthermore, if P2 is
corrupted, then the only way it can cheat is by encrypting something incorrect
and sending it to P1. However, here we can utilize the fact that we are specifically
computing a digital signature that can be publicly verified. That is, since all P1
does is locally decrypt the ciphertext received from P2 and multiply by k−1
1 , it
can locally check if the signature obtained is valid. If yes, it outputs it, and if
not it detects P2 cheating. Thus, no zero-knowledge proofs are required for P2
either (again, beyond the zero-knowledge proof in the generation of R).

As a result, we obtain a signing protocol that is extremely simple and effi-
cient. As we show, our protocol is approximately two orders of magnitude faster

3

than the previous best. Before proceeding, we remark that there are additional
elements needed in the protocol (like P2 adding random noise in the ciphertext
it sends), but these have little effect on the efficiency.

We remark that since the security of the signing protocol rests upon the
assumption that P2 holds an encryption of x1, which is P1’s share of the key,
this must be proven in the key generation phase. Thus, the key generation phase
of our protocol is more complicated than the signing phase, and includes a proof
that P1 generated the Paillier key correctly and that ckey is an encryption of x1,
given R1 = x1·G. This latter proof is of interest since it connects between Paillier
encryption and discrete log, and we present a novel efficient proof in the paper.
We remark that since key generation is run only once, having a more expensive
key-generation phase is a worthwhile tradeoff. This is especially the case since it
is still quite reasonable (concretely taking about 2.5 seconds between standard
machines in Azure and running with a single thread, which is much faster than
the key-generation phase of [18]). Furthermore, it can easily be parallelized to
further bring down the cost.

Sequential versus concurrent composition. We prove security of our protocol
under sequential composition. This is sufficient for applications like a virtual
smartcard, where keys are shared between a mobile or desktop and a server,
and signing takes place using a secure two-party protocol. Another use case
where sequential composition suffices is for so-called cryptocurrency wallets, as
motivated by [18], where a key is protected by sharing it between two devices
belonging to the user, or between the user and a non-custodial wallet provider.
We also show that a limited type of concurrency can also be achieved where
many executions can run concurrently but it is assumed that if one execution
aborts then all are immediately aborted. This type of abort can be achieved
in practice when all concurrent executions take place on the same machine (as
could be the case when the concurrency is used to increase throughput, but not
necessarily to have completely independent instances of the protocol running).

DSA vs ECDSA. In this paper, we refer to ECDSA throughout and we use
Elliptic curve (additive group) notation. However, our entire protocol translates
easily to the DSA case, since we do nothing but standard group operations.

Caveat. The only caveat of our work is that it focuses specifically on the two-
party case, whereas prior works considered general thresholds as well. The two-
party case is in some ways the most difficult case (since there is no honest
majority), and we therefore believe that our techniques may be useful for the
general case as well. We leave this for future research.

1.3 Related Work and a Comparison of Efficiency

The first specific protocol for threshold DSA signing with proven security was
presented in [17]. Their protocol works as long as more than 1/3 of the parties are
honest. The two party case (where there is no honest majority) was later dealt

4

with by [26]. The most recent protocol by [18] contains efficiency improvements
for the two-party case, and improvements regarding the thresholds for the case
of an honest majority. The efficiency comparison below holds for the sequential
composition version of our protocol (the only difference for the limited concurrent
version is in the key generation with the zero-knowledge proofs, as described in
Section 4.3, which is not significant).

Efficiency comparison with [18]. The previous best DSA/ECDSA threshold sign-
ing protocol is due to [18]. Their signing protocol requires the following opera-
tions by each party: 1 Paillier encryption, 5 Paillier homomorphic scalar multi-
plications, 5 Paillier homomorphic additions, and 46 exponentiations (the vast
majority of these modulo N or N 2 for the Paillier modulus). Furthermore, they
require the Paillier modulus to be greater than q8 where q is the group order.
Now, for P-256, this makes no difference since anyway a 2048-bit modulus is
minimal. However, for P-384 and P-521 respectively, this requires a modulus
of size 3072 and 4168 respectively, which severely slows down the computation.
Regarding the key generation phase, [18] need to run a protocol for distributed
key generation for Paillier. This outweighs all other computations and is very
expensive for the case of malicious adversaries. (They did not implement this
phase in their prototype, but the method they refer to [22] has a reported time
of 15 minutes for generating a 2048-bit modulus for the semi-honest case alone.)
In contrast, the cost of our key-generation protocol is dominated by approx-
imately 350 Paillier encryptions/exponentiations by each party; see Section 3.4
for an exact count. Furthermore, as described in Section 3.4, in the signing proto-
col, party P1 computes 7 Elliptic curve multiplications and 1 Paillier decryption,
and party P2 computes 5 Elliptic curve multiplications and 1 Paillier encryption,
1 homomorphic scalar multiplication and 1 Paillier homomorphic addition. Fur-
thermore, the Paillier modulus needs only to be greater than q3 + q2, where q
is the ECDSA group order. Thus, a 2048-bit modulus can be taken for all com-
monly used curves. We therefore conclude that the cost of our signing protocol
is approximately two orders of magnitude faster than their protocol.1 This the-
oretical estimate is validated by our experimental results. However, we stress
that [18] works for any number of parties, whereas our work focuses only on the
two-party case.

Experimental results and comparison. We provide a comparison to [18] and not
to [26] since (a) there is no implementation of [26], and (b) [18] strictly improves
upon [26] in any case. The running-time reported for the protocol of [18] for curve
P-256 is approximately 12 seconds per signing operation between a mobile and
PC. An improved optimized implementation using parallelism and 4 cores on a

1 We base this estimate on an OpenSSL speed test that puts the speed of the entire
ECDSA signing operation for P-256 (which consists of one EC multiplication and
more) at more than 10 times faster than a single RSA2048 private-key exponen-
tiation. Note that for P-521 and RSA4096 the gap is even larger with the entire
ECDSA signing operation being more than 30 times faster than a single RSA4096
private-key exponentiation.

5

2.4GHz machine achieves approximately 1 second per signing operation (these
measurements are only for the computation time and do not include communi-
cation). In contrast, as we describe in Section 3.4, for curve P-256 our signing
protocol takes approximately 37ms, using a single core (measuring the actual
full running time, including communication), on weaker Azure Standard DS3 v2
instances, including communication. This validates the theoretical analysis of ap-
proximately two orders of magnitude difference, when taking into account the
use of multiple cores. Specifically, on 4 cores, we can achieve a throughput of over
100 signatures per second, in contrast to a single signing operation for [18]. Sub-
sequently to the original publication of this paper, [3] reported on an optimized
implementation of [18], with signing times for two parties using a single core
on a 3.40GHz i7-6000 machine taking approximately 400ms (as above, counting
computation only, and not communication). This is still over an order of magni-
tude greater than our protocol. Full details of our experiments, for curves P-256,
P-384 and P-521 appear in Section 3.4.

Finally, the key generation phase of our protocol for curve P-256 takes ap-
proximately 2.5 seconds, using a single core. In contrast, [18] requires distributed
Paillier key generation which is extremely expensive, as described above.

2 Preliminaries

The ECDSA signing algorithm. The ECDSA signing algorithm is defined as
follows. Let G be an Elliptic curve group of order q with base point (generator)
G. The private key is a random value x ← Zq and the public key is Q = x · G.
The ECDSA signing operation on a message m ∈ {0, 1}∗ is defined as follows:

1. Compute m′ to be the |q| leftmost bits of SHA256(m), where |q| is the

bit-length of q

2. Choose a random k ← Z∗
q
3. Compute R ← k · G. Let R = (rx, ry).
4. Compute r = rx mod q. If r = 0, go back to Step 2.
5. Compute s ← k−1 · (m′ + r · x) mod q.
6. Output (r, s)

It is a well-known fact that for every valid signature (r, s), the pair (r, −s) is also
a valid signature. In order to make (r, s) unique (which will help in formalizing
security), we mandate that the “smaller” of s, −s is always output (where the
smaller is the value between 0 and q−1
2 .)

The ideal commitment functionality Fcom. In one of our subprotocols, we assume
an ideal commitment functionality Fcom, formally defined in Functionality 2.1.
Any UC-secure commitment scheme fulfills Fcom; e.g., [24,2,16]. In the random-
oracle model, Fcom can be trivially realized with static security by simply defining
Com(x) = H(x, r) where r ← {0, 1}n is random.

6

FIGURE 2.1 (The Commitment Functionality Fcom)

Functionality Fcom works with parties P1 and P2, as follows:

– Upon receiving (commit, sid, x) from party Pi (for i ∈ {1, 2}), record
(sid, i, x) and send (receipt, sid) to party P3−i. If some (commit, sid, ∗)
is already stored, then ignore the message.

– Upon receiving (decommit, sid) from party Pi, if (sid, i, x) is recorded then

send (decommit, sid, x) to party P3−i.

The ideal zero-knowledge functionality Fzk. We use the standard ideal zero-
knowledge functionality defined by ((x, w), λ) → (λ, (x, R(x, w))), where λ de-
notes the empty string. For a relation R, the functionality is denoted by F R
zk. Note
that any zero-knowledge proof of knowledge fulfills the Fzk functionality [21, Sec-
tion 6.5.3]; non-interactive versions can be achieved in the random-oracle model
via the Fiat-Shamir paradigm with security under sequential composition (see
Section 4.3 for security under concurrent executions); see Functionality 2.2 for
the formal definition.

FIGURE 2.2 (The Zero-Knowledge Functionality F R

zk for Relation R)

Upon receiving (prove, sid, x, w) from a party Pi (for i ∈ {1, 2}): if (x, w) /∈ R
or sid has been previously used then ignore the message. Otherwise, send
(proof, sid, x) to party P3−i.

The committed non-interactive zero-knowledge functionality Fcom-zk. In our pro-
tocol, we will have parties send commitments to non-interactive zero-knowledge
proofs. We model this formally via a commit-zk functionality, denoted Fcom-zk,
defined in Functionality 2.3. Given non-interactive zero-knowledge proofs of
knowledge, this functionality is securely realized by just having the prover com-
mit to such a proof using the ideal commitment functionality Fcom.

FIGURE 2.3 (The Committed NIZK Functionality F R
Functionality Fcom-zk works with parties P1 and P2, as follows:

com-zk for R)

– Upon receiving (com-prove, sid, x, w) from a party Pi (for i ∈ {1, 2}): if
sid has been previously used then ignore the message. Otherwise, store
(sid, i, x, w) and send (proof-receipt, sid) to P3−i.

– Upon receiving (decom-proof, sid) from Pi (for i ∈ {1, 2}): if (sid, i, x, w)
has been stored – if (x, w) ∈ R then send (decom-proof, sid, x, 1) to P3−i;
otherwise send (decom-proof, sid, x, 0) to P3−i.

Paillier encryption. Denote the public/private key pair by (pk, sk), and denote
encryption and decryption under these keys by Encpk(·) and Decsk(·), respec-
tively. We denote by c1 ⊕ c2 the “addition” of the plaintexts in c1, c2, and by
a ⊙ c the multiplication of the plaintext in c by scalar a.

7

Security, the hybrid model and composition. We prove the security of our pro-
tocol under a game-based definition with standard assumptions (in Section 4),
and under the simulation-based ideal/real model definition with a non-standard
ad-hoc assumption (in Section 5). In all cases, we prove our protocols secure in a
hybrid model with ideal functionalities that securely compute Fcom, Fzk, Fcom-zk.
The soundness of working in this model is justified in [7] (for stand-alone secu-
rity) and in [8] (for security under composition). Specifically, as long as subpro-
tocols that securely compute the functionalities are used (under the definition
of [7] or [8], respectively), it is guaranteed that the output of the honest and cor-
rupted parties when using real subprotocols is computationally indistinguishable
to when calling a trusted party that computes the ideal functionalities.

3 Two-Party ECDSA

In this section, we present our protocol for distributed ECDSA signing. We
separately describe the key generation phase (which is run once) and the signing
phase (which is run multiple times).

3.1 Zero-Knowledge Proofs

Zero-knowledge proofs of knowledge of the discrete log of an Elliptic-curve point.
Our protocol is presented in the Fzk and Fcom-zk hybrid model for the zero-
knowledge functionality F RDL

defined by the following relation:

zk

RDL = {(G, G, q, P, w) | P = w · G}

of discrete log values (relative to the given group). We use the standard Schnorr
proof for this [28] (with the variant of Section 4.3 for concurrent security).

Zero-knowledge proof that a Paillier public-key was generated correctly. We also
use a zero-knowledge proof (which is not required to be a proof of knowledge)
for the language:

LP = {N | gcd(N, ϕ(N )) = 1}

of valid Paillier public keys. We remark that standard Paillier is defined for
N = p · q with p, q being distinct primes. However, all that we require is that N
defines a public key for which the additive homomorphic operations are correct,
and this holds as long as gcd(N, ϕ(N )) = 1. This proof can be generated as
described in Section 3.3 in the full version of [22] (if concurrent security is needed
for the key generation, then a concurrently-secure version of the protocol should
be taken). The cost of this protocol is 3t Paillier exponentiations by each of the
prover and verifier for statistical error 2−t, as well as 3t GCD computations by
the prover. Note that since the proof that we use for this statement is not a
proof of knowledge, we cannot use the Fzk-hybrid model; rather we will use the
zero-knowledge properties directly in our proof.

Before proceeding, we explain why proving that gcd(N, ϕ(N )) = 1 suffices to
show that the Paillier key is “generated correctly”. First, it is important to clarify
that it clearly does not mean that it was generated honestly as the product of

8

two primes. However, we argue that it suffices for defining an encryption scheme
with all the properties of Paillier. In particular, the homomorphic operations
work as expected. In order to see this, we first note that for any N for which
gcd(N, ϕ(N )) = 1 it holds that the group ZN ×Z∗
N is isomorphic to the group Z∗
N 2
with the isomorphism given by f (a, b) = (1 + N )a · bN mod N 2. This can be seen
by inspection of the proof of Claim 15.9 of [23]. This implies that any ciphertext
c ∈ Z∗
N 2 is associated with a unique plaintext m ∈ ZN and randomness r ∈ Z∗
N .
Thus, the receiver of a Paillier ciphertext c generated by a potentially malicious
party who has generated N (but has proven that gcd(N, ϕ(N )) = 1) just has
to check that c ∈ Z∗
N 2 and it is guaranteed that this is a “valid” ciphertext.
Next, observe that multiplying some c ∈ Z∗
N 2 by ρN mod N 2 for a random
ρ ∈ Z∗
N yields a proper rerandomization of the ciphertext. Stated differently,
if c = (1 + N )m · rN mod N 2, then multiplication by ρN mod N 2 is a uniform
encryption of m. This follows trivially from the fact that irrespective of how
c ∈ Z∗
N . Thus, multiplying
by ρN mod N 2 results in a ciphertext that is associated with (m, r · ρ). Since ρ
is randomly chosen, the desired property follows. The same argument holds for
the other homomorphic operations in Paillier. (Observe that the party carrying
out the rerandomization needs to indeed check that ρ as chosen is relatively
prime to N . This isn’t needed when N is chosen honestly, since the probability
that gcd(ρ, N ) = 1 is negligible. However, it is necessary when N may have
been adversarially chosen, as is the case here, and the only guarantee is that
gcd(N, ϕ(N )) = 1.)

N 2 is generated, it is isomorphic to (m, r) ∈ ZN × Z∗

Zero-knowledge proof of a Paillier encryption of a discrete log. We also need to
prove in zero-knowledge that a value encrypted in a given Paillier ciphertext is
the discrete log of a given Elliptic curve point. This doesn’t need to be a proof of
knowledge, and we therefore define the language and not its associated relation:

LP DL = {(c, pk, Q1, G, G, q) | ∃(x1, r) such that

c = Encpk(x1; r) and Q1 = x1 · G and x1 ∈ Zq},

where pk is a given Paillier public key and sk is its associated private key. We
will actually prove a slightly relaxed variant which is that completeness holds
(cid:9) whereas soundness only holds for x1 /∈ Zq. This suffices
for x1 ∈ (cid:8) q
for our needs. As above since our proof for this statement is not a proof of
knowledge, we cannot use the Fzk-hybrid model; rather we will use the zero-
knowledge properties directly in our proof.

3 , . . . , 2q

3

We present a highly efficient zero-knowledge proof for the language LP DL;
this proof by itself is a novel contribution and of interest since it bridges between
two completely different worlds (Paillier encryption and Elliptic curve groups).
The proof appears in Section 6.

For the sake of clarity of notation, we omit the group description (G, G, q)
within calls to the Fzk functionalities and when referring to LP DL, since this
is implicit. In addition, throughout, we assume that all values (Elliptic curve
points) received are not equal to 0, and if zero is received then the party receiving
the value aborts immediately.

9

3.2 Distributed Key Generation

The idea behind the distributed key generation protocol is as follows. The parties
run a type of “simulatable coin tossing” in order to generate a random group
element Q. This coin tossing protocol works by P1 choosing a random x1 and
computing Q1 = x1 · G, and then committing to Q1 along with a zero-knowledge
proof of knowledge of x1, the discrete log of Q1 (for technical reasons that will
(cid:9), but this
become apparent in Section 6, P1 actually chooses x1 ∈ (cid:8) q
makes no difference). Then, P2 chooses a random x2 and sends Q2 = x2 · G
along with a zero-knowledge proof of knowledge to P1. Finally, P1 decommits
and P2 verifies the proof. The output is the point Q = x1 · Q2 = x2 · Q1.
This is fully simulatable due to the extractability and equivocality of the proof
and commitment. In particular, assume that P1 is corrupted. Then, a simulator
receiving Q from the trusted party can cause the output of the coin-toss to equal
Q. This is because it receives Q1, x1 from P1 (who sends these values to the proof
functionality) and can define the value sent by P2 to be Q2 = (x1)−1 · Q. Noting
that x1 · Q2 = Q, we have the desired property. Likewise, if P2 is corrupted, then
the simulator can commit to anything and then after seeing (Q2, x2) as sent to
the proof functionality, it can define Q1 = (x2)−1 · Q.

3 , . . . , 2q

3

PROTOCOL 3.1 (Key Generation Subprotocol KeyGen(G, g, q))

Given joint input (G, G, q) and security parameter 1n, work as follows:
1. P1’s first message:

(a) P1 chooses a random x1 ← (cid:8) q
(b) P1 sends (com-prove, 1, Q1, x1) to F RDL

3 , . . . , 2q

(cid:9), and computes Q1 = x1 · G.
3
com-zk (i.e., P1 sends a commitment

to Q1 and a proof of knowledge of its discrete log).

2. P2’s first message:

(a) P2 receives (proof-receipt, 1) from F RDL
com-zk.
(b) P2 chooses a random x2 ← Zq and computes Q2 = x2 · G.
(c) P2 sends (prove, 2, Q2, x2) to F RDL

.

zk

3. P1’s second message:

(a) P1 receives (proof, 2, Q2) from F RDL
zk
(b) P1 sends (decom-proof, 1) to F RDL
com-zk.
(c) P1 generates a Paillier key-pair (pk, sk) of length max(3 log |q| + 1, n)
and computes ckey = Encpk(x1). Denote N = pk. (Note that n denotes
the minimum length of N for Paillier to be secure.)

. If not, it aborts.

(d) P1 sends pk = N and ckey to P2.

4. ZK proofs: P1 proves to P2 in zero knowledge that N ∈ LP and that

(ckey, pk, Q1) ∈ LP DL.

5. P2’s verification: P2 aborts unless all the following hold: (a) it received
(decom-proof, 1, Q1) from F RDL
N 2 , (c) it ac-
cepted the proofs that N ∈ LP and (ckey, pk, Q1) ∈ LP DL, and (d) the key
pk = N is of length at least max(3 log |q| + 1, n).

, (b) it holds that ckey ∈ Z∗

zk

6. Output:

(a) P1 computes Q = x1 · Q2 and stores (x1, Q).
(b) P2 computes Q = x2 · Q1 and stores (x2, Q, ckey).

10

Beyond generating Q, the protocol concludes with P2 holding a Paillier en-
cryption of x1, where Q1 = x1 · G. As described, this is used to obtain higher
efficiency in the signing protocol, and is guaranteed via a zero-knowledge proof.
See Protocol 3.1 for a full description.

3.3 Distributed Signing

1

1

· m′ + k−1

The idea behind the signing protocol is as follows. First, the parties run a similar
“coin tossing protocol” as in the key generation phase in order to obtain a
random point R that will be used in generating the signature; after this, the
parties P1 and P2 hold k1 and k2, respectively, where R = k1 · k2 · G. Then,
since P2 already holds a Paillier encryption of x1 (under a key known only to
P1), it is possible for P1 to singlehandedly compute r from R = (rx, ry) and
an encryption of s′ = k−1
· r · x2 · x1; this can be carried out by P2
since it knows all the values involved directly except for x1 which is encrypted
under Paillier. Observe that this is “almost” a valid signature since in a valid
signature s = k−1 · m′ + k−1 · r · x (and here x = x1 · x2). Indeed, P2 can send
the encryption of this value to P1, who can then decrypt and just multiply by
k−1
1 . Since k = k1 · k2 we have that the result is a valid ECDSA signature. The
only problem with this method is that the encryption of k−1
· r · x2 · x1
may reveal information to P1 since no reduction modulo q is carried out on the
values (because Paillier works over a different modulus). In order to prevent
this, we have P2 add ρ · q to the value inside the encryption, where ρ is random
and “large enough”; in the proof, we show that if ρ ← Zq2 , then this value is
statistically close to k1 · s, where s is the final signature. Thus, P1 can learn
nothing more than the result (and in fact its view can be simulated). Note that
since s = k−1
· s′, it holds that s′ = k1 · s and so s′ reveals no more information
to P1 than the signature s itself (this is is due to the fact that P1 can compute
s′ from the signature s and from its share k1).

· m′ + k−1

1

2

2

The only problem that remains is that P2 may send an incorrect s′ value
to P1. However, since we are dealing specifically with digital signatures, P1 can
verify that the result is correct before outputting it. Thus, a corrupt P2 cannot
cause P1 to output incorrect values. However, it is conceivable that P2 may
be able to learn something from the fact that P1 output a value or aborted.
Consider, hypothetically, that P2 could generate an encryption of a value s′ so
that k−1
1 ·s′ is not a valid signature
if LSB(x1) = 1. In such a case, the mere fact that P1 aborts or not can leak a
single bit about P1’s private share of the key. In the proof(s) of security below,
we show how we deal with this issue. See the formal definition of the signing
phase in Protocol 3.2 (and a graphical representation in Figure 1).

1 ·s′ is a valid signature if LSB(x1) = 0 and k−1

11

PROTOCOL 3.2 (Signing Subprotocol Sign(sid, m))

A graphical representation of the protocol appears in Figure 1.

Inputs:

1. Party P1 has (x1, Q) as output from Protocol 3.1, the message m, and a

unique session id sid.

2. Party P2 has (x2, Q, ckey) as output from Protocol 3.1, the message m and

the session id sid.

3. P1 and P2 both locally compute m′ ← Hq(m) and verify that sid has not

been used before (if it has been, the protocol is not executed).

The Protocol:
1. P1’s first message:

(a) P1 chooses a random k1 ← Zq and computes R1 = k1 · G.
(b) P1 sends (com-prove, sid∥1, R1, k1) to F RDL
com-zk.

2. P2’s first message:

(a) P2 receives (proof-receipt, sid∥1) from F RDL
com-zk.
(b) P2 chooses a random k2 ← Zq and computes R2 = k2 · G.
(c) P2 sends (prove, sid∥2, R2, k2) to F RDL

.

zk

3. P1’s second message:

(a) P1 receives (proof, sid∥2, R2) from F RDL
(b) P1 sends (decom-proof, sid∥1) to Fcom-zk.

zk

; if not, it aborts.

4. P2’s second message:

(a) P2 receives (decom-proof, sid∥1, R1) from F RDL
(b) P2 computes R = k2 · R1. Denote R = (rx, ry). Then, P2 computes

com-zk; if not, it aborts.

r = rx mod q.

(c) P2 chooses a random ρ ← Z

q2 and random ˜r ∈ Z∗

N (verifying explicitly

that gcd(˜r, N ) = 1), and computes

c1 = Encpk

(cid:0)ρ · q + (cid:2)k−1

2

· m′ mod q; ˜r(cid:3)(cid:1) .

Then, P2 computes v = k−1

2 ·r ·x2 mod q, c2 = v ⊙ckey and c3 = c1 ⊕c2.

(d) P2 sends c3 to P1.
5. P1 generates output:

(a) P1 computes R = k1 · R2. Denote R = (rx, ry). Then, P1 computes

r = rx mod q.

(b) P1 computes s′ = Decsk(c3) and s′′ = k−1

· s′ mod q. P1 sets s =
min{s′′, q − s′′} (this ensures that the signature is always the smaller
of the two possible values).

1

(c) P1 verifies that (r, s) is a valid signature with public key Q. If yes it

outputs the signature (r, s); otherwise, it aborts.
If a party aborts at any point, then all Sign(sid, m) executions are halted.2

2

In the basic model of sequential composition for which we prove the security of this protocol,
there is only one sign execution at a time, and when a party aborts then no further executions
are carried out. If executions are run concurrently (which can be achieved when using properly
instantiated zero-knowledge and other sub-functionalities, as discussed in Section 4.3) then one
must implement a mechanism to enable halting all concurrent executions immediately (which is
possible, for example, when one application runs multiple threads for signing). We remark that
this is needed for the proof, since the simulator guesses where the first abort occurs, and cannot
continue the simulation beyond that point.

12

P1

m, x1, Q

Choose random k1
Compute R1 ← k1 · G
Compute DLOG proof π1
Compute commit to R1, π1

commit (cid:45)

Verify proof π2

(cid:27)

R2, π2

Decommit to R1, π1(cid:45)

P2

m, x2, Q, ckey

Choose random k2
Compute R2 ← k2 · G
Compute DLOG proof π2

Verify proof π1
Compute R ← k2 · R1
Compute r from R
· r · x2 · x1 + k−1

k−1
2

2

· m′ + ρ · q

(cid:17)

c3(cid:27)

c3 ← Enc

(cid:16)

Compute R ← k1 · R2
Compute r from R
Decrypt c3 to get s′

Compute s ← k−1

1

· s′ mod q

Verify signature

Fig. 1. The 2-Party ECDSA Signing Protocol

Output to both parties. Observe that since the validity of the signature can be
checked by P2, it is possible for P1 to send P2 the signature if it verifies it and
it’s valid. This will not affect security at all.

2

2

· m′ + k−1

· r · x2 · x1 = ρ · q + k−1

Correctness. Denoting k = k1·k2 and x = x1·x2, we have that c3 is an encryption
of s′ = ρ · q + k−1
· (m′ + r · x) (assuming that all
is done correctly). Thus, s = k−1
· s′ = k−1 · (m′ + rx) mod q. The above holds
as long as s′ < N and thus there is no modular reduction. Since ρ ∈ Zq2 we have
that s′ as generated by P2 is at most q3 +2q2. Thus, we only require N > q3 +q2,
meaning that a 2048-bit modulus (which is the minimal size required today in
any case) suffices for all commonly used Elliptic curve groups.

2

1

3.4 Efficiency and Experimental Results

We now analyze the theoretical complexity of our protocol, and describe its
concrete running time based on our implementation. This analysis relates to the
sequential version of our protocol.

Theoretical complexity – key-distribution protocol. Leaving aside the ZK proofs
for now, P1 carries out 2 Elliptic curve multiplications, 1 Paillier public-key
generation and 1 Paillier encryption, and P2 carries out two Elliptic curve mul-
tiplications. In addition, the parties run two discrete log proofs (each playing as

13

prover once and as verifier once), and P1 proves that N is a valid Paillier public
key and runs the PDL proof described in Section 3.2. The cost of these proofs
is as follows:

– Discrete log: the standard Schnorr zero-knowledge proof of knowledge for dis-
crete log requires a single multiplication by the prover and two by the verifier.
– Paillier public-key validity [22]: For a statistical error of 2−40 this costs 120
Paillier exponentiations by each of the prover and the verifier (but 40 of these
are “short”). In addition, the prover P1 carries out 120 GCD computations.
– PDL proof (Section 6): This proof, described in Protocol 6.1, also involves
running one executions of a range proof, and carrying out a small constant
number of operations. The cost of the proof overall is as follows:

• The instructions within Protocol 6.1 for the prover P1 are 1 Paillier de-
cryption and 1 Elliptic curve multiplication. The cost for the verifier P2
is 1 Paillier scalar multiplication and scalar addition, and 2 Elliptic curve
multiplications.

• As described in Section A, the range proof is dominated by 2t Paillier
encryptions for a statistical soundness error of 2−t. Setting t = 40, we
have 80 Paillier encryptions each.

Theoretical complexity – signing protocol. We now count the complexity of the
signing protocol. We count the number of Elliptic curve multiplications and
Paillier operations since this dominates the computation. As above, the zero-
knowledge proof of knowledge for discrete log requires a single multiplication by
the prover and two by the verifier, and ECDSA signature verification requires two
multiplications. Thus, P1 computes 7 Elliptic curve multiplications and a single
Paillier decryption. In contrast, P2 computes 5 Elliptic curve multiplications,
1 Paillier encryptions, 1 Paillier homomorphic scalar multiplication (which is a
single “short” exponentiation) and one Paillier homomorphic addition (which is
a single multiplication). Observe that unlike previous work, the length of the
Paillier key need only be 5 times the length of the order of the Elliptic curve
group (and not 8 times). Regarding rounds of communication, the protocol has
only four rounds of communication (two in each direction). Thus, the protocol
is very fast even on a slow network.

Implementation and running times. We implemented our protocol in C++ and
ran it on Azure between two Standard_DS3_v2 instances. Although these in-
stances have 4 cores each, we utilized a single core only with a single-thread
implementation (note that key generation can be easily parallelized, if desired).
We ran our implementation on the standard NIST curves P-256, P-384 and

P-521; the times for key generation and signing appear in Tables 1 and 2.

14

Curve Mean time Standard deviation
P-256
P-384
P-521

2435ms
2440ms
3535ms

142
124
166

Table 1. Running times for key generation (average over 20 executions)

Curve Mean time Standard deviation
P-256
P-384
P-521

36.8ms
47.11ms
78.19ms

7.30
1.96
1.45

Table 2. Running times for signing (average over 1,000 executions)

We remark that the size of the Paillier key has a great influence on the
running time. Thus, the fact that we only require N > q3 + q2 is very significant.

4 Proof of Security – Game-Based Definition

4.1 Definition of Security

We begin by presenting a game-based definition for the security of a digital
signature scheme π = (Gen, Sign, Verify). This will be used when proving the
security of our protocol and thus is presented for the sake of completeness and
a concrete reference.

EXPERIMENT 4.1 (Expt-SignA,π(1n))

1. (vk, sk) ← Gen(1n).
2. (m∗, σ∗) ← ASignsk(·)(1n, vk).
3. Let Q be the set of all m queried by A to its oracle. Then, the output of
the experiment equals 1 if and only if m∗ /∈ Q and Verifyvk(m∗, σ∗) = 1.

Standard security of digital signatures

Definition 4.2. A signature scheme π is existentially unforgeable under chosen-
message attacks if for every probabilistic polynomial-time oracle machine A there
exists a negligible function µ such that for every n,

Pr[Expt-SignA,π(1n) = 1] ≤ µ(n).

We now proceed to define security for a distributed signing protocol. We
define an experiment that captures concurrent signing executions under the as-
sumption that if an abort occurs, then all executions immediately abort. We call
this concurrent executions with instantaneous global abort. This trivially implies
security when the signing protocol is run sequentially between two parties, since
any abort will imply no later executions.

15

We define an experiment Expt-DistSignb

A,Π in which we consider A controlling
party Pb in protocol Π for two-party signature generation. Let Πb(·, ·) be a
stateful oracle that runs the instructions of honest party P3−b in protocol Π.
The adversary A can choose which messages will be signed, and can concurrently
interact with multiple instances of party P3−b to generate signatures. Note that
the oracle is defined so that distributed key generation is first run once, and then
multiple signing protocols can be executed concurrently.

Formally, A receives access to an oracle that receives two inputs: the first
input is a session identifier and the second is either an input or a next incoming
message. The oracle works as follows:

– Upon receiving a query of the form (0, 0) for the first time, the oracle initial-
izes a machine M running the instructions of party P3−b in the distributed
key generation part of protocol Π. If party P3−b sends the first message in
the key generation protocol, then this message is the oracle reply.

– Upon receiving a query of the form (0, m), if the key generation phase has
not been completed, then the oracle hands the machine M the message m
as its next incoming message and returns M ’s reply. (If the key generation
phase has completed, then the oracle returns ⊥.)

– If a query of the form (sid, m) is received where sid ̸= 0, but the key gener-

ation phase with M has not completed, then the oracle returns ⊥.

– If a query (sid, m) is received and the key generation phase has completed
and this is the first oracle query with this identifier sid, then the oracle in-
vokes a new machine Msid running the instructions of party P3−b in protocol
Π with session identifier sid and input message m to be signed. The machine
Msid is initialized with the key share and any state stored by M at the end
of the key generation phase. If party P3−b sends the first message in the
signing protocol, then this message is the oracle reply.

– If a query (sid, m) is received and the key generation phase has completed
and this is not the first oracle query with this identifier sid, then the oracle
hands Msid the incoming message m and returns the next message sent
by Msid. If Msid concludes, then the output obtained by Msid is returned.
– If any query (sid, m) results in Msid sending abort, then the oracle returns

abort and halts (stopping all executions).

The experiment for defining security is formalized by simply providing A who
controls party Pb with oracle access to Πb. Adversary A “wins” if it can forge
a signature on a message not queried in the oracle queries. Observe that A can
run multiple executions of the signing protocol concurrently. We remark that
we have considered only a single signing key; the extension to multiple different
signing keys is straightforward and we therefore omit it. (This is due to the fact
since signing keys are independent, one can easily simulate all executions with
other keys.)

16

EXPERIMENT 4.3 (Expt-DistSignb
Let π = (Gen, Sign, Verify) be a digital signature scheme.

A,Π (1n))

1. (m∗, σ∗) ← AΠb(·,·)(1n).
2. Let Q be the set of all inputs m such that (sid, m) was queried by A to
its oracle as the first query with identifier sid ̸= 0. Then, the output of
the experiment equals 1 if and only if m∗ /∈ Q and Verifyvk(m∗, σ∗) = 1,
where vk is the verification key output by P3−b from the key generation
phase, and Verify is as specified in π.

Security experiment for secure digital signature protocol

Definition 4.4. A protocol Π is a secure two-party protocol for distributed sig-
nature generation for π if for every probabilistic polynomial-time oracle machine
A and every b ∈ {1, 2}, there exists a negligible function µ such that for every n,
Pr[Expt-DistSignb

A,Π (1n) = 1] ≤ µ(n).

4.2 Proof of Security

In this section, we prove that Π comprised of Protocols 3.1 and 3.2 for key
generation and signing, respectively, constitutes a secure two-party protocol for
distributed signature generation of ECDSA.

Theorem 4.5. Assume that the Paillier encryption scheme is indistinguish-
able under chosen-plaintext attacks, and that ECDSA is existentially-unforgeable
under a chosen message attack. Then, Protocols 3.1 and 3.2 constitute a se-
cure two-party protocol for distributed signature generation of ECDSA, in the
(Fcom-zk, Fzk)-hybrid model, with concurrent executions with instantaneous global
abort.

Proof. We prove the security of the protocol in the (Fcom-zk, Fzk) hybrid model
for the relation RDL, for the setting of concurrent executions with instanta-
neous global abort. Thus, if the commitment and zero-knowledge protocols are
UC-secure, then the output in the hybrid and real protocols is computationally
indistinguishable under concurrent executions. This means that a proof that A
can break the protocol with some probability ϵ in the hybrid model implies that
it can break the real protocol with probability at most ϵ±µ(n) for some negligible
function µ, under concurrent executions, as required. Likewise, if the commit-
ment and zero-knowledge protocols are secure for the stand-alone model as in [7],
then the sequential composition theorem of [7] implies that when the protocol
is run sequentially, the output in the hybrid and real models is computationally
indistinguishable. Thus, the proof implies security for the real protocol under
sequential composition in this case. We will discuss this further in Section 4.3.
We now proceed to the proof.

We separately prove security for the case of a corrupted P1 and a cor-
rupted P2. Our proof works by showing that, for any adversary A attacking
the protocol, we construct an adversary S who forges an ECDSA signature in

17

Experiment 4.1 with probability that is negligibly close to the probability that A
forges a signature in Experiment 4.3. Formally, we prove that if Paillier has in-
distinguishable encryptions under chosen-plaintext attacks, then for every PPT
algorithm A and every b ∈ {1, 2} there exists a PPT algorithm S and a negligible
function µ such that for every n,

(cid:12)
(cid:12)Pr[Expt-SignS,π(1n) = 1] − Pr[Expt-DistSignb
(cid:12)

A,Π (1n) = 1]

(cid:12)
(cid:12)
(cid:12) ≤ µ(n),

(1)

where Π denotes Protocols 3.1 and 3.2, and π denotes the ECDSA signature
scheme. Proving (1) suffices, since by the assumption in the theorem that ECDSA
is secure, we have that there exists a negligible function µ′ such that for every
n, Pr[Expt-SignS,π(1n) = 1] ≤ µ′(n). Combining this with (1), we conclude
that Pr[Expt-DistSignb
A,Π (1n) = 1] ≤ µ(n) + µ′(n) and thus Π is secure by
Definition 4.4. We prove (1) separately for b = 1 and b = 2.

Proof of (1) for b = 1 – corrupted P1: Let A be a probabilistic polynomial-
time adversary in Expt-DistSign1
A,Π (n); we construct a probabilistic polynomial-
time adversary S for Expt-SignS,π(n). The adversary S essentially simulates the
execution for A, as described in the intuition behind the security of the protocol.
Formally:

1. In Expt-Sign, adversary S receives (1n, Q), where Q is the public verification

key for ECDSA.

2. S invokes A on input 1n and simulates oracle Π for A in Expt-DistSign,

answering as described in the following steps:
(a) S replies ⊥ to all queries (sid, ·) to Π by A before the key-generation
subprotocol is concluded. S replies ⊥ to all queries from A before it
queries (0, 0).

(b) After A sends (0, 0) to Π, adversary S receives (0, m1) which is P1’s first
message in the key generation subprotocol (any other query is ignored).
S computes the oracle reply as follows:

i. S parses m1 into the form (com-prove, 1, Q1, x1) that P1 sends to

F RDL

com-zk in the hybrid model.

ii. S verifies that Q1 = x1 · G. If yes, then it computes Q2 = (x1)−1 · Q
(using the value Q received as the verification key in experiment
Expt-Sign and the value x1 from A’s prove message); if no, then S
just chooses a random Q2.

iii. S sets the oracle reply of Π to be (proof, 2, Q2) and internally hands

this to A (as if sent by F RDL

).
(c) The next message of the form (0, m2) received by S is processed as

zk

follows:

i. S parses m2 into the form (decom-proof, sid∥1) as A intends to send

to F RDL

com-zk.

ii. The next messages of the form (0, mi) received by S are processed as
part of the zero-knowledge proofs that pk ∈ LP and (ckey, pk, Q1) ∈
LP DL. S verifies these proofs by running the honest verifier. (Any

18

message of the form (0, m∗) received following the number of mes-
sages in the zero-knowledge proof is ignored.)

iii. If Q1 ̸= x1 · G or S rejects either of the zero-knowledge proofs or
ckey /∈ Z∗
N 2 or N = pk is not of the appropriate length, then S
simulates an abort and the experiment concludes (since the honest
P2 no longer participates in the protocol and so all calls to Πb are
ignored). S does not output anything in this case since no verification
key vk is output by P2 in this case.
If S did not abort (and in particular Q1 = x1 ·G and S accepted both
proofs), then it stores N = pk and (x1, Q, ckey), and the distributed
key generation phase is completed.

(d) Upon receiving a query of the form (sid, m) where sid is a new session
identifier, S queries its signing oracle in experiment Expt-Sign with m
and receives back a signature (r, s). Using the ECDSA verification pro-
cedure, S computes the Elliptic curve point R. (Observe that the ECDSA
verification works by constructing a point R and then verifying that this
defines the same r as in the signature.) Then, queries received by S from
A with identifier sid are processed as follows:

i. The first message (sid, m1) is processed by first parsing the message
m1 as (com-prove, sid∥1, R1, k1). If R1 = k1 · G then S sets R2 =
k−1
· R; else it chooses R2 at random. S sets the oracle reply to A
1
to be the message (proof, sid∥2, R2) that A expects to receive. (Note
that the value R2 is computed using R from the ECDSA signature
and k1 as sent by A.)

ii. The second message (sid, m2) is processed by parsing the message
m2 as (decom-proof, sid∥1) from A. If R1 ̸= k1 · G then S simulates
P2 aborting and the experiment concludes (since the honest P2 no
longer participates in any executions of the protocol and so all calls
to Πb are ignored).
Otherwise, S chooses a random ρ ← Zq2 , computes the ciphertext
c3 ← Encpk([k1 · s mod q] + ρ · q), where s is the value from the
signature received from Fecdsa, and sets the oracle reply to A to
be c3.

3. Whenever A halts and outputs a pair (m∗, σ∗), adversary S outputs (m∗, σ∗)

and halts.

We proceed to prove that (1) holds. First, observe that the public-key gener-
ated by S in the simulation with A equals the public-key Q that it received in
experiment Expt-Sign. This is due to the fact that S defines Q2 = (x1)−1 · Q
when A is committed to Q1 = x1 · G. Thus, the public key is defined to be
x1 · Q2 = x1 · (x1)−1 · Q = Q, as required. We now proceed to show that A’s view
in the simulation by S in this corruption case is statistically close to its view
in a real execution of Protocols 3.1 and 3.2. (Note that the view is statistically
close when taking Fzk and Fcom-zk as ideal functionalities for the proof of RDL
provided by P2; the real protocol is computationally indistinguishable.) This
suffices since it implies that A outputs a pair (m∗, σ∗) that is a valid signature

19

with negligibly close probability in the simulation and in Expt-DistSign (other-
wise, the views can be distinguished by just verifying if the output signature is
correct relative to the public key). Since the public key in the simulation is the
same public key that S receives in Expt-Sign, a valid forgery generated by A in
Expt-DistSign constitutes a valid forgery by S in Expt-Sign. Thus, (1) follows.

In order to see that the view of A in the simulation of the key generation
phase is statistically close to its view in a real execution of Protocol 3.1 (as in
Expt-DistSign), note that the only difference between the simulation by A and a
real execution with an honest P2 is the way that Q2 is generated: P2 chooses a
random x2 and computes Q2 ← x2 · G, whereas S computes Q2 ← (x1)−1 · Q,
where Q is the public verification key received by S in Expt-Sign. We stress that
in all other messages and checks, S behaves exactly as P2 (note that the zero-
knowledge proof of knowledge of the discrete log of Q2 is simulated by S, but in
the Fzk, Fcom-zk-hybrid model this is identical). Now, since Q is chosen randomly,
it follows that the distributions over x2 · G and (x1)−1 · Q are identical.

Before proceeding, we note that if P2 does not abort then the public-key
defined in both a real execution and the simulation by S equals x1 · Q2 = Q.
In addition, we can assume that N defines a valid Paillier key (as defined for
language LP ), that Q1 = x1 · G, x1 = Decsk(ckey) and x1 ∈ Zq. This follows
from the soundness of the zero-knowledge proofs; if any of these do not hold
then S in the simulation (and P2 in the real protocol) would abort, except with
negligible probability.

1

In order to see that the view of A in the simulation of the signing phase is sta-
tistically close to its view in a real execution of Protocol 3.2 (as in Expt-DistSign),
note that the only difference between the view of A in a real execution and in the
simulation is the way that c3 is chosen. Specifically, R2 is distributed identically
in both cases due to the fact that R is randomly generated by Fecdsa in the
signature generation and thus k−1
· R has the same distribution as k2 · G (this
is exactly the same as in the key generation phase with Q). The zero-knowledge
proofs and verifications are also identically distributed in the Fzk, Fcom-zk-hybrid
model. Thus, the only difference is c3: in the simulation it is an encryption
of [k1 · s mod q] + ρ · q, whereas in a real execution it is an encryption of
· (m′ + rx) + ρ · q, where ρ ∈ Zq2 is random (we stress that all addi-
s′ = k−1
tions here are over the integers and not mod q, except for where it is explicitly
stated in the protocol description). We stress that the distribution of s′ in a
real execution is as above, as long as the Paillier key is valid and as long as
ckey = Encpk(x1) where Q1 = x1 · G. As discussed above, these properties are
guaranteed by the soundness of the zero-knowledge proofs in the key-generation
phase, and thus the probability that this doesn’t hold is negligible.

2

We therefore prove that A’s view is indistinguishable by showing that despite
this difference, the values are actually statistically close. In order to see this,
first observe that by the definition of ECDSA signing, s = k−1 · (m′ + rx) =
k−1
· (m′ + rx) = k1 · s mod q, implying that
1
there exists some ℓ ∈ N with 0 ≤ ℓ < q such that k−1
2 ·(m′ +rx) = k1 ·s+ℓ·q. The
reason that ℓ is bound between 0 and q is that in the protocol the only operations

· (m + rx) mod q. Thus, k−1

· k−1
2

2

20

without a modular reduction are the multiplication of [k−1
· r · x2 mod q] by x1,
and the addition of [k−1
· m′ mod q]. This cannot increase the result by more
than q2. Therefore, the difference between the real execution and simulation with
S is:

2

2

1. Real: the ciphertext c3 encrypts [k1 · s mod q] + ℓ · q + ρ · q
2. Simulated: the ciphertext c3 encrypts [k1 · s mod q] + ρ · q

We show that for all k1, s, ℓ ∈ Zq, the above values are statistically close (for a
random choice of ρ ∈ Zq2). In order to see this, fix k1, s, ℓ, and let v be a value.
If v ̸= [k1 · s mod q] + ζ · q for some ζ, then neither the real or simulated values
can equal v. Else, if v = [k1 · s mod q] + ζ · q for some ζ, then there are three
cases:

1. Case ζ < ℓ: in this case, v can be obtained in the simulated execution for

ρ < ℓ, but can never be obtained in a real execution.

2. Case ζ > q2 − 1): in this case, v can be obtained in the real execution for

ρ ≥ q2 − 1 − ℓ, but can never be obtained in a simulated execution.

3. Case ℓ ≤ ζ < q2 − 1: in this case, v can be obtained in both the real and
simulated executions, with identical probability (observe that in both the
real and simulated executions, ρ is chosen uniformly in Zq2).

Recall that the statistical distance between two distributions X and Y over a
domain D is defined to be:

∆(X, Y ) = max
T ⊆D

(cid:12)
(cid:12)
(cid:12)Pr[X ∈ T ] − Pr[Y ∈ T ]

(cid:12)
(cid:12)
(cid:12)

Let X be the values generated in a real execution of the protocol and let Y
be the values generated in the simulation with S. Then, taking T to be set of
values v for which ζ < ℓ, we have that Pr[X ∈ T ] = 0 whereas Pr[Y ∈ T ] ≤
q
q (this holds since 0 ≤ ℓ < q and ρ ∈ Zq2). Thus, ∆(X, Y ) = 1
q2 = 1
q , which
is negligible. (Taking T to be the set of values v for which ζ > q2 − 1 would
give the same result and are both the maximum since any other values add no
difference.) We therefore conclude that the distributions over c3 in the real and
simulated executions are statistically close. This proves that (1) holds for the
case that b = 1.

Proof of (1) for b = 2 – corrupted P2: We follow the same strategy as for the
case that P1 is corrupted, which is to construct a simulator S that simulates
the view of A while interacting in experiment Expt-Sign. This simulation is easy
to construct and similar to the case that P1 is corrupted, with one difference.
Recall that the last message from P2 to P1 is an encryption c3. This ciphertext
may be maliciously constructed by A, and the simulator cannot detect this.
(Formally, there is no problem for S to decrypt, since as will be apparent below, it
generates the Paillier public key. However, this strategy will fail since in order to
prove computational indistinguishability it is necessary to carry out a reduction
to the security of Paillier, meaning that the simulation must be designed to

21

work without knowing the corresponding private key.) We solve this problem
by simply having S simulate P1 aborting at some random point. That is, S
chooses a random i ∈ {1, . . . , p(n) + 1} where p(n) is an upper bound on the
number of queries made by A to Π. If S chose correctly, then the simulation
p(n)+1 , this means
is fine. Now, since S’s choice of i is correct with probability
p(n)+1 (note that S can also choose
that S simulates A’s view with probability
i = p(n) + 1, which is correct if c3 is always constructed correctly). Thus, S
p(n)+1 times the
can forge a signature in Expt-Sign with probability at least
probability that A forges a signature in Expt-DistSign.

1

1

1

Let A be a probabilistic polynomial-time adversary; S proceeds as follows:

1. In Expt-Sign, adversary S receives (1n, Q), where Q is the public verification

key for ECDSA.

2. Let p(·) denote an upper bound on the number of queries that A makes to Π
in experiment Expt-DistSign. Then, S chooses a random i ∈ {1, . . . , p(n)+1}.
3. S invokes A on input 1n and simulates oracle Π for A in Expt-DistSign,

answering as described in the following steps:
(a) S replies ⊥ to all queries (sid, ·) to Π by A before the key-generation
subprotocol is concluded. S replies ⊥ to all queries from A before it
queries (0, 0).

(b) After A sends (0, 0) to Π, adversary S computes the oracle reply to be

(proof-receipt, 1) as A expects to receive.

(c) The next message of the form (0, m1) received by S (any other query is

ignored) is processed as follows:
i. S parses m1 into the form (prove, 2, Q2, x2) that P2 sends to F RDL
com-zk

in the hybrid model.

ii. S verifies that Q2 is a non-zero point on the curve and that Q2 =
x2 · G; if not, it simulates P1 aborting, and halts (there is no point
outputting anything since no verification key is output by P1 in this
case and so the output of Expt-DistSign is always 0).

iii. S generates a valid Paillier key-pair (pk, sk), computes ckey = Encpk(˜x1)

for a random ˜x1 ∈ (cid:8) q

3 , . . . , 2q

3

(cid:9).

iv. S sets the oracle response to A to be the message (decom-proof, 1, Q1),

where Q1 = (x2)−1 · Q for Q as received by S initially.

v. S runs the simulator for the zero-knowledge proof for the language
LP with input N = pk, and then runs the simulator for the zero-
knowledge proof LP DL with input (ckey, pk, Q1), with the residual
A as verifier.

S stores (x2, Q, ckey) and the key distribution phase is completed.
(d) Upon receiving a query of the form (sid, m) where sid is a new session
identifier, S computes the oracle reply to be (proof-receipt, sid∥1) as A
expects to receive, and hands it to A.
Next, S queries its signing oracle in experiment Expt-Sign with m and
receives back a signature (r, s). Using the ECDSA verification procedure,
S computes the Elliptic curve point R. Then, queries received by S from
A with identifier sid are processed as follows:

22

i. The first message (sid, m1) is processed by first parsing the message
m1 as (prove, sid∥2, R2, k2) that A sends to F RDL
. S verifies that
R2 = k2 · G and that R2 is a non-zero point on the curve; otherwise,
it simulates P1 aborting. S computes R1 = k−1
2 ·R and sets the oracle
reply to be (decom-proof, sid∥, R1) as if coming from F RDL

zk

com-zk.

ii. The second message (sid, m2) is processed by parsing m2 as c3. If
this is the ith call by A to the oracle Π, then S simulates P1 aborting
(and not answering any further oracle calls). Otherwise, it continues.
4. Whenever A halts and outputs a pair (m∗, σ∗), adversary S outputs (m∗, σ∗)

and halts.

As in the case that P1 is corrupted, the public-key generated by S in the simu-
lation with A equals the public-key Q that it received in experiment Expt-Sign.
Now, let j be the first call to oracle Π with (sid, c3) where c3 is such that
P1 does not obtain a valid signature (r, s) with respect to Q. Then, we argue
that if j = i, then the only difference between the distribution over A’s view
in a real execution and in the simulated execution by S is the ciphertext ckey
(cid:9) as implicitly defined by the value
and the possibility that x1 ∈ Zq \ (cid:8) q
3 , . . . , 2q
Q1. Specifically, in a real execution ckey = Encpk(x1) where Q1 = x1 · G and
(cid:9), whereas in the simulation ckey = Encpk(˜x1) for a random
x1 ∈ (cid:8) q
˜x1 ∈ (cid:8) q
(cid:9) that is independent of Q1 = x1 · G and Q1 is uniform in G
(meaning that x1 is uniform in Zq).3 Observe, however, that S does not use
the private-key for Paillier at all in the simulation. Thus, indistinguishability of
this simulation follows from a straightforward reduction to the indistinguisha-
bility of the encryption scheme, under chosen-plaintext attacks. Let A denote
the set (cid:8) q
(cid:9) and note that a randomly chosen x ∈ Zq is in the set A with
3 , . . . , 2q
probability 1/3.

3 , . . . , 2q
3 , . . . , 2q

3

3

3

3

This proves that

(cid:12)
(cid:12)Pr (cid:2)Expt-SignS,π(1n) = 1 | i = j ∧ x1 ∈ A(cid:3) − Pr[Expt-DistSign2

A,Π (1n) = 1](cid:12)

(cid:12) ≤ µ(n),

and so

Pr[Expt-DistSign2

A,Π (1n) = 1] ≤

Pr (cid:2)Expt-SignS,π(1n) = 1 ∧ i = j ∧ x1 ∈ A(cid:3)
Pr[i = j ∧ x1 ∈ A]

+ µ(n)

≤

Pr[Expt-SignS,π(1n) = 1]

1
3 ·

1
p(n)+1

+ µ(n)

where the second inequality holds because i is chosen independently of j, and
because Q is independent of Q2 and so Q1 is uniformly distributed in G. Thus,

Pr[Expt-SignS,π(1n) = 1] ≥

Pr[Expt-DistSign2

A,Π (1n) = 1]

3p(n) + 3

− µ(n).

3 As before, this is true in the Fzk, Fcom-zk-hybrid model; by using UC-secure proto-
cols for Fzk, Fcom-zk the result is computationally indistinguishable. There is also a
difference due to the fact that the zero-knowledge proof for LP DL is simulated and
not real; however, this is computationally indistinguishable.

23

This implies that if A forges a signature in Expt-DistSign2

A,Π with non-
negligible probability, then S forges a signature in Expt-SignS,π with non-negligible
probability, in contradiction to the assumed security of ECDSA.

Reduction slack and key size. The proof of Theorem 4.5 shows that an adversary
who successfully forges in the distributed ECDSA computation setting with some
probability ϵ can be converted into an adversary who successfully forges ECDSA
ϵ
p(n) , where p(n) is an upper bound
in the standard setting with probability
on the number of queries to the signing oracle. Thus, if we assume that the
probability of forging an ECDSA signature in time T is at most δ, then in the
distributed setting we have that the probability of forging a signature in time
approximately T is at most δ · p(n). This would imply that the key size should
be increased in the distributed setting in order to reduce the probability back
down to δ. One way of doing this, based on the fact that Elliptic-curve discrete
log provides κ-bit security for keys of length 2κ is to increase the size of the
key by 2t where t is an upper bound on the number of signature queries. For
example, if t = 230 (≈ one billion), then one should increase the key size by 60.
However, we stress that we do not know of any actual attack that enables the
attacker to succeed more in the distributed setting. Furthermore, under the ad-
hoc assumption of Section 5, the probability of forging in the distributed setting
is the same as in the standard setting. Thus, in practice, we do not feel that
larger keys are necessary.

4.3 Instantiating Fzk, Fcom-zk and Concurrent vs Sequential

Executions

Observe that our proof of Theorem 4.5 requires no rewinding, when proved in the
(Fzk, Fcom-zk)-hybrid mode. As such, our proof holds for the concurrent setting,
as defined in the game. However, if we instantiate the zero-knowledge proofs
using a random-oracle and via the Fiat-Shamir transform [14], then rewinding is
needed in order to extract the witness. This is not an issue in the key generation
phase, since this is only run once and before any signing; thus rewinding can
be carried out. However, zero-knowledge proofs of knowledge of discrete log are
proven in every signing interaction, and this means that a rewinding strategy
will not work when run concurrently.

When considering sequential composition of the protocol, each zero-knowledge
proof is run by itself, and the modular sequential composition theorem of [7] can
be used to replace the instances of Fzk with the Fiat-Shamir based proofs.

Thus, it is either possible to run the protocol sequentially only (which can
make sense in some settings). However, if concurrent security is desired, then a
zero-knowledge proof of knowledge with straight-line extraction (and straight-
line rewinding) is needed. This can be achieved efficiently in two ways:

Using the knowledge of exponent assumption. The KEA1 knowledge of exponent
problem, as formalized in [1], states that for a given generator G of a group G

24

and random element A ∈ G, if an adversary can produce a pair (B, C) where
B = w · G and C = w · A, then there exists an extractor that can obtain w from
the adversary. This can be used by a party to prove that it knows the discrete
log w of B to base G as follows. The verifier chooses a random A ∈ G and sends
it to the prover, who computes C = w · A and proves that (G, A, B, C) is a
Diffie-Hellman tuple (using Fiat-Shamir applied to the standard Sigma protocol
for this language). Formally, the proof is for the relation

RDH = {((G, G, A, B, C), w) | B = w · G ∧ C = w · A} .

We remark that in the random-oracle model, the Fiat-Shamir transform applied
to the Sigma protocol can be simulated without rewinding (by just “program-
ming” the random oracle), and the extraction is achieved by the KEA1 assump-
tion. We stress that the soundness of the proof guarantees that the same w was
used to generate B and C (i.e., B = w · G and C = w · A), ensuring that the
KEA1 assumption can be applied. This method for achieving zero knowledge
without rewinding is from [30].

Using UC-secure ZK without rewinding. In [15], an efficient transformation from
Sigma protocols to zero-knowledge with non-rewinding extraction was given in
the random-oracle model. The transformation requires some parallel repetition of
the proof, but the additional expense is relatively mild (the example parameters
provided in [15] are such that the proof needs to be repeated approximately 10
times to get a good balance of completeness and extraction). Since this proof is
needed in every execution, this would add some cost to the signing protocol (but
the Paillier operations would still dominate). Note also that these proofs could
be precomputed, since they are independent of the message being signed.

5 Simulation Proof of Security (With a New Assumption)

There are advantages to full simulation based proofs of security (via the real/ideal
paradigm). Observe that we proved the security of our protocol in Section 4 by
simulating the view of A in a real execution. In fact, our simulation can be used
to prove the security of our protocol under the real/ideal world paradigm except
for exactly one place. Recall that when P2 is corrupted, S cannot determine if
c3 is correctly constructed or not. Thus, S simply chooses a random point and
“hopes” that the jth value c3 generated is the first badly constructed c3. This
suffices for a game-based definition, but it does not suffice for simulation-based
security definitions. Thus, in order to be able to prove our protocol using simula-
tion, we need to be able to determine if c3 was constructed correctly. Of course,
we could add zero-knowledge proofs to the protocol, but these would be very
expensive. Alternatively, we consider a rather ad-hoc but plausible assumption
that suffices. The assumption is formalized below, along with a full proof of
security under this assumption.

25

5.1 Definition of Security

We show how to securely compute the functionality Fecdsa. The functionality
is defined with two functions: key generation and signing. The key generation is
called once, and then any arbitrary number of signing operations can be carried
out with the generated key. The functionality is defined in Figure 5.1.

FIGURE 5.1 (The ECDSA Functionality Fecdsa)

Functionality Fecdsa works with parties P1 and P2, as follows:

– Upon receiving KeyGen(G, G, q) from both P1 and P2, where G is an

Elliptic-curve group of order q with generator G:
1. Generate an ECDSA key pair (Q, x) by choosing a random x ← Z∗
q
and computing Q = x · G. Choose a hash function Hq : {0, 1}∗ →
{0, 1}⌊log |q|⌋, and store (G, g, q, Hq, x).
2. Send Q (and Hq) to both P1 and P2.
3. Ignore future calls to KeyGen.

– Upon receiving Sign(sid, m) from both P1 and P2, if KeyGen was already
called and sid has not been previously used, compute an ECDSA signature
(r, s) on m, and send it to both P1 and P2. (Specifically, choose a random
k ← Z∗
q , compute (rx, ry) = k · G and r = rx mod q. Finally, compute
s ← k−1(Hq(m) + rx) and output (r, s).)

We defined Fecdsa using Elliptic curve (additive) group notation, although

all of our protocols work for any prime-order group.

Security in the presence of malicious adversaries. We prove security according
to the standard simulation paradigm with the real/ideal model [7,20] (with secu-
rity preserved under sequential composition). We prove security in the presence
of malicious adversaries and static corruptions. As is standard for the case of
no honest majority, we consider security with abort meaning that a corrupted
party can learn output while the honest party does not. In our definition of func-
tionalities, we describe the instructions of the trusted party. Since we consider
security with abort, the corrupted party receives output first and then sends
either continue or abort to the trusted party to determine whether or not the
honest party also receives output.

We remark that when all of the zero-knowledge proofs and commitments are
UC secure [8], then our protocol can also be proven secure in this framework,
guaranteeing security under concurrent composition (and not just sequential
composition), but only when all executions halt as soon as any single execution
aborts.

26

5.2 Background and New Assumption

In Section 4 , we proved the security of our protocol under a game-based defini-
tion. In some sense, proving security via simulation-based definitions (following
the ideal/real model paradigm) is preferable. In particular, it guarantees security
under composition. Following our proof in Section 4.2 closely, one may observe
that S is essentially a simulator for an ideal functionality that securely com-
putes ECDSA. Indeed, S is invoked with a public-key, and can use its oracle in
Expt-Sign to obtain a signature on any value it wishes. This is very similar to
an ideal functionality that generates a public key and can be used to generate
signatures. The only problem with the simulation strategy used in Section 4.2
is that in the case that P2 is corrupted, S just guesses if c3 is correctly con-
structed. Needless to say, this is not allowed in a simulation-based proof. One
may be tempted to solve this problem by saying that since S generates the Pail-
lier key-pair (pk, sk) when playing P1, it can decrypt c3 and check if the value is
generated as expected. However, when trying to formally prove this, one needs
to show a reduction to the indistinguishability of the encryption scheme (since
the simulator does not know x1 and so cannot provide ckey = Encpk(x1)). In
this reduction, the simulator is given pk externally and does not know sk (see
the proof of the key generation subprotocol in Section 4.2). Thus, in this reduc-
tion, it is not possible to decrypt c3 and the appropriate distributions cannot be
generated.

We introduce a new assumption under which it is possible to prove the full
simulation-based security of Protocol 3.2 without any modifications. The as-
sumption is non-standard, but very plausible. Consider an adversary who is given
a Paillier encryption of a (high-entropy) secret value w; denote c = Encpk(w).
Then, the adversary can always randomize c to generate an encryption c′ of the
same w, but without anyone but itself and the secret-key owner knowing whether
c and c′ encrypt the same value. In addition, the adversary can always generate
an encryption c′ of a plaintext value that it knows but without knowing whether
c and c′ encrypt the same value. Now, consider a setting where an adversary is
given an oracle Oc(c′) that outputs 1 if and only if Decsk(c′) = Decsk(c), where
c = Encpk(w) is the challenge ciphertext, and the adversary’s task is to learn w.
Clearly, the adversary can use this oracle to try and guess the value encrypted in
c one at a time (just guess x′, compute c′ = Encpk(x′) and query Oc(c′)). How-
ever, since w has high entropy, this seems to be futile. Furthermore, it seems
that the oracle Oc cannot help in any other way.

Extending the above a further step, the adversary can generate any affine
function of w by choosing scalars α and β and computing c′ = α ⊙ (Encpk(β) ⊕ c)
= Encpk(α+β·w). Then, as before, A tries to output w given an oracle Oc(c′, α, β)
that outputs 1 if and only if Decsk(c′) = α + β · Decsk(c). The adversary can
actually use this oracle, and the fact that the modulus inside the encryption is
not q (for Paillier it is a much larger RSA modulus), in order to carry out a
binary search on w. In particular, given w, the adversary can check if w < q
2
by setting β = 1 and α = N − q
2 , where N is the modulus of the encryption.
In this case, if w < q
2 then the oracle will return 1 since equality holds over the

27

integers and thus modulo q. However, if w ≥ q
2 , then α + w ≥ N and so the
encrypted value will be reduced modulo N and equality will not hold modulo q.
Thus, the oracle will return 0. The adversary can proceed in a similar way and
learn w efficiently. However, observe that in the signing protocol, as soon as an
abort occurs, the parties do not participate further. Thus, we only need to be
able to simulate up to the first time that there is inequality in the call to the
oracle. Thus, we modify the oracle so that the first time that there is inequality,
it returns 0 and then does not respond to any more queries. This prevents the
adversary from learning anything significant from the fact that there are different
moduli, and in fact can only learn as long as each “guess” always gives equality.
In order to formally define a security experiment including such an oracle, one
must consider the task of the adversary. Since w must be a high-entropy random
value one cannot consider the standard indistinguishability game. Rather, one
could formalize a simple task where some w is randomly chosen and the adversary
is given (pk, Encpk(w)) and oracle access to O above (recall that O answers only
until it returns 0 for the first time, and it then halts), and its task is to output w
(in entirety). This is very plausible since without the oracle it is clearly hard, and
the oracle only answers queries (c′, α, β) by determining if “c′ encrypts α + β · x”,
which essentially gives a single guess on the value of w. However, requiring that
the adversary output the entire w turns out to not be very helpful for us. This
is due to the fact that w must maintain some property of secrecy. We therefore
extend this experiment by giving the adversary either (pk, f (w0), Encpk(w0)) or
(pk, f (w0), Encpk(w1)), where w0, w1 are random and f is a one-way function.
The adversary’s task is to guess which input type it received (with the input to
the one-way function equal to what is encrypted or independent of it), and it is
given the oracle O above to help it. Note that f may reveal some information
about w0 (since it is only a one-way function), but if f is somehow unrelated of
the encryption scheme, then it still seems that this should not help very much.
For our actual experiment, we will define the one-way function to be the
computation w0 · G in a group where the discrete log is hard. Observe that here
the one-way function is related to the discrete log problem over Elliptic curve
groups, whereas the encryption is Paillier and thus seems completely unrelated.
Thus, we conjecture that this problem is hard. Since we consider a group, the
equality that is actually checked by the oracle is modulo q, where q is the order
of the group.

Formal assumption definition. The above description leads to the following ex-
periment. Let G be a generator of a group G of order q. Consider the following
experiment with an adversary A, denoted ExptA(1n):

1. Generate a Paillier key pair (pk, sk).
2. Choose random w0, w1 ∈ Zq and compute Q = w0 · G.
3. Choose a random bit b ∈ {0, 1} and compute c = Encpk(wb).
4. Let b′ = AOc(·,·,·)(pk, c, Q), where Oc(c′, α, β) = 1 if and only if Decsk(c′) =

α + β · wb mod q and O halts after the first time it returns 0.

5. The output of the experiment is 1 if and only if b′ = b.

28

We define the following:

Definition 5.2. We say that the Paillier-EC assumption is hard if for every prob-
abilistic polynomial-time adversary A there exists a negligible function µ such
that Pr[ExptA(1n) = 1] ≤ 1

2 + µ(n).

The assumption in Definition 5.2 is rather ad-hoc and tailored to the problem
at hand. However, it is very plausible and enables us prove full simulation without
modifying the protocol.

5.3 Proof of Security

Under the above assumption, we are able to prove full simulation-based security
of our protocol. We show this now. We assume only that the Paillier-EC as-
sumption is hard, since this trivially implies that the Paillier encryption scheme
is indistinguishable under chosen-plaintext attacks.

Before stating the theorem, we note that the limitation of x1 ∈ (cid:8) q

(cid:9) is
a challenge here, since unlike in the game-based setting, we are “not allowed” to
succeed in the simulation with probability only 1
3 . This can be fixed by modifying
Fecdsa so that the adversary can choose Q2 and then Q is computed by the ideal
(cid:9) and setting Q = x1 · Q2. However,
functionality by choosing x1 ∈ (cid:8) q
for the sake of simplicity, we will prove the theorem under the assumption that
a tight range proof is used. Such proofs are described in [4], and although more
complicated and a bit slower than the proof described in Appendix A, this isn’t
very significant since it is used only in key generation.

3 , . . . , 2q

3 , . . . , 2q

3

3

Theorem 5.3. Assume that the Paillier-EC assumption is hard. Then, Pro-
tocol 3.2 (with a tight range proof for x1) securely computes Fecdsa in the
(Fzk, Fcom-zk)-hybrid model in the presence of a malicious static adversary (un-
der the full ideal/real definition for sequential composition).

Proof. We separately prove security for the case of a corrupted P1 and a cor-
rupted P2. Let A be an adversary who has corrupted P1; we construct a simu-
lator S. We separately show how to simulate the key generation and sign sub-
protocols.

Simulating key generation – corrupted P1: The intuition behind the simulation
of the key generation was already provided above; we therefore proceed directly
to the details.

1. Upon input KeyGen(G, G, q), simulator S sends KeyGen(G, G, q) to Fecdsa

and receives back Q.

2. S invokes A upon input KeyGen(G, G, q) and receives (com-prove, 1, Q1, x1)

as A intends to send to F RDL

.

zk

3. S verifies that Q1 = x1 · G. If yes, then it computes Q2 = (x1)−1 · Q (using
the value Q received from Fecdsa and x1 from A’s prove message); if no,
then S just chooses a random Q2.

29

4. S internally hands (proof, 2, Q2) to A as if sent by F RDL
5. S receives (decom-proof, sid∥1) as A intends to send to F RDL

zk

.
com-zk, and honestly

verifies the zero-knowledge proofs for languages LP and LP DL.

6. S simulates P2 aborting if Q1 ̸= x1 · G, if it did not accept both of the zero-

knowledge proofs, if ckey /∈ Z∗

N 2 or if the length of pk = N is not correct.

7. S sends continue to Fecdsa for P2 to receive output, and stores x1, Q, ckey.

We prove that the joint distribution of A’s view and P2’s output in the ideal
simulation is statistically close to in a real protocol execution. The main differ-
ence between the simulation by A and a real execution with an honest P2 is the
way that Q2 is generated: P2 chooses a random x2 and computes Q2 ← x2 · G,
whereas S computes Q2 ← (x1)−1 · Q. However, as we have already seen, since
Q is chosen randomly, the distributions over x2 · G and (x1)−1 · Q are iden-
tical. We stress that in all other messages and checks, S behaves in the same
way as P2 (note that the zero-knowledge proofs of Q2 is simulated by S, but in
the Fzk, Fcom-zk-hybrid model these is identical). Now, observe finally that if P2
does not abort then the public-key defined in both the ideal and real executions
equals x1 · Q2 = Q. Thus, the joint distributions over A’s view and P2’s output
are statistically close.

We remark that ckey is guaranteed to be a valid Paillier encryption of x1
where Q1 = x1 · G, except with negligible probability. This is guaranteed by
the zero-knowledge proofs for the languages LP and LP DL; we will use this fact
below.

Simulating signing – corrupted P1: The idea behind the security of the signing
subprotocol is that a corrupted P1 cannot do anything since all it does is partici-
pate in a “coin tossing” protocol to generate R and receives a ciphertext c3 from
P2. Since the coin-tossing subprotocol is simulatable, a simulator can make the
result equal the R used in a signature received from the trusted party computing
Fecdsa. Thus, the main challenge is in proving that a simulator can generate
the corrupted P1’s view of the decryption of c3, given only the signature (r, s)
from Fecdsa.

1. Upon input Sign(sid, m), simulator S sends Sign(sid, m) to Fecdsa and

receives back a signature (r, s).

2. Using the ECDSA verification procedure, S computes the point R.
3. S invokes A with input Sign(sid, m) and simulates the first three messages so
that the result is R. This follows the exact strategy as used in the simulation
of the key generation phase, as follows (in brief):
(a) S receives (com-prove, sid∥1, R1, k1) from A.
(b) If R1 = k1 · G then S sets R2 = k−1

· R; else it chooses R2 at random. S

1

hands A the message (proof, sid∥2, R2).

(c) S receives (decom-proof, sid∥1) from A. If R1 ̸= k1 · G then A simulates
P2 aborting and sends abort to the trusted party computing Fecdsa.
Otherwise, it continues.

30

4. S chooses a random ρ ← Zq2, computes c3 ← Encpk([k1 · s mod q] + ρ · q),
where s is the value from the signature received from Fecdsa, and internally
hands c3 to A.

1

The only difference between the view of A in a real execution and in the sim-
ulation is the way that c3 is chosen. Specifically, R2 is distributed identically
in both cases due to the fact that R is randomly generated by Fecdsa in the
signature generation and thus k−1
· R has the same distribution as k2 · G. The
zero-knowledge proofs and verifications are also identically distributed in the
Fzk, Fcom-zk-hybrid model. Thus, the only difference is c3: in the simulation it
is an encryption of [k1 · s mod q] + ρ · q, whereas in a real execution it is an
· (m′ + rx) + ρ · q, where ρ ∈ Zq2 is random (we stress
encryption of s′ = k−1
that all additions here are over the integers and not modq, except for where it
is explicitly stated in the protocol description). The fact that this is statistically
close has already been shown in the proof of Theorem 4.5. This completes the
proof of this simulation case.

2

Simulating key generation – corrupted P2: We now consider the case of a mali-
cious P2.

1. Upon input KeyGen(G, G, q), simulator S sends KeyGen(G, G, q) to Fecdsa

and receives back Q.

2. S generates a valid Paillier key-pair (pk, sk), computes ckey = Encpk(˜x1) for
a random ˜x1 ∈ Zq, and internally hands A the message (proof-receipt, 1) as
if sent by F RDL

com-zk, and the pair (pk, ckey) as if sent by P1.

3. S receives Q2 as A intends to send to P1, and (prove, 2, Q2, x2) as A intends

4. S verifies that Q2 is a non-zero point on the curve and that Q2 = x2 · G; if

not, it simulates P1 aborting and halts.

5. S computes Q1 = (x2)−1 · Q and hands A the message (decom-proof, 1, Q1)

to send to F RDL

.

zk

as if sent by F RDL

com-zk.

6. S runs the simulator for the zero-knowledge proof for the language LP with
input N = pk, and then runs the simulator for the zero-knowledge proof
LP DL with input (ckey, pk, Q1), with the residual A as verifier.
7. S sends continue to Fecdsa for P1 to receive output, and stores Q.

It is immediate that the distributions of A’s view in a real and ideal execution
are identical, except for ckey which equals Encpk(x1) where Q1 = x1 · G in a
real execution but equals Encpk(˜x1) for a random ˜x1 in the ideal simulation,
and except for the simulation of the zero-knowledge proofs of LP and LP DL.
The latter is indistinguishable from the zero-knowledge property of the proofs.
Regarding the former, observe that S does not use the private-key at all. Thus,
indistinguishability of this simulation follows from a straightforward reduction to
the indistinguishability of the encryption scheme, under chosen-plaintext attacks.
The fact that the joint view of the adversary A and the honest party P1 is
indistinguishable follows from the fact that the honest party always outputs
Q = x1 · Q2 = x2 · Q1 in a real protocol execution, where Q1 = x1 · G. In the

31

simulation, we have that Q1 = (x2)−1 · Q and thus x2 · Q1 = x2 · (x2)−1 · Q = Q,
exactly as in the real protocol execution.

Simulating signing – corrupted P2: The simulator for the signing phase works
as follows:

1. Upon input Sign(sid, m), simulator S sends Sign(sid, m) to Fecdsa and

receives back a signature (r, s).

2. Using the ECDSA verification procedure, S computes the point R.
3. S invokes A with input Sign(sid, m) and internally hands A the message

(proof-receipt, sid∥1) as if sent by F RDL

com-zk.

4. S receives R2 as A intends to send to P1, and (prove, sid||2, R2, k2) as A

intends to send to F RDL

.

zk

5. S verifies that R2 = k2 · G and that R2 is a non-zero point on the curve;

otherwise, it simulates P1 aborting.

6. S computes R1 ← k−1

2

A as if coming from F RDL

· R and internally hands (decom-proof, sid∥1, R1) to
com-zk.

7. S receives c3 from P1, decrypts it using sk and reduces the result modulo
q. S checks if the result equals (cid:0)k−1
(cid:1) · ˜x1 mod q, where
ckey = Encpk(˜x1) was as generated by P1 in the key-generation simulation.
If the result is equal, then S instructs the trusted party to provide the output
to the honest party (by sending continue). Otherwise, it instructs it to abort
(by sending abort).

· m′(cid:1) + (cid:0)k−1

· r · x2

2

2

It is clear that the distribution over the messages seen by P2 is identical, except
for the encryption of ckey which is computationally indistinguishable. Further-
more, there is exactly one value modulo q that P2 can use to generate c3, and
this is validated by S.4 Formally, we need to show that the output distributions
in the ideal model of both the key generation and signing phases are computa-
tionally indistinguishable from a real execution. In order to do this, we need to
reduce the security to that of Paillier encryption since this is the only difference.
However, in the simulation, S must have the private key sk in order to decrypt
c3 and verify that A (controlling P2) computed the correct value. Thus, it is not
possible to prove this via a standard reduction to the indistinguishability of the
encryption scheme. We therefore prove this under the Paillier-EC assumption.
We modify S to a simulator S ′ who is given an oracle Oc(c′, α, β) that out-
puts 1 if and only if Decsk(c′, α, β) = α + β · ˜x1 mod q. Observe that S ′ can
complete the simulation exactly as S as follows:
1. Compute α = k−1
2. Compute β = k−1
3. Query Oc(c3, α, β) and denote the response by b.
4. If b = 1 then S ′ continues like S when Decsk(c3) = (cid:0)k−1

· m′ mod q.
· r · x2 mod q.

· m′(cid:1)+(cid:0)k−1

· r · x2

(cid:1)·

2

2

2

2

˜x1 mod q.

4 Note that for every valid ECDSA signature (r, s), the pair (r, −s) is also a valid sig-
nature. Nevertheless, since the “smaller” of s, −s is always taken, the value is unique.

32

It is immediate that these checks by S and S ′ are equivalent. In order to see
(cid:1) · ˜x1 mod q is equivalent
this, observe that Decsk(c3) = (cid:0)k−1
to Decsk(c3) = α + β · ˜x1 mod q which is equivalent to Oc(c3, α, β) = 1. Thus, S
accepts if and only if S ′ accepts.

· m′(cid:1) + (cid:0)k−1

· r · x2

2

2

We now construct a distinguisher D for the Paillier-EC experiment ExptD,
such that if b = 0 then the distribution generated by D is exactly that generated
in a real execution whereas if b = 1 then the distribution is that generated by S ′.
D receives (pk, c, Q) and runs the simulation of the key generation (as described
above) with the given pk and Q. In addition, D sets ckey = c as received. Recall
that the simulation of this phase doesn’t require sk and so this works. Next,
D proceeds to simulate the signing phase, following the instructions of S ′. In
particular, it uses its oracle O in order to determine whether to send continue
or abort for P1 to receive output. Note that D never needs to query O after an
abort occurs; this is needed since O halts as soon as it returns 0 (inequality).

Observe that if b = 0 in the experiment then ckey = Encpk(w0) and Q = w0·G.
Setting x1 = w0, these values are distributed exactly as in a real execution.
Furthermore, P1 outputs a signature if and only if c3 encrypts s′ = k−1
· (m′ +
r · x1) mod q which is equivalent to (r, s) being a valid signature where s =
k−1
· s′ mod q. Thus, this is exactly a real execution. In contrast, if b = 1 in
1
the experiment then ckey = Encpk(w1) and Q = w0 · G. Setting x1 = w0 and
˜x1 = w1, we have that this is exactly the distribution generated by S ′. Thus,
by the Paillier-EC assumption, we have that the output distribution generated
by S ′ in the ideal model is computationally indistinguishable from the output
distribution in a real execution.

2

Since the output distributions of S and S ′ in the ideal model are identical,
as described, we conclude that the output distribution generated by S in the
ideal model is computationally indistinguishable from the output distribution in
a real execution, thus concluding the proof.

6 Zero-Knowledge Proof for the Language LP DL

In this section, we present an efficient construction of a zero-knowledge proof for
the language LP DL, defined by:

LP DL = {(c, pk, Q1, G, G, q) | ∃(x1, r)) : c = Encpk(x1; r) and Q1 = x1·G and x1 ∈ Zq}.

Intuitively, this relation means that c is a valid Paillier encryption of the discrete
log of Q1. The idea behind the proof is as follows. First, the prover P proves
that the value encrypted inside c is in Zq; this is a “range proof”. For simplicity
of implementation, we use a proof that guarantees that Decsk(c) ∈ Zq, but
is only complete if Decsk(c) ∈ (cid:8) q
(cid:9). This suffices since P1 can choose
3 , . . . , 2q
x1 ∈ (cid:8) q
(cid:9) and this does not affect security, as discussed in Section 3.2.
In addition, V chooses random values a and b, and computes an encryption of
α = a · x1 + b using the homomorphic properties of Paillier encryption on the
input ciphertext c, and sends it to P . In addition, V locally computes Q′ =
a · Q1 + b · G. The key observation is that if Q1 = x1 · G where x1 = Decsk(c),

3 , . . . , 2q

3

3

33

then Q′ = (a·x1 +b)·G = α·G, and so P can decrypt the Paillier encryption sent
by V to get α and can compute Q′ = α · G. However, if c is not an encryption of
x1 where x1 = Decsk(c), then P will obtain α = a · ˜x + b for some ˜x ̸= x1, since
that will be the value encrypted in the Paillier encryption that V sends to P . In
this case, V will only accept if P can send the correct Q′ = a · x1 + b. However,
f (x) = a · x + b is an information-theoretic MAC, and thus P can only guess
a · x1 + b given a · ˜x + b with negligible probability. (Note that the computation
of f is over the integers, unlike standard information-theoretic MACs which are
computed over a finite field. However, by taking large enough a, b, this is good
enough. For this reason, we take a ∈ Zq and b ∈ Zq2 .) Zero knowledge is achieved
by having V first commit to a, b, enabling the simulator to extract these values
before sending Q′. Clearly, given a, b, the simulator can generate the correct Q′,
even without knowing x1 or the Paillier secret key.

PROTOCOL 6.1 (Zero-Knowledge Proof for the Language LP DL)

Inputs: The joint statement is (c, pk, Q1, G, G, q), and the prover has a
(cid:9). (Recall that the proof is that
3 , . . . , 2q

witness (x1, sk) with x1 ∈ (cid:8) q
x1 = Decsk(c) and Q1 = x1 · G and x1 ∈ Zq.)

3

The Protocol:

1. V chooses a random a ← Zq and b ← Z
q2 and computes c′ =
(a ⊙ c) ⊕ Encpk(b; r) for a random r ∈ Z∗
N (verifying explicitly that
gcd(r, N ) = 1), and c′′ = commit(a, b). V sends (c′, c′′) to P . Mean-
while, V computes Q′ = a · Q1 + b · G.

2. P receives (c′, c′′) from V , decrypts it to obtain α = Decsk(c′), and

computes ˆQ = α · G. P sends ˆc = commit( ˆQ) to V .

3. V decommits c′′, revealing (a, b).
4. P checks that α = a · x1 + b (over the integers). If not, it aborts. Else,

it decommits ˆc revealing ˆQ.

5. Range-ZK proof: In parallel to the above, P proves in zero knowledge

that x1 ∈ Zq, using the proof described in Appendix A.

V ’s output: V accepts if and only if it accepts the range proof and ˆQ = Q′.

Theorem 6.2. Let N > 2q2+q. Then, Protocol 6.1 is a zero-knowledge proof for
the language LP DL in the Fcom-hybrid model, with completeness 1 for
x1 ∈ (cid:8) q

(cid:9) and with soundness error 2/q + 2−t.

3 , . . . , 2q

3

Proof. We prove completeness, soundness and zero knowledge. Completeness
follows from the fact that when N > 2q2 + q there is no reduction modulo N
in the Paillier computation and thus P obtains the correct value when decrypt-
ing c′. Furthermore, the range zero-knowledge proof has completeness 1 as long as
x1 ∈ (cid:8) q

(cid:9). We now proceed to the other properties.

3 , . . . , 2q

3

Soundness. Let x1 = Decsk(c). We consider two cases:

34

1. Case 1 – x1 /∈ Zq: The soundness of the range proof of Step 5 guarantees

that V will reject in this case except with probability 2−t.

2. Case 2 – x1 ∈ Zq but Q1 ̸= x1 · G: We claim that even an all-powerful
cheating P ∗ cannot cause V to accept with probability greater than 2/q, in
the Fcom-hybrid model. In order to see this, observe that V accepts only if
P ∗ commits to ˆQ = a · Q1 + b · G in Step 2.
P ∗ receives c′ and can decrypt to obtain α = a · x1 + b. Let y ∈ Zq be
such that Q1 = y · G; for this case, y ̸= x1. Then, V only accepts if P ∗ can
compute β = a · y + b mod q; to be more exact, P must have committed to
ˆQ = a · Q1 + b · G = a · (y · G) + b · G = [a · y + b mod q] · G. (Note that
although P commits to ˆQ, since it is all-powerful it can compute its discrete
log. Thus, if ˆQ = Q′ then P can obtain β = a · y + b mod q.)
Intuitively, P ∗ cannot succeed since V computes a type of information-
theoretic MAC; it is not standard since the computation is over the integers.
Formally, assume that P ∗ succeeds. This implies that it obtains α = a·x1 +b
and β = a · y + b mod q. Now, P can compute a = α−β
x1−y mod q in order to
obtain a. Since a ∈ Zq, we have that this is the same value as a over the
integers. Next, P ∗ can compute b = α − a · x1. Thus, if P ∗ succeeds, then it
obtains (a, b) ∈ Zq × Zq2.
Consider the following experiment, denoted Expt1:

(a) P ∗ outputs x1, y
(b) Values a ← Zq and b ← Zq2 are chosen uniformly, and α =

a · x1 + b is computed.

(c) P ∗ is given α and outputs (a′, b′).
(d) P ∗ succeeds if and only if a′ = a and b′ = b.

By what we have seen above, if P ∗ succeeds in computing β that causes V
to accept, then P ∗ succeeds in this experiment. Thus, it suffices to show that
P ∗ can succeed in this experiment with probability at most 2/q. We denote
Expt1P ∗ = 1 if P ∗ succeeds; using this notation, we wish to prove that

Pr (cid:2)Expt1

P ∗ = 1(cid:3) ≤

2
q

.

We now modify the experiment to the following one, denoted Expt2:

(a) P ∗ outputs x1, y
(b) Values a ← Zq and b ← Zq2 are chosen uniformly, and a value

α ← Z2q2 is chosen uniformly.
(c) P ∗ is given α and outputs (a′, b′).
(d) P ∗ succeeds if and only if a′ = a and b′ = b.

Observe that in Expt1, it holds that α ∈ Z2q2 , because a, x1 ∈ Zq and b ∈ Zq2
(we know that x1 ∈ Zq by this case). Thus, the values α in both experiments
are from the same range.
Now, we claim that

Pr (cid:2)Expt2

P ∗ = 1(cid:3) ≥

1

2q2 · Pr (cid:2)Expt1

P ∗ = 1(cid:3) .

35

This holds because with probability 1/2q2 the value α received by P ∗ in
Expt2 is such that α = a · x1 + b. Noting now that

Pr (cid:2)Expt2

P ∗ = 1(cid:3) ≤

1
q3

because P ∗ receives no information whatsoever on (a, b) in Expt2. Combining
the above, we have

Pr (cid:2)Expt1

P ∗ = 1(cid:3) ≤ 2q2 · Pr (cid:2)Expt2

P ∗ = 1(cid:3) ≤

2q2
q3 =

2
q

,

as required.

Zero knowledge. We construct a simulator S for a cheating verifier V ∗ in the
Fcom-hybrid model. S works as follows:

1. S invokes V ∗ and obtains (c′, c′′).
2. S sends a simulated commitment value ˆc to V ∗ (a receipt value from Fcom).
3. S receives the decommitment (a, b) from V ∗. S verifies that c′ = (a ⊙ c) ⊕ b.
If no, then it aborts. If yes, then it sends a decommitment of ˆc to ˆQ =
a · Q1 + b · G.

4. S simulates the range zero-knowledge proof.

V ∗’s view is identical to a real protocol execution, in the Fcom-hybrid model.
This is because if c′ = (a ⊙ c) ⊕ b then P would send the same ˆQ as sent by S.
This is the only difference between a real execution and the simulated one.

Observe that we only need the commitment to be equivocal; extraction is

actually not needed.

Acknowledgements

We would like to thank Valery Osheter from Unbound Security for the imple-
mentation of ECDSA protocol and for running the experiments, Claudio Orlandi
for pointing out some minor errors, and Cheng Yifan for pointing out errors in
the definition of the committed non-interactive zero-knowledge functionality and
the zero-knowledge range proof. We also thank Rosario Gennaro for pointing out
that the oracle in Section 5.2 needs to be defined so that it halts the first time
that it returns 0. Finally, we sincerely thank the Stanislaw Jarecki who as a ref-
eree contributed significantly to making the presentation much clearer and more
accurate.

References

1. M. Bellare and A. Palacio. The Knowledge-of-Exponent Assumptions and 3-
Round Zero-Knowledge Protocols. In CRYPTO 2004, Springer (LNCS 3152),
pages 273–289, 2004.

36

2. O. Blazy, C. Chevalier, D. Pointcheval and D. Vergnaud. Analysis and Improve-
ment of Lindell’s UC-Secure Commitment Schemes. In ACNS 2013, Springer
(LNCS 7954), pages 534–551, 2013.

3. D. Boneh, R. Gennaro and S. Goldfeder. Using Level-1 Homomorphic Encryp-
tion to Improve Threshold DSA Signatures for Bitcoin Wallet Security. In LAT-
INCRYPT 2017.

4. F. Boudot: Efficient Proofs that a Committed Number Lies in an Interval. In

EUROCRYPT 2000, Springer (LNCS 1807), pages 431–444, 2000.

5. C. Boyd. Digital Multisignatures. In Cryptography and Coding, pages 241–246,

1986.

6. E. Brickell, D. Chaum, I. Damg˚ard,J. Van de Graaf. Gradual and Verifiable
Release of a Secret. In CRYPTO’87, Springer (LNCS 293), pages 156-–166,
1988.

7. R. Canetti. Security and Composition of Multiparty Cryptographic Protocols.

Journal of Cryptology, 13(1):143–202, 2000.

8. R. Canetti. Universally Composable Security: A New Paradigm for Crypto-
graphic Protocols. In 42nd FOCS, pages 136–145, 2001. Full version available
at http://eprint.iacr.org/2000/067.

9. A. Chan, Y. Frankel and Y. Tsiounis. Easy Come - Easy Go Divisible Cash. In

EUROCRYPT 1998, Springer (LNCS 1403), pages 561–575, 1998.

10. R.A. Croft and S.P. Harris. Public-Key Cryptography and Reusable Shared

Secrets. In Cryptography and Coding, pages 189–201, 1989.

11. I. Damg˚ard and M. Jurik. A Generalisation, a Simplification and Some Applica-
tions of Paillier’s Probabilistic Public-Key System. In Public Key Cryptography
2001, Springer (LNCS 1992), pages 119–136, 2001.

12. Y. Desmedt. Society and Group Oriented Cryptography: A New Concept. In

CRYPTO’87, Springer (LNCS 293), pages 120–127, 1988.

13. Y. Desmedt and Y. Frankel. Threshold Cryptosystems. In CRYPTO’89,

Springer (LNCS 435), pages 307–315, 1990.

14. A. Fiat and A. Shamir: How to Prove Yourself: Practical Solutions to Identifi-
cation and Signature Problems. In CRYPTO 1986, Springer (LNCS 263), pages
186–194, 1986.

15. M. Fischlin. Communication-Efficient Non-interactive Proofs of Knowledge with
Online Extractors. In CRYPTO 2005, Springer (LNCS 3621), pages 152–168,
2005.

16. E. Fujisaki. Improving Practical UC-Secure Commitments Based on the DDH

Assumption. In SCN 2016, Springer (LNCS 9841), pages 257–272, 2016.

17. R. Gennaro, S. Jarecki, H. Krawczyk and T. Rabin. Robust Threshold DSS
Signatures. In EUROCRYPT’96, Springer (LNCS 1070), pages 354-–371, 1996.
18. R. Gennaro, S. Goldfeder and A. Narayanan: Threshold-Optimal DSA/ECDSA
Signatures and an Application to Bitcoin Wallet Security. In ACNS 2016, pages
156–174, 2016.

19. S. Goldfeder. Personal communication, December 2016.
20. O. Goldreich. Foundations of Cryptography: Volume 2 – Basic Applications.

Cambridge University Press, 2004.

21. C. Hazay and Y. Lindell. Efficient Secure Two-Party Protocols: Techniques and

Constructions. Springer, November 2010.

22. C. Hazay, G.L. Mikkelsen, T. Rabin and T. Toft. Efficient RSA Key Generation
and Threshold Paillier in the Two-Party Setting. In CT-RSA 2012, Springer
(LNCS 7178), pages 313–331, 2012. See http://eprint.iacr.org/2011/494 for
the full version.

37

23. J. Katz and Y. Lindell. Introduction to Modern Cryptography, 3rd Edition.

Chapman and Hall/CRC Press, 2020.

24. Y. Lindell: Highly-Efficient Universally-Composable Commitments Based on the
DDH Assumption. In EUROCRYPT 2011, Springer (LNCS 6632), pages 446–
466, 2011.

25. H. Lipmaa. On Diophantine Complexity and Statistical Zero-Knowledge Argu-
ments. In ASIACRYPT 2003, Springer (LNCS 2894), pages 398–415, 2003.
26. P.D. MacKenzie and M.K. Reiter. Two-party generation of DSA signatures. In-
ternational Journal of Information Security, 2(3-4):218–239, 2004. An extended
abstract appeared at CRYPTO 2001.

27. P. Paillier. Cryptosystems Based on Composite Degree Residuosity Classes. In

EUROCRYPT’99, Springer (LNCS 1592), pages 223–238, 1999.

28. C.P. Schnorr. Efficient Identification and Signatures for Smart Cards. In

CRYPTO 1989, Springer (LNCS 435), pages 239–252, 1990.

29. V. Shoup. Practical Threshold Signatures. In EUROCRYPT 2000, Springer

(LNCS 1807), pages 207–220, 2000.
30. V. Shoup. Private communication, 2019.
31. V. Shoup and R. Gennaro. Securing Threshold Cryptosystems against Chosen
Ciphertext Attack. In EUROCRYPT 1998, Springer (LNCS 1403), pages 1–16,
1998.

32. Porticor, www.porticor.com.
33. Dyadic Security, www.dyadicsec.com.
34. Sepior, www.sepior.com.

A Zero-Knowledge Range Proof

3

3 , . . . , 2q

For the sake of completenesss, in this appendix we present the ZK-proof that
x ∈ (cid:8) q
(cid:9) where c = Encpk(x). The value sid is a unique session identifier
obtained from the application. Our proof is based on the proof described [4,
Section 1.2.2], with adaptations as required for our setting here. The proof that
we use proves for x ∈ {0, . . . , ⌊ q
3 ⌋.
Stated differently, the input is x ∈ {0, . . . , ℓ} and the proof guarantees that
x ∈ [−ℓ, 2ℓ]. In order to use this proof, we begin by subtracting q
3 from x.
(cid:9) and soundness for
This suffices since we need completeness for x ∈ (cid:8) q
x ∈ Zq, and the proof that we use works with completeness for x ∈ (cid:8)0, . . . , q
(cid:9)
and soundness for x ∈ (cid:8)− q

3 ⌋} that it is in the range (cid:2)− q

(cid:3). Let ℓ = ⌊ q

3 , . . . , 2q

3 , 2q

(cid:9).

3

3

3

3 , . . . , 2q

3

– Input: The prover P has input (c, x, r) where c = Encpk(x; r) and the Paillier
key-pair (N, ϕ(N )); the verifier V has input c and the Paillier public key N .
Both parties have q and ℓ = ⌊ q
Both parties have a parameter t = 40.
– The protocol: P computes x ← x− q

3 , and both P and V compute c ← c⊖ q
3
(with the latter operation being the homomorphic property of Paillier to
subtract the constant q
1. V ’s first message: V chooses a random e ← {0, 1}t, computes com =

3 ⌋.

3 ).

commit(e, sid) and sends com to P . Denote e = e1, . . . , et.

2. P ’s first message:

38

(a) P chooses random w1

1, . . . , wt

1 ← {ℓ, . . . , 2ℓ} and computes wi

2 =

wi

1 − ℓ for every i = 1, . . . , t.

(b) For every i = 1, . . . , t, P switches the values of wi

1 and wi

2 with

probability 1/2 (independently for each i).

(c) For every i = 1, . . . , t, P computes ci
2), where ri

1 = Encpk(wi
2 =
2 ← ZN are the randomness used in Paillier

1) and ci

1; ri

1, ri

2; ri
Encpk(wi
encryption.
(d) P sends c1

2 . . . , ct
3. V ’s second message: Upon receiving c1

2 to V .

1, c1

1, ct

com, revealing (e, sid) to P .

1, c1

2 . . . , ct

1, ct

2, V decommits to

4. P ’s second message: For i = 1, . . . , t:
1, wi

(a) If ei = 0 then P sets zi = (wi
1, ri
(b) If ei = 1 then P sets zi as follows. Let j ∈ {1, 2} be the unique value
j, r ·

j ∈ {ℓ, . . . , 2ℓ}. Then, P sets zi = (j, x + wi

2, ri

2).

of j such that x + wi
ri
j mod N ).

(c) P sends z1, . . . , zt to V .

– V ’s output: V parses zi appropriately according to the value of ei. Then:

For i = 1, . . . , t:
1. If ei = 0 then V checks that ci

and that one of wi
where zi = (wi

1, ri
2. If ei = 1 then V checks that c ⊕ ci

1, wi

1, wi
2, ri

1 = Encpk(wi

2; ri
2)
2 ∈ {ℓ, . . . , 2ℓ} while the other is in {0, . . . , ℓ},
2).

2 = Encpk(wi

1) and ci

1; ri

j = Encpk(wi; ri) and wi ∈ {ℓ, . . . , 2ℓ},

where zi = (j, wi, ri).

V outputs 1 if and only if all of the checks pass.

Security. We sketch the proof here (for x and c, after having subtracted q

3 ):

– Completeness (for x ∈ {0, . . . , ℓ}): As long as there exists a j ∈ {1, 2}
j ∈ {ℓ, . . . , 2ℓ}, for every i, it is clear that V will accept. In
i are chosen

such that x + wi
order to see why this holds, observe that by the way w1
we have w1
i ∈ {ℓ, . . . , 2ℓ} and w2
There are two cases. If x + w1
x + w1
Since x + w2
x + w2

i ∈ {0, . . . , ℓ}.
i < 2ℓ then since x + w1

i ≤ 2ℓ (since both 0 ≤ x ≤ ℓ and 0 ≤ w2

i ∈ {ℓ, . . . , 2ℓ}. In contrast, if x + w1

i ≥ ℓ we have
i − ℓ ≥ ℓ.
i ≤ ℓ), it follows that

i ≥ 2ℓ, then w2

i ∈ {ℓ, . . . , 2ℓ}, as required.

i and w2

i = w1

i ≥ w1

1 and ci

1, ri
2 are correctly constructed and that wi

– Soundness (for x /∈ {−ℓ, . . . , 2ℓ}): Let c = Encpk(x) and assume that
x /∈ [−ℓ, 2ℓ] and so in particular x < −ℓ or x > 2ℓ. We need to prove
that V accepts with probability at most 2−t. Let P ∗ be the cheating prover.
For every i, if ei = 0 then V receives zi = (wi
2) and verifies
that ci
2 are in the correct
ranges. We now show that if these values are correctly constructed, then P ∗
cannot answer for ei = 1 without V rejecting. This suffices since P ∗ must
either provide correctly constructed values in which case V is convinced when
ei = 0 but rejects if ei = 1, or it must provide incorrect values in which case
V is convinced when ei = 1 but rejects if ei = 0. Recall that V ∗ accepts
for ei = 1 if and only if c ⊕ ci
j = Encpk(wi; ri) and wi ∈ {ℓ, . . . , 2ℓ} where
zi = (j, wi, ri). We consider the cases for x separately:

1, w2,i , ri
1, wi

39

1. Case 1 – (x < −ℓ): It is given that one of the w1

i values is in {0, . . . , ℓ}
i ∈ {0, . . . , ℓ}
i ∈ {ℓ, . . . , 2ℓ}. Since x < −ℓ it follows that x + w1
i < 0 and
i < ℓ. Thus, there does not exist a value j ∈ {1, 2} such that
j = Encpk(wi; ri) with wi ∈ {ℓ, . . . , 2ℓ}.

while the other is in {ℓ, . . . , 2ℓ}. For simplicity, assume w1
and w2
x + w2
c ⊕ ci

i , w2

2. Case 2 – (x > 2ℓ): As in the previous case, if x > 2ℓ, then x + w1

i > 2ℓ
i > 3ℓ. Thus, there does not exist a value j ∈ {1, 2} such that

and x + w2
c ⊕ ci

j = Encpk(wi; ri) with wi ∈ {ℓ, . . . , 2ℓ}.

This proves that for each i, the probability that V ∗ is convinced is at most 1
2 ,
as required.

1, ci

j = Encpk(wi; ri) ⊖ c and sets ci

– Zero knowledge: The simulator S extracts e from the commitment pro-
vided by the potentially cheating verifier V ∗. Then, for every i, if ei = 0
then S generates ci
2 like the honest prover does. In contrast, if ei = 1,
then S chooses a random j ∈ {1, 2}, a random wi ∈ {ℓ, . . . , 2ℓ} and a ran-
dom ri ∈ ZN . Then, S sets ci
3−j to be an
encryption of 0. Finally, S hands V ∗ all of the encryptions, receives back the
decommitment, and provides the answers appropriately.
We argue that the view generated by S is computationally indistinguishable
from the view of V ∗ in a real proof. In order to see this, first observe that the
ciphertexts are given in random order in a real proof. Next, observe that for
every i for which ei = 1, the ciphertext opened is an encryption of a value
that is uniformly distributed in {ℓ, . . . , 2ℓ}. This holds because wi
1 is uni-
formly distributed in {ℓ, . . . , 2ℓ} and wi
2 is uniformly distributed in {0, . . . , ℓ}.
This implies that x + wi
1 is uniformly distributed in {x + ℓ, . . . , x + 2ℓ} and
x + wi
2 is uniformly distributed in {x, . . . , x + ℓ}. Thus, the distribution over
the subset of values between ℓ and 2ℓ is uniform.

40



=== Content from github.com_fd21f54a_20250110_165742.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=fireblocks-labs%2Fzengo-lindell17-exploit-poc)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[fireblocks-labs](/fireblocks-labs)
/
**[zengo-lindell17-exploit-poc](/fireblocks-labs/zengo-lindell17-exploit-poc)**
Public

* [Notifications](/login?return_to=%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc) You must be signed in to change notification settings
* [Fork
  7](/login?return_to=%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc)
* [Star
   6](/login?return_to=%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc)

[6
stars](/fireblocks-labs/zengo-lindell17-exploit-poc/stargazers) [7
forks](/fireblocks-labs/zengo-lindell17-exploit-poc/forks) [Branches](/fireblocks-labs/zengo-lindell17-exploit-poc/branches) [Tags](/fireblocks-labs/zengo-lindell17-exploit-poc/tags) [Activity](/fireblocks-labs/zengo-lindell17-exploit-poc/activity)
 [Star](/login?return_to=%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc)

 [Notifications](/login?return_to=%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc) You must be signed in to change notification settings

* [Code](/fireblocks-labs/zengo-lindell17-exploit-poc)
* [Issues
  0](/fireblocks-labs/zengo-lindell17-exploit-poc/issues)
* [Pull requests
  0](/fireblocks-labs/zengo-lindell17-exploit-poc/pulls)
* [Actions](/fireblocks-labs/zengo-lindell17-exploit-poc/actions)
* [Projects
  0](/fireblocks-labs/zengo-lindell17-exploit-poc/projects)
* [Security](/fireblocks-labs/zengo-lindell17-exploit-poc/security)
* [Insights](/fireblocks-labs/zengo-lindell17-exploit-poc/pulse)

Additional navigation options

* [Code](/fireblocks-labs/zengo-lindell17-exploit-poc)
* [Issues](/fireblocks-labs/zengo-lindell17-exploit-poc/issues)
* [Pull requests](/fireblocks-labs/zengo-lindell17-exploit-poc/pulls)
* [Actions](/fireblocks-labs/zengo-lindell17-exploit-poc/actions)
* [Projects](/fireblocks-labs/zengo-lindell17-exploit-poc/projects)
* [Security](/fireblocks-labs/zengo-lindell17-exploit-poc/security)
* [Insights](/fireblocks-labs/zengo-lindell17-exploit-poc/pulse)

# fireblocks-labs/zengo-lindell17-exploit-poc

    main[Branches](/fireblocks-labs/zengo-lindell17-exploit-poc/branches)[Tags](/fireblocks-labs/zengo-lindell17-exploit-poc/tags)Go to fileCode
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit History[3 Commits](/fireblocks-labs/zengo-lindell17-exploit-poc/commits/main/) | | |
| [README.md](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/README.md "README.md") | | [README.md](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/README.md "README.md") |  |  |
| [gotham-city.zip](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/gotham-city.zip "gotham-city.zip") | | [gotham-city.zip](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/gotham-city.zip "gotham-city.zip") |  |  |
| [preview.gif](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/preview.gif "preview.gif") | | [preview.gif](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/preview.gif "preview.gif") |  |  |
| View all files | | |

## Repository files navigation

* README
# ZenGo Lindell17 Exploit PoC

This repo contains working exploit code that exfiltrates the private key share from a victim using ZenGo's Lindel17 MPC protocol implementation.

[![](/fireblocks-labs/zengo-lindell17-exploit-poc/raw/main/preview.gif)](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/preview.gif)

## Build and run

```
unzip gotham-city.zip
cd gotham-city/integration-tests
cargo test -- --nocapture
```

## Notable changes

The most interesting parts of the PoC are in the following files inside [gotham-city.zip](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/gotham-city.zip):

* [gotham-city/integration-tests/tests/ecdsa.rs](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/gotham-city/integration-tests/tests/ecdsa.rs)
* [gotham-city/two-party-ecdsa/src/party\_two.rs (in the `compute` function)](/fireblocks-labs/zengo-lindell17-exploit-poc/blob/main/gotham-city/two-party-ecdsa/src/party_two.rs#398)

## Affected Libraries

* <https://github.com/ZenGo-X/gotham-city> (server)
* <https://github.com/ZenGo-X/multi-party-ecdsa> (protocol)

The library was patched: <https://github.com/ZenGo-X/gotham-city/releases/tag/v1.0.0>

## About

No description, website, or topics provided.
### Resources

[Readme](#readme-ov-file)

[Activity](/fireblocks-labs/zengo-lindell17-exploit-poc/activity)
[Custom properties](/fireblocks-labs/zengo-lindell17-exploit-poc/custom-properties)
### Stars

[**6**
stars](/fireblocks-labs/zengo-lindell17-exploit-poc/stargazers)
### Watchers

[**2**
watching](/fireblocks-labs/zengo-lindell17-exploit-poc/watchers)
### Forks

[**7**
forks](/fireblocks-labs/zengo-lindell17-exploit-poc/forks)
[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fzengo-lindell17-exploit-poc&report=fireblocks-labs+%28user%29)

## [Releases](/fireblocks-labs/zengo-lindell17-exploit-poc/releases)

No releases published

## [Packages 0](/orgs/fireblocks-labs/packages?repo_name=zengo-lindell17-exploit-poc)

No packages published

## [Contributors 2](/fireblocks-labs/zengo-lindell17-exploit-poc/graphs/contributors)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_9697470e_20250110_165742.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=fireblocks-labs%2Fmpc-ecdsa-attacks-23)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[fireblocks-labs](/fireblocks-labs)
/
**[mpc-ecdsa-attacks-23](/fireblocks-labs/mpc-ecdsa-attacks-23)**
Public

* [Notifications](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23) You must be signed in to change notification settings
* [Fork
  3](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)
* [Star
   17](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

[17
stars](/fireblocks-labs/mpc-ecdsa-attacks-23/stargazers) [3
forks](/fireblocks-labs/mpc-ecdsa-attacks-23/forks) [Branches](/fireblocks-labs/mpc-ecdsa-attacks-23/branches) [Tags](/fireblocks-labs/mpc-ecdsa-attacks-23/tags) [Activity](/fireblocks-labs/mpc-ecdsa-attacks-23/activity)
 [Star](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23)

 [Notifications](/login?return_to=%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23) You must be signed in to change notification settings

* [Code](/fireblocks-labs/mpc-ecdsa-attacks-23)
* [Issues
  1](/fireblocks-labs/mpc-ecdsa-attacks-23/issues)
* [Pull requests
  0](/fireblocks-labs/mpc-ecdsa-attacks-23/pulls)
* [Actions](/fireblocks-labs/mpc-ecdsa-attacks-23/actions)
* [Projects
  0](/fireblocks-labs/mpc-ecdsa-attacks-23/projects)
* [Security](/fireblocks-labs/mpc-ecdsa-attacks-23/security)
* [Insights](/fireblocks-labs/mpc-ecdsa-attacks-23/pulse)

Additional navigation options

* [Code](/fireblocks-labs/mpc-ecdsa-attacks-23)
* [Issues](/fireblocks-labs/mpc-ecdsa-attacks-23/issues)
* [Pull requests](/fireblocks-labs/mpc-ecdsa-attacks-23/pulls)
* [Actions](/fireblocks-labs/mpc-ecdsa-attacks-23/actions)
* [Projects](/fireblocks-labs/mpc-ecdsa-attacks-23/projects)
* [Security](/fireblocks-labs/mpc-ecdsa-attacks-23/security)
* [Insights](/fireblocks-labs/mpc-ecdsa-attacks-23/pulse)

# fireblocks-labs/mpc-ecdsa-attacks-23

    main[Branches](/fireblocks-labs/mpc-ecdsa-attacks-23/branches)[Tags](/fireblocks-labs/mpc-ecdsa-attacks-23/tags)Go to fileCode
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit History[3 Commits](/fireblocks-labs/mpc-ecdsa-attacks-23/commits/main/) | | |
| [2023-1234.pdf](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/2023-1234.pdf "2023-1234.pdf") | | [2023-1234.pdf](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/2023-1234.pdf "2023-1234.pdf") |  |  |
| [README.md](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/README.md "README.md") | | [README.md](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/README.md "README.md") |  |  |
| View all files | | |

## Repository files navigation

* README
# Practical Key-Extraction Attacks in Leading MPC Wallets (2023)

The most updated version of the paper can be found on eprint: <https://eprint.iacr.org/2023/1234>

An additional copy of the paper can be found in this repo: [2023-1234.pdf](/fireblocks-labs/mpc-ecdsa-attacks-23/blob/main/2023-1234.pdf)

## About

No description, website, or topics provided.
### Resources

[Readme](#readme-ov-file)

[Activity](/fireblocks-labs/mpc-ecdsa-attacks-23/activity)
[Custom properties](/fireblocks-labs/mpc-ecdsa-attacks-23/custom-properties)
### Stars

[**17**
stars](/fireblocks-labs/mpc-ecdsa-attacks-23/stargazers)
### Watchers

[**0**
watching](/fireblocks-labs/mpc-ecdsa-attacks-23/watchers)
### Forks

[**3**
forks](/fireblocks-labs/mpc-ecdsa-attacks-23/forks)
[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Ffireblocks-labs%2Fmpc-ecdsa-attacks-23&report=fireblocks-labs+%28user%29)

## [Releases](/fireblocks-labs/mpc-ecdsa-attacks-23/releases)

No releases published

## [Packages 0](/orgs/fireblocks-labs/packages?repo_name=mpc-ecdsa-attacks-23)

No packages published

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from www.fireblocks.com_278a99e7_20250110_165743.html ===


[Skip To Content](#main)

[Fireblocks](https://www.fireblocks.com)

Menu

* Platform
  + Back
    #### Platform

    ### Products

    - #### Treasury Management

      Manage and secure your digital asset treasury and trading operations.
    - #### Wallets as a Service

      Create secure MPC wallets at scale | Embedded Wallets and Direct Custody Wallets
    - #### Tokenization

      Securely mint, custody, and transfer tokenized assets and manage smart contracts.
    - #### Payments

      Suite of tools to accept, orchestrate, and settle digital asset payments.
  + ### Platform

    - #### Governance and Policy Engine

      Automate permissions, transaction rules, and approvals
    - #### Security

      Multi-layer key management, certifications, policies.
    - #### Staking

      Stake tokens and manage rewards across blockchains.
    - #### Compliance

      Automate detection and removal of high-risk transactions.
    - #### Fireblocks Network

      Simplify transfers and trading with trusted counterparties.
    - #### Off-Exchange

      Eliminate exchange counterparty risk
    - #### Flexible Deployment

      Cloud, Hybrid, On-Prem
    - #### DeFi

      Create and manage wallets for end users at scale.
    - #### Web3

      Automate permissions, transaction rules, and approvals.
    - #### Automation

      Eliminate manual operations in minutes[All Support and Integrations](/integrations/exchanges)
* Solutions
  + Back
    #### Solutions

    ### SOLUTIONS

    - #### Trading Firms
    - #### Fintechs and Exchanges
    - #### Financial Institutions
    - #### Web3 Companies
    - #### Blockchain Payments
    - #### Startups
  + ### ECOSYSTEM

    - #### Partners
    - #### Professional Services
    - #### Support
* Resources
  + Back
    #### Resources

    ###

    - #### SPARK
    - #### Blogs
    - #### Webinars
    - #### Customer Stories
    - #### White Papers and Guides
    - #### Fireblocks Academy
    - #### ETH Savings Calculator
  + ###
* [Developers](https://www.fireblocks.com/developers/)
* Company
  + Back
    #### Company

    ###

    - #### About Fireblocks
    - #### Executive Team
    - #### Culture
    - #### Careers
  + ###
* [Pricing](https://www.fireblocks.com/pricing/)
* [Login](https://console.fireblocks.io/)
* [Try in Sandbox](https://www.fireblocks.com/developer-sandbox-sign-up/)
* [Request Demo](https://www.fireblocks.com/#request-demo/)

![](/wp-content/themes/studio-simpatico/public/img/orange-blur.svg)
![](/wp-content/themes/studio-simpatico/public/img/blue-blur.svg)

August 9, 2023

[Knowledge Base](https://www.fireblocks.com/category/knowledge-base/)

# Lindell17 Abort Vulnerability [CVE-2023-33242]: Technical Report

[![Marketing Headshot](https://www.fireblocks.com/wp-content/uploads/2024/05/FB-user-profile.jpg)

Daniel Evans

Marketing](https://www.fireblocks.com/author/daniel-evans)

9 min. read
![](https://www.fireblocks.com/wp-content/uploads/2023/08/Fireblocks-BitForge-Tech-Lindell-Blog_2x-1024x572.jpg)

This vulnerability allows an attacker to extract a full private key from a wallet implementing Lindell17 2PC protocol, by extracting a single bit in every signature attempt (256 in total). Coinbase WaaS, Zengo and other libraries have been patched.

## Executive Summary

Fireblocks’ research team found a vulnerability in real-world deployments of the [Lindell17](https://eprint.iacr.org/2017/552.pdf) threshold-ECDSA protocol. The vulnerability was found at the interface between the protocol and the wider security infrastructure, and all security products based on Lindell17 are potentially affected. We found multiple wallet-as-a-service providers, retail wallets, and open source libraries that were vulnerable to this attack to varying degrees of exploitability.

The exploit originates from Lindell17 implementations deviating from the specification of the academic paper and ignoring or mishandling aborts in case of failed signatures. Assuming privileged access on the part of the attacker, the vulnerability can be exploited to exfiltrate the key after approximately 200 signature requests. The vulnerability has been proven to be practical and validated on popular open source libraries and some real-world systems.

Practical implementations of the protocol for wallets often encounter a difficult dilemma: either halt operations after a failed signature, which could potentially result in locked funds, or continue with the signing process, thereby risking the exposure of additional key bits with each signature.

The vulnerability was initially discovered in ZenGo wallet and then verified in the Coinbase Wallet as a Service (WaaS) library, with additional wallet providers and libraries impacted. It was also validated with a working POC in a common open source implementation of the protocol (link below). Both Coinbase and ZenGo have mitigated the issue promptly as part of our responsible disclosure process and assured us that they checked and no wallets were exploited.

## Vulnerability Risk Profile

The vulnerability enables full private key extraction, allowing attackers to steal all funds from the crypto wallet. However, it is an *asymmetric* vulnerability, meaning the attacker must corrupt a specific party to mount the attack (i.e., the parties are not indistinguishable in terms of the attack).

To elaborate, the Lindell17 protocol is typically employed for wallets that involve a wallet provider and an end user, with the underlying secret key distributed between the two. Additionally, there are two possible configurations for the wallet: either the wallet provider (Service) finalizes the signature, or the end user (Client) does so at the end of the protocol. The party tasked with finalizing the signature is the one at risk, and an attacker can exploit this vulnerability by compromising the counterparty.

**Case 1.** Server finalizes the signature

In this case, the attacker may exfiltrate the key by compromising the Client and sending malicious messages on its behalf. Specifically, the attacker may initiate two hundred transactions such that, in each signature session, the attacker crafts a different malicious message which will result in a valid signature *only if a targeted bit the Server’s secret share is equal to zero.*

Thus, depending on whether the Server finalizes the signature or not (the attacker obtains this information either because the signature does or doesn’t appear on the Blockchain, or the Server itself notifies the attacker), the attacker obtains a bit of the Server’s share. It eventually can recover the key in full after 256 signatures.

We should note that the above attack could be expedited if signature requests can be “blitzed” (rapidly initiated one after another), which is typically possible as the server is usually automated and doesn’t significantly limit the number of signatures.

**Case 2.** Client finalizes the signature

In the second case, by compromising the Server and executing the above attack in reverse, the attacker may extract the key in an analogous way.

It’s worth noting that there may be additional safeguards in place to limit the attack’s exploitability. For example, the signing of transactions might require multi-factor authentication from the user. Consequently, frequent authentication requests could raise suspicion, diminishing the efficiency of a rapid “blitz” attack. However, if the server remains compromised over an extended period, the attacker might opt for a slower-paced attack, reducing its detectability by users that might be willing to do a “retry” and just assume the system is not very stable rather than that they are being attacked.

## Recommended mitigation for clients

Note that the above attack can be identified by the server because of the failed signature. Namely, after the data-processing step, the server reconstructs a string that does not verify according to the ECDSA verification algorithm. This event should **never** happen unless the system is attacked (or it has a serious bug). We recommend tracking these events and distinguishing them from other abort events, e.g. time-outs.

If you are using the protocol as a self implementation or an open source of the protocol you should upgrade to a non vulnerable version or implement your own abort mitigation mechanism that would not allow an attacker to extract additional bits after the first failed transaction.

An alternative approach is to use a ZK proof for the client’s last message.

## A short introduction to the Lindell17 protocol

The Lindell17 protocol employs homomorphic encryption (specifically, Paillier encryption) for generating ECDSA signatures in the client-server model, where each party holds a share of the ECDSA secret key. For the purposes of this presentation, we’ll assume the server finalizes the signature. At its core, the protocol consists of the client computing a partial signature encrypted with the server’s Paillier public key and sending the resultant ciphertext to the server. In turn, the server finalizes the partial signature into a full signature by decrypting the ciphertext and performing some data processing.

![](https://www.fireblocks.com/wp-content/uploads/2023/08/A-short-introduction-to-the-Lindell17-protocol-1.png)
## Overview of the Attack

When deployed for security-oriented applications, special care must be taken for so-called *abort events*, i.e. what should the honest server do if it fails to finalize the signature? The paper does not describe an abort-handling mechanism and it explicitly instructs the signatories to terminate signing operations in such an event.

![](https://www.fireblocks.com/wp-content/uploads/2023/08/Overview-of-the-Attack.png)

We show that ignoring failed signatures leads to a vulnerable protocol which can be exploited  as follows by a corrupted client. Using the notation from the picture, the client calculates *C* such that *C* is an encryption of *sig\** only if the least significant bit (lsb) of *x* is zero and otherwise *C* is an encryption of a random number (if the lsb of *x* is one). Thus, when the server obtains *C*, the signature-generation process will terminate successfully only if the lsb of x is zero, and this information is inadvertently leaked to the attacker. Then, if signing operations are not terminated, this attack can be iterated to obtain the higher-order bits. By combining with brute-force techniques, the key can be recovered in full after roughly 200 signature attempts.

## Technical Attack Description

We recall that (standard) ECDSA signatures are calculated as follows:

**1.** Sample ephemeral key k

*(a random number between 1 and q, where q is an ECDSA constant)*

**2.** Calculate the public nonce r which is a function of k and public parameters

**3.** Set  s = (HASH(msg) + r x ) \* k^(-1) % q where msg is the message for signing and x is the ECDSA private key.

**4.** Output (r,s)

In the Lindell17 protocol, the secret material (i.e. the k and the x) are split between the two parties such that k = k1\*k2 and x = x1+x2 and each party holds the relevant secret (say the client holds k1, x1 and the server holds k2, x2)

Furthermore, after the parties calculate r,  the client is instructed to send the server the following value encrypted under the the server’s Paillier key (the clients calculates this value by homomorphically operating on Enc(x2)) :

C =  Enc(HASH(msg)+r\* x1 \* (k1^(-1) % q)+  x2 \*r \* (k1^(-1) % q))

Once the server receives C, it calculates s = k2^(-1)\*dec(C) \mod q  and outputs (r,s) **if it’s a valid signature.**

**Obtaining the LSB (least significant bit)**

To obtain the least significant bit, the client sets k1 = 2 and maliciously sets

C =  Enc(HASH(msg) + r\* x1 \* (k1^(-1) % q)+  x2 \* \rho \* (k1^(-1) % N))

Where N is the public key of the encryption scheme and \rho = r if r is odd and \rho = r + q otherwise. In the end of the signature process, the validity of the signature leaks the lsb.

**Iterating the attack to obtain the next bits**

Suppose that the malicious client already knows the i-1 least significant bits (i.e. y = x2 % 2^{i-1}). To obtain the least significant bit, the client sets k1 = 2^i  (the ith power of two) and maliciously sets

C =  Enc(HASH(msg) + r\* x1 \* (k1^(-1) % q)+  x2 \* \rho \* (k1^(-1) % N) + offset))

Where N and \rho are as above and offset = y\*rho\*((k1^(-1) % q) – (k1^(-1) % N)). In the end of the signature process, the validity of the signature leaks the i-th bit.

## Responsible Disclosure

We found the vulnerability in a single wallet provider in April 2023.

At the beginning of May 2023 we validated the vulnerability was affecting multiple wallets and libraries and initiated a 90-day responsible disclosure with multiple wallet providers that were found vulnerable.

On August 9th, 2023 we published our findings publicly and attached a CVE for this issue: CVE-2023-33242.

## Affected Open Source Libraries

* <https://github.com/coinbase/waas-sdk-react-native> – prior to version 1.0.0
* <https://github.com/ZenGo-X/gotham-city> / <https://github.com/ZenGo-X/multi-party-ecdsa> – prior to tag v1.0.0 (<https://github.com/ZenGo-X/gotham-city/releases/tag/v1.0.0>)

## Additional Links:

**POC:** <https://github.com/fireblocks-labs/zengo-lindell17-exploit-poc>

**CVE Link:** <https://www.cve.org/CVERecord?id=CVE-2023-33242>

**Academic paper (cryptography of the exploits):** <https://github.com/fireblocks-labs/mpc-ecdsa-attacks-23>

#### Share This Article

* [![](https://www.fireblocks.com/wp-content/themes/studio-simpatico/public/img/twitter.svg)
  Share on Twitter](https://twitter.com/intent/tweet?url=https%3A%2F%2Fwww.fireblocks.com%2Fblog%2Flindell17-abort-vulnerability-technical-report%2F)
* [![](https://www.fireblocks.com/wp-content/themes/studio-simpatico/public/img/linkedin.svg)
  Share on LinkedIn](https://www.linkedin.com/shareArticle?url=https%3A%2F%2Fwww.fireblocks.com%2Fblog%2Flindell17-abort-vulnerability-technical-report%2F)
* [![](https://www.fireblocks.com/wp-content/themes/studio-simpatico/public/img/facebook.svg)
  Share on Facebook](https://www.facebook.com/sharer/sharer.php?u=https%3A%2F%2Fwww.fireblocks.com%2Fblog%2Flindell17-abort-vulnerability-technical-report%2F)

#### Table of Contents

[Executive Summary](#h-executive-summary)[Vulnerability Risk Profile](#h-vulnerability-risk-profile)[Recommended mitigation for clients](#h-recommended-mitigation-for-clients)[A short introduction to the Lindell17 protocol](#h-a-short-introduction-to-the-lindell17-protocol)[Overview of the Attack](#h-overview-of-the-attack)[Technical Attack Description](#h-technical-attack-description)[Responsible Disclosure](#h-responsible-disclosure)[Affected Open Source Libraries](#h-affected-open-source-libraries)[Additional Links:](#h-additional-links)
#### Ready to get started?

Join the largest institutional players running their businesses with Fireblocks.

[Request Demo](/request-demo)

#### About Us

Fireblocks is an easy-to-use platform to create new blockchain based products, and manage day-to-day digital asset operations. Exchanges, banks, PSPs, lending desks, custodians, trading desks, and hedge funds can securely scale their digital asset operations through the Fireblocks Network and MPC-based Wallet Infrastructure. Fireblocks serves thousands of organizations in the financial, payments, and web3 space, has secured the transfer of over $6 trillion in digital assets and has a unique insurance policy that covers assets in storage & transit. Find out why CISOs and Ops Teams love Fireblocks at www.Fireblocks.com.

#### Topics

* Security

Get Started

* [Request Demo](https://www.fireblocks.com/request-demo)
* [Start Developing](https://www.fireblocks.com/developer-sandbox-sign-up/)

Close

###### Ready for a deeper dive?

# Get a Fireblocks Platform Demo

Find out how Fireblocks helps your digital asset business to grow fast and stay secure.

![g2 & 4.5/5 stars](https://www.fireblocks.com/wp-content/uploads/2024/10/g2-stars-1.svg)

[![Fireblocks](https://www.fireblocks.com/wp-content/themes/studio-simpatico/svgs/logo.svg)](https://www.fireblocks.com)

Fireblocks is an enterprise-grade platform delivering a secure infrastructure for moving, storing, and issuing digital assets. Fireblocks enables exchanges, custodians, banks, trading desks, and hedge funds to securely scale digital asset operations through patent-pending SGX & MPC technology.

[[email protected]](/cdn-cgi/l/email-protection#f1989f979eb197988394939d9e929a82df929e9c)

* [Twitter](https://twitter.com/FireblocksHQ)
* [LinkedIn](https://www.linkedin.com/company/fireblocks)
* [Facebook](https://www.facebook.com/pg/FireblocksHQ)

* Platform
  + [Treasury Management](https://www.fireblocks.com/platforms/treasury-management/)
  + [Wallet as a Service](https://www.fireblocks.com/platforms/wallet-as-a-service/)
  + [Tokenization](https://www.fireblocks.com/platforms/tokenization/)
  + [Payments](https://www.fireblocks.com/platforms/payments/)
  + [Governance & Policy Engine](https://www.fireblocks.com/platforms/governance-and-policy-engine/)
  + [Off Exchange](https://www.fireblocks.com/platforms/off-exchange/)
  + [Security](https://www.fireblocks.com/platforms/security/)
  + [Staking](https://www.fireblocks.com/platforms/staking/)
  + [Web3](https://www.fireblocks.com/platforms/web3/)
  + [Fireblocks Network](https://www.fireblocks.com/platforms/fireblocks-network/)
  + [Flexible Deployment](https://www.fireblocks.com/platforms/flexible-deployment/)
  + [Compliance](https://www.fireblocks.com/platforms/compliance/)
  + [DeFi](https://www.fireblocks.com/platforms/defi)
  + [Automation](https://www.fireblocks.com/platforms/automation/)
  + [Integrations](https://www.fireblocks.com/integrations/)
  + [How Fireblocks Compares](https://www.fireblocks.com/compare/)
* Solutions
  + [Trading Firms](https://www.fireblocks.com/use-case/trading-firms/)
  + [Fintechs and Exchanges](https://www.fireblocks.com/use-case/fintechs-and-exchanges/)
  + [Financial Institutions](https://www.fireblocks.com/use-case/financial-institutions/)
  + [Web3 Companies](https://www.fireblocks.com/use-case/web3-companies/)
  + [Blockchain Payments](https://www.fireblocks.com/use-case/blockchain-payments/)
  + [Startups](https://www.fireblocks.com/startups/)
* Ecosystem
  + [Partners](https://www.fireblocks.com/partners/)
  + [Professional Services](https://www.fireblocks.com/professional-services/)
  + [Support](https://www.fireblocks.com/global-platinum-support/)
* Company
  + [About](https://www.fireblocks.com/about/)
  + [Custody & Risk Principles](https://www.fireblocks.com/principles/)
  + [Executive Team](https://www.fireblocks.com/team/)
  + [Culture](https://www.fireblocks.com/careers/)
  + [Modern Slavery Statement](https://www.fireblocks.com/modern-slavery-statement/)
  + [Careers](https://www.fireblocks.com/careers/current-openings/)
* [Developers](https://developers.fireblocks.com)
* Blog & Resources
  + [SPARK](https://www.fireblocks.com/spark/)
  + [Blog](https://www.fireblocks.com/blog/)
  + [Webinars](https://www.fireblocks.com/webinars/)
  + [Customer Stories](https://www.fireblocks.com/customers/)
  + [White Papers and Guides](https://www.fireblocks.com/resources/)
  + [Fireblocks Academy](https://www.fireblocks.com/academy/)
  + [ETH Savings Calculator](https://www.fireblocks.com/eth-fees-calculator/)
  + [Glossary](https://www.fireblocks.com/glossary/)
  + [Secure Multi-Party Computation Framework](https://www.fireblocks.com/secure-multi-party-computation-framework/)
  + [Crypto Treasury Management 101](https://www.fireblocks.com/crypto-treasury-management-101/)
  + [Digital Asset Custody 101](https://www.fireblocks.com/digital-asset-custody/)
  + [Institutional DeFi 101](https://www.fireblocks.com/institutional-defi/)
  + [MPC 101](https://www.fireblocks.com/what-is-mpc/)
* [Pricing](https://www.fireblocks.com/pricing/)
* [Request Demo](https://www.fireblocks.com/request-demo/)
* [Bug Bounty](https://hackerone.com/fireblocks_mpc)
* [Login](https://console.fireblocks.io/)

Fireblocks © 2025 All Rights Reserved. Fireblocks LLC NMLS Registration Number: 2066055

[Privacy Policy](https://www.fireblocks.com/privacy-policy/)[Cookie Policy](https://www.fireblocks.com/fireblocks-cookie-policy/)Manage Cookies[Terms of Use](https://www.fireblocks.com/terms-of-use/)[Fireblocks LLC State Licenses](https://www.fireblocks.com/state-licenses/)
![](https://www.fireblocks.com/wp-content/uploads/2025/01/FB-Footer-Badges-Jan-2025.svg)


