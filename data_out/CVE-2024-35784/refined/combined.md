=== Content from git.kernel.org_caab5383_20250111_184200.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=b0ad381fa7690244802aed119b478b4bdafc31dd)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=b0ad381fa7690244802aed119b478b4bdafc31dd)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=b0ad381fa7690244802aed119b478b4bdafc31dd)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=b0ad381fa7690244802aed119b478b4bdafc31dd)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Josef Bacik <josef@toxicpanda.com> | 2024-02-12 11:56:02 -0500 |
| --- | --- | --- |
| committer | David Sterba <dsterba@suse.com> | 2024-02-19 11:20:00 +0100 |
| commit | [b0ad381fa7690244802aed119b478b4bdafc31dd](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=b0ad381fa7690244802aed119b478b4bdafc31dd) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=b0ad381fa7690244802aed119b478b4bdafc31dd)) | |
| tree | [e244c2a3c93ce542a60747f69d29ac80fdd85340](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=b0ad381fa7690244802aed119b478b4bdafc31dd) | |
| parent | [e42b9d8b9ea2672811285e6a7654887ff64d23f3](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=e42b9d8b9ea2672811285e6a7654887ff64d23f3) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=b0ad381fa7690244802aed119b478b4bdafc31dd&id2=e42b9d8b9ea2672811285e6a7654887ff64d23f3)) | |
| download | [linux-b0ad381fa7690244802aed119b478b4bdafc31dd.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-b0ad381fa7690244802aed119b478b4bdafc31dd.tar.gz) | |

btrfs: fix deadlock with fiemap and extent lockingWhile working on the patchset to remove extent locking I got a lockdep
splat with fiemap and pagefaulting with my new extent lock replacement
lock.
This deadlock exists with our normal code, we just don't have lockdep
annotations with the extent locking so we've never noticed it.
Since we're copying the fiemap extent to user space on every iteration
we have the chance of pagefaulting. Because we hold the extent lock for
the entire range we could mkwrite into a range in the file that we have
mmap'ed. This would deadlock with the following stack trace
[<0>] lock\_extent+0x28d/0x2f0
[<0>] btrfs\_page\_mkwrite+0x273/0x8a0
[<0>] do\_page\_mkwrite+0x50/0xb0
[<0>] do\_fault+0xc1/0x7b0
[<0>] \_\_handle\_mm\_fault+0x2fa/0x460
[<0>] handle\_mm\_fault+0xa4/0x330
[<0>] do\_user\_addr\_fault+0x1f4/0x800
[<0>] exc\_page\_fault+0x7c/0x1e0
[<0>] asm\_exc\_page\_fault+0x26/0x30
[<0>] rep\_movs\_alternative+0x33/0x70
[<0>] \_copy\_to\_user+0x49/0x70
[<0>] fiemap\_fill\_next\_extent+0xc8/0x120
[<0>] emit\_fiemap\_extent+0x4d/0xa0
[<0>] extent\_fiemap+0x7f8/0xad0
[<0>] btrfs\_fiemap+0x49/0x80
[<0>] \_\_x64\_sys\_ioctl+0x3e1/0xb50
[<0>] do\_syscall\_64+0x94/0x1a0
[<0>] entry\_SYSCALL\_64\_after\_hwframe+0x6e/0x76
I wrote an fstest to reproduce this deadlock without my replacement lock
and verified that the deadlock exists with our existing locking.
To fix this simply don't take the extent lock for the entire duration of
the fiemap. This is safe in general because we keep track of where we
are when we're searching the tree, so if an ordered extent updates in
the middle of our fiemap call we'll still emit the correct extents
because we know what offset we were on before.
The only place we maintain the lock is searching delalloc. Since the
delalloc stuff can change during writeback we want to lock the extent
range so we have a consistent view of delalloc at the time we're
checking to see if we need to set the delalloc flag.
With this patch applied we no longer deadlock with my testcase.
CC: stable@vger.kernel.org # 6.1+
Reviewed-by: Filipe Manana <fdmanana@suse.com>
Signed-off-by: Josef Bacik <josef@toxicpanda.com>
Reviewed-by: David Sterba <dsterba@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=b0ad381fa7690244802aed119b478b4bdafc31dd)

| -rw-r--r-- | [fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/btrfs/extent_io.c?id=b0ad381fa7690244802aed119b478b4bdafc31dd) | 62 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 45 insertions, 17 deletions

| diff --git a/fs/btrfs/extent\_io.c b/fs/btrfs/extent\_io.cindex a0ffd41c5cc19f..61d961a30dee2c 100644--- a/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=e42b9d8b9ea2672811285e6a7654887ff64d23f3)+++ b/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=b0ad381fa7690244802aed119b478b4bdafc31dd)@@ -2689,16 +2689,34 @@ static int fiemap\_process\_hole(struct btrfs\_inode \*inode, \* it beyond i\_size. \*/ while (cur\_offset < end && cur\_offset < i\_size) {+ struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end; u64 prealloc\_start;+ u64 lockstart;+ u64 lockend; u64 prealloc\_len = 0; bool delalloc; + lockstart = round\_down(cur\_offset, inode->root->fs\_info->sectorsize);+ lockend = round\_up(end, inode->root->fs\_info->sectorsize);++ /\*+ \* We are only locking for the delalloc range because that's the+ \* only thing that can change here. With fiemap we have a lock+ \* on the inode, so no buffered or direct writes can happen.+ \*+ \* However mmaps and normal page writeback will cause this to+ \* change arbitrarily. We have to lock the extent lock here to+ \* make sure that nobody messes with the tree while we're doing+ \* btrfs\_find\_delalloc\_in\_range.+ \*/+ lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, cur\_offset, end, delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);+ unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) break; @@ -2866,15 +2884,15 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, u64 start, u64 len) { const u64 ino = btrfs\_ino(inode);- struct extent\_state \*cached\_state = NULL; struct extent\_state \*delalloc\_cached\_state = NULL; struct btrfs\_path \*path; struct fiemap\_cache cache = { 0 }; struct btrfs\_backref\_share\_check\_ctx \*backref\_ctx; u64 last\_extent\_end; u64 prev\_extent\_end;- u64 lockstart;- u64 lockend;+ u64 range\_start;+ u64 range\_end;+ const u64 sectorsize = inode->root->fs\_info->sectorsize; bool stopped = false; int ret; @@ -2885,12 +2903,11 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, goto out; } - lockstart = round\_down(start, inode->root->fs\_info->sectorsize);- lockend = round\_up(start + len, inode->root->fs\_info->sectorsize);- prev\_extent\_end = lockstart;+ range\_start = round\_down(start, sectorsize);+ range\_end = round\_up(start + len, sectorsize);+ prev\_extent\_end = range\_start;  btrfs\_inode\_lock(inode, BTRFS\_ILOCK\_SHARED);- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state);  ret = fiemap\_find\_last\_extent\_offset(inode, path, &last\_extent\_end); if (ret < 0)@@ -2898,7 +2915,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, btrfs\_release\_path(path);  path->reada = READA\_FORWARD;- ret = fiemap\_search\_slot(inode, path, lockstart);+ ret = fiemap\_search\_slot(inode, path, range\_start); if (ret < 0) { goto out\_unlock; } else if (ret > 0) {@@ -2910,7 +2927,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, goto check\_eof\_delalloc; } - while (prev\_extent\_end < lockend) {+ while (prev\_extent\_end < range\_end) { struct extent\_buffer \*leaf = path->nodes[0]; struct btrfs\_file\_extent\_item \*ei; struct btrfs\_key key;@@ -2933,19 +2950,19 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, \* The first iteration can leave us at an extent item that ends \* before our range's start. Move to the next item. \*/- if (extent\_end <= lockstart)+ if (extent\_end <= range\_start) goto next\_item;  backref\_ctx->curr\_leaf\_bytenr = leaf->start;  /\* We have in implicit hole (NO\_HOLES feature enabled). \*/ if (prev\_extent\_end < key.offset) {- const u64 range\_end = min(key.offset, lockend) - 1;+ const u64 hole\_end = min(key.offset, range\_end) - 1;  ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx, 0, 0, 0,- prev\_extent\_end, range\_end);+ prev\_extent\_end, hole\_end); if (ret < 0) { goto out\_unlock; } else if (ret > 0) {@@ -2955,7 +2972,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, }  /\* We've reached the end of the fiemap range, stop. \*/- if (key.offset >= lockend) {+ if (key.offset >= range\_end) { stopped = true; break; }@@ -3049,29 +3066,41 @@ check\_eof\_delalloc: btrfs\_free\_path(path); path = NULL; - if (!stopped && prev\_extent\_end < lockend) {+ if (!stopped && prev\_extent\_end < range\_end) { ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx,- 0, 0, 0, prev\_extent\_end, lockend - 1);+ 0, 0, 0, prev\_extent\_end, range\_end - 1); if (ret < 0) goto out\_unlock;- prev\_extent\_end = lockend;+ prev\_extent\_end = range\_end; }  if (cache.cached && cache.offset + cache.len >= last\_extent\_end) { const u64 i\_size = i\_size\_read(&inode->vfs\_inode);  if (prev\_extent\_end < i\_size) {+ struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end;+ u64 lockstart;+ u64 lockend; bool delalloc; + lockstart = round\_down(prev\_extent\_end, sectorsize);+ lockend = round\_up(i\_size, sectorsize);++ /\*+ \* See the comment in fiemap\_process\_hole as to why+ \* we're doing the locking here.+ \*/+ lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, prev\_extent\_end, i\_size - 1, &delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);+ unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) cache.flags |= FIEMAP\_EXTENT\_LAST; } else {@@ -3082,7 +3111,6 @@ check\_eof\_delalloc: ret = emit\_last\_fiemap\_cache(fieinfo, &cache);  out\_unlock:- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); btrfs\_inode\_unlock(inode, BTRFS\_ILOCK\_SHARED); out: free\_extent\_state(delalloc\_cached\_state); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 18:40:37 +0000



=== Content from git.kernel.org_0237eafb_20250111_184159.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Josef Bacik <josef@toxicpanda.com> | 2024-02-12 11:56:02 -0500 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-04-03 15:11:42 +0200 |
| commit | [89bca7fe6382d61e88c67a0b0e7bce315986fb8b](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)) | |
| tree | [b2c4d39c66c4ff54e6ad905b4844d8a4790d9593](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b) | |
| parent | [a825ce9181e65a7729b0f8041f9210962b6e8cd0](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=a825ce9181e65a7729b0f8041f9210962b6e8cd0) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b&id2=a825ce9181e65a7729b0f8041f9210962b6e8cd0)) | |
| download | [linux-89bca7fe6382d61e88c67a0b0e7bce315986fb8b.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-89bca7fe6382d61e88c67a0b0e7bce315986fb8b.tar.gz) | |

btrfs: fix deadlock with fiemap and extent lockingcommit b0ad381fa7690244802aed119b478b4bdafc31dd upstream.
While working on the patchset to remove extent locking I got a lockdep
splat with fiemap and pagefaulting with my new extent lock replacement
lock.
This deadlock exists with our normal code, we just don't have lockdep
annotations with the extent locking so we've never noticed it.
Since we're copying the fiemap extent to user space on every iteration
we have the chance of pagefaulting. Because we hold the extent lock for
the entire range we could mkwrite into a range in the file that we have
mmap'ed. This would deadlock with the following stack trace
[<0>] lock\_extent+0x28d/0x2f0
[<0>] btrfs\_page\_mkwrite+0x273/0x8a0
[<0>] do\_page\_mkwrite+0x50/0xb0
[<0>] do\_fault+0xc1/0x7b0
[<0>] \_\_handle\_mm\_fault+0x2fa/0x460
[<0>] handle\_mm\_fault+0xa4/0x330
[<0>] do\_user\_addr\_fault+0x1f4/0x800
[<0>] exc\_page\_fault+0x7c/0x1e0
[<0>] asm\_exc\_page\_fault+0x26/0x30
[<0>] rep\_movs\_alternative+0x33/0x70
[<0>] \_copy\_to\_user+0x49/0x70
[<0>] fiemap\_fill\_next\_extent+0xc8/0x120
[<0>] emit\_fiemap\_extent+0x4d/0xa0
[<0>] extent\_fiemap+0x7f8/0xad0
[<0>] btrfs\_fiemap+0x49/0x80
[<0>] \_\_x64\_sys\_ioctl+0x3e1/0xb50
[<0>] do\_syscall\_64+0x94/0x1a0
[<0>] entry\_SYSCALL\_64\_after\_hwframe+0x6e/0x76
I wrote an fstest to reproduce this deadlock without my replacement lock
and verified that the deadlock exists with our existing locking.
To fix this simply don't take the extent lock for the entire duration of
the fiemap. This is safe in general because we keep track of where we
are when we're searching the tree, so if an ordered extent updates in
the middle of our fiemap call we'll still emit the correct extents
because we know what offset we were on before.
The only place we maintain the lock is searching delalloc. Since the
delalloc stuff can change during writeback we want to lock the extent
range so we have a consistent view of delalloc at the time we're
checking to see if we need to set the delalloc flag.
With this patch applied we no longer deadlock with my testcase.
CC: stable@vger.kernel.org # 6.1+
Reviewed-by: Filipe Manana <fdmanana@suse.com>
Signed-off-by: Josef Bacik <josef@toxicpanda.com>
Reviewed-by: David Sterba <dsterba@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)

| -rw-r--r-- | [fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/btrfs/extent_io.c?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b) | 62 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 45 insertions, 17 deletions

| diff --git a/fs/btrfs/extent\_io.c b/fs/btrfs/extent\_io.cindex eade0432bd9ceb..3f795f105a6459 100644--- a/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=a825ce9181e65a7729b0f8041f9210962b6e8cd0)+++ b/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=89bca7fe6382d61e88c67a0b0e7bce315986fb8b)@@ -2734,16 +2734,34 @@ static int fiemap\_process\_hole(struct btrfs\_inode \*inode, \* it beyond i\_size. \*/ while (cur\_offset < end && cur\_offset < i\_size) {+ struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end; u64 prealloc\_start;+ u64 lockstart;+ u64 lockend; u64 prealloc\_len = 0; bool delalloc; + lockstart = round\_down(cur\_offset, inode->root->fs\_info->sectorsize);+ lockend = round\_up(end, inode->root->fs\_info->sectorsize);++ /\*+ \* We are only locking for the delalloc range because that's the+ \* only thing that can change here. With fiemap we have a lock+ \* on the inode, so no buffered or direct writes can happen.+ \*+ \* However mmaps and normal page writeback will cause this to+ \* change arbitrarily. We have to lock the extent lock here to+ \* make sure that nobody messes with the tree while we're doing+ \* btrfs\_find\_delalloc\_in\_range.+ \*/+ lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, cur\_offset, end, delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);+ unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) break; @@ -2911,15 +2929,15 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, u64 start, u64 len) { const u64 ino = btrfs\_ino(inode);- struct extent\_state \*cached\_state = NULL; struct extent\_state \*delalloc\_cached\_state = NULL; struct btrfs\_path \*path; struct fiemap\_cache cache = { 0 }; struct btrfs\_backref\_share\_check\_ctx \*backref\_ctx; u64 last\_extent\_end; u64 prev\_extent\_end;- u64 lockstart;- u64 lockend;+ u64 range\_start;+ u64 range\_end;+ const u64 sectorsize = inode->root->fs\_info->sectorsize; bool stopped = false; int ret; @@ -2930,12 +2948,11 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, goto out; } - lockstart = round\_down(start, inode->root->fs\_info->sectorsize);- lockend = round\_up(start + len, inode->root->fs\_info->sectorsize);- prev\_extent\_end = lockstart;+ range\_start = round\_down(start, sectorsize);+ range\_end = round\_up(start + len, sectorsize);+ prev\_extent\_end = range\_start;  btrfs\_inode\_lock(inode, BTRFS\_ILOCK\_SHARED);- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state);  ret = fiemap\_find\_last\_extent\_offset(inode, path, &last\_extent\_end); if (ret < 0)@@ -2943,7 +2960,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, btrfs\_release\_path(path);  path->reada = READA\_FORWARD;- ret = fiemap\_search\_slot(inode, path, lockstart);+ ret = fiemap\_search\_slot(inode, path, range\_start); if (ret < 0) { goto out\_unlock; } else if (ret > 0) {@@ -2955,7 +2972,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, goto check\_eof\_delalloc; } - while (prev\_extent\_end < lockend) {+ while (prev\_extent\_end < range\_end) { struct extent\_buffer \*leaf = path->nodes[0]; struct btrfs\_file\_extent\_item \*ei; struct btrfs\_key key;@@ -2978,19 +2995,19 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, \* The first iteration can leave us at an extent item that ends \* before our range's start. Move to the next item. \*/- if (extent\_end <= lockstart)+ if (extent\_end <= range\_start) goto next\_item;  backref\_ctx->curr\_leaf\_bytenr = leaf->start;  /\* We have in implicit hole (NO\_HOLES feature enabled). \*/ if (prev\_extent\_end < key.offset) {- const u64 range\_end = min(key.offset, lockend) - 1;+ const u64 hole\_end = min(key.offset, range\_end) - 1;  ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx, 0, 0, 0,- prev\_extent\_end, range\_end);+ prev\_extent\_end, hole\_end); if (ret < 0) { goto out\_unlock; } else if (ret > 0) {@@ -3000,7 +3017,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, }  /\* We've reached the end of the fiemap range, stop. \*/- if (key.offset >= lockend) {+ if (key.offset >= range\_end) { stopped = true; break; }@@ -3094,29 +3111,41 @@ check\_eof\_delalloc: btrfs\_free\_path(path); path = NULL; - if (!stopped && prev\_extent\_end < lockend) {+ if (!stopped && prev\_extent\_end < range\_end) { ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx,- 0, 0, 0, prev\_extent\_end, lockend - 1);+ 0, 0, 0, prev\_extent\_end, range\_end - 1); if (ret < 0) goto out\_unlock;- prev\_extent\_end = lockend;+ prev\_extent\_end = range\_end; }  if (cache.cached && cache.offset + cache.len >= last\_extent\_end) { const u64 i\_size = i\_size\_read(&inode->vfs\_inode);  if (prev\_extent\_end < i\_size) {+ struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end;+ u64 lockstart;+ u64 lockend; bool delalloc; + lockstart = round\_down(prev\_extent\_end, sectorsize);+ lockend = round\_up(i\_size, sectorsize);++ /\*+ \* See the comment in fiemap\_process\_hole as to why+ \* we're doing the locking here.+ \*/+ lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, prev\_extent\_end, i\_size - 1, &delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);+ unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) cache.flags |= FIEMAP\_EXTENT\_LAST; } else {@@ -3127,7 +3156,6 @@ check\_eof\_delalloc: ret = emit\_last\_fiemap\_cache(fieinfo, &cache);  out\_unlock:- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); btrfs\_inode\_unlock(inode, BTRFS\_ILOCK\_SHARED); out: free\_extent\_state(delalloc\_cached\_state); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 18:40:36 +0000



=== Content from git.kernel.org_e895a1e0_20250111_184200.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Josef Bacik <josef@toxicpanda.com> | 2024-02-12 11:56:02 -0500 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-04-03 15:28:49 +0200 |
| commit | [ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)) | |
| tree | [bfe470bb38f02c0ce52525a3a53df54a6d4747c8](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf) | |
| parent | [ea01221f95f35b8fc9bd6fb61070b5201731075b](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ea01221f95f35b8fc9bd6fb61070b5201731075b) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf&id2=ea01221f95f35b8fc9bd6fb61070b5201731075b)) | |
| download | [linux-ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf.tar.gz) | |

btrfs: fix deadlock with fiemap and extent lockingcommit b0ad381fa7690244802aed119b478b4bdafc31dd upstream.
While working on the patchset to remove extent locking I got a lockdep
splat with fiemap and pagefaulting with my new extent lock replacement
lock.
This deadlock exists with our normal code, we just don't have lockdep
annotations with the extent locking so we've never noticed it.
Since we're copying the fiemap extent to user space on every iteration
we have the chance of pagefaulting. Because we hold the extent lock for
the entire range we could mkwrite into a range in the file that we have
mmap'ed. This would deadlock with the following stack trace
[<0>] lock\_extent+0x28d/0x2f0
[<0>] btrfs\_page\_mkwrite+0x273/0x8a0
[<0>] do\_page\_mkwrite+0x50/0xb0
[<0>] do\_fault+0xc1/0x7b0
[<0>] \_\_handle\_mm\_fault+0x2fa/0x460
[<0>] handle\_mm\_fault+0xa4/0x330
[<0>] do\_user\_addr\_fault+0x1f4/0x800
[<0>] exc\_page\_fault+0x7c/0x1e0
[<0>] asm\_exc\_page\_fault+0x26/0x30
[<0>] rep\_movs\_alternative+0x33/0x70
[<0>] \_copy\_to\_user+0x49/0x70
[<0>] fiemap\_fill\_next\_extent+0xc8/0x120
[<0>] emit\_fiemap\_extent+0x4d/0xa0
[<0>] extent\_fiemap+0x7f8/0xad0
[<0>] btrfs\_fiemap+0x49/0x80
[<0>] \_\_x64\_sys\_ioctl+0x3e1/0xb50
[<0>] do\_syscall\_64+0x94/0x1a0
[<0>] entry\_SYSCALL\_64\_after\_hwframe+0x6e/0x76
I wrote an fstest to reproduce this deadlock without my replacement lock
and verified that the deadlock exists with our existing locking.
To fix this simply don't take the extent lock for the entire duration of
the fiemap. This is safe in general because we keep track of where we
are when we're searching the tree, so if an ordered extent updates in
the middle of our fiemap call we'll still emit the correct extents
because we know what offset we were on before.
The only place we maintain the lock is searching delalloc. Since the
delalloc stuff can change during writeback we want to lock the extent
range so we have a consistent view of delalloc at the time we're
checking to see if we need to set the delalloc flag.
With this patch applied we no longer deadlock with my testcase.
CC: stable@vger.kernel.org # 6.1+
Reviewed-by: Filipe Manana <fdmanana@suse.com>
Signed-off-by: Josef Bacik <josef@toxicpanda.com>
Reviewed-by: David Sterba <dsterba@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)

| -rw-r--r-- | [fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/btrfs/extent_io.c?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf) | 62 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 45 insertions, 17 deletions

| diff --git a/fs/btrfs/extent\_io.c b/fs/btrfs/extent\_io.cindex a068982da91ded..f7a10e421f128a 100644--- a/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=ea01221f95f35b8fc9bd6fb61070b5201731075b)+++ b/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=ded566b4637f1b6b4c9ba74e7d0b8493e93f19cf)@@ -2735,16 +2735,34 @@ static int fiemap\_process\_hole(struct btrfs\_inode \*inode, \* it beyond i\_size. \*/ while (cur\_offset < end && cur\_offset < i\_size) {+ struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end; u64 prealloc\_start;+ u64 lockstart;+ u64 lockend; u64 prealloc\_len = 0; bool delalloc; + lockstart = round\_down(cur\_offset, inode->root->fs\_info->sectorsize);+ lockend = round\_up(end, inode->root->fs\_info->sectorsize);++ /\*+ \* We are only locking for the delalloc range because that's the+ \* only thing that can change here. With fiemap we have a lock+ \* on the inode, so no buffered or direct writes can happen.+ \*+ \* However mmaps and normal page writeback will cause this to+ \* change arbitrarily. We have to lock the extent lock here to+ \* make sure that nobody messes with the tree while we're doing+ \* btrfs\_find\_delalloc\_in\_range.+ \*/+ lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, cur\_offset, end, delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);+ unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) break; @@ -2912,15 +2930,15 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, u64 start, u64 len) { const u64 ino = btrfs\_ino(inode);- struct extent\_state \*cached\_state = NULL; struct extent\_state \*delalloc\_cached\_state = NULL; struct btrfs\_path \*path; struct fiemap\_cache cache = { 0 }; struct btrfs\_backref\_share\_check\_ctx \*backref\_ctx; u64 last\_extent\_end; u64 prev\_extent\_end;- u64 lockstart;- u64 lockend;+ u64 range\_start;+ u64 range\_end;+ const u64 sectorsize = inode->root->fs\_info->sectorsize; bool stopped = false; int ret; @@ -2931,12 +2949,11 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, goto out; } - lockstart = round\_down(start, inode->root->fs\_info->sectorsize);- lockend = round\_up(start + len, inode->root->fs\_info->sectorsize);- prev\_extent\_end = lockstart;+ range\_start = round\_down(start, sectorsize);+ range\_end = round\_up(start + len, sectorsize);+ prev\_extent\_end = range\_start;  btrfs\_inode\_lock(inode, BTRFS\_ILOCK\_SHARED);- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state);  ret = fiemap\_find\_last\_extent\_offset(inode, path, &last\_extent\_end); if (ret < 0)@@ -2944,7 +2961,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, btrfs\_release\_path(path);  path->reada = READA\_FORWARD;- ret = fiemap\_search\_slot(inode, path, lockstart);+ ret = fiemap\_search\_slot(inode, path, range\_start); if (ret < 0) { goto out\_unlock; } else if (ret > 0) {@@ -2956,7 +2973,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, goto check\_eof\_delalloc; } - while (prev\_extent\_end < lockend) {+ while (prev\_extent\_end < range\_end) { struct extent\_buffer \*leaf = path->nodes[0]; struct btrfs\_file\_extent\_item \*ei; struct btrfs\_key key;@@ -2979,19 +2996,19 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, \* The first iteration can leave us at an extent item that ends \* before our range's start. Move to the next item. \*/- if (extent\_end <= lockstart)+ if (extent\_end <= range\_start) goto next\_item;  backref\_ctx->curr\_leaf\_bytenr = leaf->start;  /\* We have in implicit hole (NO\_HOLES feature enabled). \*/ if (prev\_extent\_end < key.offset) {- const u64 range\_end = min(key.offset, lockend) - 1;+ const u64 hole\_end = min(key.offset, range\_end) - 1;  ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx, 0, 0, 0,- prev\_extent\_end, range\_end);+ prev\_extent\_end, hole\_end); if (ret < 0) { goto out\_unlock; } else if (ret > 0) {@@ -3001,7 +3018,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, }  /\* We've reached the end of the fiemap range, stop. \*/- if (key.offset >= lockend) {+ if (key.offset >= range\_end) { stopped = true; break; }@@ -3095,29 +3112,41 @@ check\_eof\_delalloc: btrfs\_free\_path(path); path = NULL; - if (!stopped && prev\_extent\_end < lockend) {+ if (!stopped && prev\_extent\_end < range\_end) { ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx,- 0, 0, 0, prev\_extent\_end, lockend - 1);+ 0, 0, 0, prev\_extent\_end, range\_end - 1); if (ret < 0) goto out\_unlock;- prev\_extent\_end = lockend;+ prev\_extent\_end = range\_end; }  if (cache.cached && cache.offset + cache.len >= last\_extent\_end) { const u64 i\_size = i\_size\_read(&inode->vfs\_inode);  if (prev\_extent\_end < i\_size) {+ struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end;+ u64 lockstart;+ u64 lockend; bool delalloc; + lockstart = round\_down(prev\_extent\_end, sectorsize);+ lockend = round\_up(i\_size, sectorsize);++ /\*+ \* See the comment in fiemap\_process\_hole as to why+ \* we're doing the locking here.+ \*/+ lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, prev\_extent\_end, i\_size - 1, &delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);+ unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) cache.flags |= FIEMAP\_EXTENT\_LAST; } else {@@ -3128,7 +3157,6 @@ check\_eof\_delalloc: ret = emit\_last\_fiemap\_cache(fieinfo, &cache);  out\_unlock:- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); btrfs\_inode\_unlock(inode, BTRFS\_ILOCK\_SHARED); out: free\_extent\_state(delalloc\_cached\_state); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 18:40:38 +0000


