=== Content from security.gentoo.org_8d9f0d19_20250111_024725.html ===

[![Gentoo](https://assets.gentoo.org/tyrian/v2/site-logo.png)](/ "Back to the homepage")
Security

[**Get Gentoo!**](https://get.gentoo.org/)
gentoo.org sites
[gentoo.org](https://www.gentoo.org/ "Main Gentoo website")
[Wiki](https://wiki.gentoo.org/ "Find and contribute documentation")
[Bugs](https://bugs.gentoo.org/ "Report issues and find common issues")
[Forums](https://forums.gentoo.org/ "Discuss with the community")
[Packages](https://packages.gentoo.org/ "Find software for your Gentoo")

[Planet](https://planet.gentoo.org/ "Find out what's going on in the developer community")
[Archives](https://archives.gentoo.org/ "Read up on past discussions")
[Sources](https://sources.gentoo.org/ "Browse our source code")

[Infra Status](https://infra-status.gentoo.org/ "Get updates on the services provided by Gentoo")

* [Home](/)
* [Stay informed](/subscribe)
* [Advisories](/glsa)

# Rust: Multiple Vulnerabilities — GLSA **202210-09**

Multiple vulnerabilities have been discovered in Rust, the worst of which could result in denial of service.

### Affected packages

| Package | **dev-lang/rust** on all architectures |
| --- | --- |
| Affected versions | < **1.63.0-r1** |
| Unaffected versions | >= **1.63.0-r1** |

| Package | **dev-lang/rust-bin** on all architectures |
| --- | --- |
| Affected versions | < **1.64.0** |
| Unaffected versions | >= **1.64.0** |

### Background

A systems programming language that runs blazingly fast, prevents segfaults, and guarantees thread safety.

### Description

Multiple vulnerabilities have been discovered in Rust. Please review the CVE identifiers referenced below for details.

### Impact

Please review the referenced CVE identifiers for details.

### Workaround

There is no known workaround at this time.

### Resolution

All Rust users should upgrade to the latest version:

```
 # emerge --sync
 # emerge --ask --oneshot --verbose ">=dev-lang/rust-1.63.0-r1"

```

All Rust binary users should upgrade to the latest version:

```
 # emerge --sync
 # emerge --ask --oneshot --verbose ">=dev-lang/rust-bin-1.64.0"

```

In addition, users using Portage 3.0.38 or later should ensure that packages with Rust binaries have no vulnerable code statically linked into their binaries by rebuilding the @rust-rebuild set:

```
 # emerge --ask --oneshot --verbose @rust-rebuild

```
### References

* [CVE-2021-28875](https://nvd.nist.gov/vuln/detail/CVE-2021-28875)
* [CVE-2021-28876](https://nvd.nist.gov/vuln/detail/CVE-2021-28876)
* [CVE-2021-28877](https://nvd.nist.gov/vuln/detail/CVE-2021-28877)
* [CVE-2021-28878](https://nvd.nist.gov/vuln/detail/CVE-2021-28878)
* [CVE-2021-28879](https://nvd.nist.gov/vuln/detail/CVE-2021-28879)
* [CVE-2021-29922](https://nvd.nist.gov/vuln/detail/CVE-2021-29922)
* [CVE-2021-31162](https://nvd.nist.gov/vuln/detail/CVE-2021-31162)
* [CVE-2021-36317](https://nvd.nist.gov/vuln/detail/CVE-2021-36317)
* [CVE-2021-36318](https://nvd.nist.gov/vuln/detail/CVE-2021-36318)
* [CVE-2021-42574](https://nvd.nist.gov/vuln/detail/CVE-2021-42574)
* [CVE-2021-42694](https://nvd.nist.gov/vuln/detail/CVE-2021-42694)
* [CVE-2022-21658](https://nvd.nist.gov/vuln/detail/CVE-2022-21658)
* [CVE-2022-36113](https://nvd.nist.gov/vuln/detail/CVE-2022-36113)
* [CVE-2022-36114](https://nvd.nist.gov/vuln/detail/CVE-2022-36114)

**Release date**

October 16, 2022

**Latest revision**

October 16, 2022: 1

**Severity**

normal

**Exploitable**

remote

**Bugzilla entries**

* [870166](https://bugs.gentoo.org/show_bug.cgi?id=870166)
* [831638](https://bugs.gentoo.org/show_bug.cgi?id=831638)
* [821157](https://bugs.gentoo.org/show_bug.cgi?id=821157)
* [807052](https://bugs.gentoo.org/show_bug.cgi?id=807052)
* [782367](https://bugs.gentoo.org/show_bug.cgi?id=782367)

### Questions or comments?

Please feel free to contact us.

**© 2001–2020 Gentoo Foundation, Inc.**



=== Content from www.openwall.com_73f7b514_20250111_024722.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Hash Suite - Windows password security audit tool. GUI, reports in PDF.](https://hashsuite.openwall.net) | | --- | |
| --- | --- |

[[<prev]](../../../2021/10/31/1) [[next>]](2) [[thread-next>]](4) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <aa5e1a0e-daba-41f2-1f98-91d36584f119@pietroalbini.org>
Date: Mon, 1 Nov 2021 01:01:46 +0100
From: Pietro Albini <pietro@...troalbini.org>
To: oss-security@...ts.openwall.com
Subject: CVE-2021-42574: rustc 1.56.0 and bidirectional-override codepoints in
 source code

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

The Rust Security Response WG was notified of a security concern affecting
source code containing "bidirectional override" Unicode codepoints: in some
cases the use of those codepoints could lead to the reviewed code being
different than the compiled code.

This is a vulnerability in the Unicode specification, and its assigned
identifier is CVE-2021-42574. While the vulnerability itself is not a rustc
flaw, we're taking proactive measures to mitigate its impact on Rust
developers.

## Overview

Unicode has support for both left-to-right and right-to-left languages, and to
aid writing left-to-right words inside a right-to-left sentence (or vice versa)
it also features invisible codepoints called "bidirectional override".

These codepoints are normally used across the Internet to embed a word inside a
sentence of another language (with a different text direction), but it was
reported to us that they could be used to manipulate how source code is
displayed in some editors and code review tools, leading to the reviewed code
being different than the compiled code. This is especially bad if the whole
team relies on bidirectional-aware tooling.

As an example, the following snippet (with `{U+NNNN}` replaced with the Unicode
codepoint `NNNN`):

```rust
if access_level != "user{U+202E} {U+2066}// Check if admin{U+2069} {U+2066}" {
```

...would be rendered by bidirectional-aware tools as:

```rust
if access_level != "user" { // Check if admin
```

## Affected Versions

Rust 1.56.1 introduces two new lints to detect and reject code containing the
affected codepoints. Rust 1.0.0 through Rust 1.56.0 do not include such lints,
leaving your source code vulnerable to this attack if you do not perform
out-of-band checks for the presence of those codepoints.

To assess the security of the ecosystem we analyzed all crate versions ever
published on crates.io (as of 2021-10-17), and only 5 crates have the affected
codepoints in their source code, with none of the occurrences being malicious.

## Mitigations

We will be releasing Rust 1.56.1 today, 2021-11-01, with two new
deny-by-default lints detecting the affected codepoints, respectively in string
literals and in comments. The lints will prevent source code files containing
those codepoints from being compiled, protecting you from the attack.

If your code has legitimate uses for the codepoints we recommend replacing them
with the related escape sequence. The error messages will suggest the right
escapes to use.

If you can't upgrade your compiler version, or your codebase also includes
non-Rust source code files, we recommend periodically checking that the
following codepoints are not present in your repository and your dependencies:
U+202A, U+202B, U+202C, U+202D, U+202E, U+2066, U+2067, U+2068, U+2069.

## Timeline of events

* 2021-07-25: we received the report and started working on a fix.
* 2021-09-14: the date for the embargo lift (2021-11-01) is communicated to us.
* 2021-10-17: performed an analysis of all the source code ever published to
   crates.io to check for the presence of this attack.
* 2021-11-01: embargo lifts, the vulnerability is disclosed and Rust 1.56.1 is
   released.

## Acknowledgments

Thanks to Nicholas Boucher [1] and Ross Anderson [2] from the University of
Cambridge for disclosing this to us according to our security policy [3]!

We also want to thank the members of the Rust project who contributed to the
mitigations for this issue. Thanks to Esteban Küber for developing the lints,
Pietro Albini for leading the security response, and many others for their
involvement, insights and feedback: Josh Stone, Josh Triplett, Manish
Goregaokar, Mara Bos, Mark Rousskov, Niko Matsakis, and Steve Klabnik.

## Appendix: Homoglyph attacks

As part of their research, Nicholas Boucher and Ross Anderson also uncovered a
similar security issue identified as CVE-2021-42694 involving homoglyphs inside
identifiers. Rust already includes mitigations for that attack since Rust
1.53.0. Rust 1.0.0 through Rust 1.52.1 is not affected due to the lack of
support for non-ASCII identifiers in those releases.

[1] <https://github.com/nickboucher>
[2] <https://www.cl.cam.ac.uk/~rja14>
[3] <https://www.rust-lang.org/policies/security>
-----BEGIN PGP SIGNATURE-----

iQIzBAEBCgAdFiEEV2nIi/XdPRSiNKes77mGCudSDawFAmF+hJkACgkQ77mGCudS
DaxljBAAtBlcz3g8h8lZvzOfOb8zRNfgw7mvBxr1fNyjNkV6n/xJA5yO6DC7K5ra
qqHXVdn7yfN5PvCBB7+vqQMDbM3X+m0Ui1eSIW09hGuyqBEc2+3UXlcWe0RVFBjT
ZiGb0TvHqaCZT9z+fRWtkbUia/vnZfTfJkQ0Xj4SE325I0k3uimBpJ+jZFLl98kR
1fnQtDkPQHK+VG5PdlYrZiGB+CibwlJWSqi7qyedPE7BVyFxSn2fHuFmQ4rUpBQc
fAMWI83B+HuQ650vJY2mGCq2qedsTaUDK9S9oF+7pl7FtSjlsBdmJ9ikGB1FFlVP
/6l0DZBRx2o3dp0KlD7k/MsXWZdo2Wg3wRamCltA/9f+uZBxLsdwJ+z1mvZB+wah
jDkrDMOXdacZA5Yr69swY5UnTDyM5oZixT6LQTDCTQTBGMOLFsWTc3kNk7v4r+vj
CR6pVj/2+jqy3hI/IrAWm129KVpyp8XM4KQbMenOBN32eBbDOtIZBn7cjqizfamU
mP5dvUaIfUzOkHcr1Bcx5WJSSTgON8pVTb6AsreCY7rSG2fiHT2beb6W5yZFhdm2
vWefxdcsL/h5WF0NHO5Hgj5o5a29sCpKOuSLfyW6GsA8waSRPkZBs2YWyzidhFr3
A9hmwxWAyDQv8NZZcThepdMjFT8zoDq6cb/aDX28OOjIfJAFQWQ=
=IsMc
-----END PGP SIGNATURE-----

View attachment "[rust-1.56.0-fix.patch](1/1)" of type "text/x-patch" (34016 bytes)

View attachment "[rust-1.56.0-fix.patch.asc](1/2)" of type "text/plain" (833 bytes)

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from www.unicode.org_3b508eaa_20250111_024730.html ===


| [[Unicode]](https://www.unicode.org/) | [Technical Reports](https://www.unicode.org/reports/) |
| --- | --- |
|  | |

## Unicode® Standard Annex #9

# Unicode Bidirectional Algorithm

| Version | Unicode 14.0.0 |
| --- | --- |
| Editors | Mark Davis (markdavis@google.com), Aharon Lanin (aharon@google.com), and Andrew Glass (andrew.glass@microsoft.com) |
| Date | 2021-08-27 |
| This Version | <https://www.unicode.org/reports/tr9/tr9-44.html> |
| Previous Version | <https://www.unicode.org/reports/tr9/tr9-42.html> |
| Latest Version | <https://www.unicode.org/reports/tr9/> |
| Latest Proposed Update | <https://www.unicode.org/reports/tr9/proposed.html> |
| Revision | [44](#Modifications) |

#### Summary

*This annex describes specifications for the positioning of characters in text containing characters flowing from right
to left, such as Arabic or Hebrew.*

#### Status

*This document has been reviewed by Unicode members and other
interested parties, and has been approved for publication by the Unicode
Consortium. This is a stable document and may be used as reference
material or cited as a normative reference by other specifications.*

> ***A Unicode Standard Annex (UAX)** forms an integral part of the
> Unicode Standard, but is published online as a separate document. The
> Unicode Standard may require conformance to normative content in a Unicode
> Standard Annex, if so specified in the Conformance chapter of that version
> of the Unicode Standard. The version number of a UAX document corresponds to
> the version of the Unicode Standard of which it forms a part.*

*Please submit corrigenda and other comments with the online reporting
form [[Feedback](https://www.unicode.org/reporting.html)].
Related information that is useful in understanding this annex is found in Unicode Standard Annex #41,
“[Common References for Unicode Standard Annexes](https://www.unicode.org/reports/tr41/tr41-28.html).”
For the latest version of the Unicode Standard, see [[Unicode](https://www.unicode.org/versions/latest/)].
For a list of current Unicode Technical Reports, see [[Reports](https://www.unicode.org/reports/)].
For more information about versions of the Unicode Standard, see [[Versions](https://www.unicode.org/versions/)].
For any errata which may apply to this annex, see [[Errata](https://www.unicode.org/errata/)].*

#### *Contents*

* 1  [Introduction](#Introduction)
* 2  [Directional Formatting Characters](#Directional_Formatting_Characters)
  + 2.1  [Explicit Directional Embeddings](#Explicit_Directional_Embeddings)
  + 2.2  [Explicit Directional Overrides](#Explicit_Directional_Overrides)
  + 2.3  [Terminating Explicit Directional
    Embeddings and Overrides](#Terminating_Explicit_Directional_Embeddings_and_Overrides)
  + 2.4  [Explicit Directional Isolates](#Explicit_Directional_Isolates)
  + 2.5  [Terminating Explicit Directional Isolates](#Terminating_Explicit_Directional_Isolates)
  + 2.6  [Implicit Directional Marks](#Implicit_Directional_Marks)
  + 2.7  [Markup and Formatting Characters](#Markup_And_Formatting)
* 3  [Basic Display Algorithm](#Basic_Display_Algorithm)
  + 3.1  [Definitions](#Definitions)
    - 3.1.1  [Basics](#Basics):
      [BD1](#BD1), [BD2](#BD2), [BD3](#BD3), [BD4](#BD4),
      [BD5](#BD5), [BD6](#BD6), [BD7](#BD7)
    - 3.1.2  [Matching Explicit Directional Formatting Characters](#Matching_Explicit_Directional_Formatting_Characters):
      [BD8](#BD8), [BD9](#BD9),
      [BD10](#BD10), [BD11](#BD11),
      [BD12](#BD12), [BD13](#BD13)
    - 3.1.3  [Paired Brackets](#Paired_Brackets):
      [BD14](#BD14), [BD15](#BD15), [BD16](#BD16)
    - 3.1.4  [Additional Abbreviations](#Additional_Abbreviations)
  + 3.2  [Bidirectional Character Types](#Bidirectional_Character_Types)
  + 3.3  [Resolving Embedding Levels](#Resolving_Embedding_Levels)
    - 3.3.1  [The Paragraph Level](#The_Paragraph_Level):
      [P1](#P1), [P2](#P2), [P3](#P3)
    - 3.3.2  [Explicit Levels and Directions](#Explicit_Levels_and_Directions):
      [X1](#X1), [X2](#X2), [X3](#X3), [X4](#X4),
      [X5](#X5), [X5a](#X5a), [X5b](#X5b), [X5c](#X5c),
      [X6](#X6), [X6a](#X6a),
      [X7](#X7), [X8](#X8)
    - 3.3.3  [Preparations for Implicit Processing](#Preparations_for_Implicit_Processing):
      [X9](#X9), [X10](#X10)
    - 3.3.4  [Resolving Weak Types](#Resolving_Weak_Types):
      [W1](#W1), [W2](#W2), [W3](#W3), [W4](#W4),
      [W5](#W5), [W6](#W6), [W7](#W7)
    - 3.3.5  [Resolving Neutral and Isolate Formatting Types](#Resolving_Neutral_Types):
      [N0](#N0), [N1](#N1), [N2](#N2)
    - 3.3.6  [Resolving Implicit Levels](#Resolving_Implicit_Levels):
      [I1](#I1), [I2](#I2)
  + 3.4  [Reordering Resolved Levels](#Reordering_Resolved_Levels):
    [L1](#L1), [L2](#L2), [L3](#L3), [L4](#L4)
  + 3.5  [Shaping](#Shaping)
* 4  [Bidirectional Conformance](#Bidirectional_Conformance)
  + 4.1  [Boundary Neutrals](#Boundary_Neutrals)
  + 4.2  [Explicit Formatting Characters](#Explicit_Formatting_Characters)
  + 4.3  [Higher-Level Protocols](#Higher-Level_Protocols): [HL1](#HL1),
    [HL2](#HL2), [HL3](#HL3), [HL4](#HL4), [HL5](#HL5),
    [HL6](#HL6)
  + 4.4 [Bidirectional Conformance Testing](#Bidi_Conformance_Testing)
* 5  [Implementation Notes](#Implementation_Notes)
  + 5.1  [Reference Code](#Reference_Code)
  + 5.2  [Retaining BNs and
    Explicit Formatting Characters](#Retaining_Explicit_Formatting_Characters)
* 6  [Usage](#Usage)
  + 6.1  [Joiners](#Joiners)
  + 6.2  [Vertical Text](#Vertical_Text)
  + 6.3  [Formatting](#Formatting)
  + 6.4  [Separating Punctuation Marks](#Separators)
  + 6.5  [Conversion to Plain Text](#Conversion_to_Plain_Text)
* 7  [Mirroring](#Mirroring)
* [Migration Issues](#Migration)
  + [Section Reorganization](#section_reorg)
* [Acknowledgments](#Acknowledgements)
* [References](#References)
* [Modifications](#Modifications)

---

## 1 [Introduction](#Introduction)

The Unicode Standard prescribes a *memory* representation order
known as logical order. When text is presented in horizontal lines, most
scripts display characters from left to right. However, there are several
scripts (such as Arabic or Hebrew) where the natural ordering of horizontal
text in display is from right to left. If all of the text has
a uniform horizontal
direction, then the ordering of the display text is unambiguous.

However, because these right-to-left scripts
use digits that are written from left to right, the text is actually *bidirectional*:
a mixture of right-to-left *and* left-to-right text. In addition to
digits, embedded words from English and other scripts are also written from
left to right, also producing bidirectional text. Without a clear
specification, ambiguities can
arise in determining the ordering of the displayed characters when the
horizontal direction of the text is not uniform.

This annex describes the algorithm used to determine the directionality for bidirectional
Unicode text. The algorithm extends the implicit model currently employed by a number of existing
implementations and adds explicit formatting characters for special circumstances.
In most cases, there is no need to include additional information with the text to obtain correct display
ordering.

However, in the case of bidirectional text, there are circumstances where
an implicit bidirectional ordering is not sufficient to produce
comprehensible text. To deal with these cases, a minimal set of directional
formatting characters is defined to control the ordering of characters when
rendered. This allows exact control of the display ordering for legible
interchange and
ensures that plain text used for simple items like filenames or labels can always be correctly
ordered for display.

The directional formatting characters are used *only* to influence the display ordering of
text. In all other respects they should be ignored—they have no effect on the comparison of text or on word breaks, parsing, or numeric analysis.

Each character has an implicit *bidirectional type*.
The bidirectional types left-to-right and right-to-left are called *strong types*, and characters
of those types are called strong directional characters. The bidirectional types associated with numbers
are called *weak types*, and characters of those types are called weak directional characters.
With the exception of the directional formatting characters, the remaining bidirectional types and characters are called neutral.
The algorithm uses the implicit bidirectional types of the characters in a text to arrive at a
reasonable display ordering for text.

When working with bidirectional text, the characters are still interpreted in logical
order—only the display is affected. The display ordering of bidirectional text depends on the
directional properties of the characters in the text. Note that there
are important security issues connected with bidirectional text: for more information, see [[UTR36](https://www.unicode.org/reports/tr41/tr41-28.html#UTR36)].

## 2 [Directional Formatting Characters](#Directional_Formatting_Characters)

Three types of explicit directional formatting characters are used to modify the standard implicit Unicode
Bidirectional Algorithm (UBA). In addition, there are implicit directional formatting characters, the *right-to-left* and *left-to-right* marks. The effects of all of these formatting characters are limited to the current paragraph;
thus, they are terminated by a *paragraph separator*.

These formatting characters all have the property *Bidi\_Control*,
and are divided into three groups:

| Implicit Directional Formatting Characters | LRM, RLM, ALM |
| --- | --- |
| Explicit Directional Embedding and Override Formatting Characters | LRE, RLE, LRO, RLO, PDF |
| Explicit Directional Isolate Formatting Characters | LRI, RLI, FSI, PDI |

Although the term *embedding* is used for some explicit formatting characters, the text within the scope
of the embedding formatting characters is not independent of the surrounding text. Characters within an embedding can affect
the ordering of characters outside, and vice versa.
This is not the case with the isolate formatting characters, however.
Characters within an isolate cannot affect the ordering of characters outside it, or vice versa.
The effect that an isolate as a whole has on the ordering of the surrounding characters
is the same as that of a neutral character,
whereas an embedding or override roughly has the effect of a strong character.

Directional isolate characters were introduced in Unicode 6.3 after it became apparent that
directional embeddings usually have too strong an effect on their surroundings and are thus unnecessarily difficult to use.
The new characters were introduced instead of changing the behavior of the existing ones because doing so might have
had an undesirable effect on those existing documents that do rely on the old behavior.
Nevertheless, the use of the directional isolates instead of embeddings is encouraged in new documents –
once target platforms are known to support them.

On web pages, the *explicit* directional formatting characters (of all types – embedding, override, and isolate)
should be replaced by other mechanisms suitable for HTML and CSS. For information on the correspondence between
explicit directional formatting characters and equivalent HTML5 markup and CSS properties, see
*Section 2.7, [Markup and Formatting Characters](#Markup_And_Formatting)*.

### 2.1 [Explicit Directional Embeddings](#Explicit_Directional_Embeddings)

The following characters signal that a piece of text is to be treated as embedded. For example, an
English quotation in the middle of an Arabic sentence could be marked as being embedded
left-to-right text. If there were a Hebrew phrase in the middle of the English quotation,
that phrase could be marked as being embedded right-to-left text.
Embeddings can be nested one inside another, and in isolates and overrides.

| Abbr. | Code Point | Name | Description |
| --- | --- | --- | --- |
| **LRE** | U+202A | LEFT-TO-RIGHT EMBEDDING | Treat the following text as embedded left-to-right. |
| **RLE** | U+202B | RIGHT-TO-LEFT EMBEDDING | Treat the following text as embedded right-to-left. |

The
effect of right-left line direction, for example, can be accomplished by embedding the text
with RLE...PDF. (PDF will be described in *Section 2.3, [Terminating Explicit Directional Embeddings and Overrides](#Terminating_Explicit_Directional_Embeddings_and_Overrides)*.)

### 2.2 [Explicit Directional Overrides](#Explicit_Directional_Overrides)

The following characters allow the bidirectional character types to be overridden when required for
special cases, such as for part numbers.
They are to be avoided wherever possible, because of
security concerns. For more information, see [[UTR36](https://www.unicode.org/reports/tr41/tr41-28.html#UTR36)].
Directional overrides can be nested one inside another, and in embeddings and isolates.

| Abbr. | Code Point | Name | Description |
| --- | --- | --- | --- |
| **LRO** | U+202D | LEFT-TO-RIGHT OVERRIDE | Force following characters to be treated as strong left-to-right characters. |
| **RLO** | U+202E | RIGHT-TO-LEFT OVERRIDE | Force following characters to be treated as strong right-to-left characters. |

The precise meaning of these characters will be made clear in the discussion of the algorithm. The
right-to-left override, for example, can be used to force a part number made of mixed English,
digits and Hebrew letters to be written from right to left.

### 2.3 [Terminating Explicit Directional Embeddings and Overrides](#Terminating_Explicit_Directional_Embeddings_and_Overrides)

The following character terminates the scope of the last
LRE, RLE, LRO, or RLO whose scope has not yet been terminated.

| Abbr. | Code Point | Name | Description |
| --- | --- | --- | --- |
| **PDF** | U+202C | POP DIRECTIONAL FORMATTING | End the scope of the last LRE, RLE, RLO, or LRO. |

The precise meaning of this character will be made clear in the discussion
of the algorithm.

### 2.4 [Explicit Directional Isolates](#Explicit_Directional_Isolates)

The following characters signal that a piece of text is to be treated as
directionally isolated from its surroundings.
They are very similar to the explicit embedding formatting characters.
However, while an embedding roughly has
the effect of a strong character on the ordering of the surrounding text,
an isolate has the effect of a neutral like U+FFFC OBJECT REPLACEMENT CHARACTER,
and is assigned the corresponding display position in the surrounding text.
Furthermore, the text inside the isolate has no effect on the ordering of the text outside it,
and vice versa.

In addition to allowing the embedding of strongly directional text without unduly affecting
the bidirectional order of its surroundings,
one of the isolate formatting characters also offers an extra feature:
embedding text while inferring its direction heuristically from its constituent characters.

Isolates can be nested one inside another, and in embeddings and overrides.

| Abbr. | Code Point | Name | Description |
| --- | --- | --- | --- |
| **LRI** | U+2066 | LEFT‑TO‑RIGHT ISOLATE | Treat the following text as isolated and left-to-right. |
| **RLI** | U+2067 | RIGHT‑TO‑LEFT ISOLATE | Treat the following text as isolated and right-to-left. |
| **FSI** | U+2068 | FIRST STRONG ISOLATE | Treat the following text as isolated and in the direction of its first strong directional character that is not inside a nested isolate. |

The precise meaning of these characters will be made clear in the discussion of the algorithm.

### 2.5 [Terminating Explicit Directional Isolates](#Terminating_Explicit_Directional_Isolates)

The following character terminates the scope of the last LRI, RLI, or FSI
whose scope has not yet been terminated,
as well as the scopes of any subsequent LREs, RLEs, LROs, or RLOs whose scopes have not yet been terminated.

| Abbr. | Code Point | Name | Description |
| --- | --- | --- | --- |
| **PDI** | U+2069 | POP DIRECTIONAL ISOLATE | End the scope of the last LRI, RLI, or FSI. |

The precise meaning of this character will be made clear in the discussion of the algorithm.

### 2.6 [Implicit Directional Marks](#Implicit_Directional_Marks)

These characters are very light-weight formatting. They act exactly like right-to-left or
left-to-right characters, except that they do not display or have any other semantic effect. Their
use is more convenient than using explicit embeddings or overrides because their scope is
much more local.

| Abbr. | Code Point | Name | Description |
| --- | --- | --- | --- |
| **LRM** | U+200E | LEFT-TO-RIGHT MARK | Left-to-right zero-width character |
| **RLM** | U+200F | RIGHT-TO-LEFT MARK | Right-to-left zero-width non-Arabic character |
| **ALM** | U+061C | ARABIC LETTER MARK | Right-to-left zero-width Arabic character |

There is no special mention of the implicit directional marks in the following algorithm. That
is because their effect on bidirectional ordering is exactly the same as a corresponding strong
directional character; the only difference is that they do not appear in the display.

### 2.7 [Markup and Formatting Characters](#Markup_And_Formatting)

The explicit formatting characters introduce state into the plain text, which must be maintained when editing or displaying the text. Processes that are modifying the text without being aware of this state may inadvertently affect the rendering of large portions of the text, for example by removing a PDF.

The Unicode Bidirectional Algorithm is designed so that the use of
explicit formatting characters can be equivalently represented by out-of-line information, such as stylesheet
information or markup. Conflicts can arise if markup and explicitly formatting characters are both used in the same paragraph.
Where available, markup should be used instead of the explicit formatting characters: for more information, see [[UnicodeXML](https://www.unicode.org/reports/tr41/tr41-28.html#UnicodeXML)].
However, any alternative representation is only to be defined by reference to the behavior
of the corresponding explicit formatting characters in this algorithm, to ensure conformance with the Unicode Standard.

HTML5 [[HTML5](https://www.unicode.org/reports/tr41/tr41-28.html#HTML5)] and CSS3 [[CSS3Writing](https://www.unicode.org/reports/tr41/tr41-28.html#CSS3Writing)]
provide support for bidi markup as follows:

| Unicode | Equivalent Markup | Equivalent CSS | Comment |
| --- | --- | --- | --- |
| RLI ... PDI | dir = "rtl" | direction:rtl; unicode-bidi:isolate | dir attribute on any element |
| LRI ... PDI | dir = "ltr" | direction:ltr; unicode-bidi:isolate | dir attribute on any element |
| FSI ... PDI | <bdi>, dir = "auto" | unicode-bidi:plaintext | dir attribute on any element |
| RLE ... PDF |  | direction:rtl; unicode-bidi:embed | markup not available in HTML |
| LRE ... PDF |  | direction:ltr; unicode-bidi:embed | markup not available in HTML |
| RLO ... PDF |  | direction:rtl; unicode-bidi:bidi-override | markup not available in HTML |
| LRO ... PDF |  | direction:ltr; unicode-bidi:bidi-override | markup not available in HTML |
| FSI RLO . . . PDF PDI | <bdo dir = "rtl"> | direction:rtl; unicode-bidi:isolate-override |  |
| FSI LRO . . . PDF PDI | <bdo dir = "ltr"> | direction:ltr; unicode-bidi:isolate-override |  |

Unlike HTML4.0, HTML5 does not provide exact equivalents for LRE, RLE, LRO, and RLO, although
the dir attribute and the BDO element as outlined above should in most cases work as well or better than those formatting characters.
When absolutely necessary, CSS can be used to get exact equivalents for LRE, RLE, LRO, and RLO, as well as for LRI, RLI, and FSI.

Whenever plain text is produced from a document containing markup, the equivalent formatting characters should be introduced, so that the correct ordering is not lost. For example, whenever cut and paste results in plain text this transformation should occur.

## 3 [Basic Display Algorithm](#Basic_Display_Algorithm)

The Unicode Bidirectional Algorithm
(UBA) takes a stream of text as input and proceeds in
four main phases:

* **Separation into paragraphs.** The
  rest of the algorithm is applied separately to the text within each
  paragraph.
* **Initialization.** A list of
  bidirectional character types is initialized, with one entry for each
  character in the original text. The value of each entry is the
  Bidi\_Class property value of the respective character.
  A list of embedding levels, with one level per character, is then initialized.
  Note that the original characters are referenced in *Section 3.3.5,
  [Resolving Neutral and Isolate Formatting Types](#Resolving_Neutral_Types)*.
* **Resolution of the embedding levels.**
  A series of rules is applied to the lists of embedding levels and
  bidirectional character types. Each rule
  operates on the current values of those lists, and can modify those values.
  The original characters and their Bidi\_Paired\_Bracket and Bidi\_Paired\_Bracket\_Type
  property values are referenced in the application of certain rules.
  The result of this phase is a modified list of embedding levels;
  the list of bidirectional character types is no longer needed.
* **Reordering.**  The text within each
  paragraph is reordered for display: first, the text in the paragraph is
  broken into lines, then the resolved embedding levels are used to reorder the
  text of each line for display.

The algorithm reorders text only within a paragraph; characters in one paragraph have no effect
on characters in a different paragraph. Paragraphs are divided by the Paragraph Separator or
appropriate Newline Function (for guidelines on the handling of CR, LF, and CRLF, see *Section 4.4, Directionality*, and *Section 5.8, Newline Guidelines* of [[Unicode](https://www.unicode.org/reports/tr41/tr41-28.html#Unicode)]).
Paragraphs may also be determined by higher-level protocols: for example, the text in two
different cells of a table will be in different paragraphs.

Combining characters always attach to the preceding base character in the memory
representation. Even after reordering for display and performing character shaping, the glyph
representing a combining character will attach to the glyph representing its base character in
memory. Depending on the line orientation and the placement direction of base letterform glyphs,
it may, for example, attach to the glyph on the left, or on the right, or above.

This annex uses the numbering conventions for normative
definitions and rules in *Table 1*.

Table 1. [Normative Definitions and Rules](#Table_Normative_Defs_Rules)

| Numbering | Section |
| --- | --- |
| BDn | Definitions |
| Pn | Paragraph levels |
| Xn | Explicit levels and directions |
| Wn | Weak types |
| Nn | Neutral types |
| In | Implicit levels |
| Ln | Resolved levels |

### 3.1 [Definitions](#Definitions)

### 3.1.1 [Basics](#Basics)

***[BD1](#BD1).*** The *bidirectional character types* are values assigned to each
Unicode character, including unassigned characters.
The formal property name in the
*Unicode Character Database* [[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)]
is Bidi\_Class.

***[BD2](#BD2).*** *Embedding levels* are numbers that indicate how deeply the text is
nested, and the default direction of text on that level. The minimum embedding level of text is zero, and the maximum explicit depth is
125, a value referred to as *max\_depth* in the rest of this document.

As rules [X1](#X1) through [X8](#X8) will specify,
embedding levels are set by
explicit formatting characters (embedding, isolate, and override);
higher numbers mean the text is more deeply nested. The reason for having a limitation is
to provide a precise stack limit for implementations to guarantee the same results. A
maximum explicit level of 125
is far more than sufficient for ordering, even with mechanically generated formatting;
the display becomes rather muddied with more than a small number of embeddings.

For implementation stability, this specification now guarantees that the
value of 125 for max\_depth will not be increased (or decreased) in future versions.
Thus, it is safe for implementations to treat the max\_depth value as a constant. The max\_depth
value has been 125 since UBA Version 6.3.0.

***[BD3](#BD3).*** The default direction of the current embedding level
(for the character in question) is called the *embedding direction*. It is **L** if the embedding level is even,
and **R** if the embedding level is odd.

For example, in a particular piece of text, level 0 is plain English text. Level 1 is plain
Arabic text, possibly embedded within English level 0 text. Level 2 is English text, possibly
embedded within Arabic level 1 text, and so on. Unless their direction is overridden, English
text and numbers will always be an even level; Arabic text (excluding numbers) will always be an
odd level. The exact meaning of the embedding level will become clear when the reordering
algorithm is discussed, but the following provides an example of how the algorithm works.

***[BD4](#BD4).*** The *paragraph embedding level* is the embedding level that
determines the default bidirectional orientation of the text in that paragraph.

***[BD5](#BD5).*** The direction of the paragraph embedding level is called the *paragraph direction*.

* In some contexts the paragraph direction is also known as the *base direction*.

***[BD6](#BD6).*** The *directional override status* determines whether the
bidirectional type of characters is to be reset. The directional override status
is set by using explicit directional formatting characters. This status
has three states, as shown in *Table 2*.

Table 2. [Directional Override Status](#Table_Directional_Override_Status)

| Status | Interpretation |
| --- | --- |
| **Neutral** | No override is currently active |
| **Right-to-left** | Characters are to be reset to **R** |
| **Left-to-right** | Characters are to be reset to **L** |

***[BD7](#BD7).*** A *level run* is a maximal substring of characters that have the
same embedding level. It is maximal in that no character immediately before or after the substring
has the same level (a level run is also known as a *directional run)*.

As specified below, level runs are important at two different stages of the Bidirectional Algorithm.
The first stage occurs after rules [X1](#X1) through [X9](#X9) have assigned an explicit embedding level
to each character on the basis of the paragraph direction and the explicit directional formatting characters.
At this stage, in rule [X10](#X10), level runs are used to build up the units to which subsequent rules are applied.
Those rules further adjust each character’s embedding level on the basis of its implicit bidirectional type and those
of other characters in the unit – but not outside it.
The level runs resulting from these resolved embedding levels are then used in the actual reordering of the text by rule [L2](#L2).
The following example illustrates level runs at this later stage of the algorithm.

#### Example

In this and the following examples, case is used to indicate different
implicit character types for those unfamiliar with right-to-left letters.
Uppercase letters stand for right-to-left characters (such as Arabic or
Hebrew), and lowercase letters stand for left-to-right characters (such as
English or Russian).

```

Memory:            car is THE CAR in arabic

Character types:   LLL-LL-RRR-RRR-LL-LLLLLL

Paragraph level:   0

Resolved levels:   000000011111110000000000

```

Notice that the neutral character (space) between THE and CAR gets the level of the surrounding
characters. The level of the neutral characters could be changed by
inserting appropriate directional marks around neutral characters, or using explicit directional formatting characters.

### 3.1.2 [Matching Explicit Directional Formatting Characters](#Matching_Explicit_Directional_Formatting_Characters)

***[BD8](#BD8).*** An *isolate initiator* is a character of type LRI, RLI, or FSI.

As rules [X5a](#X5a) through [X5c](#X5c) will specify,
an isolate initiator raises the embedding level for the characters following it
when the rules enforcing the depth limit allow it.

***[BD9](#BD9).*** The *matching PDI* for a given isolate initiator
is the one determined by the following algorithm:

* Initialize a counter to one.
* Scan the text following the isolate initiator to the end of the paragraph
  while incrementing the counter at every isolate initiator,
  and decrementing it at every PDI.
* Stop at the first PDI, if any, for which the counter is decremented to zero.
* If such a PDI was found, it is the matching PDI for the given isolate initiator.
  Otherwise, there is no matching PDI for it.

Note that all formatting characters except for isolate initiators and PDIs are ignored when finding the matching PDI.

Note that this algorithm assigns a matching PDI (or lack of one) to an isolate initiator
whether the isolate initiator raises the embedding level or is prevented from doing so by the depth limit rules.

As rule [X6a](#X6a) will specify,
a matching PDI returns the embedding level to the value it had before the isolate initiator that the PDI matches.
The PDI itself is assigned the new embedding level.
If it does not match any isolate initiator, or if the isolate initiator did not raise the embedding level,
it leaves the embedding level unchanged.
Thus, an isolate initiator and its matching PDI are always assigned the same explicit embedding level, which is the one outside the isolate.
In the later stages of the Bidirectional Algorithm, an isolate initiator and its matching PDI function as invisible neutral characters,
and their embedding level then helps ensure that
the isolate has the effect of a neutral character on the display order of the text outside it,
and is assigned the corresponding display position in the surrounding text.

***[BD10](#BD10).*** An *embedding initiator* is a character of type LRE, RLE, LRO, or RLO.

Note that an embedding initiator initiates either a directional embedding or a directional override;
its name omits overrides only for conciseness.

As rules [X2](#X2) through [X5](#X5) will specify,
an embedding initiator raises the embedding level for the characters following it
when the rules enforcing the depth limit allow it.

***[BD11](#BD11).*** The *matching PDF* for a given embedding initiator
is the one determined by the following algorithm:

* Initialize a counter to one.
* Scan the text following the embedding initiator:
  + At an isolate initiator, skip past the matching PDI,
    or if there is no matching PDI, to the end of the paragraph.
  + At the end of a paragraph, or at a PDI that matches an isolate initiator
    whose text location is before the embedding initiator's location,
    stop: the embedding initiator has no matching PDF.
  + At an embedding initiator, increment the counter.
  + At a PDF, decrement the counter. If its new value is zero, stop: this is the matching PDF.

Note that this algorithm assigns a matching PDF (or lack of one)
to an embedding initiator whether it raises the embedding level or is prevented from doing so by the depth limit rules.

Although the algorithm above serves to give a precise meaning to the term “matching PDF”,
note that the overall Bidirectional Algorithm never actually calls for its use to find the PDF matching an embedding initiator.
Instead, rules [X1](#X1) through [X7](#X7) specify a mechanism
that determines what embedding initiator scope, if any, is terminated by a PDF, i.e. which valid embedding initiator a PDF matches.

As rule [X7](#X7) will specify,
a matching PDF returns the embedding level to the value it had before the embedding initiator that the PDF matches.
If it does not match any embedding initiator, or if the embedding initiator did not raise the embedding level,
a PDF leaves the embedding level unchanged.

As rule [X9](#X9) will specify,
once explicit directional formatting characters have been used to assign embedding levels to the characters in a paragraph,
embedding initiators and PDFs are removed (or virtually removed) from the paragraph.
Thus, the embedding levels assigned to the embedding initiators and PDFs themselves are irrelevant.
In this, embedding initiators and PDFs differ from isolate initiators and PDIs,
which continue to play a part in determining the paragraph’s display order as mentioned above.

***[BD12](#BD12).*** The *directional isolate status* is a Boolean value set by using isolate formatting characters:
it is true when the current embedding level was started by an isolate initiator.

***[BD13](#BD13).*** An *isolating run sequence* is a maximal sequence of level runs such that
for all level runs except the last one in the sequence,
the last character of the run is an isolate initiator whose matching PDI is the first character of the next level run in the sequence.
It is maximal in the sense that if the first character of the first level run in the sequence is a PDI, it must not match any isolate initiator,
and if the last character of the last level run in the sequence is an isolate initiator, it must not have a matching PDI.

The set of isolating run sequences in a paragraph can be computed by the following algorithm:

* Start with an empty set of isolating run sequences.
* For each level run in the paragraph whose first character is not a PDI, or is a PDI that does not match any isolate initiator:
  + Create a new level run sequence, and initialize it to contain just that level run.
  + While the level run currently last in the sequence ends with an isolate initiator that has a matching PDI, append the level run containing the matching PDI to the sequence.
    (Note that this matching PDI must be the first character of its level run.)
  + Add the resulting sequence of level runs to the set of isolating run sequences.

Note that:

* Each level run in a paragraph belongs to exactly one isolating run sequence.
* In the absence of isolate initiators, each isolating run sequence in a paragraph consists of exactly one level run,
  and each level run constitutes a separate isolating run sequence.
* For any two adjacent level runs in an isolating run sequence,
  since one ends with an isolate initiator whose matching PDI starts the other,
  the two must have the same embedding level.
  Thus, all the level runs in an isolating run sequence have the same embedding level.
* When an isolate initiator raises the embedding level,
  both the isolate initiator and its matching PDI, if any, get the original embedding level, not the raised one.
  Thus, if the matching PDI does not immediately follow the isolate initiator in the paragraph,
  the isolate initiator is the last character in its level run, but the matching PDI, if any,
  is the first character of its level run and immediately follows the isolate initiator in the same isolating run sequence.
  On the other hand, the level run following the isolate initiator in the paragraph starts a new isolating run sequence,
  and the level run preceding the matching PDI (if any) in the paragraph ends its isolating run sequence.

In the following examples, assume that:

* The paragraph embedding level is 0.
* No character sequence *texti* contains explicit formatting characters or paragraph separators.
* The dots are used only to improve the example's visual clarity; they are not part of the text.
* The characters in the paragraph text are assigned embedding levels as loosely described above such that they form the set of level runs given in each example.

#### Example 1

Paragraph text: *text1*·RLE·*text2*·PDF·RLE·*text3*·PDF·*text4*

Level runs:

* *text1* – level 0
* *text2*·*text3* – level 1
* *text4* – level 0

Resulting isolating run sequences:

* *text1* – level 0
* *text2*·*text3* – level 1
* *text4* – level 0

#### Example 2

Paragraph text: *text1*·RLI·*text2*·PDI·RLI·*text3*·PDI·*text4*

Level runs:

* *text1*·RLI – level 0
* *text2* – level 1
* PDI·RLI – level 0
* *text3* – level 1
* PDI·*text4* – level 0

Resulting isolating run sequences:

* *text1*·RLI
  PDI·RLI
  PDI·*text4* – level 0
* *text2* – level 1
* *text3* – level 1

#### Example 3

Paragraph text: *text1*·RLI·*text2*·LRI·*text3*·RLE·*text4*·PDF·*text5*·PDI·*text6*·PDI·*text7*

Level runs:

* *text1*·RLI – level 0
* *text2*·LRI – level 1
* *text3* – level 2
* *text4* – level 3
* *text5* – level 2
* PDI·*text6* – level 1
* PDI·*text7* – level 0

Resulting isolating run sequences:

* *text1*·RLI
  PDI·*text7* – level 0
* *text2*·LRI
  PDI·*text6* – level 1
* *text3* – level 2
* *text4* – level 3
* *text5* – level 2

As rule [X10](#X10) will specify, an isolating run sequence is the unit
to which the rules following it are applied,
and the last character of one level run in the sequence is considered to be
immediately followed by the first character of the next level run in the sequence
during this phase of the algorithm.
Since those rules are based on the characters' implicit bidirectional types,
an isolate really does have the same effect on the ordering of the text surrounding it
as a neutral character –
or, to be more precise, a pair of neutral characters, the isolate initiator and the PDI,
which behave in those rules just like neutral characters.

### 3.1.3 [Paired Brackets](#Paired_Brackets)

The following definitions utilize the normative properties
Bidi\_Paired\_Bracket and Bidi\_Paired\_Bracket\_Type defined in the `BidiBrackets.txt` file
[[Data9](https://www.unicode.org/reports/tr41/tr41-28.html#Data9)] of the *Unicode Character Database*
[[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)].

***[BD14](#BD14).*** An *opening paired bracket* is a character whose
Bidi\_Paired\_Bracket\_Type property value is Open and whose current bidirectional character type is ON.

***[BD15](#BD15).*** A *closing paired bracket* is a character whose Bidi\_Paired\_Bracket\_Type
property value is Close and whose current bidirectional character type is ON.

***[BD16](#BD16).*** A *bracket pair* is a pair of characters consisting of an opening
paired bracket and a closing paired bracket such that the Bidi\_Paired\_Bracket property
value of the former or its canonical equivalent equals the latter or its canonical equivalent
and which are algorithmically identified at specific text positions
within an isolating run sequence. The following algorithm identifies all of the bracket pairs
in a given isolating run sequence:

* Create a fixed-size stack for exactly 63 elements each consisting of a bracket character and a text
  position. Initialize it to empty.
* Create a list for elements each consisting of two text positions, one for an opening
  paired bracket and the other for a corresponding closing paired bracket. Initialize it to empty.
* Inspect each character in the isolating run sequence in logical order.
  + If an opening paired bracket is found and there is room in the stack, push its Bidi\_Paired\_Bracket property
    value and its text position onto the stack.
  + If an opening paired bracket is found and there is no room in the stack, stop processing BD16 for the remainder of the isolating run sequence.
  + If a closing paired bracket is found, do the following:
    1. Declare a variable that holds a reference to the current stack element and initialize
       it with the top element of the stack.
    2. Compare the closing paired bracket being inspected or its canonical equivalent
       to the bracket in the current stack element.
    3. If the values match, meaning the two characters form a bracket pair, then
       - Append the text position in the current stack element together with the
         text position of the closing paired bracket to the list.
       - Pop the stack through the current stack element inclusively.
    4. Else, if the current stack element is not at the bottom of the stack, advance it to
       the next element deeper in the stack and go back to step 2.
    5. Else, continue with inspecting the next character without popping the stack.
* Sort the list of pairs of text positions in ascending order based on the text position of the opening paired bracket.

Note that bracket pairs can only occur in an isolating run sequence
because they are processed in rule [N0](#N0) after explicit level resolution. See
*Section 3.3.2, [Explicit Levels and Directions](#Explicit_Levels_and_Directions)*.

#### Examples of bracket pairs

```

	Text			Pairings
	1 2 3 4 5 6 7 8
	a ) b ( c		None
	a ( b ] c		None
	a ( b ) c		2-4
	a ( b [ c ) d ]		2-6
	a ( b ] c ) d		2-6
	a ( b ) c ) d		2-4
	a ( b ( c ) d		4-6
	a ( b ( c ) d )		2-8, 4-6
	a ( b { c } d )		2-8, 4-6

```
### 3.1.4 [Additional Abbreviations](#Additional_Abbreviations)

*Table 3* lists additional abbreviations used in the examples and internal character types used
in the algorithm.

Table 3. [Abbreviations for Examples and Internal Types](#Table_Abbrevs_for_Examples_Internal_Types)

| **Symbol** | **Description** |
| --- | --- |
| [NI](#NI) | Neutral or Isolate formatting character ([B](#B), [S](#S), [WS](#WS), [ON](#ON), [FSI](#FSI), [LRI](#LRI), [RLI](#RLI), [PDI](#PDI)). |
| [e](#e) | The text ordering type ([L](#L) or [R](#R)) that matches the **embedding** level direction (even or odd). |
| [o](#o) | The text ordering type ([L](#L) or [R](#R)) that matches the direction **opposite** the embedding level direction (even or odd). Note that o is the opposite of e. |
| [sos](#sos) | The text ordering type ([L](#L) or [R](#R)) assigned to the virtual position before an isolating run sequence. |
| [eos](#eos) | The text ordering type ([L](#L) or [R](#R)) assigned to the virtual position after an isolating run sequence. |

### 3.2 [Bidirectional Character Types](#Bidirectional_Character_Types)

The normative bidirectional character types for each character are specified in the
[Unicode Character Database](https://www.unicode.org/Public/UNIDATA/) [[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)]
and are summarized in *[Table 4](#Table_Bidirectional_Character_Types)*. This is a summary only: there are exceptions to the general
scope. For example, certain characters such as U+0CBF KANNADA VOWEL SIGN I are given Type L
(instead of NSM) to preserve canonical equivalence.

* The term European digits is used to refer to decimal forms common in Europe and elsewhere,
  and Arabic-Indic digits to refer to the native Arabic forms. (See *Section 9.2, Arabic* of
  [[Unicode](https://www.unicode.org/reports/tr41/tr41-28.html#Unicode)], for more details on naming digits.)
* Unassigned characters are given strong types in the algorithm. This is an explicit exception
  to the general Unicode conformance requirements with respect to unassigned characters. As
  characters become assigned in the future, these bidirectional types may change. For
  assignments to character types, see DerivedBidiClass.txt
  [[DerivedBIDI](https://www.unicode.org/reports/tr41/tr41-28.html#Props)]
  in the [[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)].
* Private-use characters can be assigned different values by a conformant implementation.
* For the purpose of the Bidirectional Algorithm, inline objects (such as graphics) are
  treated as if they are an U+FFFC OBJECT REPLACEMENT CHARACTER.
* As of Unicode 4.0, the Bidirectional Character Types of a few Indic characters were altered
  so that the Bidirectional Algorithm preserves [canonical
  equivalence](#canonical_equivalence). That is, two canonically equivalent strings will result in equivalent ordering
  after applying the algorithm. This invariant will be maintained in the future.

  **Note:**
  The Bidirectional Algorithm does *not* preserve compatibility equivalence.

Table 4. [Bidirectional Character Types](#Table_Bidirectional_Character_Types)

| Category | Type | Description | General Scope |
| --- | --- | --- | --- |
| **Strong** | **[L](#L)** | Left-to-Right | LRM, most alphabetic, syllabic, Han ideographs, non-European or non-Arabic digits, ... |
| **[R](#R)** | Right-to-Left | RLM, Hebrew alphabet, and related punctuation |
| **[AL](#AL)** | Right-to-Left Arabic | ALM, Arabic, Thaana, and Syriac alphabets, most punctuation specific to those scripts, ... |
| **Weak** | **[EN](#EN)** | European Number | European digits, Eastern Arabic-Indic digits, ... |
| **[ES](#ES)** | European Number Separator | PLUS SIGN, MINUS SIGN |
| **[ET](#ET)** | European Number Terminator | DEGREE SIGN, currency symbols, ... |
| **[AN](#AN)** | Arabic Number | Arabic-Indic digits, Arabic decimal and thousands separators, ... |
| **[CS](#CS)** | Common Number Separator | COLON, COMMA, FULL STOP, NO-BREAK SPACE, ... |
| **[NSM](#NSM)** | Nonspacing Mark | Characters with the General\_Category values: Mn (Nonspacing\_Mark) and Me (Enclosing\_Mark) |
| **[BN](#BN)** | Boundary Neutral | Default ignorables, non-characters, and control characters, other than those explicitly given other types. |
| **Neutral** | **[B](#B)** | Paragraph Separator | PARAGRAPH SEPARATOR, appropriate Newline Functions, higher-level protocol paragraph determination |
| **[S](#S)** | Segment Separator | *Tab* |
| **[WS](#WS)** | Whitespace | SPACE, FIGURE SPACE, LINE SEPARATOR, FORM FEED, General Punctuation spaces, ... |
| **[ON](#ON)** | Other Neutrals | All other characters, including OBJECT REPLACEMENT CHARACTER |
| **Explicit Formatting** | **[LRE](#LRE)** | Left-to-Right Embedding | LRE |
| **[LRO](#LRO)** | Left-to-Right Override | LRO |
| **[RLE](#RLE)** | Right-to-Left Embedding | RLE |
| **[RLO](#RLO)** | Right-to-Left Override | RLO |
| **[PDF](#PDF)** | Pop Directional Format | PDF |
| **[LRI](#LRI)** | Left-to-Right Isolate | LRI |
| **[RLI](#RLI)** | Right-to-Left Isolate | RLI |
| **[FSI](#FSI)** | First Strong Isolate | FSI |
| **[PDI](#PDI)** | Pop Directional Isolate | PDI |

### 3.3 [Resolving Embedding Levels](#Resolving_Embedding_Levels)

The body of the Bidirectional Algorithm uses bidirectional character types,
explicit formatting characters, and bracket pairs to produce a
list of resolved levels. This resolution process consists of the following steps:

* Applying rule [P1](#P1) to split the text into paragraphs, and for each of these:
  + Applying rules [P2](#P2) and [P3](#P3)
    to determine the paragraph level.
  + Applying rule [X1](#X1) (which employs rules [X2](#X2)–[X8](#X8))
    to determine explicit embedding levels and directions.
  + Applying rule [X9](#X9) to remove many control characters from further consideration.
  + Applying rule [X10](#X10) to split the paragraph into isolating run sequences
    and for each of these:
    - Applying rules [W1](#W1)–[W7](#W7)
      to resolve weak types.
    - Applying rules [N0](#N0)–[N2](#N2)
      to resolve neutral types.
    - Applying rules [I1](#I1)–[I2](#I2)
      to resolve implicit embedding levels.

### 3.3.1 [The Paragraph Level](#The_Paragraph_Level)

***[P1](#P1).** Split the text into separate paragraphs. A paragraph separator (type B) is kept
with the previous paragraph. Within each paragraph, apply all the other rules of this algorithm.*

***[P2](#P2).** In each paragraph, find the first character of type L, AL, or R
while skipping over any characters
between an isolate initiator and its matching PDI or,
if it has no matching PDI, the end of the paragraph.*

Note that:

* Because paragraph separators delimit text in this algorithm,
  the character found by this rule will generally be the first
  strong character after a paragraph separator or at the very beginning of the text.
* The characters between an isolate initiator and its matching PDI are ignored by this rule
  because a directional isolate is supposed to have the same effect on the ordering of the surrounding text as a neutral character,
  and the rule ignores neutral characters.
* The characters between an isolate initiator and its matching PDI are ignored by this rule
  even if the depth limit (as defined in rules [X5a](#X5a) through [X5c](#X5c) below)
  prevents the isolate initiator from raising the embedding level.
  This is meant to make the rule easier to implement.
* Embedding initiators (but not the characters within the embedding)
  are ignored in this rule.

***[P3](#P3).** If a character is found in [P2](#P2) and it is of type AL or R, then set the
paragraph embedding level to one; otherwise, set it to zero.*

Whenever a higher-level protocol specifies the paragraph level, rules [P2](#P2) and [P3](#P3) may be overridden: see [HL1](#HL1).

### 3.3.2 [Explicit Levels and Directions](#Explicit_Levels_and_Directions)

All explicit embedding levels are determined from explicit directional formatting characters (embedding, override, and isolate),
by applying the explicit level rule [X1](#X1).
This performs a logical pass over the
paragraph, applying rules [X2](#X2)–[X8](#X8) to each characters in turn.
The following variables are used during this pass:

* A *directional status stack* of max\_depth+2 entries where each entry consists of:
  + An embedding level, which is at least zero and at most max\_depth.
  + A directional override status.
  + A directional isolate status.In addition to supporting the usual destructive “pop” operation,
  the stack also allows read access to its last (i.e. top) entry without popping it.
  For efficiency, that last entry can be kept in a separate variable instead of on the directional status stack,
  but it is easier to explain the algorithm without that optimization.
  At the start of the pass, the directional status stack is initialized to an entry reflecting the paragraph embedding level,
  with the directional override status neutral and the directional isolate status false;
  this entry is not popped off until the end of the paragraph.
  During the pass, the directional status stack always contains entries for all the directional embeddings, overrides,
  and isolates within which the current position lies
  – except those that would overflow the depth limit –
  in addition to the paragraph level entry at the start of the stack.
  The last entry reflects the innermost valid scope within which the pass's current position lies.
  Implementers may find it useful to include more information in each stack entry.
  For example, in an isolate entry, the location of the isolate initiator could be used to create
  a mapping from the location of each valid isolate initiator to the location of the matching PDI, or vice versa.
  However, such optimizations are beyond the scope of this specification.
* A counter called the *overflow isolate count*.

  This reflects the number of isolate initiators
  that were encountered in the pass so far without encountering their matching PDIs,
  but were invalidated by the depth limit and thus are not reflected in the directional status stack.
  They are nested one within the other and the stack's last scope.
  This count is used to determine whether a newly encountered PDI matches and terminates the scope of an overflow isolate initiator, thus decrementing the count,
  as opposed to possibly matching and terminating the scope of a valid isolate initiator, which should result in popping its entry off the directional status stack.
  It is also used to determine whether a newly encountered PDF falls within the scope of an overflow isolate initiator
  and can thus be completely ignored
  (regardless of whether it matches an embedding initiator within the same overflow isolate or nothing at all).
* A counter called the *overflow embedding count*.

  This reflects the number of embedding initiators
  that were encountered in the pass so far without encountering their matching PDF, or encountering the PDI of an isolate within which they are nested,
  but were invalidated by the depth limit, and thus are not reflected in the directional status stack.
  They are nested one within the other and the stack's last scope.
  This count is used to determine whether a newly encountered PDF matches and terminates the scope of an overflow embedding initiator, thus decrementing the count,
  as opposed to possibly matching and terminating the scope of a valid embedding initiator, which should result in popping its entry off the directional status stack.
  However, this count does *not* include embedding initiators encountered within the scope of an overflow isolate
  (i.e. encountered when the overflow isolate count above is greater than zero).
  The scopes of those overflow embedding initiators fall within the scope of an overflow isolate and are terminated when the overflow isolate count turns zero.
  Thus, they do not need to be counted.
  In fact, if they were counted in the overflow embedding count,
  there would be no way to properly update that count when a PDI matching an overflow isolate initiator is encountered:
  without a stack of the overflow scopes, there would be no way to know how many (if any) overflow embedding initiators fall within the scope of that overflow isolate.
* A counter called the *valid isolate count*.

  This reflects the number of isolate initiators
  that were encountered in the pass so far without encountering their matching PDIs,
  and have been judged valid by the depth limit, i.e. all the entries on the stack with a true directional isolate status.
  It ignores all embeddings and overrides,
  and is used to determine without having to look through the directional status stack
  whether a PDI encountered by the pass when the overflow isolate count is zero matches some valid isolate initiator or nothing at all.
  A PDI encountered when this counter is above zero terminates the scope of the isolate initiator it matches,
  as well as the embeddings and overrides nested within it – which appear above it on the stack, or are reflected in the overflow embedding count.

Note that there is no need for a valid embedding count in order to tell
whether a PDF encountered by the pass matches a valid embedding initiator or nothing at all.
That can be decided by checking the directional isolate status of the last entry on the directional status stack and the number of entries on the stack.
If the last entry has a true directional isolate status, it is for a directional isolate within whose scope the PDF lies.
Since the PDF cannot match an embedding initiator outside that isolate,
and there are no embedding entries within the isolate, it matches nothing at all.
And if the last entry has a false directional isolate status, but is also the
only entry on the stack, it belongs to paragraph level, and thus once again
the PDF matches nothing at all.

As each character is processed,
these variables’ values are modified and the character’s explicit embedding level is set
as defined by rules [X2](#X2) through [X8](#X8)
on the basis of the character’s bidirectional type and the variables’ current values.

***[X1](#X1).** At the beginning of a paragraph, perform the following steps:*

* *Set the stack to empty.*
* *Push onto the stack an entry consisting of the paragraph embedding level, a **neutral** directional override status, and a **false** directional isolate status.*
* *Set the overflow isolate count to zero.*
* *Set the overflow embedding count to zero.*
* *Set the valid isolate count to zero.*
* *Process each character iteratively, applying rules [X2](#X2) through
  [X8](#X8).
  Only embedding levels from 0 through max\_depth are valid in this phase.*
  (Note that in the resolution of levels in rules [I1](#I1) and [I2](#I2),
  the maximum embedding level of max\_depth+1 can be reached.)

#### Explicit Embeddings

***[X2](#X2).** With each RLE, perform the following steps:*

* *Compute the least **odd** embedding level greater than the embedding level of the last entry on the directional status stack.*
* *If this new level would be valid,
  and the overflow isolate count and overflow embedding count are both zero,
  then this RLE is valid.
  Push an entry consisting of the new embedding level, **neutral** directional override status, and **false** directional isolate status onto the directional status stack.*
* *Otherwise, this is an overflow RLE.
  If the overflow isolate count is zero, increment the overflow embedding count by one. Leave all other variables unchanged.*

For example, assuming the overflow counts are both zero,
level 0 → 1; levels 1, 2 → 3; levels 3, 4 → 5; and so on.
At max\_depth or if either overflow count is non-zero, the level remains the same (overflow RLE).

***[X3](#X3).** With each LRE, perform the following steps:*

* *Compute the least **even** embedding level greater than the embedding level of the last entry on the directional status stack.*
* *If this new level would be valid,
  and the overflow isolate count and overflow embedding count are both zero,
  then this LRE is valid.
  Push an entry consisting of the new embedding level, **neutral** directional override status, and **false** directional isolate status onto the directional status stack.*
* *Otherwise, this is an overflow LRE.
  If the overflow isolate count is zero, increment the overflow embedding count by one. Leave all other variables unchanged.*

For example, assuming the overflow counts are both zero,
levels 0, 1 → 2; levels 2, 3 → 4; levels 4, 5 → 6; and so on.
At max\_depth or max\_depth-1 (which, being even, would have to go to max\_depth+1) or if either overflow count is non-zero, the level remains the same (overflow LRE).

#### Explicit Overrides

An explicit directional override sets the embedding level in the same way the explicit
embedding formatting characters do, but also changes the bidirectional character type of affected characters to the
override direction.

***[X4](#X4).** With each RLO, perform the following steps:*

* *Compute the least **odd** embedding level greater than the embedding level of the last entry on the directional status stack.*
* *If this new level would be valid,
  and the overflow isolate count and overflow embedding count are both zero,
  then this RLO is valid.
  Push an entry consisting of the new embedding level, **right-to-left** directional override status, and **false** directional isolate status onto the directional status stack.*
* *Otherwise, this is an overflow RLO.
  If the overflow isolate count is zero, increment the overflow embedding count by one. Leave all other variables unchanged.*

***[X5](#X5).** With each LRO, perform the following steps:*

* *Compute the least **even** embedding level greater than the embedding level of the last entry on the directional status stack.*
* *If this new level would be valid,
  and the overflow isolate count and overflow embedding count are both zero,
  then this LRO is valid.
  Push an entry consisting of the new embedding level, **left-to-right** directional override status, and **false** directional isolate status onto the directional status stack.*
* *Otherwise, this is an overflow LRO.
  If the overflow isolate count is zero, increment the overflow embedding count by one. Leave all other variables unchanged.*

#### Isolates

***[X5a](#X5a).**
With each RLI, perform the following steps:*

* *Set the RLI’s embedding level to the embedding level of the last entry on the directional status stack.*
* *If the directional override status of the last entry on the directional status stack is not neutral,
  reset the current character type from RLI to L if the override status is left-to-right,
  and to R if the override status is right-to-left.*
* *Compute the least **odd** embedding level greater than the embedding level of the last entry on the directional status stack.*
* *If this new level would be valid
  and the overflow isolate count and the overflow embedding count are both zero,
  then this RLI is valid.
  Increment the valid isolate count by one, and push an entry consisting of the new embedding level, **neutral** directional override status, and **true** directional isolate status onto the directional status stack.*
* *Otherwise, this is an overflow RLI.
  Increment the overflow isolate count by one, and leave all other variables unchanged.*

***[X5b](#X5b).**
With each LRI, perform the following steps:*

* *Set the LRI’s embedding level to the embedding level of the last entry on the directional status stack.*
* *If the directional override status of the last entry on the directional status stack is not neutral,
  reset the current character type from LRI to L if the override status is left-to-right,
  and to R if the override status is right-to-left.*
* *Compute the least **even** embedding level greater than the embedding level of the last entry on the directional status stack.*
* *If this new level would be valid
  and the overflow isolate count and the overflow embedding count are both zero,
  then this LRI is valid.
  Increment the valid isolate count by one, and push an entry consisting of the new embedding level, **neutral** directional override status, and **true** directional isolate status onto the directional status stack.*
* *Otherwise, this is an overflow LRI.
  Increment the overflow isolate count by one, and leave all other variables unchanged.*

***[X5c](#X5c).**
With each FSI, apply rules [P2](#P2) and [P3](#P3)
to the sequence of characters between the FSI and its matching PDI,
or if there is no matching PDI, the end of the paragraph,
as if this sequence of characters were a paragraph.
If these rules decide on paragraph embedding level 1,
treat the FSI as an RLI in rule [X5a](#X5a).
Otherwise, treat it as an LRI in rule [X5b](#X5b).*

Note that the new embedding level is not set
to the paragraph embedding level determined by P2 and P3.
It goes up by one or two levels, as it would for an LRI or RLI.

#### Non-formatting characters

***[X6](#X6).** For all types besides B, BN, RLE, LRE, RLO, LRO, PDF,
RLI, LRI, FSI, and PDI:*

* *Set the current character’s embedding level to the embedding level of the last entry on the directional status stack.*
* *Whenever the directional override status of the last entry on the directional status stack is not neutral, reset the current
  character type according to the directional override status of the last entry on the directional status stack.*

In other words, if the directional override status of the last entry on the directional status stack is neutral,
then characters retain their normal types:
Arabic characters stay AL, Latin characters stay L, spaces stay WS, and so on. If the directional
override status is right-to-left, then characters become R. If the directional override status is left-to-right, then
characters become L.

Note that the current embedding level is not changed by this rule.

#### Terminating Isolates

A PDI terminates the scope of the isolate initiator it matches.
It also terminates the scopes of all embedding initiators
within the scope of the matched isolate initiator for which a matching PDF has not been encountered.
If it does not match any isolate initiator, it is ignored.

***[X6a](#X6a).** With each PDI, perform the following steps:*

* *If the overflow isolate count is greater than zero, this PDI matches an overflow isolate initiator.
  Decrement the overflow isolate count by one.*
* *Otherwise, if the valid isolate count is zero, this PDI does not match any isolate initiator, valid or overflow.
  Do nothing.*
* *Otherwise, this PDI matches a valid isolate initiator. Perform the following steps:*
  + *Reset the overflow embedding count to zero.*
    (This terminates the scope of those overflow embedding initiators
    within the scope of the matched isolate initiator
    whose scopes have not been terminated by a matching PDF, and which thus lack a matching PDF.)
  + *While the directional isolate status of the last entry on the stack is false,
    pop the last entry from the directional status stack.*
    (This terminates the scope of those valid embedding initiators
    within the scope of the matched isolate initiator
    whose scopes have not been terminated by a matching PDF, and which thus lack a matching PDF.
    Given that the valid isolate count is non-zero,
    the directional status stack before this step is executed
    must contain an entry with directional isolate status true,
    and thus after this step is executed the last entry on the stack will indeed have a true directional isolate status,
    i.e. represent the scope of the matched isolate initiator.
    This cannot be the stack's first entry, which always belongs to the paragraph level and has a false directional status,
    so there is at least one more entry below it on the stack.)
  + *Pop the last entry from the directional status stack
    and decrement the valid isolate count by one.*
    (This terminates the scope of the matched isolate initiator.
    Since the preceding step left the stack with at least two entries, this pop does not leave the stack empty.)
* *In all cases, look up
  the last entry on the directional status stack left after the steps above and:*
  + *Set the PDI’s level to the entry's embedding level.*
  + *If the entry's directional override status is not neutral,
    reset the current character type from PDI to L if the override status is left-to-right,
    and to R if the override status is right-to-left.*

Note that the level assigned to an isolate initiator
is always the same as that assigned to the matching PDI.

#### Terminating Embeddings and Overrides

A PDF terminates the scope of the embedding initiator it matches.
If it does not match any embedding initiator, it is ignored.

***[X7](#X7).** With each PDF,
perform the following steps:*

* *If the overflow isolate count is greater than zero, do nothing.*
  (This PDF is within the scope of an overflow isolate initiator.
  It either matches and terminates the scope of an overflow embedding initiator within that overflow isolate,
  or does not match any embedding initiator.)
* *Otherwise, if the overflow embedding count is greater than zero, decrement it by one.*
  (This PDF matches and terminates the scope of an overflow embedding initiator
  that is not within the scope of an overflow isolate initiator.)
* *Otherwise, if the directional isolate status of the last entry on the directional status stack is false,
  and the directional status stack contains at least two entries,
  pop the last entry from the directional status stack.*
  (This PDF matches and terminates the scope of a valid embedding initiator.
  Since the stack has at least two entries, this pop does not leave the stack empty.)
* *Otherwise, do nothing.*
  (This PDF does not match any embedding initiator.)

#### End of Paragraph

***[X8](#X8).** All explicit directional embeddings, overrides
and isolates are completely
terminated at the end of each paragraph.*

* Explicit paragraph separators (bidirectional character type B) indicate the end of a paragraph. As such, they
  are **not** included in any embedding, override or isolate. They are simply assigned
  the paragraph embedding level.

### 3.3.3 [Preparations for Implicit Processing](#Preparations_for_Implicit_Processing)

The explicit embedding levels that have been assigned to the characters by the preceding rules
will soon be further adjusted on the basis of the characters' implicit bidirectional types.
The adjustment made for a given character will then depend on the characters around it.
However, this dependency is limited by logically dividing the paragraph into sub-units,
and doing the subsequent implicit processing on each unit independently.

***[X9](#X9).** Remove all RLE, LRE, RLO, LRO, PDF, and BN characters.*

* Note that an implementation does not have to actually remove the characters; it just has to
  behave as though the characters were not present for the remainder of the algorithm. Conformance does
  not require any particular placement of these characters as long as all other characters are ordered
  correctly.

  See Section 5, *[Implementation Notes](#Implementation_Notes)*, for information on
  implementing the algorithm without removing the formatting characters.
* The *zero width joiner* and *non-joiner* affect the shaping of the adjacent characters—those
  that are adjacent in the original backing-store order, even though those characters may end up
  being rearranged to be non-adjacent by the Bidirectional Algorithm. For more information, see
  Section 6.1,
  *[Joiners](#Joiners)*.
* Note that FSI, LRI, RLI, and PDI characters are **not** removed.
  As indicated by the rules below, they are used, in part, to determine the paragraph’s isolating run sequences,
  within which they are then treated as neutral characters.
  Nevertheless, they are of course zero-width characters and, like LRM and RLM, should not be visible in the final output.

***[X10](#X10).** Perform the following steps:*

* *Compute the set of isolating run sequences as specified by [BD13](#BD13),
  based on the bidirectional types of the characters
  and the embedding levels assigned by the rules above
  ([X1](#X1)–[X9](#X9)).*
* *Determine the *start-of-sequence* (**sos**)
  and end-of-sequence (**eos**) types,
  either L or R, for each isolating run sequence.
  These depend on the higher of the two levels on either side of the sequence boundary:*
  + *For sos, compare the level of the first character in the sequence
    with the level of the character preceding it in the paragraph (not counting characters removed by [X9](#X9)),
    and if there is none, with the paragraph embedding level.*
  + *For eos, compare the level of the last character in the sequence
    with the level of the character following it in the paragraph (not counting characters removed by [X9](#X9)),
    and if there is none or the last character of the sequence is an isolate initiator (lacking a matching PDI),
    with the paragraph embedding level.*
  + *If the higher level is odd, the sos or eos is R; otherwise, it is L.*
  + Note that these computations must use the embedding levels assigned by the rules above,
    before any changes are made to them in the steps below.
* *Apply rules [W1](#W1)–[W7](#W7),
  [N0](#N0)–[N2](#N2),
  and [I1](#I1)–[I2](#I2),
  in the order in which they appear below,
  to each of the isolating run sequences,
  applying one rule to all the characters in the sequence in the order in which they occur in the sequence
  before applying another rule to any part of the sequence.
  The order that one isolating run sequence is treated relative to another does not matter.
  When applying a rule to an isolating run sequence,
  the last character of each level run in the isolating run sequence
  is treated as if it were immediately followed by the first character in the next level run in the sequence, if any.*

Here are some examples, each of which is assumed to be a paragraph
with base level 0 where no character sequence *texti* contains explicit directional formatting characters or paragraph separators.
The dots in the examples are intended to separate elements for visual clarity; they are not part of the text.

Example 1: *text1*·RLE·*text2*·LRE·*text3*·PDF·*text4*·PDF·RLE·*text5*·PDF·*text6*

| Isolating Run Sequence | Embedding Level | sos | eos |
| --- | --- | --- | --- |
| *text1* | 0 | L | R |
| *text2* | 1 | R | L |
| *text3* | 2 | L | L |
| *text4*·*text5* | 1 | L | R |
| *text6* | 0 | R | L |

Example 2: *text1*·RLI·*text2*·LRI·*text3*·PDI·*text4*·PDI·RLI·*text5*·PDI·*text6*

| Isolating Run Sequence | Embedding Level | sos | eos |
| --- | --- | --- | --- |
| *text1*·RLI·PDI·RLI·PDI·*text6* | 0 | L | L |
| *text2*·LRI·PDI·*text4* | 1 | R | R |
| *text3* | 2 | L | L |
| *text5* | 1 | R | R |

Example 3: *text1*·RLE·*text2*·LRI·*text3*·RLE·*text4*·PDI·*text5*·PDF·*text6*

| Isolating Run Sequence | Embedding Level | sos | eos |
| --- | --- | --- | --- |
| *text1* | 0 | L | R |
| *text2*·LRI·PDI·*text5* | 1 | R | R |
| *text3* | 2 | L | R |
| *text4* | 3 | R | R |
| *text6* | 0 | R | L |

### 3.3.4 [Resolving Weak Types](#Resolving_Weak_Types)

Weak types are now resolved one isolating run sequence at a time.
At isolating run sequence boundaries where the type of
the character on the other side of the boundary is required, the type assigned to
*sos* or *eos* is used.

First, each nonspacing mark is resolved based on the character it follows.

***[W1](#W1).** Examine each nonspacing mark (NSM) in the isolating run sequence, and change the
type of the NSM to Other Neutral if the previous character is an isolate initiator or PDI, and to
the type of the previous character otherwise.
If the NSM is at the start of the
isolating run sequence, it will get the type of **sos**.*
(Note that in an isolating run sequence, an isolate initiator followed by an NSM or any type other than PDI must be an overflow isolate initiator.)

Assume in this example that *sos* is R:

> ```
>
> AL  NSM NSM → AL  AL  AL
>
> sos NSM     → sos R
>
> LRI NSM     → LRI ON
>
> PDI NSM     → PDI ON
>
> ```

The text is next parsed for numbers. This pass will change the directional
types European Number Separator, European Number Terminator, and Common
Number Separator to be European Number text, Arabic Number text, or Other
Neutral text. The text to be scanned may have already had its type altered
by directional overrides. If so, then it will not parse as numeric.

***[W2](#W2).** Search backward from each instance of a European number until the
first strong type (R, L, AL, or **sos**) is found. If an AL is found, change the type of
the European number to Arabic number.*

> ```
>
> AL EN     → AL AN
>
> AL NI EN  → AL NI AN
>
> sos NI EN → sos NI EN
>
> L NI EN   → L NI EN
>
> R NI EN   → R NI EN
>
> ```

***[W3](#W3).** Change all ALs to R.*

***[W4](#W4).** A single European separator between two European numbers changes to a
European number. A single common separator between two numbers of the same type changes to that
type.*

> ```
> EN ES EN → EN EN EN
>
> EN CS EN → EN EN EN
>
> AN CS AN → AN AN AN
> ```

***[W5](#W5).** A sequence of European terminators adjacent to European numbers changes
to all European numbers.*

> ```
> ET ET EN → EN EN EN
>
> EN ET ET → EN EN EN
>
> AN ET EN → AN EN EN
> ```

***[W6](#W6).** Otherwise, separators and terminators change to Other Neutral.*

> ```
> AN ET    → AN ON
>
> L  ES EN → L  ON EN
>
> EN CS AN → EN ON AN
>
> ET AN    → ON AN
> ```

***[W7](#W7).** Search backward from each instance of a European number until the
first strong type (R, L, or **sos**) is found. If an L is found, then change the type of
the European number to L.*

> ```
> L  NI EN → L  NI  L
>
> R  NI EN → R  NI  EN
> ```

### 3.3.5 [Resolving Neutral and Isolate Formatting Types](#Resolving_Neutral_Types)

In the next phase, neutral and isolate formatting (i.e. [NI](#NI)) characters are resolved
one isolating run sequence at a time.
Its results are that all
[NIs](#NI) become either **R** or **L**.
Generally, [NIs](#NI) take on the direction of the
surrounding text. In case of a conflict, they take on the embedding direction.
At isolating run sequence boundaries where the type
of the character on the other side of the boundary is required, the type assigned
to *sos* or *eos*
is used.

Bracket pairs within an isolating run sequence are processed as units so that both the opening
and the closing paired bracket in a pair resolve to the same direction.
Note that this rule is applied based on the current bidirectional character type of each paired bracket
and not the original type, as this could have changed under [X6](#X6). The current bidirectional character type
may also have changed under a previous iteration of the *for* loop in [N0](#N0) in the case of nested bracket pairs.

***[N0](#N0).** Process bracket pairs in an isolating run sequence sequentially in the logical
order of the text positions of the opening paired brackets using the logic given below.
Within this scope, bidirectional types EN and AN are treated as R.*

* *Identify the bracket pairs in the current isolating run sequence according to [BD16](#BD16).*
* *For each bracket-pair element in the list of pairs of text positions*
  1. *Inspect the bidirectional types of the characters enclosed
     within the bracket pair.*
  2. *If any strong type (either L or R) matching
     the embedding direction is found, set the type for both brackets in the pair to match
     the embedding direction.*
     > ```
     >
     > o [ e ] o → o e e e o
     >
     > o [ o e ] → o e o e e
     >
     > o [ NI e ] → o e NI e e
     >
     > ```
  3. *Otherwise, if there is a strong type it must be opposite the embedding direction. Therefore, test for an established context with a preceding strong type by checking backwards before the opening paired bracket until the first strong type (L, R, or sos) is found.*
     1. *If the preceding strong type is also opposite the embedding direction, context is established, so set the type for both brackets in the pair to that direction.*
        > ```
        >
        > o [ o ] e → o o o o e
        >
        > o [ o NI ] o → o o o NI o o
        >
        > ```
     2. *Otherwise set the type for both brackets in the pair to the embedding direction.*
        > ```
        >
        > e [ o ] o → e e o e o
        >
        > e [ o ] e → e e o e e
        >
        > ```
  4. *Otherwise, there are no strong types within the bracket pair. Therefore, do not set the type for that bracket pair.*
     > ```
     >
     > e ( NI ) o → e ( NI ) o
     >
     > ```

     Note that if the enclosed text contains no strong types the bracket pairs will both resolve
     to the same level when resolved individually using rules [N1](#N1) and [N2](#N2).
* *Any number of characters that had original bidirectional character type NSM prior
  to the application of [W1](#W1) that immediately follow a paired bracket
  which changed to L or R under [N0](#N0) should change
  to match the type of their preceding bracket.*

**Example 1**. Bracket pairs are resolved sequentially in logical order of the opening paired brackets.

(RTL paragraph direction)

| Storage | `AB` | `(` | `CD` | `[` | `&` | `ef` | `]` | `!` | `)` | `gh` |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Bidi\_Class | `R` | `ON` | `R` | `ON` | `ON` | `L` | `ON` | `ON` | `ON` | `L` |
| N0 applied (first pair) |  | `N0b: ON→R` |  |  |  |  |  |  | `N0b: ON→R` |  |
| N0 applied (second pair) |  |  |  | `N0c2: ON→R` |  |  | `N0c2: ON→R` |  |  |  |
| Display | `gh(![ef&]DC)BA` | | | | | | | | | |

**Example 2**. Bracket pairs enclosing mixed strong types take the paragraph direction.

(RTL paragraph direction)

| Storage | `smith` |  | `(` | `fabrikam` |  | `ARABIC` | `)` |  | `HEBREW` |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| Bidi\_Class | `L` | `WS` | `ON` | `L` | `WS` | `R` | `ON` | `WS` | `R` |
| N0 applied |  |  | `N0b: ON→R` |  |  |  | `N0b: ON→R` |  |  |
| Display | `WERBEH (CIBARA fabrikam) smith` | | | | | | | | |

Note that in the above example, the resolution of the bracket pairs is
stable if the order of smith and HEBREW, or fabrikam and ARABIC, is reversed.

**Example 3**. Bracket pairs enclosing strong types opposite the
embedding direction with additional strong-type context take the direction
opposite the embedding direction.

(RTL paragraph direction)

| Storage | `ARABIC` |  | `book` | `(` | `s` | `)` |
| --- | --- | --- | --- | --- | --- | --- |
| Bidi\_Class | `R` | `WS` | `L` | `ON` | `L` | `ON` |
| N0 applied |  |  |  | `N0c1: ON→L` |  | `N0c1: ON→L` |
| Display | `book(s) CIBARA` | | | | | |

***[N1](#N1).** A sequence of [NIs](#NI) takes the direction of the surrounding strong
text if the text on both sides has the same direction.
European and Arabic numbers act as if they were R in terms of their influence on
[NIs](#NI).
The start-of-sequence (**sos**)
and end-of-sequence (**eos**) types
are used at isolating run sequence boundaries.*

> ```
>
>  L  NI   L  →   L  L   L
>
>  R  NI   R  →   R  R   R
>
>  R  NI  AN  →   R  R  AN
>
>  R  NI  EN  →   R  R  EN
>
> AN  NI   R  →  AN  R   R
>
> AN  NI  AN  →  AN  R  AN
>
> AN  NI  EN  →  AN  R  EN
>
> EN  NI   R  →  EN  R   R
>
> EN  NI  AN  →  EN  R  AN
>
> EN  NI  EN  →  EN  R  EN
> ```

***[N2](#N2).** Any remaining [NIs](#NI) take the embedding direction.*

> ```
> NI → e
> ```

The embedding direction for the given [NI](#NI)
character is derived from its embedding level: L if the character is set to
an even level, and R if the level is odd. (See [BD3](#BD3).)

Assume in the following example that *eos* is L and *sos* is R. Then an application of
[N1](#N1) and [N2](#N2) yields the following:

> ```
> L   NI eos → L   L eos
>
> R   NI eos → R   e eos
>
> sos NI L   → sos e L
>
> sos NI R   → sos R R
> ```

*Examples.* A list of numbers separated by neutrals and embedded in a directional run will
come out in the run’s order.

```
Storage:	he said "THE VALUES ARE 123, 456, 789, OK".

Display:	he said "KO ,789 ,456 ,123 ERA SEULAV EHT".
```

In this case, both the comma and the space between the numbers take on the direction of the
surrounding text (uppercase = right-to-left), ignoring the numbers. The commas are not considered
part of the number because they are not surrounded on both sides
by digits (see
Section 3.3.4, *Resolving Weak Types*). However, if
there is a preceding left-to-right sequence, then European numbers will adopt that direction:

```
Storage:	IT IS A bmw 500, OK.

Display:	.KO ,bmw 500 A SI TI
```
### 3.3.6 [Resolving Implicit Levels](#Resolving_Implicit_Levels)

In the final phase, the embedding level of text may be increased, based on the resolved
character type. Right-to-left text will always end up with an odd level, and left-to-right and
numeric text will always end up with an even level. In addition, numeric text will always end up
with a higher level than the paragraph level. (Note that it is possible for text to end up at
level max\_depth+1 as a result of this process.) This results in the following rules:

***[I1](#I1).** For all characters with an even (left-to-right) embedding
level, those of type R go up one level and those of type AN or EN go up two levels.*

***[I2](#I2).** For all characters with an odd (right-to-left)
embedding level, those of type L, EN or AN go up one level.*

*Table 5* summarizes the results of the implicit algorithm.

Table 5. [Resolving Implicit Levels](#Table_Resolving_Implicit_Levels)

| Type | Embedding Level | |
| --- | --- | --- |
| Even | Odd |
| **L** | EL | EL+1 |
| **R** | EL+1 | EL |
| **AN** | EL+2 | EL+1 |
| **EN** | EL+2 | EL+1 |

### 3.4 [Reordering Resolved Levels](#Reordering_Resolved_Levels)

The following rules describe the logical process of finding the correct display order.
As opposed to resolution phases,
these rules act on a per-line basis *and are applied **after** any line wrapping is
applied to the paragraph.*

Logically there are the following steps:

* The levels of the text are determined according to the previous rules.
* The characters are shaped into glyphs according to their context *(taking the embedding
  levels into account for mirroring).*
* The accumulated widths of those glyphs *(in logical order)* are used to determine line
  breaks.
* For each line, rules [L1](#L1)–[L4](#L4) are used to reorder the characters on that line.
* The glyphs corresponding to the characters on the line are displayed in that order.

***[L1](#L1).** On each line, reset the embedding level of the following characters to
the paragraph embedding level:*

1. *Segment separators,*
2. *Paragraph separators,*
3. *Any sequence of whitespace characters and/or isolate formatting characters (FSI, LRI, RLI, and PDI)
   preceding a segment separator or paragraph separator, and*
4. *Any sequence of whitespace characters and/or isolate formatting characters (FSI, LRI, RLI, and PDI)
   at the end of the line.*

* The types of characters used here are the *original* types, not those modified by the
  previous phase.
* Because a *paragraph separator* breaks lines, there will be at most one per line, at the end of
  that line.

In combination with the following rule, this means that trailing whitespace will appear at the
visual end of the line (in the paragraph direction). Tabulation will always have a consistent
direction within a paragraph.

***[L2](#L2).** From the highest level found in the text to the lowest odd level on
each line, including intermediate levels not actually present in the text, reverse
any contiguous sequence of characters that are at that level or higher.*

This rule reverses a progressively larger series of substrings.

The following examples illustrate the reordering, showing the
successive steps in application of Rule [L2](#L2).
The original text is shown in the "Storage" row in the
example tables.
The invisible, zero-width formatting characters LRI, RLI, and PDI
are represented with the symbols **>**,
**<**, and **=**, respectively.
The application of the rules from *Section 3.3, [Resolving Embedding Levels](#Resolving_Embedding_Levels)*
and of the Rule
[L1](#L1) results in the resolved levels listed in the "Resolved
Levels" row.
(Since these examples only make use of the isolate formatting characters, Rule [X9](#X9) does not remove any characters.
Note that Example 3 would not work if it used embeddings instead because the two right-to-left phrases would have merged into a single right-to-left run,
together with the neutral punctuation in between.)
Each successive row thereafter shows one pass of reversal from Rule [L2](#L2), such as
"Reverse levels 1-2". At each iteration, the underlining shows the text that has been reversed.

The paragraph embedding level for the first, second, and third examples is 0 (left-to-right direction),
and for the fourth example is 1 (right-to-left direction).

**Example 1**. (embedding level = 0)

| Storage | `car means CAR.` |
| --- | --- |
| Resolved levels | `00000000001110` |
| Reverse level 1 | `car means RAC.` |
| Display | car means RAC. |

**Example 2**. (embedding level = 0)

| Storage | `<car MEANS CAR.=` |
| --- | --- |
| Resolved levels | `0222111111111110` |
| Reverse level 2 | `<rac MEANS CAR.=` |
| Reverse levels 1-2 | `<.RAC SNAEM car=` |
| Display | .RAC SNAEM car |

**Example 3**. (embedding level = 0)

| Storage | `he said “<car MEANS CAR=.” “<IT DOES=,” she agreed.` |
| --- | --- |
| Resolved levels | `000000000022211111111110000001111111000000000000000` |
| Reverse level 2 | `he said “<rac MEANS CAR=.” “<IT DOES=,” she agreed.` |
| Reverse levels 1-2 | `he said “<RAC SNAEM car=.” “<SEOD TI=,” she agreed.` |
| Display | he said “RAC SNAEM car.” “SEOD TI,” she agreed. |

**Example 4**. (embedding level = 1)

| Storage | `DID YOU SAY ’>he said “<car MEANS CAR=”=‘?` |
| --- | --- |
| Resolved levels | `111111111111112222222222444333333333322111` |
| Reverse level 4 | `DID YOU SAY ’>he said “<rac MEANS CAR=”=‘?` |
| Reverse levels 3-4 | `DID YOU SAY ’>he said “<RAC SNAEM car=”=‘?` |
| Reverse levels 2-4 | `DID YOU SAY ’>”=rac MEANS CAR<“ dias eh=‘?` |
| Reverse levels 1-4 | `?‘=he said “<RAC SNAEM car=”>’ YAS UOY DID` |
| Display | ?‘he said “RAC SNAEM car”’ YAS UOY DID |

***[L3](#L3).** Combining marks applied to a right-to-left base character will at this
point precede their base character. If the rendering engine expects them to follow the base
characters in the final display process, then the ordering of the marks and the base character
must be reversed.*

Many font designers provide default metrics for combining marks that support rendering by
simple overhang. Because of the reordering for right-to-left characters, it is common practice to
make the glyphs for most combining characters overhang to the left (thus assuming the characters
will be applied to left-to-right base characters) and make the glyphs for combining characters in
right-to-left scripts overhang to the right (thus assuming that the characters will be applied to
right-to-left base characters). With such fonts, the display ordering of the marks and base glyphs
may need to be adjusted when combining marks are applied to “unmatching” base characters. See *Section 5.13, Rendering Nonspacing Marks* of [[Unicode](https://www.unicode.org/reports/tr41/tr41-28.html#Unicode)], for more
information.

***[L4](#L4).** A character is
depicted by a mirrored glyph if and only if (a)
the resolved directionality of that character is R,
and (b) the Bidi\_Mirrored
property value of that character is Yes.*

* *The Bidi\_Mirrored property
  is defined by Section 4.7, Bidi Mirrored of [[Unicode](https://www.unicode.org/reports/tr41/tr41-28.html#Unicode)];
  the property values are specified in [[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)].*
* *This rule can be overridden in certain
  cases; see
  [HL6](#HL6).*

For example, U+0028 LEFT PARENTHESIS—which is interpreted in the Unicode
Standard as an opening parenthesis—appears as “**(**” when its resolved
level is even, and as the mirrored glyph “**)**”
when its resolved level is odd. Note that for
backward compatibility the characters U+FD3E ( ﴾ ) ORNATE LEFT PARENTHESIS
and U+FD3F ( ﴿ ) ORNATE RIGHT PARENTHESIS are not mirrored.

### 3.5 [Shaping](#Shaping)

Cursively connected scripts, such as Arabic or
Syriac, require the selection of positional character shapes that depend on
adjacent characters (see *Section 9.2, Arabic* of [[Unicode](https://www.unicode.org/reports/tr41/tr41-28.html#Unicode)]).
Shaping is logically applied *after* Rule [I2](#I2) of the Bidirectional Algorithm
and is limited to characters within the same level run.
(Note that there is no practical difference between limiting shaping to a level run
and an isolating run sequence because the isolate initiator and PDI characters are defined to have joining type U, i.e. non-joining.
Thus, the characters before and after a directional isolate will not join across the isolate,
even if the isolate is empty or overflows the depth limit.)
Consider the following example string
of Arabic characters, which is represented in memory as characters 1, 2, 3, and 4, and where the first two characters
are overridden to be LTR. To show both paragraph directions, the next two are embedded, but with
the normal RTL direction.

| **1** | **2** | ***3*** | ***4*** |
| --- | --- | --- | --- |
| ج 062C JEEM | ع 0639 AIN | ل 0644 LAM | م 0645 MEEM |
| **L** | **L** | **R** | **R** |

One can use explicit directional formatting characters to achieve this effect in plain text or use markup in HTML, as in the
examples below. (The **bold** text would be for the right-to-left paragraph direction.)

* LRM/**RLM** LRO *JEEM AIN* PDF RLO *LAM MEEM* PDF
* <p dir="ltr"/"**rtl**">LRO *JEEM AIN* PDF RLO *LAM MEEM* PDF</p>
* <p dir="ltr"/"**rtl**"><bdo dir="ltr">*JEEM AIN*</bdo>

                <bdo dir="rtl">*LAM MEEM*</bdo></p>

The resulting shapes will be the following, according to the paragraph direction:

| Left-Right Paragraph | Right-Left Paragraph |
| --- | --- |
| | **1** | **2** | ***4*** | ***3*** | | --- | --- | --- | --- | | ﺞJEEM-F | ﻋAIN-I | ﻢMEEM-F | ﻟLAM-I | | | ***4*** | ***3*** | **1** | **2** | | --- | --- | --- | --- | | ﻢMEEM-F | ﻟLAM-I | ﺞJEEM-F | ﻋAIN-I | |

### 3.5.1 [Shaping and Line Breaking](#Shaping_and_line_breaking)

The process of breaking a paragraph into one or
more lines that fit within particular bounds is outside the scope of the
Bidirectional Algorithm. Where character shaping is involved, the width
calculations must be based on the shaped glyphs.

Note that the *soft-hyphen* (SHY) works in
cursively connected scripts as it does in other scripts. That is, it
indicates a point where the line could be broken in the middle of a word. If
the rendering system breaks at that point, the display—including shaping—should be what is appropriate for the given language. For more information
on this and other line breaking issues, see Unicode Standard Annex #14, “Line Breaking Properties” [[UAX14](https://www.unicode.org/reports/tr41/tr41-28.html#UAX14)].

## 4 [Bidirectional Conformance](#Bidirectional_Conformance)

The Bidirectional Algorithm specifies part of the intrinsic semantics of right-to-left
characters and is thus required for conformance to the Unicode Standard where any such
characters are displayed.

A process that claims conformance to this specification shall satisfy the following
clauses:

***[UAX9-C1](#C1).**
In the absence of a permissible higher-level protocol, a
process that renders text shall display all visible representations of characters (excluding
formatting characters) in the order described by Section 3,
[Basic Display Algorithm](#Basic_Display_Algorithm), of this annex. In particular, this includes definitions
[BD1](#BD1)–[BD16](#BD16) and steps*  *[P1](#P1)–[P3](#P3),
[X1](#X1)–[X10](#X10), [W1](#W1)–[W7](#W7),
[N0](#N0)–[N2](#N2), [I1](#I1)–[I2](#I2), and
[L1](#L1)–[L4](#L4).*

As is the case for all other Unicode algorithms, this is a *logical* description—particular implementations can have more efficient mechanisms as long as they produce the same
results. See C18 in *Chapter 3, Conformance* of [[Unicode](https://www.unicode.org/reports/tr41/tr41-28.html#Unicode)], and the notes following.

***[UAX9-C2](#C2).**
The only permissible higher-level protocols are those
listed in Section 4.3,
[Higher-Level Protocols](#Higher-Level_Protocols). They are [HL1](#HL1), [HL2](#HL2),
[HL3](#HL3), [HL4](#HL4), [HL5](#HL5), and [HL6](#HL6).*

> Note: Use of higher-level protocols is discouraged,
> because it introduces interchange problems and can lead to security
> problems. For more information, see Unicode Technical Report #36, “Unicode Security
> Considerations” [[UTR36](https://www.unicode.org/reports/tr41/tr41-28.html#UTR36)].

### 4.1 [Boundary Neutrals](#Boundary_Neutrals)

The goal in marking a formatting or control character as BN is that it have no effect on the rest
of the algorithm. (ZWJ and ZWNJ are exceptions; see [X9](#X9)). Because
conformance does not require the
precise ordering of formatting characters with respect to others,
implementations can handle them in different ways as long as they preserve the ordering
of the other characters.

### 4.2 [Explicit Formatting Characters](#Explicit_Formatting_Characters)

As with any Unicode characters, systems do not have to support any particular explicit
directional formatting character (although it is not generally useful to include a terminating character
without including the initiator). Generally, conforming systems will fall into four classes:

* *No bidirectional formatting.* This implies that the system does not visually interpret
  characters from right-to-left scripts.
* *Implicit bidirectionality.* The implicit Bidirectional Algorithm and the directional
  marks ALM, RLM and LRM are supported.
* *Non-isolate bidirectionality.* The implicit Bidirectional Algorithm, the implicit directional
  marks, and the explicit non-isolate directional formatting characters are supported:
  ALM, RLM, LRM, LRE, RLE, LRO, RLO,
  PDF.
* *Full bidirectionality.* The implicit Bidirectional Algorithm, the implicit directional
  marks, and all the explicit directional formatting characters are supported:
  ALM, RLM, LRM, LRE, RLE, LRO, RLO,
  PDF, FSI, LRI, RLI, PDI.

### 4.3 [Higher-Level Protocols](#Higher-Level_Protocols)

The following clauses are the only permissible ways for systems to apply higher-level protocols
to the ordering of bidirectional text. Some of the clauses apply to *segments* of structured
text. This refers to the situation where text is interpreted as being structured, whether with
explicit markup such as XML or HTML, or internally structured such as in a word processor or
spreadsheet. In such a case, a segment is span of text that is distinguished in some way by the
structure.

***[HL1](#HL1).**
Override [P3](#P3), and set the paragraph embedding level explicitly.
This does **not** apply when deciding how to treat FSI in rule [X5c](#X5c).*

* A higher-level protocol may set any paragraph level. This can be done on the basis of the context, such as on a table cell, paragraph, document, or system level. ([P2](#P2) may be skipped if [P3](#P3) is overridden). Note that this does not allow a higher-level protocol to override the limit specified in [BD2](#BD2).
* A higher-level protocol may apply rules equivalent to [P2](#P2) and [P3](#P3) but default to level 1 (RTL) rather than 0 (LTR) to match overall RTL context.
* A higher-level protocol may use an entirely different algorithm that heuristically auto-detects the paragraph embedding level based on the paragraph text and its context. For example, it could base it on whether there are more RTL characters in the text than LTR. As another example, when the paragraph contains no strong characters, its direction could be determined by the levels of the paragraphs before and after.

***[HL2](#HL2).** Override [W2](#W2), and set EN or AN explicitly.*

* A higher-level protocol may reset characters of type EN to AN, or vice versa, and ignore
  [W2](#W2). For example, style sheet or markup information can be used within a span of text to
  override the setting of EN text to be always be AN, or vice versa.

***[HL3](#HL3).** Emulate explicit directional formatting characters.*

* A higher-level protocol can impose a directional embedding, isolate or override on a segment of
  structured text. The behavior must always be defined by reference to what would happen if
  the equivalent explicit directional formatting characters as defined in the algorithm were inserted into the text. For
  example, a style sheet or markup can modify the embedding level on a span of text.

***[HL4](#HL4).** Apply the Bidirectional Algorithm to segments*.

* The Bidirectional Algorithm can be applied independently to one or more segments of structured
  text. For example, when displaying a document consisting of textual data and visible markup
  in an editor, a higher-level process can handle syntactic elements in the markup separately
  from the textual data.

***[HL5](#HL5).** Provide artificial context.*

* Text can be processed by the Bidirectional Algorithm as if it were preceded by a character of a
  given type and/or followed by a character of a given type. This allows a piece of text that
  is extracted from a longer sequence of text to behave as it did in the larger context.

***[HL6](#HL6).** Additional mirroring*.

* Certain characters that do not
  have the Bidi\_Mirrored property can also be depicted by
  a mirrored glyph in specialized contexts. Such contexts include, but are
  not limited to, historic scripts and associated punctuation, private-use
  characters, and characters in mathematical expressions. (See Section 7, *[Mirroring](#Mirroring)*.)
  These characters are those that fit at least one of the following
  conditions:
  1. Characters with a resolved directionality of R
  2. Characters with a resolved
     directionality of L and whose bidirectional type is R or AL

Clauses [HL1](#HL1) and [HL3](#HL3) are specialized applications of the more general clauses [HL4](#HL4) and [HL5](#HL5). They are provided here explicitly because they directly correspond to common operations.

As an example of the application of [HL4](#HL4), suppose an XML document contains the following
fragment. (Note: This is a simplified example for illustration: element names, attribute names,
and attribute values could all be involved.)

> `ARABICenglishARABIC<e1 type='ab'>ARABICenglish<e2 type='cd'>english`

This can be analyzed as being five different segments:

1. `ARABICenglishARABIC`
2. `<e1 type='ab'>`
3. `ARABICenglish`
4. `<e2 type='cd'>`
5. `english`

To make the XML file readable as source text, the display in an editor
could order these elements all in a uniform direction (for example, all left-to-right) and apply the
Bidirectional Algorithm to each
field separately. It could also choose to order the element names, attribute names, and attribute
values uniformly in the same direction (for example, all left-to-right). For final display, the markup
could be ignored, allowing all of the text (segments a, c, and e) to be reordered together.

### 4.4 [Bidirectional Conformance Testing](#Bidi_Conformance_Testing)

The *Unicode Character Database* [[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)]
includes two files that provide conformance tests for implementations of
the Bidirectional Algorithm [[Tests9](https://www.unicode.org/reports/tr41/tr41-28.html#Tests9)].
One of the test files, `BidiTest.txt`, comprises exhaustive test sequences
of bidirectional types up to a given length, currently 4. The other test file, `BidiCharacterTest.txt`,
contains test sequences of explicit code points, including, for example, bracket pairs.
The format of each test file is described in the header of that file.

## 5 [Implementation Notes](#Implementation_Notes)

### 5.1 [Reference Code](#Reference_Code)

Reference implementations of the Bidirectional Algorithm written in C and in Java are available.
The source code can be downloaded from [[Code9](https://www.unicode.org/reports/tr41/tr41-28.html#Code9)].
Implementers are encouraged to use these resources to test their implementations.

The reference code is designed to follow the steps of the algorithm without applying
any optimizations. An example of an effective optimization is to first test for right-to-left characters and
invoke the Bidirectional Algorithm only if they are present. Another example of optimization is in matching bracket pairs.
The bidirectional bracket pairs (the characters with Bidi\_Paired\_Bracket\_Type property values Open and Close)
constitute a subset of the characters with bidirectional type ON. Conversely, the characters with a bidirectional type
distinct from ON have the Bidi\_Paired\_Bracket\_Type property value None. Therefore, lookup of Bidi\_Paired\_Bracket\_Type
property values for the identification of bracket pairs can be optimized by restricting the processing to characters
whose bidirectional type is ON.

An online demo is also available at [[Demo9](https://www.unicode.org/reports/tr41/tr41-28.html#Demo9)],
which shows the results of the Bidirectional Algorithm, as well as the embedding levels and
the rules invoked for each character. Implementers are cautioned when using that online demo that it implements
the rules for UBA as of Version 6.2, and has not been updated for the major changes to UBA in Version 6.3 and
subsequent versions. The online demo also does not handle supplemental characters gracefully.

### 5.2 [Retaining BNs and Explicit Formatting Characters](#Retaining_Explicit_Formatting_Characters)

Some implementations may wish to retain the explicit directional embedding and override formatting characters
and BNs when running the algorithm.
In fact, retention of these formatting characters and BNs is important to
users who need to display a graphic representation of hidden characters, and who thus need to obtain
their visual positions for display.

The following describes
how this may be done by implementations that do retain these characters
through the steps of the algorithm. Note that this description is an informative
implementation guideline; it should provide the same results as the explicit algorithm above, but
in case of any deviation the explicit algorithm is the normative statement for conformance.

* In rules [X2](#X2) through [X5](#X5),
  insert an initial step setting the explicit embedding or override character's
  embedding level to the embedding level of the last entry on the directional status stack. This
  applies to RLE, LRE, RLO, and LRO.
* In rule [X6](#X6), remove the exclusion of
  BN characters. In other words, apply the rule to all types except
  B, RLE, LRE, RLO, LRO, PDF, RLI, LRI, FSI, and PDI.
* In rule [X7](#X7), add a final step setting
  the embedding level of the PDF to the embedding level of the last entry on the
  directional status stack, in all cases.
* In rule [X9](#X9), do not remove any characters, but turn
  all RLE, LRE, RLO, LRO, and PDF characters into BN.
* In rule [X10](#X10),
  when determining the sos and eos for an isolating run sequence,
  skip over any BNs when looking for the character preceding the isolating run sequence's first character and following its last character.
* In rule [W1](#W1), search backward from each NSM to the first character in the isolating run sequence whose
  bidirectional type is not BN, and set the NSM to ON if it is an isolate initiator or PDI, and to its type otherwise.
  If the NSM is the first non-BN character, change the NSM to the type of *sos*.
* In rule [W4](#W4), scan past BN types that are adjacent to ES or CS.
* In rule [W5](#W5), change all appropriate sequences of ET and BN, not just ET.
* In rule [W6](#W6), change all BN types adjacent to ET, ES, or CS to ON as well.
* In rule [W7](#W7), scan past BN.
* In rules [N0](#N0)–[N2](#N2), treat BNs that adjoin
  neutrals the same as those neutrals.
* In rules [I1](#I1) and [I2](#I2), ignore BN.
* In rule [L1](#L1), include the embedding and override formatting characters and BNs
  together with whitespace characters and isolate formatting characters in the sequences
  whose level gets reset before a separator or line break. Resolve any LRE, RLE, LRO, RLO, PDF, or BN to the level of the preceding character if there is one,
  and otherwise to the base level.

## 6 [Usage](#Usage)

### 6.1 [Joiners](#Joiners)

As described under [X9](#X9), the *zero width joiner* and
*non-joiner* affect the
shaping of the adjacent characters—those that are adjacent in the original backing-store
order—even though those characters may end up being rearranged to be non-adjacent by the
Bidirectional Algorithm. To determine the joining behavior of a particular
character after applying the Bidirectional Algorithm, there are two main
strategies:

* When shaping, an implementation can refer back to the original backing store to see if there
  were adjacent ZWNJ or ZWJ characters.
* Alternatively, the implementation can replace ZWJ and ZWNJ by an out-of-band character
  property associated with those adjacent characters, so that the information does not interfere
  with the Bidirectional Algorithm and the information is preserved across rearrangement of those
  characters. Once the Bidirectional Algorithm has been applied, that out-of-band information can then be
  used for proper shaping.

### 6.2 [Vertical Text](#Vertical_Text)

In the case of vertical line orientation, there are multiple ways
to display bidirectional text. Some
methods use the Bidirectional Algorithm, and some do not. The Unicode Standard does not specify whether
text is presented with horizontal or vertical layout, or for vertical
layout whether elements within the line are rotated. That is left up to higher-level protocols.
For example, one of the common approaches for vertical line orientation is to rotate all the glyphs
uniformly 90° clockwise. The
Bidirectional Algorithm is used with this method. While some characters end up ordered from bottom to top,
this method can represent a mixture of Arabic and Latin glyphs in the same way as occurs
for horizontal line orientation.

Another possible approach is to render the text in a uniform
single direction from top to bottom.
This method has multiple
variations to determine the orientation of characters. One variant uses the Bidirectional Algorithm to
determine the level of the text, but then the levels are not used to reorder the text. Instead, the levels are
used to determine the *rotation* of each segment of the text.
Sometimes vertical lines follow a vertical baseline in which
each character is oriented as normal (with no rotation), with characters ordered from top to bottom
whether they are Hebrew, numbers, or Latin. When setting text using the Arabic script in vertical lines, it
is more common to employ a horizontal baseline that is rotated by 90° counterclockwise so that the
characters are ordered from top to bottom. Latin text and numbers may be rotated 90° clockwise so
that those characters are also ordered from top to bottom.

### 6.3 [Formatting](#Formatting)

Because of the implicit character types and the heuristics for resolving neutral and numeric
directional behavior, the implicit bidirectional ordering will generally produce the correct
display without any further work. However, problematic cases may occur when a right-to-left
paragraph begins with left-to-right characters, or there are nested segments of
different-direction text, or there are weak characters on directional boundaries. In these cases,
embeddings or directional marks may be required to get the right display. Part numbers may also
require directional overrides.

The most common problematic case is that of neutrals on the boundary of an embedded language.
This can be addressed by setting the level of the embedded text correctly. For example, with all
the text at level 0 the following occurs:

```

Memory:  he said "I NEED WATER!", and expired.

Display: he said "RETAW DEEN I!", and expired.

```

If the exclamation mark is to be part of the Arabic quotation, then the user can select the
text *I NEED WATER!* and explicitly mark it as embedded Arabic, which produces the following
result:

```

Memory:  he said "RLII NEED WATER!PDI", and expired.

Display: he said "!RETAW DEEN I", and expired.

```

However, an often simpler and better method of doing this is
to place a right directional mark (RLM) after the exclamation mark.
Because the exclamation mark is now not on a directional boundary, this produces the correct result.
This is the best approach when manually editing text or programmatically generating text meant to be edited,
or dealing with an application that simply does not support explicit formatting characters.

```

Memory:  he said "I NEED WATER!RLM", and expired.

Display: he said "!RETAW DEEN I", and expired.

```

This latter approach is preferred because it does not make use of the explicit formatting characters,
which can easily get out of sync if not fully supported by editors and other string manipulation.
Nevertheless, the explicit formatting characters are
absolutely necessary in cases
where text of one direction
contains text of the opposite direction which itself contains text of the original direction.
Such cases are not as rare as one might think, because Latin-script brand names, technical terms, and abbreviations are often written in their
original Latin characters when used in non-Latin-script text, including right-to-left text, as in the following:

```

Memory:  it is called "RLIAN INTRODUCTION TO javaPDI" - $19.95 in hardcover.

Display: it is called "java OT NOITCUDORTNI NA" - $19.95 in hardcover.

```

Thus, when text is programmatically generated by inserting data into a template,
and is not intended for later manual editing,
and a particular insert happens to be of the opposite direction to the template's text,
it is easiest to wrap the insert in explicit formatting characters (or their markup equivalent) declaring its direction,
without analyzing whether it is really necessary to do so,
or if the job could be done just with stateless directional marks.

Furthermore, in this common scenario, it is highly recommended to use directional isolate formatting characters
as opposed to directional embedding formatting characters (once targeted display platforms are known to support isolates).
This is because embeddings affect the surrounding text similarly to a strong character,
whereas directional isolates have the effect of a neutral.
The embeddings' stronger effect is often difficult to anticipate and is rarely useful.
To demonstrate, here is the example above with embeddings instead of isolates:

```

Memory:  it is called "RLEAN INTRODUCTION TO javaPDF" - $19.95 in hardcover.

Display: it is called "$19.95 - "java OT NOITCUDORTNI NA in hardcover.

```

This, of course, is not the intended display, and is due to the number “sticking”
to the preceding RTL embedding (along with all the neutral characters in between),
just as it would “stick” to a preceding RTL character.

Directional isolates also offer a solution to the very common case where the direction of the text
to be programmatically inserted is not known. Instead of analyzing the characters of the text to be inserted in order
to decide whether to use an LRE or RLE (or LRI or RLI - or nothing at all), the software can take the easy way out
and *always* wrap each unknown-direction insert in an FSI and PDI.
Thus, an FSI instead of an RLI in the example above would produce the same display.
FSI's first-strong heuristic is not infallible, but it will work most of the time even on mixed-script text.

Although wrapping inserts in isolates is a useful technique,
it is best not to wrap text that is known to contain no opposite-direction characters that are not already wrapped in an isolate.
Unnecessary layers of wrapping not only add bulk and complexity;
they can also wind up exceeding the depth limit and rendering ineffective the innermost isolates,
which can make the text display incorrectly.
One very common case of an insert that does not need wrapping is one known to be localized to the context locale,
e.g. a translated message with all its inserted values either themselves localized, or wrapped in an isolate.

### 6.4 [Separating Punctuation Marks](#Separators)

A common problem case is where the text really represents a
sequence of items with separating punctuation marks,
often programmatically concatenated. These separators are often strings of neutral characters. For example, a web page might have the following at the
bottom:

advertising programs - business solutions - privacy policy
- help - about

This might be built up on the server by concatenating a variable number of strings with " - " as a
separator, for example. If all of the text is translated into Arabic or Hebrew and the overall
page direction is set to be RTL, then the right result occurs, such as the following:

TUOBA - PLEH - YCILOP YCAVIRP - SNOITULOS SSENISUB
- SMARGORP GNISITREVDA

However, suppose that in the translation, there remain some LTR characters. This is not
uncommon for company names, product names, technical terms, and so on. If one of the separators is bounded on
both sides by LTR characters, then the result will be badly jumbled. For example, suppose that
"programs" in the first term and "business" in the second were left in English. Then the result
would be

TUOBA - PLEH - YCILOP YCAVIRP - SNOITULOS **programs****-** **business** GNISITREVDA

The result is a jumble, with
the apparent first term being "advertising business" and the second being "programs solutions".
The simplest solution for this problem is to include an RLM character in each separator string. That will
cause each separator to adopt a right-to-left direction, and produce the correct output:

TUOBA - PLEH - YCILOP YCAVIRP - SNOITULOS **business****-** **programs** GNISITREVDA

The explicit formatting characters
(LRE, RLE, and PDF or LRI, RLI, FSI, and PDI) can be used to achieve the
same effect; web pages would use spans with the attributes *dir="ltr"* or *dir="rtl"*.
Each separate field would be embedded, excluding the separators. In general, LRM and RLM are
preferred to the explicit formatting characters because their effects are more local in scope, and are more
robust than the dir attributes when text is copied. (Ideally programs would convert *dir*
attributes to the corresponding explicit formatting characters when converting to plain text, but that is not
generally supported.)

### 6.5 [Conversion to Plain Text](#Conversion_to_Plain_Text)

For consistent appearance, when bidirectional text subject to a higher-level
protocol is to be converted to Unicode plain text, formatting
characters should be inserted to ensure that the display order resulting from
the application of the Unicode Bidirectional Algorithm matches that specified by the
higher-level protocol. The same principle should be followed whenever text using a
higher-level protocol is converted to marked-up text that is unaware of the higher-level
protocol. For example, if a higher-level protocol sets the paragraph direction to 1
(R) based on the number of L versus R/AL characters, when converted to plain text the
paragraph would be embedded in a bracketing pair of RLE..PDF formatting
characters. If the same text were converted to HTML4.0 the attribute dir =
"rtl" would be added to the paragraph element.

## 7 [Mirroring](#Mirroring)

The mirrored property is important to ensure that the correct characters are used for the
desired semantic. This is of particular importance where the name of a character does not indicate
the intended semantic, such as with U+0028 “(” LEFT PARENTHESIS. While the name
indicates that it is a left parenthesis, the character really expresses an *open parenthesis*—the *leading* character in a parenthetical phrase, not the trailing one.

Some of the characters that do not have the Bidi\_Mirrored property
may be rendered with mirrored glyphs, according to a higher level
protocol that adds
mirroring: see Section 4.3,
*[Higher-Level Protocols](#Higher-Level_Protocols)*, especially
[HL6](#HL6). Except in such cases, mirroring must be done
according to rule [L4](#L4), to ensure that the correct character
is used to express the intended semantic,
and to avoid interoperability and security problems.

Implementing rule [L4](#L4) calls for mirrored glyphs. These glyphs may not be exact
*graphical* mirror images. For example, clearly an italic parenthesis is not
an exact mirror image of another— “*(*” is not the mirror image of “*)*”.
Instead, mirror glyphs are those acceptable as mirrors within the normal parameters of the font in
which they are represented.

In implementation, sometimes pairs of characters are acceptable mirrors for one
another—for example, U+0028 “(” LEFT PARENTHESIS and U+0029
“)”
RIGHT PARENTHESIS or U+22E0 “⋠” DOES NOT PRECEDE OR EQUAL and
U+22E1 “⋡” DOES NOT SUCCEED OR EQUAL. Other characters such as
U+2231 “∱” CLOCKWISE INTEGRAL do not have corresponding characters that can be
used for acceptable mirrors. The informative BidiMirroring.txt data file [[Data9]](https://www.unicode.org/reports/tr41/tr41-28.html#Data9),
lists the paired characters with acceptable mirror glyphs.
The formal property name for this data in the
*Unicode Character Database* [[UCD](https://www.unicode.org/reports/tr41/tr41-28.html#UCD)]
is
Bidi\_Mirroring\_Glyph. A comment in the file indicates where
the pairs are “best fit”: they should be acceptable in rendering, although ideally the mirrored
glyphs may have somewhat different shapes.

## [Migration Issues](#Migration)

There are two major enhancements in the Unicode 6.3 version of the UBA:

* Directional isolates
* Bracket Pairs

Implementations of the new directional isolates should see very few compatibility issues; the UBA has been carefully modified to minimize differences for older text written without them. There are a few edge cases near the limit of the number of levels where there are some differences, but those are not likely to be encountered in practice.

With bracket pairs, there may be more changes. The problem is that without knowing (or having good UI access to) the directional marks or embeddings, people have constructed text with the correct visual appearance but incorrect underlying structure (eg …[…[…, appearing as …[…]…). The new algorithm catches cases like these, because such malformed sequences of brackets are not matched.

However, there are some cases where older implementations without rule [N0](#N0) produced the desired appearance, and newer implementations will not. The user feedback on implementations was sufficiently positive that the decision was made to add [N0](#N0).

There are also incompatibilities from some implementation's failing to updating correctly to previous versions of Unicode, notably in the mishandling solidus such that "T 1/2" (T is an Arabic character) appears incorrectly as "2/1 T".

To mitigate compatibility problems, it is strongly recommended that implementations take the following steps:

* Add appropriate directional formatting characters on both any parentheses that are resolved with rule [N0](#N0) so that they appear properly on older systems. This can be done with directional marks
  (RLM or LRM) on both sides of each parenthesis. For forward compatibility, text authored on older systems should use semantically correct brackets (with directional formatting characters as necessary) to ensure correct display on systems with implementations after Unicode 6.3.
* Add the appropriate explicit embedding around any sequence of numbers + solidus + numbers.

### [Section Reorganization](#section_reorg)

In Unicode 6.3, there was significant reorganization of the text. The following table shows the new and old section numbers.

| Unicode 6.3 | Unicode 6.2 |
| --- | --- |
| 2.4 [Explicit Directional Isolates](#Explicit_Directional_Isolates) | n/a |
| 2.5 [Terminating Explicit Directional Isolates](#Terminating_Explicit_Directional_Isolates) | n/a |
| 2.6 [Implicit Directional Marks](#Implicit_Directional_Marks) | 2.4 |
| 3.3.3 [Preparations for Implicit Processing](#Preparations_for_Implicit_Processing) | n/a |
| 3.3.4 [Resolving Weak Types](#Resolving_Weak_Types) …3.3.6 [Resolving Implicit Levels](#Resolving_Implicit_Levels) | 3.3.3…3.3.5 |
| 6.1 [Joiners](#Joiners) | 5.3 |
| 6.2 [Vertical Text](#Vertical_Text) | 5.4 |
| 6.3 [Formatting](#Formatting) | 5.5 |
| 6.4 [Separating Punctuation Marks](#Separators) | 5.6 |
| 6.5 [Conversion to Plain Text](#Conversion_to_Plain_Text) | n/a |
| [Migration Issues](#Migration) | 5.7 |

## [Acknowledgments](#Acknowledgements)

Mark Davis created the initial version of this annex and maintains the text.
Aharon Lanin and Andrew Glass made substantial additions to Revision 29 (Unicode 6.3.0).

Thanks to the following people for their contributions to the Bidirectional
Algorithm or for their feedback on earlier versions of this annex:
Ahmed Talaat (أحمد طلعت),
Alaa Ghoneim (علاء غنيم),
Asmus Freytag, Avery Bishop, Ayman Aldahleh (أيمن الدحلة), Behdad Esfahbod (بهداد اسفهبد), Doug Felt,
Dwayne Robinson,
Eric Mader, Ernest Cline, Gidi Shalom-Bendor (גידי שלום-בן דור), Gilead Almosnino (גלעד אלמוסנינו), Isai Scheinberg,
Israel Gidali (ישראל גידלי), Joe Becker, John McConnell, Jonathan Kew, Jonathan Rosenne (יונתן רוזן),
Kamal Mansour (كمال منصور), Kenneth Whistler,
Khaled Sherif (خالد شريف), Koji Ishii, Laurențiu Iancu,
Maha Hassan (مها حسن), Markus Scherer, Martin Dürst, Mati Allouche (מתתיהו אלוש), Michel Suignard, Mike Ksar (ميشيل قصار),
Murray Sargent, Paul Nelson, Pedro Navarro, Peter Constable, Rick McGowan,
Robert Steen,
Roozbeh Pournader (روزبه پورنادر),
Solra Bizna, Steve Atkin, and Thomas Milo (تُومَاسْ مِيلُو).

## [References](#References)

For references for this annex, see Unicode Standard Annex #41, “[Common
References for Unicode Standard Annexes](https://www.unicode.org/reports/tr41/tr41-28.html).”

## [Modifications](#Modifications)

The following summarizes modifications from the previous version of this
annex.

### Revision 45

* **Reissued** for Unicode 14.0.0.
* Updated [Section 6.2](#Vertical_Text), Vertical Text to clarify how
  the Bidirectional Algorithm is (or is not) used when text is laid
  out in vertical orientation.
* Updated various links in the text.

Previous revisions can be accessed with the “Previous Version” link in the header.

---

© 2021 Unicode, Inc. All Rights Reserved. The
Unicode Consortium makes no expressed or implied warranty of any kind, and assumes no liability
for errors or omissions. No liability is assumed for incidental and consequential damages in
connection with or arising out of the use of the information or programs contained or accompanying
this technical report. The Unicode [Terms of Use](https://www.unicode.org/copyright.html)
apply.

Unicode and the Unicode logo are trademarks of Unicode, Inc., and are
registered in some jurisdictions.



=== Content from www.openwall.com_7bedfce7_20250111_024723.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

[[<prev]](4) [[next>]](6) [[<thread-prev]](4) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <alpine.BSF.2.21.9999.2111020349110.70183@aneurin.horsfall.org>
Date: Tue, 2 Nov 2021 03:53:12 +1100 (EST)
From: Dave Horsfall <dave@...sfall.org>
To: oss-security@...ts.openwall.com
Subject: Re: CVE-2021-42574: rustc 1.56.0 and bidirectional-override
 codepoints in source code

On Mon, 1 Nov 2021, Pietro Albini wrote:

> The Rust Security Response WG was notified of a security concern
> affecting source code containing "bidirectional override" Unicode
> codepoints: in some cases the use of those codepoints could lead to the
> reviewed code being different than the compiled code.

[...]

Am I the only one here who remembers the original ALGOL specification that
what is printed on the paper is the language?

We've seen the same in the DNS, so I guess that it was only a matter of
time.

-- Dave

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from www.scyon.nl_e692e13a_20250111_024727.html ===


top of page

* [Home](https://www.scyon.nl)
* [Contact](https://www.scyon.nl)
* [Werken bij](https://www.scyon.nl/werken-bij)
* [Blog](https://www.scyon.nl/blog)
* More

Use tab to navigate through the menu items.

* [![LinkedIn]()](https://www.linkedin.com/company/scyon)
* [![Twitter]()](https://twitter.com/ScyonSecurity)
![Foto van schrijver]()Coen Goedegebure11 nov 20214 minuten om te lezen
# Trojans in your source code

Bijgewerkt op: 12 nov 2021

As part of my work I frequently perform source code reviews for security issues. Looking for vulnerabilities in the logic of the source code is not easy, but when the encoding of that code is attacked, things get unreal pretty fast. Especially when you realise how often code is copy-pasted from sites like [StackOverflow](https://stackoverflow.com/).

This article describes the dangers of hidden Unicode control characters and how they can make your source code appear differently than it is executed.

## **The vulnerability**

Consider the following piece of Javascript:

![](https://static.wixstatic.com/media/2b3606_7578a4064e584240839195db7c3d8667~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_7578a4064e584240839195db7c3d8667~mv2.png)

This code contains a simple "demo"-function that starts by setting the "isAdmin" variable to "false" in line 2. Line 4 starts with a comment and checks whether "isAdmin" is set to "true" in which case the message *"You are an admin"* would be printed in line 5. Logically, this message will never be printed since "isAdmin" is explicitly set to "false".
However, when executing this script, the following output is generated:

```
You are an admin
```

## **How does this work?**

Using Unicode control characters we can reorder the tokens of the source code. By doing this, the way the source code is rendered to screen no longer matches the actual logic of the source code itself.
In other words, by carefully placing these control characters, we can visually reorder the source code so that it is displayed differently than how it is processed by the compiler or interpreter.

## **Modifying the code**

The table below lists the abbreviations of the special Unicode control characters that are used to create the examples in this chapter.

| Abbreviation | Unicode | Name | Description |
| --- | --- | --- | --- |
| RLO | U+202E | Right-to-Left Override | Treat following text as right-to-left |
| LRI | U+2066 | Left-to-Right Isolate | Treat following text as left-to-right without affecting adjacent text |
| PDI | U+2069 | Pop Directional Isolate | Terminate the nearest LRI or RLI |

The example mentioned at the beginning of the article, works by making a comment appear as if it were code. Let's again take a look at how the IDE displays the Javascript code:

![](https://static.wixstatic.com/media/2b3606_7578a4064e584240839195db7c3d8667~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_7578a4064e584240839195db7c3d8667~mv2.png)

Now compare it to the way the code is handled by the Javascript interpreter. In the figure below the Unicode control characters are made visible:

![](https://static.wixstatic.com/media/2b3606_80bf1f3c6b904ce1a753f08035f20ddd~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_80bf1f3c6b904ce1a753f08035f20ddd~mv2.png)

As you can see, line 4 is processed as a normal comment section with some special characters in it. However, when the line is displayed on screen in the IDE, the special characters inside the comment manipulate the text so that it is rendered in a different order. This vulnerability is tracked as [CVE-2021-42574](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-42574). The sample code can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/comment_out.html).

## **Impact**

Adversaries can use this vulnerability, the difference between handling and rendering of these Unicode control characters, to hide malicious behaviour from human reviewers.
The impact of this kind of an attack lies within the context of software supply chains; open source projects used by other applications. When a vulnerability like this slips through the code review and ends up unnoticed in an open source library, it is likely to be inherited downstream by the software using that library.

## **Exploits**

Visually reordering the source code can be done in different ways:

### **Commenting-Out**

This is the example explained above. Comments visually appear as executable code, which are not executed by compiler or interpreter.

### **Commenting-In**

In this case, executable code visually appears to be a comment, but is actually executed. For example, in the python code below, the code "amount -= 70" in line 3 appears to be part of a comment section:

![](https://static.wixstatic.com/media/2b3606_5ad22d74f48c4614841b2378eed381f0~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_5ad22d74f48c4614841b2378eed381f0~mv2.png)

However, after running the script, we see it is actually executed:

```
Amount: 30
done
```

Below is the actual code, with Unicode control characters made visible, as it would be processed by the python interpreter:

![](https://static.wixstatic.com/media/2b3606_b412703bbb7d4b33b15c89f072d58ede~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_b412703bbb7d4b33b15c89f072d58ede~mv2.png)

The sample code can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/comment_in.py).

### **Early returns**

This technique is a variation on the commenting-in technique. It executes a return statement that appears to be part of a comment, to exit a function early. In the python example below, the "return" command in line 3 appears to be included in the comment, but is actually executed.

![](https://static.wixstatic.com/media/2b3606_dc7d04b303464f72bb5cc610d2daa9bb~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_dc7d04b303464f72bb5cc610d2daa9bb~mv2.png)

Output:

```
first comment
done
```

The figure below shows the code as it is processed by the python interpreter:

![](https://static.wixstatic.com/media/2b3606_681ba800b0ee4c1da0757b444ba94ed8~mv2.png/v1/fill/w_49,h_11,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_681ba800b0ee4c1da0757b444ba94ed8~mv2.png)

The early returns example can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/early_returns.py).

### **Stretched strings**

Another way to exploit this vulnerability, is to have pieces of string literals render as code. This could break equality checks like the one in the bash script below:

![](https://static.wixstatic.com/media/2b3606_a6931a8af4704d8faa38971727f5825f~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_a6931a8af4704d8faa38971727f5825f~mv2.png)

Line 2 assigns the value "user" to the ACCESS\_LEVEL variable. If the ACCESS\_LEVEL is **not** equal to "user" (line 4), the message *"You are an admin"* is displayed, otherwise the output is *"You are a user"*. Since the ACCESS\_LEVEL has been explicitly set to "user", we would expect the output is the latter. The output however is the following:

```
You are an admin
```

The figure below shows the source code as it is processed by the bash interpreter:

![](https://static.wixstatic.com/media/2b3606_0ebde09aac9448aa9fb774ebfdf1b835~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_0ebde09aac9448aa9fb774ebfdf1b835~mv2.png)

Notice the string literal in line 4 is not "user", but rather contains other characters as well. This way, given the explicit assignment in line 2, the comparison in line 4 always yields true (i.e. ACCESS\_LEVEL is **never** equal to "user") and the message *"You are an admin"* is output.

The sample code for stretched strings can be found [here](https://github.com/CoenGoedegebure/trojansource/blob/master/stretched_strings.sh).

### **Homoglyphs**

A [homoglyph](https://en.wikipedia.org/wiki/Homoglyph) attack exploits the fact that two characters look alike. For example, it is hard to see the difference between the Cyrillic letter "a" (U+0430) and the letter "a" from the latin alphabet. This is a similar to the [IDN homograph attack](https://en.wikipedia.org/wiki/IDN_homograph_attack) in which domain names are spoofed using the same principle.

In the following Javascript snippet an extra, evil function 'demo' was created in which the letter "e" is replaced by the Cyrillic letter "e" (U+0435, marked in red).

![](https://static.wixstatic.com/media/2b3606_56b48c54bc3d4bca9e8f31df68f92b03~mv2.png/v1/fill/w_49,h_12,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_56b48c54bc3d4bca9e8f31df68f92b03~mv2.png)

It would be very difficult for a reviewer to visually make a distinction between the function call to the good and the evil demo function in line 8. This vulnerability is tracked as [CVE-2021-42694](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-42694).

## **Mitigation**

The issues mentioned in this article can be mitigated by limiting the way the bidirectional Unicode control characters are processed. Either by making these clearly visible, or producing errors or warnings when these characters are encountered:

##### **GUI**

IDE's and other code editors should provide visual feedback for these characters. Either by making them clearly visible, or notifying the user with a warning. The figure below depicts how IntelliJ handles the visual representation of Unicode control characters for example:

![](https://static.wixstatic.com/media/2b3606_b97c2fb4c938403baa4bcd49ed3a7efa~mv2.png/v1/fill/w_49,h_17,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_b97c2fb4c938403baa4bcd49ed3a7efa~mv2.png)

The example below shows how GitHub handles the issue in [comment\_in.py](https://github.com/CoenGoedegebure/trojansource/blob/master/comment_in.py):

![](https://static.wixstatic.com/media/2b3606_081e45ab1689440fb869f74033b38171~mv2.png/v1/fill/w_49,h_16,al_c,q_85,usm_0.66_1.00_0.01,blur_2,enc_auto/2b3606_081e45ab1689440fb869f74033b38171~mv2.png)
##### **Automated systems and software**

Systems and software that process source code, like compilers, interpreters, build pipelines, etc. should throw exceptions or generate warnings whenever special characters are encountered.

##### **Language specifications**

Unterminated bidirectional control characters in comments and string literals should be disallowed by means of language specifications.

Reference:
Paper: *"Trojan Source: Invisible Vulnerabilities"* by Nicholas Boucher and Ross Anderson, 2021 [[link](https://trojansource.codes/trojan-source.pdf) (pdf)]

* [Secure Coding](https://www.scyon.nl/blog/categories/securecoding)
* •
* [Cyber Security](https://www.scyon.nl/blog/categories/cyber-security)
0 opmerkingen11 Likes. Post is niet als leuk gemarkeerd11
## Recente blogposts

[Alles weergeven](https://www.scyon.nl/blog)[![]()](https://www.scyon.nl/post/kopie-van-the-best-resources-to-get-your-cissp)

[The best resources to get your CISSP](https://www.scyon.nl/post/kopie-van-the-best-resources-to-get-your-cissp)

0 opmerkingen0Post is niet als leuk gemarkeerd[![]()](https://www.scyon.nl/post/surviving-a-cyber-security-job-interview-cryptography-1)

[Surviving a cyber security job interview (Cryptography)](https://www.scyon.nl/post/surviving-a-cyber-security-job-interview-cryptography-1)

0 opmerkingen01 like. Post is niet als leuk gemarkeerd1[![]()](https://www.scyon.nl/post/5-ways-to-improve-your-cyber-security-now-software-developer-edition-1)

[5 ways to improve your cyber security now - Software Developer edition](https://www.scyon.nl/post/5-ways-to-improve-your-cyber-security-now-software-developer-edition-1)

0 opmerkingen05 Likes. Post is niet als leuk gemarkeerd5xml version="1.0" encoding="UTF-8"?

[privacy statement](https://www.scyon.nl/privacy)

info@scyon.nl

+31 (0) 30 22 715 88

Europalaan 93, Utrecht

* [![LinkedIn]()](https://www.linkedin.com/company/scyon)
* [![Twitter]()](https://twitter.com/ScyonSecurity)

©2025 Scyon B.V.

bottom of page



=== Content from www.starwindsoftware.com_6f5778b7_20250111_024727.html ===

[![logo](https://www.starwindsoftware.com/v20/assets/images/logo-with-slogan-white-sw.svg)
![logo](https://www.starwindsoftware.com/v20/assets/images/logo-with-slogan-white-sw.svg)](https://www.starwindsoftware.com/)

* [Search](#search)
* [Request a Call](https://www.starwindsoftware.com/request-a-call)
* [Download](https://www.starwindsoftware.com/download-starwind-products)
* [Forum](https://forums.starwindsoftware.com/)
* [Blog](https://www.starwindsoftware.com/blog)
* EN
  + English
  + [Deutsch](https://de.starwindsoftware.com/)
  + [Español](https://es.starwindsoftware.com/)
* [[!getUserAuthorized? &chunkTrue=`user-authorized-block-new` &chunkFalse=`user-unauthorized-block-new`]]
* [[!getUserAuthorized? &chunkTrue=`user-authorized-block-sign-out` &chunkFalse=``]]

* Why Us
* + [Why Us](https://www.starwindsoftware.com/why-starwind)
  + [What's Hyperconvergence?](https://www.starwindsoftware.com/hyperconverged-infrastructure)
  + [What's Software-Defined Storage?](https://www.starwindsoftware.com/software-defined-storage)
  + [What's All-Flash Exactly?](https://www.starwindsoftware.com/starwind-hyperconverged-appliance-going-all-flash)

  + [Why Hyperconvergence?](https://www.starwindsoftware.com/why-starwind#performance)
  + [Why Software-Defined Storage?](https://www.starwindsoftware.com/why-starwind#flexibility)
  + [Why All-Flash Exactly?](https://www.starwindsoftware.com/why-starwind#cost_reduction_and_planning)

  + [Who's Virtual SAN?](https://www.starwindsoftware.com/vsan/)
  + [Who's HCI Appliance?](https://www.starwindsoftware.com/hci-appliance/)
* Software
* + [PAID](https://www.starwindsoftware.com/download-starwind-products)
  + [Virtual SAN (VSAN)](https://www.starwindsoftware.com/starwind-virtual-san)
  + [Virtual HCI Appliance (VHCA)](https://www.starwindsoftware.com/starwind-hyperconverged-appliance#uber)

  + [Virtual Tape Library (VTL)](https://www.starwindsoftware.com/vtl)
  + [NVMe-oF Initiator](https://www.starwindsoftware.com/starwind-nvme-of-initiator)
  + [Free](https://www.starwindsoftware.com/download-starwind-products#free)
  + [VSAN Free](https://www.starwindsoftware.com/starwind-virtual-san#uber)
  + [V2V Converter](https://www.starwindsoftware.com/starwind-v2v-converter)
  + [VTL Free](https://www.starwindsoftware.com/starwind-virtual-tape-library-free)
  + [NVMe-oF Initiator Free](https://www.starwindsoftware.com/starwind-nvme-of-initiator#free)

  + [Deduplication Analyzer](https://www.starwindsoftware.com/starwind-deduplication-analyzer)
  + [P2V Migrator](https://www.starwindsoftware.com/starwind-v2v-converter?utm_source=starwind&utm_medium=link_menu)
  + [Tape Redirector](https://www.starwindsoftware.com/download-starwind-tape-redirector)
  + [RDMA Performance Benchmark](https://www.starwindsoftware.com/starwind-rperf)
* Hardware
* + [Hardware](https://www.starwindsoftware.com/request)
  + [HCI Appliance (HCA)](https://www.starwindsoftware.com/hci-appliance)
  + [Backup Appliance](https://www.starwindsoftware.com/backup-appliance)

  + [HCA for Video Surveillance](https://www.starwindsoftware.com/hyperconverged-appliance-for-video)
  + [VTL Appliance](https://www.starwindsoftware.com/starwind-virtual-tape-library-appliance)
* [Pricing](https://www.starwindsoftware.com/pricing)
* Solutions
* + [Solutions by Industries](https://www.starwindsoftware.com/solutions-by-industry)
  + [IT & Services](https://www.starwindsoftware.com/solutions-by-industry/information-technology-and-services)
  + [Finance](https://www.starwindsoftware.com/solutions-by-industry/finance)
  + [Education](https://www.starwindsoftware.com/solutions-by-industry/education)
  + [Healthcare](https://www.starwindsoftware.com/solutions-by-industry/healthcare)
  + [Maritime & Marine](https://www.starwindsoftware.com/solutions-by-industry/maritime-solution)
  + [Military & Law Enforcement](https://www.starwindsoftware.com/solutions-by-industry/military)
  + [Legal](https://www.starwindsoftware.com/solutions-by-industry/legal)
  + [Oil & Gas](https://www.starwindsoftware.com/solutions-by-industry/oil-and-gas)
* Resources
* + Resources
  + [Use Cases](https://www.starwindsoftware.com/resource-library/resource-type/use_cases/)
  + [White Papers](https://www.starwindsoftware.com/resource-library/resource-type/white_papers)
  + [Success
    Stories](https://www.starwindsoftware.com/resource-library/resource-type/success_stories)
  + [Technical
    Papers](https://www.starwindsoftware.com/resource-library/resource-type/technical_papers)

  + [Webinars](https://www.starwindsoftware.com/resource-library/resource-type/videos)
  + [Best Practices](https://www.starwindsoftware.com/best-practices/)
  + [Release Notes](https://www.starwindsoftware.com/release-notes-build)
* Support
* + Support
  + [Support Program](https://www.starwindsoftware.com/support)
  + [Product Lifecycle](https://www.starwindsoftware.com/product-lifecycle-announcements)
  + [Support Forum](https://forums.starwindsoftware.com/)
  + [System Requirements](https://www.starwindsoftware.com/system-requirements)
  + [Product Security](https://www.starwindsoftware.com/security/)

  + [StarWind FAQ](https://www.starwindsoftware.com/starwind-faq)
  + [Knowledge Base](https://knowledgebase.starwindsoftware.com/)
  + [StarWind VSAN Help](https://www.starwindsoftware.com/help/)
  + [StarWind V2V Help](https://www.starwindsoftware.com/v2v-help/)
* Partners
* + Channel Partners
  + [Technology
    Partners](https://www.starwindsoftware.com/technology-alliances)
  + [Become
    a Reseller](https://www.starwindsoftware.com/become-a-reseller)
  + [Find a
    Reseller](https://www.starwindsoftware.com/locate-a-reseller)
  + [VAR Portal](https://www.starwindsoftware.com/var)
  + [StarWind OEM Solutions](https://www.starwindsoftware.com/oem-solutions)
  + [StarWind Virtual SAN (VSAN) OEM](https://www.starwindsoftware.com/vsan-oem)
  + [StarWind Virtual Tape Library (VTL) OEM](https://www.starwindsoftware.com/vtl-oem)
  + [StarWind NVMe-oF Initiator OEM](https://www.starwindsoftware.com/nvme-of-initiator-oem)
* About Us
* + About Us
  + [About StarWind](https://www.starwindsoftware.com/company)
  + [Management](https://www.starwindsoftware.com/executive-team)
  + [Events](https://www.starwindsoftware.com/events)
  + [Press Releases](https://www.starwindsoftware.com/news/)

  + [Product
    Reviews](https://www.starwindsoftware.com/starwind-product-reviews)
  + [Certifications](https://www.starwindsoftware.com/certifications)
  + [Our
    Customers](https://www.starwindsoftware.com/customers)
  + [Contact Us](https://www.starwindsoftware.com/contact-us)
* [[headerButton\_v20]]

Search

[Close](#0)

[![logo](https://www.starwindsoftware.com/v20/assets/images/logo-with-slogan-white-sw.svg)](https://www.starwindsoftware.com/)

* EN
  + [Deutsch](https://de.starwindsoftware.com/)
  + [Español](https://es.starwindsoftware.com/)

[[!getUserAuthorized? &chunkTrue=`user-authorized-block-new` &chunkFalse=`user-unauthorized-block-new`]]

* [Request a Call](https://www.starwindsoftware.com/request-a-call)
* [Downloads](https://www.starwindsoftware.com/download-starwind-products)
* Request Demo
  + [Software](https://www.starwindsoftware.com/download-starwind-products#demo)
  + [Hardware](https://www.starwindsoftware.com/request#demo)

* [StarWind Blog](https://www.starwindsoftware.com/blog)
* [StarWind Forum](https://forums.starwindsoftware.com/)

* [Why Us](https://www.starwindsoftware.com/why-starwind)
  + [Why Us](https://www.starwindsoftware.com/why-starwind)
  + [Why Hyperconvergence](https://www.starwindsoftware.com/hyperconverged-infrastructure)
  + [What is Software-Defined Storage](https://www.starwindsoftware.com/software-defined-storage)
  + [Why All-Flash Exactly?](https://www.starwindsoftware.com/starwind-hyperconverged-appliance-going-all-flash)
  + [Flexibility and Simplicity](https://www.starwindsoftware.com/why-starwind#flexibility)
  + [Fault Tolerance and Performance](https://www.starwindsoftware.com/why-starwind#performance)
  + [Cost Reduction and Planning](https://www.starwindsoftware.com/why-starwind#cost_reduction)
* Software
  + [Virtual SAN (VSAN)](https://www.starwindsoftware.com/vsan)
  + [Virtual HCI Appliance (VHCA)](https://www.starwindsoftware.com/starwind-hyperconverged-appliance#uber)
  + [Virtual HCI Appliance (VHCA)](https://www.starwindsoftware.com/vhci-appliance)
  + [Virtual Tape Library (VTL)](https://www.starwindsoftware.com/vtl)
  + [NVMe-oF Initiator](https://www.starwindsoftware.com/starwind-nvme-of-initiator)
  + [VSAN Free](https://www.starwindsoftware.com/starwind-virtual-san-free)
  + [V2V Converter](https://www.starwindsoftware.com/starwind-v2v-converter)
  + [VTL Free](https://www.starwindsoftware.com/starwind-virtual-tape-library-free)
  + [NVMe-oF Initiator Free](https://www.starwindsoftware.com/starwind-nvme-of-initiator#free)
  + [Tape Redirector](https://www.starwindsoftware.com/download-starwind-tape-redirector)
  + [P2V Migrator](https://www.starwindsoftware.com/starwind-v2v-converter?utm_source=starwind&utm_medium=link_menu)
  + [Deduplication Analyzer](https://www.starwindsoftware.com/starwind-deduplication-analyzer)
  + [RDMA Performance Benchmark (rPerf)](https://www.starwindsoftware.com/starwind-rperf)
* Hardware
  + [HCI Appliance (HCA)](https://www.starwindsoftware.com/hci-appliance)
  + [HCA for Video Surveillance](https://www.starwindsoftware.com/hyperconverged-appliance-for-video)
  + [Backup Appliance](https://www.starwindsoftware.com/backup-appliance)
  + [VTL Appliance](https://www.starwindsoftware.com/starwind-virtual-tape-library-appliance)
* [Pricing](https://www.starwindsoftware.com/pricing)
* Solutions
  + [Solutions by Industries](https://www.starwindsoftware.com/solutions-by-industry)
  + [IT & Services](https://www.starwindsoftware.com/solutions-by-industry/information-technology-and-services)
  + [Finance](https://www.starwindsoftware.com/solutions-by-industry/finance)
  + [Education](https://www.starwindsoftware.com/solutions-by-industry/education)
  + [Healthcare](https://www.starwindsoftware.com/solutions-by-industry/healthcare)
  + [Maritime & Marine](https://www.starwindsoftware.com/solutions-by-industry/maritime-solution)
  + [Military & Law Enforcement](https://www.starwindsoftware.com/solutions-by-industry/military)
  + [Legal](https://www.starwindsoftware.com/solutions-by-industry/legal)
  + [Oil & Gas](https://www.starwindsoftware.com/solutions-by-industry/oil-and-gas)
* Resources
  + [Use Cases](https://www.starwindsoftware.com/resource-library/resource-type/use_cases/)
  + [White Papers](https://www.starwindsoftware.com/resource-library/resource-type/white_papers)
  + [Success
    Stories](https://www.starwindsoftware.com/resource-library/resource-type/success_stories)
  + [Technical
    Papers](https://www.starwindsoftware.com/resource-library/resource-type/technical_papers)
  + [Webinars](https://www.starwindsoftware.com/resource-library/resource-type/videos)
  + [Best
    Practices](https://www.starwindsoftware.com/best-practices/)
  + [Release Notes](https://www.starwindsoftware.com/release-notes-build)
* Support
  + [Software
    as a Service (SaaS) & Financing](https://www.starwindsoftware.com/saas-and-financing)
  + [Equipment
    Financing](https://www.starwindsoftware.com/equipment-financing)
  + [Support Program](https://www.starwindsoftware.com/support)
  + [Product Lifecycle](https://www.starwindsoftware.com/product-lifecycle-announcements)
  + [Support Forum](https://forums.starwindsoftware.com/)
  + [System Requirements](https://www.starwindsoftware.com/system-requirements)
  + [Product Security](https://www.starwindsoftware.com/security/)
  + [StarWind FAQ](https://www.starwindsoftware.com/starwind-faq)
  + [Knowledge Base](https://knowledgebase.starwindsoftware.com/)
  + [StarWind VSAN Help](https://www.starwindsoftware.com/help/)
  + [StarWind V2V Help](https://www.starwindsoftware.com/v2v-help/)
* Partners
  + [Technology
    Partners](https://www.starwindsoftware.com/technology-alliances)
  + [Become
    a Reseller](https://www.starwindsoftware.com/become-a-reseller)
  + [Find a
    Reseller](https://www.starwindsoftware.com/locate-a-reseller)
  + [VAR Portal](https://www.starwindsoftware.com/var)
  + [StarWind OEM Solutions](https://www.starwindsoftware.com/oem-solutions)
  + [StarWind Virtual SAN (VSAN) OEM](https://www.starwindsoftware.com/vsan-oem)
  + [StarWind Virtual Tape Library (VTL) OEM](https://www.starwindsoftware.com/vtl-oem)
  + [StarWind NVMe-oF Initiator OEM](https://www.starwindsoftware.com/nvme-of-initiator-oem)
* About Us
  + [About StarWind](https://www.starwindsoftware.com/company)
  + [Management](https://www.starwindsoftware.com/executive-team)
  + [Events](https://www.starwindsoftware.com/events)
  + [Press Releases](https://www.starwindsoftware.com/news/)
  + [Product
    Reviews](https://www.starwindsoftware.com/starwind-product-reviews)
  + [Certifications](https://www.starwindsoftware.com/certifications)
  + [Our
    Customers](https://www.starwindsoftware.com/customers)
  + [Contact Us](https://www.starwindsoftware.com/contact-us)

* [Security Advisories](https://www.starwindsoftware.com/security)
* [StarWind Security Contact](https://www.starwindsoftware.com/security/starwind-security-contact/)
* [StarWind Security Policy](https://www.starwindsoftware.com/security/starwind-security-policy/)

# CVE-2021-42574 Bidirectional Algorithm issue in StarWind Products

**Title:** CVE-2021-42574 Bidirectional Algorithm issue in StarWind Products

**Note:** StarWind will continue to update this vulnerability as new information becomes available

**Vulnerability ID:** SW-20220804-0002

**Version:** 1.0

**Date:** 2022-08-04

**Status:** Interim

**CVEs:** CVE-2021-42574

* Overview
* Affected Products
* Remediation
* Revision History

### **Summary**

An issue was discovered in the Bidirectional Algorithm in the Unicode Specification through 14.0. It permits the visual reordering of characters via control sequences, which can be used to craft source code that renders different logic than the logical ordering of tokens ingested by compilers and interpreters.

### **Impact**

Adversaries can leverage this to encode source code for compilers accepting Unicode such that targeted vulnerabilities are introduced invisibly to human reviewers.

### **Vulnerability Scoring**

| CVE | CVSS 2.0 Score | CVSS 3.x Score |
| --- | --- | --- |
| CVE-2021-42574 | 5.1 (MEDIUM) | 8.3 (HIGH) |

### Vector

CVSS:3.1/AV:N/AC:H/PR:N/UI:R/S:C/C:H/I:H/A:H

### References

| Resource | Hyperlink |
| --- | --- |
| NVD | [NVD – CVE-2021-42574 (nist.gov)](https://nvd.nist.gov/vuln/detail/CVE-2021-42574) |

### **Affected Products:**

StarWind VSAN Version V8 (build 14398)

**Not affected products:**

SAN&NAS (vSAN) V8 R13

StarWind VSAN (all versions)

StarWind SA (all versions)

StarWind VTLA (all versions)

StarWind VTL component (all versions)

StarWind V2V (all versions)

StarWind Tape Redirector component (all versions)

StarWind Deduplication Analyzer (all versions)

StarWind rPerf (all versions)

StarWind iSCSI Accelerator (all versions)

### **Workaround**

None

### **Obtaining Software Fixes**

Software updates will be available in StarWind release notes – <https://www.starwindsoftware.com/release-notes-build>. To update the software, perform the steps described at the following link  – <https://knowledgebase.starwindsoftware.com/guidance/upgrading-from-any-starwind-version-to-any-starwind-version/> or contact support to perform an update. You can submit a support request using the following link <https://www.starwindsoftware.com/support-form> or contact Support directly via email support@starwind.com or via phone +1 617 829 4499.

### **Status of Notice**

**Interim**

StarWind will continue to update information regarding this vulnerability as new details become available.

This vulnerability article should be considered as the single source of current, up-to-date, authorized and accurate information posted by StarWind Software.

**Revision History**

| Revision # | Date | Comments |
| --- | --- | --- |
| 1.0 | 2022-08-04 | Initial Public Release |

We are social

* [>](https://twitter.com/starwindsan)

[Site Map](https://www.starwindsoftware.com/sitemap)

Software

* [Virtual SAN (VSAN)](https://www.starwindsoftware.com/vsan)
* [Virtual HCI Appliance (VHCA)](https://www.starwindsoftware.com/vhci-appliance)
* [Virtual Tape Library (VTL)](https://www.starwindsoftware.com/vtl)
* [NVMe-oF Initiator](https://www.starwindsoftware.com/starwind-nvme-of-initiator)

Hardware

* [HCI Appliance (HCA)](https://www.starwindsoftware.com/hci-appliance)
* [HCA for Video Surveillance](https://www.starwindsoftware.com/hyperconverged-appliance-for-video)
* [Backup Appliance](https://www.starwindsoftware.com/backup-appliance)
* [VTL Appliance](https://www.starwindsoftware.com/starwind-virtual-tape-library-appliance)

Services

* [StarWind NVMe-oF Initiator OEM](https://www.starwindsoftware.com/nvme-of-initiator-oem)
* [Software as a Service (SaaS) & Financing](https://www.starwindsoftware.com/saas-and-financing)
* [Equipment Financing](https://www.starwindsoftware.com/equipment-financing)

[Technology Partners](https://www.starwindsoftware.com/technology-alliances)

Channel Partners

* [Become a Reseller](https://www.starwindsoftware.com/become-a-reseller)
* [Find a Reseller](https://www.starwindsoftware.com/locate-a-reseller)
* [VAR Portal](https://www.starwindsoftware.com/var)

Free Software

* [VSAN Free](https://www.starwindsoftware.com/starwind-virtual-san-free)
* [V2V Converter](https://www.starwindsoftware.com/starwind-v2v-converter)
* [VTL Free](https://www.starwindsoftware.com/starwind-virtual-tape-library-free)
* [NVMe-oF Initiator Free](https://www.starwindsoftware.com/starwind-nvme-of-initiator#free)
* [Tape Redirector](https://www.starwindsoftware.com/download-starwind-tape-redirector)
* [P2V Migrator](https://www.starwindsoftware.com/starwind-v2v-converter?utm_source=starwind&utm_medium=link_menu)
* [Deduplication Analyzer](https://www.starwindsoftware.com/starwind-deduplication-analyzer)
* [RDMA Performance Benchmark (rPerf)](https://www.starwindsoftware.com/starwind-rperf)

Support

* [Support Program](https://www.starwindsoftware.com/support)
* [Product Lifecycle](https://www.starwindsoftware.com/product-lifecycle-announcements)
* [Support Forum](https://forums.starwindsoftware.com/)
* [System Requirements](https://www.starwindsoftware.com/system-requirements)
* [Starwind Product Security](https://www.starwindsoftware.com/security/)
* [StarWind FAQ](https://www.starwindsoftware.com/starwind-faq)
* [Knowledge Base](https://knowledgebase.starwindsoftware.com/)
* [StarWind VSAN Help](https://www.starwindsoftware.com/help/)
* [StarWind V2V Help](https://www.starwindsoftware.com/v2v-help/)

Resourses

* [Solutions by industries](https://www.starwindsoftware.com/solutions-by-industry)
* [White Papers](https://www.starwindsoftware.com/resource-library/resource-type/white_papers)
* [Success Stories](https://www.starwindsoftware.com/resource-library/resource-type/success_stories)
* [Technical Papers](https://www.starwindsoftware.com/resource-library/resource-type/technical_papers/)
* [Webinars](https://www.starwindsoftware.com/resource-library/resource-type/videos)
* [Best Practices](https://www.starwindsoftware.com/best-practices/)
* [Release Notes](https://www.starwindsoftware.com/release-notes-build)
* [Why HyperConverged Infrastructure?](https://www.starwindsoftware.com/hyperconverged-infrastructure)
* [Hyperconverged Storage](https://www.starwindsoftware.com/hyperconverged-storage)
* [Hardware Upgrade](https://www.starwindsoftware.com/replace-piles-of-outdated-hardware-with-high-performing-starwind-hyperconverged-appliance)
* [Storage Spaces Direct](https://www.starwindsoftware.com/storage-spaces-direct)

About us

* [About StarWind](https://www.starwindsoftware.com/company)
* [Why us?](https://www.starwindsoftware.com/why-starwind)
* [Events](https://www.starwindsoftware.com/events)
* [Press Releases](https://www.starwindsoftware.com/news/)
* [Product Reviews](https://www.starwindsoftware.com/starwind-product-reviews)
* [Certifications](https://www.starwindsoftware.com/certifications)
* [Our Customers](https://www.starwindsoftware.com/customers)
* [Contact Us](https://www.starwindsoftware.com/contact-us)

* [VMware vSphere vs. vSphere VSAN from StarWind](https://www.starwindsoftware.com/vmware-vsphere-vs-vsphere-vsan-from-starwind)
* [VMware VSAN vs. StarWind VSAN](https://www.starwindsoftware.com/vmware-vsan-vs-vsan-from-starwind)

* [Microsoft Hyper-V and StarWind VSAN for Hyper-V](https://www.starwindsoftware.com/starwind-virtual-san-hyper-v)
* [Scale Computing vs. StarWind HCA](https://www.starwindsoftware.com/scale-computing-hc3-vs-starwind-hca)
* [Linux KVM and StarWind VSAN](https://www.starwindsoftware.com/linux-kvm-and-starwind-vsan)

* [Nutanix Hardware vs. StarWind HCA](https://www.starwindsoftware.com/starwind-hca-vs-nutanix-hardware)
* [Xen Project Software and StarWind VSAN](https://www.starwindsoftware.com/xen-hypervisor)
* [VMware ESXi and StarWind VSAN](https://www.starwindsoftware.com/vmware-esxi-starwind-vsan)

* [Terms of Use](https://www.starwindsoftware.com/terms)
* [Privacy Policy](https://www.starwindsoftware.com/privacy-policy)
* [ProActive Terms of Service](https://www.starwindsoftware.com/proactive-support)
* [SLA](https://www.starwindsoftware.com/commercial-license-agreement)
* [Refund Policy](https://www.starwindsoftware.com/refund-policy)
* [![vsan licensing](https://www.starwindsoftware.com/v20/assets/images/footer_microsoft_partner_w.svg)](https://www.starwindsoftware.com/certifications)
* [![starwind virtual san](https://www.starwindsoftware.com/v20/assets/images/footer_wmware partner.svg)](https://www.starwindsoftware.com/certifications)
* ©  StarWind Software Inc.



=== Content from www.openwall.com_2e57fbd3_20250111_024723.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Hash Suite - Windows password security audit tool. GUI, reports in PDF.](https://hashsuite.openwall.net) | | --- | |
| --- | --- |

[[<prev]](9) [[next>]](11) [[<thread-prev]](9) [[thread-next>]](12) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <cb5b46fd-8e2c-2638-c23-f557483c6fa@gathman.org>
Date: Tue, 2 Nov 2021 16:52:33 -0400 (EDT)
From: Stuart D Gathman <stuart@...hman.org>
To: oss-security@...ts.openwall.com
Subject: Re: Trojan Source Attacks

On Mon, 1 Nov 2021, Nicholas Boucher wrote:

> The first and primary technique, which we dub the Trojan Source attack, uses
> Unicode Bidirectional (Bidi) control characters embedded in comments and
> string literals to produce visually deceptive source code files. This
> technique enables an adversary to encode constructs that visually appear to
> be comments or string literals but execute as code, or vice versa. Complete
> details, as well as recommended mitigations, can be found in the attachment
> 001 Trojan Source.pdf. This vulnerability is tracked under CVE-2021-42574.

Syntax coloring thus becomes a critical security tool.  And bugs in
syntax coloring for an editor/viewer should be consider security flaws
and reported on oss-security.

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from lists.fedoraproject.org_92fd864f_20250111_024724.html ===


[![Fedora Mailing-Lists](/static/logo-hyperkitty-fedora.png)](/archives/ "Fedora Mailing-Lists")

[Sign In](/accounts/login/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD/)
[Sign Up](/accounts/signup/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD/)

* [Sign In](/accounts/login/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD/)
* [Sign Up](/accounts/signup/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD/)

* [Manage this list](/admin/lists/package-announce.lists.fedoraproject.org/)

×
#### Keyboard Shortcuts

### Thread View

* `j`: Next unread message
* `k`: Previous unread message
* `j a`: Jump to all threads* `j l`: Jump to MailingList overview

### 2025

* [January](/archives/list/package-announce%40lists.fedoraproject.org/2025/1/)

### 2024

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2024/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2024/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2024/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2024/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2024/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2024/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2024/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2024/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2024/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2024/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2024/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2024/1/)

### 2023

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2023/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2023/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2023/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2023/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2023/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2023/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2023/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2023/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2023/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2023/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2023/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2023/1/)

### 2022

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2022/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2022/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2022/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2022/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2022/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2022/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2022/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2022/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2022/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2022/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2022/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2022/1/)

### 2021

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2021/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2021/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2021/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2021/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2021/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2021/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2021/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2021/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2021/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2021/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2021/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2021/1/)

### 2020

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2020/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2020/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2020/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2020/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2020/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2020/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2020/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2020/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2020/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2020/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2020/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2020/1/)

### 2019

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2019/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2019/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2019/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2019/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2019/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2019/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2019/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2019/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2019/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2019/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2019/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2019/1/)

### 2018

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2018/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2018/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2018/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2018/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2018/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2018/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2018/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2018/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2018/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2018/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2018/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2018/1/)

### 2017

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2017/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2017/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2017/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2017/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2017/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2017/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2017/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2017/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2017/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2017/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2017/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2017/1/)

### 2016

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2016/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2016/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2016/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2016/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2016/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2016/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2016/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2016/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2016/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2016/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2016/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2016/1/)

### 2015

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2015/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2015/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2015/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2015/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2015/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2015/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2015/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2015/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2015/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2015/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2015/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2015/1/)

### 2014

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2014/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2014/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2014/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2014/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2014/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2014/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2014/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2014/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2014/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2014/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2014/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2014/1/)

### 2013

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2013/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2013/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2013/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2013/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2013/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2013/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2013/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2013/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2013/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2013/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2013/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2013/1/)

### 2012

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2012/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2012/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2012/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2012/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2012/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2012/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2012/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2012/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2012/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2012/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2012/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2012/1/)

### 2011

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2011/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2011/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2011/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2011/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2011/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2011/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2011/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2011/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2011/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2011/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2011/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2011/1/)

### 2010

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2010/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2010/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2010/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2010/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2010/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2010/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2010/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2010/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2010/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2010/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2010/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2010/1/)

### 2009

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2009/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2009/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2009/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2009/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2009/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2009/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2009/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2009/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2009/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2009/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2009/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2009/1/)

### 2008

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2008/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2008/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2008/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2008/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2008/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2008/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2008/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2008/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2008/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2008/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2008/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2008/1/)

### 2007

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2007/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2007/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2007/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2007/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2007/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2007/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2007/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2007/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2007/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2007/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2007/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2007/1/)

### 2006

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2006/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2006/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2006/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2006/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2006/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2006/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2006/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2006/5/)

[List overview](/archives/list/package-announce%40lists.fedoraproject.org/)

[Download](/archives/list/package-announce%40lists.fedoraproject.org/export/package-announce%40lists.fedoraproject.org-IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD.mbox.gz?message=IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD "This message in gzipped mbox format")

[thread](/archives/list/package-announce%40lists.fedoraproject.org/thread/IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD/#IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD)

# [SECURITY] Fedora 33 Update: rust-1.56.1-1.fc33

![](https://seccdn.libravatar.org/avatar/be256568dfce45c1862b55e6cf3f2726.jpg?s=120&d=retro&r=g)

[updates＠fedoraproject.org](/archives/users/3d8bb2e4c1d843beb492d4f8a7c44761/ "See the profile for updates＠fedoraproject.org")

11 Nov
2021

11 Nov
'21

1:22 a.m.

--------------------------------------------------------------------------------
Fedora Update Notification
FEDORA-2021-443139f67c
2021-11-11 01:22:23.181028
--------------------------------------------------------------------------------

Name : rust
Product : Fedora 33
Version : 1.56.1
Release : 1.fc33
URL : <https://www.rust-lang.org>
Summary : The Rust Programming Language
Description :
Rust is a systems programming language that runs blazingly fast, prevents
segfaults, and guarantees thread safety.

This package includes the Rust compiler and documentation generator.

--------------------------------------------------------------------------------
Update Information:

Rust 1.56.1 adds a mitigation for CVE-2021-42574, the "trojan source" attack
that obfuscates code with BiDi control characters. The compiler will now error
on such characters in code comments and string/char literals. For more details,
see the upstream [security advisory](<https://blog.rust->
lang.org/2021/11/01/cve-2021-42574.html).
--------------------------------------------------------------------------------
ChangeLog:

\* Mon Nov 1 2021 Josh Stone jistone@redhat.com - 1.56.1-1
- Update to 1.56.1.
--------------------------------------------------------------------------------

This update can be installed with the "dnf" update program. Use
su -c 'dnf upgrade --advisory FEDORA-2021-443139f67c' at the command
line. For more information, refer to the dnf documentation available at
<http://dnf.readthedocs.io/en/latest/command_ref.html#upgrade-command-label>

All packages are signed with the Fedora Project GPG key. More details on the
GPG keys used by the Fedora Project can be found at
<https://fedoraproject.org/keys>
--------------------------------------------------------------------------------

[0](#like "You must be logged-in to vote.")
[0](#dislike "You must be logged-in to vote.")

Reply

[Back to the thread](/archives/list/package-announce%40lists.fedoraproject.org/thread/IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD/#IH2RG5YTR6ZZOLUV3EUPZEIJR7XHJLVD)

[Back to the list](/archives/list/package-announce%40lists.fedoraproject.org/)

Powered by [HyperKitty](http://hyperkitty.readthedocs.org) version 1.3.7.



=== Content from www.openwall.com_11da79da_20250111_024723.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Hash Suite - Windows password security audit tool. GUI, reports in PDF.](https://hashsuite.openwall.net) | | --- | |
| --- | --- |

[[<prev]](5) [[next>]](7) [[thread-next>]](7) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <c2d12374-0ed6-d6d4-60ea-799934b6f173@cl.cam.ac.uk>
Date: Mon, 1 Nov 2021 17:27:53 +0000
From: Nicholas Boucher <nicholas.boucher@...cam.ac.uk>
To: oss-security@...ts.openwall.com
Subject: Trojan Source Attacks

OSS Security teams,

We have identified an issue affecting all compilers and interpreters
that support Unicode. We believe that the techniques described hereafter
can be used to generate adversarial encodings of source code files that
can be used to craft targeted attacks against source code that cannot be
seen by human reviewers in rendered text. This is of concern to the open
source community because, absent defenses, supply chain attacks can be
imperceptibly mounted against the ecosystem.

This vulnerability has undergone a coordinated disclosure process that
has concluded today. The security advisory can be found at
<https://trojansource.codes>.

Multiple organizations will be releasing parallel security advisories,
such as Rust's advisory at
<https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html>, Red Hat's
advisory at
<https://access.redhat.com/security/vulnerabilities/RHSB-2021-007>
<<https://access.redhat.com/security/vulnerabilities/RHSB-2021-007>>, and
GitHub's advisory at
<https://github.blog/changelog/2021-10-31-warning-about-bidirectional-unicode-text/>
<<https://github.blog/changelog/2021-10-31-warning-about-bidirectional-unicode-text/>>.

The attached paper describes an attack paradigm -- which we believe to
be novel -- discovered by security researchers at the University of
Cambridge. There are two techniques for attack, both of which exploit
Unicode's high expressiveness to craft source code files for which
rendered text displays divergent logic from the underlying encoded bytes
seen by compilers.

The first and primary technique, which we dub the Trojan Source attack,
uses Unicode Bidirectional (Bidi) control characters embedded in
comments and string literals to produce visually deceptive source code
files. This technique enables an adversary to encode constructs that
visually appear to be comments or string literals but execute as code,
or vice versa. Complete details, as well as recommended mitigations, can
be found in the attachment 001 Trojan Source.pdf. This vulnerability is
tracked under CVE-2021-42574.

The second technique, to which we refer as the homoglyph variant, uses
homoglyphs (characters that render to the same glyph but are represented
by different Unicode values) to define adversarial identifiers. In this
technique, an adversary defines an identifier such as a function name
that appears visually identical to a target function, but is defined
using Unicode homoglyphs. This adversarial function then performs some
malicious action, then optionally calls the original function it is
impersonating. When defined in upstream dependencies such as open source
software, these adversarial functions can be imported into downstream
software and invoked without visual indication of malicious code.
Complete details, as well as recommended mitigations, can also be found
in the attachment 001 Trojan Source.pdf. This vulnerability is tracked
under CVE-2021-42694.

Proofs-of-concept can be found at
<https://github.com/nickboucher/trojan-source>.

We hope that this information proves useful in building and applying
defenses where applicable.

Best,
Nicholas Boucher
University of Cambridge

Content of type "text/html" skipped

Download attachment "[001 Trojan Source.pdf](6/1)" of type "application/pdf" (737637 bytes)

Download attachment "[OpenPGP_0x5662BCEC5F1D2BEA.asc](6/2)" of type "application/pgp-keys" (3160 bytes)

Download attachment "[OpenPGP_signature](6/3)" of type "application/pgp-signature" (841 bytes)

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from lists.fedoraproject.org_96112230_20250111_024725.html ===


[![Fedora Mailing-Lists](/static/logo-hyperkitty-fedora.png)](/archives/ "Fedora Mailing-Lists")

[Sign In](/accounts/login/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ/)
[Sign Up](/accounts/signup/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ/)

* [Sign In](/accounts/login/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ/)
* [Sign Up](/accounts/signup/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ/)

* [Manage this list](/admin/lists/package-announce.lists.fedoraproject.org/)

×
#### Keyboard Shortcuts

### Thread View

* `j`: Next unread message
* `k`: Previous unread message
* `j a`: Jump to all threads* `j l`: Jump to MailingList overview

### 2025

* [January](/archives/list/package-announce%40lists.fedoraproject.org/2025/1/)

### 2024

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2024/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2024/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2024/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2024/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2024/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2024/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2024/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2024/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2024/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2024/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2024/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2024/1/)

### 2023

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2023/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2023/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2023/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2023/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2023/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2023/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2023/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2023/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2023/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2023/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2023/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2023/1/)

### 2022

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2022/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2022/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2022/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2022/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2022/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2022/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2022/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2022/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2022/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2022/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2022/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2022/1/)

### 2021

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2021/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2021/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2021/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2021/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2021/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2021/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2021/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2021/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2021/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2021/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2021/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2021/1/)

### 2020

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2020/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2020/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2020/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2020/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2020/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2020/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2020/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2020/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2020/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2020/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2020/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2020/1/)

### 2019

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2019/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2019/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2019/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2019/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2019/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2019/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2019/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2019/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2019/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2019/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2019/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2019/1/)

### 2018

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2018/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2018/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2018/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2018/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2018/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2018/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2018/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2018/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2018/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2018/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2018/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2018/1/)

### 2017

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2017/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2017/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2017/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2017/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2017/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2017/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2017/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2017/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2017/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2017/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2017/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2017/1/)

### 2016

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2016/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2016/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2016/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2016/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2016/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2016/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2016/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2016/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2016/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2016/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2016/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2016/1/)

### 2015

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2015/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2015/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2015/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2015/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2015/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2015/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2015/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2015/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2015/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2015/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2015/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2015/1/)

### 2014

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2014/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2014/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2014/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2014/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2014/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2014/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2014/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2014/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2014/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2014/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2014/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2014/1/)

### 2013

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2013/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2013/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2013/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2013/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2013/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2013/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2013/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2013/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2013/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2013/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2013/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2013/1/)

### 2012

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2012/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2012/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2012/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2012/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2012/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2012/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2012/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2012/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2012/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2012/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2012/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2012/1/)

### 2011

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2011/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2011/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2011/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2011/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2011/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2011/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2011/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2011/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2011/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2011/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2011/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2011/1/)

### 2010

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2010/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2010/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2010/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2010/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2010/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2010/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2010/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2010/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2010/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2010/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2010/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2010/1/)

### 2009

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2009/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2009/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2009/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2009/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2009/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2009/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2009/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2009/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2009/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2009/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2009/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2009/1/)

### 2008

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2008/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2008/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2008/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2008/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2008/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2008/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2008/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2008/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2008/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2008/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2008/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2008/1/)

### 2007

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2007/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2007/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2007/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2007/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2007/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2007/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2007/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2007/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2007/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2007/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2007/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2007/1/)

### 2006

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2006/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2006/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2006/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2006/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2006/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2006/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2006/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2006/5/)

[List overview](/archives/list/package-announce%40lists.fedoraproject.org/)

[Download](/archives/list/package-announce%40lists.fedoraproject.org/export/package-announce%40lists.fedoraproject.org-QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ.mbox.gz?message=QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ "This message in gzipped mbox format")

[thread](/archives/list/package-announce%40lists.fedoraproject.org/thread/QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ/#QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ)

# [SECURITY] Fedora 34 Update: rust-1.56.1-1.fc34

![](https://seccdn.libravatar.org/avatar/be256568dfce45c1862b55e6cf3f2726.jpg?s=120&d=retro&r=g)

[updates＠fedoraproject.org](/archives/users/3d8bb2e4c1d843beb492d4f8a7c44761/ "See the profile for updates＠fedoraproject.org")

4 Nov
2021

4 Nov
'21

1:34 a.m.

--------------------------------------------------------------------------------
Fedora Update Notification
FEDORA-2021-0578e23912
2021-11-04 01:32:58.741794
--------------------------------------------------------------------------------

Name : rust
Product : Fedora 34
Version : 1.56.1
Release : 1.fc34
URL : <https://www.rust-lang.org>
Summary : The Rust Programming Language
Description :
Rust is a systems programming language that runs blazingly fast, prevents
segfaults, and guarantees thread safety.

This package includes the Rust compiler and documentation generator.

--------------------------------------------------------------------------------
Update Information:

Rust 1.56.1 adds a mitigation for CVE-2021-42574, the "trojan source" attack
that obfuscates code with BiDi control characters. The compiler will now error
on such characters in code comments and string/char literals. For more details,
see the upstream [security advisory](<https://blog.rust->
lang.org/2021/11/01/cve-2021-42574.html).
--------------------------------------------------------------------------------
ChangeLog:

\* Mon Nov 1 2021 Josh Stone jistone@redhat.com - 1.56.1-1
- Update to 1.56.1.
--------------------------------------------------------------------------------

This update can be installed with the "dnf" update program. Use
su -c 'dnf upgrade --advisory FEDORA-2021-0578e23912' at the command
line. For more information, refer to the dnf documentation available at
<http://dnf.readthedocs.io/en/latest/command_ref.html#upgrade-command-label>

All packages are signed with the Fedora Project GPG key. More details on the
GPG keys used by the Fedora Project can be found at
<https://fedoraproject.org/keys>
--------------------------------------------------------------------------------

[0](#like "You must be logged-in to vote.")
[0](#dislike "You must be logged-in to vote.")

Reply

[Back to the thread](/archives/list/package-announce%40lists.fedoraproject.org/thread/QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ/#QUPA37D57VPTDLSXOOGF4UXUEADOC4PQ)

[Back to the list](/archives/list/package-announce%40lists.fedoraproject.org/)

Powered by [HyperKitty](http://hyperkitty.readthedocs.org) version 1.3.7.



=== Content from www.openwall.com_6876b2ab_20250111_024722.html ===


| [Openwall](/) * [Products](/)   + [Openwall GNU/\*/Linux   *server OS*](/Owl/)+ [Linux Kernel Runtime Guard](/lkrg/)+ [John the Ripper   *password cracker*](/john/)         - [Free & Open Source for any platform](/john/)- [in the cloud](/john/cloud/)- [Pro for Linux](/john/pro/linux/)- [Pro for macOS](/john/pro/macosx/)+ [Wordlists   *for password cracking*](/wordlists/)+ [passwdqc   *policy enforcement*](/passwdqc/)             - [Free & Open Source for Unix](/passwdqc/)- [Pro for Windows (Active Directory)](/passwdqc/windows/)+ [yescrypt   *KDF & password hashing*](/yescrypt/)+ [yespower   *Proof-of-Work (PoW)*](/yespower/)+ [crypt\_blowfish   *password hashing*](/crypt/)+ [phpass   *ditto in PHP*](/phpass/)+ [tcb   *better password shadowing*](/tcb/)+ [Pluggable Authentication Modules](/pam/)+ [scanlogd   *port scan detector*](/scanlogd/)+ [popa3d   *tiny POP3 daemon*](/popa3d/)+ [blists   *web interface to mailing lists*](/blists/)+ [msulogin   *single user mode login*](/msulogin/)+ [php\_mt\_seed   *mt\_rand() cracker*](/php_mt_seed/)* [Services](/services/)* Publications       + [Articles](/articles/)+ [Presentations](/presentations/)* Resources         + [Mailing lists](/lists/)+ [Community wiki](https://openwall.info/wiki/)+ [Source code repositories (GitHub)](https://github.com/openwall)+ [Source code repositories (CVSweb)](https://cvsweb.openwall.com)+ [File archive & mirrors](/mirrors/)+ [How to verify digital signatures](/signatures/)+ [OVE IDs](/ove/)* [What's new](/news) | |
| --- | --- |

| | [Follow @Openwall on Twitter for new release announcements and other news](https://twitter.com/openwall) | | --- | |
| --- | --- |

[[<prev]](3) [[next>]](5) [[<thread-prev]](1) [[thread-next>]](5) [[day]](.) [[month]](..) [[year]](../..) [[list]](../../..)
```

Message-ID: <20211101151002.po6yfo7lgenrucet@jwilk.net>
Date: Mon, 1 Nov 2021 16:10:02 +0100
From: Jakub Wilk <jwilk@...lk.net>
To: <oss-security@...ts.openwall.com>
Subject: Re: CVE-2021-42574: rustc 1.56.0 and
 bidirectional-override codepoints in source code

>+    ('\u{202A}', ""), // The following unicode text flow control characters are inconsistently
>+    ('\u{202B}', ""), // supported accross CLIs and can cause confusion due to the bytes on disk
>+    ('\u{202D}', ""), // not corresponding to the visible source code, so we replace them always.
>+    ('\u{202E}', ""),
>+    ('\u{2066}', ""),
>+    ('\u{2067}', ""),
>+    ('\u{2068}', ""),
>+    ('\u{202C}', ""),
>+    ('\u{2069}', ""),

Is it intentional that (here and elsewhere in the patch) they didn't
include all the characters with the Bidi_Control property?

    $ grep -w Bidi_Control /usr/share/unicode/PropList.txt
    061C          ; Bidi_Control # Cf       ARABIC LETTER MARK
    200E..200F    ; Bidi_Control # Cf   [2] LEFT-TO-RIGHT MARK..RIGHT-TO-LEFT MARK
    202A..202E    ; Bidi_Control # Cf   [5] LEFT-TO-RIGHT EMBEDDING..RIGHT-TO-LEFT OVERRIDE
    2066..2069    ; Bidi_Control # Cf   [4] LEFT-TO-RIGHT ISOLATE..POP DIRECTIONAL ISOLATE

So U+061C, U+200E and U+200F appear to be missing from the patch.

--
Jakub Wilk

```

[Powered by blists](https://www.openwall.com/blists/) - [more mailing lists](https://lists.openwall.net)

Please check out the
[Open Source Software Security Wiki](https://oss-security.openwall.org/wiki/), which is counterpart to this
[mailing list](https://oss-security.openwall.org/wiki/mailing-lists/oss-security).

Confused about [mailing lists](/lists/) and their use?
[Read about mailing lists on Wikipedia](https://en.wikipedia.org/wiki/Electronic_mailing_list)
and check out these
[guidelines on proper formatting of your messages](https://www.complang.tuwien.ac.at/anton/mail-news-errors.html).



=== Content from www.unicode.org_aca087b2_20250111_024728.html ===


| [[Unicode]](https://www.unicode.org/) | [Technical Reports](https://www.unicode.org/reports/) |
| --- | --- |
|  | |

## Unicode® Standard Annex #31

# Unicode Identifiers and Syntax

| Version | Unicode 16.0.0 |
| --- | --- |
| Editors | Mark Davis (mark@unicode.org) and Robin Leroy (eggrobin@unicode.org) |
| Date | 2024-09-02 |
| This Version | <https://www.unicode.org/reports/tr31/tr31-41.html> |
| Previous Version | <https://www.unicode.org/reports/tr31/tr31-39.html> |
| Latest Version | <https://www.unicode.org/reports/tr31/> |
| Latest Proposed Update | <https://www.unicode.org/reports/tr31/proposed.html> |
| Revision | [41](#Modifications) |

#### Summary

*This annex describes specifications for recommended defaults
for the use of Unicode in the definitions of general-purpose identifiers, immutable identifiers, hashtag identifiers, and in
pattern-based syntax. It also supplies guidelines for use of
normalization with identifiers.*

#### Status

*This document has been reviewed by Unicode members and other
interested parties, and has been approved for publication by the
Unicode Consortium. This is a stable document and may be used as
reference material or cited as a normative reference by other
specifications.*

> ***A Unicode Standard Annex (UAX)** forms an integral part
> of the Unicode Standard, but is published online as a separate
> document. The Unicode Standard may require conformance to normative
> content in a Unicode Standard Annex, if so specified in the
> Conformance chapter of that version of the Unicode Standard. The
> version number of a UAX document corresponds to the version of the
> Unicode Standard of which it forms a part.*

*Please submit corrigenda and other comments with the online
reporting form [[Feedback](https://www.unicode.org/reporting.html)].
Related information that is useful in understanding this annex is
found in Unicode Standard Annex #41, “[Common
References for Unicode Standard Annexes](https://www.unicode.org/reports/tr41/tr41-34.html).” For the latest version of
the Unicode Standard, see [[Unicode](https://www.unicode.org/versions/latest/)]. For a
list of current Unicode Technical Reports, see [[Reports](https://www.unicode.org/reports/)]. For more
information about versions of the Unicode Standard, see [[Versions](https://www.unicode.org/versions/)]. For any
errata which may apply to this annex, see [[Errata](https://www.unicode.org/errata/)].*

#### Contents

* 1 [Introduction](#Introduction)
  + Figure 1. [Code Point Categories for Identifier Parsing](#Figure_Code_Point_Categories_for_Identifier_Parsing)
  + 1.1 [Stability](#Stability)
    - Table 1. [Permitted Changes in Future Versions](#Table_Permitted_Changes_in_Future_Versions)
  + 1.2 [Customization](#Customization)
  + 1.3 [Display Format](#Display_Format)
  + 1.4 [Conformance](#Conformance)
  + 1.5 [Notation](#Notation)
* 2 [Default Identifiers](#Default_Identifier_Syntax)
  + Table 2. [Properties for Lexical Classes for Identifiers](#Table_Lexical_Classes_for_Identifiers)
  + 2.1 [Combining Marks](#Combining_Marks)
  + 2.2 [Modifier Letters](#Modifier_Letters)
  + 2.3 [Layout
    and Format Control Characters](#Layout_and_Format_Control_Characters)
  + 2.4 [Specific
    Character Adjustments](#Specific_Character_Adjustments)
    - Table 3. [Optional
      Characters for Start](#Table_Optional_Start)
    - Table 3a. [Optional
      Characters for Medial](#Table_Optional_Medial)
    - Table 3b. [Optional Characters for Continue](#Table_Optional_Continue)
    - Table 4. [Excluded Scripts](#Table_Candidate_Characters_for_Exclusion_from_Identifiers)
    - Table 5. [Recommended Scripts](#Table_Recommended_Scripts)
    - Table 6. [Aspirational Use Scripts](#Aspirational_Use_Scripts) (Withdrawn)
    - Table 7. [Limited Use Scripts](#Table_Limited_Use_Scripts)
  + 2.5 [Backward
    Compatibility](#Backward_Compatibility)
* 3 [Immutable Identifiers](#Immutable_Identifier_Syntax)
* 4 [Whitespace and Syntax](#Whitespace_and_Syntax)
  + 4.1 [Whitespace](#Whitespace)
    - 4.1.1 [Bidirectional Ordering](#Bidirectional_Ordering)
    - 4.1.2 [Required\_Spaces](#Required_Spaces)
    - 4.1.3 [Contexts for Ignorable Format Controls](#Contexts_for_Ignorable_Format_Controls)
  + 4.2 [Syntax](#Syntax)
    - 4.2.1 [User-Defined Operators](#User-Defined_Operators)
  + 4.3 [Pattern Syntax](#Pattern_Syntax)
* 5 [Normalization and
  Case](#normalization_and_case)
  + 5.1 [NFKC Modifications](#NFKC_Modifications)
    - 5.1.1 [Modifications
      for Characters that Behave Like Combining Marks](#Combining_Mark_Mods)
    - 5.1.2 [Modifications for
      Irregularly Decomposing Characters](#Irreg_Decomp_Mods)
    - 5.1.3 [Identifier
      Closure Under Normalization](#Identifier_Closure)
      * Figure 5. [Normalization Closure](#Figure_Normalization_Closure)
      * Figure 6. [Case
        Closure](#Figure_Case_Closure)
      * Figure 7. [Reverse Normalization Closure](#Figure_Reverse_Normalization_Closure)
      * Table 8. [Compatibility Equivalents to Letters or Decimal Numbers](#Figure_Compatibility_Equivalents_to_Letters_or_Decimal_Numbers)
      * Table 9. [Canonical Equivalence Exceptions Prior to Unicode 5.1](#Figure_Canonical_Equivalence_Exceptions_Prior_to_Unicode_5.1)
  + 5.2 [Case and Stability](#Case_and_Stability)
    - 5.2.1 [Edge Cases
      for Folding](#Edge_Cases_for_Folding)
* 6 [Hashtag Identifiers](#hashtag_identifiers)
* 7 [Standard Profiles](#Standard_Profiles)
  + 7.1 [Mathematical Compatibility Notation Profile](#Mathematical_Compatibility_Notation_Profile)
  + 7.2 [Emoji Profile](#Emoji_Profile)
  + 7.3 [Default Ignorable Exclusion Profile](#Default_Ignorable_Exclusion_Profile)
* [Acknowledgments](#Acknowledgments)
* [References](#References)
* [Migration](#Migration)
* [Modifications](#Modifications)

---

## 1 [Introduction](#Introduction)

A common task facing an implementer of the Unicode Standard is the
provision of a parsing and/or lexing engine for identifiers, such as
programming language variables or domain names.
There are also realms where identifiers need to be defined with an extended set of
characters to align better with what end users expect, such as in
hashtags.

To assist in the standard treatment of identifiers in Unicode
character-based parsers and lexical analyzers, a set of
specifications is provided here as a
basis for parsing identifiers that contain Unicode characters. These specifications
include:

* [Default Identifiers](#Default_Identifier_Syntax): a
  recommended default for the definition of identifiers.
* [Immutable
  Identifiers](#Immutable_Identifier_Syntax): for environments that need a definition of
  identifiers that does not change across versions of Unicode.
* [Hashtag
  Identifiers](#hashtag_identifiers): for identifiers that need a broader set of
  characters, principally for hashtags.

These guidelines follow the typical pattern of identifier
syntax rules in common programming languages, by defining an ID\_Start
class and an ID\_Continue class and using a simple BNF rule for
identifiers based on those classes; however, the composition of those
classes is more complex and contains additional types of characters,
due to the universal scope of the Unicode Standard.

This annex also provides guidelines for the use of normalization and
case insensitivity with identifiers, expanding on a section that was
originally in Unicode Standard Annex #15, “Unicode Normalization
Forms” [[UAX15](../tr41/tr41-34.html#UAX15)].

Lexical analysis of computer languages is also concerned with lexical
elements other than identifiers, and with white space and line breaks
that separate them. This annex provides guidelines for the sets of
characters that have such lexical significance outside of identifiers.

The specification in this annex provides a definition of identifiers
that is guaranteed to be backward compatible with each successive
release of Unicode, but also allows any appropriate new Unicode
characters to become available in identifiers. In addition, Unicode
character properties for stable pattern syntax are provided. The
resulting pattern syntax is backward compatible *and* forward
compatible over future versions of the Unicode Standard. These
properties can either be used alone or in conjunction with the
identifier characters.

*Figure 1* shows the disjoint categories of code points defined
in this annex. (The sizes of the boxes are not to scale.)

Figure 1. [Code
Point Categories for Identifier Parsing](#Figure_Code_Point_Categories_for_Identifier_Parsing)

| ID\_Start Characters | Pattern\_Syntax Characters | Unassigned Code Points |
| --- | --- | --- |
| ID\_Nonstart Characters | Pattern\_White\_Space Characters |
| Other Assigned Code Points | |

The set consisting of the union of *ID\_Start* and *ID\_Nonstart*
characters is known as *Identifier Characters* and has the
property *ID\_Continue*. The *ID\_Nonstart* set is defined as
the set difference *ID\_Continue* minus *ID\_Start*: it is
not a formal Unicode property. While lexical rules are traditionally
expressed in terms of the latter, the discussion here is simplified
by referring to disjoint categories.

### 1.1 [Stability](#Stability)

There are certain features that developers can depend on for
stability:

* Identifier characters, Pattern\_Syntax characters, and
  Pattern\_White\_Space are disjoint: they will never overlap.
* By definition, the Identifier characters are always a superset of the
  ID\_Start characters.
* The Pattern\_Syntax characters and Pattern\_White\_Space
  characters are immutable and will not change over successive
  versions of Unicode.
* The ID\_Start and ID\_Nonstart characters may grow over time,
  either by the addition of new characters provided in a future
  version of Unicode or (in rare cases) by the addition of characters
  that were in Other.

In successive versions of Unicode, the only allowed changes of
characters from one of the above classes to another are those listed
with a plus sign (+) in *Table 1.*

Table 1. [Permitted
Changes in Future Versions](#Table_Permitted_Changes_in_Future_Versions)

|  | ID\_Start | ID\_Nonstart | Other Assigned |
| --- | --- | --- | --- |
| Unassigned | **+** | **+** | **+** |
| Other Assigned | **+** | **+** |  |
| ID\_Nonstart | **+** |  |  |

The Unicode Consortium has formally adopted a stability policy on
identifiers. For more information, see [[Stability](../tr41/tr41-34.html#Stability)].

### 1.2 [Customization](#Customization)

Each programming language standard has its own identifier
syntax; different programming languages have different conventions
for the use of certain characters such as $, @, #, and \_ in
identifiers. To extend such a syntax to cover the full behavior of a
Unicode implementation, implementers may combine those specific rules
with the syntax and properties provided here.

Each programming language can define its identifier syntax as *relative*
to the Unicode identifier syntax, such as saying that identifiers are
defined by the Unicode properties, with the addition of “$”. By
addition or subtraction of a small set of language specific
characters, a programming language standard can easily track a
growing repertoire of Unicode characters in a compatible way. See
also *Section 2.5, [Backward
Compatibility](#Backward_Compatibility)*.

Similarly, each programming language can define its own
whitespace characters or syntax characters relative to the Unicode
Pattern\_White\_Space or Pattern\_Syntax characters, with some specified
set of additions or subtractions.

Systems that want to extend identifiers to encompass words used in
natural languages, or narrow identifiers for security may do so as
described in *Section 2.3, [Layout and Format
Control Characters](#Layout_and_Format_Control_Characters)*, *Section 2.4, [Specific Character
Adjustments](#Specific_Character_Adjustments)*, and *Section 5, [Normalization and Case](#normalization_and_case)*.

To preserve the disjoint nature of the categories illustrated in *Figure
1*, any character *added* to one of the categories must be *subtracted*
from the others.

> **Note:** In many cases there are important
> security implications that may require additional constraints on
> identifiers. For more information, see [[UTR36](../tr41/tr41-34.html#UTR36)].

### 1.3 [Display Format](#Display_Format)

Implementations may use a format for *displaying* identifiers
that differs from the internal form used to *compare*
identifiers. For example, an implementation might display what
the user has entered, but use a normalized format for comparison.
Examples of this include:

> **Case.** The display format retains case differences,
> but the comparison format erases them by using Case\_Folding. Thus
> “A” and its lowercase variant “a” would be treated as the same
> identifier internally, even though they may have been input
> differently and may display differently.
>
> **Variants.** The display format retains variant
> distinctions, such as halfwidth versus fullwidth forms, or between
> variation sequences and their base characters, but the comparison
> format erases them by using NFKC\_Case\_Folding. Thus “A” and its
> full-width variant “Ａ” would be treated as the same identifier
> internally, even though they may have been input differently and may
> display differently.

For an example of the use of display versus comparison formats see *UTS
#46: Unicode IDNA Compatibility Processing* [[UTS46](../tr41/tr41-34.html#UTS46)]. For more information
about normalization and case in identifiers see *Section 5, [Normalization and Case](#normalization_and_case)*.

### 1.4 [Conformance](#Conformance)

The following describes the possible ways that an
implementation can claim conformance to this specification.

**[UAX31-C1](#C1)**. *An implementation
claiming conformance to this specification shall identify the
version of this specification.*

> **Note:** An implementation can make use of the property-based definitions from a specific version of this
> specification with property assignments from an unversioned reference to the Unicode Character Database.
> In this case, the implementation should specify a minimum version of Unicode for the properties.

**[UAX31-C2](#C2)**. *An implementation
claiming conformance to this specification shall describe which of
the following requirements it observes:*

* [R1. Default Identifiers](#R1)
* [R1b. Stable Identifiers](#R1b)
* [R2. Immutable Identifiers](#R2)
* [R3. Pattern\_White\_Space and Pattern\_Syntax
  Characters](#R3)
* [R3a. Pattern\_White\_Space Characters](#R3a)
* [R3b. Pattern\_Syntax Characters](#R3b)
* [R3c. Operator Identifiers](#R3c)
* [R4. Equivalent Normalized Identifiers](#R4)
* [R5. Equivalent Case-Insensitive
  Identifiers](#R5)
* [R6. Filtered Normalized Identifiers](#R6)
* [R7. Filtered Case-Insensitive Identifiers](#R7)
* [R8. Hashtag Identifiers](#R8)

> **Note:** Requirement [R1a](#R1a) has been removed. The characters that were added when meeting
> this requirement are now part of the default; the contextual checks required by this
> requirement remain as part of the General Security Profile in Unicode Technical Standard #39, “Unicode Security Mechanisms” [[UTS39](../tr41/tr41-34.html#UTS39)].

> **Note:** Meeting requirement R3 is equivalent to meeting requirements R3a and R3b.

### 1.5 [Notation](#Notation)

This annex uses *UnicodeSet* notation to illustrate the derivation of
some properties or sets of characters.
This notation is defined in the
[“Unicode Sets” section](https://www.unicode.org/reports/tr35/#Unicode_Sets) of
*UTS #35, Unicode Locale Data Markup Language*
[[UTS35](../tr41/tr41-34.html#UTS35)].

## 2 [Default Identifiers](#Default_Identifier_Syntax)

The formal syntax provided here captures the general intent
that an identifier consists of a string of characters beginning with
a letter or an ideograph, and followed by any number of letters,
ideographs, digits, or underscores. It provides a definition of
identifiers that is guaranteed to be backward compatible with each
successive release of Unicode, but also adds any appropriate new
Unicode characters.

The formulations allow for extensions, also
known as *profiles*. That is, the particular set of code points or sequences of code points for
each category used by the syntax can be customized according to the
requirements of the environment. Profiles are described
as additions to or removals from the categories used by the syntax.
They can thus be combined, provided that there are no conflicts (whereby one profile adds a character
and another removes it), or that the resolution of such conflicts is specified.

If such extensions include characters from Pattern\_White\_Space or
Pattern\_Syntax, then such identifiers do not conform to an unmodified
*[UAX31-R3 Pattern\_White\_Space and Pattern\_Syntax
Characters](#R3)*. However, such extensions may often be necessary. For
example, Java and C++ identifiers include ‘$’, which is a
Pattern\_Syntax character.

**[UAX31-D1](#D1)**. **Default
Identifier Syntax:**

> `<Identifier> := <Start> <Continue>*
> (<Medial> <Continue>+)*`

Identifiers are defined by assigning the
sets of lexical classes defined as properties in the Unicode
Character Database [[UAX44](../tr41/tr41-34.html#UAX44)].
These properties are shown in *Table 2*. The
first column shows the property name, whose values are defined in
the UCD. The second column provides a general description of the
coverage for the associated class, the derivational relationship
between the ID properties and the XID properties, and an associated
UnicodeSet notation for the class.

Table 2. [Properties for Lexical Classes for
Identifiers](#Table_Lexical_Classes_for_Identifiers)

| Properties | General Description of Coverage |
| --- | --- |
| `ID_Start` | `ID_Start` characters are derived from the Unicode General\_Category of uppercase letters, lowercase letters, titlecase letters, modifier letters, other letters, letter numbers, plus Other\_ID\_Start, minus Pattern\_Syntax and Pattern\_White\_Space code points. In UnicodeSet notation: [\p{L}\p{Nl}\p{Other\_ID\_Start}-\p{Pattern\_Syntax}-\p{Pattern\_White\_Space}] |
| `XID_Start` | `XID_Start` characters are derived from `ID_Start` as per *Section 5.1, [NFKC Modifications](#NFKC_Modifications)*. |
| `ID_Continue` | `ID_Continue` characters include ID\_Start characters, plus characters having the Unicode General\_Category of nonspacing marks, spacing combining marks, decimal number, connector punctuation, plus Other\_ID\_Continue, minus Pattern\_Syntax and Pattern\_White\_Space code points. In UnicodeSet notation: [\p{ID\_Start}\p{Mn}\p{Mc}\p{Nd}\p{Pc}\p{Other\_ID\_Continue}-\p{Pattern\_Syntax}-\p{Pattern\_White\_Space}] |
| `XID_Continue` | `XID_Continue` characters are derived from `ID_Continue` as per *Section 5.1, [NFKC Modifications](#NFKC_Modifications)*.  `XID_Continue` characters are also known simply as *Identifier Characters*, because they are a superset of the `XID_Start` characters. |

Note that “other letters” includes ideographs. For more about the
stability extensions, see *Section 2.5 [Backward Compatibility](#Backward_Compatibility)*.

The innovations in the identifier syntax to cover the Unicode
Standard include the following:

* Incorporation of proper handling of combining marks.
* Allowance for layout and format control characters, which
  should be ignored when parsing identifiers.

The XID\_Start and XID\_Continue properties are improved lexical
classes that incorporate the changes described in *Section 5.1,
[NFKC Modifications](#NFKC_Modifications)*.
They are recommended for most purposes, especially for security,
over the original ID\_Start and ID\_Continue properties.

**[UAX31-R1](#R1)**. **Default
Identifiers:** *To meet this requirement, to determine whether a string
is an identifier an implementation shall
choose either [UAX31-R1-1](#R1-1) or [UAX31-R1-2](#R1-2).*

**[UAX31-R1-1](#R1-1)**.
*Use definition [UAX31-D1](#D1), setting Start and
Continue to the properties XID\_Start and XID\_Continue, respectively, and leaving Medial empty.*

**[UAX31-R1-2](#R1-2)**.
*Declare that it uses a **profile**
of [UAX31-R1-1](#R1-1)
and define that profile with a precise specification of the
characters and character sequences that are added to or removed from Start,
Continue, and Medial and/or provide a list of additional
constraints on identifiers.*

> **Note:** Such a specification may incorporate a reference to one or more of the
> standard profiles described in *Section 7, [Standard
> Profiles](#Standard_Profiles)*.

One such profile may
be to use the contents of ID\_Start and ID\_Continue in place of
XID\_Start and XID\_Continue, for backward compatibility.

Another such profile would be to include some set of
the optional characters, for example:

* Start := XID\_Start, plus some characters
  from [Table 3](#Table_Optional_Start)
* Continue := Start + XID\_Continue, plus some
  characters from [Table 3b](#Table_Optional_Continue)
* Medial := some characters from [Table 3a](#Table_Optional_Medial)

> **Note:** Characters in the Medial class must not overlap with those in
> either the Start or Continue classes.
> Thus, any characters added to the Medial class from *[Table 3a](#Table_Optional_Medial)*
> must be be checked to ensure they do not also occur in either the newly defined Start class
> or Continue class.

Beyond such minor modifications, profiles could also be used to significantly extend the
character set available in identifiers.
In so doing, care must be taken not to unintentionally include undesired characters,
or to violate important invariants.

An implementation should be careful when adding a property-based set to a profile.

For example, consider a profile that adds subscript and superscript digits and
operators in order to support technical notations, such as:

| Context | Example Identifier |
| --- | --- |
| Assyriology | `dun₃⁺` |
| Chemistry | `Ca²⁺_concentration` |
| Mathematics | `xₖ₊₁` *or* `f⁽⁴⁾` |
| Phonetics | `daan⁶` |

That profile may be described as adding the following set to XID\_Continue:

> `[⁽₍⁾₎⁺₊⁼₌⁻₋⁰₀¹₁²₂³₃⁴₄⁵₅⁶₆⁷₇⁸₈⁹₉]`.

> **Note:** The above list is for illustration only.
> A standard profile is provided to support the use of Mathematical Compatibility Notation Profile in identifiers.
> See *Section 7.1, [Mathematical Compatibility Notation Profile](#Mathematical_Compatibility_Notation_Profile)*.

If, instead of listing these characters explicitly, the profile had chosen to use
properties or combinations of properties, that might result in including
undesired characters.

For example, `\p{General_Category=Other_Number}` is the general category set
containing the subscript and superscript digits.
But it also includes the compatibility characters [`⑴ 🄂 ⒈`], which are
not needed for technical notations,
and are very likely inappropriate for identifiers—on multiple counts.

On the other hand, a language that allows currency symbols in identifiers could have
`\p{General_Category=Currency_Symbol}` as a profile,
since that property matches the intent.

Similarly, a profile based on adding entire blocks is likely to include unintended characters,
or to miss ones that are desired.
For the use of blocks see *Annex A, Character Blocks*,
in [[UTS18](../tr41/tr41-34.html#UTS18)].

Defining a profile by use of a property also needs to take account of the fact that
unless the property is designed to be stable (such as XID\_Continue),
code points could be removed in a future version of Unicode.
If the profile also needs stable identifiers (backwards compatible),
then it must take additional measures.
See *[UAX31-R1b Stable Identifiers](#R1b)*.

Implementations that require identifier closure
under normalization should ensure that any custom profile preserves identifier closure
under the chosen normalization form. See
*Section 5.1.3, [Identifier Closure Under Normalization](#Identifier_Closure)*. The example cited above regarding subscripts and superscripts preserves identifier closure under
Normalization Forms C and D, but *not* under Forms KC and KD.
Under NFKC and NFKD, the subscript and superscript parentheses and operators normalize
to their ASCII counterparts.
If an implementation that uses this profile relies on identifier closure under normalization, it
should conform to [UAX31-R4](#R4) using NFC, not NFKC.

> **Note:** While default identifiers are less open-ended than immutable identifiers,
> they are still subject to spoofing issues arising from invisible characters,
> visually identical characters, or bidirectional reordering causing distinct sequences to appear
> in the same order.
> Where spoofing concerns are relevant, the mechanisms described in
> Unicode Technical Standard #39, “Unicode Security Mechanisms” [[UTS39](../tr41/tr41-34.html#UTS39)],
> should be used.
> For the specific case of programming languages and programming environments,
> recommendations are provided in
> Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

**[UAX31-R1a](#R1a)**. **Restricted
Format Characters:** *This clause has been removed.*

The characters that were added when meeting
this requirement are now part of the default; the contextual checks required by this
requirement remain as part of the General Security Profile in Unicode Technical Standard #39, “Unicode Security Mechanisms” [[UTS39](../tr41/tr41-34.html#UTS39)].

**[UAX31-R1b](#R1b)**. **Stable
Identifiers:** *To meet this requirement, an implementation shall
guarantee that identifiers are stable across versions of the Unicode
Standard: that is, once a string qualifies as an identifier, it does
so in all future versions of the Unicode Standard.*

> **Note:** The UAX31-R1b requirement is
> relevant when an identifier definition is based on property assignments from an
> unversioned reference to the Unicode Standard, as property assignments may
> change in a future version of the standard. It is typically achieved by using
> a small list of characters that qualified as identifier characters
> in some previous version of Unicode.
> See *Section 2.5, [Backward Compatibility](#Backward_Compatibility)*.
> Where profiles are allowed,
> management of those profiles may also be required to guarantee backwards
> compatibility. Typically such management also uses
> a list of characters that qualified previously.
> Because of the stability policy [[Stability](../tr41/tr41-34.html#Stability)],
> if an implementation meets either requirement
> [UAX31-R1](#R1) or [UAX31-R2](#R2) without declaring a
> profile, that implementation also meets requirement UAX31-R1b.

> **Example:** Consider an identifier definition which uses
> [UAX31-R1](#R1) default identifiers with a profile that adds digits
> (characters with General\_Category=Nd) to the set *Start*, and uses an
> unversioned reference to the Unicode Character Database,
> with a minimum version of 5.2.0.
>
> With property assignments from Unicode Version 5.2.0, both
> `᧚` (U+19DA) and `A᧚` (U+0041, U+19DA) are valid identifiers
> under this definition: U+19DA has General\_Category=Nd.
>
> In Unicode Version 6.0.0, U+19DA has General\_Category=No.
> The identifier `A᧚` (U+0041, U+19DA)
> remains valid, because XID\_Continue includes any characters that used to be XID\_Continue.
> However, `᧚` is not a valid identifier, because U+19DA is no
> longer in the set [:Nd:].
>
> In order to meet requirement [UAX31-R1b](#R1b), the definition would
> need to be changed to add to the set *Start* all characters that have the
> property General\_Category=Nd in any version of Unicode starting from Unicode 5.2.0
> and up to the version used by the implementation.

### 2.1 [Combining Marks](#Combining_Marks)

Combining marks are accounted for in identifier syntax: a composed
character sequence consisting of a base character followed by any
number of combining marks is valid in an identifier. Combining marks
are required in the representation of many languages, and the
conformance rules in *Chapter 3, Conformance*, of [[Unicode](../tr41/tr41-34.html#Unicode)] require the
interpretation of canonical-equivalent character sequences. The
simplest way to do this is to require identifiers in the NFC format
(or transform them into that format); see *Section 5, [Normalization and Case](#normalization_and_case)*.

Enclosing combining marks (such as U+20DD..U+20E0) are excluded from
the definition of the
lexical class
`ID_Continue`,
because the composite characters that result from their composition
with letters are themselves not normally considered valid
constituents of these identifiers.

### 2.2 [Modifier Letters](#Modifier_Letters)

Modifier letters (General\_Category=Lm) are also included in the
definition of the syntax classes for identifiers. Modifier letters
are often part of natural language orthographies and are useful for
making word-like identifiers in formal languages. On the other hand,
modifier symbols (General\_Category=Sk), which are seldom a part of
language orthographies, are excluded from identifiers. For more
discussion of modifier letters and how they function, see [[Unicode](../tr41/tr41-34.html#Unicode)].

Implementations that tailor identifier syntax for special
purposes may wish to take special note of modifier letters, as in
some cases modifier letters have appearances, such as raised commas,
which may be confused with common syntax characters such as quotation
marks.

### 2.3 [Layout and Format Control Characters](#Layout_and_Format_Control_Characters)

Certain Unicode characters are known as
Default\_Ignorable\_Code\_Points. These include variation selectors and
characters used to control joining behavior, bidirectional ordering
control, and alternative formats for display (having the
General\_Category value of Cf). The use of
default-ignorable characters in identifiers is problematic, first
because the effects they represent are stylistic or otherwise out of
scope for identifiers, and second because the characters themselves
often have no visible display. It is also possible to misapply these
characters such that users can create strings that look the same but
actually contain different characters, which can create security
problems. In environments where spoofing concerns are paramount, such as top-level domain names, identifiers should also be limited to
characters that are case-folded and normalized with the NFKC\_Casefold
operation. For more information, see *Section 5, [Normalization and Case](#normalization_and_case)* and *UTR
#36: Unicode Security Considerations* [[UTR36](../tr41/tr41-34.html#UTR36)].

While not all Default\_Ignorable\_Code\_Points are in XID\_Continue, the variation selectors and joining controls *are* included in XID\_Continue.
These variation selectors are used in standardized variation sequences, sequences from the Ideographic Variation Database, and emoji variation sequences.
The joining controls are used in the orthographies of some languages, as well as in emoji ZWJ sequences.
However, these characters are subject to the same considerations as other Default\_Ignorable\_Code\_Points listed above.
Because variation selectors and joining controls request a difference in display but do not guarantee it, they do not work well in general-purpose identifiers.
A profile should be used to remove them from general-purpose identifiers (along with other Default\_Ignorable\_Code\_Points), unless their use is required in a particular domain, such as in a profile that includes emoji.
For such a profile it may be useful to explicitly retain or even add certain Default\_Ignorable\_Code\_Points in the identifier syntax.

For programming language identifiers, spoofing issues are more comprehensively addressed by higher-level diagnostics rather than at the syntactic level. See Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

***Comparison.*** In any environment where the display form for identifiers differs from the form used to compare them, Default\_Ignorable\_Code\_Points should be ignored for comparison.
For example, this applies to case-insensitive identifiers.
For more information, see *Section 1.3, [Display Format](#Display_Format)*.

> **Notes:**
>
> * An implementation of [UAX31-R4](#R4) and [UAX31-R5](#R5) (Equivalent Case and Compatibility-Insensitive Identifiers) that compares identifiers under the *identifier caseless match* defined by D147 [[Unicode](../tr41/tr41-34.html#Unicode)], that is, canonical decomposition (NFD) followed by the toNFKC\_Casefold operation, ignores Default\_Ignorable\_Code\_Points.
> * The Default\_Ignorable\_Code\_Point property values are not guaranteed to be stable.
>   However, the derivation of the NFKC\_Casefold property will be changed if necessary to ensure that it remains stable for default identifiers.
>   That means that the toNFKC\_Casefold operation applied to a string with only characters in XID\_Continue in a version of Unicode will have the same results in any future version of Unicode.

In addition, a standard profile is provided to exclude all Default\_Ignorable\_Code\_Points; see *Section 7, [Standard Profiles](#Standard_Profiles)*. Note however that, even if Default\_Ignorable\_Code\_Points are excluded, spoofing issues remain unless the mechanisms in Unicode Technical Standard #39, “Unicode Security Mechanisms” [[UTS39](../tr41/tr41-34.html#UTS39)] are utilized.

The General Security Profile defined in Section 3.1, General Security Profile for Identifiers, in *UTS #39, Unicode Security Mechanisms* [[UTS39](../tr41/tr41-34.html#UTS39)], excludes all Default\_Ignorable\_Code\_Points by default, including variation selectors.

### 2.4 [Specific Character Adjustments](#Specific_Character_Adjustments)

Specific identifier syntaxes can be treated as tailorings (or *profiles*)
of the generic syntax based on character properties. For example, SQL
identifiers allow an underscore as an identifier continue, but not as
an identifier start; C identifiers allow an underscore as either an
identifier continue or an identifier start. Specific languages may
also want to exclude the characters that have a Decomposition\_Type
other than Canonical or None, or to exclude some subset of those,
such as those with a Decomposition\_Type equal to Font.

There are circumstances in which identifiers are expected to more
fully encompass words or phrases used in natural languages.

For more natural-language identifiers, a profile should allow the
characters in *[Table 3](#Table_Optional_Start)*, *[Table
3a](#Table_Optional_Medial)*, and *[Table 3b](#Table_Optional_Continue)* in
identifiers, unless there are compelling reasons not to. Most additions to identifiers are restricted
to medial positions. These are listed in *[Table 3a](#Table_Optional_Medial)*. A few characters can
also occur in final positions, and are listed in *[Table 3b](#Table_Optional_Continue)*. The contents of these
tables may overlap.

In some environments even spaces and @
are allowed in identifiers, such as in SQL: *SELECT \* FROM
Employee Pension.*

Table 3. [Optional Characters for Start](#Table_Optional_Start)

| Code Point | Character | Name |
| --- | --- | --- |
| 0024 | $ | DOLLAR SIGN |
| 005F | \_ | LOW LINE |

Table 3a. [Optional Characters for Medial](#Table_Optional_Medial)

| Code Point | Character | Name |
| --- | --- | --- |
| 0027 | ' | APOSTROPHE |
| 002D | - | HYPHEN-MINUS |
| 002E | . | FULL STOP |
| 003A | : | COLON |
| 058A | ֊ | ARMENIAN HYPHEN |
| 05F4 | ״ | HEBREW PUNCTUATION GERSHAYIM |
| 0F0B | ་ | TIBETAN MARK INTERSYLLABIC TSHEG |
| 2010 | ‐ | HYPHEN |
| 2019 | ’ | RIGHT SINGLE QUOTATION MARK |
| 2027 | ‧ | HYPHENATION POINT |
| 30A0 | ゠ | KATAKANA-HIRAGANA DOUBLE HYPHEN |

Table 3b. [Optional Characters for
Continue](#Table_Optional_Continue)

| Code Point | Character | Name |
| --- | --- | --- |
| 05F3 | ׳ | HEBREW PUNCTUATION GERESH |

In UnicodeSet notation, the characters in these tables are:

* Table 3: [\$\_]
* Table 3a: ['\-.\:֊״་‐’‧゠・]
* Table 3b: [ ׳]

In identifiers that allow for unnormalized characters, the
compatibility equivalents of the characters listed in *[Table 3](#Table_Optional_Start)*,
*[Table 3a](#Table_Optional_Medial)*, and *[Table 3b](#Table_Optional_Continue)*
may also be appropriate.

For more information on characters that may occur in words, and those
that may be used in name validation, see Section 4, *Word Boundaries*, in [[UAX29](../tr41/tr41-34.html#UAX29)].

Some scripts are not in customary modern use, and thus
implementations may want to exclude them from identifiers. These
include historic and obsolete scripts, scripts used
mostly liturgically, and regional scripts used only in very small
communities or with very limited current usage. Some scripts also have unresolved architectural issues that make them currently unsuitable for identifiers. The scripts in *Table 4, [Excluded Scripts](#Table_Candidate_Characters_for_Exclusion_from_Identifiers)* are recommended for exclusion from identifiers.

Table 4. [Excluded Scripts](#Table_Candidate_Characters_for_Exclusion_from_Identifiers)

| Property Notation | Description |
| --- | --- |
| `\p{script=Aghb}` | Caucasian Albanian |
| `\p{script=Ahom}` | Ahom |
| `\p{script=Armi}` | Imperial Aramaic |
| `\p{script=Avst}` | Avestan |
| `\p{script=Bass}` | Bassa Vah |
| `\p{script=Bhks}` | Bhaiksuki |
| `\p{script=Brah}` | Brahmi |
| `\p{script=Bugi}` | Buginese |
| `\p{script=Buhd}` | Buhid |
| `\p{script=Cari}` | Carian |
| `\p{script=Chrs}` | Chorasmian |
| `\p{script=Copt}` | Coptic |
| `\p{script=Cpmn}` | Cypro-Minoan |
| `\p{script=Cprt}` | Cypriot |
| `\p{script=Diak}` | Dives Akuru |
| `\p{script=Dogr}` | Dogra |
| `\p{script=Dsrt}` | Deseret |
| `\p{script=Dupl}` | Duployan |
| `\p{script=Egyp}` | Egyptian Hieroglyphs |
| `\p{script=Elba}` | Elbasan |
| `\p{script=Elym}` | Elymaic |
| `\p{script=Glag}` | Glagolitic |
| `\p{script=Gong}` | Gunjala Gondi |
| `\p{script=Gonm}` | Masaram Gondi |
| `\p{script=Goth}` | Gothic |
| `\p{script=Gran}` | Grantha |
| `\p{script=Hano}` | Hanunoo |
| `\p{script=Hatr}` | Hatran |
| `\p{script=Hluw}` | Anatolian Hieroglyphs |
| `\p{script=Hmng}` | Pahawh Hmong |
| `\p{script=Hung}` | Old Hungarian |
| `\p{script=Ital}` | Old Italic |
| `\p{script=Kawi}` | Kawi |
| `\p{script=Khar}` | Kharoshthi |
| `\p{script=Khoj}` | Khojki |
| `\p{script=Kits}` | Khitan Small Script |
| `\p{script=Kthi}` | Kaithi |
| `\p{script=Lina}` | Linear A |
| `\p{script=Linb}` | Linear B |
| `\p{script=Lyci}` | Lycian |
| `\p{script=Lydi}` | Lydian |
| `\p{script=Maka}` | Makasar |
| `\p{script=Mahj}` | Mahajani |
| `\p{script=Mani}` | Manichaean |
| `\p{script=Marc}` | Marchen |
| `\p{script=Medf}` | Medefaidrin |
| `\p{script=Mend}` | Mende Kikakui |
| `\p{script=Merc}` | Meroitic Cursive |
| `\p{script=Mero}` | Meroitic Hieroglyphs |
| `\p{script=Modi}` | Modi |
| `\p{script=Mong}` | Mongolian |
| `\p{script=Mroo}` | Mro |
| `\p{script=Mult}` | Multani |
| `\p{script=Nagm}` | Nag Mundari |
| `\p{script=Narb}` | Old North Arabian |
| `\p{script=Nand}` | Nandinagari |
| `\p{script=Nbat}` | Nabataean |
| `\p{script=Nshu}` | Nushu |
| `\p{script=Ogam}` | Ogham |
| `\p{script=Orkh}` | Old Turkic |
| `\p{script=Osma}` | Osmanya |
| `\p{script=Ougr}` | Old Uyghur |
| `\p{script=Palm}` | Palmyrene |
| `\p{script=Pauc}` | Pau Cin Hau |
| `\p{script=Perm}` | Old Permic |
| `\p{script=Phag}` | Phags-pa |
| `\p{script=Phli}` | Inscriptional Pahlavi |
| `\p{script=Phlp}` | Psalter Pahlavi |
| `\p{script=Phnx}` | Phoenician |
| `\p{script=Prti}` | Inscriptional Parthian |
| `\p{script=Rjng}` | Rejang |
| `\p{script=Runr}` | Runic |
| `\p{script=Samr}` | Samaritan |
| `\p{script=Sarb}` | Old South Arabian |
| `\p{script=Sgnw}` | SignWriting |
| `\p{script=Shaw}` | Shavian |
| `\p{script=Shrd}` | Sharada |
| `\p{script=Sidd}` | Siddham |
| `\p{script=Sind}` | Khudawadi |
| `\p{script=Sora}` | Sora Sompeng |
| `\p{script=Sogd}` | Sogdian |
| `\p{script=Sogo}` | Old Sogdian |
| `\p{script=Soyo}` | Soyombo |
| `\p{script=Tagb}` | Tagbanwa |
| `\p{script=Takr}` | Takri |
| `\p{script=Tang}` | Tangut |
| `\p{script=Tglg}` | Tagalog |
| `\p{script=Tirh}` | Tirhuta |
| `\p{script=Tnsa}` | Tangsa |
| `\p{script=Toto}` | Toto |
| `\p{script=Ugar}` | Ugaritic |
| `\p{script=Vith}` | Vithkuqi |
| `\p{script=Wara}` | Warang Citi |
| `\p{script=Xpeo}` | Old Persian |
| `\p{script=Xsux}` | Cuneiform |
| `\p{script=Yezi}` | Yezidi |
| `\p{script=Zanb}` | Zanabazar Square |

Some characters used with recommended scripts may still be problematic for identifiers, for example because they are part of extensions that are not in modern customary use, and thus implementations may want to exclude them from identifiers. These include characters for historic and obsolete orthographies, characters used mostly liturgically, and in orthographies for languages used only in very small communities or with very limited current or declining usage. Some characters also have architectural issues that may make them unsuitable for identifiers. See *UTS #39, Unicode Security Mechanisms* [[UTS39](../tr41/tr41-34.html#UTS39)] for more information.

The scripts listed in *Table 5, [Recommended Scripts](#Table_Recommended_Scripts)* are generally recommended for use in
identifiers. These are in widespread modern customary use, or are
regional scripts in modern customary use by large communities.

Table 5. [Recommended Scripts](#Table_Recommended_Scripts)

| Property Notation | Description |
| --- | --- |
| `\p{script=Zyyy}` | Common |
| `\p{script=Zinh}` | Inherited |
| `\p{script=Arab}` | Arabic |
| `\p{script=Armn}` | Armenian |
| `\p{script=Beng}` | Bengali |
| `\p{script=Bopo}` | Bopomofo |
| `\p{script=Cyrl}` | Cyrillic |
| `\p{script=Deva}` | Devanagari |
| `\p{script=Ethi}` | Ethiopic |
| `\p{script=Geor}` | Georgian |
| `\p{script=Grek}` | Greek |
| `\p{script=Gujr}` | Gujarati |
| `\p{script=Guru}` | Gurmukhi |
| `\p{script=Hang}` | Hangul |
| `\p{script=Hani}` | Han |
| `\p{script=Hebr}` | Hebrew |
| `\p{script=Hira}` | Hiragana |
| `\p{script=Kana}` | Katakana |
| `\p{script=Knda}` | Kannada |
| `\p{script=Khmr}` | Khmer |
| `\p{script=Laoo}` | Lao |
| `\p{script=Latn}` | Latin |
| `\p{script=Mlym}` | Malayalam |
| `\p{script=Mymr}` | Myanmar |
| `\p{script=Orya}` | Oriya |
| `\p{script=Sinh}` | Sinhala |
| `\p{script=Taml}` | Tamil |
| `\p{script=Telu}` | Telugu |
| `\p{script=Thaa}` | Thaana |
| `\p{script=Thai}` | Thai |
| `\p{script=Tibt}` | Tibetan |

As of Unicode 10.0, there is no longer a distinction between
aspirational use and limited use scripts, as this has not proven
to be productive for the derivation of identifier-related classes
used in security profiles. (See *UTS #39, Unicode Security Mechanisms*
[[UTS39](../tr41/tr41-34.html#UTS39)].) Thus the aspirational use scripts
in *Table 6, [Aspirational Use Scripts](#Aspirational_Use_Scripts)* have been recategorized
as Limited Use and moved to *Table 7, [Limited Use Scripts](#Table_Limited_Use_Scripts)*.

Table 6.  [Aspirational Use Scripts](#Aspirational_Use_Scripts) (Withdrawn)

| Property Notation | Description |
| --- | --- |
| *intentionally blank* | |

Modern scripts that are in more limited use are listed in *Table 7, [Limited Use Scripts](#Table_Limited_Use_Scripts)*.
To avoid security issues, some implementations may wish to disallow
the limited-use scripts in identifiers. For more information on
usage, see the Unicode Locale project [[CLDR](../tr41/tr41-34.html#CLDR)].

Table 7. [Limited Use Scripts](#Table_Limited_Use_Scripts)

| Property Notation | Description |
| --- | --- |
| `\p{script=Adlm}` | Adlam |
| `\p{script=Bali}` | Balinese |
| `\p{script=Bamu}` | Bamum |
| `\p{script=Batk}` | Batak |
| `\p{script=Cakm}` | Chakma |
| `\p{script=Cans}` | Canadian Aboriginal Syllabics |
| `\p{script=Cham}` | Cham |
| `\p{script=Cher}` | Cherokee |
| `\p{script=Hmnp}` | Nyiakeng Puachue Hmong |
| `\p{script=Java}` | Javanese |
| `\p{script=Kali}` | Kayah Li |
| `\p{script=Lana}` | Tai Tham |
| `\p{script=Lepc}` | Lepcha |
| `\p{script=Limb}` | Limbu |
| `\p{script=Lisu}` | Lisu |
| `\p{script=Mand}` | Mandaic |
| `\p{script=Mtei}` | Meetei Mayek |
| `\p{script=Newa}` | Newa |
| `\p{script=Nkoo}` | Nko |
| `\p{script=Olck}` | Ol Chiki |
| `\p{script=Osge}` | Osage |
| `\p{script=Plrd}` | Miao |
| `\p{script=Rohg}` | Hanifi Rohingya |
| `\p{script=Saur}` | Saurashtra |
| `\p{script=Sund}` | Sundanese |
| `\p{script=Sylo}` | Syloti Nagri |
| `\p{script=Syrc}` | Syriac |
| `\p{script=Tale}` | Tai Le |
| `\p{script=Talu}` | New Tai Lue |
| `\p{script=Tavt}` | Tai Viet |
| `\p{script=Tfng}` | Tifinagh |
| `\p{script=Vaii}` | Vai |
| `\p{script=Wcho}` | Wancho |
| `\p{script=Yiii}` | Yi |

This is the recommendation as of the current version of Unicode; as
new scripts are added to future versions of Unicode, characters and scripts may
be added to Tables *[4](#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*,
*[5](#Table_Recommended_Scripts)*, and *[7](#Table_Limited_Use_Scripts)*. Characters may also be
moved from one table to another as more information becomes
available.

There are a few special cases:

* The Common and Inherited script values
  [\p{script=Zyyy}\p{script=Zinh}] are used widely with other scripts,
  rather than being scripts per se. See also the Script\_Extensions
  property in the Unicode Character Database [[UAX44](../tr41/tr41-34.html#UAX44)].
* The Unknown script \p{script=Zzzz} is used for Unassigned
  characters.
* Braille \p{script=Brai} consists only of symbols
* Katakana\_Or\_Hiragana \p{script=Hrkt} is empty. This value was used
  in earlier versions, but is no longer used.
* With respect to the scripts Balinese, Cham, Ol Chiki, Vai,
  Kayah Li, and Saurashtra, there may be large communities of people
  speaking an associated language, but the script itself is not in
  widespread use. However, there are significant revival efforts.
* Bopomofo is used primarily in education.

For programming language identifiers, normalization and case have a
number of important implications. For a discussion of these issues,
see *Section 5, [Normalization
and Case](#normalization_and_case)*.

### 2.5 [Backward Compatibility](#Backward_Compatibility)

Unicode General\_Category values are kept as stable as possible, but
they can change across versions of the Unicode Standard. The bulk of
the characters having a given value are determined by other
properties, and the coverage expands in the future according to the
assignment of those properties. In addition, the Other\_ID\_Start
property provides a small list of characters that qualified as
ID\_Start characters in some previous version of Unicode solely on the
basis of their General\_Category properties, but that no longer
qualify in the current version.

The Other\_ID\_Start property includes characters such as the
following:

> U+2118 ( ℘ ) SCRIPT CAPITAL P
>  U+212E ( ℮ ) ESTIMATED SYMBOL
>
> U+309B ( ゛ ) KATAKANA-HIRAGANA VOICED SOUND MARK
>  U+309C ( ゜
> ) KATAKANA-HIRAGANA SEMI-VOICED SOUND MARK

Similarly, the Other\_ID\_Continue property adds a small list of
characters that qualified as ID\_Continue characters in some previous
version of Unicode solely on the basis of their General\_Category
properties, but that no longer qualify in the current version.

The Other\_ID\_Continue property includes characters such as the
following:

> U+1369 ETHIOPIC DIGIT ONE...U+1371 ETHIOPIC DIGIT NINE
>
> U+00B7 ( · ) MIDDLE DOT
>  U+0387 ( · ) GREEK ANO TELEIA
>
> U+19DA ( ᧚ ) NEW TAI LUE THAM DIGIT ONE

The exact list of characters covered by the Other\_ID\_Start and
Other\_ID\_Continue properties depends on the version of Unicode. For
more information, see Unicode Standard Annex #44, “Unicode Character
Database” [[UAX44](../tr41/tr41-34.html#UAX44)].

The Other\_ID\_Start and Other\_ID\_Continue properties are thus
designed to ensure that the Unicode identifier specification is
backward compatible. Any sequence of characters that qualified as an
identifier in some version of Unicode will continue to qualify as an
identifier in future versions.

If a specification tailors the Unicode recommendations for
identifiers, then this technique can also be used to maintain
backwards compatibility across versions.

## 3 [Immutable Identifiers](#Immutable_Identifier_Syntax)

The disadvantage of working with the lexical classes defined
previously is the storage space needed for the detailed definitions,
plus the fact that with each new version of the Unicode Standard new
characters are added, which an existing parser would not be able to
recognize. In other words, the recommendations based on that table
are not upwardly compatible.

This problem can be addressed by turning the question around.
Instead of defining the set of code points that are allowed, define a
small, fixed set of code points that are reserved for syntactic use
and allow everything else (including unassigned code points) as part
of an identifier. All parsers written to this specification would
behave the same way for all versions of the Unicode Standard, because
the classification of code points is fixed forever.

The drawback of this method is that it allows “nonsense” to be part
of identifiers because the concerns of lexical classification and of
human intelligibility are separated. Human intelligibility can,
however, be addressed by other means, such as usage guidelines that
encourage a restriction to meaningful terms for identifiers. For an
example of such guidelines, see the XML specification by the W3C,
Version 1.0 5th Edition or later [[XML](../tr41/tr41-34.html#XML)].

By increasing the set of disallowed characters, a reasonably
intuitive recommendation for identifiers can be achieved. This
approach uses the full specification of identifier classes, as of a
particular version of the Unicode Standard, and permanently disallows
any characters not recommended in that version for inclusion in
identifiers. All code points unassigned as of that version would be
allowed in identifiers, so that any future additions to the standard
would already be accounted for. This approach ensures both upwardly
compatible identifier stability and a reasonable division of
characters into those that do and do not make human sense as part of
identifiers.

With or without such fine-tuning, such a compromise approach
still incurs the expense of implementing large lists of code points.
While they no longer change over time, it is a matter of choice
whether the benefit of enforcing somewhat word-like identifiers
justifies their cost.

Alternatively, one can use the properties described below and
allow all sequences of characters to be identifiers that are neither
Pattern\_Syntax nor Pattern\_White\_Space. This has the advantage of
simplicity and small tables, but allows many more “unnatural”
identifiers.

**[UAX31-R2](#R2)**.
**Immutable Identifiers:** *To meet this requirement,
an implementation shall
choose either [UAX31-R2-1](#R2-1) or [UAX31-R2-2](#R2-2).*

**[UAX31-R2-1](#R2-1)**.
*Define identifiers to be any non-empty
string of characters that contains no character having any of the
following property values:*

* Pattern\_White\_Space=True
* Pattern\_Syntax=True
* General\_Category=Private\_Use, Surrogate, or Control
* Noncharacter\_Code\_Point=True

**[UAX31-R2-2](#R2-2)**.
*Declare that it uses a **profile**
of [UAX31-R2-1](#R2-1)
and define that profile with a precise specification of the
characters and character sequences that are added to or removed from the sets of code points
defined by these properties and/or provide a list of additional constraints on identifiers.*

> **Note:** The expectation from an implementation meeting requirement UAX31-R2 Immutable Identifiers is that it will never change its definition of identifiers; in particular, that it will not switch to UAX31-R1 Default Identifiers. However, the downsides of normalization issues and the inapplicability of measures guarding against spoofing attacks may warrant such a change in definition. In such circumstances, a profile should be used to extend XID\_Start and XID\_Continue to cover likely existing usages. See *Section 3.3, Language Evolution*, in Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

In its profile, a specification can define identifiers to be
more in accordance with the Unicode identifier definitions at the
time the profile is adopted, while still allowing for strict
immutability. For example, an implementation adopting a profile after
a particular version of Unicode is released (such as Unicode 5.0)
could define the profile as follows:

1. All characters satisfying *[UAX31-R1
   Default Identifiers](#R1)* according to Unicode 5.0
2. Plus all code points unassigned in Unicode 5.0 that do not
   have the property values specified in
   *[UAX31-R2 Immutable Identifiers](#R2)*.

This technique allows identifiers to have a more natural
format—excluding symbols and punctuation already defined—yet also
provides absolute code point immutability.

Immutable identifiers are intended for those cases (like XML) that
cannot update across versions of Unicode, and do not require
information about normalization form, or properties such as
General\_Category and Script. Immutable identifers that allow
unassigned characters cannot provide for normalization forms
or these properties, which means that they:

* cannot be compared for NFC, NFKC, or case-insensitive equality
* are unsuitable for restrictions such as those in UTS #39

For best practice, a profile disallowing unassigned characters should be provided where possible.

Specifications should also include guidelines and recommendations for
those creating new identifiers. Although
*[UAX31-R2 Immutable Identifiers](#R2)* permits a wide range of
characters, as a best practice identifiers should be in the format
NFKC, without using any unassigned characters. For more information
on NFKC, see Unicode Standard Annex #15, “Unicode Normalization
Forms” [[UAX15](../tr41/tr41-34.html#UAX15)].

## 4 [Whitespace and Syntax](#Whitespace_and_Syntax)

Most programming languages have a concept of
whitespace as part of their lexical structure, as well as some set of
characters that are disallowed in identifiers but have syntactic
use, such as arithmetic operators.
Beyond general programming languages,
there are also many circumstances where software interprets
patterns that are a mixture of literal characters, whitespace, and syntax
characters. Examples include regular expressions, Java collation
rules, Excel or ICU number formats, and many others. In the past,
regular expressions and other formal languages have been forced to
use clumsy combinations of ASCII characters for their syntax. As
Unicode becomes ubiquitous, some of these will start to use non-ASCII
characters for their syntax: first as more readable optional
alternatives, then eventually as the standard syntax.

For forward and backward compatibility, it is advantageous to have a
fixed set of whitespace and syntax code points.
This follows the recommendations that the Unicode Consortium has made
regarding completely stable identifiers, and the practice that is
seen in XML 1.0, 5th Edition or later [[XML](../tr41/tr41-34.html#XML)]. (In particular, the
Unicode Consortium is committed to not allocating characters suitable
for identifiers in the range U+2190..U+2BFF, which is being used by
XML 1.0, 5th Edition.)

As of Unicode 4.1, two Unicode character properties are defined
to provide for stable syntax: Pattern\_White\_Space and
Pattern\_Syntax.  Particular languages may, of course,
override these recommendations, for example, by adding or removing
other characters for compatibility with ASCII usage.

For stability, the values of these properties are absolutely
invariant, not changing with successive versions of Unicode. Of
course, this does not limit the ability of the Unicode Standard to
encode more symbol or whitespace characters, but the default sets of syntax and
whitespace code points recommended for use in computer languages will not
change.

**[UAX31-R3](#R3)**. **Pattern\_White\_Space
and Pattern\_Syntax Characters:** *To meet this requirement, an
implementation shall
meet both [UAX31-R3a](#R3a) and [UAX31-R3b](#R3b).*

> **Note:** When meeting requirement [UAX31-R3](#R3) with no profile, all characters except
> those that have the Pattern\_White\_Space or Pattern\_Syntax properties
> are available for use in the definition of identifiers or literals.

### 4.1 [Whitespace](#Whitespace)

Many computer languages treat two categories of whitespace differently: horizontal space (such as the ASCII horizontal tabulation and space), and line terminators.

When a syntax supports non-ASCII characters, it is useful to consider a third category: *ignorable format controls*. Ignorable format controls may be inserted between lexical elements in order to resolve bidirectional ordering issues, as described in *Section 4.1.1, [Bidirectional Ordering](#Bidirectional_Ordering)*. The insertion of these characters does not change the meaning of the program; in particular, they are not spacing characters. See *Section 4.1.2, [Required Spaces](#Required_Spaces)*.

> **Note:** Allowing for the insertion of ignorable format controls does not prevent spoofing based on bidirectional reordering.
> In order to guard against such spoofing, implementations should make use of the higher-level protocols and conversion to plain text described in Unicode Standard Annex #9, “Unicode Bidirectional Algorithm” [[UAX9](../tr41/tr41-34.html#UAX9)]. See Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

> **Note:** Since these characters are allowed only where a boundary would, in their absence, exist between lexical elements, an implementation could ignore them when lexing, and then consider as illegal any lexical element that contains them. An exception must be made for comments and strings, which should be able to freely contain these characters.

Implementations should also allow these characters in other contexts where reordering issues could arise. See Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

**[UAX31-R3a](#R3a)**. **Pattern\_White\_Space Characters:** *To meet this requirement, an
implementation shall
choose either [UAX31-R3a-1](#R3a-1) or [UAX31-R3a-2](#R3a-2).*

**[UAX31-R3a-1](#R3a-1)**.
*Use Pattern\_White\_Space characters as the set of characters interpreted as whitespace in parsing, as follows:*

1. *A sequence of one or more of any of the following characters shall be interpreted as a sequence of one or more end of line:*
   1. U+000A (line feed)
   2. U+000B (vertical tabulation)
   3. U+000C (form feed)
   4. U+000D (carriage return)
   5. U+0085 (next line)
   6. U+2028 LINE SEPARATOR
   7. U+2029 PARAGRAPH SEPARATOR
2. *The Pattern\_White\_Space characters with the property Default\_Ignorable\_Code\_Point shall be treated as ignorable format controls; they shall be allowed in the contexts [UAX31-I1](#I1), [UAX31-I2](#I2), and [UAX31-I3](#I3) defined in *Section 4.1.3, [Contexts for Ignorable Format Controls](#Contexts_for_Ignorable_Format_Controls)*, where their insertion shall have no effect on the meaning of the program.*
3. *All other characters in Pattern\_White\_Space shall be interpreted as horizontal space.*

**[UAX31-R3a-2](#R3a-2)**.
*Declare that it uses a **profile**
of [UAX31-R3a-1](#R3a-1)
and define that profile with a precise specification of the
characters that are added to or removed from the set of code points
defined by the Pattern\_White\_Space property, and of any changes to the criteria under which a character or sequence of characters is interpreted as an end of line, as ignorable format controls, or as horizontal space.*

> **Note:** The characters to be treated as ignorable format controls under item 2 of [UAX31-R3a-1](#R3a-1) are U+200E LEFT-TO-RIGHT MARK and U+200F RIGHT-TO-LEFT MARK. The characters to be treated as horizontal space under item 3 of [UAX31-R3a-1](#R3a-1) are U+0020 SPACE and U+0009 (horizontal tabulation, TAB).

> **Note:** The characters LEFT-TO-RIGHT MARK and RIGHT-TO-LEFT MARK are two of the Implicit Directional Marks defined by *Section 2.6, Implicit Directional Marks*, in Unicode Standard Annex #9, “Unicode Bidirectional Algorithm” [[UAX9](../tr41/tr41-34.html#UAX9)]. The third one, ARABIC LETTER MARK, is used far less frequently than the others, even in Arabic text; its behavior differs subtly from RIGHT-TO-LEFT MARK in ways that are not usually relevant to the ordering of source code. If it is added to the set of whitespace characters by a profile, it is interpreted as an ignorable format control.

> **Note:** Failing to interpret all characters listed in item 1 of [UAX31-R3a-1](#R3a-1) as line terminators would lead to spoofing issues; see Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

#### 4.1.1 [Bidirectional Ordering](#Bidirectional_Ordering)

Requirement [UAX31-R3a](#R3a) is relevant even for languages that do not
use immutable identifiers, or that have lexical structure outside of the
categories of syntax and whitespace characters. In particular, the set of
Pattern\_White\_Space characters is chosen to make it possible to correct
bidirectional ordering issues that can arise in a wide range of programming
languages, visually obfuscating the logic of expressions.
In the absence of higher-level protocols (see Section 4.3,
*Higher-Level Protocols*, in
[[UAX9](../tr41/tr41-34.html#UAX9)]), tokens may be visually
reordered by the Unicode Bidi Algorithm in bidirectional source text,
producing a visual result that conveys a different logical intent.
To remedy that, two implicit directional marks are among Pattern\_White\_Space
characters; if these can be freely inserted between tokens, implicit
directional marks *consistent with the paragraph direction* can be used to
ensure that the visual order of tokens matches their logical order.

> **Example:** Consider the following two lines:
>
> > (1) `x + tav == 1`
>
> > (2) `x + תו == 1`
>
> Internally, they are the same except that the ASCII identifier `tav` in line (1) is replaced by the Hebrew
> identifier `תו` in line (2). However, with a plain text display (with left-to-right paragraph direction) the user
> will be misled, thinking that line (2) is a comparison between `(x + 1)` and `תו`, whereas it is actually a
> comparison between `(x + תו)` and `1`.
> The misleading rendering of (2) occurs because the directionality of the identifier תו
> influences subsequent weakly-directional tokens; inserting a left-to-right
> mark after the identifier `תו` stops it from influencing the remainder of the
> line, and thus yields a better rendering in plain text with left-to-right
> paragraph direction, as demonstrated in the following table, wherein characters
> whose ordering is affected by that identifier have been highlighted.
>
> | Underlying Representation | | | | | | | | | | | | Display (LTR paragraph direction) |
> | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
> | `x` |  | `+` |  | `ת` | `ו` |  | | `=` | `=` |  | `1` | `x + תו == 1` |
> | `x` |  | `+` |  | `ת` | `ו` | ⟨LRM⟩ |  | `=` | `=` |  | `1` | `x + תו‎ == 1` |
>
> *Section 5.2, Conversion to Plain Text*, in Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)],
> specifies an algorithm for the automatic insertion of LRM characters.

> **Note:** Left-to-right marks are used for this purpose when the main
> direction is left–to-right. Correspondingly, right-to-left marks are used
> when the main direction is right-to-left.

#### 4.1.2 [Required Spaces](#Required_Spaces)

Since the implicit directional marks are nonspacing, where a syntax requires
a sequence of spaces (such as between identifiers), it should require that at
least one of those be neither LEFT-TO-RIGHT MARK nor RIGHT-TO-LEFT MARK. The
visual appearance would otherwise be too confusing to readers: “`else`⟨LRM⟩`if`”
would be seen by the user as “`elseif`” but parsed by the compiler as “`else if`”,
whereas “`else`⟨LRM⟩ `if`” would be seen and parsed as “`else if`” and be harmless.

#### 4.1.3 [Contexts for Ignorable Format Controls](#Contexts_for_Ignorable_Format_Controls)

Implementations should at least allow for the insertion of ignorable format controls in the following contexts, illustrated by examples wherein the ignorable format control is represented by ⟨LRM⟩.

**[UAX31-I1](#I1)**. Adjacent to lexical horizontal space (within a sequence of lexical horizontal spaces, or at the start or end of such a sequence).

> **Example:** Between the following keywords separated by a space:
>
> `else` ⟨LRM⟩`if`

> **Note:** The phrase “lexical horizontal space” refers to characters that are not merely in the set of horizontal space characters, but are also in a context where they are lexically spaces. For instance, it does not include horizontal space characters in string literals. Implementations should permit these characters in string literals, but in such a literal, their insertion has an effect on the meaning of the program, as they are then present in the string represented by that literal.

**[UAX31-I2](#I2)**. As optional space, that is, wherever horizontal space could be inserted without changing the meaning of the program.

> **Example:** Before the plus sign in the following arithmetic expression:
>
> `x`⟨LRM⟩`+1`

**[UAX31-I3](#I3)**. At the start and end of a lexical line.
> **Example:** Before the word import in the following line of Python:
>
> ⟨LRM⟩`import unicodedata`

> **Note:** As is the case for [UAX31-I1](#I1), the start and end of a “lexical line” in [UAX31-I3](#I3) does not include the start and end of a line in a multiline string literal, respectively. This context is distinct from [UAX31-I2](#I2) in languages where leading or trailing spaces are meaningful.

### 4.2 [Syntax](#Syntax)

The lexical structure of formal languages involves characters that are not allowed in identifiers and are not whitespace, but that have some special lexical significance other than being literal characters (such as in string literals) or ignored (such as in comments). These are referred to in this document as *characters with syntactic use*.

Examples of characters with syntactic use include:

* decimal marks in numeric literals
* arithmetic operators, such as `+`, `-`, `*`, `/`
* parentheses and other brackets
* characters in comment delimiters, such as `#`, `/*`, `--`, or `⍝`
* quotation marks delimiting strings
* characters such as `\` introducing escape sequences

It is useful to bound the set of characters with syntactic use.
This makes it possible to build tools that handle source code, but do not validate it, such as
syntax highlighters, in a forward-compatible way; see Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].
It further provides a stable set of characters that can be used for user-defined operators.
In addition, this allows for backward compatibility of literals (including patterns), as described in *Section 4.3, [Pattern Syntax](#Pattern_Syntax)*.

**[UAX31-R3b](#R3b)**. **Pattern\_Syntax Characters:** *To meet this requirement, an
implementation shall
choose either [UAX31-R3b-1](#R3b-1) or [UAX31-R3b-2](#R3b-2).*

**[UAX31-R3b-1](#R3b-1)**.
*Use Pattern\_Syntax characters as the set of characters
with syntactic use. The following sets shall be disjoint:*

1. characters allowed in identifiers
2. characters treated as whitespace
3. characters with syntactic use

**[UAX31-R3b-2](#R3b-2)**.
*Declare that it uses a **profile**
of [UAX31-R3b-1](#R3b-1)
and define that profile with a precise specification of the
characters that are added to or removed from the set of code points
defined by the Pattern\_Syntax property.*

> **Note:** When meeting requirement [UAX31-R3b](#R3b), characters allowed in identifiers may be given special significance in the syntax even when they are not part of identifiers.
>
> For instance, in a language which uses the C syntax for hexadecimal literals and meets requirement [UAX31-R1](#R1), the literal `0xDEADBEEF` consists entirely of identifier characters, yet the `0x` has special significance in the syntax, and the characters after that prefix are subject to special restrictions (only 0 through 9 and A through F are allowed).
>
> However, characters outside of those allowed in identifiers, those treated as whitespace, and the set [:Pattern\_Syntax:] cannot be given special significance in the syntax. For instance, if a language meets requirements [UAX31-R1](#R1) and [UAX31-R3](#R3) with no profile and allows for user-defined operators, that language cannot allow the user to define an operator 🐈.
>
> Characters outside of those allowed in identifiers, those treated as whitespace, and those with syntactic use can still be allowed in a program, for instance, as part of string literals or comments.

#### 4.2.1 [User-Defined Operators](#User-Defined_Operators)

Some programming languages allow for user-defined operators. When meeting requirement [UAX31-R3b](#R3b), the set of characters that can be allowed in operators is limited; however, that leaves open the exact definition of operators. In order to avoid ambiguities in lexical analysis, operators should not be allowed to contain characters that may be found at the beginning of an identifier or literal; for instance, `+1` or `−x` should not be operators.

The following definition avoids such interactions with default identifiers and with numbers.

**[UAX31-R3c](#R3c)**. **Operator Identifiers:** *To meet this requirement, an implementation shall meet requirement [UAX31-R3b](#R3b) Pattern\_Syntax Characters, and, to determine whether a string is an operator, it shall choose either UAX31-R3c-1 or UAX31-R3c-2.*

**[UAX31-R3c-1](#R3c-1)**. *Use definition [UAX31-D1](#D1), setting Start to be the set of characters with syntactic use, setting Continue to be the union of the set of characters with syntactic use and the set of characters with General\_Category Mn, and leaving Medial empty.*

**[UAX31-R3c-2](#R3c-2)**. *Declare that it uses a profile of [UAX31-R3c-1](#R3c-1) and define that profile with a precise specification of the characters and character sequences that are added to or removed from Start, Continue, and Medial and/or provide a list of additional constraints on operators.*

> **Note:** The set of Pattern\_Syntax characters, which is the default for characters with syntactic use, contains some emoji. Implementations may wish to remove them, either to allow for their use in identifiers, or to reduce potential confusion arising from ⚽ being an operator but 🏉 not being one. This may be done using the standard profile for [UAX31-R3b](#R3b) Pattern\_Syntax Characters defined in *Section 7.2, [Emoji Profile](#Emoji_Profile)*.
>
> Nonspacing marks are included in Continue because they are part of the representation for many operators, such as some of the negated operators.
>
> Unassigned code points are not characters; they are therefore excluded by this definition.

When meeting this requirement, a profile is likely to be needed depending on the specifics of the syntax. For instance, a programming language wherein string literals start with " should remove that character from the characters allowed in operators.

### 4.3 [Pattern Syntax](#Pattern_Syntax)

With a fixed set of whitespace and syntax code points, a
pattern language can have a policy requiring all possible syntax
characters (even ones currently unused) to be quoted if they are
literals. Using this policy preserves the freedom to extend the
syntax in the future by using those characters. Past patterns on
future systems will always work; future patterns on past systems will
signal an error instead of silently producing the wrong results.
Consider the following scenario, for example.

> In version 1.0 of program X, '≈' is a reserved syntax
> character; that is, it does not perform an operation, and it needs
> to be quoted. In this example, '\' *quotes* the next
> character; that is, it causes it to be treated as a literal instead
> of a syntax character. In version 2.0 of program X, '≈' is
> given a real meaning—for example, “uppercase the subsequent
> characters”.
>
> * The pattern abc...\≈...xyz works on both versions 1.0 and
>   2.0, and refers to the literal character because it is quoted in
>   both cases.
> * The pattern abc...≈...xyz works on version 2.0 and
>   uppercases the following characters. On version 1.0, the engine
>   (rightfully) has no idea what to do with ≈. Rather than silently
>   fail (by ignoring ≈ or turning it into a literal), it has the
>   opportunity to signal an error.

When *generating* rules or patterns, all whitespace and syntax
code points that are to be literals require quoting, using whatever
quoting mechanism is available. For readability, it is recommended
practice to quote or escape all literal whitespace and default-ignorable code points as well.

> Consider the following example, where the items in angle
> brackets indicate literal characters:
>
> > a<SPACE>b → x<ZERO WIDTH SPACE>y  +
> > z;
>
> Because <SPACE> is a Pattern\_White\_Space character, it
> requires quoting. Because <ZERO WIDTH SPACE> is a default-ignorable character, it should also be quoted for readability. So in
> this example, if \uXXXX is used for a code point literal, but is
> resolved before quoting, and if single quotes are used for quoting,
> this example might be expressed as:
>
> > 'a\u0020b' → 'x\u200By' + z;

## 5 [Normalization and Case](#normalization_and_case)

This section discusses issues that must be taken into account
when considering normalization and case folding of identifiers in
programming languages or scripting languages. Using normalization
avoids many problems where apparently identical identifiers are not
treated equivalently. Such problems can appear both during
compilation and during linking—in particular across different
programming languages. To avoid such problems, programming languages
can normalize identifiers before storing or comparing them. Generally
if the programming language has case-sensitive identifiers, then
Normalization Form C is appropriate; whereas, if the programming
language has case-insensitive identifiers, then Normalization Form KC
is more appropriate.

Implementations that take normalization and case into account
have two choices: to treat variants as equivalent, or to disallow
variants.

**[UAX31-R4](#R4)**. **Equivalent
Normalized Identifiers:** *To meet this requirement, an implementation
shall specify the Normalization Form and shall provide a precise
specification of the characters that are excluded from
normalization, if any. If the Normalization Form is NFKC, the
implementation shall apply the modifications in Section 5.1, [NFKC Modifications](#NFKC_Modifications), given by the
properties XID\_Start and XID\_Continue. Except for identifiers
containing excluded characters, any two identifiers that have the
same Normalization Form shall be treated as equivalent by the
implementation.*

**[UAX31-R5](#R5)**. **Equivalent
Case-Insensitive Identifiers:** *To meet this requirement, an
implementation shall specify either simple or full case folding, and
adhere to the Unicode specification for that folding. Any two
identifiers that have the same case-folded form shall be treated as
equivalent by the implementation.*

**[UAX31-R6](#R6)**. **Filtered
Normalized Identifiers:** *To meet this requirement, an implementation
shall specify the Normalization Form and shall provide a precise
specification of the characters that are excluded from
normalization, if any. If the Normalization Form is NFKC, the
implementation shall apply the modifications in Section 5.1, [NFKC Modifications](#NFKC_Modifications), given by the
properties XID\_Start and XID\_Continue. Except for identifiers
containing excluded characters, allowed identifiers must be in the
specified Normalization Form.*

> **Note:** For requirement UAX31-R6, filtering involves disallowing any
> characters in the set \p{NFKC\_QuickCheck=No}, or equivalently,
> disallowing \P{isNFKC}.

**[UAX31-R7](#R7)**. **Filtered
Case-Insensitive Identifiers:** *To meet this requirement, an
implementation shall specify either simple or full case folding, and
adhere to the Unicode specification for that folding. Except for
identifiers containing excluded characters, allowed identifiers must
be in the specified case folded form.*

> **Note:** For requirement UAX31-R7 with full case folding, filtering
> involves disallowing any characters in the set `\p{Changes_When_Casefolded}`.

As of Unicode 5.2, an additional string transform is available for
use in matching identifiers:
`toNFKC_Casefold(S)`.
See **R5** in *Section 3.13, Default Case Algorithms* in
[[Unicode](../tr41/tr41-34.html#Unicode)]. That operation
case folds and normalizes a string, and also removes default-ignorable code points.
It can be used to support an implementation of [UAX31-R4](#R4) and [UAX31-R5](#R5)
*Equivalent Case and Compatibility-Insensitive Identifiers*.
In order to implement requirement [UAX31-R4](#R4), canonical
decomposition must be applied prior to the toNFKC\_Casefold operation.
The resulting equivalence relation between identifiers is an *identifier caseless match*,
see definition D147 of [[Unicode](../tr41/tr41-34.html#Unicode)].
There is a corresponding boolean property,
Changes\_When\_NFKC\_Casefolded, which can be used to support an
implementation of *Filtered Case and Compatibility-Insensitive
Identifiers*. The NFKC\_Casefold character mapping property and the
Changes\_When\_NFKC\_Casefolded property are described in Unicode
Standard Annex #44, "Unicode Character Database" [[UAX44](../tr41/tr41-34.html#UAX44)].

> **Note:** In mathematically oriented programming languages that
> make distinctive use of the Mathematical Alphanumeric Symbols, such
> as U+1D400 MATHEMATICAL BOLD CAPITAL A, an application of NFKC must
> filter characters to exclude characters with the property value
> Decomposition\_Type=Font.

### 5.1 [NFKC Modifications](#NFKC_Modifications)

Where programming languages are using NFKC to fold differences
between characters, they need the following modifications of the
identifier syntax from the Unicode Standard to deal with the
idiosyncrasies of a small number of characters. These modifications
are reflected in the XID\_Start and XID\_Continue properties.

#### 5.1.1 [Modifications for Characters that Behave Like Combining Marks](#Combining_Mark_Mods)

Certain characters are not formally combining characters,
although they behave in most respects as if they were. In most cases,
the mismatch does not cause a problem, but when these characters have
compatibility decompositions, they can cause identifiers not to be
closed under Normalization Form KC. In particular, the following four
characters are included in XID\_Continue and not XID\_Start:

* U+0E33 THAI CHARACTER SARA AM
* U+0EB3 LAO VOWEL SIGN AM
* U+FF9E HALFWIDTH KATAKANA VOICED SOUND MARK
* U+FF9F HALFWIDTH KATAKANA SEMI-VOICED SOUND MARK

#### 5.1.2 [Modifications for Irregularly Decomposing Characters](#Irreg_Decomp_Mods)

U+037A GREEK YPOGEGRAMMENI and certain Arabic presentation
forms have irregular compatibility decompositions and are excluded
from both XID\_Start and XID\_Continue. It is recommended that all
Arabic presentation forms be excluded from identifiers in any event,
although only a few of them must be excluded for normalization to
guarantee identifier closure.

#### 5.1.3 [Identifier Closure Under Normalization](#Identifier_Closure)

With these amendments to the identifier syntax, all identifiers are
closed under all four Normalization Forms. This means that for any
string S, the implications shown in *Figure 5* hold.

Figure 5. [Normalization Closure](#Figure_Normalization_Closure)

| `isIdentifier(S)` → | `isIdentifier(toNFD(S)) isIdentifier(toNFC(S)) isIdentifier(toNFKD(S)) isIdentifier(toNFKC(S))` |
| --- | --- |

Identifiers are also closed under case operations. For any string S
(with exceptions involving a single character), the implications
shown in *Figure 6* hold.

Figure 6. [Case Closure](#Figure_Case_Closure)

| `isIdentifier(S)` → | `isIdentifier(toLowercase(S)) isIdentifier(toUppercase(S)) isIdentifier(toFoldedcase(S))` |
| --- | --- |

The one exception for casing is U+0345 COMBINING GREEK
YPOGEGRAMMENI. In the very unusual case that U+0345 is at the start
of S, U+0345 is not in XID\_Start, but its uppercase and case-folded
versions are. In practice, this is not a problem because of the way
normalization is used with identifiers.

The reverse implication is true for canonical equivalence but *not*
true in the case of compatibility equivalence:

Figure 7. [Reverse
Normalization Closure](#Figure_Reverse_Normalization_Closure)

| `isIdentifier(toNFD(S)) isIdentifier(toNFC(S))` | → `isIdentifier(S)` |
| --- | --- |
| `isIdentifier(toNFKD(S)) isIdentifier(toNFKC(S))` | ↛ `isIdentifier(S)` |

There are many characters for which the reverse implication is not
true for compatibility equivalence, because there are many characters
counting as symbols or non-decimal numbers—and thus outside of
identifiers—whose compatibility equivalents are letters or decimal
numbers and thus in identifiers. Some examples are shown in *[Table
8](#Figure_Compatibility_Equivalents_to_Letters_or_Decimal_Numbers)*.

Table 8. [Compatibility Equivalents to Letters or Decimal Numbers](#Figure_Compatibility_Equivalents_to_Letters_or_Decimal_Numbers)

| Code Points | GC | Samples | Names |
| --- | --- | --- | --- |
| 2070 | No | ⁰ | SUPERSCRIPT ZERO |
| 20A8 | Sc | ₨ | RUPEE SIGN |
| 2116 | So | № | NUMERO SIGN |
| 2120..2122 | So | ℠..™ | SERVICE MARK..TRADE MARK SIGN |
| 2460..2473 | No | ①..⑳ | CIRCLED DIGIT ONE..CIRCLED NUMBER TWENTY |
| 3300..33A6 | So | ㌀..㎦ | SQUARE APAATO..SQUARE KM CUBED |

If an implementation needs to ensure both directions for
compatibility equivalence of identifiers, then the identifier
definition needs to be tailored to add these characters.

For canonical equivalence the implication is true in both directions.
`isIdentifier(toNFC(S))`
if and only if
`isIdentifier(S)`.

There were two exceptions before Unicode 5.1, as shown in [*Table
9*](#Figure_Canonical_Equivalence_Exceptions_Prior_to_Unicode_5.1). If an implementation needs to ensure full canonical equivalence
of identifiers, then the identifier definition must be tailored so
that these characters have the same value, so that either both
isIdentifier(S) and isIdentifier(toNFC(S)) are true, or so that both
values are false.

Table 9. [Canonical Equivalence Exceptions Prior to Unicode 5.1](#Figure_Canonical_Equivalence_Exceptions_Prior_to_Unicode_5.1)

| isIdentifier(toNFC(S))=True | isIdentifier(S)=False | Different in |
| --- | --- | --- |
| 02B9 ( ʹ ) MODIFIER LETTER PRIME | 0374 ( ʹ ) GREEK NUMERAL SIGN | XID and ID |
| 00B7 ( · ) MIDDLE DOT | 0387 ( · ) GREEK ANO TELEIA | XID alone |

Those programming languages with case-insensitive identifiers should
use the case foldings described in *Section 3.13, Default Case
Algorithms*, of [[Unicode](../tr41/tr41-34.html#Unicode)]
to produce a case-insensitive normalized form.

When source text is parsed for identifiers, the folding of
distinctions (using case mapping or NFKC) must be delayed until after
parsing has located the identifiers. Thus such folding of
distinctions should not be applied to string literals or to comments
in program source text.

The Unicode Standard supports case folding with normalization, with
the function toNFKC\_Casefold(X). See definition R5 in *Section
3.13, Default Case Algorithms* in [[Unicode](../tr41/tr41-34.html#Unicode)] for the
specification of this function and further explanation of its use.

### 5.2 [Case and Stability](#Case_and_Stability)

The alphabetic case of the initial character of an identifier
is used as a mechanism to distinguish syntactic classes in some
languages like Prolog, Erlang, Haskell, Clean, and Go. For example,
in Prolog and Erlang, variables must begin with capital letters (or
underscores) and atoms must not. There are some complications in the
use of this mechanism.

For such a casing distinction in a programming language to work
with unicameral writing systems (such as Kanji or Devanagari),
another mechanism (such as underscores) needs to substitute for the
casing distinction.

Casing stability is also an issue for bicameral writing systems. The
assignment of General\_Category property values, such as gc=Lu, is not
guaranteed to be stable, nor is the assignment of characters to the
broader properties such as Uppercase. So these property values cannot
be used by themselves, without incorporating a
mechanism that preserves backward compatibility,
such as is done for Unicode identifiers in *Section
2.5 [Backward Compatibility](#Backward_Compatibility)*.
That is, the implementation would maintain its own list of special
inclusions and exclusions that require updating for each new version
of Unicode.

Alternatively, a programming language specification can use the
operation specified in [Case
Folding Stability](https://www.unicode.org/policies/stability_policy.html#Case_Folding) as the basis for its casing distinction. That
operation *is* guaranteed to be stable. That is, one can use a
casing distinction such as the following:

1. S is a **variable** if S begins with an
   underscore.
2. Otherwise, produce S' = toCasefold(toNFKC(S))
   1. S is a **variable** if firstCodePoint(S) ≠
      firstCodePoint(S'),
   2. otherwise S is an **atom**.

This test can clearly be optimized ​for the normal cases, such
as initial ASCII. It is also recommended that identifiers be in NFKC
format, which makes the detection even simpler.

#### 5.2.1 [Edge Cases for Folding](#Edge_Cases_for_Folding)

In Unicode 8.0, the Cherokee script letters have been changed
from gc=Lo to gc=Lu, and corresponding lowercase letters (gc=Ll) have
been added. This is an unusual pattern; typically when case pairs are
added, existing letters are changed from gc=Lo to gc=Ll, and new
corresponding uppercase letters (gc=Lu) are added. In the case of
Cherokee, it was felt that this solution provided the most
compatibility for existing implementations in terms of font
treatment.

The downside of this approach is that the Cherokee characters,
when case-folded, will convert as necessary to the pre-8.0
characters, namely to the uppercase versions. This folding is unlike
that of any other case-mapped characters in Unicode. Thus the
case-folded version of a Cherokee string will contain uppercase
letters instead of lowercase letters. Compatibility with fonts for
the current user community was felt to be more important than the
confusion introduced by this edge case of case folding, because
Cherokee programmatic identifiers would be rare.

The upshot is that when it comes to identifiers,
implementations should never use the General\_Category or Lowercase or
Uppercase properties to test for casing conditions, nor use
toUppercase(), toLowercase(), or toTitlecase() to fold or test
identifiers. Instead, they should instead use Case\_Folding or
NFKC\_CaseFold.

## 6 [Hashtag Identifiers](#hashtag_identifiers)

Hashtag identifiers have become very popular in
social media. They consist of a number sign in front of some string
of characters, such as #emoji. The actual composition of allowable
Unicode hashtag identifiers varies between vendors. It has also
become common for hashtags to include emoji characters, without a
clear notion of exactly which characters are included.

This section presents a syntax that can be used
for parsing Unicode hashtag identifiers for increased interoperability.

**[UAX31-D2](#D2)**. **Default
Hashtag Identifier Syntax:**

> `<Hashtag-Identifier> := <Start> <Continue>*
> (<Medial> <Continue>+)*`

When parsing hashtags in flowing text, it is
recommended that an extended Hashtag only be recognized when there
is no Continue character before a Start character. For example, in
“abc#def” there would be no hashtag, while there would be in “abc
#def” or “abc.#def”.

**[UAX31-R8](#R8)**. **Extended
Hashtag Identifiers:** *To meet this requirement, to determine whether
a string is a hashtag identifier an implementation shall
choose either [UAX31-R8-1](#R8-1) or [UAX31-R8-2](#R8-2).*

**[UAX31-R8-1](#R8-1)**.
*Use definition [UAX31-D2](#D2), setting:*

1. Start := [#﹟＃]
   * U+0023 NUMBER SIGN
   * U+FE5F SMALL NUMBER SIGN
   * U+FF03 FULLWIDTH NUMBER SIGN
   * (These are # and its compatibility equivalents.)
2. Medial is currently empty, but can be used for customization.
3. Continue := XID\_Continue, plus Extended\_Pictographic, Emoji\_Component, and “\_”, “-”, “+”, minus Start characters.
   * Note the subtraction of # characters.
   * This is expressed in UnicodeSet notation as:

     [\p{XID\_Continue}\p{Extended\_Pictographic}\p{Emoji\_Component}[-+\_]-[#﹟＃]]

**[UAX31-R8-2](#R8-2)**.
*Declare that
it uses a **profile** of [UAX31-R8-1](#R8-1) as in **[UAX31-R1](#R1)**.*

The emoji properties are from the corresponding version of [[UTS51](../tr41/tr41-34.html#UTS51)]. The version of the emoji properties is tied to the version of the Unicode Standard, starting with Version 11.0.

The techniques mentioned in Section 2.5 [Backward Compatibility](#Backward_Compatibility) may be
used where stability between successive versions is required.

Comparison and matching should be done after converting to NFKC\_CF format. Thus #MötleyCrüe should match #MÖTLEYCRÜE and other variants.

Implementations may choose to add characters in *Table 3a, [Optional Characters for Medial](#Table_Optional_Medial)* to **Medial** and *Table 3b, [Optional Characters for Continue](#Table_Optional_Continue)* to **Continue** for better identifiers for natural languages.

## 7 [Standard Profiles](#Standard_Profiles)

Two standard profiles for default identifiers are provided to cater to common patterns of use observed in programming languages with less restrictive identifier syntaxes, including those that use UAX31-R2 default identifiers: the inclusion of characters suitable for mathematical usage in identifiers, and the inclusion of emoji in identifiers.

These profiles are associated with profiles for requirements [UAX31-R3b](#R3b).

Further, a standard profile is provided to exclude default-ignorable code points from identifiers. Having no visible effect in most contexts, these characters can lead to spoofing issues; see *Section 2.3, [Layout and Format Control Characters](#Layout_and_Format_Control_Characters)*.

For guidance on the applicability of these profiles to programming languages, see Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

### 7.1 [Mathematical Compatibility Notation Profile](#Mathematical_Compatibility_Notation_Profile)

The Mathematical Compatibility Notation Profile for default identifiers consists of the addition of the set [:ID\_Compat\_Math\_Start:] to the set *Start*, and the set [:ID\_Compat\_Math\_Continue:] to the set *Continue*, in definition [UAX31-D1](#D1).

> **Note:** The set [:ID\_Compat\_Math\_Start:] comprises ∂, ∇, and their mathematical style variants, as well as ∞.
> The set [:ID\_Compat\_Math\_Continue:] comprises [:ID\_Compat\_Math\_Start:], as well as subscript and superscript digits and signs with mathematical use.

It is associated with a profile for [UAX31-R3b](#R3b), which consists of removing the characters in [[:Pattern\_Syntax:] - [:ID\_Compat\_Math\_Continue:]] from the set of characters with syntactic use (these are the characters ∂, ∇, and ∞).

> **Note:** While *supporting* these characters is recommended for some computer languages because they can be beneficial in some applications, these characters, like many others characters that are allowed in default identifiers, are discouraged in general use, as they are confusing to most readers. See Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

### 7.2 [Emoji Profile](#Emoji_Profile)

The Emoji Profile for default identifiers provides for the inclusion of emoji characters and sequences in identifiers. A large subset of emoji are already supported in some programming languages, but this profile provides a mechanism for treating them consistently as part of the lexical structure of a language.

The Emoji Profile for default identifiers consists of:

1. The addition of the RGI emoji set defined by ED-27 in Unicode Technical Standard #51, “Unicode Emoji” [[UTS51](../tr41/tr41-34.html#UTS51)] for a given version of Unicode to the sets *Start* and *Continue* in definition [UAX31-D1](#D1).
2. The removal of the code point U+FE0E VARIATION SELECTOR-15 (the Text Presentation Selector) from the set *Continue*.

> **Note:** The Emoji Profile requires the use of character sequences, rather than individual code points, in the sets *Start* and *Continue* defined by [UAX31-D1](#D1). When using this profile, U+002A asterisk (\*), U+203C double exclamation mark (‼), or U+263A white smiling face (☺) are not legal identifiers, but the sequences (U+002A, U+FE0F, U+20E3) \*️⃣, (U+203C, U+FE0F) ‼️, and (U+263A, U+FE0F) ☺️ are allowed in identifiers. This would require some changes to lexers: when they hit a character that starts an emoji sequence they will (logically) switch to a different mechanism for parsing.

The Emoji Profile includes characters that are in Pattern\_Syntax; it is therefore associated with a profile for [UAX31-R3b](#R3b), which consists of replacing each emoji character of a certain subset of [:Pattern\_Syntax:] by its ***text presentation sequence*** (ED-8a):

1. Remove the characters in the set [[:Pattern\_Syntax:]&[:Emoji\_Presentation:]] from the set of characters with syntactic use.
2. For all C in [[:Pattern\_Syntax:]&[:Emoji\_Presentation:]], add the sequence consisting of C followed by U+FE0E VARIATION SELECTOR-15 (the Text Presentation Selector) to the set of characters with syntactic use.

In addition, in order to avoid lexical ambiguities between identifiers and operators, the Emoji Profile includes a profile for [UAX31-R3c](#R3c), which consists of the removal of the character U+FE0F VARIATION SELECTOR-16 (the Emoji Presentation Selector) from the set *Continue*.

> **Example:** Consider a language that meets requirements [UAX31-R3b](#R3b) and [UAX31-R3c](#R3b) with no profile. U+2615 HOT BEVERAGE (☕) is a character with syntactic use, and therefore it is an operator. When meeting these requirements with the Emoji Profile, U+2615 HOT BEVERAGE (☕) is not a character with syntactic use (which allows it to be an identifier character) and ☕ is not a valid operator. However, the sequence U+2615 U+FE0F (☕︎) is added to the set of characters with syntactic use, and therefore ☕︎ is a valid operator.

This change means that if some of the Pattern\_Syntax characters with the Emoji\_Presentation property were in syntactic use (e.g., in operators) prior to adopting the Emoji Profile, they become identifiers once the profile is adopted, but can be turned back into operators by adding U+FE0E VARIATION SELECTOR-15, allowing for a migration path.

Of course, if a programming language only uses a subset of the Pattern\_Syntax characters that does not include these characters, no action needs to be taken.

Some other characters in Pattern\_Syntax (such as ↔) are used in emoji (such as ↔️), but they are not emoji on their own, so that they do not need to be removed from the set of characters with syntactic use as long as lexical analysis properly takes sequences into account.

The emoji sequences require 98 default-ignorable characters:

* U+200D ZERO WIDTH JOINER (also known as ZWJ)
* U+FE0F VARIATION SELECTOR-16 (also known as Emoji Presentation Selector)
* U+E0020..U+E007F 96 TAG characters

Thus, if this profile is combined with any profile that removes default-ignorable characters, such as the Default-Ignorable Exclusion Profile, those characters need to be retained in the context of emoji sequences.

Consider the following examples, in a language that meets requirement [UAX31-R1](#R1) with both the Emoji Profile and the Default Ignorable Exclusion Profile:

| Sequence | Appearance | Legal Identifier? | Reason |
| --- | --- | --- | --- |
| A+ZWJ+B | A‍B | No | ZWJ is not part of an emoji sequence |
| U+1F408 + ZWJ + U+2B1B | 🐈‍⬛ | Yes | ZWJ is part of an emoji sequence (for *black cat*) |
| BIG + U+1F408 + ZWJ + U+2B1B | BIG🐈‍⬛ | Yes |

### 7.3 [Default-Ignorable Exclusion Profile](#Default_Ignorable_Exclusion_Profile)

The default-ignorable exclusion profile for default identifiers consists of the exclusion of the code points with property Default\_Ignorable\_Code\_Point from the sets *Start* and *Continue* in definition [UAX31-D1](#D1).

> **Note:** While it reduces the attack surface, excluding default-ignorable code points does not prevent spoofing issues. More comprehensive mechanisms are described in Unicode Technical Standard #39, “Unicode Security Mechanisms” [[UTS39](../tr41/tr41-34.html#UTS39)]; in particular, the exclusion of default-ignorable code points is part of the General for Profile for Identifiers.

> **Note:** Where higher level diagnostics are available, such as in programming environments, more targeted measures can be taken in order to still allow for the legitimate use of these characters. See Unicode Technical Standard #55, “Unicode Source Code Handling” [[UTS55](../tr41/tr41-34.html#UTS55)].

## [Acknowledgments](#Acknowledgments)

Mark Davis is the author of the initial version and has added
to and maintained the text of this annex. Robin Leroy has assisted in updating it starting with Version 15.0.

The attendees of the Source Code Working Group meetings assisted with the substantial changes made in Versions 15.0 and 15.1:
Peter Constable,
Elnar Dakeshov,
Mark Davis,
Barry Dorrans,
Steve Dower,
Michael Fanning,
Asmus Freytag,
Dante Gagne,
Rich Gillam,
Manish Goregaokar,
Tom Honermann,
Jan Lahoda,
Nathan Lawrence,
Robin Leroy,
Chris Ries,
Markus Scherer,
Richard Smith.

Thanks to Eric Muller, Asmus Freytag, Lisa Moore, Julie Allen, Jonathan Warden, Kenneth
Whistler, David Corbett, Klaus Hartke, Martin Dürst, Deborah Anderson, Steve Downey, Ned Holbrook, Corentin Jabot, 梁海 Liang Hai, Jens Maurer, and Hubert Tong for feedback on this annex.

## [References](#References)

For references for this annex, see Unicode Standard Annex #41, “[Common References for Unicode
Standard Annexes](../tr41/tr41-34.html).”

## [Migration](#Migration)

**Version 15.1**

Requirement [UAX31-R1a Restricted Format Characters](#R1a) has been withdrawn.

If implementations that claimed conformance to UAX31-R1a wish to retain the contextual checks for ZWJ and ZWNJ, they should refer to the General Security Profile in Unicode Technical Standard #39, “Unicode Security Mechanisms” [[UTS39](../tr41/tr41-34.html#UTS39)].

In previous versions, requirement [UAX31-R3 Pattern\_White\_Space and Pattern\_Syntax Characters](#R3) did not require any particular interpretation of whitespace characters. It now specifies which characters are to be treated as line terminators, horizontal space, and ignorable format controls. The meaning of syntactic use has also been clarified.

Implementations that claim conformance to UAX31-R3 should check that they interpret the characters in Pattern\_White\_Space as described in [UAX31-R3a Pattern\_White\_Space Characters](#R3a), and that their use of Pattern\_Syntax characters is consistent with [UAX31-R3b Pattern\_Syntax Characters](#R3b).

**Version 15.0**

In previous versions, the note explaining how to implement requirement [UAX31-R7 Filtered Case-Insensitive Identifiers](#R7) with full case folding referred to the wrong property, and the requirement itself incorrectly refered to Normalization Form rather than case folded form.

Implementations that claim conformance to UAX31-R7 should check that they use the correct property.

**Version 13.0**

Version 13.0 changed the structure of Table 4. [Excluded Scripts](#Table_Candidate_Characters_for_Exclusion_from_Identifiers) significantly, dropping conditions that were not based on script. Implementations that were based on Table 4 should refer to *UTS #39, Unicode Security Mechanisms* [[UTS39](../tr41/tr41-34.html#UTS39)] for additional restrictions.

**Version 11.0**

Version 11.0 refines the use of ZWJ in identifiers (adding some restrictions and relaxing others slightly), and broadens the definition of hashtag identifiers somewhat. For details, see the [Modifications](#Modifications).

**Version 9.0**

In previous versions, the text favored the use
of XID\_Start and XID\_Continue, as in the following paragraph. However, the formal definition used ID\_Start and ID\_Continue.

> The XID\_Start and XID\_Continue properties are improved lexical
> classes that incorporate the changes described in *Section
> 5.1, [NFKC Modifications](#NFKC_Modifications)*.
> They are recommended for most purposes, especially for security,
> over the original ID\_Start and ID\_Continue properties.

In version 9.0, that is swapped and the X versions are
stated explicitly in the formal definition. This affects just the
following characters.

> `037A ; GREEK YPOGEGRAMMENI
>  0E33 ; THAI CHARACTER SARA AM
>
> 0EB3 ; LAO VOWEL SIGN AM
>  309B ; KATAKANA-HIRAGANA VOICED
> SOUND MARK
>  309C ; KATAKANA-HIRAGANA SEMI-VOICED SOUND MARK
>
> FC5E..FC63 ; ARABIC LIGATURE SHADDA WITH SUPERSCRIPT ALEF ISOLATED
> FORM
>  FDFA ; ARABIC LIGATURE SALLALLAHOU ALAYHE WASALLAM
>
> FDFB ; ARABIC LIGATURE JALLAJALALOUHOU
>  FE70 ; ARABIC
> FATHATAN ISOLATED FORM
>  FE72 ; ARABIC DAMMATAN ISOLATED
> FORM
>  FE74 ; ARABIC KASRATAN ISOLATED FORM
>  FE76 ;
> ARABIC FATHA ISOLATED FORM
>  FE78 ; ARABIC DAMMA ISOLATED
> FORM
>  FE7A ; ARABIC KASRA ISOLATED FORM
>  FE7C ;
> ARABIC SHADDA ISOLATED FORM
>  FE7E ; ARABIC SUKUN ISOLATED
> FORM
>  FF9E ; HALFWIDTH KATAKANA VOICED SOUND MARK
>
> FF9F ; HALFWIDTH KATAKANA SEMI-VOICED SOUND MARK`

Implementations that wish to maintain
conformance to the older recommendation need only declare a profile
that uses ID\_Start and ID\_Continue instead of XID\_Start and XID\_Continue.

Version 9.0 splits the older Table 3 from Version 8.0 into 3
parts.

| Current Tables | Unicode 8.0 |
| --- | --- |
| *Table 3, [Optional Characters for Start](#Table_Optional_Start)* | *Table 3, Candidate Characters for Inclusion in ID\_Continue* |
| *Table 3a, [Optional Characters for Medial](#Table_Optional_Medial)* |
| *Table 3b, [Optional Characters for Continue](#Table_Optional_Continue)* | *only outlined in text* |

**Version 6.1**

Between Unicode Versions 5.2, 6.0 and 6.1, Table 5 was split in
three. In Version 6.1, the resulting tables were renumbered for
easier reference. The titles and links remain the same, for
stability.

The following shows the correspondences:

| Current Tables | Unicode 6.0 | Unicode 5.2 |
| --- | --- | --- |
| *Table 5, [Recommended Scripts](#Table_Recommended_Scripts)* | 5a | 5 |
| *Table 6, [Aspirational Use Scripts](#Aspirational_Use_Scripts)* |
| *Table 7, [Limited Use Scripts](#Table_Limited_Use_Scripts)* | 5b |
| *Table 8, [Compatibility Equivalents to Letters or Decimal Numbers](#Figure_Compatibility_Equivalents_to_Letters_or_Decimal_Numbers)* | 6 | 6 |
| *Table 9, [Canonical Equivalence Exceptions Prior to Unicode 5.1](#Figure_Canonical_Equivalence_Exceptions_Prior_to_Unicode_5.1)* | 7 | 7 |

## [Modifications](#Modifications)

The following summarizes modifications from the previously published version
of this annex.

**Revision 41**

* **Reissued** for Unicode 16.0.
* *Section 2.3, [Layout and Format Control Characters](#Layout_and_Format_Control_Characters)*,
  and *Section 5, [Normalization and Case](#normalization_and_case)*: clarified that
  NFD must be applied before toNFKC\_Casefold in order to correctly meet
  requirements UAX31-R4 and UAX-R5 with NFKC and full case folding, and added
  a reference to definition D147 of the Unicode Standard.
* *Section 2.4, [Specific Character Adjustments](#Specific_Character_Adjustments)*,
  Removed the suggestion to add MIDDLE DOT to as part of a profile:
  it is already part of default identifiers with no profile since Unicode Version 5.1.
* *Section 2.5, [Backward Compatibility](#Backward_Compatibility)*:
  corrected the inappropriately-normalized occurrence of U+0387 in the list of Other\_ID\_Continue characters.

Modifications for previous versions are listed in those respective versions.

---

© 2005–2024 Unicode, Inc. This publication is protected by copyright, and permission must be obtained from Unicode, Inc. prior to any reproduction, modification, or other use not permitted by the [Terms of Use](https://www.unicode.org/copyright.html). Specifically, you may make copies of this publication and may annotate and translate it solely for personal or internal business purposes and not for public distribution, provided that any such permitted copies and modifications fully reproduce all copyright and other legal notices contained in the original. You may not make copies of or modifications to this publication for public distribution, or incorporate it in whole or in part into any product or publication without the express written permission of Unicode.

Use of all Unicode Products, including this publication, is governed by the Unicode [Terms of Use](https://www.unicode.org/copyright.html). The authors, contributors, and publishers have taken care in the preparation of this publication, but make no express or implied representation or warranty of any kind and assume no responsibility or liability for errors or omissions or for consequential or incidental damages that may arise therefrom. This publication is provided “AS-IS” without charge as a convenience to users.

Unicode and the Unicode Logo are registered trademarks of Unicode, Inc., in the United States and other countries.



=== Content from trojansource.codes_028e4e24_20250111_024725.html ===
You need to enable JavaScript to run this app.[Trojan Source](/index "Trojan Source")

* [GitHub](https://github.com/nickboucher/trojan-source "Star on GitHub")
* [Read Paper](/trojan-source.pdf)
# Trojan Source

![...](/static/media/fog-low.965eab52.png)![...](/static/media/fog-low.965eab52.png)
## Invisible Source Code Vulnerabilities

## Some Vulnerabilities are Invisible

#### Rather than inserting logical bugs, adversaries can attack the encoding of source code files to inject vulnerabilities.

### These adversarial encodings produce no visual artifacts.

`#include <stdio.h>
#include <stdbool.h>

int main() {
bool isAdmin = false;
/* begin admins only */ if (isAdmin) {
printf("You are an admin.\n");
/* end admins only */ }
return 0;
}`

---

# The trick

#### The trick is to use Unicode control characters to reorder tokens in source code at the encoding level.

#### These visually reordered tokens can be used to display logic that, while semantically correct, diverges from the logic presented by the logical ordering of source code tokens.

#### Compilers and interpreters adhere to the logical ordering of source code, not the visual order.

# The attack

#### The attack is to use control characters embedded in comments and strings to reorder source code characters in a way that changes its logic.

#### The previous example, for instance, works by making a comment appear as if it were code:

## /\*Â if (isAdmin) {Â begin admins only \*/Â

#### Adversaries can leverage this deception to commit vulnerabilities into code that will not be seen by human reviewers.

#### This attack pattern is tracked as CVE-2021-42574.

# The supply chain

#### This attack is particularly powerful within the context of software supply chains.

#### If an adversary successfully commits targeted vulnerabilities into open source code by deceiving human reviewers, downstream software will likely inherit the vulnerability.

# The technique

#### There are multiple techniques that can be used to exploit the visual reordering of source code tokens:

#### **Early Returns** cause a function to short circuit by executing a `return` statement that visually appears to be within a comment.

#### **Commenting-Out** causes a comment to visually appear as code, which in turn is not executed.

#### **Stretched Strings** cause portions of string literals to visually appear as code, which has the same effect as commenting-out and causes string comparisons to fail.

# The variant

#### A similar attack exists which uses homoglyphs, or characters that appear near identical.

`#include <iostream>

void sayHello() {
std::cout << "Hello, World!\n";
}` `void sayÐello() {
std::cout << "Bye, World!\n";
}`
#### The above example defines two distinct functions with near indistinguishable visual differences highlighted for reference.

#### An attacker can define such homoglyph functions in an upstream package imported into the global namespace of the target, which they then call from the victim code.

#### This attack variant is tracked as CVE-2021-42694.

# The defense

#### Compilers, interpreters, and build pipelines supporting Unicode should throw errors or warnings for unterminated bidirectional control characters in comments or string literals, and for identifiers with mixed-script confusable characters.

#### Language specifications should formally disallow unterminated bidirectional control characters in comments and string literals.

#### Code editors and repository frontends should make bidirectional control characters and mixed-script confusable characters perceptible with visual symbols or warnings.

# The paper

#### Complete details can be found in the related [paper](/trojan-source.pdf).

#### If you use the paper or anything on this site in your own work, please cite the following:

`@inproceedings{boucher_trojansource_2023,
Â Â Â Â title = {Trojan {Source}: {Invisible} {Vulnerabilities}},
Â Â Â Â author = {Nicholas Boucher and Ross Anderson},
Â Â Â Â booktitle = {32nd USENIX Security Symposium (USENIX Security 23)},
Â Â Â Â year = {2023},
Â Â Â Â address = {Anaheim, CA},
Â Â Â Â publisher = {USENIX Association},
Â Â Â Â month = aug,
Â Â Â Â url = {https://arxiv.org/abs/2111.00169}
}`Produced by researchers at the University of Cambridge.Â© 2023 [Nicholas Boucher](https://www.cl.cam.ac.uk/~ndb40) with thanks to [Paper Kit React](https://github.com/creativetimofficial/paper-kit-react) and [SRCF](https://www.srcf.net).
![](https://sa.trojansource.codes/noscript.gif?collect-dnt=true)

=== Content from www.unicode.org_f2580a57_20250111_024723.html ===


| | [[Unicode]](https://www.unicode.org/) | [Unicode 14.0.0](https://www.unicode.org/versions/Unicode14.0.0/) | [Tech Site](https://www.unicode.org/main.html) | [Site Map](https://www.unicode.org/sitemap/) | [Search](https://www.unicode.org/search) | | --- | --- | --- | | |
|  | |
| | 14.0.0 Core Specification | | | --- | --- | | All Chapters and Appendices Together: | |   | • | [Full Text pdf for Viewing](https://www.unicode.org/versions/Unicode14.0.0/UnicodeStandard-14.0.pdf) (14 MB) | | • | Print-on-Demand (POD) for purchase: [Volume 1](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-1/paperback/product-p8674j.html) and [Volume 2](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-2/paperback/product-q46246.html) | | 14.0.0 Front Matter | |   |  | [Title and Copyright](https://www.unicode.org/versions/Unicode14.0.0/Title.pdf) | |  | [Contents](https://www.unicode.org/versions/Unicode14.0.0/UnicodeBookTOC.pdf) | |  | [Unicode 14.0 Web Bookmarks](https://www.unicode.org/versions/Unicode14.0.0/bookmarks.html) | |  | [Preface](https://www.unicode.org/versions/Unicode14.0.0/Preface.pdf) | | 14.0.0 Chapters | |   | 1 | [Introduction](https://www.unicode.org/versions/Unicode14.0.0/ch01.pdf) | | 2 | [General Structure](https://www.unicode.org/versions/Unicode14.0.0/ch02.pdf) | | 3 | [Conformance](https://www.unicode.org/versions/Unicode14.0.0/ch03.pdf) | | 4 | [Character Properties](https://www.unicode.org/versions/Unicode14.0.0/ch04.pdf) | | 5 | [Implementation Guidelines](https://www.unicode.org/versions/Unicode14.0.0/ch05.pdf) | | 6 | [Writing Systems and Punctuation](https://www.unicode.org/versions/Unicode14.0.0/ch06.pdf) | | 7 | [Europe-I](https://www.unicode.org/versions/Unicode14.0.0/ch07.pdf) | | 8 | [Europe-II](https://www.unicode.org/versions/Unicode14.0.0/ch08.pdf) | | 9 | [Middle East-I](https://www.unicode.org/versions/Unicode14.0.0/ch09.pdf) | | 10 | [Middle East-II](https://www.unicode.org/versions/Unicode14.0.0/ch10.pdf) | | 11 | [Cuneiform and Hieroglyphs](https://www.unicode.org/versions/Unicode14.0.0/ch11.pdf) | | 12 | [South and Central Asia-I](https://www.unicode.org/versions/Unicode14.0.0/ch12.pdf) | | 13 | [South and Central Asia-II](https://www.unicode.org/versions/Unicode14.0.0/ch13.pdf) | | 14 | [South and Central Asia-III](https://www.unicode.org/versions/Unicode14.0.0/ch14.pdf) | | 15 | [South and Central Asia-IV](https://www.unicode.org/versions/Unicode14.0.0/ch15.pdf) | | 16 | [Southeast Asia](https://www.unicode.org/versions/Unicode14.0.0/ch16.pdf) | | 17 | [Indonesia and Oceania](https://www.unicode.org/versions/Unicode14.0.0/ch17.pdf) | | 18 | [East Asia](https://www.unicode.org/versions/Unicode14.0.0/ch18.pdf) | | 19 | [Africa](https://www.unicode.org/versions/Unicode14.0.0/ch19.pdf) | | 20 | [Americas](https://www.unicode.org/versions/Unicode14.0.0/ch20.pdf) | | 21 | [Notational Systems](https://www.unicode.org/versions/Unicode14.0.0/ch21.pdf) | | 22 | [Symbols](https://www.unicode.org/versions/Unicode14.0.0/ch22.pdf) | | 23 | [Special Areas and Format Characters](https://www.unicode.org/versions/Unicode14.0.0/ch23.pdf) | | 24 | [About the Code Charts](https://www.unicode.org/versions/Unicode14.0.0/ch24.pdf) | | 14.0.0 Appendices and Back Matter | |   | A | [Notational Conventions](https://www.unicode.org/versions/Unicode14.0.0/appA.pdf) | | B | [Unicode Publications and Resources](https://www.unicode.org/versions/Unicode14.0.0/appB.pdf) | | C | [Relationship to ISO/IEC 10646](https://www.unicode.org/versions/Unicode14.0.0/appC.pdf) | | D | [Version History of the Standard](https://www.unicode.org/versions/Unicode14.0.0/appD.pdf) | | E | [Han Unification History](https://www.unicode.org/versions/Unicode14.0.0/appE.pdf) | | F | [Documentation of CJK Strokes](https://www.unicode.org/versions/Unicode14.0.0/appF.pdf) | |  | [Index](https://www.unicode.org/versions/Unicode14.0.0/UnicodeBookIX.pdf) | |  | [Colophon](https://www.unicode.org/versions/Unicode14.0.0/Colophon.pdf) | | Code Charts | | | • | [Latest Code Charts](https://www.unicode.org/charts/) ([Tableaux des caractères](https://www.unicode.org/charts/fr/)) | | • | [Delta Code Charts](https://www.unicode.org/charts/PDF/Unicode-14.0/) (additions to 14.0.0 highlighted) | | • | [Archival Code Charts](https://www.unicode.org/Public/14.0.0/charts/) (14.0.0) ([French](https://www.unicode.org/Public/14.0.0/charts/fr/)) | | Han Radical-Stroke Indices | | | • | [Interactive Han Radical-Stroke Index](https://www.unicode.org/charts/unihanrsindex.html) | | • | [IICore Radical-Stroke Index](https://www.unicode.org/versions/IICoreRSIndex.pdf) (3.8 MB) | | • | [Unihan Core 2020 Radical-Stroke Index](https://www.unicode.org/versions/UnihanCore2020RSIndex.pdf) (8.2 MB) | | • | [Full Han Radical-Stroke Index](https://www.unicode.org/Public/14.0.0/charts/RSIndex.pdf) (41 MB) | | 14.0.0 Unicode Standard Annexes | | | [UAX #9, The Unicode Bidirectional Algorithm](https://www.unicode.org/reports/tr9/tr9-44.html) | | | [UAX #11, East Asian Width](https://www.unicode.org/reports/tr11/tr11-39.html) | | | [UAX #14, Unicode Line Breaking Algorithm](https://www.unicode.org/reports/tr14/tr14-47.html) | | | [UAX #15, Unicode Normalization Forms](https://www.unicode.org/reports/tr15/tr15-51.html) | | | [UAX #24, Unicode Script Property](https://www.unicode.org/reports/tr24/tr24-32.html) | | | [UAX #29, Unicode Text Segmentation](https://www.unicode.org/reports/tr29/tr29-39.html) | | | [UAX #31, Unicode Identifier and Pattern Syntax](https://www.unicode.org/reports/tr31/tr31-35.html) | | | [UAX #34, Unicode Named Character Sequences](https://www.unicode.org/reports/tr34/tr34-27.html) | | | [UAX #38, Unicode Han Database (Unihan)](https://www.unicode.org/reports/tr38/tr38-31.html) | | | [UAX #41, Common References for Unicode Standard Annexes](https://www.unicode.org/reports/tr41/tr41-28.html) | | | [UAX #42, Unicode Character Database in XML](https://www.unicode.org/reports/tr42/tr42-30.html) | | | [UAX #44, Unicode Character Database](https://www.unicode.org/reports/tr44/tr44-28.html) | | | [UAX #45, U-Source Ideographs](https://www.unicode.org/reports/tr45/tr45-25.html) | | | [UAX #50, Unicode Vertical Text Layout](https://www.unicode.org/reports/tr50/tr50-26.html) | | | 14.0.0 UCD | | | 14.0.0 ([files](https://www.unicode.org/Public/14.0.0/)) ([about](https://www.unicode.org/reports/tr44/tr44-28.html)) | | | 14.0.0 [Zipped files](https://www.unicode.org/Public/zipped/14.0.0/) (for bulk download) | | | Related Links | | | [Unicode Acknowledgements](https://www.unicode.org/acknowledgements/) | | | [Archive of Unicode Versions](https://www.unicode.org/versions/enumeratedversions.html) | | | [About Versions](https://www.unicode.org/versions/index.html) | | | [Updates and Errata](https://www.unicode.org/errata/) | | | [Glossary of Unicode Terms](https://www.unicode.org/glossary/) | | | [References for the Unicode Standard](https://www.unicode.org/references/) | | | [Unicode Character Name Index](https://www.unicode.org/charts/charindex.html) | | | [Technical Reports](https://www.unicode.org/reports/) | | | [Unicode Emoji](https://www.unicode.org/emoji/) | | | | Unicode® 14.0.02021 September 14 ([Announcement](http://blog.unicode.org/2021/09/announcing-unicode-standard-version-140.html)) *Version 14.0.0 has been superseded by the [latest version](http://www.unicode.org/versions/latest/) of the Unicode Standard.*  This page summarizes the important changes for the Unicode Standard, Version 14.0.0. This version supersedes all previous versions of the Unicode Standard.  A. [Summary](#Summary) B. [Technical Overview](#Technical_Overview) C. [Stability Policy Update](#Stability_Policy) D. [Textual Changes and Character Additions](#Character_Additions) E. [Conformance Changes](#Conformance_Changes) F. [Changes in the Unicode Character Database](#Database_Changes) G. [Changes in the Unicode Standard Annexes](#UAX_Changes) H. [Changes in Synchronized Unicode Technical Standards](#UTS_Changes) M. [Implications for Migration](#Migration) A. Summary Unicode 14.0 adds 838 characters, for a total of 144,697 characters. These additions include [5 new scripts](#New_Scripts), for a total of 159 scripts, as well as 37 new emoji characters.  The new scripts and characters in Version 14.0 add support for lesser-used languages and unique written requirements worldwide, including numerous symbols additions. Funds from the [Adopt-a-Character](https://www.unicode.org/consortium/adopt-a-character.html) program provided support for some of these additions. The new scripts and characters include:   * Toto, used to write the Toto language in northeast India * Cypro-Minoan, an undeciphered historical script primarily used on the island of Cyprus * Vithkuqi, an historic script used to write Albanian, and undergoing a modern revival * Old Uyghur, an historic script used in Central Asia and elsewhere to write Turkic, Chinese, Mongolian, Tibetan, and Arabic languages * Tangsa, a modern script used to write the Tangsa language, which is spoken in India and Myanmar * Many Latin additions for extended IPA * Arabic script additions used to write languages across Africa and in Iran,   Pakistan, Malaysia, Indonesia, Java, and Bosnia, and to write honorifics,   and additions for Quranic use * Other character additions support languages of North America and of the Philippines, India, and Mongolia   Popular symbol additions:   * 37 emoji characters. For complete statistics regarding all emoji as of   Unicode 14.0, see   [Emoji Counts](https://www.unicode.org/emoji/charts-14.0/emoji-counts.html).   For more information about emoji additions in version 14.0, including new   emoji ZWJ sequences and emoji modifier sequences, see   [Emoji Recently Added, v14.0](https://unicode.org/emoji/charts-14.0/emoji-released.html).   Other symbol and notational additions include:   * The som currency sign used in the Kyrgyz Republic * Znamenny musical notation used to write Znamenny Chant, a form of liturgical singing that developed in Russia in the 11th century CE. It is derived from early Byzantine musical notation and is mainly of scholarly interest.   Support for CJK unified ideographs was enhanced in Version 14.0 by significant corrections and improvements to the Unihan database. Changes to the Unihan database include updated source lists, regular expressions, and new and updated fields. See [UAX #38, Unicode Han Database (Unihan)](https://www.unicode.org/reports/tr38/tr38-31.html) for more information on the updates.  Additional support for lesser-used languages and scholarly work was extended, including:   * Ahom, Balinese, Brahmi, Canadian aboriginal languages (UCAS), Glagolitic, Kaithi, Kannada, Mongolian, Tagalog, Takri, and Telugu * Arabic support for Hausa, Wolof, Hindko, and Punjabi, and Ethiopic support for Gurage   Important chart font updates, including:   * CJK auxiliary blocks and enclosed alphanumerics. See the [delta charts](https://www.unicode.org/charts/PDF/Unicode-14.0/) for detailed information on significant chart font changes.  Synchronization Several other important Unicode specifications have been updated for Version 14.0. The following four Unicode Technical Standards are versioned in synchrony with the Unicode Standard, because their data files cover the same repertoire. All have been updated to Version 14.0:   * [UTS #10, Unicode Collation Algorithm](https://www.unicode.org/reports/tr10/tr10-45.html) — sorting Unicode text * [UTS #39, Unicode Security Mechanisms](https://www.unicode.org/reports/tr39/tr39-24.html) — reducing Unicode spoofing * [UTS #46, Unicode IDNA Compatibility Processing](https://www.unicode.org/reports/tr46/tr46-27.html) — compatible processing of non-ASCII URLs * [UTS #51, Unicode Emoji](https://www.unicode.org/reports/tr51/tr51-21.html) — emoji-related data and behavior   Some of the changes in Version 14.0 and associated Unicode Technical Standards may require modifications to implementations. For more information, see the migration and modification sections of UTS #10, UTS #39, UTS #46, and UTS #51.  See Sections D through H below for additional details regarding the changes in this version of the Unicode Standard, its associated annexes, and the other synchronized Unicode specifications. B. Technical Overview Version 14.0 of the Unicode Standard consists of:   * The core specification * The code charts (delta and archival) for this version * The Unicode Standard Annexes * The Unicode Character Database (UCD)   The core specification gives the general principles, requirements for conformance, and guidelines for implementers. The code charts show representative glyphs for all the Unicode characters. The Unicode Standard Annexes supply detailed normative information about particular aspects of the standard. The Unicode Character Database supplies normative and informative data for implementers to allow them to implement the Unicode Standard. Core Specification The core specification is available as a [single pdf for viewing](https://www.unicode.org/versions/Unicode14.0.0/UnicodeStandard-14.0.pdf). (14 MB) Links are also available in the navigation bar on the left of this page to access [individual chapters](#Chapters_nb) and [appendices](#Appendices_nb) of the core specification. It is also available as Print-on-Demand (POD) for purchase: [Volume 1](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-1/paperback/product-p8674j.html%20) and [Volume 2](https://www.lulu.com/en/us/shop/unicode-consortium/the-unicode-standard-version-140-volume-2/paperback/product-q46246.html). Code Charts Several sets of code charts are available. They serve different purposes:   * The [latest set of code charts](https://www.unicode.org/charts/) for   the Unicode Standard is available online. Those charts are always the most current   code charts available, and may be updated at any time. The charts are organized by   scripts and blocks for easy reference.   An online [index by character name](https://www.unicode.org/charts/charindex.html)   is also provided. The [Tableaux des caractères](https://www.unicode.org/charts/fr/)   provides a French translation of these latest code charts.   For Unicode 14.0.0 in particular two additional sets of code chart pages are provided:   * A [set of delta code charts](https://www.unicode.org/charts/PDF/Unicode-14.0/) showing the   new blocks and any blocks in which characters were added for Unicode 14.0.0. The new characters are visually highlighted in the charts. * A [set of archival code charts](https://www.unicode.org/Public/14.0.0/charts/) that represents   the entire set of characters, names and representative glyphs at the time of publication of Unicode 14.0.0.   A [French translation](https://www.unicode.org/Public/14.0.0/charts/fr/) of the archival code charts is also available for this version.   The delta and archival code charts are a stable part of this release of the Unicode Standard. They will never be updated.  The old, frozen UCS2003 source column has been removed from the multi-column display for CJK Unified Ideographs Extension B for Version 14.0.0. For permanent reference, a [single source display of UCS2003](https://www.unicode.org/Public/13.0.0/charts/UCS2003.pdf) (8.7 MB) for the CJK Unified Ideographs Extension B has been provided as part of the Version 13.0.0 archival charts. Unicode Standard Annexes Links to the individual [Unicode Standard Annexes](#Unicode_Standard_Annexes_nb) are available in the navigation bar on the left of this page. The list of significant changes in the content of the Unicode Standard Annexes for Version 14.0 can be found in [Section G](#UAX_Changes) below. Unicode Character Database [Data files](https://www.unicode.org/Public/14.0.0/) for Version 14.0 of the Unicode Character Database are available. The ReadMe.txt in that directory provides a roadmap to the functions of the various subdirectories. [Zipped versions](https://www.unicode.org/Public/zipped/14.0.0/) of the UCD for bulk download are available, as well. Version References Version 14.0.0 of the Unicode Standard should be referenced as:  The Unicode Consortium. *The Unicode Standard, Version 14.0.0*, (Mountain View, CA: The Unicode Consortium, 2021. ISBN 978-1-936213-29-0) [http://www.unicode.org/versions/Unicode14.0.0/](https://www.unicode.org/versions/Unicode14.0.0/)  The terms “Version 14.0” or “Unicode 14.0” are abbreviations for the full version reference, Version 14.0.0.  The citation and permalink for the latest published version of the Unicode Standard is:  The Unicode Consortium. *The Unicode Standard*. [http://www.unicode.org/versions/latest/](https://www.unicode.org/versions/latest/)  A complete specification of the contributory files for Unicode 14.0 is found on the page [Components for 14.0.0](https://www.unicode.org/versions/components-14.0.0.html). That page also provides the recommended reference format for Unicode Standard Annexes. For examples of how to cite particular portions of the Unicode Standard, see also the [Reference Examples](https://www.unicode.org/versions/#References). Errata Errata incorporated into Unicode 14.0 are listed by date in a [separate table](erratafixed.html). For corrigenda and errata after the release of Unicode 14.0, see the list of current [Updates and Errata](https://www.unicode.org/errata/). C. Stability Policy Update There were no significant changes to the Stability Policy of the core specification between Unicode 13.0 and Unicode 14.0. D. Textual Changes and Character Additions Five new scripts were added with accompanying new block descriptions:   | Script | Number ofCharacters | | --- | --- | | Vithkuqi | 70 | | Old Uyghur | 26 | | Cypro-Minoan | 99 | | Tangsa | 89 | | Toto | 31 |   Changes in the Unicode Standard Annexes are listed in [Section G](#UAX_Changes). Character Assignment Overview 838 characters have been added. Most character additions are in new blocks, but there are also character additions to a number of existing blocks. For details, see [delta code charts](https://www.unicode.org/charts/PDF/Unicode-14.0/). E. Conformance Changes There are no significant new conformance requirements in Unicode 14.0. F. Changes in the Unicode Character Database The detailed listing of all changes to the contributory data files of the Unicode Character Database for Version 14.0 can be found in [UAX #44, Unicode Character Database](https://www.unicode.org/reports/tr44/tr44-28.html#Unicode_14.0.0). The changes listed there include character additions and property revisions to existing characters that will affect implementations. Some of the important impacts on implementations migrating from earlier versions of the standard are highlighted in [Section M](#Migration). G. Changes in the Unicode Standard Annexes In Version 14.0, some of the Unicode Standard Annexes have had significant revisions. The most important of these changes are listed below. For the full details of all changes, see the Modifications section of each UAX, linked directly from the following list of UAXes.  Note that for Unicode 14.0, all pertinent links to URLs on the Unicode website in these Unicode Standard Annexes were updated to use the https protocol.   | Unicode Standard Annex | Changes | | --- | --- | | [UAX #9](https://www.unicode.org/reports/tr9/tr9-44.html#Modifications)Unicode Bidirectional Algorithm | Section 6.2, Vertical Text was clarified to indicate how the Bidirectional Algorithm is (or is not) used when text is laid out in vertical orientation. | | [UAX #11](https://www.unicode.org/reports/tr11/tr11-39.html#Modifications)East Asian Width | No significant changes in this version. | | [UAX #14](https://www.unicode.org/reports/tr14/tr14-47.html#Modifications)Unicode Line Breaking Algorithm | One redundant rule part was removed from LB27 in Section 6.1, Non-tailorable Line Breaking Rules. Also, LB30b was updated to include potential emoji. | | [UAX #15](https://www.unicode.org/reports/tr15/tr15-51.html#Modifications)Unicode Normalization Forms | No significant changes in this version. | | [UAX #24](https://www.unicode.org/reports/tr24/tr24-32.html#Modifications)Unicode Script Property | No significant changes in this version. | | [UAX #29](https://www.unicode.org/reports/tr29/tr29-39.html#Modifications)Unicode Text Segmentation | A Swedish "AIK:are" example was added to the word boundary discussion. The description of the charts in the auxiliary data files was updated, to make it more accurate. Other small editorial fixes were applied to the text. | | [UAX #31](https://www.unicode.org/reports/tr31/tr31-35.html#Modifications)Unicode Identifier and Pattern Syntax | Scripts new to Unicode 14.0 were added to the appropriate tables. A new Section 1.5, Notation, was added, referring to the LDML for the UnicodeSet notation used in this annex. | | [UAX #34](https://www.unicode.org/reports/tr34/tr34-27.html#Modifications)Unicode Named Character Sequences | No significant changes in this version. | | [UAX #38](https://www.unicode.org/reports/tr38/tr38-31.html#Modifications)Unicode Han Database (Unihan) | The kCantonese field was redefined, and its description was updated accordingly. The new kStrange field was added. Regular expressions, source lists, and descriptions were updated for many other fields. | | [UAX #41](https://www.unicode.org/reports/tr41/tr41-28.html)Common References for Unicode Standard Annexes | All references were updated for Unicode 14.0. | | [UAX #42](https://www.unicode.org/reports/tr42/tr42-30.html#Modifications)Unicode Character Database in XML | New code point attributes, values, and patterns were added for Unicode 14.0. | | [UAX #44](https://www.unicode.org/reports/tr44/tr44-28.html#Modifications) Unicode Character Database | The documentation was updated to describe the changes to the UCD for Version 14.0. The distinction between properties of strings and string-valued properties was clarified. A note was added clarifying that Vertical\_Orientation defaults to U in some blocks associated with notational systems. An erroneous statement about which General\_Category values can be associated with ccc≠0 was corrected. | | [UAX #45](https://www.unicode.org/reports/tr45/tr45-25.html#Modifications) U-Source Ideographs | Descriptions were added for new data fields (total strokes and first residual stroke) in the data file associated with UAX #45. The KangXi dictionary index field was obsoleted. New information was added about the submission process. | | [UAX #50](https://www.unicode.org/reports/tr50/tr50-26.html#Modifications) Unicode Vertical Text Layout | No significant changes in this version. |   H. Changes in Synchronized Unicode Technical Standards There are also significant revisions in the Unicode Technical Standards whose versions are synchronized with the Unicode Standard. The most important of these changes are listed below. For the full details of all changes, see the Modifications section of each UTS, linked directly from the following list of UTSes.   | Unicode Technical Standard | Changes | | --- | --- | | [UTS #10](https://www.unicode.org/reports/tr10/tr10-45.html#Modifications)Unicode Collation Algorithm | No significant changes in this version. | | [UTS #39](https://www.unicode.org/reports/tr39/tr39-24.html#Modifications)Unicode Security Mechanisms | Section 3, Identifier Characters was adjusted to better introduce the topic of identifiers. The text in Section 3.1, General Security Profile for Identifiers was clarified regarding the rationales for restricting a character. The descriptions of identifier types in Table 1 were clarified. | | [UTS #46](https://www.unicode.org/reports/tr46/tr46-27.html#Modifications)Unicode IDNA Compatibility Processing | No significant changes in this version. | | [UTS #51](https://www.unicode.org/reports/tr51/tr51-21.html#Modifications)Unicode Emoji | The introduction was reworded. The definition of Basic\_Emoji was clarified, and it was noted that emoji sets are binary properties of strings. In Section 2.6.2, Multi-Person Skin Tones, the *handshake* was added to the list of emoji with RGI skin tones. |   M. Implications for Migration There are a significant number of changes in Unicode 14.0 which may impact implementations upgrading to Version 14.0 from earlier versions of the standard. The most important of these are listed and explained here, to help focus on the issues most likely to cause unexpected trouble during upgrades. Script-related Changes Five new scripts have been added in Unicode 14.0.0. Some of these scripts have particular attributes which may cause issues for implementations. The more important of these attributes are summarized here.   * Old Uyghur is an abjad, historically related to Sogdian. Representation   of Old Uyghur text poses many significant issues. See the original proposal   documentation in [L2/20-191](https://www.unicode.org/L2/L2020/20191-old-uyghur.pdf)   for an extensive discussion.  Casing Issues  * Four new Latin case pairs and one new Glagolitic case pair have been added   in Version 14.0.0. In addition, one of the newly added scripts, Vithkuqi,   is a bicameral script with casing. Implementations   of case mapping and case folding should be checked to ensure they account   correctly for the new case pairs.  Numeric Property Issues  * A new set of decimal digits has been added for the Tangsa script.   See U+16AC0..U+16AC9. Implementations of digits will need to take those   into account.  CJK/Unihan Changes  * A new provisional property, kStrange, has been added to Unihan.   This property is documented in detail in a new Unicode Technical   Note, [UTN #43](https://www.unicode.org/notes/tn43/). * The provisional kCantonese property was extensively refined.   This work included 6,000 additional property values, as well as changing the property   values for nearly 5,000 existing ideographs to reflect only one reading. * Over 1,000 kIRG\_VSource property values with "VU-"" prefix were changed   to use the "VN-" prefix. * WARNING: There are changes to the ends of three existing   CJK unified ideograph ranges in Unicode 14.0.0. Because implementations often hard-code   ideographic ranges to short-cut lookups and reduce table sizes, it is   especially important that implementers pay close attention to the   implications of range changes for Version 14.0.0. These extensions bump up the end   ranges of the encoded ideographs by a few code points within each block:    + 3 code points for the [URO](https://www.unicode.org/glossary/#URO):     ending at U+9FFF [fills the block]   + 2 code points for Extension B: ending at U+2A6DF [fills the block]   + 4 code points for Extension C: ending at U+2B738 See [Section 4.4,   *Listing of Characters Covered by the Unihan Database*](https://www.unicode.org/reports/tr38/tr38-31.html#BlockListing)   in UAX #38   for the version history of all these small CJK unified ideograph additions   inside existing blocks.   See [UAX #38](https://www.unicode.org/reports/tr38/tr38-31.html), Unicode Han Database (Unihan) for further details on these changes, especially Section 4.2, *Listing by Date of Addition to the Unicode Standard*, and Section 4.3, *Listing by Location within Unihan.zip*. UAX #38 also has updated regex values for numerous Unihan properties. Emoji Changes  * 37 new emoji characters have been added. However, in addition   to those individual characters, many new emoji sequences have been   recognized, as well. Implementations supporting emoji should be   checked to reflect changes in   [UTS #51, Unicode Emoji](https://www.unicode.org/reports/tr51/tr51-21.html)   and all of its associated data files.  Code Charts  * There was a significant update in the fonts used for many CJK auxiliary blocks,   to improve the design and consistency of glyphs. Details of the affected ranges   of glyphs can be found in the Glyph and Variation Sequence Changes table   on the   [single block delta charts page](https://www.unicode.org/charts/PDF/Unicode-14.0/). * There have also been systematic updates to many glyphs in the   [Egyptian Hieroglyphs](https://www.unicode.org/charts/PDF/Unicode-14.0/U140-13000.pdf)   block, to more accurately reflect current practice.   The old, frozen UCS2003 source column has been removed from the multi-column display for CJK Unified Ideographs Extension B for Version 14.0.0. For permanent reference, a [single source display of UCS2003](https://www.unicode.org/Public/13.0.0/charts/UCS2003.pdf) (8.7 MB) for the CJK Unified Ideographs Extension B has been provided as part of the Version 13.0.0 archival charts. The rationale for this change is that the UCS2003 source was the source corresponding to the single column chart first printed in Unicode 4.0 in 2003. The glyphs for that single source had not tracked the extensive updates for characters in Extension B over the intervening years, and so in some cases were becoming misleading about the identity of some of the corrected characters in Extension B.   ---   | [Access to Copyright and terms of use](https://www.unicode.org/copyright.html) | | --- | | | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | |



=== Content from www.unicode.org_70dca9b0_20250111_024730.html ===


| [[Unicode]](https://www.unicode.org/) | [Technical Reports](https://www.unicode.org/reports/) |
| --- | --- |
|  | |

## Unicode® Technical Standard #39

# Unicode Security Mechanisms

| Version | 16.0.0 |
| --- | --- |
| Editors | Mark Davis (markdavis@google.com), Michel Suignard (michel@suignard.com) |
| Date | 2024-09-03 |
| This Version | <https://www.unicode.org/reports/tr39/tr39-30.html> |
| Previous Version | <https://www.unicode.org/reports/tr39/tr39-28.html> |
| Latest Version | <https://www.unicode.org/reports/tr39/> |
| Latest Proposed Update | <https://www.unicode.org/reports/tr39/proposed.html> |
| Revision | [30](#Modifications) |

### *Summary*

*Because Unicode contains such a large number of characters and
incorporates the varied writing systems of the world, incorrect
usage can expose programs or systems to possible security attacks.
This document specifies mechanisms that can be used to detect
possible security problems.*

### *Status*

*This document has been reviewed by Unicode members and other
interested parties, and has been approved for publication by the Unicode
Consortium. This is a stable document and may be used as reference
material or cited as a normative reference by other specifications.*

> ***A Unicode Technical Standard (UTS)** is an independent
> specification. Conformance to the Unicode Standard does not imply
> conformance to any UTS.*

*Please submit corrigenda and other comments with the online
reporting form [[Feedback](https://www.unicode.org/reporting.html)].
Related information that is useful in understanding this document is
found in the [References](#References). For the latest
version of the Unicode Standard, see [[Unicode](https://www.unicode.org/versions/latest/)]. For a
list of current Unicode Technical Reports, see [[Reports](https://www.unicode.org/reports/)]. For more
information about versions of the Unicode Standard, see [[Versions](https://www.unicode.org/versions/)].*

### *Contents*

* 1 [Introduction](#Introduction)
* 2 [Conformance](#Conformance)
* 3 [Identifier Characters](#Identifier_Characters)
  + 3.1 [General
    Security Profile for Identifiers](#General_Security_Profile)
    - Table 1. [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)
    - 3.1.1 [Joining Controls](#Joining_Controls)
      * 3.1.1.1 [Limited Contexts for Joining Controls](#Limited_Contexts_for_Joining_Controls)
      * 3.1.1.2 [Limitations](#Limitations)
  + 3.2 [IDN Security
    Profiles for Identifiers](#IDN_Security_Profiles)
  + 3.3 [Email
    Security Profiles for Identifiers](#Email_Security_Profiles)
* 4 [Confusable Detection](#Confusable_Detection)
  + 4.1 [Whole-Script
    Confusables](#Whole_Script_Confusables)
  + 4.2 [Mixed-Script
    Confusables](#Mixed_Script_Confusables)
* 5 [Detection Mechanisms](#Detection_Mechanisms)
  + 5.1 [Mixed-Script
    Detection](#Mixed_Script_Detection)
    - Table 1a. [Mixed Script Examples](#Mixed_Script_Examples)
  + 5.2 [Restriction-Level
    Detection](#Restriction_Level_Detection)
  + 5.3 [Mixed-Number
    Detection](#Mixed_Number_Detection)
  + 5.4 [Optional Detection](#Optional_Detection)
* 6 [Development Process](#Development_Process)
  + 6.1 [Confusables Data
    Collection](#Data_Collection)
  + 6.2 [Identifier
    Modification Data Collection](#IDMOD_Data_Collection)
* 7 [Data Files](#Data_Files)
  + Table 2. [Data File List](#Data_File_List)
* [Migration](#Migration)
  + Table 3. [Version
    Correspondence](#Version_Correspondance)
  + [Migrating
    Persistent Data](#Migrating_Persistent_Data)
  + [Version 8.0 Migration](#Version_8_Migration)
  + [Version 7.0 Migration](#Version_7_Migration)
* [Acknowledgments](#Acknowledgments)
* [References](#References)
* [Modifications](#Modifications)

---

## 1 [Introduction](#Introduction)

*Unicode Technical Report #36, "Unicode Security
Considerations"* [[UTR36](#UTR36)]
provides guidelines for detecting and avoiding security problems
connected with the use of Unicode. This document specifies mechanisms
that are used in that document, and can be used elsewhere. Readers
should be familiar with [[UTR36](#UTR36)] before
continuing. See also the Unicode FAQ on *Security
Issues* [[FAQSec](#FAQSec)].

## 2 [Conformance](#Conformance)

An implementation claiming conformance to this specification
must do so in conformance to the following clauses:

**[UTS-39-C1](#UTS-39-C1)**.
*An implementation claiming to implement
the **General Profile for Identifiers** shall do so by conforming to either [UTS-39-C1-1](#UTS-39-C1-1) or [UTS-39-C1-2](#UTS-39-C1-2).*

> **[UTS-39-C1-1](#UTS-39-C1-1)**. *The Implementation shall be in accordance with the specifications in Section 3.1, [General Security Profile for Identifiers](#General_Security_Profile), without change.*
>
> **[UTS-39-C1-2](#UTS-39-C1-2)**. *The implementation shall provide a precise list of characters that are added to or removed from the profile, but otherwise be in accordance with the specifications in Section 3.1, [General Security Profile for Identifiers](#General_Security_Profile).*

**[UTS-39-C1.1](#UTS-39-C1.1)**.
*An implementation claiming to implement
the **IDN Security Profiles for Identifiers** shall do so by conforming to either [UTS-39-C1.1-1](#UTS-39-C1.1-1) or [UTS-39-C1.1-2](#UTS-39-C1.1-2).*

> **[UTS-39-C1.1-1](#UTS-39-C1.1-1)**. *The implementation shall be in accordance with the specifications in Section 3.2, [IDN Security Profiles for Identifiers](#IDN_Security_Profiles) for Identifiers, without change.*
>
> **[UTS-39-C1.1-2](#UTS-39-C1.1-2)**. *The implementation shall provide a precise list of characters that are added to or removed from the profile, but otherwise be in accordance with the specifications in Section 3.2, [IDN Security Profiles for Identifiers](#IDN_Security_Profiles).*

**[UTS-39-C1.2](#UTS-39-C1.2)**. *An implementation claiming to implement the **Email Security Profiles for Identifiers** shall do so by conforming to either [UTS-39-C1.2-1](#UTS-39-C1.2-1) or [UTS-39-C1.2-2](#UTS-39-C1.2-2).*

> **[UTS-39-C1.2-1](#UTS-39-C1.2-1)**. *The implementation shall be in accordance with the specifications in Section 3.3, [Email Security Profiles for Identifiers](#Email_Security_Profiles), without change.*
>
> **[UTS-39-C1.2-2](#UTS-39-C1.2-2)**. *The implementation shall provide a precise list of characters that are added to or removed from the profile, but otherwise be in accordance with the specifications in Section 3.3, [Email Security Profiles for Identifiers](#Email_Security_Profiles).*

**[UTS-39-C2](#UTS-39-C2)**. *An implementation claiming to implement any of the following confusable-detection functions for Identifiers defined in Section 4,
[Confusable Detection](#Confusable_Detection) shall do so by conforming to either [UTS-39-C2-1](#UTS-39-C2-1) or [UTS-39-C2-2](#UTS-39-C2-2)*.

1. X and Y are single-script confusables
2. X and Y are mixed-script confusables
3. X and Y are whole-script confusables
4. X has whole-script confusables in set of scripts S

> **[UTS-39-C2-1](#UTS-39-C2-1)**. *The implementation of the function shall be in accordance with the specifications in Section 4,
> [Confusable Detection](#Confusable_Detection), without change.*
>
> **[UTS-39-C2-2](#UTS-39-C2-2)**. *The implementation shall provide a precise list of character mappings that are added to or removed from those provided, but otherwise be in accordance with the specifications in Section 4,
> [Confusable Detection](#Confusable_Detection).*

**[UTS-39-C3](#UTS-39-C3)**. *An implementation claiming to detect mixed scripts shall do so by conforming to either [UTS-39-C3-1](#UTS-39-C3-1) or [UTS-39-C3-2](#UTS-39-C3-2).*

> **[UTS-39-C3-1](#UTS-39-C3-1)**. *The implementation shall be in accordance with the specifications in Section 5.1, [Mixed-script Detection](#Mixed_Script_Detection), without change.*
>
> **[UTS-39-C3-2](#UTS-39-C3-2)**. *The implementation shall provide a precise description of changes in behavior, but otherwise be in accordance with the specifications in Section 5.1, [Mixed-Script Detection](#Mixed_Script_Detection).*

**[UTS-39-C4](#UTS-39-C4)**. *An implementation claiming to detect Restriction-Levels shall do so by conforming to either [UTS-39-C4-1](#UTS-39-C4-1) or [UTS-39-C4-2](#UTS-39-C4-2).*

> **[UTS-39-C4-1](#UTS-39-C4-1)**. *The implementation shall be in accordance with the specifications in Section 5.2, [Restriction-Level Detection](#Restriction_Level_Detection), without change.*
>
> **[UTS-39-C4-2](#UTS-39-C4-2)**. *The implementation shall provide a precise description of changes in behavior, but otherwise be in accordance with the specifications in Section 5.2, [Restriction-Level Detection](#Restriction_Level_Detection).*

**[UTS-39-C5](#UTS-39-C5)**. *An implementation claiming to detect mixed numbers shall do so by conforming to either [UTS-39-C5-1](#UTS-39-C5-1) or [UTS-39-C5-2](#UTS-39-C5-2).*

> **[UTS-39-C5-1](#UTS-39-C5-1)**. *The implementation shall be in accordance with the specifications in Section 5.3, [Mixed-Number Detection](#Mixed_Number_Detection), without change.*
>
> **[UTS-39-C5-2](#UTS-39-C5-2)**. *The implementation shall provide a precise description of changes in behavior, but otherwise be in accordance with the specifications in Section 5.3, [Mixed-Number Detection](#Mixed_Number_Detection).*

## 3 [Identifier Characters](#Identifier_Characters)

Identifiers ("IDs") are strings used in application contexts
to refer to specific entities of certain significance in the given application. In a
given application, an identifier will map to at most one specific entity.
Many applications have security requirements related to identifiers.
A common example is URLs referring to pages
or other resources on the Internet: when a user wishes to access a
resource, it is important that the user can be certain what resource they
are interacting with. For example, they need to know that they are interacting with a
particular financial service and not some other entity that is spoofing the
intended service for malicious purposes. This illustrates a
general security concern for identifiers: potential ambiguity of strings.
While a machine has no difficulty distinguishing between any two different
character sequences, it could be very difficult for humans to
recognize and distinguish identifiers if an application did not limit which
Unicode characters could be in identifiers.
The focus of this specification is mitigation of such issues related
to the security of identifiers.

Deliberately restricting the characters that can be used in identifiers
is an important security technique.
The exclusion of characters from identifiers does not affect the general
use of those characters for other purposes, such as for general text in documents.
Unicode Standard Annex #31,
"Unicode Identifier and Pattern Syntax" [[UAX31](#UAX31)]
provides a recommended method of determining which strings should
qualify as identifiers. The UAX #31 specification extends the common
practice of defining identifiers in terms of letters and numbers to
the Unicode repertoire.

That specification also permits other protocols to use that method as
a base, and to define a  *profile* that adds or removes
characters. For example, identifiers for specific programming
languages typically add some characters like "$", and
remove others like "-" (because of the use as *minus*),
while IDNA removes "\_" (among others)—see Unicode
Technical Standard #46, "Unicode IDNA Compatibility
Processing" [[UTS46](#UTS46)], as well as [[IDNA2003](#IDNA2003)], and [[IDNA2008](#IDNA2008)].

This document provides for additional identifier profiles for
environments where security is an issue. These are profiles of the
extended identifiers based on properties and specifications of the
Unicode Standard [[Unicode](#Unicode)], including:

* The XID\_Start and XID\_Continue properties defined in the
  Unicode Character Database (see [[DCore](#DCore)])
* The toCasefold(X) operation defined in *Chapter
  3, Conformance* of [[Unicode](#Unicode)]
* The NFKC and NFKD normalizations defined in *Chapter
  3, Conformance* of [[Unicode](#Unicode)]

The data files used in defining these profiles follow the UCD File
Format, which has a semicolon-delimited list of data fields
associated with given characters, with each field referenced by
number. For more details, see [[UCDFormat](#UCDFormat)].

### 3.1 [General Security Profile for Identifiers](#General_Security_Profile)

The files under [[idmod](#idmod)] provide data for a profile of
identifiers in environments where security is at issue. The files
contain a set of characters recommended to be restricted from use.
They also contain a small set of characters that are recommended as
additions to the list of characters defined by the XID\_Start and
XID\_Continue properties, because they may be used in identifiers in a
broader context than programming identifiers.

The Restricted characters are characters not in common use, and
they can be blocked to further reduce the possibilities for visual
confusion. They include the following:

* characters not in modern use
* characters only used in specialized fields, such as
  liturgical characters, phonetic letters, and mathematical
  letter-like symbols
* characters in limited use by very small communities

The choice of which characters to specify as Restricted starts conservatively, but allows additions
in the future as requirements for characters are refined.
For information on handling modifications
over time, see *2.10.1, Backward
Compatibility* in *Unicode Technical Report #36,
"Unicode Security Considerations"* [[UTR36](#UTR36)].

An implementation following the General Security Profile does not
permit any characters in \p{Identifier\_Status=Restricted}, unless it documents the
additional characters that it does allow. Such documentation can specify characters via properties, such as \p{Identifier\_Type=Technical}, or by explicit lists, or by combinations of these. Implementations may also specify that fewer characters are allowed than implied by \p{Identifier\_Status=Allowed}; for example, they can allow only characters permitted by [[IDNA2008](#IDNA2008)].

Common candidates for such
additions include characters for scripts listed in *Table 7,
[Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* of [[UAX31](#UAX31)]. However,
characters from these scripts have not been a priority for
examination for confusables or to determine specialized, non-modern,
or uncommon-use characters.

Canonical equivalence is applied when testing candidate identifiers
for inclusion of *Allowed* characters. For example, suppose
the candidate string is the sequence

<u, *combining-diaeresis*>

The target string would be Allowed in *either* of the
following 2 situations:

1. u is Allowed and ¨ is Allowed, or
2. ü is Allowed

For details of the format for the [[idmod](#idmod)] files, see *Section 7, [Data Files](#Data_Files)*.

Table 1. [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)

| Identifier\_Status | Identifier\_Type | Description |
| --- | --- | --- |
| [Restricted](#restricted) | Not\_Character | Unassigned characters, private use characters, surrogates, non-whitespace control characters. |
| Deprecated | Characters with the Unicode property *Deprecated=Yes*. |
| Default\_Ignorable | Characters with the Unicode property *Default\_Ignorable\_Code\_Point=Yes*. |
| Not\_NFKC | Characters that cannot occur in strings normalized to NFKC. |
| Not\_XID | Characters that do not qualify as default Unicode identifiers; that is, they do not have the Unicode property *XID\_Continue=True*. |
| Exclusion | Characters with Script\_Extensions values containing a script in *Table 4, [Excluded Scripts](https://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*from [[UAX31](#UAX31)], and no script from *Table 7, [Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* or *Table 5, [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*, other than “Common” or “Inherited”. |
| Obsolete | Characters that are no longer in modern use, or that are not commonly used in modern text. |
| Technical | Specialized usage: technical, liturgical, etc. |
| Uncommon\_Use | Characters that are uncommon, or are limited in use (even though they are in scripts that are not "Limited\_Use"), or whose usage is uncertain.  May be combined with Exclusion or Limited\_Use for characters that are less common than the main characters of their scripts. |
| Limited\_Use | Characters from scripts that are in limited use: with Script\_Extensions values containing a script in *Table 7, [Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* in [[UAX31](#UAX31)], and no script from *Table 5, [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*, other than “Common” or “Inherited”. |
| [Allowed](#allowed) | **Inclusion** | Exceptionally allowed characters, including *Table 3a, [Optional Characters for Medial](https://www.unicode.org/reports/tr31/#Table_Optional_Medial)* and *Table 3b, [Optional Characters for Continue](https://www.unicode.org/reports/tr31/#Table_Optional_Continue)* in [[UAX31](#UAX31)], and some characters for [[IDNA2008](#IDNA2008)], except for certain characters that are Restricted above. |
| **Recommended** | Characters from scripts that are in widespread everyday common use: with Script\_Extensions values containing a script in *Table 5, [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)* in [[UAX31](#UAX31)], except for those characters that are Restricted above. |

> **Note:** In Unicode 15.0, the Joiner\_Control characters (ZWJ/ZWNJ) have been removed from
> Identifier\_Type=[Inclusion](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=[:Identifier_Type=Inclusion:]).
> They thereby have the properties
> Identifier\_Type=[Default\_Ignorable](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=[:Identifier_Type=Default_Ignorable:]) and
> Identifier\_Status=[Restricted](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=[:Identifier_Status=Restricted:]).
> Their inclusion in programming language identifier profiles has usability and security implications.
>
> Implementations of the General Profile for Identifiers that wish to retain ZWJ and ZWNJ should declare that they use a modification of the profile per
> *[Section 2, Conformance](#Conformance)*,
> and should ensure that they implement the restrictions described in
> *[Section 3.1.1, Joining Controls](#Joining_Controls)*.

Identifier\_Status and Identifier\_Type are properties of characters (code points).
See *UTS #18: Unicode Regular Expressions* [[UTS18](#UTS18)]
and *UTR #23: The Unicode Character Property Model* [[UTR23](#UTR23)] for
more discussion.
For the purpose of regular expressions,
the long and short names of these properties and their values
are documented in their respective data files;
see *Section 7, [Data Files](#Data_Files)*.

For stability considerations, see [Migrating
Persistent Data](#Migrating_Persistent_Data).

There may be multiple reasons for restricting a character; therefore,
the Identifier\_Type property allows multiple values that correspond with
Restricted. For example, some characters have Identifier\_Type values of
Limited\_Use and Technical. Multiple values are not assigned to characters with strong restrictions: Not\_Character, Deprecated, Default\_Ignorable, Not\_NFKC. For
example, if a character is Deprecated, there is little value in also
marking it as Uncommon\_Use. For the qualifiers on usage, Obsolete,
Uncommon\_Use and Technical, the distinctions among the Identifier\_Type values is not strict and
only one might be given. The important characteristic is the Identifier\_Status:
whether or not the character is Restricted.

The default Identifier\_Type property value should be Uncommon\_Use if no other categories apply.

*As more
information is gathered about characters, this data may change in
successive versions.* That can cause either the Identifier\_Status
or Identifier\_Type to change for a particular character. Thus users of
this data should be prepared for changes in successive versions, such
as by having a grandfathering policy in place for previously
supported characters or registrations. Both Identifier\_Status
and Identifier\_Type values are to be compared
case-insensitively and ignoring hyphens and underbars.

Restricted characters should be treated with caution when considering possible use in identifiers,
and should be disallowed unless there is good reason to allow them in the
environment in question. However, the set of Identifier\_Status=Allowed
characters are not typically used as is by implementations. Instead,
they are applied as filters to the set of characters C that are
supported by the identifier syntax, generating a new set C′.
Typically there are also particular characters or classes of
characters from C that are retained as **Exception**
characters.

C′ = (C ∩ {Identifier\_Status=Allowed}) ∪ **Exception**

The implementation may simply restrict use of new identifiers to C′,
or may apply some other strategy. For example, there might be an
appeal process for registrations of ids that contain characters
outside of C′ (but still inside of C), or in user interfaces for
lookup of identifiers, warnings of some kind may be appropriate. For
more information, see [[UTR36](#UTR36)].

The **Exception** characters would be
implementation-specific. For example, a particular implementation
might extend the default Unicode identifier syntax by adding **Exception**
characters with the Unicode property *XID\_Continue=False*,
such as “$”, “-”, and “.”. Those characters are specific to that
identifier syntax, and would be retained even though they are not in
the Identifier\_Status=Allowed set. Some
implementations may also wish to add some [[CLDR](#CLDR)]
exemplar characters for particular supported languages that have
unusual characters.

The Identifier\_Type=Inclusion characters already
contain some characters that are not letters or numbers, but that are
used within words in some languages. For example, it is recommended
that U+00B7 (·) MIDDLE DOT be allowed in identifiers, because it is
required for Catalan.

The implementation may also apply other restrictions discussed
in this document, such as checking for confusable characters or doing
mixed-script detection.

### 3.1.1 [Joining Controls](#Joining_Controls)

Visible distinctions
created by certain characters excluded by the
General Security Profile because their Identifier\_Type is Default\_Ignorable (particularly the *Join\_Control
characters*) are necessary in certain languages. A blanket exclusion
of these characters makes it impossible to create identifiers with
the correct visual appearance for common words or phrases in those
languages.

Identifier systems that attempt to provide more natural
representations of terms in "modern, customary usage"
should allow these characters in input and display, but limit them to
contexts in which they are necessary. The term *modern
customary usage* includes characters that are in common use in
newspapers, journals, lay publications; on street signs; in
commercial signage; and as part of common geographic names and
company names, and so on. It does not include technical or academic
usage such as in mathematical expressions, using archaic scripts or
words, or pedagogical use (such as illustration of half-forms or
joining forms in isolation), or liturgical use.

The goals for such a restriction of format characters to
particular contexts are to:

* Allow the use of these characters where required in normal
  text
* Exclude as many cases as possible where no visible
  distinction results
* Be simple enough to be easily implemented with standard
  mechanisms such as regular expressions

An implementation following the General Security Profile that allows the additional characters ZWJ and ZWNJ shall only permit them where they
satisfy the conditions A1, A2, and B in *Section 3.1.1.1, [Limited Contexts for Joiner Controls](#Limited_Contexts_for_Joining_Controls)*, unless it documents the
additional contexts where it allows them.

More advanced implementations may use script-specific information for more detailed testing. In particular, they can:

1. *Disallow joining controls* in sequences that meet the conditions of A1, A2, and B, where in common fonts the resulting appearance of the sequence is normally not distinct from appearance in the same sequences with the joining controls removed.

2. *Allow joining controls* in sequences that don't meet the conditions of A1, A2, and B, where in common fonts the resulting appearance of the sequence is normally distinct from the appearance in the same sequences with the joining controls removed. The following regular expressions describe sequences that typically result in distinct rendering. They use the notation explained below in [A1](#A1).

> /$L ZWNJ $V $L/
>
> /$L ZWJ $V $L/

#### 3.1.1.1 [Limited Contexts for Joining Controls](#Limited_Contexts_for_Joining_Controls)

An implementation that
attempts to provide more natural representations of terms in "modern, customary usage" should allow the
following Join\_Control characters in the limited contexts specified
in [A1](#A1), [A2](#A2), and [B](#B) below.

> U+200C ZERO WIDTH NON-JOINER (ZWNJ)
>  U+200D ZERO WIDTH JOINER
> (ZWJ)

There are also two global conditions incorporated in each of [A1](#A1), [A2](#A2), and [B](#B):

* **Script Restriction.** In each of the following cases,
  the specified sequence must only consist of characters from a single
  script (after ignoring *Common* and *Inherited* script
  characters).
* **Normalization.** In each of the following cases, the
  specified sequence must be in NFC format. (To test an identifier
  that is not required to be in NFC, first transform into NFC format
  and then test the condition.)

Implementations may also impose tighter restrictions than provided below, in order to eliminate some other circumstances where the characters either have no visual effect or the effect has no semantic importance.

**[A1](#A1). Allow ZWNJ in the
following context:**

**Breaking a cursive connection.**  That is, in the context based
on the Joining\_Type property, consisting of:

* A Left-Joining or Dual-Joining character, followed by zero
  or more Transparent characters, followed by a ZWNJ, followed by zero
  or more Transparent characters, followed by a Right-Joining or
  Dual-Joining character

This corresponds to the following regular expression (in Perl-style
syntax): **/$LJ $T\* ZWNJ $T\* $RJ/**

Where the character classes like $T could be
defined with Unicode properties
(similar to UnicodeSet notation) like this:

> $T = \p{Joining\_Type=Transparent}
>  $RJ =
> [\p{Joining\_Type=Dual\_Joining}\p{Joining\_Type=Right\_Joining}]
>
> $LJ = [\p{Joining\_Type=Dual\_Joining}\p{Joining\_Type=Left\_Joining}]

For example, consider Farsi <*Noon, Alef, Meem, Heh, Alef,
Farsi Yeh*>. Without a ZWNJ, it translates to "names",
as shown in the first row; with a ZWNJ between Heh and Alef, it means
"a letter", as shown in the second row of *Figure 1*.

Figure 1. [Persian Example with
ZWNJ](#Figure_Farsi_Example_with_ZWNJ)

| Appearance | Code Points | Abbreviated Names |
| --- | --- | --- |
| diagram1 | 0646 + 0627 + 0645 + 0647 + 0627 + 06CC | NOON + ALEF + MEEM + HEH + ALEF + FARSI YEH |
| diagram2 | 0646 + 0627 + 0645 + 0647 + 200C + 0627 + 06CC | NOON + ALEF + MEEM + HEH + ZWNJ + ALEF + FARSI YEH |

**[A2](#A2). Allow ZWNJ in the
following context:**

**In a conjunct context.** That is, a sequence of the form:

* A Letter, followed by a Virama, followed by a ZWNJ (optionally preceded or followed by certain nonspacing marks), followed by a Letter.

This corresponds to the following regular expression (in Perl-style
syntax): **/$L $M\* $V $M₁\* ZWNJ $M₁\* $L/**

Where:

> $L = \p{General\_Category=Letter}
>
> $V =
> \p{Canonical\_Combining\_Class=Virama}
>
> $M = \p{General\_Category=Mn}
>
> $M₁ = [\p{General\_Category=Mn}&\p{CCC≠0}]

For example, the Malayalam word for *eyewitness* is shown in *Figure
2*. The form without the ZWNJ in the second row is incorrect in this
case.

Figure 2. [Malayalam Example
with ZWNJ](#Figure_Malayalam_Example_with_ZWNJ)

| Appearance | Code Points | Abbreviated Names |
| --- | --- | --- |
| diagram3 | 0D26 + 0D43 + 0D15 + 0D4D + 200C + 0D38 + 0D3E + 0D15 + 0D4D + 0D37 + 0D3F | DA + VOWEL SIGN VOCALIC R + KA + VIRAMA + ZWNJ + SA + VOWEL SIGN AA + KA + VIRAMA + SSA + VOWEL SIGN I |
| diagram4 | 0D26 + 0D43 + 0D15 + 0D4D + 0D38 + 0D3E + 0D15 + 0D4D + 0D37 + 0D3F | DA + VOWEL SIGN VOCALIC R + KA + VIRAMA + SA + VOWEL SIGN AA + KA + VIRAMA + SSA + VOWEL SIGN I |

**[B](#B). Allow ZWJ in the
following context:**

**In a conjunct context.** That is, a sequence of the form:

* A Letter, followed by a Virama, followed by a ZWJ (optionally preceded or followed by certain nonspacing marks), and not followed by a character of type Indic\_Syllabic\_Category=Vowel\_Dependent

This corresponds to the following regular expression (in Perl-style
syntax):  **/$L $M\* $V $M₁\* ZWJ (?!$D)/**

Where:

> $L= \p{General\_Category=Letter}
>
> $V =
> \p{Canonical\_Combining\_Class=Virama}
>
> $M = \p{General\_Category=Mn}
>
> $M₁ = [\p{General\_Category=Mn}&\p{CCC≠0}]
>
> $D = \p{Indic\_Syllabic\_Category=Vowel\_Dependent}

For example, the Sinhala word for the country 'Sri Lanka' is
shown in the first row of *Figure 3*, which uses both a space
character and a ZWJ. Removing the space results in the text shown in
the second row of *Figure 3*, which is still legible, but
removing the ZWJ completely modifies the appearance of the
'Sri' cluster and results in the unacceptable text appearance
shown in the third row of *Figure 3*.

Figure 3. [Sinhala Example with
ZWJ](#Figure_Sinhala_Example_with_ZWJ)

| Appearance | Code Points | Abbreviated Names |
| --- | --- | --- |
| diagram5 | 0DC1 + 0DCA + 200D + 0DBB + 0DD3 + 0020 + 0DBD + 0D82 + 0D9A + 0DCF | SHA + VIRAMA + ZWJ + RA + VOWEL SIGN II + SPACE + LA + ANUSVARA + KA + VOWEL SIGN AA |
| diagram6 | 0DC1 + 0DCA + 200D + 0DBB + 0DD3 + 0DBD + 0D82 + 0D9A + 0DCF | SHA + VIRAMA + ZWJ + RA + VOWEL SIGN II + LA + ANUSVARA + KA + VOWEL SIGN AA |
| diagram7 | 0DC1 + 0DCA + 0DBB + 0DD3 + 0020 + 0DBD + 0D82 + 0D9A + 0DCF | SHA + VIRAMA + RA + VOWEL SIGN II + SPACE + LA + ANUSVARA + KA + VOWEL SIGN AA |

> **Note:** The restrictions in [A1](#A1),
> [A2](#A2), and [B](#B)
> are similar to the CONTEXTJ rules defined in *Appendix A, Contextual Rules Registry*,
> in *The Unicode Code Points and Internationalized Domain Names for Applications (IDNA)*
> [[IDNA2008](#IDNA2008)].

#### 3.1.1.2 [Limitations](#Limitations)

While the restrictions in [A1](#A1), [A2](#A2), and [B](#B) greatly
limit visual confusability, they do not prevent it. For example,
because Tamil only uses a Join\_Control character in one specific
case, most of the sequences these rules allow in Tamil are, in fact,
visually confusable. Therefore based on their knowledge of the script
concerned, implementations may choose to have tighter restrictions
than specified in *Section 3.1.1.2, [Limited Contexts for Joining Controls](#Limited_Contexts_for_Joining_Controls)*—for example, by explicitly providing for the exceptional sequence, while otherwise disallowing the joiner in context.

There are also cases where a joiner preceding a
virama makes a visual distinction in some scripts. It is currently
unclear whether this distinction is important enough in identifiers
to warrant retention of a joiner. For more information, see UTR #36: *Unicode Security Considerations* [[UTR36](#UTR36)].

***Performance.*** Parsing identifiers can be a
performance-sensitive task. However, these characters are quite rare
in practice, thus the regular expressions (or equivalent processing)
only rarely would need to be invoked. Thus these tests should not add
any significant performance cost overall.

### 3.2 [IDN Security Profiles for Identifiers](#IDN_Security_Profiles)

Version 1 of this document defined operations and data that apply to
[[IDNA2003](#IDNA2003)], which has been superseded by [[IDNA2008](#IDNA2008)] and Unicode Technical
Standard #46, "Unicode IDNA Compatibility
Processing" [[UTS46](#UTS46)]. The identifier
modification data can be applied to whichever specification of IDNA
is being used. For more information, see the [[IDN
FAQ](#IDN_FAQ)].

However, implementations can claim conformance to other features of
this document as applied to domain names, such as [Restriction Levels](#Restriction_Level_Detection).

### 3.3 [Email Security Profiles for Identifiers](#Email_Security_Profiles)

The *SMTP Extension for Internationalized Email* provides for specifications of internationalized email addresses [[EAI](#EAI)]. However, it does not provide for testing those addresses for security issues. This section provides an email security profile that may be used for that. It can be applied for different purposes, such as:

1. When an email address is registered, flag anything that
   does not meet the profile:
   * Either forbid the registration, or
   * Allow for an appeals process.
2. When an email address is detected in linkification of plain
   text:
   * Do not linkify if the identifier does not meet
     the profile.
3. When an email address is displayed in incoming email:
   * Flag it as suspicious with a wavy underline, if it
     does not meet the profile.
   * Filter characters from the quoted-string-part to prevent
     display problems.

This profile does not exclude characters from
EAI. Instead, it provides a profile that can be used for registration, linkification,
and notification. The goal is to flag
addresses that are structurally unsound or contain unexpected detritus.

An email address is formed from three main parts. (There are more elements of an email address, but these are the ones for which Unicode security is important.) For example:

> "Joey" <joe31834@gmail.com>
>
> * The **domain-part** is "gmail.com"
> * The **local-part** is "joe31834"
> * The **quoted-string-part** is "Joey"

To meet the requirements of the **Email Security Profiles for Identifiers** section of this specification, an identifier must satisfy the following
conditions for the specified <restriction level>.

#### Domain-Part

The domain-part of an email address must satisfy *Section 3.2, [IDN
Security Profiles for Identifiers](#IDN_Security_Profiles)*, and satisfy the conformance
clauses of [[UTS46](#UTS46)].

#### Local-Part

The local-part of an email address must satisfy all the following conditions:

1. It must be in NFKC format
2. It must have level = <restriction level> or less,
   from [Restriction\_Level\_Detection](#Restriction_Level_Detection)
3. It must not have mixed number systems according to [Mixed\_Number\_Detection](#Mixed_Number_Detection)
4. It must satisfy *dot-atom-text* from [RFC
   5322 §3.2.3](https://www.rfc-editor.org/rfc/rfc5322.html#section-3.2.3), where *atext* is extended as follows:

> Where C ≤ U+007F, C is defined as in
> [§3.2.3](https://www.rfc-editor.org/rfc/rfc5322.html#section-3.2.3).
> (That is, C ∈ [[!#-'\*+\-/-9=?A-Z\^-~](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=%5B%21%23-%27*%2B%5C-%2F-9%3D%3FA-Z%5C%5E-~%5D&abb=on&g=)].
> This list copies what is already in §3.2.3,
> and follows [HTML5](https://html.spec.whatwg.org/multipage/input.html#email-state-(type=email))
> for ASCII.)
>
> Where C > U+007F, both of the following conditions
> are true:
>
> 1. C has Identifier\_Status=Allowed from [General Security Profile](#General_Security_Profile)
> 2. If C is the first character, it must be XID\_Start from
>    [Default Identifier\_Syntax](https://www.unicode.org/reports/tr31/#Default_Identifier_Syntax) in [[UAX31](#UAX31)]

Note that in [RFC
5322 §3.2.3](https://www.rfc-editor.org/rfc/rfc5322.html#section-3.2.3):

> `dot-atom-text   =
>   1*atext *("." 1*atext)`

That is, dots can also occur in the local-part, but
not leading, trailing, or two in a row. In more conventional regex syntax, this would be:

> `dot-atom-text   =
>   atext+ ("." atext+)*`

Note that bidirectional controls and other format characters are
specifically disallowed in the local-part, according to the
above.

#### Quoted-String-Part

The quoted-string-part of an email address must
satisfy the following conditions:

1. It must be in NFC.
2. It must not contain any stateful bidirectional format characters.
   * That is, no [:bidicontrol:] except for the LRM, RLM, and ALM, since the bidirectional controls could influence the ordering of characters outside
     the quotes.
3. It must not contain more than four nonspacing marks in a row, and no
   sequence of two of the same nonspacing marks.
4. It may contain mixed scripts, symbols (including emoji),
   and so on.

#### Other Issues

The restrictions above are insufficient to
prevent bidirectional-reordering that could intermix the quoted-string-part
with the local-part or the domain-part in display. To prevent that,
implementations could use bidirectional isolates (or equivalent) around the
each of these parts in display.

Implementations may also want to use other checks, such as for confusability, or services such as Safe Browsing.

A serious practical issue is that clients do not know what the
identity rules are for any particular email server: that is, when two
email addresses are considered equivalent. For example, are *mark@macchiato.com*
and *Mark@macchiato.com* treated the same by the server?
Unfortunately, there is no way to query a server to see
what identity rules it follows. One of the techniques used to deal with
this problem is having whitelists of email providers indicating which of them are case-insensitive, dot-insensitive, or both.

## 4 [Confusable Detection](#Confusable_Detection)

The data in [[confusables](#confusables)] provide a
mechanism for determining when two strings are visually confusable.
The data in these files may be refined and extended over time. For
information on handling modifications over time, see *Section
2.10.1, Backward Compatibility* in Unicode Technical Report #36,
"Unicode Security Considerations" [[UTR36](#UTR36)]
and the [Migration](#Migration) section of this document.

Collection of data for detecting gatekeeper-confusable strings is not
currently a goal for the confusable detection mechanism in this
document. For more information, see *Section 2, Visual
Security Issues* in [[UTR36](#UTR36)].

The data provides a mapping from source characters to their prototypes. A prototype should be thought of as a sequence of one or more classes of symbols, where each class has an exemplar character. For example, the character U+0153 (œ), LATIN SMALL LIGATURE OE, has a prototype consisting of two symbol classes: the one with exemplar character U+006F (o), and the one with exemplar character U+0065 (e). If an input character does not have a prototype explicitly defined in the data file, the prototype is assumed to consist of the class of symbols with the input character as the exemplar character.

For an input string X, define [internalSkeleton](#def-internalSkeleton)(X) to be the following transformation on the string:

1. Convert X to NFD format, as described in [[UAX15](#UAX15)].
2. Remove any characters in X that have the property Default\_Ignorable\_Code\_Point.
3. Concatenate the prototypes for each character in X according to the specified data, producing a string of exemplar characters.
4. Reapply NFD.

For an input string X and a direction 𝑑 ∈ {RTL, LTR, FS}, define bidiSkeleton(𝑑, X) to be the following transformation on the string:

1. Reorder the code points in X for display by applying the rules of the Unicode Bidirectional Algorithm [[UAX9](#UAX9)] up to and including L2, treating X in isolation; if 𝑑≠FS, apply protocol HL1 to set the paragraph level to 1 if 𝑑=RTL, and to 0 if 𝑑=LTR; this yields the reordered sequence of characters R.
2. Apply rule L3 of the UBA: move combining marks after their base in R; this yields the sequence R′.
3. Replace any character whose glyph would be mirrored by rule L4 of the UBA by the value of its Bidi\_Mirroring\_Glyph property, yielding R″.
4. bidiSkeleton(𝑑, X) is then internalSkeleton(R″).

The strings X and Y are defined to be 𝑑-confusable if and only if bidiSkeleton(𝑑, X) = bidiSkeleton(𝑑, Y). This is abbreviated as X ≒ Y (𝑑).

This mechanism imposes transitivity on the data, so if X ≒ Y (𝑑) and Y ≒ Z (𝑑), then X ≒ Z (𝑑). It is possible to provide a more sophisticated confusable detection, by providing a metric between given characters, indicating their "closeness." However, that is computationally much more expensive, and requires more sophisticated data, so at this point in time the simpler mechanism has been chosen. That means that in some cases the test may be overly inclusive.

> **Note:** The operation *internalSkeleton* may change the Bidi\_Class of characters, so it does not commute with the reordering and mirroring steps, and needs to be performed after them.

> **Example:** The sequences of code points S₁ and S₂ are LTR-confusable:
>
> > S₁ ≔ "A1<שׂ" = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT SIN DOT)
> >
> > S₂ ≔ "Αשֺ>1" = (GREEK CAPITAL LETTER ALPHA, HEBREW LETTER SHIN, HEBREW POINT HOLAM HASER FOR VAV, GREATER-THAN SIGN, DIGIT ONE)
>
> Computation of bidiSkeleton(LTR, S₁):
>
> R₁ = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW POINT SIN DOT, HEBREW LETTER SHIN)
>
> R′₁ = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT SIN DOT)
>
> R″₁ = (LATIN CAPITAL LETTER A, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT SIN DOT)
>
> bidiskeleton(LTR, S₁) = internalSkeleton(R″₁) = (LATIN CAPITAL LETTER A, LATIN SMALL LETTER L, LESS-THAN SIGN, HEBREW LETTER SHIN, COMBINING DOT ABOVE)
>
> Computation of bidiSkeleton(LTR, S₂):
>
> R₂ = (GREEK CAPITAL LETTER ALPHA, DIGIT ONE, GREATER-THAN SIGN, HEBREW POINT HOLAM HASER FOR VAV, HEBREW LETTER SHIN)
>
> R′₂ = (GREEK CAPITAL LETTER ALPHA, DIGIT ONE, GREATER-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT HOLAM HASER FOR VAV)
>
> R″₂ = (GREEK CAPITAL LETTER ALPHA, DIGIT ONE, LESS-THAN SIGN, HEBREW LETTER SHIN, HEBREW POINT HOLAM HASER FOR VAV)
>
> bidiskeleton(LTR, S₂) = internalSkeleton(R″₂) = (LATIN CAPITAL LETTER A, LATIN SMALL LETTER L, LESS-THAN SIGN, HEBREW LETTER SHIN, COMBINING DOT ABOVE)
>
> Note that these sequences are not RTL-confusable; indeed in a right-to-left paragraph, the strings look distinct:
>
> > S₁ = "A1<שׂ"
> >
> > S₂ = "Αשֺ>1"

LTR, and RTL, and FS confusability should be used when it is inappropriate to enforce that strings be single-script,
or at least single-directionality; this is the case in programming language identifiers.
See *Section 5.1, Confusability Mitigation Diagnostics*, in
*Unicode Technical Standard #55, Unicode Source Code Handling* [[UTS55](#UTS55)].

The bidiSkeleton is costlier to compute than the internalSkeleton, as the bidirectional algorithm must be applied.
However, a fast path can be used: if 𝑑=LTR and X has no characters with bidi classes R or AL, bidiSkeleton(𝑑, X) = internalSkeleton(X).

Further, if the strings are known not to contain explicit directional formatting characters (as is the case for UAX31-R1 Default Identifiers
defined in *Unicode Standard Annex #31, Identifiers and Syntax* [[UAX31](#UAX31)]), the algorithm can be drastically simplified,
as the X rules are trivial, obviating the need for the directional status stack of the Unicode Bidirectional Algorithm.
The highest possible resolved level is then 2; see *Table 5, Resolving Implicit Levels*,
in *Unicode Standard Annex #9, Unicode Bidirectional Algorithm* [[UAX9](#UAX9)].

> **Note:** The strings *bidiSkeleton*(𝑑, X) and *bidiSkeleton*(𝑑, Y)
> are ***not*** intended for display.
> Further, they are not stable across versions of Unicode, so that
> they can only be interchanged between systems that use the same version of Unicode to compute *bidiSkeleton*.
> If they are stored, they must be recomputed when updating the version of Unicode used to compute *bidiSkeleton*.
> They should be thought of as an intermediate processing form,
> similar to a hashcode. The exemplar characters are ***not*** guaranteed to be identifier characters.

The use of bidirectional confusability with an appropriate direction is preferable when possible.
However, for cases where the direction with which identifiers will be displayed is unknown,
and for compatibility with earlier definitions of confusability which did not take bidirectional reordering into account,
the operation [skeleton](#def-skeleton) is
defined as skeleton(X) = bidiSkeleton(LTR, X). The strings X and Y are then
defined to be [confusable](#def-confusable) if and only if skeleton(X) = skeleton(Y). This is abbreviated as X ≅ Y.

> **Note:** Some implementations of confusable detection outside Unicode use different terminology.
> In particular, in the ICANN Root Zone Label Generation Rules [[RZLGR5](#RZLGR5)], the term
> *variant of X* is used for a property similar to *confusable with X*, and the term
> *index variant* is used for the equivalent of *skeleton*.

**Definitions**

Confusables are divided into three classes: single-script confusables, mixed-script confusables, and whole-script confusables, defined below. All confusables are either a single-script confusable or a mixed-script confusable, but not both. All whole-script confusables are also mixed-script confusables.

The definitions of these three classes of confusables depend on the definitions of *resolved script set* and *single-script*, which are provided in *Section 5, [Mixed-Script
Detection](#Mixed_Script_Detection)*.

X and Y are *[single-script confusables](#single_script_confusables)* if
and only if they are confusable, and their resolved script sets have at least one element in common.

> Examples: “ǉeto” and “ljeto” in Latin (the Croatian word for “summer”), where the first word uses only four codepoints, the first of which is U+01C9 (ǉ) LATIN SMALL LETTER LJ.

X and Y are *[mixed-script confusables](#mixed_script_confusables)* if
and only if they are confusable but their resolved script sets have no elements in common.

> Examples: "paypal" and "pаypаl", where the
> second word has the character [U+0430](https://util.unicode.org/UnicodeJsps/character.jsp?a=0430) ( а )
> CYRILLIC SMALL LETTER A.

X and Y are *[whole-script confusables](#def_whole_script_confusables)* if
and only if they are *mixed-script confusables,* and each of them is a
single-script string.

> Example: "scope" in Latin and "ѕсоре" in Cyrillic.

As noted in Section 5, the resolved script set ignores characters with Script\_Extensions {Common} and {Inherited} and augments characters with CJK scripts with their respective writing systems. Characters with the Script\_Extension property values COMMON or
INHERITED are ignored when testing for differences in script.

### Data File Format

Each line in the data file has the following format: Field 1 is
the source, Field 2 is the target, and Field 3 is obsolete, always containing the letters “MA” for backwards compatibility. For example:

> 0441 ; 0063 ; MA # ( с → c ) CYRILLIC SMALL LETTER ES → LATIN SMALL
> LETTER C #
>
> 2CA5 ; 0063 ; MA # ( ⲥ → c ) COPTIC SMALL LETTER SIMA → LATIN
> SMALL LETTER C # →ϲ→

Everything after the # is a comment and is purely informative. A
asterisk after the comment indicates that the character is not an XID
character [[UAX31](#UAX31)]. The comments provide the
character names.

Implementations that use the confusable data do not have to
recursively apply the mappings, because the transforms are
idempotent. That is,

*skeleton(skeleton(X)) = skeleton(X)*

If the data was derived via transitivity, there is
an extra comment at the end. For instance, in the above example the
derivation was:

1. ⲥ (U+2CA5 COPTIC SMALL LETTER SIMA)
2. → ϲ (U+03F2 GREEK LUNATE SIGMA SYMBOL)
3. → c (U+0063 LATIN SMALL LETTER C)

To reduce security risks, it is advised that identifiers use
casefolded forms, thus eliminating uppercase variants where possible.

The data may change between versions. Even where the data is the
same, the order of lines in the files may change between versions.
For more information, see [Migration](#Migration).

> **Note:** Due to production problems, versions
> before 7.0 did not maintain idempotency in all cases. For more
> information, see [Migration](#Migration).

### 4.1 [Whole-Script Confusables](#Whole_Script_Confusables)

For some applications, it is useful to determine if a given input string has any whole-script confusable. For example, the identifier "ѕсоре" using Cyrillic characters would pass the single-script test described in *Section 5.2, [Restriction-Level Detection](#Restriction_Level_Detection)*, even though it is likely to be a spoof attempt.

It is possible to determine whether a single-script string X has a whole-script confusable:

1. Consider Q, the set of all strings that are confusable with X.
2. Remove all strings from Q whose resolved script set intersects with the resolved script set of X.
3. If Q is nonempty and contains any single-script string, return TRUE.
4. Otherwise, return FALSE.

The logical description above can be used for a reference implementation for testing, but is not particularly efficient. A production implementation can be optimized as long as it produces the same results.

Note that the confusables data include a large number of mappings between Latin and Cyrillic text. For this reason, the above algorithm is likely to flag a large number of legitimate strings written in Latin or Cyrillic as potential whole-script confusables. To effectively use whole-script confusables, it is often useful to determine both whether a string has a whole-script confusable, and *which* scripts those whole-script confusables have.

This information can be used, for example, to distinguish between reasonable versus suspect whole-script confusables. Consider the Latin-script domain-name label “circle”. It would be appropriate to have that in the domain name “circle.com”. It would also be appropriate to have the Cyrillic confusable “сігсӀе” in the Cyrillic domain name “сігсӀе.рф”. However, a browser may want to alert the user to possible spoofs if the Cyrillic “сігсӀе” is used with .com or the Latin “circle” is used with .рф.

The process of determining suspect usage of whole-script confusables is more complicated than simply looking at the scripts of the labels in a domain name. For example, it can be perfectly legitimate to have scripts in a SLD (second level domain) not be the same as scripts in a TLD (top-level domain), such as:

* Cyrillic labels in a domain name with a TLD of .ru or .рф
* Chinese labels in a domain name with a TLD of .com.au or .com
* Cyrillic labels *that aren’t confusable* with Latin with a TLD of .com.au or .com

The following high-level algorithm can be used to determine all scripts that contain a whole-script confusable with a string X:

1. Consider Q, the set of all strings confusable with X.
2. Remove all strings from Q whose resolved script set is ∅ or **ALL** (that is, keep only single-script strings plus those with characters only in Common).
3. Take the union of the resolved script sets of all strings remaining in Q.

As usual, this algorithm is intended only as a definition; implementations should use an optimized routine that produces the same result.

### 4.2 [Mixed-Script Confusables](#Mixed_Script_Confusables)

To determine the existence of a mixed-script confusable, a similar process could be used:

1. Consider Q, the set of all strings that are confusable with X.
2. Remove all strings from Q whose resolved script set intersects with the resolved script set of X.
3. If Q is nonempty, return TRUE.
4. Otherwise, return FALSE.

The logical description above can be used for a reference implementation for testing, but is not particularly efficient. A production implementation can be optimized as long as it produces the same results.

Note that due to the number of mappings provided by the confusables data, the above algorithm is likely to flag a large number of legitimate strings as potential mixed-script confusables.

## 5 [Detection Mechanisms](#Detection_Mechanisms)

### 5.1 [Mixed-Script Detection](#Mixed_Script_Detection)

The Unicode Standard supplies information that can be used for
determining the script of characters and detecting mixed-script text.
The determination of script is according to the *UAX #24, Unicode Script Property* [[UAX24](#UAX24)], using data from the Unicode Character Database [[UCD](#UCD)].

Define a character's [augmented script set](#def-augmented-script-set) to be a character's Script\_Extensions with the following two modifications.

1. Entries for the writing systems containing multiple scripts — Hanb (Han with Bopomofo), Jpan (Japanese), and Kore (Korean) — are added according to the following rules.
   1. If Script\_Extensions contains Hani (Han), add Hanb, Jpan, and Kore.
   2. If Script\_Extensions contains Hira (Hiragana), add Jpan.
   3. If Script\_Extensions contains Kana (Katakana), add Jpan.
   4. If Script\_Extensions contains Hang (Hangul), add Kore.
   5. If Script\_Extensions contains Bopo (Bopomofo), add Hanb.
2. Sets containing Zyyy (Common) or Zinh (Inherited) are treated as **ALL**, the set of all script values.

The Script\_Extensions data is from the Unicode Character Database [[UCD](#UCD)]. For more information on the Script\_Extensions property and Jpan, Kore, and Hanb, see *UAX #24, Unicode Script Property* [[UAX24](#UAX24)].

Define the [resolved script set](#def-resolved-script-set) for a string to be the intersection of the augmented script sets over all characters in the string.

A string is defined to be [mixed-script](#def-mixed-script) if its resolved script set is empty and defined to be [single-script](#def-single-script) if its resolved script set is nonempty.
> **Note:** The term “*single*-script string” may be confusing. It means that there is *at least one* script in the resolved script set, not that there is *only one*. For example, the string “〆切” is single-script, because it has *four* scripts {Hani, Hanb, Jpan, Kore} in its resolved script set.

As well as providing an API to detect whether a string *has* mixed-scripts, is also useful to offer an API that returns those scripts.
Look at the examples below.

Table 1a. [Mixed Script Examples](#Mixed_Script_Examples)

| String | Code Point | Script\_Extensions | Augmented Script Sets | Resolved Script Set | Single-Script? |
| --- | --- | --- | --- | --- | --- |
| Circle | U+0043U+0069U+0072U+0063U+006CU+0065 | {Latn}{Latn}{Latn}{Latn}{Latn}{Latn} | {Latn}{Latn}{Latn}{Latn}{Latn}{Latn} | {Latn} | Yes |
| СігсӀе | U+0421U+0456U+0433U+0441U+04C0U+0435 | {Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl} | {Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl}{Cyrl} | {Cyrl} | Yes |
| Сirсlе | U+0421U+0069U+0072U+0441U+006CU+0435 | {Cyrl}{Latn}{Latn}{Cyrl}{Latn}{Cyrl} | {Cyrl}{Latn}{Latn}{Cyrl}{Latn}{Cyrl} | ∅ | No |
| Circ1e | U+0043U+0069U+0072U+0063U+0031U+0065 | {Latn}{Latn}{Latn}{Latn}{Zyyy}{Latn} | {Latn}{Latn}{Latn}{Latn} **ALL**{Latn} | {Latn} | Yes |
| C𝗂𝗋𝖼𝗅𝖾 | U+0043U+1D5C2U+1D5CBU+1D5BCU+1D5C5U+1D5BE | {Latn}{Zyyy}{Zyyy}{Zyyy}{Zyyy}{Zyyy} | {Latn} **ALL** **ALL** **ALL** **ALL** **ALL** | {Latn} | Yes |
| 𝖢𝗂𝗋𝖼𝗅𝖾 | U+1D5A2U+1D5C2U+1D5CBU+1D5BCU+1D5C5U+1D5BE | {Zyyy}{Zyyy}{Zyyy}{Zyyy}{Zyyy}{Zyyy} | **ALL** **ALL** **ALL** **ALL** **ALL****ALL** | **ALL** | Yes |
| 〆切 | U+3006U+5207 | {Hani, Hira, Kana}{Hani} | {Hani, Hira, Kana, Hanb, Jpan, Kore}{Hani, Hanb, Jpan, Kore} | {Hani, Hanb, Jpan, Kore} | Yes |
| ねガ | U+306DU+30AC | {Hira}{Kana} | {Hira, Jpan}{Kana, Jpan} | {Jpan} | Yes |

A set of scripts is defined to [cover](#def-cover) a string if the intersection of that set with the augmented script sets of all characters in the string is nonempty; in other words, if every character in the string shares at least one script with the cover set. For example, {Latn, Cyrl} covers "Сirсlе", the third example in [Table 1a](#Mixed_Script_Examples).

A cover set is defined to be [minimal](#def-minimal) if there is no smaller cover set. For example, {Hira, Hani} covers "〆切", the seventh example in [Table 1a](#Mixed_Script_Examples), but it is not minimal, since {Hira} also covers the string, and {Hira} is smaller than {Hira, Hani}. Note that minimal cover sets are not unique: a string may have different minimal cover sets.

Typically an API that returns the scripts in a string will return one of the minimal cover sets.

For computational efficiency, a set of script sets (SOSS) can be computed, where the augmented script sets for each character in the string map to one entry in the SOSS. For example, { {Latn}, {Cyrl} } would be the SOSS for "Сirсlе". A set of scripts that covers the SOSS also covers the input string. Likewise, the intersection of all entries of the SOSS will be the input string's resolved script set.

### 5.2 [Restriction-Level Detection](#Restriction_Level_Detection)

Restriction Levels 1-5 are defined here for use in implementations.
These place restrictions on the use of identifiers according to the
appropriate *identifier profile* as specified in *Section 3, [Identifier
Characters](https://www.unicode.org/reports/tr39/#Identifier_Characters)*. The lists of Recommended scripts are
taken from *[Table
5, Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)* of [[UAX31](#UAX31)]. For
more information on the use of Restriction Levels, see *Section
2.9, Restriction Levels and Alerts* in [[UTR36](#UTR36)].

For each of the Restriction Levels 1-6, the identifier must be well-formed according to whatever general syntactic constraints are in force, such as the Default Identifier Syntax in [[UAX31](#UAX31)].

In addition, an application may provide an *identifier profile* such as the [General Security Profile for Identifiers](#General_Security_Profile), which restricts the allowed characters further. For each of the Restriction Levels 1-5, characters in the string must also be in the *identifier profile*. Where there is no such *identifier profile*, Levels 5 and 6 are identical.

1. **[ASCII-Only](#ascii_only)**
   * All characters in the string are in the ASCII range.
2. **[Single Script](#single_script)**
   * The string qualifies as ASCII-Only, or
   * The string is [single-script](#def-single-script), according to the definition in Section 5.1.
3. **[Highly Restrictive](#highly_restrictive)**
   * The string qualifies as Single Script, or
   * The string is [covered](#def-cover) by any of the following sets of scripts, according to the definition in Section 5.1:
     + *Latin + Han + Hiragana + Katakana*; or equivalently: Latn + Jpan
     + *Latin + Han + Bopomofo*; or equivalently: Latn + Hanb
     + *Latin + Han + Hangul;* or equivalently: Latn + Kore
4. **[Moderately Restrictive](#moderately_restrictive)**
   * The string qualifies as Highly Restrictive, or
   * The string is [covered](#def-cover) by Latin and any one other Recommended script, except Cyrillic, Greek
5. **[Minimally Restrictive](#minimally_restrictive)**
   * There are no restrictions on the set of scripts that [cover](#def-cover) the string.
   * The only restrictions are the identifier well-formedness criteria and *identifier profile*, allowing arbitrary mixtures of scripts such as Ωmega, Teχ,
     HλLF-LIFE, Toys-Я-Us.
6. **[Unrestricted](#unrestricted)**
   * There are no restrictions on the script coverage of the string.
   * The only restrictions are the criteria on identifier well-formedness. Characters may be outside of the
     *identifier profile*.
   * This level is primarily for use in detection APIs, providing return value indicating that the string does not match any of the levels 1-5.

Note that in all levels except ASCII-Only, any character having Script\_Extensions {Common} or {Inherited} are allowed in the identifier, as long as those characters meet the *identifier profile* requirements.

These levels can be detected by reusing some of the mechanisms
of Section 5.1. For a given input string, the Restriction Level is
determined by the following logical process:

1. If the string contains any characters outside of the
   Identifier Profile, return **Unrestricted**.
2. If no character in the string is above 0x7F, return **ASCII-Only**.
3. Compute the string's SOSS according to Section 5.1.
4. If the SOSS is empty or the intersection of all entries in the SOSS is nonempty, return **Single Script**.
5. Remove all the entries from the SOSS that contain Latin.
6. If any of the following sets cover SOSS, return **Highly
   Restrictive.**
   * {*Kore*}
   * {*Hanb*}
   * {*Japn*}
7. If the intersection of all entries in the SOSS contains any single **Recommended**
   script except *Cyrillic* *or Greek*, return **Moderately
   Restrictive**.
8. Otherwise, return **Minimally Restrictive**.

The actual implementation of this algorithm can be optimized;
as usual, the specification only depends on the results.

### 5.3 [Mixed-Number Detection](#Mixed_Number_Detection)

There are three different types of numbers in Unicode. Only numbers
with General\_Category = Decimal\_Numbers (Nd) should be allowed in
identifiers. However, characters from different decimal number
systems can be easily confused. For example, [U+0660](https://util.unicode.org/UnicodeJsps/character.jsp?a=0660) ( ٠ )
ARABIC-INDIC DIGIT ZERO can be confused with [U+06F0](https://util.unicode.org/UnicodeJsps/character.jsp?a=06F0) ( ۰ )
EXTENDED ARABIC-INDIC DIGIT ZERO, and [U+09EA](https://util.unicode.org/UnicodeJsps/character.jsp?a=09EA) ( ৪ )
BENGALI DIGIT FOUR can be confused with [U+0038](https://util.unicode.org/UnicodeJsps/character.jsp?a=0038) ( 8 )
DIGIT EIGHT. There are other reasons for disallowing mixed number systems in identifiers, just as there are for mixing scripts.

For a given input string which does not contain non-decimal
numbers, the logical process of detecting mixed numbers is the
following:

For each character in the string:

1. Find the decimal number value for that character, if any.
2. Map the value to the unique zero character for that number
   system.

If there is more than one such zero character, then the string
contains multiple decimal number systems.

The actual implementation of this algorithm can be optimized; as
usual, the specification only depends on the results. The following
Java sample using [[ICU](#ICU)] shows how this can be done
:

```

    public UnicodeSet getNumberRepresentatives(String identifier) {
        int cp;
        UnicodeSet numerics = new UnicodeSet();
        for (int i = 0; i < identifier.length(); i += Character.charCount(i)) {
            cp = Character.codePointAt(identifier, i);
            // Store a representative character for each kind of decimal digit
            switch (UCharacter.getType(cp)) {
            case UCharacterCategory.DECIMAL_DIGIT_NUMBER:
                // Just store the zero character as a representative for comparison.
                // Unicode guarantees it is cp - value.
                numerics.add(cp - UCharacter.getNumericValue(cp));
                break;
            case UCharacterCategory.OTHER_NUMBER:
            case UCharacterCategory.LETTER_NUMBER:
                throw new IllegalArgumentException("Should not be in identifiers.");
            }
        }
        return numerics;
    }
...
    UnicodeSet numerics = getMixedNumbers(String identifier);
    if (numerics.size() > 1) reject(identifier, numerics);
```
### 5.4 [Optional Detection](#Optional_Detection)

There are additional enhancements that may be useful in spoof
detection, such as:

1. Check to see that all the characters are in the sets of
   exemplar characters for at least one language in the Unicode Common
   Locale Data Repository [[CLDR](#CLDR)].
2. Check for unlikely sequences of combining marks:
   1. Forbid sequences of the same nonspacing mark.
   2. Forbid sequences of more than 4 nonspacing marks (gc=Mn or gc=Me).
   3. Forbid sequences of base character + nonspacing mark that look the same as or confusingly similar to the base character alone (because the nonspacing mark overlays a portion of the base character). An example is U+0069 LOWERCASE LETTER I + U+0307 COMBINING DOT ABOVE.
3. Add support for detecting two distinct *sequences* that have identical representations. The current data files only handle cases where a single code point is confusable with another code point or sequence. It does not handle cases like *shri*, as below.

The characters U+0BB6 TAMIL LETTER SHA and U+0BB8 TAMIL LETTER SA are normally quite distinct. However, they can both be used in the representation of the Tamil word *shri*. On some very common platforms, the following sequences result in exactly the same visual appearance:

| U+0BB6 | U+0BCD | U+0BB0 | U+0BC0 |
| --- | --- | --- | --- |
| SHA | VIRAMA | RA | II |
| ஶ | ் | ர | ◌ீ | ``` = ஶ்ரீ ``` |

| U+0BB8 | U+0BCD | U+0BB0 | U+0BC0 |
| --- | --- | --- | --- |
| SA | VIRAMA | RA | II |
| ஸ | ் | ர | ◌ீ | ``` = ஸ்ரீ ``` |

## 6 [Development Process](#Development_Process)

As discussed in Unicode Technical
Report #36, "Unicode Security Considerations" [[UTR36](#UTR36)], confusability among characters cannot be
an exact science. There are many factors that make confusability a
matter of degree:

* Shapes of characters vary greatly among fonts used to
  represent them. The Unicode Standard uses representative glyphs in
  the code charts, but font designers are free to create their own
  glyphs. Because fonts can easily be created using an arbitrary glyph
  to represent any Unicode code point, character confusability with
  arbitrary fonts can never be avoided. For example, one could design
  a font where the ‘a’ looks like a ‘b’ , ‘c’ like a ‘d’, and so on.
* Writing systems using contextual shaping (such as Arabic and many South Asian systems) introduce even more variation in text
  rendering. Characters do not really have an abstract shape in
  isolation and are only rendered as part of cluster of characters
  making words, expressions, and sentences. It is a fairly common
  occurrence to find the same visual text representation corresponding
  to very different logical words that can only be recognized by
  context, if at all.
* Font style variants such as italics may introduce a
  confusability which does not exist in another style. For example, in
  the Cyrillic script, the [U+0442](https://util.unicode.org/UnicodeJsps/character.jsp?a=0442) ( т )
  CYRILLIC SMALL LETTER TE looks like a small caps Latin ‘T’ in normal
  style, while it looks like a small Latin ‘m’ in italic style.

In-script confusability is extremely user-dependent. For example, in
the Latin script, characters with accents or appendices may look
similar to the unadorned characters for some users, especially if
they are not familiar with their meaning in a particular language.
However, most users will have at least a minimum understanding of the
range of characters in their own script, and there are separate
mechanisms available to deal with other scripts, as discussed in [[UTR36](#UTR36)].

As described elsewhere, there are cases where the confusable data may
be different than expected. Sometimes this is because two characters
or two strings may only be confusable in some fonts. In other cases,
it is because of transitivity. For example, the dotless and dotted I
are considered equivalent (ı ↔ i), because they look the same when
accents such as an *acute* are applied to each. However, for
practical implementation usage, transitivity is sufficiently
important that some oddities are accepted.

The data may be enhanced in future versions of this
specification. For information on handling changes in data over
time, see *2.10.1, Backward Compatibility* of [[UTR36](#UTR36)].

### 6.1 [Confusables Data Collection](#Data_Collection)

The confusability data was created by collecting a number of
prospective confusables, examining those confusables according to a
set of common fonts, and processing the result for transitive
closure.

The primary goal is to include characters that would be Identifier\_Status=Allowed
as in *Table 1, [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)*. Other characters, such as NFKC
variants, are not a primary focus for data collection. However, such
variants may certainly be included in the data, and may be submitted
using the online forms at [[Feedback](#Feedback)].

The prospective confusables were gathered from a number of
sources. Erik van der Poel contributed a list derived from running a
program over a large number of fonts to catch characters that shared
identical glyphs within a font, and Mark Davis did the same more
recently for fonts on Windows and the Macintosh. Volunteers from
Google, IBM, Microsoft and other companies gathered other lists of
characters. These included native speakers for languages with
different writing systems. The Unicode compatibility mappings were
also used as a source. The process of gathering visual confusables is
ongoing: the Unicode Consortium welcomes submission of additional
mappings. The complex scripts of South and Southeast Asia need
special attention. The focus is on characters that have Identifier\_Status=Allowed, because they are of most
concern.

The fonts used to assess the confusables included those used by
the major operating systems in user interfaces. In addition, the
representative glyphs used in the Unicode Standard were also
considered. Fonts used for the user interface in operating systems
are an important source, because they are the ones that will usually
be seen by users in circumstances where confusability is important,
such such as when using IRIS (Internationalized Resource Identifiers)
and their sub-elements (such as domain names). These fonts have a
number of other relevant characteristics:

* They rarely changed in updates to operating systems and
  applications; changes brought by system upgrades tend to be gradual
  to avoid usability disruption.
* Because user interface elements need to be legible at low
  screen resolution (implying a low number of pixels per EM), fonts
  used in these contexts tend to be designed in sans-serif style,
  which has the tendency to increase the possibility of confusables.
  There are, however, some languages such as Chinese where a serif
  style is in common use.
* Strict bounding box requirements create even more
  constraints for scripts which use relatively large ascenders and
  descenders. This also limits space allocated for accent or tone
  marks, and can also create more opportunities for confusability.

Pairs of prospective confusables were removed if they were always
visually distinct at common sizes, both within and across fonts. The
data was then closed under transitivity, so that if X≅Y and Y≅Z, then
X≅Z. In addition, the data was closed under substring operations, so
that if X≅Y then AXB≅AYB. It was then processed to produce the
in-script and cross-script data, so that a single data table can be
used to map an input string to a resulting *skeleton*.

A skeleton is intended *only* for internal use for testing
confusability of strings; the resulting text is not suitable for
display to users, because it will appear to be a hodgepodge of
different scripts. In particular, the result of mapping an identifier
will not necessary be an identifier. Thus the confusability mappings
can be used to test whether two identifiers are confusable (if their
skeletons are the same), but should definitely not be used as a
"normalization" of identifiers.

### 6.2 [Identifier Modification Data Collection](#IDMOD_Data_Collection)

The **idmod** data is gathered in the following way. The
basic assignments are derived based on UCD character properties,
information in [[UAX31](#UAX31)], and a curated list of
exceptions based on information from various sources, including the
core specification of the Unicode Standard, annotations in the code
charts, information regarding CLDR exemplar characters, and external
feedback.

The first condition that matches in the order of the items from top
to bottom in [Table 1.
Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type) is used, with a few exceptions:

1. When a character is in
   *Table 3a, [Optional Characters for Medial](https://www.unicode.org/reports/tr31/#Table_Optional_Medial)*
   or *Table 3b, [Optional Characters for Continue](https://www.unicode.org/reports/tr31/#Table_Optional_Continue)* in [[UAX31](#UAX31)], then it is given the Identifier\_Type=Inclusion,
   regardless of other properties.
2. When the Script\_Extensions property value for a character
   contains multiple Script property values, the Script used for the
   derivation is the first in the following list:
   1. *Table 5,
      [Recommended Scripts](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*
   2. *Table 7,
      [Limited Use Scripts](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)*
   3. *Table 4,
      [Excluded Scripts](https://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*

The script information in *[Table
4](https://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*, *[Table
5](https://www.unicode.org/reports/tr31/#Table_Recommended_Scripts)*, and *[Table
7](https://www.unicode.org/reports/tr31/#Table_Limited_Use_Scripts)* is in machine-readable form in CLDR, as scriptMetadata.txt.

## 7 [Data Files](#Data_Files)

The following files provide data used to implement the
recommendations in this document. The data may be refined in future
versions of this specification. For more information,
see *2.10.1, Backward Compatibility* of [[UTR36](#UTR36)].
For illustration, this UTS shows sample data values, but for the
actual data for the current version of Unicode always refer to the data files.

> *The Unicode Consortium welcomes feedback
> on additional confusables or identifier restrictions. There are
> online forms at [[Feedback](#Feedback)] where you can
> suggest additional characters or corrections.*

The files are in <https://www.unicode.org/Public/security/>.
The directories there contain data files associated with a given
version. The directory for *this* version is:

> <https://www.unicode.org/Public/security/16.0/>

The data files for the latest approved version are also in the
directory:

> [https://www.unicode.org/Public/security/latest](https://www.unicode.org/Public/security/latest%20)

The format for IdentifierStatus.txt follows the normal conventions for
UCD data files, and is described in the header of that file.
All characters not listed in the file default to Identifier\_Status=Restricted.
Thus the file only lists characters with Identifier\_Status=Allowed.
For example:

`002D..002E ; Allowed # 1.1 HYPHEN-MINUS..FULL STOP`

The format for IdentifierType.txt follows the normal conventions for UCD
data files, and is described in the header of that file. The value is a
set whose elements are delimited by spaces. This format is identical to
that used for ScriptExtensions.txt. This differs from prior versions
which only listed the strongest reason for exclusion. This new convention
allows the values to be used for more nuanced filtering. For example,
if an implementation wants to allow an Exclusion script, it could still
exclude Obsolete and Not\_XID characters in that script.
All characters not listed in the file default to Identifier\_Type=Not\_Character.
For example:

`2460..24EA ; Technical Not_XID Not_NFKC # 1.1 CIRCLED DIGIT ONE..CIRCLED DIGIT ZERO`

Both of these files have machine-readable `# @missing` lines
for the default property values, as in many UCD files.
For details about this syntax see
*Section 4.2.10, [@missing Conventions](https://www.unicode.org/reports/tr44/#Missing_Conventions)*
in [[UAX44](#UAX44)].

Table 2. [Data File List](#Data_File_List)

| Reference | File Name(s) | Contents |
| --- | --- | --- |
| [[idmod](#idmod)] | IdentifierStatus.txt IdentifierType.txt | **Identifier\_Type** and **Identifier\_Status:** Provides the list of additions and restrictions recommended for building a profile of identifiers for environments where security is at issue. |
| [[confusables](#confusables)] | confusables.txt | **Visually Confusable Characters:** Provides a mapping for visual confusables for use in detecting possible security problems. The usage of the file is described in *Section 4, [Confusable Detection](#Confusable_Detection).* |
| [[confusablesSummary](#confusablesSummary)] | confusablesSummary.txt | **A summary view of the confusables:** Groups each set of confusables together, listing them first on a line starting with #, then individually with names and code points. See *Section 4, [Confusable Detection](#Confusable_Detection)* |
| [[intentional](#intentional)] | intentional.txt | **Intentional Confusable Mappings:** A selection of characters whose glyphs in any particular typeface would probably be designed to be identical in shape when using a harmonized typeface design. |

## [Migration](#Migration)

Beginning with version 6.3.0, the version numbering of this
document has been changed to indicate the version of the UCD that the
data is based on. For versions up to and including 6.3.0, the
following table shows the correspondence between the versions of this
document and UCD versions that they were based on.

Table 3. [Version Correspondence](#Version_Correspondance)

| Version | Release Date | Data File Directory | UCD Version | UCD Date |
| --- | --- | --- | --- | --- |
| Version 1 | 2006-08-15 | /Public/security/revision-02/ | 5.1.0 | 2008-04 |
| *draft only* | 2010-04-12 | /Public/security/revision-03/ | *n/a* | *n/a* |
| Version 2 | 2010-08-05 | /Public/security/revision-04/ | 6.0.0 | 2010-10 |
| Version 3 | 2012-07-23 | /Public/security/revision-05/ | 6.1.0 | 2012-01 |
| 6.3.0 | 2013-11-11 | /Public/security/6.3.0/ | 6.3.0 | 2013-09 |

 If an update version of this standard is required between
the associated UCD versions, the version numbering will include an
update number in the 3rd field. For example, if a version of this
document and its associated data is needed between UCD 6.3.0 and UCD
7.0.0, then a version 6.3.**1** could be used.

### [Migrating Persistent Data](#Migrating_Persistent_Data)

Implementations must migrate their persistent data stores (such
as database indexes) whenever those implementations update to use the
data files from a new version of this specification.

Stability is never guaranteed between versions, although it is
maintained where feasible. In particular, an updated version of
confusable mapping data may use a mapping for a particular character
that is different from the mapping used for that character in an
earlier version. Thus there may be cases where X → Y in Version N,
and X → Z in Version N+1, where Z may or may not have mapped to Y in
Version N. Even in cases where the logical data has not changed
between versions, the order of lines in the data files may have been
changed.

The Identifier\_Status does not have stability guarantees (such as “Once a character is Allowed, it will not become Restricted in future versions”), because the data is changing over time as we find out more about character usage. Certain of the Identifier\_Type values, such as Not\_XID, are backward compatible but most may change as new data becomes available. The identifier data may also not appear to be completely consistent when just viewed from the perspective of script and general category. For example, it may well be that one character out of a set of nonspacing marks in a script is Restricted, while others are not. But that can be just a reflection of the fact that that character is obsolete and the others are not.

For identifier lookup, the data is aimed more at flagging possibly questionable characters, thus serving as one factor (among perhaps many, like using the "Safe Browsing" service) in determining whether the user should be notified in some way. For registration, flagged characters can result in a "soft no", that is, require the user to appeal a denial with more information.

For dealing with characters whose status changes to Restricted, implementations can use a grandfathering mechanism to maintain backwards compatibility.

Implementations should therefore have a strategy for migrating
their persistent data stores (such as database indexes) that use any
of the confusable mapping data or other data files.

### [Version 13.0 Migration](#Version_13_Migration)

As of Unicode 13.0, the Identifier\_Status and Identifier\_Type are consistently written with underbars. This may cause parsers to malfunction, those that do not follow Unicode conventions for matching of property names.

### [Version 10.0 Migration](#Version_10_Migration)

As of Unicode 10.0, Identifier\_Type=Aspirational is now empty; for more information, see [[UAX31](#UAX31)].

### [Version 9.0 Migration](#Version_9_Migration)

There is an important data format change between versions 8.0 and 9.0. In particular, the xidmodifications.txt file from Version 8.0 has been split into two files for Version 9.0: IdentifierStatus.txt and IdentifierType.txt.

| Version 9.0 | Version 8.0 |
| --- | --- |
| Field 1 of IdentifierStatus.txt | Field 1 of xidmodifications.txt |
| Field 1 of IdentifierType.txt | Field 2 of xidmodifications.txt |

Multiple values are listed in field 1 of IdentifierType.txt. To convert to the old format of xidmodifications.txt, use the *last* value of that field. For example, the following values would correspond:

| File | Field | Content |
| --- | --- | --- |
| IdentifierType.txt | 1 | `180A ; Limited_Use Exclusion Not_XID` |
| xidmodifications.txt | 2 | `180A ; Restricted ; Not_XID` |

### [Version 8.0 Migration](#Version_8_Migration)

In Version 8.0, the following changes were made to the
Identifier\_Status and Identifier\_Type:

* Changed to the standard UCD formatting. For example, *limited-use*
  → *Limited\_Use*.
  + Usually this was simply changing the case and hyphen, but
    *not-chars* changed to *Not\_Character*.
* Aligned the Identifier\_Type better with UAX 31 and Unicode
  properties
  + historic
    - → Exclusion, where from *Table 4,
      [Candidate Characters for Exclusion from Identifiers](https://www.unicode.org/reports/tr31/tr31-23.html#Table_Candidate_Characters_for_Exclusion_from_Identifiers)*,
    - → Obsolete, otherwise
  + limited-use
    - → Limited\_Use, where from *Table 7,
      [Limited Use Scripts](https://www.unicode.org/reports/tr31/tr31-23.html#Table_Limited_Use_Scripts)*,
    - → Aspirational, where from *Table 6,
      [Aspirational Use Scripts](https://www.unicode.org/reports/tr31/tr31-23.html#Aspirational_Use_Scripts)* (later incorporated into Limited\_Use
      in Version 10.0)
    - → Uncommon-Use, otherwise
  + obsolete
    - → Deprecated, where matching the Unicode property

### [Version 7.0 Migration](#Version_7_Migration)

Due to production problems, versions of the confusable mapping
tables before 7.0 did not maintain idempotency in all cases, so
updating to version 8.0 is strongly advised.

Anyone using the skeleton mappings needs to rebuild any
persistent uses of skeletons, such as in database indexes.

The SL, SA, and ML mappings in 7.0 were significantly changed
to address the idempotency problem. However, the tables SL, SA, and
ML were still problematic, and discouraged from use in 7.0. They were
thus removed from version 8.0.

All of the data necessary for an implementation to recreate the
removed tables is available in the remaining data (MA) plus the
Unicode Character Database properties (script, casing, etc.). Such a
recreation would examine each of the equivalence classes from the MA
data, and filter out instances that did not fit the constraints (of
script or casing). For the target character, it would choose the most
neutral character, typically a symbol. However, the reasons for
deprecating them still stand, so it is not recommended that
implementations recreate them.

Note also that as the Script\_Extensions data is made more complete,
it may cause characters in the whole-script confusables data file to
no longer match. For more information, see *Section 4, [Confusable Detection](#Confusable_Detection)*.

## [Acknowledgments](#Acknowledgments)

Mark Davis and Michel Suignard authored the bulk of the
text, under direction from the Unicode Technical Committee. Steven
Loomis and other people on the ICU team were very helpful in
developing the original proposal for this technical report. Shane Carr analyzed the algorithms and supplied the source text for the rewrite of Sections 4 and 5 in version 10.

The attendees of the Source Code Working Group meetings assisted with the substantial changes made in Versions 15.0 and 15.1:
Peter Constable,
Elnar Dakeshov,
Mark Davis,
Barry Dorrans,
Steve Dower,
Michael Fanning,
Asmus Freytag,
Dante Gagne,
Rich Gillam,
Manish Goregaokar,
Tom Honermann,
Jan Lahoda,
Nathan Lawrence,
Robin Leroy,
Chris Ries,
Markus Scherer,
Richard Smith.

Thanks
also to the following people for their feedback or contributions to
this document or earlier versions of it, or to the source data for
confusables or idmod: Julie Allen, Andrew Arnold, Vernon Cole, David Corbett (specal thanks for the many contributions),
Douglas Davidson, Rob Dawson, Alex Dejarnatt, Chris Fynn, Martin Dürst, Asmus Freytag, Deborah
Goldsmith, Manish Goregaokar, Paul Hoffman, Ned Holbrook, Denis Jacquerye, Cibu Johny, Patrick L.
Jones, Peter Karlsson, Robin Leroy, Mike Kaplinskiy, Gervase Markham, Eric Muller,
David Patterson, Erik van der Poel, Roozbeh Pournader, Michael van Riper, Marcos Sanz,
Alexander Savenkov, Markus Scherer, Dominikus Scherkl, Manuel Strehl, Chris Weber, Ken Whistler,
and Waïl Yahyaoui. Thanks to Peter Peng for his assistance with font
confusables.

## [References](#References)

| [[CLDR](#CLDR)] | Unicode Locales Project (Unicode Common Locale Data Repository) <http://cldr.unicode.org/> |
| --- | --- |
| [[DCore](#DCore)] | Derived Core Properties <https://www.unicode.org/Public/UCD/latest/ucd/DerivedCoreProperties.txt> |
| [[DemoConf](#DemoConf)] | <https://util.unicode.org/UnicodeJsps/confusables.jsp> |
| [[DemoIDN](#DemoIDN)] | <https://util.unicode.org/UnicodeJsps/idna.jsp> |
| [[DemoIDNChars](#DemoIDNChars)] | [https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=\p{age%3D3.2}-\p{cn}-\p{cs}-\p{co}&abb=on&uts46+idna+idna2008](https://util.unicode.org/UnicodeJsps/list-unicodeset.jsp?a=\p{age%3D3.2}-\p{cn}-\p{cs}-\p{co}&abb=on&g=uts46+idna+idna2008) |
| [[EAI](#EAI)] | <https://www.rfc-editor.org/info/rfc6531> |
| [[FAQSec](#FAQSec)] | Unicode FAQ on Security Issues <https://www.unicode.org/faq/security.html> |
| [[Feedback](#Feedback)] | *To suggest additions or changes to confusables or identifier restriction data, please see:* <https://www.unicode.org/reports/tr39/suggestions.html>   *For issues in the text, please see:* Reporting Errors and Requesting Information Online<https://www.unicode.org/reporting.html> |
| [[ICANN](#ICANN)] | ICANN Documents: Internationalized Domain Names <https://www.icann.org/en/topics/idn/> The IDN Variant Issues Project <https://www.icann.org/en/topics/new-gtlds/idn-vip-integrated-issues-23dec11-en.pdf> Maximal Starting Repertoire Version 2 (MSR-2) <https://www.icann.org/news/announcement-2-2015-04-27-en> |
| [[ICU](#ICU)] | International Components for Unicode <http://site.icu-project.org/> |
| [[IDNA2003](#IDNA2003)] | The IDNA2003 specification is defined by a cluster of IETF RFCs:  * IDNA [[RFC3490](#RFC3490)] * Nameprep [[RFC3491](#RFC3491)] * Punycode [[RFC3492](#RFC3492)] * Stringprep [[RFC3454](#RFC3454)]. |
| [[IDNA2008](#IDNA2008)] | The IDNA2008 specification is defined by a cluster of IETF RFCs:  * Internationalized Domain Names for Applications (IDNA):   Definitions and Document Framework <https://www.rfc-editor.org/info/rfc5890> * Internationalized Domain Names in Applications (IDNA)   Protocol <https://www.rfc-editor.org/info/rfc5891> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) <https://www.rfc-editor.org/info/rfc5892> * Right-to-Left Scripts for Internationalized Domain Names   for Applications (IDNA) <https://www.rfc-editor.org/info/rfc5893>  There are also informative documents:  * Internationalized Domain Names for Applications (IDNA):   Background, Explanation, and Rationale <https://www.rfc-editor.org/info/rfc5894> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) - Unicode 6.0 <https://www.rfc-editor.org/info/rfc6452> |
| [[IDN-FAQ](#IDN_FAQ)] | <https://www.unicode.org/faq/idn.html> |
| [[Reports](#Reports)] | Unicode Technical Reports <https://www.unicode.org/reports/>*For information on the status and development process for technical reports, and for a list of technical reports.* |
| [[RFC3454](#RFC3454)] | P. Hoffman, M. Blanchet. "Preparation of Internationalized Strings ("stringprep")", RFC 3454, December 2002. <https://www.rfc-editor.org/info/rfc3454> |
| [[RFC3490](#RFC3490)] | Faltstrom, P., Hoffman, P. and A. Costello, "Internationalizing Domain Names in Applications (IDNA)", RFC 3490, March 2003. <https://www.rfc-editor.org/info/rfc3490> |
| [[RFC3491](#RFC3491)] | Hoffman, P. and M. Blanchet, "Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)", RFC 3491, March 2003. <https://www.rfc-editor.org/info/rfc3491> |
| [[RFC3492](#RFC3492)] | Costello, A., "Punycode: A Bootstring encoding of Unicode for Internationalized Domain Names in Applications (IDNA)", RFC 3492, March 2003. <https://www.rfc-editor.org/info/rfc3492> |
| [[RZLGR5](#RZLGR5)] | Integration Panel, “Integration Panel: Root Zone Label Generation Rules — LGR-5”, 22 May 2022 <https://www.icann.org/sites/default/files/lgr/rz-lgr-5-overview-26may22-en.pdf> |
| [[Security-FAQ](#Security-FAQ)] | <https://www.unicode.org/faq/security.html> |
| [[UCD](#UCD)] | Unicode Character Database. <https://www.unicode.org/ucd/> *For an overview of the Unicode Character Database and a list of its associated files.* |
| [[UCDFormat](#UCDFormat)] | UCD File Format <https://www.unicode.org/reports/tr44/#Format_Conventions> |
| [[UAX9](#UAX9)] | UAX #9: *Unicode Bidirectional Algorithm* <https://www.unicode.org/reports/tr9/> |
| [[UAX15](#UAX15)] | UAX #15: *Unicode Normalization Forms* <https://www.unicode.org/reports/tr15/> |
| [[UAX24](#UAX24)] | UAX #24: Unicode Script Property <https://www.unicode.org/reports/tr24/> |
| [[UAX29](#UAX29)] | UAX #29: *Unicode Text Segmentation* <https://www.unicode.org/reports/tr29/> |
| [[UAX31](#UAX31)] | UAX #31: *Unicode Identifier and Pattern Syntax* <https://www.unicode.org/reports/tr31/> |
| [[UAX44](#UAX44)] | UAX #44: *Unicode Character Database* <https://www.unicode.org/reports/tr44/> |
| [[Unicode](#Unicode)] | The Unicode Standard*For the latest version, see:* <https://www.unicode.org/versions/latest/> |
| [[UTR23](#UTR23)] | UTR #23: *The Unicode Character Property Model* <https://www.unicode.org/reports/tr23/> |
| [[UTR36](#UTR36)] | UTR #36: *Unicode Security Considerations* <https://www.unicode.org/reports/tr36/> |
| [[UTS18](#UTS18)] | UTS #18: *Unicode Regular Expressions* <https://www.unicode.org/reports/tr18/> |
| [[UTS39](#UTS39)] | UTS #39: Unicode Security Mechanisms <https://www.unicode.org/reports/tr39/> |
| [[UTS46](#UTS46)] | Unicode IDNA Compatibility Processing <https://www.unicode.org/reports/tr46/> |
| [[UTS55](#UTS55)] | Unicode Source Code Handling <https://www.unicode.org/reports/tr55/> |
| [[Versions](#Versions)] | Versions of the Unicode Standard <https://www.unicode.org/standard/versions/> *For information on version numbering, and citing and referencing the Unicode Standard, the Unicode Character Database, and Unicode Technical Reports.* |

## [Modifications](#Modifications)

The following summarizes modifications from the previous
published version of this document.

**Revision 30**

* **Reissued** for Unicode 16.0
* **Section 3, Table 1. [Identifier\_Status and Identifier\_Type](#Identifier_Status_and_Type)**:
  Noted that Uncommon\_Use may be combined with Exclusion or Limited\_Use.
* **Section 4 [Confusable Detection](#Confusable_Detection)**: Updated the definitions of *skeleton* and *confusable* to be aliases for *bidiSkeleton(LTR, -)* and *LTR-confusable*.
* **Section 7 [Data Files](#Data_Files)**: Fixed various typos.

Modifications for previous versions are listed in those respective versions.

---

© 2006–2024 Unicode, Inc. This publication is protected by copyright, and permission must be obtained from Unicode, Inc. prior to any reproduction, modification, or other use not permitted by the [Terms of Use](https://www.unicode.org/copyright.html). Specifically, you may make copies of this publication and may annotate and translate it solely for personal or internal business purposes and not for public distribution, provided that any such permitted copies and modifications fully reproduce all copyright and other legal notices contained in the original. You may not make copies of or modifications to this publication for public distribution, or incorporate it in whole or in part into any product or publication without the express written permission of Unicode.

Use of all Unicode Products, including this publication, is governed by the Unicode [Terms of Use](https://www.unicode.org/copyright.html). The authors, contributors, and publishers have taken care in the preparation of this publication, but make no express or implied representation or warranty of any kind and assume no responsibility or liability for errors or omissions or for consequential or incidental damages that may arise therefrom. This publication is provided “AS-IS” without charge as a convenience to users.

Unicode and the Unicode Logo are registered trademarks of Unicode, Inc., in the United States and other countries.



=== Content from www.kb.cert.org_06a463ed_20250111_024726.html ===


search

menu

icon-carat-right

cmu-wordmark

* ×
* [Home](/vuls/)
* [Notes](/vuls/bypublished/desc/)
* [Search](/vuls/search/)
* [Report a Vulnerability](/vuls/report/)
* [Disclosure Guidance](/vuls/guidance/)
* [VINCE](/vince/)

[[Carnegie Mellon University](https://www.cmu.edu)](https://www.cmu.edu/)

# [Software Engineering Institute](https://www.sei.cmu.edu/)

## CERT Coordination Center

* [Home](/vuls/)
* [Notes](/vuls/bypublished/desc/)
* [Search](/vuls/search/)
* [Report a Vulnerability](/vuls/report/)
* [Disclosure Guidance](/vuls/guidance/)
* [VINCE](/vince/)

* [Home](/vuls/)
* [Notes](/vuls/bypublished/desc/)
* Current:  VU#999008

## Compilers permit Unicode control and homoglyph characters

#### Vulnerability Note VU#999008

Original Release Date: 2021-11-09 | Last Revised: 2024-12-10

---

### Overview

Attacks that allow for unintended control of Unicode and homoglyphic characters, described by the researchers in this [report](https://www.trojansource.codes/trojan-source.pdf) leverage text encoding that may cause source code to be interpreted differently by a compiler than it appears visually to a human reviewer. Source code compilers, interpreters, and other development tools may permit Unicode control and homoglyph characters, changing the visually apparent meaning of source code.

### Description

Internationalized text encodings require support for both left-to-right languages and also right-to-left languages. Unicode has built-in functions to allow for encoding of characters to account for bi-directional, or Bidi ordering. Included in these functions are characters that represent non-visual functions. These characters, as well as characters from other human language sets (i.e., English vs. Cyrillic) can also introduce ambiguities into the code base if improperly used.

This type of attack could potentially be used to compromise a code base by capitalizing on a gap in visually rendered source code as a human reviewer would see and the raw code that the compiler would evaluate.

### Impact

The use of attacks that incorporate maliciously encoded source code may go undetected by human developers and by many automated coding tools. These attacks also work against many of the compilers currently in use. An attacker with the ability to influence source code could introduce undetected ambiguity into source code using this type of attack.

### Solution

The simplest defense is to ban the use of text directionality control characters both in language specifications and in compilers implementing these languages.

Two CVEs were assigned to address the two types of attacks described in this report.

CVE-2021-42574 was created for tracking the Bidi attack.
CVE-2021-42694 was created for tracking the homoglyph attack.

### Acknowledgements

Thanks to the reporters, Nicholas Boucher and Ross Anderson of The University of Cambridge (UK).

This document was written by Chuck Yarbrough.

### Vendor Information

999008
Filter by status:
All
Affected
Not Affected
Unknown

Filter by content:
 Additional information available

 Sort by:
Status
Alphabetical

Expand all

### [Atlassian](#Atlassian) Affected

Notified:  2021-09-27
Updated: 2021-11-09

**Statement Date:   November 03, 2021**

| **CVE-2021-42574** | Affected |
| --- | --- |
| **CVE-2021-42694** | Affected |
| **VU#999008.1** | Affected |

#### Vendor Statement

We have not received a statement from the vendor.

#### References

* <https://confluence.atlassian.com/security/cve-2021-42574-unrendered-unicode-bidirectional-override-characters-in-cloud-sites-1086420599.html>
* <https://confluence.atlassian.com/security/multiple-products-security-advisory-unrendered-unicode-bidirectional-override-characters-cve-2021-42574-1086419475.html>

### [Rust Security Response WG](#Rust%20Security%20Response%20WG) Affected

Notified:  2021-10-26
Updated: 2021-11-09

**Statement Date:   November 04, 2021**

| **CVE-2021-42574** | Affected |
| --- | --- |
| **CVE-2021-42694** | Not Affected |
| **VU#999008.1** | Affected |

#### Vendor Statement

Regarding CVE-2021-42574, the Rust project released Rust 1.56.1, featuring new lints to alert developers about the presence of bidirectional-override codepoints in their source code. No builtin mitigation is present in Rust 1.0.0 to Rust 1.56.0: we recommend users of those compiler versions to either upgrade to a newer compiler, or to perform out-of-band checks for the presence of those codepoints in their codebase.

Regarding CVE-2021-42694, Rust already includes protection from homoglyphs in identifiers. Rust 1.0.0 to Rust 1.52.1 doesn't support non-ASCII identifiers, which prevents the issue completely. Rust 1.53.0 and later versions do support non-ASCII identifiers, but include lints to alert developers about the presence of homoglyphs or similar issues.

#### References

* <https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html>

### [The LLVM Security Group](#The%20LLVM%20Security%20Group) Affected

Notified:  2021-09-27
Updated: 2021-11-09

**Statement Date:   October 30, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Affected |

#### Vendor Statement

In a future release the LLVM project will include new checkers as part of clang-tidy to detect occurences of both CVE-2021-42574 and CVE-2021-42694. In the meantime we recommend clang users to perform out-of-band checks for the presence of these security issues in their codebases.

#### References

* <https://bugs.chromium.org/p/llvm/issues/detail?id=11>

### [Meta](#Meta) Not Affected

Notified:  2021-09-27
Updated: 2021-11-09

**Statement Date:   October 18, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Not Affected |

#### Vendor Statement

We have not received a statement from the vendor.

### [Veracode](#Veracode) Not Affected

Notified:  2021-10-26
Updated: 2021-11-09

**Statement Date:   November 02, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Not Affected |

#### Vendor Statement

We have not received a statement from the vendor.

### [Node.js](#Node.js) Unknown

Notified:  2021-10-19
Updated: 2024-12-10

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

#### References

* <https://groups.google.com/g/nodejs-sec/c/_w6hoamG14E/m/MrmeX2WMBQAJ>

#### CERT Addendum

Per the node.js statement published Nov 1, 2021, 1:29:33â¯PM:

> You may have read the announcement today about the potential for supply chain attacks using characters within source files that are not visible to human code reviewers: https://www.trojansource.codes/.
>
> The ECMAScript specification requires support for these characters (see section 12.1 at https://tc39.es/ecma262/#sec-unicode-format-control-characters). Node.js or any ECMAScript-compliant engine must allow these characters, which have valid uses in source code.
>
> Due diligence including code scans (for example for licenses) should already be part of your processes both for the code you write and dependencies that you use within your application. The script provided by Red Hat [at] https://access.redhat.com/sites/default/files/find\_unicode\_control2--2021-11-01-1136.zip is a good way to scan and identify files that you may want to review with respect to usage of the special characters identified.
>
> For some statically compiled languages, it may make sense to incorporate a check into the compiler instead of using an external script. However, for dynamic languages such as JavaScript, there are potential issues with that approach. These include:
>
> \*\* Finding out too late that there is usage of these characters. Dynamic languages may load a source file in the middle of their execution. At this point the application is already deployed and you don't necessarily want to block it from running and non-blocking warnings may not be noticed. It is more effective to scan all files that make up the application before it is run.
>
> \*\* The runtime overhead of the scan will be incurred unnecessarily every time the application is run. It is better to scan as part of your development/build/release processes as it will not add any additional runtime overhead once the application is deployed.
>
> At this time, we do not plan to provide an option to scan at runtime. We recommend that external scripts/processes be used instead

### [Red Hat](#Red%20Hat) Unknown

Notified:  2021-09-27
Updated: 2024-12-10

**Statement Date:   December 17, 2021**

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

Red Hat's guidance for this issue can be found at Security Bulletin RHSB-2021-007

#### References

* <https://access.redhat.com/security/vulnerabilities/RHSB-2021-007>

### [Amazon](#Amazon) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Apple](#Apple) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [GitLab Inc.](#GitLab%20Inc.) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [GNU Compiler Collection](#GNU%20Compiler%20Collection) Unknown

Notified:  2021-10-19
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Google](#Google) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Micro Focus](#Micro%20Focus) Unknown

Notified:  2021-10-26
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Microsoft](#Microsoft) Unknown

Notified:  2021-10-19
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Oracle Corporation](#Oracle%20Corporation) Unknown

Notified:  2021-09-27
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

### [Snyk](#Snyk) Unknown

Notified:  2021-11-02
Updated: 2021-11-09

| **CVE-2021-42574** | Unknown |
| --- | --- |
| **CVE-2021-42694** | Unknown |
| **VU#999008.1** | Unknown |

#### Vendor Statement

We have not received a statement from the vendor.

View all 16 vendorsView less vendors

### References

* <https://www.trojansource.codes/trojan-source.pdf>

### Other Information

| **CVE IDs:** | [CVE-2021-42574](https://www.cve.org/CVERecord?id=CVE-2021-42574)  [CVE-2021-42694](https://www.cve.org/CVERecord?id=CVE-2021-42694) |
| --- | --- |
| **API URL:** | [VINCE JSON](/vuls/api/999008/) | [CSAF](/vuls/api/999008/csaf/) |
| **Date Public:** | 2021-11-09 |
| **Date First Published:** | 2021-11-09 |
| **Date Last Updated:** | 2024-12-10 02:09 UTC |
| **Document Revision:** | 3 |

* [About vulnerability notes](https://vuls.cert.org/confluence/display/VIN/Vulnerability%2BNote%2BHelp)
* Contact us about this vulnerability
* [Provide a vendor statement](https://vuls.cert.org/confluence/display/VIN/Case%2BHandling#CaseHandling-Givingavendorstatusandstatement)

Sponsored by [CISA.](https://www.cisa.gov/cybersecurity)

 [Download PGP Key](https://vuls.cert.org/confluence/pages/viewpage.action?pageId=25985026)

[Read CERT/CC Blog](https://insights.sei.cmu.edu/cert/)

[Learn about Vulnerability Analysis](https://www.sei.cmu.edu/research-capabilities/all-work/display.cfm?customel_datapageid_4050=21304)

Carnegie Mellon University

Software Engineering Institute

4500 Fifth Avenue

Pittsburgh, PA 15213-2612

412-268-5800

[Office Locations](http://www.sei.cmu.edu/locations/index.cfm) | [Additional Sites Directory](http://www.sei.cmu.edu/additional-sites-directory/index.cfm) | [Legal](https://vuls.cert.org/confluence/display/VIN/VINCE%2BCode%2Bof%2BConduct#VINCECodeofConduct-TermsofUse) | [Privacy Notice](https://www.sei.cmu.edu/legal/privacy-notice/index.cfm) | [CMU Ethics Hotline](https://www.cmu.edu/hr/ethics-hotline/) | [www.sei.cmu.edu](http://www.sei.cmu.edu)

Â©2024 Carnegie Mellon University

[Contact SEI](https://www.sei.cmu.edu/contact-us/)
#### Contact CERT/CC

 412-268-5800



=== Content from www.unicode.org_349390cd_20250111_024729.html ===


| [[Unicode]](http://www.unicode.org)  [Technical Reports](http://www.unicode.org/reports/) |
| --- |
|  |

## Unicode Technical Report #36

# Unicode Security Considerations

| Editors | [Mark Davis](https://plus.google.com/114199149796022210033?rel=author) (markdavis@google.com), Michel Suignard (michel@suignard.com) |
| --- | --- |
| Date | 2014-09-19 |
| This Version | <http://www.unicode.org/reports/tr36/tr36-15.html> |
| Previous Version | <http://www.unicode.org/reports/tr36/tr36-13.html> |
| Latest Version | <http://www.unicode.org/reports/tr36/> |
| Latest Proposed Update | <http://www.unicode.org/reports/tr36/proposed.html> |
| Revision | [15](#Modifications) |

### *Summary*

*Because Unicode contains such a large number of characters and
incorporates the varied writing systems of the world, incorrect
usage can expose programs or systems to possible security attacks.
This is especially important as more and more products are
internationalized. This document describes some of the security
considerations that programmers, system analysts, standards
developers, and users should take into account, and provides
specific recommendations to reduce the risk of problems.*

### *Status*

*This document has been reviewed by Unicode members and other
interested parties, and has been approved for publication by the Unicode
Consortium. This is a stable document and may be used as reference
material or cited as a normative reference by other specifications.*

> ***A Unicode Technical Report (UTR)** contains informative
> material. Conformance to the Unicode Standard does not imply
> conformance to any UTR. Other specifications, however, are free to
> make normative references to a UTR.*

*Please submit corrigenda and other comments with the online
reporting form [[Feedback](#Feedback)]. Related
information that is useful in understanding this document is found
in the [References](#References). For the latest version
of the Unicode Standard see [[Unicode](#Unicode)]. For a
list of current Unicode Technical Reports see [[Reports](#Reports)].
For more information about versions of the Unicode Standard, see [[Versions](#Versions)].*

### *Contents*

* 1 [Introduction](#Introduction)
  + 1.1 [Structure](#Structure)
* 2 [Visual Security Issues](#visual_spoofing)
  + 2.1 [Internationalized
    Domain Names](#international_domain_names)
    - [Table 1. Safe Domain
      Names](#TableSafeDomainNames)
  + 2.2 [Mixed-Script
    Spoofing](#Mixed_Script_Spoofing)
    - [Table 2.
      Mixed-Script Spoofing](#TableMixedScriptSpoofing)
  + 2.3 [Single-Script
    Spoofing](#Single_Script_Spoofing)
    - [Table 3.
      Single-Script Spoofing](#TableSingleScriptSpoofing)
    - [Table 4.
      Combining Mark Order Spoofing](#TableCombiningMarkOrderSpoofing)
  + 2.4 [Inadequate
    Rendering Support](#Inadequate_Rendering_Support)
    - [Table 5.
      Inadequate Rendering Support](#TableInadequateRenderingSupport)
    - 2.4.1 [Malicious
      Rendering](#Malicious_Rendering)
  + 2.5 [Bidirectional
    Text Spoofing](#Bidirectional_Text_Spoofing)
    - [Table 6. Bidi Examples](#TableBidiExamples)
    - 2.5.1 [Glyphs in Complex
      Scripts](#Complex_Scripts)
      * [Table 7. Glyphs in
        Complex Scripts](#TableComplexScripts)
  + 2.6 [Syntax Spoofing](#Syntax_Spoofing)
    - [Table 8. Syntax
      Spoofing](#TableSyntaxSpoofing)
    - 2.6.1 [Missing Glyphs](#Missing_Glyphs)
  + 2.7 [Numeric Spoofs](#Numeric_Spoofs)
  + 2.8 [IDNA Ambiguity](#IDNA_Ambiguity)
    - 2.8.1 [Punycode Spoofs](#Punycode_Spoofs)
      * [Table 8a.
        Punycode Spoofing](#TablePunycodeSpoofing)
  + 2.9 [Techniques](#Techniques)
    - 2.9.1 [Casefolded
      Format](#Case_Folded_Format)
    - 2.9.2 [Mapping and
      Prohibition](#Mapping_and_Prohibition)
  + 2.10 [Restriction
    Levels and Alerts](#Security_Levels_and_Alerts)
    - 2.10.1 [Backward
      Compatibility](#Backwards_Compatibility)
  + 2.11 [Recommendations](#Visual_Spoofing_Recommendations)
    - 2.11.1 [Recommendations
      for End-Users](#User_Recommendations)
    - 2.11.2 [Recommendations
      for Programmers](#Recommendations_General)
    - 2.11.3 [Recommendations
      for User Agents](#Recommendations_User_Agents)
    - 2.11.4 [Recommendations
      for Registries](#Recommendations_Registries)
    - 2.11.5 [Registrar
      Recommendations](#Recommendations_Registrars)
* 3 [Non-Visual Security
  Issues](#Canonical_Represenation)
  + 3.1 [UTF-8 Exploits](#UTF-8_Exploit)
    - 3.1.1 [Ill-Formed
      Subsequences](#Ill-Formed_Subsequences)
    - 3.1.2 [Substituting
      for Ill-Formed Subsequences](#Substituting_for_Ill_Formed_Subsequences)
  + 3.2 [Text Comparison
    (Sorting, Searching, Matching)](#Text_Comparison)
  + 3.3 [Buffer Overflows](#Buffer_Overflows)
    - [Table 9.
      Maximum Expansion Factors](#TableMaximumExpansionFactors)
  + 3.4 [Property
    and Character Stability](#Property_and_Character_Stability)
  + 3.5 [Deletion of
    Code Points](#Deletion_of_Noncharacters)
  + 3.6 [Secure
    Encoding Conversion](#SecureEncodingConversion)
    - 3.6.1 [Illegal
      Input Byte Sequences](#Illegal_Input_Byte_Sequences)
    - 3.6.2 [Some
      Output For All Input](#Some_Output_For_All_Input)
  + 3.7 [Enabling
    Lossless Conversion](#EnablingLosslessConversion)
    - 3.7.1 [PEP 383
      Approach](#TOC-PEP-383-Approach)
    - 3.7.2 [Notation](#TOC-Notation)
    - 3.7.3 [Security](#TOC-Security)
    - 3.7.4 [Interoperability](#TOC-Interoperability)
    - 3.7.5 [Safely
      Converting to Bytes](#TOC-Safely-Converting-to-Bytes)
  + 3.8 [Idempotence](#TOC-Idempotence)
* [Appendix A Script Icons](#Missing_Glyph_Icons)
  + [Table 10. Sample
    Script Icons](#TableSampleScriptIcons)
* [Appendix B
  Language-Based Security](#Language_Based_Security)
  + [Table 11. CLDR
    Script Mappings](#TableCLDRScriptMappings)
* [Acknowledgments](#Acknowledgments)
* [References](#References)
* [Modifications](#Modifications)

---

## [1 Introduction](#Introduction)

The Unicode Standard represents a very significant advance over all
previous methods of encoding characters. For the first time, all of
the world's characters can be represented in a uniform manner,
making it feasible for the vast majority of programs to be *globalized:*
built to handle any language in the world.

In many ways, the use of Unicode makes programs much more
robust and secure. When systems used a hodge-podge of different
charsets for representing characters, there were security and
corruption problems that resulted from differences between those
charsets, or from the way in which programs converted to and from
them.

However, because Unicode contains such a large number of
characters, and incorporates the varied writing systems of the world,
incorrect usage can expose programs or systems to possible security
attacks. This document describes some of the security considerations
that programmers, system analysts, standards developers, and users
should take into account.

For example, consider visual spoofing, where a similarity in
visual appearance fools a user and causes him or her to take unsafe
actions.

> Suppose that the user gets an email notification about an apparent
> problem in their Citibank account. Security-savvy users realize that
> it might be a spoof; the HTML email might be presenting the URL http://citibank.com/...
> visually, but might be hiding the *real* URL. They realize that
> even what shows up in the status bar might be a lie, because clever
> Javascript or ActiveX can work around that. (And users are likely to
> have these turned on, unless they know to turn them off.) They click
> on the link, and carefully examine the browser's address box to
> make sure that it is actually going to http://citibank.com/....
> They see that it is, and use their password. However, what they saw
> was wrong—it is actually
> going to a spoof site with a fake "citibank.com", using
> the Cyrillic letter that looks precisely like a 'c'. They
> use the site without suspecting, and the password ends up
> compromised.

This problem is not new to Unicode: it was possible to spoof even
with ASCII characters alone. For example, "inteI.com" uses a capital I instead of
an L. The infamous example here involves "paypaI.com":

> ... Not only was "Paypai.com"
> very convincing, but the scam artist even goes one step further. He
> or she is apparently emailing PayPal customers, saying they have a
> large payment waiting for them in their account.
>
> The message then offers up a link, urging
> the recipient to claim the funds. However, the URL that is displayed
> for the unwitting victim uses a capital "i" (I), which
> looks just like a lowercase "L" (l), in many computer
> fonts. ...
>
> *(for details, see the [Unicode
> Security FAQ](http://www.unicode.org/faq/security.html))*

While some browsers prevent this spoof by lowercasing domain
names, others do not.

Thus to a certain extent, the new forms of visual spoofing
available with Unicode are a matter of degree and not kind. However,
because of the very large number of Unicode characters (over 107,000
in the current version), the number of opportunities for visual
spoofing is significantly larger than with a restricted character set
such as ASCII.

### 1.1 [Structure](#Structure)

This document is organized into two sections: visual security issues
and non-visual security issues. Each section presents background
information on the kinds of problems that can occur, and lists
specific recommendations for reducing the risk of such problems. For
background information, see the [References](#References)
and the Unicode FAQ on *Security Issues* [[FAQSec](#FAQSec)].

A URL is technically a type of uniform resource
identifier (URI). In many technical documents and verbal discussions,
however, URL is often used as a synonym for URI or IRI, and this is
not considered a problem. That practice is followed here.

## [2 Visual Security Issues](#visual_spoofing)

Visual spoofs depend on the use of *visually confusable*
strings: two different strings of Unicode characters whose appearance
in common fonts in small sizes at typical screen resolutions is
sufficiently close that people easily mistake one for the other.

There are no hard-and-fast rules for visual confusability: many
characters look like others when used with sufficiently small sizes.
"Small sizes at screen resolutions" means fonts whose
ascent plus descent is from 9 to 12 pixels for most scripts, and
somewhat larger for scripts, such as Japanese, where the users
typically have larger sizes. Confusability also depends on the style
of the font: with a traditional Hebrew style, many characters are
only distinguishable by fine differences which may be lost at small
sizes. In some cases sequences of characters can be used to spoof:
for example, "rn" ("r" followed by "n")
is visually confusable with "m" in many sans-serif fonts.

Where two different strings can always be represented by the same
sequence of glyphs, those strings are called *homographs*. For
example, "AB" in Latin and "AB" in Greek are
homographs. Spoofing is not dependent on just homographs; if the
visual appearance is close enough at small sizes or in the most
common fonts, that can be sufficient to cause problems. Some people
use the term *homograph* broadly, encompassing all visually
confusable strings.

Two characters with similar or identical glyph shapes are not
visually confusable if the positioning of the respective shapes is
sufficiently different. For example, foo·com (using the hyphenation point
instead of the period) should be distinguishable from foo.com by the
positioning of the dot.

It is important to be aware that identifiers are
special-purpose strings used for identification, strings that are
deliberately limited to particular repertoires for that purpose.
Exclusion of characters from identifiers does not affect the general
use of those characters, such as within documents.

The remainder of this section is concerned with identifiers that can
be confused by ordinary users at typical sizes and screen
resolutions. For examples of visually confusable characters, see *Section
4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

There is another kind of confusability, where the goal is not to
"fool the user", but rather to "slip by a
gatekeeper". For example, consider a spam email for
"Ⓥ\*ⓘ\*ⓐ\*ⓖ\*ⓡ\*ⓐ". In this case, the end user isn't fooled by
the characters into thinking that ⓐ is a regular "a". The
real goal is to fool mechanical gatekeepers, such as spam detectors,
while being recognizable to an end user. Collection of data for
detecting gatekeeper-confusable strings is not currently a goal for *UTS
#39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

It is also important to recognize that the use of visually confusable
characters in spoofing is often overstated. Moreover, confusable
characters account for a small proportion of phishing problems: most
are cases like "secure-wellsfargo.com". For more information, see the
[Unicode
Security FAQ](http://www.unicode.org/faq/security.html).

### 2.1 [Internationalized Domain Names](#international_domain_names)

Visual spoofing is an especially important subject given the
introduction in 2003 of Internationalized Domain Names (IDN) [[IDNA2003](#IDNA2003)]. There is a natural desire for people
to see domain names in their own languages and writing systems;
English speakers can understand this if they consider what it would
be like if they always had to type Web addresses with Japanese
characters. IDNs represent a very significant advance for most people
in the world. However, the larger repertoire of characters results in
more opportunities for spoofing. Proper implementation in browsers
and other programs is required to minimize security risks while still
allowing for effective use of non-ASCII characters.

Internationalized Domain Names are, of course, not the only cases
where visual spoofing can occur. One example is a message offering to
install software from "IBM", authenticated with a
certificate in which the "М" character
happens to be the Russian (Cyrillic) character that looks precisely
like the English "M". Wherever strings are used as
identifiers, this kind of spoofing is possible.

IDNs provide a good starting point for a discussion of visual
spoofing, and are the focus of the next part of this section. In
2010, there was a update to [[IDNA2003](#IDNA2003)] called
[[IDNA2008](#IDNA2008)]. Because the concepts and
recommendations discussed here can be generalized to the use of other
types of identifiers, both [[IDNA2003](#IDNA2003)] and [[IDNA2008](#IDNA2008)] will be used in examples. For
background information on identifiers, see UAX #31: *Identifier
and Pattern Syntax* [[UAX31](#UAX31)]. For more
information on how to handle international domain names in a
compatible fashion, see *UTS #46: Unicode IDNA Compatibility
Processing* [[UTS46](#UTS46)].

Fortunately the design of IDN prevents a huge number of spoofing
attacks. All conformant users of [[IDNA2003](#IDNA2003)]
are required to process domain names to convert what are called *[compatibility-equivalent](http://www.unicode.org/glossary/#compatibility_equivalent)* characters into a unique form using a process called compatibility
normalization (NFKC)—for more information on this, see [[UAX15](#UAX15)]. This processing eliminates most
possibilities for visual spoofing by mapping away a large number of
visually confusable characters and sequences. For example, characters
like the halfwidth Japanese *katakana* character ｶ are converted to the
regular character カ, and single ligature characters like  "ﬁ" to the
sequence of regular characters "fi". Unicode contains the
"ä"
(a-umlaut) character, but also contains a free-standing umlaut
("  ̈")
which can be used in combination with any character, including an
"a". The compatibility normalization will convert any
sequence of "a" plus "  ̈" into the
regular "ä".
([[IDNA2008](#IDNA2008)] disallows these compatibility
characters as output, but allows them to be mapped on input.)

Thus someone cannot spoof an *a-umlaut* with *a + umlaut*;
it simply results in the same domain name. See the example in *Table
1, [Safe Domain Names](#TableSafeDomainNames)*. The String column shows the actual characters; the UTF-16 column
shows the underlying encoding and the Punycode column shows the
internal format of the domain name. This is the result of applying
the ToASCII() operation [[RFC3490](#RFC3490)] to the
original IDN, which is the way this IDN is stored and queried in the
DNS (Domain Name System).

Table 1. [Safe Domain Names](#TableSafeDomainNames)

|  | String | UTF-16 | Punycode | Comments |
| 1a | ät.com | 0061 0308 0074 002E 0063 006F 006D | xn--t-zfa.com | Uses the decomposed form, a plus umlaut |
| 1b | ät.com | 00E4 0074 002E 0063 006F 006D | xn--t-zfa.com | The decomposed form ends up being identical to the composed form, in IDNA |

Similarly, for most
scripts, two accents that do not interact typographically are put
into a determinate order when the text is normalized. Thus the sequence
<x, dot\_above, dot\_below> is reordered as <x, dot\_below,
dot\_above>. This ensures that the two sequences that look identical
(ẋ̣ and ẋ̣̇) have the same representation.

**Note:** The demo at [[IDN-Demo](#IDN-Demo)] can be
used to demonstrate the results of processing different domain names.
That demo was also used to get the Punycode values shown in *Table
1, [Safe Domain Names](#TableSafeDomainNames)*.

The [[IDNA2003](#IDNA2003)] and[[UTS46](#UTS46)]
processing also removes case distinctions by performing a *casefolding*
to reduce characters to a lowercase form*.* This is helps avoid
spoofing problems, because characters are generally more distinctive
in their lowercase forms. That means that implementers can focus on
just dealing with the lowercase characters. There are some cases
where people will want to see certain special differences preserved
in display. For more information, and information about characters
allowed in IDN, see *UTS #46: Unicode IDNA Compatibility
Processing* [[UTS46](#UTS46)].

> **Note**: Users expect diacritical marks to distinguish domain
> names. For example, the domain names "resume.com" and
> "résumé.com" are (and should be) distinguished. In
> languages where the spelling may allow certain words with and
> without diacritics, registrants would have to register two or more
> domain names to cover user expectations (just as one may register
> both "analyze.com" and "analyse.com" to cover
> variant spellings). The registry can support this automatically by
> using a technique known as "bundling".

Although normalization and casefolding prevent many possible
spoofing attacks, visual spoofing can still occur with many IDNs.
This poses the question of which parts of the infrastructure using
and supporting domain names are best suited to minimize possible
spoofing attacks.

Some of the problems of visual spoofing can be best handled on the
registry side, while others can be best handled on the side of the *user
agent*: browsers, emailers, and other programs that display and
process URLs. The registry has the most data available about
alternative registered names, and can process that information the
most efficiently at the time of registration, using policies to
reduce visual spoofing. For example, given the method described in *Section
4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)], the registry can easily determine if a
proposed registration could be visually confused with an existing
one; that determination is much more difficult for user agents
because of the sheer number of combinations that they would have to
check.

However, there are certain issues much more easily addressed by
the user agent:

* the user agent has more control over the display of
  characters, which is crucial to spoofing
* there are legitimate cases of visually confusable characters
  that one may want to allow *after* alerting the user, such as
  single-script confusables discussed below
* one cannot depend on all registries being responsive to
  security issues
* due to the decentralized nature of DNS, a registry for a
  domain does not control subdomains: thus the registry for a
  top-level domain (TLD) like ".com" may not control the
  labels accepted by a subdomain like "blogspot.com".

Thus the problem of visual spoofing is most effectively
addressed by a combination of strategies involving user agents and
registries.

### **2.2 [Mixed-Script Spoofing](#Mixed_Script_Spoofing)**

Visually confusable characters are not usually unified across
scripts. Thus a Greek *omicron* is encoded as a different
character from the Latin "o", even though it is usually
identical or nearly identical in appearance. There are good reasons
for this: often the characters were separate in legacy encodings, and
preservation of those distinctions was necessary for data to be
converted to Unicode and back without loss. Moreover, the characters
generally have very different behavior: two visually confusable
characters may be different in casing behavior, in category (letter
versus number), or in numeric value. After all, ASCII does not unify
lowercase letter l and digit 1, even though those are visually
confusable. (Many fonts always distinguish them, but many others do
not.) Encoding the Cyrillic character б (corresponding to the letter
"b") by using the numeral 6, would clearly have been a
mistake, even though they are visually confusable.

However, the existence of visually confusable characters across
scripts offers numerous opportunities for spoofing. For example, a
domain name can be spoofed by using a Greek omicron instead of an
'o', as in example 1a in *Table 2, [Mixed-Script Spoofing](#TableMixedScriptSpoofing)*.

Table 2. [Mixed-Script Spoofing](#TableMixedScriptSpoofing)

|  | String | UTF-16 | Punycode | Comments |
| 1a | tοp.com | 0074 03BF 0070 002E 0063 006F 006D | xn--tp-jbc.com | Uses a Greek omicron in place of the o |
| 1b | tοp.com | 0074 006F 0070 002E 0063 006F 006D | top.com |  |

There are many legitimate uses of mixed scripts. For example, it is
quite common to mix English words (with Latin characters) in other
languages, including languages using non-Latin scripts. For example,
one could have XML-документы.com (which would be a site for "XML
documents" in Russian). Even in English, legitimate product or
organization names may contain non-Latin characters, such as Ωmega,
Teχ, Toys-Я-Us, or HλLF-LIFE. The lack of IDNs in the past has also
led to the usage in some registries (such as the .ru top-level
domain) where Latin characters have been used to create
pseudo-Cyrillic names in the .ru (Russian) top-level domain. For
example, see http://caxap.ru/ (сахар means sugar in Russian).

For information on detecting mixed scripts, see *Section 5, [Mixed
Script Detection](http://www.unicode.org/reports/tr39/#Mixed_Script_Detection)*of **UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].*

Cyrillic, Latin, and Greek represent special challenges, because the
number of common glyphs shared between them is so high, as can be
seen from *Section 4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)]. It may be possible to compose an entire
domain name (except the top-level domain) in Cyrillic using letters
that will be essentially always identical in form to Latin letters,
such as "scope.com": with "scope" in Cyrillic
looking just like "scope" in Latin. Such spoofs are called
*whole-script spoofs,* and the strings that cause the problem
are correspondingly called *whole-script confusables.*

### 2.3 [Single-Script Spoofing](#Single_Script_Spoofing)

Spoofing with characters entirely within one script, or using
characters that are common across scripts (such as numbers), is
called *single-script spoofing*, and the strings that cause it
are correspondingly called *single-script confusables*. While
compatibility normalization and mixed-script detection can handle the
majority of spoofing cases, they do not handle single-script
confusables. Especially at the smaller font sizes in the context of
an address bar, any visual confusables within a single script can be
used in spoofing. Importantly, these problems can be illustrated with
common, widely available fonts on widely available operating
systems—the problems are not specific to any single vendor.

Consider the examples in *Table 3, [Single-Script Spoofing](#TableSingleScriptSpoofing)*, all in
the same script. In each numbered case, the strings will look
identical or nearly identical in most browsers.

Table 3. [Single-Script Spoofing](#TableSingleScriptSpoofing)

|  | String | UTF-16 | Punycode | Comments |
| 1a | a‐b.com | 0061 2010 0062 002E 0063 006F 006D | xn--ab-v1t.com | Uses a real hyphen, instead of the ASCII hyphen-minus |
| 1b | a-b.com | 0061 002D 0062 002E 0063 006F 006D | a-b.com |  |
|  | | | | |
| 2a | so̷s.com | 0073 006F 0337 0073 002E 0063 006F 006D | xn--sos-rjc.com | Uses o + combining slash |
| 2b | søs.com | 0073 00F8 0073 002E 0063 006F 006D | xn--ss-lka.com |  |
|  | | | | |
| 3a | z̵o.com | 007A 0335 006F 002E 0063 006F 006D | xn--zo-pyb.com | Uses z + combining bar |
| 3b | ƶo.com | 01B6 006F 002E 0063 006F 006D | xn--o-zra.com |  |
|  | | | | |
| 4a | an͂o.com | 0061 006E 0342 006F 002E 0063 006F 006D | xn--ano-0kc.com | Uses n + greek perispomeni |
| 4b | año.com | 0061 00F1 006F 002E 0063 006F 006D | xn--ao-zja.com |  |
|  | | | | |
| 5a | ʣe.org | 02A3 0065 002E 006F 0072 0067 | xn--e-j5a.org | Uses d-z digraph |
| 5b | dze.org | 0064 007A 0065 002E 006F 0072 0067 | dze.org |  |

Examples exist in various scripts. For instance, 'rn' was
already mentioned above, and the sequence अ + ा typically looks
identical to आ.

In most cases two sequences of accents that have the same visual
appearance are put into a canonical order. This does not happen,
however, for certain scripts used in Southeast Asia, so reordering
characters may be used for spoofs in those cases. See *Table
4, [Combining Mark
Order Spoofing](#TableCombiningMarkOrderSpoofing).*

Table 4. [Combining Mark Order
Spoofing](#TableCombiningMarkOrderSpoofing)

|  | String | UTF-16 | Punycode | Comments |
| 1a | လို.com | 101C 102D 102F | xn--gjd8ag.com | Reorders two combining marks |
| 1b | လုိ.com | 101C 102F 102D | xn--gjd8af.com |  |

### 2.4 [Inadequate Rendering Support](#Inadequate_Rendering_Support)

An additional problem arises when a font or rendering engine has
inadequate support for characters or sequences of characters that
should be visually distinguishable, but do not appear that way. In *Table
5, [Inadequate
Rendering Support](#TableInadequateRenderingSupport)*, examples 1a and 1b show the cases of lowercase L and digit one,
mentioned above. While this depends on the font, on the computer used
to write this document, roughly 30% of the fonts display glyphs that
are essentially identical. In example 2a, the *a-umlaut* is
followed by another *umlaut*. The Unicode Standard guidelines
indicate that the second *umlaut* should be 'stacked'
above the first, producing a distinct visual difference. However, as
example 2a shows, common fonts will simply superimpose the second *umlaut*;
and if the positioning is close enough, the user will not see a
difference between 2a and 2b. Examples 3 a, b, and c show an even
worse case. The *underdot* character in 3a should appear under
the 'l', but as rendered with many fonts, it appears under
the 'e'. It is thus visually confusable with 3b (where the *underdot*
is under the e) or the equivalent normalized form 3c.

Table 5. [Inadequate Rendering
Support](#TableInadequateRenderingSupport)

|  | String | UTF-16 | Punycode | Comments |
| 1a | al.com | 0061 006C 002E 0063 006F 006D | al.com | 1 and l may appear alike, depending on font. |
| 1b | a1.com | 0061 0031 002E 0063 006F 006D | a1.com |  |
|  | | | | |
| 2a | ä̈t.com | 00E4 0308 0074 002E 0063 006F 006D | xn--t-zfa85n.com | a-umlaut + umlaut |
| 2b | ät.com | 00E4 0074 002E 0063 006F 006D | xn--t-zfa.com |  |
|  | | | | |
| 3a | eḷ.com | 0065 006C  0323 002E 0063 006F 006D | xn--e-zom.com | Has a dot under the l; may appear under the e |
| 3b | ẹl.com | 0065 0323 006C 002E 0063 006F 006D | xn--l-ewm.com |  |
| 3c | ẹl.com | 1EB9 006C 002E 0063 006F 006D | xn--l-ewm.com |  |

Certain Unicode characters are invisible, although they may affect
the rendering of the characters around them. An example is the *joiner*
character, used to request a cursive connection such as in Arabic.
Such characters may often be in positions where they have no visual
distinction, and are thus discouraged for use in identifiers except
in specific contexts. For more information, see *UTS #46:
Unicode IDNA Compatibility Processing* [[UTS46](#UTS46)].

A sequence of ideographic description characters may be
displayed as if it were a CJK character; thus they are also
discouraged.

#### 2.4.1 [Malicious Rendering](#Malicious_Rendering)

Font technologies such as TrueType/OpenType are extremely powerful. A
glyph in such a font actually may use a small programs to transform
the shape radically according to resolution, platform, or language.
This is used to chose an optimal shape for the character under
different conditions. However, it can also be used in a security
attack, because it is powerful enough to change the appearance of,
say "$**1**00.00" on the screen to "$**2**00.00"
when printed.

In addition Cascading Style Sheets (CSS) can change to a
different font for printing versus screen display, which can open up
the use of more confusable fonts.

These problems are not specific to Unicode. To reduce the risk
of this kind of exploit, programmers and users should only allow
trusted fonts in such circumstances.

### 2.5 [Bidirectional Text Spoofing](#Bidirectional_Text_Spoofing)

Some characters, such as those used in the Arabic and Hebrew script,
have an inherent right-to-left writing direction. When these
characters are mixed with characters of other scripts or symbol sets
which are displayed left-to-right, the resulting text is called
bidirectional (abbreviated as *bidi*). The relationship
between the memory representation of the text (logical order) and the
display appearance (visual order) of bidi text is governed by *UAX
#9: Unicode Bidirectional Algorithm* [[UAX9](#UAX9)].

 Because some characters have weak or neutral
directionalities, as opposed to strong left-to-right or
right-to-left, the Unicode Bidirectional Algorithm uses a precise set
of rules to determine the final visual rendering. However, presented
with arbitrary sequences of text, this may lead to text sequences
which may be impossible to read intelligibly, or which may be
visually confusable. To mitigate these issues, the [[IDNA2003](#IDNA2003)] specification requires that:

* each label of a host name must not use both right-to-left
  and left-to-right characters,
* a label using right-to-left character must start and end
  with right-to-left characters.

The [[IDNA2008](#IDNA2008)] specification improves these
rules, allowing some sequences that are incorrectly forbidden by the
above rules, and disallowing others that can cause visual confusion.

In addition, the IRI specification [[RFC3987](#RFC3987)]
extends those requirements to other components of an URL, not just
the host name labels. Not respecting them would result in
insurmountable visual confusion. A large part of the confusability in
reading an URL containing bidi
characters is created by the weak or neutral directionality property
of many URL delimiters such as
'/', '.', '?' which makes them change
directionality depending on their surrounding characters. This is
shown with the dots in *Table 6, [Bidi
Examples](#TableBidiExamples)* , where they are colored the same as the preceding label. Notice
that the placement of that following punctuation may vary.

Table 6. [Bidi
Examples](#TableBidiExamples)

|  | Samples |
| 1 | http://سلام.دائم.com |
| 2 | http://سلام.a.دائم.com |

Adding the left-to-right label "a"
between the two Arabic labels splits them up and reverses their
display order, as seen in example #2 in *Table 6, [Bidi Examples](#TableBidiExamples)*. The IRI specification [[RFC3987](#RFC3987)] provides more examples of valid and
invalid IRIs using various mixes of bidi text.

To minimize the opportunities for confusion, it is imperative that
the [[IDNA2008](#IDNA2008)] and IRI requirements
concerning bidi processing be fully implemented in the processing of
host names containing bidi characters. Nevertheless, even when these
requirements are met, reading IRIs correctly is not trivial. Because
of this, mixing right-to-left and left-to-right characters should be
done with great care when creating bidi IRIs.

**Recommendations:**

* Never allow bidi override characters.
* As much as possible, avoid mixing right-to-left and
  left-to-right characters in a single name.
* When right-to-left characters are used, limit the usage of
  left-to-right characters to well-known cases such as TLD names and URL scheme names (such as http, ftp, mailto,
  and so on).
* Minimize the use of digits in host names and other
  components of IRIs containing right-to-left characters.
* Keep IRIs containing bidi content simple to read.
* Use reverse-bidi (visual order -> storage order) to
  detect possible bidi spoofs. That is, one can apply bidi, then
  reverse bidi: if the result does not match the original storage
  order, then the visual reading is ambiguous and the string can be
  rejected. This is, however, subject to false positives, so this
  should probably be presented to users for confirmation.

#### 2.5.1 [Glyphs in Complex Scripts](#Complex_Scripts)

In complex scripts such as Arabic and South Asian scripts, characters
may change shape according to the surrounding characters, as shown in
*Table 7, [Glyphs in
Complex Scripts](#TableComplexScripts)*. Note that this also occurs in higher-end
typography in English, as illustrated by the "fi" ligature.
Two characters might be visually distinct in a stand-alone form, but
not be distinct in a particular context.

Table 7. [Glyphs in Complex Scripts](#TableComplexScripts)

| 1. | Glyphs may change shape depending on their surroundings: | ه | | ه | | ه | | → | ههه | | |
|  | | | | | | | | | |
| 2. | Multiple characters may produce a single glyph: | f | | | i | | | → | ﬁ | | |
| ل | | | ا | | | → | لا | | |
| image | | image | | image | | → | image | | |
|  | | | | | | | | | |
| 3. | A single character may produce multiple glyphs: | க | | | ொ | | | → | ெ | க | ா |

Some complex scripts are encoded with a so-called *font-encoding,* where non-private-use characters are misused as other characters or
parts of characters. These present special risks, because the
encodings are not identified, and the visual interpretation of the
characters depends entirely on the font, and is completely
disconnected from the underlying characters. Luckily such
font-encodings are seldom used, and their use is decreasing rapidly
with the growth of Unicode.

### 2.6 [Syntax Spoofing](#Syntax_Spoofing)

Spoofing syntax characters can be even worse than regular characters,
as illustrated in *Table 8, [Syntax
Spoofing](#TableSyntaxSpoofing)*. For example, U+2044 ( ⁄
) FRACTION SLASH can
look like a regular ASCII '/' in many fonts—ideally the
spacing and angle are sufficiently different to distinguish these
characters. However, this is not always the case. When this
character is allowed, the URL in line 1 may appear to be in the
domain **macchiato.com**, but is actually in a particular subzone
of the domain **bad.com**.

Table 8. [Syntax
Spoofing](#TableSyntaxSpoofing)

|  | URL | Subzone | Domain |
| 1 | http://macchiato.com/x.bad.com | macchiato.com/x | bad.com |
| 2 | http://macchiato.com?x.bad.com | macchiato.com?x | bad.com |
| 3 | http://macchiato.com.x.bad.com | macchiato.com.x | bad.com |
| 4 | http://macchiato.com#x.bad.com | macchiato.com#x | bad.com |

Where there are visual confusables other syntax characters can be
similarly spoofed, as in lines 2 through 4. Nameprep [[RFC3491](#RFC3491)] and [[UTS46](#UTS46)]
disallow many such cases, such as such as U+2024 (·) ONE DOT LEADER. However, not
all syntax spoofs are disallowed.

Of course, these types of spoofs do not require IDNs. For example, in
the following the real domain name, **bad.com**, is also
obscured for the casual user, who may not realize that "--"
does not terminate the domain name.

> http://macchiato.com--long-and-obscure-list-of-characters.bad.com?findid=12

In retrospect, it would have been much better if domain names
were customarily written with the most significant label first. The
following hypothetical display would be harder to spoof: it is easy
to see that the top level is "com.bad".

> http://**com.bad**.org/x.example?findid=12
>
> http://**com.bad**.org--long-and-obscure-list-of-characters.example?findid=12

However, that would be an impossible change at this point.
However, much the same effect can be produced by always visually
distinguishing the domain, for example:

> http://**macchiato.com**
>
> http://**bad.com**
>
> http://macchiato.com/**x.bad.com**
>
> http://**macchiato.com--long-and-obscure-list-of-characters.bad.com**?findid=12
>
> http://**220.135.25.171**/amazon/index.html

Such visual distinction could be in different ways, such as
highlighting in an address box as above, or extracting and displaying
the domain name in a noticeable place.

User agents already have to deal with syntax issues. For example,
Firefox gives something like the following alert when given the URL http://something@macchiato.com:

| warning | You are about to go to the site "macchiato.com" with the username "something", but the web site does not require authentication. This may be an attempt to trick you.  Is "macchiato.com" the site you want to visit? |
| --- | --- |

Such a mechanism can be used to alert the user to cases of
syntax spoofing.

#### 2.6.1 [Missing Glyphs](#Missing_Glyphs)

It is very important not to show a missing glyph or character with a
simple "?", because every such character is visually
confusable with a real question mark. Instead, follow the Unicode
guidelines for displaying missing glyphs using a rounded-rectangle,
as listed in *Appendix A [Script
Icons](#Missing_Glyph_Icons)* and described in **Section 5.3, Unknown and
Missing Characters** of [[Unicode](#Unicode)].

Private use characters must be avoided in identifiers, except in
closed environments. There is no predicting what either the visual
display or the programmatic interpretation will be on any given
machine, so this can obviously lead to security problems. This is not
a problem for IDNs, because private use characters are excluded in
all specifications: [[IDNA2003](#IDNA2003)], [[IDNA2008](#IDNA2008)], and[[UTS46](#UTS46)].

What is true for private use characters is doubly true of
unassigned code points. Secure systems will not use them: any future
Unicode Standard could assign those codepoints to any new character.
This is especially important in the case of certification.

### 2.7 [Numeric Spoofs](#Numeric_Spoofs)

Turning away from the focus on domain names for a moment, there is
another area where visual spoofs can be used. Many scripts have sets
of decimal digits that are different in shape from the typical
European digits. For example, Bengali has {০ ১ ২ ৩  ৪ ৫ ৬  ৭ ৮ ৯}, while Oriya has {୦ ୧ ୨ ୩  ୪ ୫ ୬  ୭ ୮  ୯}. Individual digits may
have the same shapes as digits from other scripts, even digits of
different values. For example, the Bengali string "**৪****୨****"** is visually
confusable with the European digits "**89"**, but
actually has the numeric value 42! If software interprets the
numeric value of a string of digits without detecting that the
digits are from different or inappropriate scripts, such spoofs can
be used.

### [2.8 IDNA Ambiguity](#IDNA_Ambiguity)

IDNA2008, just approved in 2010, opens up new opportunities for
spoofing. In the 2003 version of international domain names, a
correctly processed URL containing Unicode characters always resolved
to the same Punycode URL for lookup. IDNA2008, in certain cases, will
resolve to a different Punycode URL. Thus the same URL, whether typed
in by the user or present in data (such as in an href) will resolve
to two different locations, depending on whether the user is using a
browser on the pre-2010 international domain name specification or
the post-2010 specification. For more information on this topic, see
*UTS #46: Unicode IDNA Compatibility Processing* [[UTS46](#UTS46)] and [[IDN\_FAQ](#IDN_FAQ)].

#### 2.8.1 [Punycode Spoofs](#Punycode_Spoofs)

The Punycode transformation is relatively dense. That means that it
is fairly likely that arbitrary words after the "xn--" will result in
valid labels. For example, see *Table 8a. [Punycode Spoofing](#TablePunycodeSpoofing)*.

Table 8a. [Punycode Spoofing](#TablePunycodeSpoofing)

|  | URL | Punycode URL |
| 1 | http://䕮䕵䕶䕱.com | http://xn--google.com |
| 2 | http://䁾.com | http://xn--cnn.com |
| 3 | http://岍岊岊岅岉岎.com | http://xn--citibank.com |

These examples demonstrate that the common tactic of displaying
Punycode for suspicious URLs or for URLs with languages or scripts
not in the user's settings can actually backfire, producing display
results that are *more* likely to mislead the user. For example,
if a user is unfamiliar with Chinese but knows Latin characters, she
is more likely to be mislead by the Punycode URL “http://xn--cnn.com”
than by the corresponding Unicode URL “http://䁾.com”. More examples
can be created with the demo at [[IDN-Demo](#IDN-Demo)].

### [2.9 Techniques](#Techniques)

This section lists techniques for reducing the risks of visual
spoofing. These techniques are referenced by *Section 2.10, [Recommendations](#Visual_Spoofing_Recommendations).*

#### [2.9.1 Casefolded Format](#Case_Folded_Format)

Many opportunities for spoofing can be removed by using a *casefolded*
format. This format, defined by the Unicode Standard, produces a
string that only contains lowercase characters where possible.

However, four characters that require special handling in
casefolding, where the pure casefolded format of a string as defined
by the Unicode Standard is not desired. For example, the character
U+03A3 "Σ" *capital sigma* lowercases to U+03C3
"σ" *small sigma* if it is followed by another letter,
but lowercases to U+03C2 "ς" *small final sigma* if it
is not. Because both σ and ς have a case-insensitive match to Σ, and
the casefolding algorithm needs to map both of them together (so that
transitivity is maintained), only one of them appears in the
casefolded form.

> When σ comes after a cased letter, and not before a cased letter
> (where certain ignorable characters can come in between), it should
> be transformed into ς. For more details, see the test for
> Final\_Sigma as provided in Table 3-15 of [[Unicode](#Unicode)].

For more information, see *UTS #46: Unicode IDNA
Compatibility Processing* [[UTS46](#UTS46)]. For more
information on case mapping and folding, see the following: *Section
3.13, Default Case Operations*, *Section 4.2; Case Normative*;
and *Section 5.18, Case Mappings* of [[Unicode](#Unicode)].

#### [2.9.2 Mapping and Prohibition](#Mapping_and_Prohibition)

Mapping and prohibition are two useful techniques to reduce the risk
of spoofing that can be applied to identifiers. A number of
characters are included in Unicode for compatibility. *Compatibility
Normalization* (NFKC) can be used to map these characters to the
regular variants. For example, a halfwidth Japanese *katakana*
character ｶ is mapped to the regular
character カ. Additional mappings can be added beyond compatibility
mappings, for example, [[IDNA2003](#IDNA2003)]
 adds the following:

> `200D; ZERO WIDTH JOINER`
> maps to nothing (that is, is removed)
>
> `0041; 0061;`
> Case maps 'A' to 'a'
>
> `20A8; 0072 0073;`
> Additional folding, mapping ₨
> to "rs"

In addition, characters may be prohibited. For example, IDNA2003
prohibits *space* and *no-break
s**pace* (U+00A0).
Instead of removing a ZERO WIDTH JOINER, or mapping ₨ to "rs", one could
prohibit these characters. There are pluses and minuses to both
approaches. If compatibility characters are widely used in practice
in entering text, it is much more user-friendly to remap them. This
also extends to deletion; for example, the ZERO WIDTH JOINER is
commonly used to affect the presentation of characters in languages
such as Hindi or Arabic. In this case, text copied into the address
box may often contain the character.

Where this is not the case, however, it may be advisable to simply
prohibit the character. It is unlikely, for example, that ㋕ would be typed by a
Japanese user, nor that it would need to work in copied text.

Where both mapping and prohibition are used, the mapping should be
done before the prohibition, to ensure that characters do not
"sneak past". For example, the Greek character TONOS (΄) ends up being prohibited in [[IDNA2003](#IDNA2003)]
, because it normalizes to *space + acute*, and *space*
itself is prohibited.

Many languages have words whose correct spelling requires the
use of certain invisible characters, especially the Join\_Control
characters:

> `[200C](http://unicode.org/cldr/utility/character.jsp?a=200C)`
> ZERO WIDTH NON-JOINER
>
> `[200D](http://unicode.org/cldr/utility/character.jsp?a=200D)`
> ZERO WIDTH JOINER

For that reason, as of Version 5.1 of the Unicode Standard the
recommendations for identifiers were modified to allow these
characters in certain circumstances. (For more
information, see *UAX #31: Unicode Identifier and Pattern
Syntax* [[UAX31](#UAX31)].) There are very stringent
constraints on the use of these characters, so that they are only
allowed with certain scripts, and in certain circumscribed contexts.
In particular, in Indic scripts the ZWJ and ZWNJ may only be used in
combination with a *virama* character. This approach is adopted
in [[IDNA2008](#IDNA2008)] and[[UTS46](#UTS46)].

Even when the join controls are constrained to being next to a *virama*,
in some contexts they may not result in a different visual
appearance. For example, in roughly half of the possible pairs of
Malayalam consonants linked by a *virama*, the ZWNJ makes a
visual difference; in the remaining cases, the appearance is the same
as if only the virama were present, without a ZWNJ. Implementations
or standards may thus place further restrictions on invisible
characters. For join controls in Indic scripts, such restrictions
would typically consist of providing a table per script, containing
pairs of consonants which allow intervening *joiners*.

The Unicode property [[NFKC\_Casefold](#NFKC_CaseFold)] can
be used to get a combined casefolding, normalization, and removal of
default-ignorable code points. It is the basis for the mapping of
international domain names in *UTS #46: Unicode IDNA
Compatibility Processing* [[UTS46](#UTS46)]. For more
information, also see *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

### [2.10 Restriction Levels and Alerts](#Security_Levels_and_Alerts)

To help avoid problems with mixtures of scripts, *UTS #39:
Unicode Security Mechanisms* [[UTS39](#UTS39)] defines *Restriction
Levels*. An appropriate alert should be generated if an identifier
fails to satisfy the Restriction Level chosen by the user or set in
the browser. Depending on the circumstances and the level difference,
the form of such alerts could be minimal, such as special coloring or
icons (perhaps with a tool-tip for more information); or more
obvious, such as an alert dialog describing the issue and requiring
user confirmation before continuing; or even more stringent, such as
disallowing the use of the identifier. Where icons are used to
indicate the presence of characters from scripts, the glyphs in *Appendix
A [Script Icons](#Missing_Glyph_Icons)* can be used.

The UI for giving users choice among restriction levels may
vary considerably. In the case of domain names, only the middle three
levels are interesting. Level 1 turns IDNs completely off, while
Level 5 is not recommended for IDNs.

Note that the examples in Level 4 are chosen for their familiarity to
English speakers. For most languages that customarily use the Latin
script, there is probably little need to mix in other scripts. That
is not necessarily the case for languages that customarily use a
non-Latin script. Because of the widespread commercial use of English
and other Latin-based languages, it is quite common to have
Latin-script characters (especially ASCII) in text that principally
consists of other scripts, such as "[خدمة RSS](http://news.bbc.co.uk/hi/arabic/help/rss/newsid_3492000/3492193.stm?rss=http://newsrss.bbc.co.uk/rss/arabic/news/rss.xml)".

*Section 3, [Identifier
Characters](http://www.unicode.org/reports/tr39/#Identifier_Characters)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)] provides for two profiles of identifiers
that could be used in Restriction Levels 1 through 4. The strict
profile is recommended. If the lenient profile is used, the user
should have some way to choose the strict profile.

At all Restriction Levels, an appropriate alert should be generated
if the domain name contains a syntax character that might be used in
a spoof, as described in *Section 2.6, [Syntax Spoofing](#Syntax_Spoofing)*.

For example, an alert might be presented
for a syntax character spoof:

| warning | You are about to go to the site "bad.com", but part of the address contains a character which may have led you to think you were going to "macchiato.com". This may be an attempt to trick you.  Is "bad.com" the site you want to visit?    Remember my answer for future addresses with "bad.com" |
| --- | --- |

As another example, an alert might be
presented for a mixed-script spoof:

| warning | You are about to go to the site "goоgle.com", but the underlined character is a Cyrillic о. This may be an attempt to trick you.  Is "goоgle.com" the site you want to visit?    Remember my answer for future addresses with "google.com" |
| --- | --- |

This alert does not need to be presented in a dialog window;
there are a variety of ways to alert users, such as in an information
bar.

User agents should remember when the user has accepted an alert, for
say  *Ωmega.com*, and permit future access without bothering the
user again. This essentially builds up a whitelist of allowed values.
This whitelist should contain the "nameprepped" form of
each string. When used for visually confusable detection, each
element in the whitelist should also have an associated transformed
string as described in *Section 4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)*[[UTS39](#UTS39)]. If a system allows
uppercase and lowercase forms, then both transforms should be
available. The program should allow access to editing this whitelist
directly, in case the user wants to correct the values. The whitelist
may also include items known by the user agent to be 'safe'.

#### [2.10.1 Backward Compatibility](#Backwards_Compatibility)

The set of characters in the identifier profile and the results of
the confusable mappings may be refined over time, so implementations
should recognize and allow for that. Characters suitable for
identifiers are periodically added to the Unicode Standard, and thus
the data for *Section 4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)*[[UTS39](#UTS39)] is also periodically
updated.

There may also be cases where characters are no longer
recommended for inclusion in identifiers as more information becomes
available about them. Thus some characters may be removed from the
identifier profile in the future. Of course, once identifiers are
registered they cannot be withdrawn, but new proposed identifiers
that contain such characters can be denied.

### [2.11 Recommendations](#Visual_Spoofing_Recommendations)

The Unicode Consortium recommends a somewhat conservative
approach at this point, because is always easier to widen
restrictions than narrow them.

Some have proposed restricting domain names according to language, to
prevent spoofing. In practice, that is very problematic: it is very
difficult to determine the intended language of many terms,
especially product or company names, which are often constructed to
be neutral regarding language. Moreover, languages tend to be quite
fluid; foreign words are continually being adopted. Except for
registries with very special policies (such as the blocking used by
some East Asian registries as described in [[RFC3743](#RFC3743)]),
the language association does not make too much sense. For more
information, see *Appendix B, [Language-Based Security](#Language_Based_Security)*.

Instead, the Consortium recommends processing strings to remove basic
equivalences, promoting adequate rendering support, and putting
restrictions in place according to script, and restricting by
confusable characters. While the ICANN guidelines say "top-level
domain registries will [...] associate each registered
internationalized domain name with one language or set of
languages" [[ICANN](#ICANN)], that guidance is better
interpreted as limiting to *script* rather than *language*.

Also see the security discussions in IRI [[RFC3987](#RFC3987)],
URI [[RFC3986](#RFC3986)], and Nameprep [[RFC3491](#RFC3491)].

#### [2.11.1 Recommendations for End-Users](#User_Recommendations)

1. Use browsers, mail clients, and other software that have put
   user-agent guidelines into place to detect spoofing.
2. If registering domain names, verify that the registry
   follows appropriate guidelines for preventing spoofing.
3. If the desired domain name can have any whole-script or
   single-script confusables (such as "scope" in Latin and
   Cyrillic), register those as well, if "bundling" is not
   automatically provided by the registry.
4. Where there are alternative domain names, choose those that
   are less spoofable.
5. When using bidi IRIs, follow the recommendations in *Section
   2.5, [Bidirectional Text
   Spoofing](#Bidirectional_Text_Spoofing)*.
6. Be aware that fonts can be used in spoofing, as discussed in
   *Section 2.4.1, [Malicious
   Rendering](#Malicious_Rendering)*. With documents having embedded fonts (web fonts), be
   aware that the content on a printed form can be different than is on
   the screen.

#### [2.11.2 Recommendations for Programmers](#Recommendations_General)

1. When parsing numbers, detect digits of mixed scripts and
   unexpected scripts and alert the user.
2. When defining identifiers in programming languages,
   protocols, and other environments:
   1. Use the general security profile for identifiers from *Section
      3, [Identifier
      Characters](http://www.unicode.org/reports/tr39/#Identifier_Characters)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)]*.*
      * Note that the general security profile
        allows characters from [*Table
        3, Candidate Characters for Inclusion in Identifiers*](http://www.unicode.org/reports/tr31/#Table_Candidate_Characters_for_Inclusion_in_Identifiers) in [[UAX31](#UAX31)], such as U+00B7 (·) MIDDLE DOT used in
        Catalan.
   2. For equivalence of identifiers, preprocess both strings by
      applying NFKC and case folding. Display all such identifiers to
      users in their processed form. (There may be two displays: one in
      the original and one in the processed form.) An example of this
      methodology is Nameprep [[RFC3491](#RFC3491)]. Although
      Nameprep is currently limited to Unicode 3.2, the same methodology
      can be applied by implementations that need to support more
      up-to-date versions of Unicode.
3. In choosing or deploying fonts:
   1. If there is no available glyph for a character, *never*
      show a simple "?" or omit the character.
   2. Use distinctive fonts, where possible.
   3. Use a size that makes it easier to see the differences in
      characters. Disallow the use of font sizes that are so small as to
      cause even more characters to be visually confusable. Use larger
      sizes for East/South/South East Asian scripts, such as for
      Japanese and Thai.
   4. Watch for clipping, vertically and horizontally. That is,
      make sure that the visible area extends outside of the text width
      and height, to the character bounding box: the maximum extent of
      the shape of the glyph.
   5. Assess the font support of the OS/platform according to
      recommendations D1-D3 below (see also the W3C [[CharMod](#CharMod)]).
      If it is inadequate, work with the OS/platform vendor to address
      those problems, or implement special handling of problematic
      cases.
4. In developing rendering systems or fonts:
   1. Verify that accents do not appear to apply to the wrong
      characters.
   2. Follow [UTN
      #2: *Rendering Combining Marks*](http://www.unicode.org/notes/tn2/) in providing layout of nonspacing marks that would otherwise
      collide. If this is not done, follow the "Show Hidden"
      option of *Section 5.13,* [*Rendering
      Nonspacing Marks*](http://www.unicode.org/versions/Unicode5.0.0/ch05.pdf#G1095) of [[Unicode](#Unicode)] for the
      display of nonspacing marks.
   3. Follow the Unicode guidelines for displaying missing
      glyphs using a rounded-rectangle, as described in *Section
      5.3, [Unknown
      and Missing Characters](http://www.unicode.org/versions/Unicode5.0.0/ch05.pdf#G7730)* of [[Unicode](#Unicode)]. The recommended glyphs
      according to scripts are shown in *Appendix A*  *[Script Icons](#Missing_Glyph_Icons)*.

#### [2.11.3 Recommendations for User Agents](#Recommendations_User_Agents)

The following recommendations are for user agents in handling
domain names. The term "user agent" is interpreted broadly
to mean any program that displays Internationalized Domain Names to a
user, including browsers and emailers.

For information on the confusable tests mentioned below, see *Section
4,* *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)]*.* If the user can see the casefolded
form, use the lowercase-only confusable mappings; otherwise use the
broader mappings.

1. Follow *Section 2.10.2, [Recommendations for Programmers](#Recommendations_General)*.
2. Display
   1. Either always show the domain name in nameprepped form [[RFC3491](#RFC3491)], or make it very easy for the user to
      see it (see *Section 2.8.1, [Casefolded Format](#Case_Folded_Format)*). For example,
      this could be a tooltip interface, or a separate box.
   2. Always display the domain name with a visually highlighted
      domain name, to prevent syntax spoofs (see *Section 2.6, [Syntax Spoofing](#Syntax_Spoofing)*).
   3. Always display IRIs with bidi content according to the IRI
      specification [[RFC3987](#RFC3987)].
3. Preferences
   1. In preferences, allow the user to select the desired
      Restriction Level to apply to domain names. Set the default to
      Restriction Level 2.
   2. In preferences, allow the user to select among additional
      scripts that can be used without alerting. The default can be
      based on the user's locale.
   3. In preferences, allow the user to choose a backward
      compatibility setting; see *Section 2.9.1, [Backward Compatibility](#Backwards_Compatibility)*.
4. Alerts
   1. If the user agent maintains a domain whitelist for the
      user, and the domain name is in the whitelist, allow it and skip
      the remaining items in this section. (The domain whitelist can
      take into account the documented policies of the registry as per *Section
      2.10.4, [Recommendations
      for Registries](#Recommendations_Registries)*.)
   2. If the visual appearance of a link does not match the end
      location, alert the user.
   3. If the domain name does not satisfy the requirements of
      the user preferences (such as the Restriction Level), alert the
      user.
   4. If the domain name contains any letters confusable with
      syntax characters, alert the user.
   5. If there is a whitelist, and the domain name is visually
      confusable with a whitelist domain name, but not identical to it
      (after nameprep), alert the user.
   6. If any label in the domain name is a whole-script or a
      mixed-script confusable, alert the user.

#### [2.11.4 Recommendations for Registries](#Recommendations_Registries)

The following recommendations are for registries in dealing
with identifiers such as domain names. The term "Registry"
is to be interpreted broadly, as any agency that sets the policy for
which identifiers are accepted.

Thus the .com operator can impose restrictions on the 2nd level
domain label, but if someone registers *foo.com*, then it is up
to them to decide what will be allowed at the 3rd level (for example,
*bar.foo.com*). So for that purpose, the owner of *foo.com*
is treated as the "Registry" for the 3rd level (the *bar*).
Similarly, the owner of a domain name is acting as an internal
registry in terms of the policies for the non-domain name portions of
a URL, such as *banking*  in *http://bar.foo.com/banking.*
Thus the following recommendations still apply.

For information on the confusable tests mentioned below, see *Section
4,*  *[Confusable
Detection](http://www.unicode.org/reports/tr39/#Confusable_Detection)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].

1. Publicly document the Restriction Level being enforced. For
   IDN, the Restriction Level is not to be higher than Level 4: that
   is, no characters can be outside of the *General Security
   Profiles for Identifiers* in *Section 3, [Identifier
   Characters](http://www.unicode.org/reports/tr39/#Identifier_Characters)* in *UTS #39: Unicode Security Mechanisms* [[UTS39](#UTS39)].
2. Publicly document the enforcement policy on confusables:
   whether two domain names are allowed to be single-script or mixed
   script confusables.
3. If there are any pre-existing exceptions to A or B, then
   document them also.
4. Define an IDN registration in terms of both its
   Nameprep-Normalized Unicode representation (the *output format*)
   and its Punycode representation.

#### [2.11.5 Registrar Recommendations](#Recommendations_Registrars)

The following recommendations are for registrars in dealing
with domain names. The term "Registrar" is to be
interpreted broadly, as any agency that presents a UI for registering
domain names, and allows users to see whether a name is registered.
The same entity may be both a Registrar and Registry.

1. When a user's name is (or would be) rejected by the
   registry for security reasons, show the user the reason for
   rejection (such as the existence of an already-registered
   confusable).

## 3 [Non-Visual Security Issues](#Canonical_Represenation)

There are a number of exploits based on misuse of character
encodings. Some of these are fairly well-known, such as buffer
overflows in conversion, while others are not. Many are involved in
the common practice of having a 'gatekeeper' for a system.
That gatekeeper checks incoming data to ensure that it is safe, and
passes only safe data through. Once in the system, the other
components assume that the data is safe. A problem arises when a
component treats two pieces of text as identical—typically by
canonicalizing them to the same form—but the gatekeeper only detected
that one of them was unsafe.

For example, suppose that strings containing the letters
"delete" are sensitive internally, and that therefore a
gatekeeper checks for them. If some process casefolds
"DELETE" *after* the gatekeeper has checked, then
the sensitive string can sneak through. While many programmers are
aware of this, they may not be aware that the same thing can happen
with other transformations, such as an NFKC transformation of
"Ⓓⓔⓛⓔⓣⓔ" into "delete".

These gatekeeper problems can also happen with charset
converters. Where a character in a source string cannot be expressed
in a target string, it is quite common for charset converters to have
a "fallback conversion", picking the next best conversion.
For example, when converting from Unicode to Latin-1, the character
"ⓔ" cannot be expressed exactly, and the converter may fall
back to "e". This can be used for the same kind of exploit.
Unfortunately, some charset converter APIs, such as in Java, do not
allow such fallbacks to be turned off. This is not only a problem for
security, but also for other kinds of processing. For example, when
converting an XML or HTML page, a character such as "ⓔ"
missing from the target charset must be represented by an NCR such as
&#x24D4; instead of using a lossy converter. Where possible,
using Unicode instead of other charsets avoids many of these kinds of
problems.

### 3.1 [UTF-8 Exploit](#UTF-8_Exploit)s

There are three equivalent encoding forms for Unicode: UTF-8,
UTF-16, and UTF-32. UTF-8 is commonly used in XML and HTML; UTF-16 is
the most common in program APIs; and UTF-32 is the best for
representing single characters. While these forms are all equivalent
in terms of the ability to express Unicode, the original usage of
UTF-8 was open to a canonicalization exploit.

Originally, Unicode forbade the *generation* of
"non-shortest form" UTF-8, but not the *interpretation*
of "non-shortest form" UTF-8. This was fixed in Unicode
3.0, because security issues can arise when software does interpret
the non-shortest forms. For example:

* Process *A* performs security checks, but does not
  check for non-shortest forms.
* Process *B* accepts the byte sequence from process *A*,
  and transforms it into UTF-16 while interpreting non-shortest forms.
* The UTF-16 text may then contain characters that should have
  been filtered out by process *A*.

For example, the backslash character "\" can often be
a dangerous character to let through a gatekeeper, because it can be
used to access different directories. Thus a gatekeeper might
specifically prevent it from getting through. The backslash is
represented in UTF-8 as the byte sequence <5C>. However, as a
non-shortest form, backslash could also be represented as the byte
sequence<C1 9C>. When a gatekeeper does not check for
non-shortest form, this situation can lead to a severe security
breach.

To address this issue, the Unicode Technical Committee modified the
definition of UTF-8 in [Unicode
3.1](http://www.unicode.org/reports/tr27/) to forbid conformant implementations from interpreting
non-shortest forms for [BMP
characters](http://www.unicode.org/glossary/#BMP_character), and clarified some of the conformance clauses.

#### 3.1.1 [Ill-Formed Subsequences](#Ill-Formed_Subsequences)

Suppose that a UTF-8 converter is iterating through input UTF-8
bytes, converting to an output character encoding. If the converter
encounters an ill-formed UTF-8 sequence it can treat it as an error
in a number of different ways, including substituting a character
like U+FFFD, SUB, "?", or SPACE. However, it *must
not* consume any valid successor bytes. For example, suppose we have
the following sequence:

> X = <... 41 **C2** 3E 42 ... >

This sequence overall is ill-formed, because it contains an
ill-formed substring, namely the <**C2**>. That is, there is
no substring of X containing the **C2** byte which matches the
specification for UTF-8 in Table 3-7 of Unicode 5.2 [[Unicode](#Unicode)]. The UTF-8 converter can stop at the **C2**
byte, or substitute a character or sequence like U+FFFD and continue.
However, it must not consume the **3E** byte if it continues. That
is, it is acceptable to convert X to “...**A >B**...”, but not
acceptable to convert X to **“...A B...”** (that is, deleting the
>).

Consuming a subsequent byte (such as **3E** above) is
not only non-conformant; it can lead to security breaches. For
example, suppose that a web page is constructed with user input. The
user input is filtered to catch problem attributes such as
onMouseOver. However, incorrect conversion can defeat that filtering
by removing important syntax characters like > in HTML attribute
values. Take the following string, where “✘” indicates a bare **C2**
byte:

> <span style=width:100%✘> onMouseOver=doBadStuff()...

When this is converted with a bad UTF-8 converter, the **C2**
would cause the > character to be consumed, and the HTML served up
would be of the following form, allowing for a cross-site scripting
attack:

> <span style=width:100% onMouseOver=doBadStuff()...

For more information on how to handle ill-formed subsequences, see
"Constraints on Conversion Processes" in *Section
3.9, Unicode Encoding Forms* in Unicode 5.2 [[Unicode](#Unicode)].

#### 3.1.2 [Substituting for Ill-Formed Subsequences](#Substituting_for_Ill_Formed_Subsequences)

If characters *are* to be substituted for ill-formed
subsequences, it is important that those characters be relatively
safe.

* Deletion (substituting the empty string) can be quite nasty,
  because it joins characters that would have been separate (such as
  on MouseOver).
* Substituting characters that are valid syntax for constructs
  such as file names has similar problems. For example, the
  '.' can be very problematic.
  + U+FFFD is usually unproblematic, because it is designed
    expressly for this kind of purpose. That is, because it does not
    have syntactic meaning in programming languages or structured
    data, it will typically just cause a failure in parsing. Where the
    output character set is not Unicode, though, this character may
    not be available.
  + Where U+FFFD is not available, a common alternative is
    "?". While this character may occur syntactically, it
    appears to be less subject to attack than most others.

UTF-16 converters that do not handle isolated surrogates
correctly are subject to the same type of attack, although
historically UTF-16 converters have generally handled these well.

### 3.2 [Text Comparison](#Text_Comparison) (Sorting, Searching, Matching)

The UTF-8 exploit is a special case of a general problem. Security
problems may arise where a user and a system (or two systems) compare
text differently. For example, this happens where text does not
compare as users expect. See the discussions in *UTS#10:
Unicode Collation Algorithm* [[UTS10](#UTS10)], especially
Section 1.

A system is particularly vulnerable when two
different implementations of the same protocol use different
mechanisms for text comparison, such as the comparison as to whether
two identifiers are equivalent or not.

Assume a system consists of two modules: a user
registry and the access control. Suppose that the user registry does
not use NamePrep, while the access control module does. Two
situations can arise:

1. The user with valid access rights to a certain
   resource actually cannot access it, because the binary
   representation of user ID used for the user registry differs from
   the one specified in the access control list. This situation is not
   a major security concern—because the person in this situation
   cannot access the protected resource.
2. The opposite case creates a security hole: a new
   user whose ID is NamePrep-equivalent to another user's in the
   directory system can get the access right to a protected resource.

For example, a fundamental standard, [[LDAP](#LDAP)], used
to be subject to this problem; thus steps were taken to remedy this
in later versions.

There are some other areas to watch for. Where these
are overlooked, it may leave a system open to the text comparison
security problems.

1. Normalization is context dependent; do not assume
   NFC(x + y) = NFC(x) + NFC(y).
2. There are ***two*** binary Unicode orders: code
   point/UTF-8/UTF-32 and UTF-16 order. In the latter, U+10000 **<**
   U+E000 (because U+10000 = D800 DC00).
3. Avoid using non-Unicode charsets where possible. IANA / MIME
   charset names are ill-defined: vendors often convert the same
   charset different ways. For example, in Shift-JIS the value 0x5C
   converts to ***either***U+005C ***or*** U+00A5 depending on the vendor, resulting in
   different, unrelated characters with unrelated glyphs. See:
   * <http://www.w3.org/TR/japanese-xml/>
   * <http://icu.sourceforge.net/charts/charset/>
4. When converting charsets, *never* simply omit
   characters that cannot be converted; at least substitute U+FFFD
   (when converting to Unicode) or 0x1A (when converting to bytes) to
   reduce security problems. See also [[UTS22](#UTS22)].
5. Regular expression engines use character properties in
   matching. They may vary in how they match, depending on the
   interpretation of those properties. Where regex matching is
   important to security, ensure that the regular expression engine
   conforms to the requirements of [[UTS18](#UTS18)], and
   uses an up-to-date version of the Unicode Standard for its
   properties.

Transitivity is crucial to correct functioning of sorting
algorithms. Transitivity means that if a < b and b < c then a
< c. It means that there cannot be any cycles: a < b < c
< a.

A lack of transitivity in string comparisons may cause security
problems, including denial-of-service attacks. As an example of a
failure of transitivity, consider the following pseudocode:

```
int compare(a,b) {
  if (isNumber(a) && isNumber(b)) {
    return numberComparison(a,b);
  } else {
    return textComparison(a,b);
  }
}
```

The code seems straightforward, but produces the following
non-transitive result:

"12" < "12a" < "2" <
"12"

For the first two comparisons, one of the values is not a
number, therefore both values are compared as text. For the last two,
both are numbers, and compared numerically. This breaks transitivity
because a cycle is introduced.

The following pseudocode illustrates one way to repair the
code, by sorting all numbers before all non-numbers:

```
int compare(a,b) {
  if (isNumber(a)) {
    if (isNumber(b)) {
      return numberComparison(a,b);
    } else {
      return -1; // a is less than b, since a is a number and b isn't
    }
  } else if (isNumber(b)) {
    return 1;    // b is less than a, since b is a number and a isn't
  } else {
    return textComparison(a,b);
  }
}

```

Therefore, for complex comparisons, such as language-sensitive
comparison, it is important to test for transitivity thoroughly.

### 3.3 [Buffer Overflows](#Buffer_Overflows)

Some programmers may rely on limitations that are
true of ASCII or Latin-1, but fail with general Unicode text. These
can cause failures such as buffer overruns if the length of text
grows. In particular:

1. Strings may
   expand in casing: Fluß → FLUSS → fluss.
   The expansion factor may change depending on the UTF as well.
2. Programmers
   assume that NFC always composes, and thus is the same or shorter
   length than the original source. However, some characters *decompose*
   in NFC. The expansion factor may change depending on the UTF as
   well.
3. *Table 9, [Maximum
   Expansion Factors](#TableMaximumExpansionFactors)* illustrates the expansions for case operations
   and normalization. These factors are for a particular version of
   Unicode: they should be recomputed for the particular version of
   Unicode being used.
   * The very large factors in the case of NFKC and NFKD are
     due to some extremely rare characters. Thus algorithms can use
     much smaller expansion factors for the typical cases as long as
     they have a fallback process that accounts for the possibility of
     these characters in data.
   * As of Unicode 5.0, a *Stream-Safe Text Format* was
     added to *UAX #15: Unicode Normalization Forms [[UAX15](#UAX15)]*. This format allows protocols to limit the number of characters
     that they need to buffer in handling normalization.
4. When performing character conversion, text may grow or
   shrink, sometimes substantially. Always account for that possibility
   in processing.

Table 9.
 [Maximum Expansion
Factors](#TableMaximumExpansionFactors)

| Operation | UTF | Factor | Sample | |
| Lower | 8 | 1.5X | Ⱥ | U+023A |
| 16, 32 | 1X | A | U+0041 |
| Upper/Title/Fold | 8, 16, 32 | 3X | ΐ | U+0390 |
| Operation | UTF | Factor | Sample | |
| NFC | 8 | 3X | 𝅘𝅥𝅮 | U+1D160 |
| 16, 32 | 3X | שּׁ | U+FB2C |
| NFD | 8 | 3X | ΐ | U+0390 |
| 16, 32 | 4X | ᾂ | U+1F82 |
| NFKC/NFKD | 8 | 11X | ﷺ | U+FDFA |
| 16, 32 | 18X |

### 3.4 [Property and Character Stability](#Property_and_Character_Stability)

The Unicode Consortium Stability Policies [[Stability](#Stability)]
limit the ways in which the standards developed by the Unicode
Consortium can change. These policies are intended to ensure that
text encoded in one version of the Unicode Standard remains valid and
unchanged in later versions. In many cases, the constraints imposed
by these stability policies allow implementers to simplify support
for particular features of Unicode, with the assurance that their
implementations will not be invalidated by a later update to Unicode.

Implementations should not make assumptions beyond what is documented
in the Stability Policies. For example, some implementations assumed
that no new decomposable characters would be added to Unicode. The
actual restriction is slightly looser: that decomposable characters
will not be added if their decompositions were already in Unicode. It
is therefore possible to add a decomposable character *if* one
of the characters in its decomposition is also new in that version of
Unicode. For example, decomposable Balinese characters were added to
the standard in Version 5.0, which caused some implementations to
break.

Similarly, some applications assumed that all Chinese
characters were three bytes in UTF-8. Thus once a string was known to
be all Chinese, iteration through the string could take the form of
simply advancing an offset or pointer by three bytes. This assumption
proved incorrect and caused implementations to break when Chinese
characters were added on Plane 2, requiring 4-byte representations in
UTF-8.

Making such unwarranted assumptions can lead to security problems.
For example, advancing uniformly by three bytes for Chinese will
corrupt the interpretation of text, leading to problems like those
mentioned in *Section 3.1.1,  [Ill-Formed\_Subsequences](#Ill-Formed_Subsequences)*.
Implementers should thus be careful to only depend on the documented
stability policies.

An implementation may need to make certain assumptions for
performance—assumptions that are not guaranteed by the policies. In
such a case, it is recommended to at least have unit tests that
detect whether those assumptions have become invalid when the
implementation is upgraded to a new version of Unicode. That allows
the problem to be detected and code to be revised if the assumption
is invalidated.

### 3.5 [Deletion of Code Points](#Deletion_of_Noncharacters)

In some versions prior to Unicode 5.2, conformance clause C7
allowed the deletion of noncharacter code points:

> C7. When a process purports not to modify the interpretation of a
> valid coded character sequence, it shall make no change to that coded
> character sequence other than the possible replacement of character
> sequences by their canonical-equivalent sequences ***or
> the deletion of noncharacter code points*****.**

Whenever a character is invisibly deleted (instead of
replaced), such as in this older version of C7, it may cause a
security problem. The issue is the following: A gateway might be
checking for a sensitive sequence of characters, say "delete". If
what is passed in is "deXlete", where X is a noncharacter, the
gateway lets it through: the sequence "deXlete" may be in and of
itself harmless. However, suppose that later on, past the gateway, an
internal process invisibly deletes the X. In that case, the sensitive
sequence of characters is formed, and can lead to a security breach.

The following is an example of how this can be used for
malicious purposes.

> <a href=“java**\uFEFF**script:alert("XSS")>

### 3.6 [Secure Encoding Conversion](#SecureEncodingConversion)

In addition to handling Unicode text safely, character encoding
conversion also needs to be designed and implemented carefully in
order to avoid security issues.

#### [3.6.1 Illegal Input Byte Sequences](#Illegal_Input_Byte_Sequences)

When converting from a multi-byte encoding, a byte value may
not be a valid trailing byte, in a context where it follows a
particular leading byte. For example, when converting UTF-8 input,
the byte sequence E3 80 22 is malformed because 0x22 is not a valid
second trailing byte following the leading byte 0xE3. Some conversion
code may report the three-byte sequence E3 80 22 as one illegal
sequence and continue converting the rest, while other conversion
code may report only the two-byte sequence E3 80 as an illegal
sequence and continue converting with the 0x22 byte which is a syntax
character in HTML and XML (U+0022 double quote). Implementations that
report the 0x22 byte as part of the illegal sequence can be exploited
for cross-site-scripting (XSS) attacks.

Therefore, an illegal byte sequence must not include bytes that
encode valid characters or are leading bytes for valid characters.

The following are safe error handling strategies for conversion
code dealing with illegal multi-byte sequences. (An illegal
single/leading byte does not pose this problem.)

1. Stop with an error. Do not continue converting the rest of
   the text.
2. In a reported illegal byte sequence, do not include any
   non-initial byte that encodes a valid character or is a leading byte
   for a valid sequence.
3. Report the first byte of the illegal sequence as an error
   and continue with the second byte.

Strategy 1 is the simplest, but in many cases it is desirable
to convert as much of the text as possible. For example, a web
browser will usually replace a small number of illegal byte sequences
with U+FFFD each and display the page as best it can. Strategy 3 is
the next simplest but can lead to multiple U+FFFD or other error
handling artifacts for what is a single-byte error.

Strategy 2 is the most natural and fits well with an assumption
that most errors are not due to physical transmission corruption but
due to truncated multi-byte sequences from improper string handling.
It also avoids going back to an earlier byte stream position in most
cases.

Converters for single-byte encodings are unaffected by any of these
issues. Nor are converters for the Character Encoding Schemes
UTF-16 and UTF-32 and their variants affected, because they are not
really byte-based encodings: they are often "converted" via memcpy(),
at most with a byte swap, so a converter needs to always deliver
pairs or quads of bytes.

#### [3.6.2 Some Output For All Input](#Some_Output_For_All_Input)

Character encoding conversion must also not simply skip an illegal
input byte sequence. Instead, it must stop with an error or
substitute a replacement character (such as [U+FFFD](http://unicode.org/cldr/utility/character.jsp?a=FFFD) ( � )
REPLACEMENT CHARACTER) or an escape sequence in the output. (See also
*Section 3.5 [Deletion
of Code Points](#Deletion_of_Noncharacters)*.) It is important to do this not only for byte
sequences that encode characters, but also for unrecognized or
"empty" state-change sequences. For example:

* An illegal or unrecognized ISO-2022 designation or escape
  sequence.
* Pairs of SI/SO without text characters between them.
* ISO-2022 shift sequences without text characters before the
  next shift sequence. The formal syntaxes for HZ and most CJK
  ISO-2022 variants require at least one character in a text segment
  between shift sequences. Security software written to the formal
  specification may not detect malicious text  (for example, "delete"
  with a shift-to-double-byte then an immediate shift-to-ASCII in the
  middle).

### 3.7 [Enabling Lossless Conversion](#EnablingLosslessConversion)

There is a known problem with file systems that use a legacy
charset. When a Unicode API is used to find the files in a directory,
the return value is a list Unicode file names. Those names are used
to access the files through some other API. There are two possible
problems:

* One of the file names is invalid according to the legacy
  charset converter. For example, it is an [SJIS](http://demo.icu-project.org/icu-bin/convexp?conv=ibm-943_P15A-2003) string consisting of bytes <E0 30>.
* Two of the file names are mapped to the same Unicode string
  by the legacy charset converter.

These problems come up in other situations besides file systems
as well. One common source of the problem is a byte string valid in
one charset that is converted according to a different charset. For
example, the byte string <E0 30> is invalid in SJIS, but is
perfectly meaningful in Latin-1, representing "à0".

One possible solution is to enable all charset converters to
losslessly (reversibly) convert to Unicode. That is, any sequence of
bytes can be converted by each charset converter to a Unicode string,
and that Unicode string would be converted back to exactly that
original sequence of bytes by the converter. This precludes, for
example, the charset converter's mapping two different [unmappable](http://unicode.org/reports/tr22/#Illegal_and_Unassigned) byte sequences to
`[U+FFFD](http://unicode.org/cldr/utility/character.jsp?a=FFFD)`
( � ) REPLACEMENT CHARACTER, because the original bytes
could not be recovered. It also precludes having "fallbacks" (see <http://unicode.org/reports/tr22/>): cases where two different byte
sequences map to the same Unicode sequence.

#### 3.7.1 [PEP 383 Approach](#TOC-PEP-383-Approach)

[PEP 383](http://www.python.org/dev/peps/pep-0383/) takes
this approach. It enables lossless conversion to Unicode by
converting all "unmappable" sequences to a sequence of one or more
isolated surrogate code points. That is, each unmappable byte's value
is a code point whose value is 0xDC00 plus byte value. With this
mechanism, every maximal subsequence of bytes that can be reversibly
mapped to Unicode by the charset converter is so mapped; any
intervening subsequences are converted to a sequence of high
surrogates. The result is a [Unicode
String](http://unicode.org/glossary/#unicode_string), but not a well-formed UTF sequence.

For example, suppose that the byte 81 is illegal in charset *n*.
When converted to Unicode, PEP 383 represents this as U+D881. When
mapped back to bytes for charset *n*, it turns back into the
byte 81. This allows the source byte sequence to be reversibly
represented in a [Unicode
String](http://unicode.org/glossary/#unicode_string), no matter what the contents. If this mechanism is applied to
a charset converter that has no fallbacks from bytes to Unicode, then
the charset converter becomes reversible (from bytes to Unicode to
bytes).

This only works when the [Unicode
String](http://unicode.org/glossary/#unicode_string) is converted back with the very same charset converter that
was used to convert from bytes. For more information on PEP 383, see
<http://python.org/dev/peps/pep-0383/>.

#### 3.7.2 [Notation](#TOC-Notation)

The following notation is used in the rest of this section:

* B2Un is the bytes-to-Unicode converter for charset n
* U2Bn is the Unicode-to-bytes converter for charset n
* An *invalid* byte is one that would be mapped by a PEP
  to a high surrogate, because it is part of a sequence that is not
  reversibly mappable. The context of the byte is important: for
  example, the byte 81 alone might be unmappable, while an 81 followed
  by a 40 is valid.

#### 3.7.3 [Security](#TOC-Security)

Unicode implementations have been subject to a number of security
exploits centered around ill-formed encoding, such as <http://blogs.technet.com/srd/archive/2009/05/18/more-information-about-the-iis-authentication-bypass.aspx>.
Systems making incorrect use of a PEP 383-style mechanism are subject
to such an attack.

Suppose that the source byte stream is <A B X D>, and
that according to the charset converter being used (n), X is an
invalid byte. B2Un transforms the byte stream into Unicode as <G Y
H>, where Y is an isolated surrogate. U2Bn maps back to the
correct original <A B X D>. This is the intended usage of PEP
383.

The problem comes when that Unicode sequence is converted back to
bytes by a different charset converter *m*. Suppose that U2Bm
maps Y into a valid byte representing "/", or any one of a number of
other security-sensitive characters. That means that converting <G
Y H> via U2Bm to bytes, and back to Unicode results in the string
"G/Y", where the "/" did not exist in the original.

This violates one of the cardinal security rules for
transformations of Unicode strings: creating a character where no
valid character previously existed. This was at the heart of the
"non-shortest form" security exploits. A gatekeeper watches for
suspicious characters. It does not see Y as one of them, but past the
gatekeeper, a conversion of U2Bm followed by B2Um results in a
suspicious character where none previously existed.

There is a suggested solution for this. A converter would map an
isolated surrogate Y onto a byte stream only when the resulting byte
would be an *illegal* byte. If not, then an exception would be
thrown, or a replacement byte or byte sequence must be used instead
(such as the SUB character). For details, see *Section 3.7.5
 [Safely Converting to
Bytes](#TOC-Safely-Converting-to-Bytes)*. This replacement would be similar to what is used when trying to
convert a Unicode character that cannot be represented in the target
encoding. This strategy preserves the ability to round-trip when the
same encoding is used, but prevents security attacks. *Note
that simply deleting Y in the output is not an option, because that
is also open to security exploits.*

When used as intended in Python, PEP 383 appears unlikely to
present security problems. According to information from the author:

* PEP 383 is only intended for use with ASCII-based charsets.
* Only bytes >= 128 will be transformed to D8xx or back.
* The combination of these factors means that no
  ASCII-repertoire characters (which represent the most serious
  problems for security) would ever be generated.
* The primary use of PEP 383 is in file systems, where the [Unicode
  String](http://unicode.org/glossary/#unicode_string) resulting from PEP 383 is only converted back to bytes on
  the same system, using the same charset converter.

However, if PEP 383 is used more generally by applications, or
similar systems are used more generally, security exploits are
possible.

#### 3.7.4 [Interoperability](#TOC-Interoperability)

Using isolated surrogates (D8xx) as the way to represent the
unconvertible bytes appears harmless at first glance. However, it
presents certain interoperability and security issues. Such isolated
surrogates are not well-formed. Although they can be represented in a
[Unicode
String](http://unicode.org/glossary/#unicode_string), they are not supported by conformant UTF-8, UTF-16, or
UTF-32 converters or implementations. This may cause interoperability
problems, because many systems replace incoming ill-formed Unicode
sequences by replacement characters. It may also cause security
problems. Although strongly discouraged for security reasons, some
implementations may delete the isolated surrogates, which can cause a
security problem when two separated substrings become adjacent.

There are different alternatives:

1. Use 256 private-use code points, somewhere in the ranges
   F0000..FFFFD or 100000..10FFFD. This would probably cause the fewest
   security and interoperability problems. There is, however, some
   possibility of collision with other uses of private-use characters.
2. Use pairs of noncharacter code points in the range
   FDD0..FDEF. These are "super" private-use characters, and are
   discouraged for general interchange. The transformation would take
   each nibble of a byte Y, and add to FDD0 and FDE0, respectively.
   However, noncharacter code points may be replaced by `[U+FFFD](http://unicode.org/cldr/utility/character.jsp?a=FFFD)` ( � ) REPLACEMENT CHARACTER by some implementations,
   especially when they use them internally. *(Again, incoming
   characters must never be deleted, because that can cause security
   problems.)*

#### 3.7.5 [Safely Converting to Bytes](#TOC-Safely-Converting-to-Bytes)

The following describes how to safely convert a Unicode buffer
U1 to a byte buffer B1 when the D8xx convention is used.

* Convert from Unicode buffer U1 to byte buffer B1.
* If there were any D8XX's in U1
  + Convert back to Unicode buffer U2 (according to the same
    Charset C1)
  + If U1 != U2, throw an exception.

This approach is simple, and sufficient for the vast majority
of implementations because the frequency of D8xx's will be extremely
low. Where necessary, there are a number of different optimizations
that can be used to increase performance.

### [3.8 Idempotence](#TOC-Idempotence)

idempotence is a property of a function, whereby repeated
application of that function produces the same result. That is:
f(f(x)) = f(x). Some functions have this property, such as f(x) :=
|x|, while others do not, such as f(x) := x+1.

Properties that are expected to be idempotent—but actually aren't—can
represent severe problems for security. For more information, see the
[Unicode
Security FAQ](http://www.unicode.org/faq/security.html).

---

## Appendix A [Script Icons](#Missing_Glyph_Icons)

*Table 10, [Sample
Script Icons](#TableSampleScriptIcons)* shows sample icons that can be used to represent
scripts in user interfaces. They are derived from from the *Last
Resort Font*, which is available on the Unicode site [[LastResort](#LastResort)]. While the Last Resort Font is
organized by Unicode block instead of by script, the glyphs from that
font can also be used to represent scripts. This is done by picking
one of the possible glyphs whenever a script spans multiple blocks.

Table 10. [Sample Script Icons](#TableSampleScriptIcons)

| X Arabic | X Armenian | X Bengali |
| X Bopomofo | X Braille | X Buginese |
| X Buhid | X Canadian Aboriginal | X Cherokee |
| X Coptic | X Cypriot | X Cyrillic |
| X Deseret | X Devanagari | X Ethiopic |
| X Georgian | X Glagolitic | X Gothic |
| X Greek | X Gujarati | X Gurmukhi |
| X Hangul | X Han | X Hanunoo |
| X Hebrew | X Hiragana | X Latin |
| X Lao | X Limbu | X Linear B |
| X Kannada | X Katakana | X Kharoshthi |
| X Khmer | X Mongolian | X Myanmar |
| X Malayalam | X Ogham | X Old Italic |
| X Old Persian | X Oriya | X Osmanya |
| X New Tai Lue | X Runic | X Shavian |
| X Sinhala | X Syloti Nagri | X Syriac |
| X Tagalog | X Tagbanwa | X Tai Le |
| X Tamil | X Telugu | X Thaana |
| X Thai | X Tibetan | X Tifinagh |
| X Ugaritic | X Yi |  |
| Special cases | | |
| X Common | X Inherited |  |

## Appendix B [Language-Based Security](#Language_Based_Security)

It is very hard to determine exactly which characters are used
by a language. For example, English is commonly thought of as having
letters A-Z, but in customary practice many other letters appear as
well. For examples, consider proper names such as "Zoë",
words from the Oxford English Dictionary such as
"coöperate", and many foreign words in common use:
"René", ‘naïve’, ‘déjà vu’, ‘résumé’, and so on.Thus the
problem with restricting identifiers by language is the difficulty in
defining exactly what that implies. See the following definitions:

> **Language**: Communication of thoughts and feelings through a
> system of arbitrary signals, such as voice sounds, gestures, or
> written symbols. Such a system including its rules for combining its
> components, such as words. Such a system as used by a nation,
> people, or other distinct community; often contrasted with dialect.
> *(From American Heritage, Web search)*

> **Language**: The systematic, conventional use of sounds, signs,
> or written symbols in a human society for communication and
> self-expression. Within this broad definition, it is possible to
> distinguish several uses, operating at different levels of
> abstraction. In particular, linguists distinguish between language
> viewed as an act of speaking, writing, or signing, in a given
> situation […], the linguistic system underlying an individual’s use
> of speech, writing, or sign […], and the abstract system underlying
> the spoken, written, or signed behaviour of a whole community. *(David
> Crystal, An Encyclopedia of Language and Languages)*

> **Language** is a finite system of arbitrary symbols combined
> according to rules of grammar for the purpose of communication.
> Individual languages use sounds, gestures, and other symbols to
> represent objects, concepts, emotions, ideas, and thoughts…
>
> Making a principled distinction between one language and
> another is usually impossible. For example, the boundaries between
> named language groups are in effect arbitrary due to blending
> between populations (the dialect continuum). For instance, there are
> dialects of German very similar to Dutch which are not mutually
> intelligible with other dialects of (what Germans call) German.
>
> Some like to make parallels with biology, where it is not always
> possible to make a well-defined distinction between one species and
> the next. In either case, the ultimate difficulty may stem from the
> interactions between languages and populations.  *<http://en.wikipedia.org/wiki/Language>, September 2005*

The Unicode Common Locale Data
Repository (CLDR) supplies a set of exemplar characters per language,
the characters used to write that language. Originally, there was a
single set per language. However, it became clear that a single set
per language was far too restrictive, and the structure was revised
to provide auxiliary characters, other characters that are in more or
less common use in newspapers, product and company names, and so on.
For example, auxiliary set provided for English is: [áà éè íì óò úù
âêîôû æœ äëïöüÿ āēīōū ăĕĭŏŭ åø çñß]. As this set makes clear, the
frequency of occurrence of a given character may depend greatly on
the domain of discourse, and it is difficult to draw a precise line;
instead there is a trailing off of frequency of occurrence.

In contrast, the definitions of writing systems and scripts are
much simpler:

> **Writing system**: A determined collection of characters or
> signs together with an associated conventional spelling of texts,
> and the principle therefore. *(extrapolated from
> Daniels/Bright: The World's Writing Systems)*
>
> **Script**: A collection of symbols used to represent textual
> information in one or more writing systems.

Writing systems and scripts only relate to the written form of
the language and do not require judgment calls concerning language
boundaries. Therefore security considerations that relate to written
form of languages are often better served by using the concept of
writing system and/or script.

**Note:** A writing system uses one or more scripts, plus
additional symbols such as punctuation. For example, the Japanese
writing system uses the scripts Hiragana, Katakana, Kanji (Han
ideographs), and sometimes Latin.

Nevertheless, language identifiers
are extremely useful in other contexts. They allow cultural tailoring
for all sorts of processing such as sorting, line breaking, and text
formatting.

**Note:** As mentioned below, language identifiers (called
language tags), may contain information about the writing system and
can help to determine an appropriate script.

As explained in the *Section 6.1, Writing Systems* of [[Unicode](#Unicode)], scripts can be classified in various
groups: Alphabets, Abjads, Abugidas, Logosyllabaries, Simple or
Featural Syllabaries. Those classifications, in addition to historic
evidence, makes it reasonably easy to arrange encoded characters into
script classes.

The set of characters sharing the same script value determines a
script set. The script value can be easily determined by using the
information available in *UAX #24: Unicode Script Property*.
No such concept exists for languages. It is generally not possible to
attach a single language property value to a given character.
Similarly, it is not possible to determine the exact repertoire of
characters used for the written expression of most common languages.

Creating "safe character
sets" is an important goal in a security context, and it would
appear that the characters used in a language is an obvious choice.
However, because of the indeterminate set of characters used for a
language, it is typically more effective to move to the higher level,
the script, which can be more easily specified and tested.

Customarily, languages are written in a small number of scripts. This
is reflected in the structure of language tags, as defined by BCP47
"Tags for the Identification of Languages", which are the
industry standard for the identification of languages. Languages that
require more than one script are given separate language tags. See <http://www.iana.org/assignments/language-subtag-registry>.

The CLDR also provides a mapping from languages to scripts which is
being extended over time to more languages. *Table 11, [CLDR Script Mappings](#TableCLDRScriptMappings)* provides
examples of the association between language tags and default
scripts. (CLDR also provides other information about scripts, such as
the most likely language for each script, and the most likely script
for each language, plus script metadata.)

Table 11. [CLDR Script Mappings](#TableCLDRScriptMappings)

| Language tag | Script(s) | Comment |
| en | Latin | Content in ‘en’ is presumed to be in Latin script, unless where explicitly marked |
| az- | Cyrillic | Azeri in Cyrillic script used in Azerbaijan |
| az-Latn-AZ | Latin | Azeri in Latin script used in Azerbaijan |
| az | Latin, | Azeri as used generically, can be Latin or Cyrillic |
| ja | Han, | Japanese as used in Japan or elsewhere |

The strategy of using scripts works extremely well for most of
the encoded scripts because users are either familiar with the
entirety of the script content, or the outlying characters are not
very confusable. There are however a few important exceptions, such
as the Latin and Han scripts. In those cases, it is recommended to
exclude certain technical and historic characters except where there
is a clear requirement for them in a language.

Lastly, text confusability is an inherent attribute of many writing
systems. However, if the character collection is restricted to the
set familiar to a culture, it is expected by the user, and he or she
can therefore weigh the accuracy of the written or displayed text.
The key is to (normally) restrict identifiers to a single script,
thus vastly reducing the problems with confusability. For example, in
Devanagari, the letter *aa*: आ can be confused with the
sequence consisting of the letter a अ followed by the vowel sign aa
ा. However, this is a confusability a Hindi speaking user may be
familiar with, as it relates to the structure of the Devanagari
script.

In contrast, text confusability that crosses script boundary is
completely unexpected by users within a culture, and unless some
mitigation is in place, it will create significant security risk. For
example, the Cyrillic small letter п ("pe") is
undistinguishable from the Greek letter π in at least some fonts, and
the confusion is likely to be unknown to users in cultural context
using either script. Restricting the identifier to either wholy Greek
or wholy Cyrillic will usually avoid this issue.

## [Acknowledgments](#Acknowledgments)

Mark Davis and Michel Suignard authored the bulk of the text,
under the direction of the Unicode Technical Committee. Steven Loomis
and other people on the ICU team were very helpful in developing the
original proposal for this technical report. Thanks also to the
following people for their feedback or contributions to this document
or earlier versions of it: Julie Allen, Stéphane Bortzmeyer, Roger
Costello, Douglas Davidson, Martin Dürst, Peter Edberg, Asmus
Freytag, Deborah Goldsmith, Paul Hoffman, Patrick L. Jones, Peter
Karlsson, Gervase Markham, Eric Muller, Erik van der Poel, Michael
van Riper, Marcos Sanz, Alexander Savenkov, Markus Scherer, Dominikus
Scherkl, Dave Thompson, Kenneth Whistler, and Yoshito Umaoka.

## [References](#References)

| [[CharMod](#CharMod)] | Character Model for the World Wide Web 1.0: Fundamentals <http://www.w3.org/TR/charmod/> |
| --- | --- |
| [[DCore](#DCore)] | Derived Core Properties <http://www.unicode.org/Public/UNIDATA/DerivedCoreProperties.txt> |
| [[DemoConf](#DemoConf)] | <http://unicode.org/cldr/utility/confusables.jsp> |
| [[DemoIDN](#DemoIDN)] | <http://unicode.org/cldr/utility/idna.jsp> |
| [[DemoIDNChars](#DemoIDNChars)] | <http://unicode.org/cldr/utility/list-unicodeset.jsp?a=\p{age%3D3.2}-\p{cn}-\p{cs}-\p{co}&abb=on&g=uts46+idna+idna2008> |
| [[Display](#Display)] | Display Problems? <http://www.unicode.org/help/display_problems.html> |
| [[FAQSec](#FAQSec)] | Unicode FAQ on Security Issues <http://www.unicode.org/faq/security.html> |
| [[ICANN](#ICANN)] | ICANN Documents:  Internationalized Domain Names <http://www.icann.org/en/topics/idn/>The IDN Variant Issues Project <http://www.icann.org/en/topics/new-gtlds/idn-vip-integrated-issues-23dec11-en.pdf> |
| [[IDNA2003](#IDNA2003)] | The IDNA2003 specification is defined by a cluster of IETF RFCs:  * IDNA [[RFC3490](#RFC3490)] * Nameprep [[RFC3491](#RFC3491)] * Punycode [[RFC3492](#RFC3492)] * Stringprep [[RFC3454](#RFC3454)]. |
| [[IDNA2008](#IDNA2008)] | The IDNA2008 specification is defined by a cluster of IETF RFCs:  * Internationalized Domain Names for Applications (IDNA):   Definitions and Document Framework <http://tools.ietf.org/html/rfc5890> * Internationalized Domain Names in Applications (IDNA)   Protocol <http://tools.ietf.org/html/rfc5891> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) <http://tools.ietf.org/html/rfc5892> * Right-to-Left Scripts for Internationalized Domain Names   for Applications (IDNA) <http://tools.ietf.org/html/rfc5893>  There are also informative documents:  * Internationalized Domain Names for Applications (IDNA):   Background, Explanation, and Rationale <http://tools.ietf.org/html/rfc5894> * The Unicode Code Points and Internationalized Domain   Names for Applications (IDNA) - Unicode 6.0 <http://tools.ietf.org/html/rfc6452> |
| [[IDN-Demo]](#IDN_Demo) | <http://unicode.org/cldr/utility/idna.jsp> |
| [[IDN-FAQ](#IDN_FAQ)] | <http://www.unicode.org/faq/idn.html> |
| [[IDN-Demo](#IDN-Demo)] | ICU (International Components for Unicode) IDN Demo <http://demo.icu-project.org/icu-bin/icudemos> |
| [[Feedback](#Feedback)] | Reporting Form<http://www.unicode.org/reporting.html>*For reporting errors and requesting information online.* |
| [[LastResort](#LastResort)] | Last Resort Font <http://unicode.org/policies/lastresortfont_eula.html> (See also <http://www.unicode.org/charts/lastresort.html>) |
| [[LDAP](#LDAP)] | Lightweight Directory Access Protocol (LDAP): Internationalized String Preparation <http://www.rfc-editor.org/rfc/rfc4518.txt> |
| [[NFKC\_Casefold](#NFKC_CaseFold)] | The Unicode property specified in [[UAX44](#UAX44)], and defined by the data in [DerivedNormalizationProps.txt](http://www.unicode.org/Public/UNIDATA/DerivedNormalizationProps.txt) (search for "NFKC\_Casefold"). |
| [[Reports](#Reports)] | Unicode Technical Reports <http://www.unicode.org/reports/>*For information on the status and development process for technical reports, and for a list of technical reports.* |
| [[RFC1034](#RFC1034)] | P. Mockapetris. "DOMAIN NAMES - CONCEPTS AND FACILITIES", RFC 1034, November 1987. <http://ietf.org/rfc/rfc1034.txt> |
| [[RFC1035](#RFC1035)] | P. Mockapetris. "DOMAIN NAMES - IMPLEMENTATION AND SPECIFICATION", RFC 1034, November 1987. <http://ietf.org/rfc/rfc1035.txt> |
| [[RFC1535](#RFC1535)] | E. Gavron. "A Security Problem and Proposed Correction With Widely Deployed DNS Software", RFC 1535, October 1993 <http://ietf.org/rfc/rfc1535.txt> |
| [[RFC3454](#RFC3454)] | P. Hoffman, M. Blanchet. "Preparation of Internationalized Strings ("stringprep")", RFC 3454, December 2002. <http://ietf.org/rfc/rfc3454.txt> |
| [[RFC3490](#RFC3490)] | Faltstrom, P., Hoffman, P. and A. Costello, "Internationalizing Domain Names in Applications (IDNA)", RFC 3490, March 2003. <http://ietf.org/rfc/rfc3490.txt> |
| [[RFC3491](#RFC3491)] | Hoffman, P. and M. Blanchet, "Nameprep: A Stringprep Profile for Internationalized Domain Names (IDN)", RFC 3491, March 2003. <http://ietf.org/rfc/rfc3491.txt> |
| [[RFC3492](#RFC3492)] | Costello, A., "Punycode: A Bootstring encoding of Unicode for Internationalized Domain Names in Applications (IDNA)", RFC 3492, March 2003. <http://ietf.org/rfc/rfc3492.txt> |
| [[RFC3743](#RFC3743)] | Konishi, K., Huang, K., Qian, H. and Y. Ko, "Joint Engineering Team (JET) Guidelines for Internationalized Domain Names (IDN) Registration and Administration for Chinese, Japanese, and Korean", RFC 3743, April 2004. <http://ietf.org/rfc/rfc3743.txt> |
| [[RFC3986](#RFC3986)] | T. Berners-Lee, R. Fielding, L. Masinter. "Uniform Resource Identifier (URI): Generic Syntax", RFC 3986, January 2005. <http://ietf.org/rfc/rfc3986.txt> |
| [[RFC3987](#RFC3987)] | M. Duerst, M. Suignard. "Internationalized Resource Identifiers (IRIs)", RFC 3987, January 2005. <http://ietf.org/rfc/rfc3987.txt> |
| [[Stability](#Stability)] | Unicode Character Encoding Stability Policy <http://www.unicode.org/standard/stability_policy.html> |
| [[UCD](#UCD)] | Unicode Character Database. <http://www.unicode.org/ucd/> *For an overview of the Unicode Character Database and a list of its associated files.* |
| [[UCDFormat](#UCDFormat)] | UCD File Format <http://www.unicode.org/reports/tr44/#Format_Conventions> |
| [[UAX9](#UAX9)] | UAX #9: The Bidirectional Algorithm <http://www.unicode.org/reports/tr9/> |
| [[UAX15](#UAX15)] | UAX #15: Unicode Normalization Forms <http://www.unicode.org/reports/tr15/> |
| [[UAX24](#UAX24)] | UAX #24: Unicode Script Property <http://www.unicode.org/reports/tr24/> |
| [[UAX31](#UAX31)] | UAX #31, Identifier and Pattern Syntax <http://www.unicode.org/reports/tr31/> |
| [[UAX44](#UAX44)] | UAX #44:*Unicode Character Database* <http://www.unicode.org/reports/tr44/> |
| [[Unicode](#Unicode)] | The Unicode Standard*For the latest version, see:* <http://www.unicode.org/versions/latest/> |
| [[UTS10](#UTS10)] | UTS #10: Unicode Collation Algorithm <http://www.unicode.org/reports/tr10/> |
| [[UTS18](#UTS18)] | UTS #18: Unicode Regular Expressions <http://www.unicode.org/reports/tr18/> |
| [[UTS22](#UTS22)] | UTS #22: Character Mapping Markup Language (CharMapML) <http://www.unicode.org/reports/tr22/> |
| [[UTS39](#UTS39)] | UTS #39: Unicode Security Mechanisms <http://www.unicode.org/reports/tr39/> |
| [[UTS46](#UTS46)] | Unicode IDNA Compatibility Processing [http://www.unicode.org/reports/tr46/](http://www.unicode.org/reports/tr46/%20) |
| [[Versions](#Versions)] | Versions of the Unicode Standard <http://www.unicode.org/standard/versions/> *For information on version numbering, and citing and referencing the Unicode Standard, the Unicode Character Database, and Unicode Technical Reports.* |

## [Modifications](#Modifications)

The following summarizes modifications from the previous
revisions of this document.

### Revision 15

* *Section 1.1 [Structure](#Structure)*
  + Added a note on the broad use of the term “URL”, and
    replaced some instances elsewhere of URI and IRI.
* *Section 2 [Visual
  Security Issues](#visual_spoofing)*
  + Added description of *gatekeeper-confusable*
    strings.
* *Section 2.8.1 [Punycode
  Spoofs](#Punycode_Spoofs)*
  + Added a description of how the display of Punycode URLs
    instead of Unicode can be worse for spoofing.
* *Section 2.10 [Restriction
  Levels and Alerts](#Security_Levels_and_Alerts)*
  + Add a second example of an alert, for mixed scripts.
* *Section 2.11.2 [Recommendations for
  Programmers](#Recommendations_General)*
  + Added note on the use of Catalan in identifiers.
* Copyediting
  + Added Tables to TOC

Revision 14 being a proposed update, only changes between
revisions 13 and 15 are noted here.

### Revision 13

* *Section 3.1.1 [Ill-Formed
  Subsequences](#Ill-Formed_Subsequences)*
  + Fixed various typos.
* *Section 3.2 [Text
  Comparison (Sorting, Searching, Matching)](#Text_Comparison)*
  + Added description of issues with transitivity
* *Section 3.7.1 [PEP
  383 Approach](#TOC-PEP-383-Approach)*
  + Removed the incorrect term 'high' on 'surrogate'.
* *Section 3.8 [Idempotence](#TOC-Idempotence)*
  + Added pointer to article about idempotence.
* Fleshed out table of contents, fixed links, and incorrect
  numbering of sections in 2.9-2.10.
* Changed references to point to the <http://www.unicode.org/faq/security.html>
  for links that might change.

Revision 12 being a proposed update, only changes between
revisions 11 and 13 are noted here.

### Revision 11

* Moved definition of Restriction Levels to UTS #39
* Fixed reported typos, and updated references.

Revision 10 being a proposed update, only changes between
revisions 9 and 11 are noted here.

### Revision 9

* Added table numbers and explicit references to tables in the
  text.
* Expanded the introduction to Section 3 somewhat.
* Removed Appendices A, B, D, E, and F, and renumbered the
  other Appendices.
* Moved external references to the FAQ
* Cleaned up references to UTS39 and UTS46
* Removed former Appendix F.
* Added Section 3.6, Secure Encoding Conversion.
* Added Section 3.7, Enabling Lossless Conversion.
* Removed old Section 3.6, [Recommendations](#Non_Visual_Recommendations)
* Clarified *Section 3.5, [Deletion of Code Points](#Deletion_of_Noncharacters)*
* Miscellaneous other editorial changes.

Revision 8 being a proposed update, only changes between
revisions 7 and 9 are noted here.

### Revision 7

* Added explanation of UTF-8 over-consumption attack in 3.1 [UTF-8 Exploits](#UTF-8_Exploit)
* Added subsection of 2.8.2 [Mapping
  and Prohibition](#Mapping_and_Prohibition) describing the Unicode 5.1 changes in identifiers.
* Added 3.4 [Property
  and Character Stability](#Property_and_Character_Stability)
* Updated Unicode reference.
* Broke 3.1.1 into two sections, adding header 3.1.2: [Substituting
  for Ill-Formed Subsequences](#Substituting_for_Ill_Formed_Subsequences), with some small wording changes around
  it. In particular, pointed to *Appendix E. Conformance Changes
  to the Standard* in Unicode 5.1.
* Added 3.5 [Deletion
  of Noncharacters](#Deletion_of_Noncharacters)
* Added before Sample Country Registries: "These are only
  for illustration: the exact sets may change over time, so the
  particular authorities should be consulted rather than relying on
  these contents. Some registrars now also offer machine-readable
  formats."
* Minor editing

Revision 6 being a proposed update, only changes between
revisions 4 and 7 are noted here.

### Revision 4

* Moved the contents of *Appendix A Identifier
  Characters*, *Appendix B, Confusable Detection*, and *Appendix
  D Mixed Script Detection* to the new [[UTS39](#UTS39)].
  The appendices remain (to avoid renumbering), but simply point to
  the new locations. Changed references to point to the new sections
  in [[UTS39](#UTS39)].
* Alphabetized *Appendix C. [Script Icons](#Missing_Glyph_Icons).*
* Added *Appendix G. [Language-Based Security](#Language_Based_Security).*
* Changed the "highlighting" of the core domain name
  to the whole domain name in Section 2.6, [Syntax
  Spoofing](#Syntax_Spoofing).
* Replaced *Section 2.9.4  [Recommendations for
  Registries](#Recommendations_Registries)* based on the UTC decisions.
* Removed the contents of *Appendix E. Future Topics*,
  incorporating material to address the issues in *Section 3.2,
  [Text Comparison](#Text_Comparison), Section 3.3, [Buffer Overflows](#Buffer_Overflows)*, and a few other places in the document.
* Minor editing

### **Revision 3**

* Cleaned up references
* Added Related Material section
* Add section on [Casefolded
  Format](#Case_Folded_Format)
* Refined recommendations on single-script confusables
* Reorganized introduction, and reversed the order of the main
  sections.
* Retitled the main sections
* Restructured the recommendations for Visual Security
* Added more examples
* Incorporated changes for user feedback
* Major restructuring, especially appendices. Moved data files
  and other references into the references, added section on
  confusables, scripts, future topics, revised the identifiers section
  to point at the newer data file.
* Incorporated changes for all the editorial notes: shifted
  some sections.
* Added sections on bidi, appendix F.
* Revised data files

### **Revision 2**

* Moved recommendations to separate section.
* Added new descriptions, recommendations.
* Pointed to draft data files.

### **Revision 1**

* Initial version, following proposal to UTC.
* Incorporated comments, restructured, added To Do items.

---

Copyright © 2004-2014 Unicode, Inc. All
Rights Reserved. The Unicode Consortium makes no expressed or implied
warranty of any kind, and assumes no liability for errors or
omissions. No liability is assumed for incidental and consequential
damages in connection with or arising out of the use of the
information or programs contained or accompanying this technical
report. The Unicode [Terms
of Use](http://www.unicode.org/copyright.html) apply.

Unicode and the Unicode logo are trademarks
of Unicode, Inc., and are registered in some jurisdictions.



=== Content from lists.fedoraproject.org_bc6068ce_20250111_024724.html ===


[![Fedora Mailing-Lists](/static/logo-hyperkitty-fedora.png)](/archives/ "Fedora Mailing-Lists")

[Sign In](/accounts/login/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/LQNTFF24ROHLVPLUOEISBN3F7QM27L4U/)
[Sign Up](/accounts/signup/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/LQNTFF24ROHLVPLUOEISBN3F7QM27L4U/)

* [Sign In](/accounts/login/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/LQNTFF24ROHLVPLUOEISBN3F7QM27L4U/)
* [Sign Up](/accounts/signup/?next=/archives/list/package-announce%40lists.fedoraproject.org/message/LQNTFF24ROHLVPLUOEISBN3F7QM27L4U/)

* [Manage this list](/admin/lists/package-announce.lists.fedoraproject.org/)

×
#### Keyboard Shortcuts

### Thread View

* `j`: Next unread message
* `k`: Previous unread message
* `j a`: Jump to all threads* `j l`: Jump to MailingList overview

### 2025

* [January](/archives/list/package-announce%40lists.fedoraproject.org/2025/1/)

### 2024

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2024/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2024/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2024/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2024/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2024/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2024/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2024/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2024/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2024/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2024/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2024/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2024/1/)

### 2023

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2023/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2023/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2023/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2023/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2023/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2023/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2023/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2023/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2023/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2023/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2023/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2023/1/)

### 2022

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2022/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2022/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2022/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2022/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2022/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2022/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2022/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2022/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2022/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2022/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2022/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2022/1/)

### 2021

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2021/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2021/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2021/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2021/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2021/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2021/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2021/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2021/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2021/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2021/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2021/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2021/1/)

### 2020

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2020/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2020/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2020/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2020/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2020/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2020/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2020/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2020/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2020/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2020/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2020/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2020/1/)

### 2019

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2019/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2019/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2019/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2019/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2019/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2019/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2019/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2019/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2019/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2019/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2019/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2019/1/)

### 2018

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2018/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2018/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2018/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2018/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2018/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2018/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2018/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2018/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2018/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2018/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2018/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2018/1/)

### 2017

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2017/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2017/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2017/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2017/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2017/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2017/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2017/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2017/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2017/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2017/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2017/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2017/1/)

### 2016

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2016/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2016/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2016/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2016/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2016/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2016/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2016/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2016/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2016/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2016/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2016/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2016/1/)

### 2015

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2015/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2015/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2015/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2015/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2015/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2015/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2015/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2015/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2015/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2015/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2015/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2015/1/)

### 2014

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2014/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2014/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2014/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2014/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2014/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2014/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2014/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2014/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2014/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2014/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2014/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2014/1/)

### 2013

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2013/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2013/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2013/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2013/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2013/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2013/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2013/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2013/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2013/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2013/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2013/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2013/1/)

### 2012

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2012/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2012/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2012/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2012/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2012/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2012/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2012/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2012/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2012/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2012/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2012/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2012/1/)

### 2011

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2011/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2011/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2011/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2011/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2011/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2011/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2011/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2011/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2011/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2011/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2011/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2011/1/)

### 2010

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2010/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2010/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2010/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2010/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2010/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2010/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2010/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2010/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2010/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2010/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2010/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2010/1/)

### 2009

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2009/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2009/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2009/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2009/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2009/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2009/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2009/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2009/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2009/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2009/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2009/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2009/1/)

### 2008

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2008/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2008/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2008/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2008/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2008/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2008/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2008/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2008/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2008/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2008/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2008/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2008/1/)

### 2007

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2007/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2007/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2007/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2007/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2007/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2007/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2007/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2007/5/)
* [April](/archives/list/package-announce%40lists.fedoraproject.org/2007/4/)
* [March](/archives/list/package-announce%40lists.fedoraproject.org/2007/3/)
* [February](/archives/list/package-announce%40lists.fedoraproject.org/2007/2/)
* [January](/archives/list/package-announce%40lists.fedoraproject.org/2007/1/)

### 2006

* [December](/archives/list/package-announce%40lists.fedoraproject.org/2006/12/)
* [November](/archives/list/package-announce%40lists.fedoraproject.org/2006/11/)
* [October](/archives/list/package-announce%40lists.fedoraproject.org/2006/10/)
* [September](/archives/list/package-announce%40lists.fedoraproject.org/2006/9/)
* [August](/archives/list/package-announce%40lists.fedoraproject.org/2006/8/)
* [July](/archives/list/package-announce%40lists.fedoraproject.org/2006/7/)
* [June](/archives/list/package-announce%40lists.fedoraproject.org/2006/6/)
* [May](/archives/list/package-announce%40lists.fedoraproject.org/2006/5/)

[List overview](/archives/list/package-announce%40lists.fedoraproject.org/)

[Download](/archives/list/package-announce%40lists.fedoraproject.org/export/package-announce%40lists.fedoraproject.org-LQNTFF24ROHLVPLUOEISBN3F7QM27L4U.mbox.gz?message=LQNTFF24ROHLVPLUOEISBN3F7QM27L4U "This message in gzipped mbox format")

[thread](/archives/list/package-announce%40lists.fedoraproject.org/thread/LQNTFF24ROHLVPLUOEISBN3F7QM27L4U/#LQNTFF24ROHLVPLUOEISBN3F7QM27L4U)

# [SECURITY] Fedora 35 Update: rust-1.56.1-1.fc35

![](https://seccdn.libravatar.org/avatar/be256568dfce45c1862b55e6cf3f2726.jpg?s=120&d=retro&r=g)

[updates＠fedoraproject.org](/archives/users/3d8bb2e4c1d843beb492d4f8a7c44761/ "See the profile for updates＠fedoraproject.org")

5 Nov
2021

5 Nov
'21

1:08 a.m.

--------------------------------------------------------------------------------
Fedora Update Notification
FEDORA-2021-7ad3a01f6a
2021-11-05 01:07:54.162423
--------------------------------------------------------------------------------

Name : rust
Product : Fedora 35
Version : 1.56.1
Release : 1.fc35
URL : <https://www.rust-lang.org>
Summary : The Rust Programming Language
Description :
Rust is a systems programming language that runs blazingly fast, prevents
segfaults, and guarantees thread safety.

This package includes the Rust compiler and documentation generator.

--------------------------------------------------------------------------------
Update Information:

Rust 1.56.1 adds a mitigation for CVE-2021-42574, the "trojan source" attack
that obfuscates code with BiDi control characters. The compiler will now error
on such characters in code comments and string/char literals. For more details,
see the upstream [security advisory](<https://blog.rust->
lang.org/2021/11/01/cve-2021-42574.html).
--------------------------------------------------------------------------------
ChangeLog:

\* Mon Nov 1 2021 Josh Stone jistone@redhat.com - 1.56.1-1
- Update to 1.56.1.
--------------------------------------------------------------------------------

This update can be installed with the "dnf" update program. Use
su -c 'dnf upgrade --advisory FEDORA-2021-7ad3a01f6a' at the command
line. For more information, refer to the dnf documentation available at
<http://dnf.readthedocs.io/en/latest/command_ref.html#upgrade-command-label>

All packages are signed with the Fedora Project GPG key. More details on the
GPG keys used by the Fedora Project can be found at
<https://fedoraproject.org/keys>
--------------------------------------------------------------------------------

[0](#like "You must be logged-in to vote.")
[0](#dislike "You must be logged-in to vote.")

Reply

[Back to the thread](/archives/list/package-announce%40lists.fedoraproject.org/thread/LQNTFF24ROHLVPLUOEISBN3F7QM27L4U/#LQNTFF24ROHLVPLUOEISBN3F7QM27L4U)

[Back to the list](/archives/list/package-announce%40lists.fedoraproject.org/)

Powered by [HyperKitty](http://hyperkitty.readthedocs.org) version 1.3.7.


