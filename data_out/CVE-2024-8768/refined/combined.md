=== Content from github.com_9a542f60_20250111_130546.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm%2Fpull%2F7746)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm%2Fpull%2F7746)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fpull_requests_fragments%2Fpull_request_layout&source=header-repo&source_repo=vllm-project%2Fvllm)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[vllm-project](/vllm-project)
/
**[vllm](/vllm-project/vllm)**
Public

* [Notifications](/login?return_to=%2Fvllm-project%2Fvllm) You must be signed in to change notification settings
* [Fork
  5.1k](/login?return_to=%2Fvllm-project%2Fvllm)
* [Star
   33.5k](/login?return_to=%2Fvllm-project%2Fvllm)

* [Code](/vllm-project/vllm)
* [Issues
  1.2k](/vllm-project/vllm/issues)
* [Pull requests
  457](/vllm-project/vllm/pulls)
* [Discussions](/vllm-project/vllm/discussions)
* [Actions](/vllm-project/vllm/actions)
* [Security](/vllm-project/vllm/security)
* [Insights](/vllm-project/vllm/pulse)

Additional navigation options

* [Code](/vllm-project/vllm)
* [Issues](/vllm-project/vllm/issues)
* [Pull requests](/vllm-project/vllm/pulls)
* [Discussions](/vllm-project/vllm/discussions)
* [Actions](/vllm-project/vllm/actions)
* [Security](/vllm-project/vllm/security)
* [Insights](/vllm-project/vllm/pulse)

New issue

**Have a question about this project?** Sign up for a free GitHub account to open an issue and contact its maintainers and the community.

 [Sign up for GitHub](/signup?return_to=%2Fvllm-project%2Fvllm%2Fissues%2Fnew%2Fchoose)

By clicking ‚ÄúSign up for GitHub‚Äù, you agree to our [terms of service](https://docs.github.com/terms) and
[privacy statement](https://docs.github.com/privacy). We‚Äôll occasionally send you account related emails.

Already on GitHub?
[Sign in](/login?return_to=%2Fvllm-project%2Fvllm%2Fissues%2Fnew%2Fchoose)
to your account

[Jump to bottom](#issue-comment-box)

# [BugFix] Fix server crash on empty prompt #7746

 Merged

[njhill](/njhill)
merged 10 commits into
[vllm-project:main](/vllm-project/vllm/tree/main "vllm-project/vllm:main")
from
[maxdebayser:fix\_empty\_prompt\_crash](/maxdebayser/vllm/tree/fix_empty_prompt_crash "maxdebayser/vllm:fix_empty_prompt_crash")

Aug 23, 2024

 Merged

# [[BugFix] Fix server crash on empty prompt](#top) #7746

[njhill](/njhill)
merged 10 commits into
[vllm-project:main](/vllm-project/vllm/tree/main "vllm-project/vllm:main")
from
[maxdebayser:fix\_empty\_prompt\_crash](/maxdebayser/vllm/tree/fix_empty_prompt_crash "maxdebayser/vllm:fix_empty_prompt_crash")

Aug 23, 2024

[Conversation
12](/vllm-project/vllm/pull/7746)
[Commits
10](/vllm-project/vllm/pull/7746/commits)
[Checks
17](/vllm-project/vllm/pull/7746/checks)
[Files changed](/vllm-project/vllm/pull/7746/files)

## Conversation

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

[![maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=60&v=4)](/maxdebayser)

Copy link

Contributor

### @maxdebayser **[maxdebayser](/maxdebayser)** commented [Aug 21, 2024](#issue-2478656118)

Fixes [#7632](https://github.com/vllm-project/vllm/issues/7632)

To reproduce, start the server with `python -m vllm.entrypoints.openai.api_server --model gpt2` and send an empty prompt:

```
$ curl http://localhost:8000/v1/completions    -H "Content-Type: application/json"    -d '{
     "model": "gpt2",
     "prompt": [""],
     "max_tokens": 20,
     "temperature": 0
}'
Internal Server Error

```

On the server side this log will show and the server will be dead:

```
INFO 08-21 14:49:19 logger.py:36] Received request cmpl-470c7a46582b4554b7926ce4559b0337-0: prompt: '', params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.0, top_p=1.0, top_k=-1, min_p=0.0, seed=None, use_beam_search=False, length_penalty=1.0, early_stopping=False, stop=[], stop_token_ids=[], include_stop_str_in_output=False, ignore_eos=False, max_tokens=20, min_tokens=0, logprobs=None, prompt_logprobs=None, skip_special_tokens=True, spaces_between_special_tokens=True, truncate_prompt_tokens=None), prompt_token_ids: [], lora_request: None, prompt_adapter_request: None.
INFO 08-21 14:49:19 async_llm_engine.py:208] Added request cmpl-470c7a46582b4554b7926ce4559b0337-0.
ERROR 08-21 14:49:19 async_llm_engine.py:65] Engine background task failed
ERROR 08-21 14:49:19 async_llm_engine.py:65] Traceback (most recent call last):
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 55, in _log_task_completion
ERROR 08-21 14:49:19 async_llm_engine.py:65]     return_value = task.result()
ERROR 08-21 14:49:19 async_llm_engine.py:65]                    ^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 930, in run_engine_loop
ERROR 08-21 14:49:19 async_llm_engine.py:65]     result = task.result()
ERROR 08-21 14:49:19 async_llm_engine.py:65]              ^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 873, in engine_step
ERROR 08-21 14:49:19 async_llm_engine.py:65]     request_outputs = await self.engine.step_async(virtual_engine)
ERROR 08-21 14:49:19 async_llm_engine.py:65]                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 301, in step_async
ERROR 08-21 14:49:19 async_llm_engine.py:65]     virtual_engine].schedule()
ERROR 08-21 14:49:19 async_llm_engine.py:65]                     ^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 1039, in schedule
ERROR 08-21 14:49:19 async_llm_engine.py:65]     scheduler_outputs = self._schedule()
ERROR 08-21 14:49:19 async_llm_engine.py:65]                         ^^^^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 1013, in _schedule
ERROR 08-21 14:49:19 async_llm_engine.py:65]     return self._schedule_default()
ERROR 08-21 14:49:19 async_llm_engine.py:65]            ^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 857, in _schedule_default
ERROR 08-21 14:49:19 async_llm_engine.py:65]     prefills = self._schedule_prefills(budget,
ERROR 08-21 14:49:19 async_llm_engine.py:65]                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 752, in _schedule_prefills
ERROR 08-21 14:49:19 async_llm_engine.py:65]     num_new_tokens = self._get_num_new_tokens(seq_group,
ERROR 08-21 14:49:19 async_llm_engine.py:65]                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65]   File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 1349, in _get_num_new_tokens
ERROR 08-21 14:49:19 async_llm_engine.py:65]     assert num_new_tokens > 0
ERROR 08-21 14:49:19 async_llm_engine.py:65]            ^^^^^^^^^^^^^^^^^^
ERROR 08-21 14:49:19 async_llm_engine.py:65] AssertionError
Exception in callback functools.partial(<function _log_task_completion at 0x7f1abf494220>, error_callback=<bound method AsyncLLMEngine._error_callback of <vllm.engine.async_llm_engine.AsyncLLMEngine object at 0x7f1aa38d0050>>)
handle: <Handle functools.partial(<function _log_task_completion at 0x7f1abf494220>, error_callback=<bound method AsyncLLMEngine._error_callback of <vllm.engine.async_llm_engine.AsyncLLMEngine object at 0x7f1aa38d0050>>)>
Traceback (most recent call last):
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 55, in _log_task_completion
    return_value = task.result()
                   ^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 930, in run_engine_loop
    result = task.result()
             ^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 873, in engine_step
    request_outputs = await self.engine.step_async(virtual_engine)
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 301, in step_async
    virtual_engine].schedule()
                    ^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 1039, in schedule
    scheduler_outputs = self._schedule()
                        ^^^^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 1013, in _schedule
    return self._schedule_default()
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 857, in _schedule_default
    prefills = self._schedule_prefills(budget,
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 752, in _schedule_prefills
    num_new_tokens = self._get_num_new_tokens(seq_group,
                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/core/scheduler.py", line 1349, in _get_num_new_tokens
    assert num_new_tokens > 0
           ^^^^^^^^^^^^^^^^^^
AssertionError

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "uvloop/cbhandles.pyx", line 63, in uvloop.loop.Handle._run
  File "/home/mbayser/IBMProjects/FoundationModels/inference/vllm/vllm/engine/async_llm_engine.py", line 67, in _log_task_completion
    raise AsyncEngineDeadError(

```

After the fix, an error 400 is returned:

```
$ curl http://localhost:8000/v1/completions    -H "Content-Type: application/json"    -d '{
     "model": "gpt2",
     "prompt": [""],
     "max_tokens": 20,
     "temperature": 0
}'
{"object":"error","message":"Empty prompt","type":"BadRequestError","param":null,"code":400}```

```

Sorry, something went wrong.

 üéâ
1
 tjohnson31415 reacted with hooray emoji

All reactions

* üéâ
  1 reaction

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[Validate the that the input prompts aren't empty](/vllm-project/vllm/pull/7746/commits/24862bce504479415620a0b7cff9216b1ca8c76b "Validate the that the input prompts aren't empty

This avoids a async loop crash that takes down the server

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
 ‚Ä¶

`[24862bc](/vllm-project/vllm/pull/7746/commits/24862bce504479415620a0b7cff9216b1ca8c76b)`

```
This avoids a async loop crash that takes down the server

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[![@github-actions](https://avatars.githubusercontent.com/in/15368?s=80&v=4)](/apps/github-actions)
[![GitHub Actions](https://avatars.githubusercontent.com/in/15368?s=40&u=167a342ed94d2a713daf64a8b476ead2cebe1852&v=4)](https://github.com/apps/github-actions)

Copy link

### **[github-actions](/apps/github-actions) bot** commented [Aug 21, 2024](#issuecomment-2302656153)

| üëã Hi! Thank you for contributing to the vLLM project. Just a reminder: PRs would not trigger full CI run by default. Instead, it would only run `fastcheck` CI which consists a small and essential subset of CI tests to quickly catch errors. You can run other CI tests on top of default ones by unblocking the steps in your `fast-check` build on Buildkite UI.  Once the PR is approved and ready to go, please make sure to run full CI as it is required to merge (or just use auto-merge).  To run full CI, you can do one of these:   * Comment `/ready` on the PR * Add `ready` label to the PR * Enable auto-merge.   üöÄ |
| --- |

All reactions

Sorry, something went wrong.

[![@DarkLight1337](https://avatars.githubusercontent.com/u/44970335?s=80&u=c2dd9f7890f2b8984d72acb36dabf90cf0f5f3df&v=4)](/DarkLight1337)

Copy link

Member

### **[DarkLight1337](/DarkLight1337)** commented [Aug 22, 2024](#issuecomment-2303531554) ‚Ä¢ edited Loading

| Let's perform the check inside `add_request` instead of `process_model_inputs` to move it closer to the cause of the crash. |
| --- |

 üëç
1
 mgoin reacted with thumbs up emoji

All reactions

* üëç
  1 reaction

Sorry, something went wrong.

[fialhocoelho](/fialhocoelho)
pushed a commit
to opendatahub-io/vllm
that referenced
this pull request
[Aug 22, 2024](#ref-commit-1b74b46)
[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&u=ab97163dbeb77a3abd07e84cd08e8675ff4e59e2&v=4)](/maxdebayser) [![@fialhocoelho](https://avatars.githubusercontent.com/u/14850636?s=40&v=4)](/fialhocoelho)

`[Commit from ustream PR](/opendatahub-io/vllm/commit/1b74b46621a20bc56dc0d8e2b120cfc418d403c5 "Commit from ustream PR #7746

Validate the that the input prompts aren't empty

This avoids an async loop crash that takes down the server

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
Signed-off-by: Jefferson Fialho <jfialho@ibm.com>") [vllm-project#7746](https://github.com/vllm-project/vllm/pull/7746)`
‚Ä¶

`[1b74b46](/opendatahub-io/vllm/commit/1b74b46621a20bc56dc0d8e2b120cfc418d403c5)`

```
Validate the that the input prompts aren't empty

This avoids an async loop crash that takes down the server

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
Signed-off-by: Jefferson Fialho <jfialho@ibm.com>
```

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=80&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)

Copy link

Member

### **[njhill](/njhill)** commented [Aug 22, 2024](#issuecomment-2304693290)

| [@maxdebayser](https://github.com/maxdebayser) could you add a simple test for this too? |
| --- |

 üëç
1
 maxdebayser reacted with thumbs up emoji

All reactions

* üëç
  1 reaction

Sorry, something went wrong.

 [maxdebayser](/maxdebayser)
and others
added 2 commits
[August 22, 2024 11:12](#commits-pushed-5c5a8f1)

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[Merge branch 'vllm-project:main' into fix_empty_prompt_crash](/vllm-project/vllm/pull/7746/commits/5c5a8f10308b789efde3524fb1a778969802f488 "Merge branch 'vllm-project:main' into fix_empty_prompt_crash")`

`[5c5a8f1](/vllm-project/vllm/pull/7746/commits/5c5a8f10308b789efde3524fb1a778969802f488)`

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[Move validation of empty promt to add_request fucntions](/vllm-project/vllm/pull/7746/commits/9a13407b637905be603cce6ae05eea6ac8c4df39 "Move validation of empty promt to add_request fucntions

Also add unit tests for LLM and OpenAI entrypoints

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
 ‚Ä¶

`[9a13407](/vllm-project/vllm/pull/7746/commits/9a13407b637905be603cce6ae05eea6ac8c4df39)`

```
Also add unit tests for LLM and OpenAI entrypoints

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=80&u=ab97163dbeb77a3abd07e84cd08e8675ff4e59e2&v=4)](/maxdebayser)

Copy link

Contributor

Author

### **[maxdebayser](/maxdebayser)** commented [Aug 22, 2024](#issuecomment-2305187950)

| I've added the tests and moved the validation as requested. |
| --- |

 üéâ
1
 njhill reacted with hooray emoji

All reactions

* üéâ
  1 reaction

Sorry, something went wrong.

 [maxdebayser](/maxdebayser)
and others
added 2 commits
[August 22, 2024 16:16](#commits-pushed-7f21260)

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[Merge branch 'vllm-project:main' into fix_empty_prompt_crash](/vllm-project/vllm/pull/7746/commits/7f21260ea6e277291c6131390436562321792765 "Merge branch 'vllm-project:main' into fix_empty_prompt_crash")`

`[7f21260](/vllm-project/vllm/pull/7746/commits/7f21260ea6e277291c6131390436562321792765)`

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[move test to another file due to conflicting fixtures](/vllm-project/vllm/pull/7746/commits/85ee9ff94094eb318794736e57fb54397e656589 "move test to another file due to conflicting fixtures

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
 ‚Ä¶

`[85ee9ff](/vllm-project/vllm/pull/7746/commits/85ee9ff94094eb318794736e57fb54397e656589)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[![mgoin](https://avatars.githubusercontent.com/u/3195154?s=60&v=4)](/mgoin)

**[mgoin](/mgoin)**
reviewed
[Aug 22, 2024](#pullrequestreview-2255501809)

 [View reviewed changes](/vllm-project/vllm/pull/7746/files/85ee9ff94094eb318794736e57fb54397e656589)

[tests/entrypoints/openai/test\_prompt\_validation.py](/vllm-project/vllm/pull/7746/files/85ee9ff94094eb318794736e57fb54397e656589#diff-66786cb46bdce307075c5d1ef6bc448a6ce3029229c27851fad8b71d73170c00)
Outdated

Show resolved

Hide resolved

 [maxdebayser](/maxdebayser)
added 2 commits
[August 22, 2024 16:45](#commits-pushed-4bef6f6)

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[enable frontend multiprocessing](/vllm-project/vllm/pull/7746/commits/4bef6f63c20e6b275c62789b181e977c39f508ae "enable frontend multiprocessing

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
 ‚Ä¶

`[4bef6f6](/vllm-project/vllm/pull/7746/commits/4bef6f63c20e6b275c62789b181e977c39f508ae)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[move test to another file due to conflicting fixtures](/vllm-project/vllm/pull/7746/commits/aba94ee44cbcdcddad361267f286c0f5700735f1 "move test to another file due to conflicting fixtures

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
 ‚Ä¶

`[aba94ee](/vllm-project/vllm/pull/7746/commits/aba94ee44cbcdcddad361267f286c0f5700735f1)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[![njhill](https://avatars.githubusercontent.com/u/16958488?s=60&v=4)](/njhill)

**[njhill](/njhill)**
reviewed
[Aug 22, 2024](#pullrequestreview-2255566767)

 [View reviewed changes](/vllm-project/vllm/pull/7746/files/aba94ee44cbcdcddad361267f286c0f5700735f1)

[vllm/engine/async\_llm\_engine.py](/vllm-project/vllm/pull/7746/files/aba94ee44cbcdcddad361267f286c0f5700735f1#diff-4bd825485b5162cf8021da41a2ebd3d4026929e617d1137f69bbbe4bda0ee643)
Outdated

Show resolved

Hide resolved

[vllm/engine/llm\_engine.py](/vllm-project/vllm/pull/7746/files/aba94ee44cbcdcddad361267f286c0f5700735f1#diff-c89ac25bd066e936e80260d21be63c7d2379cfedc371a9ff288fb5ba02ae1350)
Outdated

Show resolved

Hide resolved

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)

`[move validation to a better place](/vllm-project/vllm/pull/7746/commits/5f972adc82ff42460a0b9bbb6823f6a94a2be089 "move validation to a better place

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
 ‚Ä¶

`[5f972ad](/vllm-project/vllm/pull/7746/commits/5f972adc82ff42460a0b9bbb6823f6a94a2be089)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
added
the
[ready](/vllm-project/vllm/labels/ready)
ONLY add when PR is ready to merge/full CI is needed
label
[Aug 22, 2024](#event-13984695608)

[![njhill](https://avatars.githubusercontent.com/u/16958488?s=60&v=4)](/njhill)

**[njhill](/njhill)**
approved these changes
[Aug 22, 2024](#pullrequestreview-2255813632)

 [View reviewed changes](/vllm-project/vllm/pull/7746/files/5f972adc82ff42460a0b9bbb6823f6a94a2be089)

Copy link

Member

### @njhill **[njhill](/njhill)** left a comment

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

Thanks [@maxdebayser](https://github.com/maxdebayser)!

Sorry, something went wrong.

All reactions

[![njhill](https://avatars.githubusercontent.com/u/16958488?s=60&v=4)](/njhill)

**[njhill](/njhill)**
reviewed
[Aug 22, 2024](#pullrequestreview-2255852259)

 [View reviewed changes](/vllm-project/vllm/pull/7746/files/5f972adc82ff42460a0b9bbb6823f6a94a2be089)

Copy link

Member

### @njhill **[njhill](/njhill)** left a comment

There was a problem hiding this comment.

### Choose a reason for hiding this comment

The reason will be displayed to describe this comment to others. [Learn more](https://docs.github.com/articles/managing-disruptive-comments/#hiding-a-comment).

Choose a reason

Spam
Abuse
Off Topic
Outdated
Duplicate
Resolved

Hide comment

Just noticed additional simplification

Sorry, something went wrong.

All reactions

[vllm/engine/llm\_engine.py](/vllm-project/vllm/pull/7746/files/5f972adc82ff42460a0b9bbb6823f6a94a2be089#diff-c89ac25bd066e936e80260d21be63c7d2379cfedc371a9ff288fb5ba02ae1350)
Outdated

Show resolved

Hide resolved

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&v=4)](/njhill)

`[Simplify prompt check](/vllm-project/vllm/pull/7746/commits/4623dfd0891814b338ce2a1345ed7d4ed19dd2d0 "Simplify prompt check")`

`[4623dfd](/vllm-project/vllm/pull/7746/commits/4623dfd0891814b338ce2a1345ed7d4ed19dd2d0)`

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
changed the title
~~Fix server crash on empty prompt~~
[BugFix] Fix server crash on empty prompt
[Aug 22, 2024](#event-13985640621)

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&v=4)](/njhill)

`[Make test match updated exception message](/vllm-project/vllm/pull/7746/commits/68610cbe870be02cd640fbaaf5df83c4b658bb54 "Make test match updated exception message")`

`[68610cb](/vllm-project/vllm/pull/7746/commits/68610cbe870be02cd640fbaaf5df83c4b658bb54)`

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
mentioned this pull request
[Aug 23, 2024](#ref-issue-2464212312)

[Release v0.5.5
#7481](/vllm-project/vllm/issues/7481)

Closed

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
enabled auto-merge (squash)
[August 23, 2024 02:35](#event-13986718044)

 Hide details
View details

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
merged commit [`e25fee5`](/vllm-project/vllm/commit/e25fee57c2e69161bd261f5986dc5aeb198bbd42)
into
vllm-project:main

[Aug 23, 2024](https://github.com/vllm-project/vllm/pull/7746#event-13993127214)
45 checks passed

[omrishiv](/omrishiv)
pushed a commit
to omrishiv/vllm
that referenced
this pull request
[Aug 26, 2024](#ref-commit-c4177ae)
[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&u=ab97163dbeb77a3abd07e84cd08e8675ff4e59e2&v=4)](/maxdebayser) [![@omrishiv](https://avatars.githubusercontent.com/u/327609?s=40&v=4)](/omrishiv)

`[[BugFix] Fix server crash on empty prompt (](/omrishiv/vllm/commit/c4177ae8b70bb0c35a8f477f54a9f0e5fba7cf9a "[BugFix] Fix server crash on empty prompt (#7746)

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")[vllm-project#7746](https://github.com/vllm-project/vllm/pull/7746)[)](/omrishiv/vllm/commit/c4177ae8b70bb0c35a8f477f54a9f0e5fba7cf9a "[BugFix] Fix server crash on empty prompt (#7746)

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
‚Ä¶

`[c4177ae](/omrishiv/vllm/commit/c4177ae8b70bb0c35a8f477f54a9f0e5fba7cf9a)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

 [![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&u=ab97163dbeb77a3abd07e84cd08e8675ff4e59e2&v=4)](/maxdebayser)
[maxdebayser](/maxdebayser)
deleted the
fix\_empty\_prompt\_crash

branch
[August 27, 2024 16:10](#event-14031591923)

[Anyonering](/Anyonering)
added a commit
to iidsample/chatdatagen
that referenced
this pull request
[Oct 2, 2024](#ref-commit-cced6e7)
[![@Anyonering](https://avatars.githubusercontent.com/u/121237579?s=40&v=4)](/Anyonering)

`[Add grpc calls in dataset generator.](/iidsample/chatdatagen/commit/cced6e7a2e1099ba6c33066cabc4a426f5d398c6 "Add grpc calls in dataset generator.

Tested in local machines. Have assertiona failed on server side which
causes the vllm worker to crash. This may be caused by sending empty
prompt to the server as described in
https://github.com/vllm-project/vllm/issues/7632 and
https://github.com/vllm-project/vllm/pull/7746. Need to further
inspection on this later.")`
‚Ä¶

`[cced6e7](/iidsample/chatdatagen/commit/cced6e7a2e1099ba6c33066cabc4a426f5d398c6)`

```
Tested in local machines. Have assertiona failed on server side which
causes the vllm worker to crash. This may be caused by sending empty
prompt to the server as described in
[vllm-project/vllm#7632](https://github.com/vllm-project/vllm/issues/7632) and
[vllm-project/vllm#7746](https://github.com/vllm-project/vllm/pull/7746). Need to further
inspection on this later.
```

[![@tjohnson31415](https://avatars.githubusercontent.com/u/7907693?s=40&v=4)](/tjohnson31415)
[tjohnson31415](/tjohnson31415)
mentioned this pull request
[Oct 17, 2024](#ref-issue-2454314712)

[[Bug]: Empty prompt kills vllm server (AsyncEngineDeadError: Background loop is stopped.)
#7283](/vllm-project/vllm/issues/7283)

Closed

[Alvant](/Alvant)
pushed a commit
to compressa-ai/vllm
that referenced
this pull request
[Oct 26, 2024](#ref-commit-2400dfd)
[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&u=ab97163dbeb77a3abd07e84cd08e8675ff4e59e2&v=4)](/maxdebayser) [![@Alvant](https://avatars.githubusercontent.com/u/15067981?s=40&v=4)](/Alvant)

`[[BugFix] Fix server crash on empty prompt (](/compressa-ai/vllm/commit/2400dfde6173b8387c23a77564cb21ab954b92f4 "[BugFix] Fix server crash on empty prompt (#7746)

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
Signed-off-by: Alvant <alvasian@yandex.ru>")[vllm-project#7746](https://github.com/vllm-project/vllm/pull/7746)[)](/compressa-ai/vllm/commit/2400dfde6173b8387c23a77564cb21ab954b92f4 "[BugFix] Fix server crash on empty prompt (#7746)

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
Signed-off-by: Alvant <alvasian@yandex.ru>")`
‚Ä¶

`[2400dfd](/compressa-ai/vllm/commit/2400dfde6173b8387c23a77564cb21ab954b92f4)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
Signed-off-by: Alvant <alvasian@yandex.ru>
```

[KuntaiDu](/KuntaiDu)
pushed a commit
to KuntaiDu/vllm
that referenced
this pull request
[Nov 20, 2024](#ref-commit-4f7a932)
[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&u=ab97163dbeb77a3abd07e84cd08e8675ff4e59e2&v=4)](/maxdebayser)

`[[BugFix] Fix server crash on empty prompt (](/KuntaiDu/vllm/commit/4f7a932bcd88b7cf96768ecbdb889dce9209bebb "[BugFix] Fix server crash on empty prompt (#7746)

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")[vllm-project#7746](https://github.com/vllm-project/vllm/pull/7746)[)](/KuntaiDu/vllm/commit/4f7a932bcd88b7cf96768ecbdb889dce9209bebb "[BugFix] Fix server crash on empty prompt (#7746)

Signed-off-by: Max de Bayser <mbayser@br.ibm.com>")`
‚Ä¶

`[4f7a932](/KuntaiDu/vllm/commit/4f7a932bcd88b7cf96768ecbdb889dce9209bebb)`

```
Signed-off-by: Max de Bayser <mbayser@br.ibm.com>
```

[Sign up for free](/join?source=comment-repo)
**to join this conversation on GitHub**.
Already have an account?
[Sign in to comment](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm%2Fpull%2F7746)

Reviewers

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&v=4)](/njhill) [njhill](/njhill)

njhill approved these changes

[![@mgoin](https://avatars.githubusercontent.com/u/3195154?s=40&v=4)](/mgoin) [mgoin](/mgoin)

mgoin left review comments

Assignees

No one assigned

Labels

[ready](/vllm-project/vllm/labels/ready)
ONLY add when PR is ready to merge/full CI is needed

Projects

None yet

Milestone

No milestone

Development

Successfully merging this pull request may close these issues.

 [[Bug]: assert num\_new\_tokens > 0 crashes entire worker instead of just failing single API call](https://github.com/vllm-project/vllm/issues/7632)

4 participants

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=52&v=4)](/maxdebayser) [![@DarkLight1337](https://avatars.githubusercontent.com/u/44970335?s=52&v=4)](/DarkLight1337) [![@njhill](https://avatars.githubusercontent.com/u/16958488?s=52&v=4)](/njhill) [![@mgoin](https://avatars.githubusercontent.com/u/3195154?s=52&v=4)](/mgoin)

Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Suggestions cannot be applied on multi-line comments.
Suggestions cannot be applied while the pull request is queued to merge.
Suggestion cannot be applied right now. Please check back later.

## Footer

¬© 2025 GitHub,¬†Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can‚Äôt perform that action at this time.



=== Content from github.com_ab2b8a5a_20250111_130544.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm%2Fissues%2F7632)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm%2Fissues%2F7632)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-repo&source_repo=vllm-project%2Fvllm)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[vllm-project](/vllm-project)
/
**[vllm](/vllm-project/vllm)**
Public

* [Notifications](/login?return_to=%2Fvllm-project%2Fvllm) You must be signed in to change notification settings
* [Fork
  5.1k](/login?return_to=%2Fvllm-project%2Fvllm)
* [Star
   33.5k](/login?return_to=%2Fvllm-project%2Fvllm)

* [Code](/vllm-project/vllm)
* [Issues
  1.2k](/vllm-project/vllm/issues)
* [Pull requests
  457](/vllm-project/vllm/pulls)
* [Discussions](/vllm-project/vllm/discussions)
* [Actions](/vllm-project/vllm/actions)
* [Security](/vllm-project/vllm/security)
* [Insights](/vllm-project/vllm/pulse)

Additional navigation options

* [Code](/vllm-project/vllm)
* [Issues](/vllm-project/vllm/issues)
* [Pull requests](/vllm-project/vllm/pulls)
* [Discussions](/vllm-project/vllm/discussions)
* [Actions](/vllm-project/vllm/actions)
* [Security](/vllm-project/vllm/security)
* [Insights](/vllm-project/vllm/pulse)

New issue

**Have a question about this project?** Sign up for a free GitHub account to open an issue and contact its maintainers and the community.

 [Sign up for GitHub](/signup?return_to=%2Fvllm-project%2Fvllm%2Fissues%2Fnew%2Fchoose)

By clicking ‚ÄúSign up for GitHub‚Äù, you agree to our [terms of service](https://docs.github.com/terms) and
[privacy statement](https://docs.github.com/privacy). We‚Äôll occasionally send you account related emails.

Already on GitHub?
[Sign in](/login?return_to=%2Fvllm-project%2Fvllm%2Fissues%2Fnew%2Fchoose)
to your account

[Jump to bottom](#issue-comment-box)

# [Bug]: assert num\_new\_tokens > 0 crashes entire worker instead of just failing single API call #7632

Closed

[pseudotensor](/pseudotensor) opened this issue
Aug 18, 2024
¬∑ 1 comment
 ¬∑ Fixed by [#7746](https://github.com/vllm-project/vllm/pull/7746)

Closed

# [[Bug]: assert num\_new\_tokens > 0 crashes entire worker instead of just failing single API call](#top) #7632

[pseudotensor](/pseudotensor) opened this issue
Aug 18, 2024
¬∑ 1 comment
 ¬∑ Fixed by [#7746](https://github.com/vllm-project/vllm/pull/7746)

Labels
[bug](/vllm-project/vllm/labels/bug)
Something isn't working

## Comments

[![@pseudotensor](https://avatars.githubusercontent.com/u/2249614?s=80&u=dc77b597fa5c070fc5c27f3ecdbbb8f6a8cbdc93&v=4)](/pseudotensor)

Copy link

### **[pseudotensor](/pseudotensor)** commented [Aug 18, 2024](#issue-2471773286) ‚Ä¢ edited Loading

| Your current environment vllm docker 0.5.4  ``` docker pull vllm/vllm-openai:latest docker stop danube3_mig ; docker remove danube3_mig docker run -d --restart=always \     --runtime=nvidia \     --gpus '"device=MIG-a6dbed35-9d05-58da-a0b5-23ae5bf8427e"' \     --shm-size=10.24gb \     -p 5004:5004 \     -e NCCL_IGNORE_DISABLED_P2P=1 \     -e HUGGING_FACE_HUB_TOKEN=$HUGGING_FACE_HUB_TOKEN \     -e VLLM_NCCL_SO_PATH=/usr/local/lib/python3.10/dist-packages/nvidia/nccl/lib/libnccl.so.2 \     -v /etc/passwd:/etc/passwd:ro \     -v /etc/group:/etc/group:ro \     -u `id -u`:`id -g` \     -v "${HOME}"/.cache:$HOME/.cache/ -v "${HOME}"/.config:$HOME/.config/   -v "${HOME}"/.triton:$HOME/.triton/  \     --network host \     --name danube3_mig \     vllm/vllm-openai:latest \         --port=5004 \         --host=0.0.0.0 \         --model=h2oai/h2o-danube3-4b-chat \         --seed 1234 \         --trust-remote-code \         --tensor-parallel-size=1 \         --max-model-len=8192 \         --gpu-memory-utilization=0.99 \         --max-num-batched-tokens=131072 --max-log-len=100 \         --use-v2-block-manager \         --num-speculative-tokens=5 \         --ngram-prompt-lookup-max=4 \         --enable-prefix-caching \         --speculative-model="[ngram]" \         --download-dir=$HOME/.cache/huggingface/hub &>> logs.vllm_server.danube3_migb.txt  ```  Unsure if has to do with speculative, seems just like prompt='' causes it. üêõ Describe the bug ``` INFO:     172.16.0.199:21756 - "GET /health HTTP/1.1" 200 OK INFO 08-18 00:51:02 logger.py:36] Received request cmpl-14b87b97d9a8481d8963a0a1652b217b-0: prompt: '', params: SamplingParams(n=1, best_of=1, presence_penalty=0.0, frequency_penalty=0.0, repetition_penalty=1.0, temperature=0.3, top_p=1.> INFO:     172.16.0.199:21766 - "POST /v1/completions HTTP/1.1" 200 OK INFO 08-18 00:51:02 async_llm_engine.py:174] Added request cmpl-14b87b97d9a8481d8963a0a1652b217b-0. ERROR 08-18 00:51:02 async_llm_engine.py:57] Engine background task failed ERROR 08-18 00:51:02 async_llm_engine.py:57] Traceback (most recent call last): ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 47, in _log_task_completion ERROR 08-18 00:51:02 async_llm_engine.py:57]     return_value = task.result() ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 642, in run_engine_loop ERROR 08-18 00:51:02 async_llm_engine.py:57]     result = task.result() ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 585, in engine_step ERROR 08-18 00:51:02 async_llm_engine.py:57]     request_outputs = await self.engine.step_async(virtual_engine) ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 239, in step_async ERROR 08-18 00:51:02 async_llm_engine.py:57]     virtual_engine].schedule() ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 950, in schedule ERROR 08-18 00:51:02 async_llm_engine.py:57]     scheduler_outputs = self._schedule() ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 925, in _schedule ERROR 08-18 00:51:02 async_llm_engine.py:57]     return self._schedule_default() ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 785, in _schedule_default ERROR 08-18 00:51:02 async_llm_engine.py:57]     prefills = self._schedule_prefills(budget, ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 683, in _schedule_prefills ERROR 08-18 00:51:02 async_llm_engine.py:57]     num_new_tokens = self._get_num_new_tokens(seq_group, ERROR 08-18 00:51:02 async_llm_engine.py:57]   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 1206, in _get_num_new_tokens ERROR 08-18 00:51:02 async_llm_engine.py:57]     assert num_new_tokens > 0 ERROR 08-18 00:51:02 async_llm_engine.py:57] AssertionError Exception in callback _log_task_completion(error_callback=<bound method...72047c646d70>>)(<Task finishe...ertionError()>) at /usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py:37 handle: <Handle _log_task_completion(error_callback=<bound method...72047c646d70>>)(<Task finishe...ertionError()>) at /usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py:37> Traceback (most recent call last):   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 47, in _log_task_completion     return_value = task.result()   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 642, in run_engine_loop     result = task.result()   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 585, in engine_step     request_outputs = await self.engine.step_async(virtual_engine)   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 239, in step_async     virtual_engine].schedule()   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 950, in schedule     scheduler_outputs = self._schedule()   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 925, in _schedule     return self._schedule_default()   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 785, in _schedule_default     prefills = self._schedule_prefills(budget, INFO 08-18 00:51:02 async_llm_engine.py:181] Aborted request cmpl-14b87b97d9a8481d8963a0a1652b217b-0.   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 683, in _schedule_prefills     num_new_tokens = self._get_num_new_tokens(seq_group,   File "/usr/local/lib/python3.10/dist-packages/vllm/core/scheduler.py", line 1206, in _get_num_new_tokens     assert num_new_tokens > 0 AssertionError   The above exception was the direct cause of the following exception:  Traceback (most recent call last):   File "/usr/lib/python3.10/asyncio/events.py", line 80, in _run     self._context.run(self._callback, *self._args)   File "/usr/local/lib/python3.10/dist-packages/vllm/engine/async_llm_engine.py", line 59, in _log_task_completion     raise AsyncEngineDeadError( vllm.engine.async_llm_engine.AsyncEngineDeadError: Task finished unexpectedly. This should never happen! Please open an issue on Github. See stack trace above for theactual cause. ERROR:    Exception in ASGI application Traceback (most recent call last):   File "/usr/local/lib/python3.10/dist-packages/starlette/responses.py", line 265, in __call__     await wrap(partial(self.listen_for_disconnect, receive))   File "/usr/local/lib/python3.10/dist-packages/starlette/responses.py", line 261, in wrap     await func()   File "/usr/local/lib/python3.10/dist-packages/starlette/responses.py", line 238, in listen_for_disconnect     message = await receive()   File "/usr/local/lib/python3.10/dist-packages/starlette/middleware/base.py", line 54, in wrapped_receive     msg = await self.receive()   File "/usr/local/lib/python3.10/dist-packages/uvicorn/protocols/http/httptools_impl.py", line 553, in receive     await self.message_event.wait()   File "/usr/lib/python3.10/asyncio/locks.py", line 214, in wait     await fut asyncio.exceptions.CancelledError: Cancelled by cancel scope 720537665120  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File "/usr/local/lib/python3.10/dist-packages/starlette/middleware/base.py", line 192, in __call__     await response(scope, wrapped_receive, send)   File "/usr/local/lib/python3.10/dist-packages/starlette/responses.py", line 258, in __call__     async with anyio.create_task_group() as task_group:   File "/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py", line 680, in __aexit__     raise BaseExceptionGroup( exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   File "/usr/local/lib/python3.10/dist-packages/starlette/_utils.py", line 87, in collapse_excgroups     yield   File "/usr/local/lib/python3.10/dist-packages/starlette/middleware/base.py", line 190, in __call__     async with anyio.create_task_group() as task_group:   File "/usr/local/lib/python3.10/dist-packages/anyio/_backends/_asyncio.py", line 680, in __aexit__     raise BaseExceptionGroup( exceptiongroup.ExceptionGroup: unhandled errors in a TaskGroup (1 sub-exception)  During handling of the above exception, another exception occurred:  Traceback (most recent call last):   ``` |
| --- |
| The text was updated successfully, but these errors were encountered: |

All reactions

[![@pseudotensor](https://avatars.githubusercontent.com/u/2249614?s=40&u=dc77b597fa5c070fc5c27f3ecdbbb8f6a8cbdc93&v=4)](/pseudotensor)
[pseudotensor](/pseudotensor)
added
the
[bug](/vllm-project/vllm/labels/bug)
Something isn't working
label
[Aug 18, 2024](#event-13921096048)

[![@pseudotensor](https://avatars.githubusercontent.com/u/2249614?s=80&u=dc77b597fa5c070fc5c27f3ecdbbb8f6a8cbdc93&v=4)](/pseudotensor)

Copy link

Author

### **[pseudotensor](/pseudotensor)** commented [Aug 18, 2024](#issuecomment-2295099412)

| To be clear, the bug is at least that the entire vllm engine is taken down by prompt='' |
| --- |

All reactions

Sorry, something went wrong.

This was referenced Aug 18, 2024

[[Bug]: Empty prompt kills vllm server (AsyncEngineDeadError: Background loop is stopped.)
#7283](/vllm-project/vllm/issues/7283)

Closed

[[Feature]: Exit on failures
#7633](/vllm-project/vllm/issues/7633)

Closed

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
mentioned this issue
[Aug 21, 2024](#ref-issue-2464212312)

[Release v0.5.5
#7481](/vllm-project/vllm/issues/7481)

Closed

[![@maxdebayser](https://avatars.githubusercontent.com/u/1291418?s=40&v=4)](/maxdebayser)
[maxdebayser](/maxdebayser)
mentioned this issue
[Aug 21, 2024](#ref-pullrequest-2478656118)

[[BugFix] Fix server crash on empty prompt
#7746](/vllm-project/vllm/pull/7746)
 Merged

[![@njhill](https://avatars.githubusercontent.com/u/16958488?s=40&u=4937d5b5409bb56b5f3a96b18b2d365f2f5e655c&v=4)](/njhill)
[njhill](/njhill)
closed this as [completed](/vllm-project/vllm/issues?q=is%3Aissue+is%3Aclosed+archived%3Afalse+reason%3Acompleted)
in
[#7746](/vllm-project/vllm/pull/7746)
[Aug 23, 2024](#event-13993127474)

[Anyonering](/Anyonering)
added a commit
to iidsample/chatdatagen
that referenced
this issue
[Oct 2, 2024](#ref-commit-cced6e7)
[![@Anyonering](https://avatars.githubusercontent.com/u/121237579?s=40&v=4)](/Anyonering)

`[Add grpc calls in dataset generator.](/iidsample/chatdatagen/commit/cced6e7a2e1099ba6c33066cabc4a426f5d398c6 "Add grpc calls in dataset generator.

Tested in local machines. Have assertiona failed on server side which
causes the vllm worker to crash. This may be caused by sending empty
prompt to the server as described in
https://github.com/vllm-project/vllm/issues/7632 and
https://github.com/vllm-project/vllm/pull/7746. Need to further
inspection on this later.")`
‚Ä¶

`[cced6e7](/iidsample/chatdatagen/commit/cced6e7a2e1099ba6c33066cabc4a426f5d398c6)`

```
Tested in local machines. Have assertiona failed on server side which
causes the vllm worker to crash. This may be caused by sending empty
prompt to the server as described in
[vllm-project/vllm#7632](https://github.com/vllm-project/vllm/issues/7632) and
[vllm-project/vllm#7746](https://github.com/vllm-project/vllm/pull/7746). Need to further
inspection on this later.
```

[Sign up for free](/join?source=comment-repo)
**to join this conversation on GitHub**.
Already have an account?
[Sign in to comment](/login?return_to=https%3A%2F%2Fgithub.com%2Fvllm-project%2Fvllm%2Fissues%2F7632)

Assignees

No one assigned

Labels

[bug](/vllm-project/vllm/labels/bug)
Something isn't working

Projects

None yet

Milestone

No milestone

Development

Successfully merging a pull request may close this issue.

 [[BugFix] Fix server crash on empty prompt](/vllm-project/vllm/pull/7746)
 [maxdebayser/vllm](/maxdebayser/vllm)

1 participant

[![@pseudotensor](https://avatars.githubusercontent.com/u/2249614?s=52&v=4)](/pseudotensor)

## Footer

¬© 2025 GitHub,¬†Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can‚Äôt perform that action at this time.



=== Content from bugzilla.redhat.com_ad6a4f7d_20250111_130543.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D2311895)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D2311895)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D2311895)+ Login using a Red Hat Bugzilla account
  + Forgot¬†Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla ‚Äì Bug¬†2311895

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug¬†2311895**](show_bug.cgi?id=2311895)
(CVE-2024-8768)
- [CVE-2024-8768](https://access.redhat.com/security/cve/CVE-2024-8768) vllm: A completions API request with an empty prompt will crash the vllm API server.

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2024-8768 vllm: A completions API request with an empty prompt will crash...

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | NEW | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | CVE-2024-8768 | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Security Response | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Other | | [Component:](describecomponents.cgi?product=Security Response "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | vulnerability | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | unspecified | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | high | | [Severity:](page.cgi?id=fields.html#bug_severity) | high | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Product Security DevOps Team | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") |  | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") |  | | TreeView+ | [depends on](buglist.cgi?bug_id=2311895&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=2311895&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2024-09-12 11:13 UTC by OSIDB Bzimport | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2024-09-17 15:43 UTC ([History](show_activity.cgi?id=2311895)) | | [CC List:](page.cgi?id=fields.html#cclist) | 2 users (show)  jeder rkeshri | | Fixed In Version: |  | | | Doc Type: | If docs needed, set a value | | | Doc Text: | A flaw was found in the vLLM library. A completions API request with an empty prompt will crash the vLLM API server, resulting in a denial of service. | | | Clone Of: |  | | | Environment: |  | | | Last Closed: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | | |  |
| --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=2311895#c0)  OSIDB Bzimport    2024-09-12 11:13:07 UTC  ``` A completions API request with an empty prompt will crash the vllm API server.  The impact is limited based on what model is being served. * Serving gpt2 is affected. * Most models are not affected, as vllm will prepend tokens to the prompt, avoiding the problematic code.  <https://github.com/vllm-project/vllm/commit/e25fee57c2e69161bd261f5986dc5aeb198bbd42>   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=2311895&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from access.redhat.com_9fb3fff2_20250111_130542.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Fran√ßais](https://access.redhat.com/changeLanguage?language=fr)
* [ÌïúÍµ≠Ïñ¥](https://access.redhat.com/changeLanguage?language=ko)
* [Êó•Êú¨Ë™û](https://access.redhat.com/changeLanguage?language=ja)
* [‰∏≠Êñá (‰∏≠ÂõΩ)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 ¬© 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)


