=== Content from git.kernel.org_615f10f4_20250110_110646.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=05095271a4fb0f6497121a057f9a2edf386d5d96)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=05095271a4fb0f6497121a057f9a2edf386d5d96)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=05095271a4fb0f6497121a057f9a2edf386d5d96)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=05095271a4fb0f6497121a057f9a2edf386d5d96)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Zqiang <qiang.zhang1211@gmail.com> | 2024-07-10 12:45:42 +0800 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-10-10 12:03:21 +0200 |
| commit | [05095271a4fb0f6497121a057f9a2edf386d5d96](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=05095271a4fb0f6497121a057f9a2edf386d5d96) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=05095271a4fb0f6497121a057f9a2edf386d5d96)) | |
| tree | [a8b86b78f7f41f9e449706b44081634eec8a8896](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=05095271a4fb0f6497121a057f9a2edf386d5d96) | |
| parent | [29626cdda948ce93b93971b24a172c8f896a7b98](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=29626cdda948ce93b93971b24a172c8f896a7b98) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=05095271a4fb0f6497121a057f9a2edf386d5d96&id2=29626cdda948ce93b93971b24a172c8f896a7b98)) | |
| download | [linux-05095271a4fb0f6497121a057f9a2edf386d5d96.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-05095271a4fb0f6497121a057f9a2edf386d5d96.tar.gz) | |

rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()[ Upstream commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 ]
For kernels built with CONFIG\_FORCE\_NR\_CPUS=y, the nr\_cpu\_ids is
defined as NR\_CPUS instead of the number of possible cpus, this
will cause the following system panic:
smpboot: Allowing 4 CPUs, 0 hotplug CPUs
...
setup\_percpu: NR\_CPUS:512 nr\_cpumask\_bits:512 nr\_cpu\_ids:512 nr\_node\_ids:1
...
BUG: unable to handle page fault for address: ffffffff9911c8c8
Oops: 0000 [#1] PREEMPT SMP PTI
CPU: 0 PID: 15 Comm: rcu\_tasks\_trace Tainted: G W
6.6.21 #1 5dc7acf91a5e8e9ac9dcfc35bee0245691283ea6
RIP: 0010:rcu\_tasks\_need\_gpcb+0x25d/0x2c0
RSP: 0018:ffffa371c00a3e60 EFLAGS: 00010082
CR2: ffffffff9911c8c8 CR3: 000000040fa20005 CR4: 00000000001706f0
Call Trace:
<TASK>
? \_\_die+0x23/0x80
? page\_fault\_oops+0xa4/0x180
? exc\_page\_fault+0x152/0x180
? asm\_exc\_page\_fault+0x26/0x40
? rcu\_tasks\_need\_gpcb+0x25d/0x2c0
? \_\_pfx\_rcu\_tasks\_kthread+0x40/0x40
rcu\_tasks\_one\_gp+0x69/0x180
rcu\_tasks\_kthread+0x94/0xc0
kthread+0xe8/0x140
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork+0x34/0x80
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork\_asm+0x1b/0x80
</TASK>
Considering that there may be holes in the CPU numbers, use the
maximum possible cpu number, instead of nr\_cpu\_ids, for configuring
enqueue and dequeue limits.
[ neeraj.upadhyay: Fix htmldocs build error reported by Stephen Rothwell ]
Closes: https://lore.kernel.org/linux-input/CALMA0xaTSMN+p4xUXkzrtR5r6k7hgoswcaXx7baR\_z9r5jjskw@mail.gmail.com/T/#u
Reported-by: Zhixu Liu <zhixu.liu@gmail.com>
Signed-off-by: Zqiang <qiang.zhang1211@gmail.com>
Signed-off-by: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=05095271a4fb0f6497121a057f9a2edf386d5d96)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=05095271a4fb0f6497121a057f9a2edf386d5d96) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 53 insertions, 29 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex ba3440a45b6dd4..bc8429ada7a51d 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=29626cdda948ce93b93971b24a172c8f896a7b98)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=05095271a4fb0f6497121a057f9a2edf386d5d96)@@ -34,6 +34,7 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @rtp\_exit\_list: List of tasks in the latter portion of do\_exit(). \* @cpu: CPU number corresponding to this entry.+ \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -49,6 +50,7 @@ struct rcu\_tasks\_percpu { struct list\_head rtp\_blkd\_tasks; struct list\_head rtp\_exit\_list; int cpu;+ int index; struct rcu\_tasks \*rtpp; }; @@ -76,6 +78,7 @@ struct rcu\_tasks\_percpu { \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @wait\_state: Task state for synchronous grace-period waits (default TASK\_UNINTERRUPTIBLE). \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.+ \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -110,6 +113,7 @@ struct rcu\_tasks { call\_rcu\_func\_t call\_func; unsigned int wait\_state; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;+ struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -182,6 +186,8 @@ module\_param(rcu\_task\_collapse\_lim, int, 0444); static int rcu\_task\_lazy\_lim \_\_read\_mostly = 32; module\_param(rcu\_task\_lazy\_lim, int, 0444); +static int rcu\_task\_cpu\_ids;+ /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -245,6 +251,8 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) int cpu; int lim; int shift;+ int maxcpu;+ int index = 0;  if (rcu\_task\_enqueue\_lim < 0) { rcu\_task\_enqueue\_lim = 1;@@ -254,14 +262,9 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - if (lim > nr\_cpu\_ids)- lim = nr\_cpu\_ids;- shift = ilog2(nr\_cpu\_ids / lim);- if (((nr\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);+ rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);+ BUG\_ON(!rtp->rtpcp\_array);+ for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -273,14 +276,29 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;+ rtpcp->index = index;+ rtp->rtpcp\_array[index] = rtpcp;+ index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); if (!rtpcp->rtp\_exit\_list.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_exit\_list);+ maxcpu = cpu; } - pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d.\n", rtp->name,- data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim), rcu\_task\_cb\_adjust);+ rcu\_task\_cpu\_ids = maxcpu + 1;+ if (lim > rcu\_task\_cpu\_ids)+ lim = rcu\_task\_cpu\_ids;+ shift = ilog2(rcu\_task\_cpu\_ids / lim);+ if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);++ pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",+ rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),+ rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids); }  // Compute wakeup time for lazy callback timer.@@ -348,7 +366,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } // Queuing callbacks before initialization not yet supported.@@ -368,10 +386,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -444,6 +462,8 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp)  dequeue\_limit = smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); for (cpu = 0; cpu < dequeue\_limit; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -481,7 +501,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -496,7 +516,9 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) {+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -511,30 +533,32 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {- int cpu;- int cpunext; int cpuwq; unsigned long flags; int len;+ int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - cpu = rtpcp->cpu;- cpunext = cpu \* 2 + 1;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- cpunext++;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ index = rtpcp->index \* 2 + 1;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ index++;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ }+ } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu))+ if (rcu\_segcblist\_empty(&rtpcp->cblist)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:23 +0000



=== Content from git.kernel.org_e668c8bb_20250110_110648.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Zqiang <qiang.zhang1211@gmail.com> | 2024-07-10 12:45:42 +0800 |
| --- | --- | --- |
| committer | Neeraj Upadhyay <neeraj.upadhyay@kernel.org> | 2024-08-14 16:46:31 +0530 |
| commit | [fd70e9f1d85f5323096ad313ba73f5fe3d15ea41](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)) | |
| tree | [d1f70dfdeb1bfd7f9c7e2a9c5b62eb2b70c84204](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41) | |
| parent | [7945b741d1fc071a621366c512a060ea08848955](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=7945b741d1fc071a621366c512a060ea08848955) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41&id2=7945b741d1fc071a621366c512a060ea08848955)) | |
| download | [linux-fd70e9f1d85f5323096ad313ba73f5fe3d15ea41.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-fd70e9f1d85f5323096ad313ba73f5fe3d15ea41.tar.gz) | |

rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()For kernels built with CONFIG\_FORCE\_NR\_CPUS=y, the nr\_cpu\_ids is
defined as NR\_CPUS instead of the number of possible cpus, this
will cause the following system panic:
smpboot: Allowing 4 CPUs, 0 hotplug CPUs
...
setup\_percpu: NR\_CPUS:512 nr\_cpumask\_bits:512 nr\_cpu\_ids:512 nr\_node\_ids:1
...
BUG: unable to handle page fault for address: ffffffff9911c8c8
Oops: 0000 [#1] PREEMPT SMP PTI
CPU: 0 PID: 15 Comm: rcu\_tasks\_trace Tainted: G W
6.6.21 #1 5dc7acf91a5e8e9ac9dcfc35bee0245691283ea6
RIP: 0010:rcu\_tasks\_need\_gpcb+0x25d/0x2c0
RSP: 0018:ffffa371c00a3e60 EFLAGS: 00010082
CR2: ffffffff9911c8c8 CR3: 000000040fa20005 CR4: 00000000001706f0
Call Trace:
<TASK>
? \_\_die+0x23/0x80
? page\_fault\_oops+0xa4/0x180
? exc\_page\_fault+0x152/0x180
? asm\_exc\_page\_fault+0x26/0x40
? rcu\_tasks\_need\_gpcb+0x25d/0x2c0
? \_\_pfx\_rcu\_tasks\_kthread+0x40/0x40
rcu\_tasks\_one\_gp+0x69/0x180
rcu\_tasks\_kthread+0x94/0xc0
kthread+0xe8/0x140
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork+0x34/0x80
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork\_asm+0x1b/0x80
</TASK>
Considering that there may be holes in the CPU numbers, use the
maximum possible cpu number, instead of nr\_cpu\_ids, for configuring
enqueue and dequeue limits.
[ neeraj.upadhyay: Fix htmldocs build error reported by Stephen Rothwell ]
Closes: https://lore.kernel.org/linux-input/CALMA0xaTSMN+p4xUXkzrtR5r6k7hgoswcaXx7baR\_z9r5jjskw@mail.gmail.com/T/#u
Reported-by: Zhixu Liu <zhixu.liu@gmail.com>
Signed-off-by: Zqiang <qiang.zhang1211@gmail.com>
Signed-off-by: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 53 insertions, 29 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex 4bc038bcc01691..72d564c84499ae 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=7945b741d1fc071a621366c512a060ea08848955)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=fd70e9f1d85f5323096ad313ba73f5fe3d15ea41)@@ -34,6 +34,7 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @rtp\_exit\_list: List of tasks in the latter portion of do\_exit(). \* @cpu: CPU number corresponding to this entry.+ \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -49,6 +50,7 @@ struct rcu\_tasks\_percpu { struct list\_head rtp\_blkd\_tasks; struct list\_head rtp\_exit\_list; int cpu;+ int index; struct rcu\_tasks \*rtpp; }; @@ -76,6 +78,7 @@ struct rcu\_tasks\_percpu { \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @wait\_state: Task state for synchronous grace-period waits (default TASK\_UNINTERRUPTIBLE). \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.+ \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -110,6 +113,7 @@ struct rcu\_tasks { call\_rcu\_func\_t call\_func; unsigned int wait\_state; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;+ struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -182,6 +186,8 @@ module\_param(rcu\_task\_collapse\_lim, int, 0444); static int rcu\_task\_lazy\_lim \_\_read\_mostly = 32; module\_param(rcu\_task\_lazy\_lim, int, 0444); +static int rcu\_task\_cpu\_ids;+ /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -245,6 +251,8 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) int cpu; int lim; int shift;+ int maxcpu;+ int index = 0;  if (rcu\_task\_enqueue\_lim < 0) { rcu\_task\_enqueue\_lim = 1;@@ -254,14 +262,9 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - if (lim > nr\_cpu\_ids)- lim = nr\_cpu\_ids;- shift = ilog2(nr\_cpu\_ids / lim);- if (((nr\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);+ rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);+ BUG\_ON(!rtp->rtpcp\_array);+ for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -273,14 +276,29 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;+ rtpcp->index = index;+ rtp->rtpcp\_array[index] = rtpcp;+ index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); if (!rtpcp->rtp\_exit\_list.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_exit\_list);+ maxcpu = cpu; } - pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d.\n", rtp->name,- data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim), rcu\_task\_cb\_adjust);+ rcu\_task\_cpu\_ids = maxcpu + 1;+ if (lim > rcu\_task\_cpu\_ids)+ lim = rcu\_task\_cpu\_ids;+ shift = ilog2(rcu\_task\_cpu\_ids / lim);+ if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);++ pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",+ rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),+ rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids); }  // Compute wakeup time for lazy callback timer.@@ -348,7 +366,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } // Queuing callbacks before initialization not yet supported.@@ -368,10 +386,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -444,6 +462,8 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp)  dequeue\_limit = smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); for (cpu = 0; cpu < dequeue\_limit; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -481,7 +501,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -496,7 +516,9 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) {+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -511,30 +533,32 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {- int cpu;- int cpunext; int cpuwq; unsigned long flags; int len;+ int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - cpu = rtpcp->cpu;- cpunext = cpu \* 2 + 1;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- cpunext++;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ index = rtpcp->index \* 2 + 1;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ index++;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ }+ } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu))+ if (rcu\_segcblist\_empty(&rtpcp->cblist)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:25 +0000



=== Content from git.kernel.org_2d0bd4d4_20250110_110647.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Zqiang <qiang.zhang1211@gmail.com> | 2024-07-10 12:45:42 +0800 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-10-10 12:00:26 +0200 |
| commit | [3104bddc666ff64b90491868bbc4c7ebdd90aedf](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)) | |
| tree | [78d4e5bda52af07ec6cd8368f6ba7a52fe9f062d](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf) | |
| parent | [79108bef7f0202e5edc872f1cad90b138934d889](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=79108bef7f0202e5edc872f1cad90b138934d889) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf&id2=79108bef7f0202e5edc872f1cad90b138934d889)) | |
| download | [linux-3104bddc666ff64b90491868bbc4c7ebdd90aedf.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-3104bddc666ff64b90491868bbc4c7ebdd90aedf.tar.gz) | |

rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()[ Upstream commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 ]
For kernels built with CONFIG\_FORCE\_NR\_CPUS=y, the nr\_cpu\_ids is
defined as NR\_CPUS instead of the number of possible cpus, this
will cause the following system panic:
smpboot: Allowing 4 CPUs, 0 hotplug CPUs
...
setup\_percpu: NR\_CPUS:512 nr\_cpumask\_bits:512 nr\_cpu\_ids:512 nr\_node\_ids:1
...
BUG: unable to handle page fault for address: ffffffff9911c8c8
Oops: 0000 [#1] PREEMPT SMP PTI
CPU: 0 PID: 15 Comm: rcu\_tasks\_trace Tainted: G W
6.6.21 #1 5dc7acf91a5e8e9ac9dcfc35bee0245691283ea6
RIP: 0010:rcu\_tasks\_need\_gpcb+0x25d/0x2c0
RSP: 0018:ffffa371c00a3e60 EFLAGS: 00010082
CR2: ffffffff9911c8c8 CR3: 000000040fa20005 CR4: 00000000001706f0
Call Trace:
<TASK>
? \_\_die+0x23/0x80
? page\_fault\_oops+0xa4/0x180
? exc\_page\_fault+0x152/0x180
? asm\_exc\_page\_fault+0x26/0x40
? rcu\_tasks\_need\_gpcb+0x25d/0x2c0
? \_\_pfx\_rcu\_tasks\_kthread+0x40/0x40
rcu\_tasks\_one\_gp+0x69/0x180
rcu\_tasks\_kthread+0x94/0xc0
kthread+0xe8/0x140
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork+0x34/0x80
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork\_asm+0x1b/0x80
</TASK>
Considering that there may be holes in the CPU numbers, use the
maximum possible cpu number, instead of nr\_cpu\_ids, for configuring
enqueue and dequeue limits.
[ neeraj.upadhyay: Fix htmldocs build error reported by Stephen Rothwell ]
Closes: https://lore.kernel.org/linux-input/CALMA0xaTSMN+p4xUXkzrtR5r6k7hgoswcaXx7baR\_z9r5jjskw@mail.gmail.com/T/#u
Reported-by: Zhixu Liu <zhixu.liu@gmail.com>
Signed-off-by: Zqiang <qiang.zhang1211@gmail.com>
Signed-off-by: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 53 insertions, 29 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex ba3440a45b6dd4..bc8429ada7a51d 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=79108bef7f0202e5edc872f1cad90b138934d889)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=3104bddc666ff64b90491868bbc4c7ebdd90aedf)@@ -34,6 +34,7 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @rtp\_exit\_list: List of tasks in the latter portion of do\_exit(). \* @cpu: CPU number corresponding to this entry.+ \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -49,6 +50,7 @@ struct rcu\_tasks\_percpu { struct list\_head rtp\_blkd\_tasks; struct list\_head rtp\_exit\_list; int cpu;+ int index; struct rcu\_tasks \*rtpp; }; @@ -76,6 +78,7 @@ struct rcu\_tasks\_percpu { \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @wait\_state: Task state for synchronous grace-period waits (default TASK\_UNINTERRUPTIBLE). \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.+ \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -110,6 +113,7 @@ struct rcu\_tasks { call\_rcu\_func\_t call\_func; unsigned int wait\_state; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;+ struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -182,6 +186,8 @@ module\_param(rcu\_task\_collapse\_lim, int, 0444); static int rcu\_task\_lazy\_lim \_\_read\_mostly = 32; module\_param(rcu\_task\_lazy\_lim, int, 0444); +static int rcu\_task\_cpu\_ids;+ /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -245,6 +251,8 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) int cpu; int lim; int shift;+ int maxcpu;+ int index = 0;  if (rcu\_task\_enqueue\_lim < 0) { rcu\_task\_enqueue\_lim = 1;@@ -254,14 +262,9 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - if (lim > nr\_cpu\_ids)- lim = nr\_cpu\_ids;- shift = ilog2(nr\_cpu\_ids / lim);- if (((nr\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);+ rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);+ BUG\_ON(!rtp->rtpcp\_array);+ for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -273,14 +276,29 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;+ rtpcp->index = index;+ rtp->rtpcp\_array[index] = rtpcp;+ index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); if (!rtpcp->rtp\_exit\_list.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_exit\_list);+ maxcpu = cpu; } - pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d.\n", rtp->name,- data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim), rcu\_task\_cb\_adjust);+ rcu\_task\_cpu\_ids = maxcpu + 1;+ if (lim > rcu\_task\_cpu\_ids)+ lim = rcu\_task\_cpu\_ids;+ shift = ilog2(rcu\_task\_cpu\_ids / lim);+ if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);++ pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",+ rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),+ rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids); }  // Compute wakeup time for lazy callback timer.@@ -348,7 +366,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } // Queuing callbacks before initialization not yet supported.@@ -368,10 +386,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -444,6 +462,8 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp)  dequeue\_limit = smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); for (cpu = 0; cpu < dequeue\_limit; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -481,7 +501,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -496,7 +516,9 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) {+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -511,30 +533,32 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {- int cpu;- int cpunext; int cpuwq; unsigned long flags; int len;+ int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - cpu = rtpcp->cpu;- cpunext = cpu \* 2 + 1;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- cpunext++;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ index = rtpcp->index \* 2 + 1;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ index++;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ }+ } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu))+ if (rcu\_segcblist\_empty(&rtpcp->cblist)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:24 +0000



=== Content from git.kernel.org_c40ca641_20250110_110646.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Zqiang <qiang.zhang1211@gmail.com> | 2024-07-10 12:45:42 +0800 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-12-14 19:53:56 +0100 |
| commit | [224fd631c41b81697aa622d38615bfbf446b91cf](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=224fd631c41b81697aa622d38615bfbf446b91cf) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=224fd631c41b81697aa622d38615bfbf446b91cf)) | |
| tree | [8c8dbf231eb2c200550f97abf04bf7993ce4711d](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=224fd631c41b81697aa622d38615bfbf446b91cf) | |
| parent | [db1d7e1794fed62ee16d6a72a85997bb069e2e27](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=db1d7e1794fed62ee16d6a72a85997bb069e2e27) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=224fd631c41b81697aa622d38615bfbf446b91cf&id2=db1d7e1794fed62ee16d6a72a85997bb069e2e27)) | |
| download | [linux-224fd631c41b81697aa622d38615bfbf446b91cf.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-224fd631c41b81697aa622d38615bfbf446b91cf.tar.gz) | |

rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 upstream.
For kernels built with CONFIG\_FORCE\_NR\_CPUS=y, the nr\_cpu\_ids is
defined as NR\_CPUS instead of the number of possible cpus, this
will cause the following system panic:
smpboot: Allowing 4 CPUs, 0 hotplug CPUs
...
setup\_percpu: NR\_CPUS:512 nr\_cpumask\_bits:512 nr\_cpu\_ids:512 nr\_node\_ids:1
...
BUG: unable to handle page fault for address: ffffffff9911c8c8
Oops: 0000 [#1] PREEMPT SMP PTI
CPU: 0 PID: 15 Comm: rcu\_tasks\_trace Tainted: G W
6.6.21 #1 5dc7acf91a5e8e9ac9dcfc35bee0245691283ea6
RIP: 0010:rcu\_tasks\_need\_gpcb+0x25d/0x2c0
RSP: 0018:ffffa371c00a3e60 EFLAGS: 00010082
CR2: ffffffff9911c8c8 CR3: 000000040fa20005 CR4: 00000000001706f0
Call Trace:
<TASK>
? \_\_die+0x23/0x80
? page\_fault\_oops+0xa4/0x180
? exc\_page\_fault+0x152/0x180
? asm\_exc\_page\_fault+0x26/0x40
? rcu\_tasks\_need\_gpcb+0x25d/0x2c0
? \_\_pfx\_rcu\_tasks\_kthread+0x40/0x40
rcu\_tasks\_one\_gp+0x69/0x180
rcu\_tasks\_kthread+0x94/0xc0
kthread+0xe8/0x140
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork+0x34/0x80
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork\_asm+0x1b/0x80
</TASK>
Considering that there may be holes in the CPU numbers, use the
maximum possible cpu number, instead of nr\_cpu\_ids, for configuring
enqueue and dequeue limits.
[ neeraj.upadhyay: Fix htmldocs build error reported by Stephen Rothwell ]
Closes: https://lore.kernel.org/linux-input/CALMA0xaTSMN+p4xUXkzrtR5r6k7hgoswcaXx7baR\_z9r5jjskw@mail.gmail.com/T/#u
Reported-by: Zhixu Liu <zhixu.liu@gmail.com>
Signed-off-by: Zqiang <qiang.zhang1211@gmail.com>
Signed-off-by: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Xiangyu: BP to fix CVE:CVE-2024-49926, minor conflict resolution]
Signed-off-by: Xiangyu Chen <xiangyu.chen@windriver.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=224fd631c41b81697aa622d38615bfbf446b91cf)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=224fd631c41b81697aa622d38615bfbf446b91cf) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 54 insertions, 28 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex bb6b037ef30fa7..46b207eac171b7 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=db1d7e1794fed62ee16d6a72a85997bb069e2e27)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=224fd631c41b81697aa622d38615bfbf446b91cf)@@ -31,6 +31,7 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @barrier\_q\_head: RCU callback for barrier operation. \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @cpu: CPU number corresponding to this entry.+ \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -43,6 +44,7 @@ struct rcu\_tasks\_percpu { struct rcu\_head barrier\_q\_head; struct list\_head rtp\_blkd\_tasks; int cpu;+ int index; struct rcu\_tasks \*rtpp; }; @@ -68,6 +70,7 @@ struct rcu\_tasks\_percpu { \* @postgp\_func: This flavor's post-grace-period function (optional). \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.+ \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -100,6 +103,7 @@ struct rcu\_tasks { postgp\_func\_t postgp\_func; call\_rcu\_func\_t call\_func; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;+ struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -164,6 +168,8 @@ module\_param(rcu\_task\_contend\_lim, int, 0444); static int rcu\_task\_collapse\_lim \_\_read\_mostly = 10; module\_param(rcu\_task\_collapse\_lim, int, 0444); +static int rcu\_task\_cpu\_ids;+ /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -228,6 +234,8 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) unsigned long flags; int lim; int shift;+ int maxcpu;+ int index = 0;  raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rcu\_task\_enqueue\_lim < 0) {@@ -238,14 +246,9 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - if (lim > nr\_cpu\_ids)- lim = nr\_cpu\_ids;- shift = ilog2(nr\_cpu\_ids / lim);- if (((nr\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);+ rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);+ BUG\_ON(!rtp->rtpcp\_array);+ for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -258,16 +261,33 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;+ rtpcp->index = index;+ rtp->rtpcp\_array[index] = rtpcp;+ index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); raw\_spin\_unlock\_rcu\_node(rtpcp); // irqs remain disabled.+ maxcpu = cpu; } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);  if (rcu\_task\_cb\_adjust) pr\_info("%s: Setting adjustable number of callback queues.\n", \_\_func\_\_); - pr\_info("%s: Setting shift to %d and lim to %d.\n", \_\_func\_\_, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim));+ rcu\_task\_cpu\_ids = maxcpu + 1;+ if (lim > rcu\_task\_cpu\_ids)+ lim = rcu\_task\_cpu\_ids;+ shift = ilog2(rcu\_task\_cpu\_ids / lim);+ if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);++ pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",+ rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),+ rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids);+ }  // IRQ-work handler that does deferred wakeup for call\_rcu\_tasks\_generic().@@ -307,7 +327,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } if (!rcu\_segcblist\_is\_enabled(&rtpcp->cblist)) {@@ -320,10 +340,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -394,6 +414,8 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) int needgpcb = 0;  for (cpu = 0; cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -426,7 +448,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -441,7 +463,9 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) {+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -456,30 +480,32 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {- int cpu;- int cpunext; int cpuwq; unsigned long flags; int len;+ int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - cpu = rtpcp->cpu;- cpunext = cpu \* 2 + 1;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- cpunext++;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ index = rtpcp->index \* 2 + 1;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ index++;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ }+ } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu))+ if (rcu\_segcblist\_empty(&rtpcp->cblist)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:23 +0000



=== Content from git.kernel.org_01d473c7_20250110_110648.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Zqiang <qiang.zhang1211@gmail.com> | 2024-07-10 12:45:42 +0800 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-11-08 16:28:22 +0100 |
| commit | [b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)) | |
| tree | [1deafb1a389885e8e6ffff156c3abb5f01b805d1](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf) | |
| parent | [7679283e61a8b8378850e302deb5e64497b6dfbe](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=7679283e61a8b8378850e302deb5e64497b6dfbe) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf&id2=7679283e61a8b8378850e302deb5e64497b6dfbe)) | |
| download | [linux-b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf.tar.gz) | |

rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()[ Upstream commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 ]
For kernels built with CONFIG\_FORCE\_NR\_CPUS=y, the nr\_cpu\_ids is
defined as NR\_CPUS instead of the number of possible cpus, this
will cause the following system panic:
smpboot: Allowing 4 CPUs, 0 hotplug CPUs
...
setup\_percpu: NR\_CPUS:512 nr\_cpumask\_bits:512 nr\_cpu\_ids:512 nr\_node\_ids:1
...
BUG: unable to handle page fault for address: ffffffff9911c8c8
Oops: 0000 [#1] PREEMPT SMP PTI
CPU: 0 PID: 15 Comm: rcu\_tasks\_trace Tainted: G W
6.6.21 #1 5dc7acf91a5e8e9ac9dcfc35bee0245691283ea6
RIP: 0010:rcu\_tasks\_need\_gpcb+0x25d/0x2c0
RSP: 0018:ffffa371c00a3e60 EFLAGS: 00010082
CR2: ffffffff9911c8c8 CR3: 000000040fa20005 CR4: 00000000001706f0
Call Trace:
<TASK>
? \_\_die+0x23/0x80
? page\_fault\_oops+0xa4/0x180
? exc\_page\_fault+0x152/0x180
? asm\_exc\_page\_fault+0x26/0x40
? rcu\_tasks\_need\_gpcb+0x25d/0x2c0
? \_\_pfx\_rcu\_tasks\_kthread+0x40/0x40
rcu\_tasks\_one\_gp+0x69/0x180
rcu\_tasks\_kthread+0x94/0xc0
kthread+0xe8/0x140
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork+0x34/0x80
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork\_asm+0x1b/0x80
</TASK>
Considering that there may be holes in the CPU numbers, use the
maximum possible cpu number, instead of nr\_cpu\_ids, for configuring
enqueue and dequeue limits.
[ neeraj.upadhyay: Fix htmldocs build error reported by Stephen Rothwell ]
Closes: https://lore.kernel.org/linux-input/CALMA0xaTSMN+p4xUXkzrtR5r6k7hgoswcaXx7baR\_z9r5jjskw@mail.gmail.com/T/#u
Reported-by: Zhixu Liu <zhixu.liu@gmail.com>
Signed-off-by: Zqiang <qiang.zhang1211@gmail.com>
Signed-off-by: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 53 insertions, 29 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex 4eae3b1bda70e0..3fcd9f92d38612 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=7679283e61a8b8378850e302deb5e64497b6dfbe)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=b3b2431ed27f4ebc28e26cdf005c1de42dc60bdf)@@ -34,6 +34,7 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @rtp\_exit\_list: List of tasks in the latter portion of do\_exit(). \* @cpu: CPU number corresponding to this entry.+ \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -49,6 +50,7 @@ struct rcu\_tasks\_percpu { struct list\_head rtp\_blkd\_tasks; struct list\_head rtp\_exit\_list; int cpu;+ int index; struct rcu\_tasks \*rtpp; }; @@ -75,6 +77,7 @@ struct rcu\_tasks\_percpu { \* @postgp\_func: This flavor's post-grace-period function (optional). \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.+ \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -108,6 +111,7 @@ struct rcu\_tasks { postgp\_func\_t postgp\_func; call\_rcu\_func\_t call\_func; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;+ struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -181,6 +185,8 @@ module\_param(rcu\_task\_collapse\_lim, int, 0444); static int rcu\_task\_lazy\_lim \_\_read\_mostly = 32; module\_param(rcu\_task\_lazy\_lim, int, 0444); +static int rcu\_task\_cpu\_ids;+ /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -245,6 +251,8 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) unsigned long flags; int lim; int shift;+ int maxcpu;+ int index = 0;  if (rcu\_task\_enqueue\_lim < 0) { rcu\_task\_enqueue\_lim = 1;@@ -254,14 +262,9 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - if (lim > nr\_cpu\_ids)- lim = nr\_cpu\_ids;- shift = ilog2(nr\_cpu\_ids / lim);- if (((nr\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);+ rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);+ BUG\_ON(!rtp->rtpcp\_array);+ for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -275,14 +278,29 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;+ rtpcp->index = index;+ rtp->rtpcp\_array[index] = rtpcp;+ index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); if (!rtpcp->rtp\_exit\_list.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_exit\_list);+ maxcpu = cpu; } - pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d.\n", rtp->name,- data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim), rcu\_task\_cb\_adjust);+ rcu\_task\_cpu\_ids = maxcpu + 1;+ if (lim > rcu\_task\_cpu\_ids)+ lim = rcu\_task\_cpu\_ids;+ shift = ilog2(rcu\_task\_cpu\_ids / lim);+ if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);++ pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",+ rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),+ rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids); }  // Compute wakeup time for lazy callback timer.@@ -350,7 +368,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } // Queuing callbacks before initialization not yet supported.@@ -370,10 +388,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -446,6 +464,8 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp)  dequeue\_limit = smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); for (cpu = 0; cpu < dequeue\_limit; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -483,7 +503,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -498,7 +518,9 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) {+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -513,30 +535,32 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {- int cpu;- int cpunext; int cpuwq; unsigned long flags; int len;+ int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - cpu = rtpcp->cpu;- cpunext = cpu \* 2 + 1;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- cpunext++;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ index = rtpcp->index \* 2 + 1;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ index++;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ }+ } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu))+ if (rcu\_segcblist\_empty(&rtpcp->cblist)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:25 +0000



=== Content from git.kernel.org_f078671d_20250110_110647.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=acddb87620142f38fda834cd1ec661512ca59241)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=acddb87620142f38fda834cd1ec661512ca59241)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=acddb87620142f38fda834cd1ec661512ca59241)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=acddb87620142f38fda834cd1ec661512ca59241)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-12-30 15:47:08 +0100 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2025-01-02 10:30:55 +0100 |
| commit | [acddb87620142f38fda834cd1ec661512ca59241](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=acddb87620142f38fda834cd1ec661512ca59241) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=acddb87620142f38fda834cd1ec661512ca59241)) | |
| tree | [0931608e223bad17ae5ead9fd07e651c429ab3d1](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=acddb87620142f38fda834cd1ec661512ca59241) | |
| parent | [36775f42e039b01d4abe8998bf66771a37d3cdcc](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=36775f42e039b01d4abe8998bf66771a37d3cdcc) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=acddb87620142f38fda834cd1ec661512ca59241&id2=36775f42e039b01d4abe8998bf66771a37d3cdcc)) | |
| download | [linux-acddb87620142f38fda834cd1ec661512ca59241.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-acddb87620142f38fda834cd1ec661512ca59241.tar.gz) | |

Revert "rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()"This reverts commit 224fd631c41b81697aa622d38615bfbf446b91cf which is
commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 upstream.
It is reported to cause problems in testing, so revert it for now.
Link: [https://lore.kernel.org/r/20241216-comic-handling-3bcf108cc465@wendy](https://lore.kernel.org/r/20241216-comic-handling-3bcf108cc465%40wendy)
Reported-by: Conor Dooley <conor.dooley@microchip.com>
CC: Zhixu Liu <zhixu.liu@gmail.com>
Cc: Zqiang <qiang.zhang1211@gmail.com>
Cc: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Cc: Sasha Levin <sashal@kernel.org>
Cc: Xiangyu Chen <xiangyu.chen@windriver.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=acddb87620142f38fda834cd1ec661512ca59241)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=acddb87620142f38fda834cd1ec661512ca59241) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 28 insertions, 54 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex 46b207eac171b7..bb6b037ef30fa7 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=36775f42e039b01d4abe8998bf66771a37d3cdcc)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=acddb87620142f38fda834cd1ec661512ca59241)@@ -31,7 +31,6 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @barrier\_q\_head: RCU callback for barrier operation. \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @cpu: CPU number corresponding to this entry.- \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -44,7 +43,6 @@ struct rcu\_tasks\_percpu { struct rcu\_head barrier\_q\_head; struct list\_head rtp\_blkd\_tasks; int cpu;- int index; struct rcu\_tasks \*rtpp; }; @@ -70,7 +68,6 @@ struct rcu\_tasks\_percpu { \* @postgp\_func: This flavor's post-grace-period function (optional). \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.- \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -103,7 +100,6 @@ struct rcu\_tasks { postgp\_func\_t postgp\_func; call\_rcu\_func\_t call\_func; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;- struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -168,8 +164,6 @@ module\_param(rcu\_task\_contend\_lim, int, 0444); static int rcu\_task\_collapse\_lim \_\_read\_mostly = 10; module\_param(rcu\_task\_collapse\_lim, int, 0444); -static int rcu\_task\_cpu\_ids;- /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -234,8 +228,6 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) unsigned long flags; int lim; int shift;- int maxcpu;- int index = 0;  raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rcu\_task\_enqueue\_lim < 0) {@@ -246,9 +238,14 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);- BUG\_ON(!rtp->rtpcp\_array);-+ if (lim > nr\_cpu\_ids)+ lim = nr\_cpu\_ids;+ shift = ilog2(nr\_cpu\_ids / lim);+ if (((nr\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim); for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -261,33 +258,16 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;- rtpcp->index = index;- rtp->rtpcp\_array[index] = rtpcp;- index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); raw\_spin\_unlock\_rcu\_node(rtpcp); // irqs remain disabled.- maxcpu = cpu; } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);  if (rcu\_task\_cb\_adjust) pr\_info("%s: Setting adjustable number of callback queues.\n", \_\_func\_\_); - rcu\_task\_cpu\_ids = maxcpu + 1;- if (lim > rcu\_task\_cpu\_ids)- lim = rcu\_task\_cpu\_ids;- shift = ilog2(rcu\_task\_cpu\_ids / lim);- if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);-- pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",- rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),- rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids);-+ pr\_info("%s: Setting shift to %d and lim to %d.\n", \_\_func\_\_, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim)); }  // IRQ-work handler that does deferred wakeup for call\_rcu\_tasks\_generic().@@ -327,7 +307,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } if (!rcu\_segcblist\_is\_enabled(&rtpcp->cblist)) {@@ -340,10 +320,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -414,8 +394,6 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) int needgpcb = 0;  for (cpu = 0; cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); cpu++) {- if (!cpu\_possible(cpu))- continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -448,7 +426,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -463,9 +441,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {- if (!cpu\_possible(cpu))- continue;+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -480,32 +456,30 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {+ int cpu;+ int cpunext; int cpuwq; unsigned long flags; int len;- int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - index = rtpcp->index \* 2 + 1;- if (index < num\_possible\_cpus()) {- rtpcp\_next = rtp->rtpcp\_array[index];- if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ cpu = rtpcp->cpu;+ cpunext = cpu \* 2 + 1;+ if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);+ cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ cpunext++;+ if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);+ cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- index++;- if (index < num\_possible\_cpus()) {- rtpcp\_next = rtp->rtpcp\_array[index];- if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- }- } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist))+ if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:24 +0000


