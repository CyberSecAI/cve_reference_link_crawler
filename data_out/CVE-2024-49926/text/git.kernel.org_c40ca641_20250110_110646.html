

| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=224fd631c41b81697aa622d38615bfbf446b91cf)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Zqiang <qiang.zhang1211@gmail.com> | 2024-07-10 12:45:42 +0800 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-12-14 19:53:56 +0100 |
| commit | [224fd631c41b81697aa622d38615bfbf446b91cf](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=224fd631c41b81697aa622d38615bfbf446b91cf) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=224fd631c41b81697aa622d38615bfbf446b91cf)) | |
| tree | [8c8dbf231eb2c200550f97abf04bf7993ce4711d](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=224fd631c41b81697aa622d38615bfbf446b91cf) | |
| parent | [db1d7e1794fed62ee16d6a72a85997bb069e2e27](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=db1d7e1794fed62ee16d6a72a85997bb069e2e27) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=224fd631c41b81697aa622d38615bfbf446b91cf&id2=db1d7e1794fed62ee16d6a72a85997bb069e2e27)) | |
| download | [linux-224fd631c41b81697aa622d38615bfbf446b91cf.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-224fd631c41b81697aa622d38615bfbf446b91cf.tar.gz) | |

rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 upstream.
For kernels built with CONFIG\_FORCE\_NR\_CPUS=y, the nr\_cpu\_ids is
defined as NR\_CPUS instead of the number of possible cpus, this
will cause the following system panic:
smpboot: Allowing 4 CPUs, 0 hotplug CPUs
...
setup\_percpu: NR\_CPUS:512 nr\_cpumask\_bits:512 nr\_cpu\_ids:512 nr\_node\_ids:1
...
BUG: unable to handle page fault for address: ffffffff9911c8c8
Oops: 0000 [#1] PREEMPT SMP PTI
CPU: 0 PID: 15 Comm: rcu\_tasks\_trace Tainted: G W
6.6.21 #1 5dc7acf91a5e8e9ac9dcfc35bee0245691283ea6
RIP: 0010:rcu\_tasks\_need\_gpcb+0x25d/0x2c0
RSP: 0018:ffffa371c00a3e60 EFLAGS: 00010082
CR2: ffffffff9911c8c8 CR3: 000000040fa20005 CR4: 00000000001706f0
Call Trace:
<TASK>
? \_\_die+0x23/0x80
? page\_fault\_oops+0xa4/0x180
? exc\_page\_fault+0x152/0x180
? asm\_exc\_page\_fault+0x26/0x40
? rcu\_tasks\_need\_gpcb+0x25d/0x2c0
? \_\_pfx\_rcu\_tasks\_kthread+0x40/0x40
rcu\_tasks\_one\_gp+0x69/0x180
rcu\_tasks\_kthread+0x94/0xc0
kthread+0xe8/0x140
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork+0x34/0x80
? \_\_pfx\_kthread+0x40/0x40
ret\_from\_fork\_asm+0x1b/0x80
</TASK>
Considering that there may be holes in the CPU numbers, use the
maximum possible cpu number, instead of nr\_cpu\_ids, for configuring
enqueue and dequeue limits.
[ neeraj.upadhyay: Fix htmldocs build error reported by Stephen Rothwell ]
Closes: https://lore.kernel.org/linux-input/CALMA0xaTSMN+p4xUXkzrtR5r6k7hgoswcaXx7baR\_z9r5jjskw@mail.gmail.com/T/#u
Reported-by: Zhixu Liu <zhixu.liu@gmail.com>
Signed-off-by: Zqiang <qiang.zhang1211@gmail.com>
Signed-off-by: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Xiangyu: BP to fix CVE:CVE-2024-49926, minor conflict resolution]
Signed-off-by: Xiangyu Chen <xiangyu.chen@windriver.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=224fd631c41b81697aa622d38615bfbf446b91cf)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=224fd631c41b81697aa622d38615bfbf446b91cf) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 54 insertions, 28 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex bb6b037ef30fa7..46b207eac171b7 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=db1d7e1794fed62ee16d6a72a85997bb069e2e27)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=224fd631c41b81697aa622d38615bfbf446b91cf)@@ -31,6 +31,7 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @barrier\_q\_head: RCU callback for barrier operation. \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @cpu: CPU number corresponding to this entry.+ \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -43,6 +44,7 @@ struct rcu\_tasks\_percpu { struct rcu\_head barrier\_q\_head; struct list\_head rtp\_blkd\_tasks; int cpu;+ int index; struct rcu\_tasks \*rtpp; }; @@ -68,6 +70,7 @@ struct rcu\_tasks\_percpu { \* @postgp\_func: This flavor's post-grace-period function (optional). \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.+ \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -100,6 +103,7 @@ struct rcu\_tasks { postgp\_func\_t postgp\_func; call\_rcu\_func\_t call\_func; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;+ struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -164,6 +168,8 @@ module\_param(rcu\_task\_contend\_lim, int, 0444); static int rcu\_task\_collapse\_lim \_\_read\_mostly = 10; module\_param(rcu\_task\_collapse\_lim, int, 0444); +static int rcu\_task\_cpu\_ids;+ /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -228,6 +234,8 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) unsigned long flags; int lim; int shift;+ int maxcpu;+ int index = 0;  raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rcu\_task\_enqueue\_lim < 0) {@@ -238,14 +246,9 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - if (lim > nr\_cpu\_ids)- lim = nr\_cpu\_ids;- shift = ilog2(nr\_cpu\_ids / lim);- if (((nr\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);+ rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);+ BUG\_ON(!rtp->rtpcp\_array);+ for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -258,16 +261,33 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;+ rtpcp->index = index;+ rtp->rtpcp\_array[index] = rtpcp;+ index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); raw\_spin\_unlock\_rcu\_node(rtpcp); // irqs remain disabled.+ maxcpu = cpu; } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);  if (rcu\_task\_cb\_adjust) pr\_info("%s: Setting adjustable number of callback queues.\n", \_\_func\_\_); - pr\_info("%s: Setting shift to %d and lim to %d.\n", \_\_func\_\_, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim));+ rcu\_task\_cpu\_ids = maxcpu + 1;+ if (lim > rcu\_task\_cpu\_ids)+ lim = rcu\_task\_cpu\_ids;+ shift = ilog2(rcu\_task\_cpu\_ids / lim);+ if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);++ pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",+ rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),+ rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids);+ }  // IRQ-work handler that does deferred wakeup for call\_rcu\_tasks\_generic().@@ -307,7 +327,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } if (!rcu\_segcblist\_is\_enabled(&rtpcp->cblist)) {@@ -320,10 +340,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -394,6 +414,8 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) int needgpcb = 0;  for (cpu = 0; cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -426,7 +448,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -441,7 +463,9 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) {+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {+ if (!cpu\_possible(cpu))+ continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -456,30 +480,32 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {- int cpu;- int cpunext; int cpuwq; unsigned long flags; int len;+ int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - cpu = rtpcp->cpu;- cpunext = cpu \* 2 + 1;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- cpunext++;- if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);- cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ index = rtpcp->index \* 2 + 1;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ index++;+ if (index < num\_possible\_cpus()) {+ rtpcp\_next = rtp->rtpcp\_array[index];+ if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ }+ } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu))+ if (rcu\_segcblist\_empty(&rtpcp->cblist)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:23 +0000

