

| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=acddb87620142f38fda834cd1ec661512ca59241)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=acddb87620142f38fda834cd1ec661512ca59241)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=acddb87620142f38fda834cd1ec661512ca59241)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=acddb87620142f38fda834cd1ec661512ca59241)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-12-30 15:47:08 +0100 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2025-01-02 10:30:55 +0100 |
| commit | [acddb87620142f38fda834cd1ec661512ca59241](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=acddb87620142f38fda834cd1ec661512ca59241) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=acddb87620142f38fda834cd1ec661512ca59241)) | |
| tree | [0931608e223bad17ae5ead9fd07e651c429ab3d1](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=acddb87620142f38fda834cd1ec661512ca59241) | |
| parent | [36775f42e039b01d4abe8998bf66771a37d3cdcc](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=36775f42e039b01d4abe8998bf66771a37d3cdcc) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=acddb87620142f38fda834cd1ec661512ca59241&id2=36775f42e039b01d4abe8998bf66771a37d3cdcc)) | |
| download | [linux-acddb87620142f38fda834cd1ec661512ca59241.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-acddb87620142f38fda834cd1ec661512ca59241.tar.gz) | |

Revert "rcu-tasks: Fix access non-existent percpu rtpcp variable in rcu\_tasks\_need\_gpcb()"This reverts commit 224fd631c41b81697aa622d38615bfbf446b91cf which is
commit fd70e9f1d85f5323096ad313ba73f5fe3d15ea41 upstream.
It is reported to cause problems in testing, so revert it for now.
Link: [https://lore.kernel.org/r/20241216-comic-handling-3bcf108cc465@wendy](https://lore.kernel.org/r/20241216-comic-handling-3bcf108cc465%40wendy)
Reported-by: Conor Dooley <conor.dooley@microchip.com>
CC: Zhixu Liu <zhixu.liu@gmail.com>
Cc: Zqiang <qiang.zhang1211@gmail.com>
Cc: Neeraj Upadhyay <neeraj.upadhyay@kernel.org>
Cc: Sasha Levin <sashal@kernel.org>
Cc: Xiangyu Chen <xiangyu.chen@windriver.com>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=acddb87620142f38fda834cd1ec661512ca59241)

| -rw-r--r-- | [kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/kernel/rcu/tasks.h?id=acddb87620142f38fda834cd1ec661512ca59241) | 82 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 28 insertions, 54 deletions

| diff --git a/kernel/rcu/tasks.h b/kernel/rcu/tasks.hindex 46b207eac171b7..bb6b037ef30fa7 100644--- a/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=36775f42e039b01d4abe8998bf66771a37d3cdcc)+++ b/[kernel/rcu/tasks.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/kernel/rcu/tasks.h?id=acddb87620142f38fda834cd1ec661512ca59241)@@ -31,7 +31,6 @@ typedef void (\*postgp\_func\_t)(struct rcu\_tasks \*rtp); \* @barrier\_q\_head: RCU callback for barrier operation. \* @rtp\_blkd\_tasks: List of tasks blocked as readers. \* @cpu: CPU number corresponding to this entry.- \* @index: Index of this CPU in rtpcp\_array of the rcu\_tasks structure. \* @rtpp: Pointer to the rcu\_tasks structure. \*/ struct rcu\_tasks\_percpu {@@ -44,7 +43,6 @@ struct rcu\_tasks\_percpu { struct rcu\_head barrier\_q\_head; struct list\_head rtp\_blkd\_tasks; int cpu;- int index; struct rcu\_tasks \*rtpp; }; @@ -70,7 +68,6 @@ struct rcu\_tasks\_percpu { \* @postgp\_func: This flavor's post-grace-period function (optional). \* @call\_func: This flavor's call\_rcu()-equivalent function. \* @rtpcpu: This flavor's rcu\_tasks\_percpu structure.- \* @rtpcp\_array: Array of pointers to rcu\_tasks\_percpu structure of CPUs in cpu\_possible\_mask. \* @percpu\_enqueue\_shift: Shift down CPU ID this much when enqueuing callbacks. \* @percpu\_enqueue\_lim: Number of per-CPU callback queues in use for enqueuing. \* @percpu\_dequeue\_lim: Number of per-CPU callback queues in use for dequeuing.@@ -103,7 +100,6 @@ struct rcu\_tasks { postgp\_func\_t postgp\_func; call\_rcu\_func\_t call\_func; struct rcu\_tasks\_percpu \_\_percpu \*rtpcpu;- struct rcu\_tasks\_percpu \*\*rtpcp\_array; int percpu\_enqueue\_shift; int percpu\_enqueue\_lim; int percpu\_dequeue\_lim;@@ -168,8 +164,6 @@ module\_param(rcu\_task\_contend\_lim, int, 0444); static int rcu\_task\_collapse\_lim \_\_read\_mostly = 10; module\_param(rcu\_task\_collapse\_lim, int, 0444); -static int rcu\_task\_cpu\_ids;- /\* RCU tasks grace-period state for debugging. \*/ #define RTGS\_INIT 0 #define RTGS\_WAIT\_WAIT\_CBS 1@@ -234,8 +228,6 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) unsigned long flags; int lim; int shift;- int maxcpu;- int index = 0;  raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rcu\_task\_enqueue\_lim < 0) {@@ -246,9 +238,14 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) } lim = rcu\_task\_enqueue\_lim; - rtp->rtpcp\_array = kcalloc(num\_possible\_cpus(), sizeof(struct rcu\_tasks\_percpu \*), GFP\_KERNEL);- BUG\_ON(!rtp->rtpcp\_array);-+ if (lim > nr\_cpu\_ids)+ lim = nr\_cpu\_ids;+ shift = ilog2(nr\_cpu\_ids / lim);+ if (((nr\_cpu\_ids - 1) >> shift) >= lim)+ shift++;+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim); for\_each\_possible\_cpu(cpu) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu); @@ -261,33 +258,16 @@ static void cblist\_init\_generic(struct rcu\_tasks \*rtp) INIT\_WORK(&rtpcp->rtp\_work, rcu\_tasks\_invoke\_cbs\_wq); rtpcp->cpu = cpu; rtpcp->rtpp = rtp;- rtpcp->index = index;- rtp->rtpcp\_array[index] = rtpcp;- index++; if (!rtpcp->rtp\_blkd\_tasks.next) INIT\_LIST\_HEAD(&rtpcp->rtp\_blkd\_tasks); raw\_spin\_unlock\_rcu\_node(rtpcp); // irqs remain disabled.- maxcpu = cpu; } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);  if (rcu\_task\_cb\_adjust) pr\_info("%s: Setting adjustable number of callback queues.\n", \_\_func\_\_); - rcu\_task\_cpu\_ids = maxcpu + 1;- if (lim > rcu\_task\_cpu\_ids)- lim = rcu\_task\_cpu\_ids;- shift = ilog2(rcu\_task\_cpu\_ids / lim);- if (((rcu\_task\_cpu\_ids - 1) >> shift) >= lim)- shift++;- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, shift);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, lim);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, lim);-- pr\_info("%s: Setting shift to %d and lim to %d rcu\_task\_cb\_adjust=%d rcu\_task\_cpu\_ids=%d.\n",- rtp->name, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim),- rcu\_task\_cb\_adjust, rcu\_task\_cpu\_ids);-+ pr\_info("%s: Setting shift to %d and lim to %d.\n", \_\_func\_\_, data\_race(rtp->percpu\_enqueue\_shift), data\_race(rtp->percpu\_enqueue\_lim)); }  // IRQ-work handler that does deferred wakeup for call\_rcu\_tasks\_generic().@@ -327,7 +307,7 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, rtpcp->rtp\_n\_lock\_retries = 0; } if (rcu\_task\_cb\_adjust && ++rtpcp->rtp\_n\_lock\_retries > rcu\_task\_contend\_lim &&- READ\_ONCE(rtp->percpu\_enqueue\_lim) != rcu\_task\_cpu\_ids)+ READ\_ONCE(rtp->percpu\_enqueue\_lim) != nr\_cpu\_ids) needadjust = true; // Defer adjustment to avoid deadlock. } if (!rcu\_segcblist\_is\_enabled(&rtpcp->cblist)) {@@ -340,10 +320,10 @@ static void call\_rcu\_tasks\_generic(struct rcu\_head \*rhp, rcu\_callback\_t func, raw\_spin\_unlock\_irqrestore\_rcu\_node(rtpcp, flags); if (unlikely(needadjust)) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags);- if (rtp->percpu\_enqueue\_lim != rcu\_task\_cpu\_ids) {+ if (rtp->percpu\_enqueue\_lim != nr\_cpu\_ids) { WRITE\_ONCE(rtp->percpu\_enqueue\_shift, 0);- WRITE\_ONCE(rtp->percpu\_dequeue\_lim, rcu\_task\_cpu\_ids);- smp\_store\_release(&rtp->percpu\_enqueue\_lim, rcu\_task\_cpu\_ids);+ WRITE\_ONCE(rtp->percpu\_dequeue\_lim, nr\_cpu\_ids);+ smp\_store\_release(&rtp->percpu\_enqueue\_lim, nr\_cpu\_ids); pr\_info("Switching %s to per-CPU callback queuing.\n", rtp->name); } raw\_spin\_unlock\_irqrestore(&rtp->cbs\_gbl\_lock, flags);@@ -414,8 +394,6 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) int needgpcb = 0;  for (cpu = 0; cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim); cpu++) {- if (!cpu\_possible(cpu))- continue; struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  /\* Advance and accelerate any new callbacks. \*/@@ -448,7 +426,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) if (rcu\_task\_cb\_adjust && ncbs <= rcu\_task\_collapse\_lim) { raw\_spin\_lock\_irqsave(&rtp->cbs\_gbl\_lock, flags); if (rtp->percpu\_enqueue\_lim > 1) {- WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(rcu\_task\_cpu\_ids));+ WRITE\_ONCE(rtp->percpu\_enqueue\_shift, order\_base\_2(nr\_cpu\_ids)); smp\_store\_release(&rtp->percpu\_enqueue\_lim, 1); rtp->percpu\_dequeue\_gpseq = get\_state\_synchronize\_rcu(); gpdone = false;@@ -463,9 +441,7 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) pr\_info("Completing switch %s to CPU-0 callback queuing.\n", rtp->name); } if (rtp->percpu\_dequeue\_lim == 1) {- for (cpu = rtp->percpu\_dequeue\_lim; cpu < rcu\_task\_cpu\_ids; cpu++) {- if (!cpu\_possible(cpu))- continue;+ for (cpu = rtp->percpu\_dequeue\_lim; cpu < nr\_cpu\_ids; cpu++) { struct rcu\_tasks\_percpu \*rtpcp = per\_cpu\_ptr(rtp->rtpcpu, cpu);  WARN\_ON\_ONCE(rcu\_segcblist\_n\_cbs(&rtpcp->cblist));@@ -480,32 +456,30 @@ static int rcu\_tasks\_need\_gpcb(struct rcu\_tasks \*rtp) // Advance callbacks and invoke any that are ready. static void rcu\_tasks\_invoke\_cbs(struct rcu\_tasks \*rtp, struct rcu\_tasks\_percpu \*rtpcp) {+ int cpu;+ int cpunext; int cpuwq; unsigned long flags; int len;- int index; struct rcu\_head \*rhp; struct rcu\_cblist rcl = RCU\_CBLIST\_INITIALIZER(rcl); struct rcu\_tasks\_percpu \*rtpcp\_next; - index = rtpcp->index \* 2 + 1;- if (index < num\_possible\_cpus()) {- rtpcp\_next = rtp->rtpcp\_array[index];- if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;+ cpu = rtpcp->cpu;+ cpunext = cpu \* 2 + 1;+ if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);+ cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND;+ queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);+ cpunext++;+ if (cpunext < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {+ rtpcp\_next = per\_cpu\_ptr(rtp->rtpcpu, cpunext);+ cpuwq = rcu\_cpu\_beenfullyonline(cpunext) ? cpunext : WORK\_CPU\_UNBOUND; queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- index++;- if (index < num\_possible\_cpus()) {- rtpcp\_next = rtp->rtpcp\_array[index];- if (rtpcp\_next->cpu < smp\_load\_acquire(&rtp->percpu\_dequeue\_lim)) {- cpuwq = rcu\_cpu\_beenfullyonline(rtpcp\_next->cpu) ? rtpcp\_next->cpu : WORK\_CPU\_UNBOUND;- queue\_work\_on(cpuwq, system\_wq, &rtpcp\_next->rtp\_work);- }- } } } - if (rcu\_segcblist\_empty(&rtpcp->cblist))+ if (rcu\_segcblist\_empty(&rtpcp->cblist) || !cpu\_possible(cpu)) return; raw\_spin\_lock\_irqsave\_rcu\_node(rtpcp, flags); rcu\_segcblist\_advance(&rtpcp->cblist, rcu\_seq\_current(&rtp->tasks\_gp\_seq)); |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 11:05:24 +0000

