

| [cgit logo](/) | [index](/) : [kernel/git/torvalds/linux.git](/pub/scm/linux/kernel/git/torvalds/linux.git/) | for-next master vsnprintf |
| --- | --- | --- |
| Linux kernel source tree | Linus Torvalds |

| [about](/pub/scm/linux/kernel/git/torvalds/linux.git/about/)[summary](/pub/scm/linux/kernel/git/torvalds/linux.git/)[refs](/pub/scm/linux/kernel/git/torvalds/linux.git/refs/?id=b043138246a41064527cf019a3d51d9f015e9796)[log](/pub/scm/linux/kernel/git/torvalds/linux.git/log/)[tree](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/?id=b043138246a41064527cf019a3d51d9f015e9796)[commit](/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=b043138246a41064527cf019a3d51d9f015e9796)[diff](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/?id=b043138246a41064527cf019a3d51d9f015e9796)[stats](/pub/scm/linux/kernel/git/torvalds/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Boris Ostrovsky <boris.ostrovsky@oracle.com> | 2019-12-05 03:45:32 +0000 |
| --- | --- | --- |
| committer | Paolo Bonzini <pbonzini@redhat.com> | 2020-01-30 18:45:55 +0100 |
| commit | [b043138246a41064527cf019a3d51d9f015e9796](/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=b043138246a41064527cf019a3d51d9f015e9796) ([patch](/pub/scm/linux/kernel/git/torvalds/linux.git/patch/?id=b043138246a41064527cf019a3d51d9f015e9796)) | |
| tree | [e702c1dec588a3c872d1c94e8e877176480b5846](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/?id=b043138246a41064527cf019a3d51d9f015e9796) | |
| parent | [917248144db5d7320655dbb41d3af0b8a0f3d589](/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=917248144db5d7320655dbb41d3af0b8a0f3d589) ([diff](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/?id=b043138246a41064527cf019a3d51d9f015e9796&id2=917248144db5d7320655dbb41d3af0b8a0f3d589)) | |
| download | [linux-b043138246a41064527cf019a3d51d9f015e9796.tar.gz](/pub/scm/linux/kernel/git/torvalds/linux.git/snapshot/linux-b043138246a41064527cf019a3d51d9f015e9796.tar.gz) | |

x86/KVM: Make sure KVM\_VCPU\_FLUSH\_TLB flag is not missedThere is a potential race in record\_steal\_time() between setting
host-local vcpu->arch.st.steal.preempted to zero (i.e. clearing
KVM\_VCPU\_PREEMPTED) and propagating this value to the guest with
kvm\_write\_guest\_cached(). Between those two events the guest may
still see KVM\_VCPU\_PREEMPTED in its copy of kvm\_steal\_time, set
KVM\_VCPU\_FLUSH\_TLB and assume that hypervisor will do the right
thing. Which it won't.
Instad of copying, we should map kvm\_steal\_time and that will
guarantee atomicity of accesses to @preempted.
This is part of CVE-2019-3016.
Signed-off-by: Boris Ostrovsky <boris.ostrovsky@oracle.com>
Reviewed-by: Joao Martins <joao.m.martins@oracle.com>
Cc: stable@vger.kernel.org
Signed-off-by: Paolo Bonzini <pbonzini@redhat.com>
[Diffstat](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/?id=b043138246a41064527cf019a3d51d9f015e9796)

| -rw-r--r-- | [arch/x86/kvm/x86.c](/pub/scm/linux/kernel/git/torvalds/linux.git/diff/arch/x86/kvm/x86.c?id=b043138246a41064527cf019a3d51d9f015e9796) | 51 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 30 insertions, 21 deletions

| diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.cindex 0795bc876abcca..f1845df7e7c324 100644--- a/[arch/x86/kvm/x86.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/x86/kvm/x86.c?id=917248144db5d7320655dbb41d3af0b8a0f3d589)+++ b/[arch/x86/kvm/x86.c](/pub/scm/linux/kernel/git/torvalds/linux.git/tree/arch/x86/kvm/x86.c?id=b043138246a41064527cf019a3d51d9f015e9796)@@ -2581,45 +2581,47 @@ static void kvm\_vcpu\_flush\_tlb(struct kvm\_vcpu \*vcpu, bool invalidate\_gpa)  static void record\_steal\_time(struct kvm\_vcpu \*vcpu) {+ struct kvm\_host\_map map;+ struct kvm\_steal\_time \*st;+ if (!(vcpu->arch.st.msr\_val & KVM\_MSR\_ENABLED)) return; - if (unlikely(kvm\_read\_guest\_cached(vcpu->kvm, &vcpu->arch.st.stime,- &vcpu->arch.st.steal, sizeof(struct kvm\_steal\_time))))+ /\* -EAGAIN is returned in atomic context so we can just return. \*/+ if (kvm\_map\_gfn(vcpu, vcpu->arch.st.msr\_val >> PAGE\_SHIFT,+ &map, &vcpu->arch.st.cache, false)) return; + st = map.hva ++ offset\_in\_page(vcpu->arch.st.msr\_val & KVM\_STEAL\_VALID\_BITS);+ /\* \* Doing a TLB flush here, on the guest's behalf, can avoid \* expensive IPIs. \*/ trace\_kvm\_pv\_tlb\_flush(vcpu->vcpu\_id,- vcpu->arch.st.steal.preempted & KVM\_VCPU\_FLUSH\_TLB);- if (xchg(&vcpu->arch.st.steal.preempted, 0) & KVM\_VCPU\_FLUSH\_TLB)+ st->preempted & KVM\_VCPU\_FLUSH\_TLB);+ if (xchg(&st->preempted, 0) & KVM\_VCPU\_FLUSH\_TLB) kvm\_vcpu\_flush\_tlb(vcpu, false); - if (vcpu->arch.st.steal.version & 1)- vcpu->arch.st.steal.version += 1; /\* first time write, random junk \*/+ vcpu->arch.st.steal.preempted = 0; - vcpu->arch.st.steal.version += 1;+ if (st->version & 1)+ st->version += 1; /\* first time write, random junk \*/ - kvm\_write\_guest\_cached(vcpu->kvm, &vcpu->arch.st.stime,- &vcpu->arch.st.steal, sizeof(struct kvm\_steal\_time));+ st->version += 1;  smp\_wmb(); - vcpu->arch.st.steal.steal += current->sched\_info.run\_delay -+ st->steal += current->sched\_info.run\_delay - vcpu->arch.st.last\_steal; vcpu->arch.st.last\_steal = current->sched\_info.run\_delay; - kvm\_write\_guest\_cached(vcpu->kvm, &vcpu->arch.st.stime,- &vcpu->arch.st.steal, sizeof(struct kvm\_steal\_time));- smp\_wmb(); - vcpu->arch.st.steal.version += 1;+ st->version += 1; - kvm\_write\_guest\_cached(vcpu->kvm, &vcpu->arch.st.stime,- &vcpu->arch.st.steal, sizeof(struct kvm\_steal\_time));+ kvm\_unmap\_gfn(vcpu, &map, &vcpu->arch.st.cache, true, false); }  int kvm\_set\_msr\_common(struct kvm\_vcpu \*vcpu, struct msr\_data \*msr\_info)@@ -3501,18 +3503,25 @@ void kvm\_arch\_vcpu\_load(struct kvm\_vcpu \*vcpu, int cpu)  static void kvm\_steal\_time\_set\_preempted(struct kvm\_vcpu \*vcpu) {+ struct kvm\_host\_map map;+ struct kvm\_steal\_time \*st;+ if (!(vcpu->arch.st.msr\_val & KVM\_MSR\_ENABLED)) return;  if (vcpu->arch.st.steal.preempted) return; - vcpu->arch.st.steal.preempted = KVM\_VCPU\_PREEMPTED;+ if (kvm\_map\_gfn(vcpu, vcpu->arch.st.msr\_val >> PAGE\_SHIFT, &map,+ &vcpu->arch.st.cache, true))+ return;++ st = map.hva ++ offset\_in\_page(vcpu->arch.st.msr\_val & KVM\_STEAL\_VALID\_BITS);++ st->preempted = vcpu->arch.st.steal.preempted = KVM\_VCPU\_PREEMPTED; - kvm\_write\_guest\_offset\_cached(vcpu->kvm, &vcpu->arch.st.stime,- &vcpu->arch.st.steal.preempted,- offsetof(struct kvm\_steal\_time, preempted),- sizeof(vcpu->arch.st.steal.preempted));+ kvm\_unmap\_gfn(vcpu, &map, &vcpu->arch.st.cache, true, true); }  void kvm\_arch\_vcpu\_put(struct kvm\_vcpu \*vcpu) |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-10 19:39:26 +0000

