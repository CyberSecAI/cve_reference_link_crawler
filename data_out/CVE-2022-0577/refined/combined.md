=== Content from lists.debian.org_390d74f8_20250108_113732.html ===


---

[[Date Prev](msg00020.html)][[Date Next](msg00022.html)]
[[Thread Prev](msg00020.html)][[Thread Next](msg00022.html)]
[[Date Index](maillist.html#00021)]
[[Thread Index](threads.html#00021)]

# [SECURITY] [DLA 2950-1] python-scrapy security update

---

* *To*: <debian-lts-announce@lists.debian.org>
* *Subject*: [SECURITY] [DLA 2950-1] python-scrapy security update
* *From*: Emilio Pozuelo Monfort <pochu@debian.org>
* *Date*: Wed, 16 Mar 2022 12:57:06 +0100 (CET)
* *Message-id*: <[[ðŸ”Ž]](/msgid-search/20220316115706.B3FBF2A6D3B%40andromeda)Â [20220316115706.B3FBF2A6D3B@andromeda](msg00021.html)>
* *Mail-followup-to*: debian-lts@lists.debian.org
* *Reply-to*: debian-lts@lists.debian.org

---

```
-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA256

- -------------------------------------------------------------------------
Debian LTS Advisory DLA-2950-1                debian-lts@lists.debian.org
<https://www.debian.org/lts/security/>               Emilio Pozuelo Monfort
March 16, 2022                                <https://wiki.debian.org/LTS>
- -------------------------------------------------------------------------

Package        : python-scrapy
Version        : 1.0.3-2+deb9u1
CVE ID         : CVE-2021-41125 CVE-2022-0577

It was found that Scrapy, a framework for extracting data from websites,
could send HTTP Authorization as well as cookies to other domains in case
of redirections, possibly leaking user credentials.

For Debian 9 stretch, these problems have been fixed in version
1.0.3-2+deb9u1.

We recommend that you upgrade your python-scrapy packages.

For the detailed security status of python-scrapy please refer to
its security tracker page at:
<https://security-tracker.debian.org/tracker/python-scrapy>

Further information about Debian LTS security advisories, how to apply
these updates to your system and frequently asked questions can be
found at: <https://wiki.debian.org/LTS>
-----BEGIN PGP SIGNATURE-----

iQIzBAEBCAAdFiEEcJymx+vmJZxd92Q+nUbEiOQ2gwIFAmIx0I8ACgkQnUbEiOQ2
gwKNvw/+MniywnqwPiX+P/pT2FQ9wzPEd/ECTGqOVw237jR+Iz9kWX3qecnTyQrx
VwoK5AYvjX0u5kDuw8mLD1iVP7JGWtF+HGnsSJEVlQhvPSMUsOp2kZoB4+lI5UyV
j7xZgl1uuRddjuc9o370nJIoWWep4DVrd64Ssa5eAeTspTeNC4Vmo0BIHIcE1Now
2jGJ+g/mk+KzqckY8GJyYujVLaTeYpcLC7QzaF1uw2N1qtT+i67m6BRJ+fJprO9s
pRerH5ltqXiQ5lTHOUNPTY4E/zxpUnwwvEaF9PLIWwpMGH0wGPDkQKkbrrC3njtq
E6v9QxptB/Wt/fbiITNbCTJ6xIhcef9FVfyqvlM7M8RtWrX/F/94hLVFXHGJDPnB
LTxmYKia9x6o7yZ3mg1DJbrpZgrYszhVIwZ/1h4kJYHrQQEp6PhH7ANFuvXoRdeX
29JOPoVc+T7NV5VD0XsGT7ShYwzG6NDFiLlui5aA8DdDY/62tEbjaxrZbW728wkw
a/TwFBOJVHz4Gm0xg14iiNrHAX0n0nQrzB9BbjLnX2EYEfPWokXg2tx3l6xih5F6
UMr8Coukzwt67ZUcnVAFvZTMqyT91tpwbYRJF981vY9pOtJR9VEOHiUPpRm2p52P
/8STCNQaTe1BbXQczQjibDTv86xgwXfit9Nf1cywaorij0tDQ1o=
=u+85
-----END PGP SIGNATURE-----

```

---



=== Content from huntr.dev_4513e87e_20250108_113731.html ===


* [![logo](/horizontal-logo-wh.svg)](/)
* [Bounties](/bounties)
* [Partners](/partners)
* Community
* Info
[SUBMIT REPORT](/bounties/disclose)

Supported byÂ [Protect AI](https://protectai.com/)Â and leading the way to [MLSecOps](https://mlsecops.com) and greater AI security.

Â© 2024

[Privacy Policy](/privacy)[Terms of Service](/terms)[Code of Conduct](/code-of-conduct)Cookie Preferences[Contact Us](/contact-us)

=== Content from github.com_9aa06426_20250108_113731.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F8ce01b3b76d4634f55067d6cfdf632ec70ba304a)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F8ce01b3b76d4634f55067d6cfdf632ec70ba304a)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=scrapy%2Fscrapy)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[scrapy](/scrapy)
/
**[scrapy](/scrapy/scrapy)**
Public

* [Notifications](/login?return_to=%2Fscrapy%2Fscrapy) You must be signed in to change notification settings
* [Fork
  10.6k](/login?return_to=%2Fscrapy%2Fscrapy)
* [Star
   53.7k](/login?return_to=%2Fscrapy%2Fscrapy)

* [Code](/scrapy/scrapy)
* [Issues
  432](/scrapy/scrapy/issues)
* [Pull requests
  192](/scrapy/scrapy/pulls)
* [Discussions](/scrapy/scrapy/discussions)
* [Actions](/scrapy/scrapy/actions)
* [Projects
  0](/scrapy/scrapy/projects)
* [Wiki](/scrapy/scrapy/wiki)
* [Security](/scrapy/scrapy/security)
* [Insights](/scrapy/scrapy/pulse)

Additional navigation options

* [Code](/scrapy/scrapy)
* [Issues](/scrapy/scrapy/issues)
* [Pull requests](/scrapy/scrapy/pulls)
* [Discussions](/scrapy/scrapy/discussions)
* [Actions](/scrapy/scrapy/actions)
* [Projects](/scrapy/scrapy/projects)
* [Wiki](/scrapy/scrapy/wiki)
* [Security](/scrapy/scrapy/security)
* [Insights](/scrapy/scrapy/pulse)

## Commit

[Permalink](/scrapy/scrapy/commit/8ce01b3b76d4634f55067d6cfdf632ec70ba304a)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Merge pull request from [GHSA-cjvr-mfj7-j4j8](https://github.com/advisories/GHSA-cjvr-mfj7-j4j8 "GHSA-cjvr-mfj7-j4j8")

[Browse files](/scrapy/scrapy/tree/8ce01b3b76d4634f55067d6cfdf632ec70ba304a)
Browse the repository at this point in the history

```
* Do not carry over cookies to a different domain on redirect

* Cover the cookie-domain redirect fix in the release notes

* Cover 1.8.2 in the release notes

* Fix redirect Cookie handling when the cookie middleware is disabled

* Update the 1.8.2 release date
```

* Loading branch information

[![@Gallaecio](https://avatars.githubusercontent.com/u/705211?s=40&v=4)](/Gallaecio)

[Gallaecio](/scrapy/scrapy/commits?author=Gallaecio "View all commits by Gallaecio")
authored
Mar 1, 2022

1 parent
[aa0306a](/scrapy/scrapy/commit/aa0306a167ef34b23cc2ec407a48359a4b5a8d0a)

commit 8ce01b3

 Show file tree

 Hide file tree

Showing
**3 changed files**
with
**247 additions**
and
**6 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* docs

  + docs/news.rst
    [news.rst](#diff-87f7a7bb7fe8dbed76e16b67b87f27bda7b779b56e7d93ed3350d77ee4a3f217)
* scrapy/downloadermiddlewares

  + scrapy/downloadermiddlewares/redirect.py
    [redirect.py](#diff-140b76d443a1ca400ecd54af67504d909400325c30a23fafb9d746c179ae1df7)
* tests

  + tests/test\_downloadermiddleware\_cookies.py
    [test\_downloadermiddleware\_cookies.py](#diff-f164012cc343604613ebd23b6112221cbf3d7ff67c7083c367dd7e7d0d3c01e3)

## There are no files selected for viewing

67 changes: 66 additions & 1 deletion

67
[docs/news.rst](#diff-87f7a7bb7fe8dbed76e16b67b87f27bda7b779b56e7d93ed3350d77ee4a3f217 "docs/news.rst")

Show comments

[View file](/scrapy/scrapy/blob/8ce01b3b76d4634f55067d6cfdf632ec70ba304a/docs/news.rst)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

| Expand Up | | @@ -5,11 +5,13 @@ Release notes |
|  |  |  |
|  |  | .. \_release-2.6.0: |
|  |  |  |
|  |  | Scrapy 2.6.0 (2022-02-??) |
|  |  | Scrapy 2.6.0 (2022-03-01) |
|  |  | ------------------------- |
|  |  |  |
|  |  | Highlights: |
|  |  |  |
|  |  | \* :ref:`Security fixes for cookie handling <2.6-security-fixes>` |
|  |  |  |
|  |  | \* Python 3.10 support |
|  |  |  |
|  |  | \* :ref:`asyncio support <using-asyncio>` is no longer considered |
| Expand All | | @@ -20,6 +22,37 @@ Highlights: |
|  |  | :ref:`item filtering <item-filter>` and |
|  |  | :ref:`post-processing <post-processing>` |
|  |  |  |
|  |  | .. \_2.6-security-fixes: |
|  |  |  |
|  |  | Security bug fixes |
|  |  | ~~~~~~~~~~~~~~~~~~ |
|  |  |  |
|  |  | - When a :class:`~scrapy.http.Request` object with cookies defined gets a |
|  |  | redirect response causing a new :class:`~scrapy.http.Request` object to be |
|  |  | scheduled, the cookies defined in the original |
|  |  | :class:`~scrapy.http.Request` object are no longer copied into the new |
|  |  | :class:`~scrapy.http.Request` object. |
|  |  |  |
|  |  | If you manually set the ``Cookie`` header on a |
|  |  | :class:`~scrapy.http.Request` object and the domain name of the redirect |
|  |  | URL is not an exact match for the domain of the URL of the original |
|  |  | :class:`~scrapy.http.Request` object, your ``Cookie`` header is now dropped |
|  |  | from the new :class:`~scrapy.http.Request` object. |
|  |  |  |
|  |  | The old behavior could be exploited by an attacker to gain access to your |
|  |  | cookies. Please, see the `cjvr-mfj7-j4j8 security advisory`\_ for more |
|  |  | information. |
|  |  |  |
|  |  | .. \_cjvr-mfj7-j4j8 security advisory: https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8 |
|  |  |  |
|  |  | .. note:: It is still possible to enable the sharing of cookies between |
|  |  | different domains with a shared domain suffix (e.g. |
|  |  | ``example.com`` and any subdomain) by defining the shared domain |
|  |  | suffix (e.g. ``example.com``) as the cookie domain when defining |
|  |  | your cookies. See the documentation of the |
|  |  | :class:`~scrapy.http.Request` class for more information. |
|  |  |  |
|  |  |  |
|  |  | Modified requirements |
|  |  | ~~~~~~~~~~~~~~~~~~~~~ |
|  |  |  |
| Expand Down  Expand Up | | @@ -1842,6 +1875,38 @@ affect subclasses: |
|  |  |  |
|  |  | (:issue:`3884`) |
|  |  |  |
|  |  | .. \_release-1.8.2: |
|  |  |  |
|  |  | Scrapy 1.8.2 (2022-03-01) |
|  |  | ------------------------- |
|  |  |  |
|  |  | \*\*Security bug fixes:\*\* |
|  |  |  |
|  |  | - When a :class:`~scrapy.http.Request` object with cookies defined gets a |
|  |  | redirect response causing a new :class:`~scrapy.http.Request` object to be |
|  |  | scheduled, the cookies defined in the original |
|  |  | :class:`~scrapy.http.Request` object are no longer copied into the new |
|  |  | :class:`~scrapy.http.Request` object. |
|  |  |  |
|  |  | If you manually set the ``Cookie`` header on a |
|  |  | :class:`~scrapy.http.Request` object and the domain name of the redirect |
|  |  | URL is not an exact match for the domain of the URL of the original |
|  |  | :class:`~scrapy.http.Request` object, your ``Cookie`` header is now dropped |
|  |  | from the new :class:`~scrapy.http.Request` object. |
|  |  |  |
|  |  | The old behavior could be exploited by an attacker to gain access to your |
|  |  | cookies. Please, see the `cjvr-mfj7-j4j8 security advisory`\_ for more |
|  |  | information. |
|  |  |  |
|  |  | .. \_cjvr-mfj7-j4j8 security advisory: https://github.com/scrapy/scrapy/security/advisories/GHSA-cjvr-mfj7-j4j8 |
|  |  |  |
|  |  | .. note:: It is still possible to enable the sharing of cookies between |
|  |  | different domains with a shared domain suffix (e.g. |
|  |  | ``example.com`` and any subdomain) by defining the shared domain |
|  |  | suffix (e.g. ``example.com``) as the cookie domain when defining |
|  |  | your cookies. See the documentation of the |
|  |  | :class:`~scrapy.http.Request` class for more information. |
|  |  |  |
|  |  |  |
|  |  | .. \_release-1.8.1: |
|  |  |  |
| Expand Down | |  |

31 changes: 26 additions & 5 deletions

31
[scrapy/downloadermiddlewares/redirect.py](#diff-140b76d443a1ca400ecd54af67504d909400325c30a23fafb9d746c179ae1df7 "scrapy/downloadermiddlewares/redirect.py")

Show comments

[View file](/scrapy/scrapy/blob/8ce01b3b76d4634f55067d6cfdf632ec70ba304a/scrapy/downloadermiddlewares/redirect.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -4,13 +4,29 @@ |
|  |  | from w3lib.url import safe\_url\_string |
|  |  |  |
|  |  | from scrapy.http import HtmlResponse |
|  |  | from scrapy.utils.httpobj import urlparse\_cached |
|  |  | from scrapy.utils.response import get\_meta\_refresh |
|  |  | from scrapy.exceptions import IgnoreRequest, NotConfigured |
|  |  |  |
|  |  |  |
|  |  | logger = logging.getLogger(\_\_name\_\_) |
|  |  |  |
|  |  |  |
|  |  | def \_build\_redirect\_request(source\_request, \*, url, method=None, body=None): |
|  |  | redirect\_request = source\_request.replace( |
|  |  | url=url, |
|  |  | method=method, |
|  |  | body=body, |
|  |  | cookies=None, |
|  |  | ) |
|  |  | if 'Cookie' in redirect\_request.headers: |
|  |  | source\_request\_netloc = urlparse\_cached(source\_request).netloc |
|  |  | redirect\_request\_netloc = urlparse\_cached(redirect\_request).netloc |
|  |  | if source\_request\_netloc != redirect\_request\_netloc: |
|  |  | del redirect\_request.headers['Cookie'] |
|  |  | return redirect\_request |
|  |  |  |
|  |  |  |
|  |  | class BaseRedirectMiddleware: |
|  |  |  |
|  |  | enabled\_setting = 'REDIRECT\_ENABLED' |
| Expand Down  Expand Up | | @@ -47,10 +63,15 @@ def \_redirect(self, redirected, request, spider, reason): |
|  |  | raise IgnoreRequest("max redirections reached") |
|  |  |  |
|  |  | def \_redirect\_request\_using\_get(self, request, redirect\_url): |
|  |  | redirected = request.replace(url=redirect\_url, method='GET', body='') |
|  |  | redirected.headers.pop('Content-Type', None) |
|  |  | redirected.headers.pop('Content-Length', None) |
|  |  | return redirected |
|  |  | redirect\_request = \_build\_redirect\_request( |
|  |  | request, |
|  |  | url=redirect\_url, |
|  |  | method='GET', |
|  |  | body='', |
|  |  | ) |
|  |  | redirect\_request.headers.pop('Content-Type', None) |
|  |  | redirect\_request.headers.pop('Content-Length', None) |
|  |  | return redirect\_request |
|  |  |  |
|  |  |  |
|  |  | class RedirectMiddleware(BaseRedirectMiddleware): |
| Expand Down  Expand Up | | @@ -80,7 +101,7 @@ def process\_response(self, request, response, spider): |
|  |  | redirected\_url = urljoin(request.url, location) |
|  |  |  |
|  |  | if response.status in (301, 307, 308) or request.method == 'HEAD': |
|  |  | redirected = request.replace(url=redirected\_url) |
|  |  | redirected = \_build\_redirect\_request(request, url=redirected\_url) |
|  |  | return self.\_redirect(redirected, request, spider, response.status) |
|  |  |  |
|  |  | redirected = self.\_redirect\_request\_using\_get(request, redirected\_url) |
| Expand Down | |  |

155 changes: 155 additions & 0 deletions

155
[tests/test\_downloadermiddleware\_cookies.py](#diff-f164012cc343604613ebd23b6112221cbf3d7ff67c7083c367dd7e7d0d3c01e3 "tests/test_downloadermiddleware_cookies.py")

Show comments

[View file](/scrapy/scrapy/blob/8ce01b3b76d4634f55067d6cfdf632ec70ba304a/tests/test_downloadermiddleware_cookies.py)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -6,8 +6,10 @@ |
|  |  |  |
|  |  | from scrapy.downloadermiddlewares.cookies import CookiesMiddleware |
|  |  | from scrapy.downloadermiddlewares.defaultheaders import DefaultHeadersMiddleware |
|  |  | from scrapy.downloadermiddlewares.redirect import RedirectMiddleware |
|  |  | from scrapy.exceptions import NotConfigured |
|  |  | from scrapy.http import Response, Request |
|  |  | from scrapy.settings import Settings |
|  |  | from scrapy.spiders import Spider |
|  |  | from scrapy.utils.python import to\_bytes |
|  |  | from scrapy.utils.test import get\_crawler |
| Expand All | | @@ -23,9 +25,11 @@ def split\_cookies(cookies): |
|  |  | def setUp(self): |
|  |  | self.spider = Spider('foo') |
|  |  | self.mw = CookiesMiddleware() |
|  |  | self.redirect\_middleware = RedirectMiddleware(settings=Settings()) |
|  |  |  |
|  |  | def tearDown(self): |
|  |  | del self.mw |
|  |  | del self.redirect\_middleware |
|  |  |  |
|  |  | def test\_basic(self): |
|  |  | req = Request('http://scrapytest.org/') |
| Expand Down  Expand Up | | @@ -368,3 +372,154 @@ def test\_primitive\_type\_cookies(self): |
|  |  | req4 = Request('http://example.org', cookies={'a': 'b'}) |
|  |  | assert self.mw.process\_request(req4, self.spider) is None |
|  |  | self.assertCookieValEqual(req4.headers['Cookie'], b'a=b') |
|  |  |  |
|  |  | def \_test\_cookie\_redirect( |
|  |  | self, |
|  |  | source, |
|  |  | target, |
|  |  | \*, |
|  |  | cookies1, |
|  |  | cookies2, |
|  |  | ): |
|  |  | input\_cookies = {'a': 'b'} |
|  |  |  |
|  |  | if not isinstance(source, dict): |
|  |  | source = {'url': source} |
|  |  | if not isinstance(target, dict): |
|  |  | target = {'url': target} |
|  |  | target.setdefault('status', 301) |
|  |  |  |
|  |  | request1 = Request(cookies=input\_cookies, \*\*source) |
|  |  | self.mw.process\_request(request1, self.spider) |
|  |  | cookies = request1.headers.get('Cookie') |
|  |  | self.assertEqual(cookies, b"a=b" if cookies1 else None) |
|  |  |  |
|  |  | response = Response( |
|  |  | headers={ |
|  |  | 'Location': target['url'], |
|  |  | }, |
|  |  | \*\*target, |
|  |  | ) |
|  |  | self.assertEqual( |
|  |  | self.mw.process\_response(request1, response, self.spider), |
|  |  | response, |
|  |  | ) |
|  |  |  |
|  |  | request2 = self.redirect\_middleware.process\_response( |
|  |  | request1, |
|  |  | response, |
|  |  | self.spider, |
|  |  | ) |
|  |  | self.assertIsInstance(request2, Request) |
|  |  |  |
|  |  | self.mw.process\_request(request2, self.spider) |
|  |  | cookies = request2.headers.get('Cookie') |
|  |  | self.assertEqual(cookies, b"a=b" if cookies2 else None) |
|  |  |  |
|  |  | def test\_cookie\_redirect\_same\_domain(self): |
|  |  | self.\_test\_cookie\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | 'https://toscrape.com', |
|  |  | cookies1=True, |
|  |  | cookies2=True, |
|  |  | ) |
|  |  |  |
|  |  | def test\_cookie\_redirect\_same\_domain\_forcing\_get(self): |
|  |  | self.\_test\_cookie\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | {'url': 'https://toscrape.com', 'status': 302}, |
|  |  | cookies1=True, |
|  |  | cookies2=True, |
|  |  | ) |
|  |  |  |
|  |  | def test\_cookie\_redirect\_different\_domain(self): |
|  |  | self.\_test\_cookie\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | 'https://example.com', |
|  |  | cookies1=True, |
|  |  | cookies2=False, |
|  |  | ) |
|  |  |  |
|  |  | def test\_cookie\_redirect\_different\_domain\_forcing\_get(self): |
|  |  | self.\_test\_cookie\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | {'url': 'https://example.com', 'status': 302}, |
|  |  | cookies1=True, |
|  |  | cookies2=False, |
|  |  | ) |
|  |  |  |
|  |  | def \_test\_cookie\_header\_redirect( |
|  |  | self, |
|  |  | source, |
|  |  | target, |
|  |  | \*, |
|  |  | cookies2, |
|  |  | ): |
|  |  | """Test the handling of a user-defined Cookie header when building a |
|  |  | redirect follow-up request. |
|  |  |  |
|  |  | We follow RFC 6265 for cookie handling. The Cookie header can only |
|  |  | contain a list of key-value pairs (i.e. no additional cookie |
|  |  | parameters like Domain or Path). Because of that, we follow the same |
|  |  | rules that we would follow for the handling of the Set-Cookie response |
|  |  | header when the Domain is not set: the cookies must be limited to the |
|  |  | target URL domain (not even subdomains can receive those cookies). |
|  |  |  |
|  |  | .. note:: This method tests the scenario where the cookie middleware is |
|  |  | disabled. Because of known issue #1992, when the cookies |
|  |  | middleware is enabled we do not need to be concerned about |
|  |  | the Cookie header getting leaked to unintended domains, |
|  |  | because the middleware empties the header from every request. |
|  |  | """ |
|  |  | if not isinstance(source, dict): |
|  |  | source = {'url': source} |
|  |  | if not isinstance(target, dict): |
|  |  | target = {'url': target} |
|  |  | target.setdefault('status', 301) |
|  |  |  |
|  |  | request1 = Request(headers={'Cookie': b'a=b'}, \*\*source) |
|  |  |  |
|  |  | response = Response( |
|  |  | headers={ |
|  |  | 'Location': target['url'], |
|  |  | }, |
|  |  | \*\*target, |
|  |  | ) |
|  |  |  |
|  |  | request2 = self.redirect\_middleware.process\_response( |
|  |  | request1, |
|  |  | response, |
|  |  | self.spider, |
|  |  | ) |
|  |  | self.assertIsInstance(request2, Request) |
|  |  |  |
|  |  | cookies = request2.headers.get('Cookie') |
|  |  | self.assertEqual(cookies, b"a=b" if cookies2 else None) |
|  |  |  |
|  |  | def test\_cookie\_header\_redirect\_same\_domain(self): |
|  |  | self.\_test\_cookie\_header\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | 'https://toscrape.com', |
|  |  | cookies2=True, |
|  |  | ) |
|  |  |  |
|  |  | def test\_cookie\_header\_redirect\_same\_domain\_forcing\_get(self): |
|  |  | self.\_test\_cookie\_header\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | {'url': 'https://toscrape.com', 'status': 302}, |
|  |  | cookies2=True, |
|  |  | ) |
|  |  |  |
|  |  | def test\_cookie\_header\_redirect\_different\_domain(self): |
|  |  | self.\_test\_cookie\_header\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | 'https://example.com', |
|  |  | cookies2=False, |
|  |  | ) |
|  |  |  |
|  |  | def test\_cookie\_header\_redirect\_different\_domain\_forcing\_get(self): |
|  |  | self.\_test\_cookie\_header\_redirect( |
|  |  | 'https://toscrape.com', |
|  |  | {'url': 'https://example.com', 'status': 302}, |
|  |  | cookies2=False, |
|  |  | ) |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `8ce01b3`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fscrapy%2Fscrapy%2Fcommit%2F8ce01b3b76d4634f55067d6cfdf632ec70ba304a) to comment.

## Footer

Â© 2025 GitHub,Â Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You canâ€™t perform that action at this time.


