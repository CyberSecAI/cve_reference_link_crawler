=== Content from access.redhat.com_c6c4f599_20250110_143643.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:1706 - Security Advisory

Issued:
2024-04-09
Updated:
2024-04-09
# RHSA-2024:1706 - Security Advisory

* [Overview](#overview)

## Synopsis

Important: Red Hat Build of Apache Camel 4.0 for Quarkus 3.2 is now available (updates to RHBQ 3.2.11)

## Type/Severity

Security Advisory: Important

## Topic

An update for Red Hat Build of Apache Camel 4.0 for Quarkus 3.2 is now available (updates to RHBQ 3.2.11).
Red Hat Product Security has rated this update as having a security impact of
Important.
The purpose of this text-only errata is to inform you about the enhancements that improve your developer experience and ensure the security and stability of your products

## Description

An update for Red Hat Build of Apache Camel 4.0 for Quarkus 3.2 is now available (updates to RHBQ 3.2.11).
The purpose of this text-only errata is to inform you about the enhancements that improve your developer experience and ensure the security and stability of your products:

* TRIAGE CVE-2024-25710 commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file
* TRIAGE CVE-2024-26308 commons-compress: OutOfMemoryError unpacking broken Pack200 file
* TRIAGE CVE-2024-1300 vertx-core: io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* TRIAGE CVE-2024-1023 vert.x: io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx

## Solution

Before applying the update, back up your existing installation, including all applications, configuration files, databases and database settings, and so on.
The References section of this erratum contains a download link (you must log in to download the update).

## Affected Products

* Red Hat Build of Apache Camel 1 x86\_64

## Fixes

(none)

## CVEs

* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-25710](https://access.redhat.com/security/cve/CVE-2024-25710)
* [CVE-2024-26308](https://access.redhat.com/security/cve/CVE-2024-26308)

## References

* <https://access.redhat.com/security/updates/classification/#important>
* <https://access/redhat/com/security/cve/CVE-2024-25710>
* <https://access/redhat/com/security/cve/CVE-2024-26308>
* <https://access/redhat/com/security/cve/CVE-2024-1300>
* <https://access/redhat/com/security/cve/CVE-2024-1023>

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from access.redhat.com_e45d1ad6_20250110_143644.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:3989 - Security Advisory

Issued:
2024-06-20
Updated:
2024-06-20
# RHSA-2024:3989 - Security Advisory

* [Overview](#overview)
* [Updated Images](#containers)

## Synopsis

Important: Migration Toolkit for Applications security and bug fix update

## Type/Severity

Security Advisory: Important

## Topic

Migration Toolkit for Applications 6.2.3 release

Red Hat Product Security has rated this update as having a security impact
of Important. A Common Vulnerability Scoring System (CVSS) base score, which
gives a detailed severity rating, is available for each vulnerability from
the CVE link(s) in the References section.

## Description

Migration Toolkit for Applications 6.2.3 Images

Security Fix(es) from Bugzilla:

* keycloak: path transversal in redirection validation (CVE-2024-1132)
* webpack-dev-middleware: lack of URL validation may lead to file leak (CVE-2024-29180)
* axios: exposure of confidential data stored in cookies (CVE-2023-45857)
* css-tools: Improper Input Validation causes Denial of Service via Regular Expression (CVE-2023-26364)
* css-tools: regular expression denial of service (ReDoS) when parsing CSS (CVE-2023-48631)
* follow-redirects: Improper Input Validation due to the improper handling of URLs by the url.parse() (CVE-2023-26159)
* io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx (CVE-2024-1023)
* io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support (CVE-2024-1300)
* commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file (CVE-2024-25710)
* commons-compress: OutOfMemoryError unpacking broken Pack200 file (CVE-2024-26308)
* follow-redirects: Possible credential leak (CVE-2024-28849)
* jetty: Improper addition of quotation marks to user inputs in CgiServlet (CVE-2023-36479)
* commons-configuration: StackOverflowError calling ListDelimiterHandler.flatten(Object, int) with a cyclical object tree (CVE-2024-29133)
* commons-configuration: StackOverflowError adding property in AbstractListDelimiterHandler.flattenIterator() (CVE-2024-29131)

## Solution

For details on how to apply this update, refer to:

<https://access.redhat.com/articles/11258>

## Affected Products

* Red Hat Migration Toolkit for Applications 1 x86\_64

## Fixes

* [BZ - 2239630](https://bugzilla.redhat.com/show_bug.cgi?id=2239630)
  - CVE-2023-36479 jetty: Improper addition of quotation marks to user inputs in CgiServlet
* [BZ - 2248979](https://bugzilla.redhat.com/show_bug.cgi?id=2248979)
  - CVE-2023-45857 axios: exposure of confidential data stored in cookies
* [BZ - 2250364](https://bugzilla.redhat.com/show_bug.cgi?id=2250364)
  - CVE-2023-26364 css-tools: Improper Input Validation causes Denial of Service via Regular Expression
* [BZ - 2254559](https://bugzilla.redhat.com/show_bug.cgi?id=2254559)
  - CVE-2023-48631 css-tools: regular expression denial of service (ReDoS) when parsing CSS
* [BZ - 2256413](https://bugzilla.redhat.com/show_bug.cgi?id=2256413)
  - CVE-2023-26159 follow-redirects: Improper Input Validation due to the improper handling of URLs by the url.parse()
* [BZ - 2260840](https://bugzilla.redhat.com/show_bug.cgi?id=2260840)
  - CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx
* [BZ - 2262117](https://bugzilla.redhat.com/show_bug.cgi?id=2262117)
  - CVE-2024-1132 keycloak: path transversal in redirection validation
* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2264988](https://bugzilla.redhat.com/show_bug.cgi?id=2264988)
  - CVE-2024-25710 commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file
* [BZ - 2264989](https://bugzilla.redhat.com/show_bug.cgi?id=2264989)
  - CVE-2024-26308 commons-compress: OutOfMemoryError unpacking broken Pack200 file
* [BZ - 2269576](https://bugzilla.redhat.com/show_bug.cgi?id=2269576)
  - CVE-2024-28849 follow-redirects: Possible credential leak
* [BZ - 2270673](https://bugzilla.redhat.com/show_bug.cgi?id=2270673)
  - CVE-2024-29133 commons-configuration: StackOverflowError calling ListDelimiterHandler.flatten(Object, int) with a cyclical object tree
* [BZ - 2270674](https://bugzilla.redhat.com/show_bug.cgi?id=2270674)
  - CVE-2024-29131 commons-configuration: StackOverflowError adding property in AbstractListDelimiterHandler.flattenIterator()
* [BZ - 2270863](https://bugzilla.redhat.com/show_bug.cgi?id=2270863)
  - CVE-2024-29180 webpack-dev-middleware: lack of URL validation may lead to file leak

## CVEs

* [CVE-2014-1745](https://access.redhat.com/security/cve/CVE-2014-1745)
* [CVE-2021-29390](https://access.redhat.com/security/cve/CVE-2021-29390)
* [CVE-2022-33065](https://access.redhat.com/security/cve/CVE-2022-33065)
* [CVE-2022-40090](https://access.redhat.com/security/cve/CVE-2022-40090)
* [CVE-2022-48554](https://access.redhat.com/security/cve/CVE-2022-48554)
* [CVE-2023-2975](https://access.redhat.com/security/cve/CVE-2023-2975)
* [CVE-2023-3446](https://access.redhat.com/security/cve/CVE-2023-3446)
* [CVE-2023-3618](https://access.redhat.com/security/cve/CVE-2023-3618)
* [CVE-2023-3817](https://access.redhat.com/security/cve/CVE-2023-3817)
* [CVE-2023-5678](https://access.redhat.com/security/cve/CVE-2023-5678)
* [CVE-2023-6129](https://access.redhat.com/security/cve/CVE-2023-6129)
* [CVE-2023-6228](https://access.redhat.com/security/cve/CVE-2023-6228)
* [CVE-2023-6237](https://access.redhat.com/security/cve/CVE-2023-6237)
* [CVE-2023-7008](https://access.redhat.com/security/cve/CVE-2023-7008)
* [CVE-2023-25193](https://access.redhat.com/security/cve/CVE-2023-25193)
* [CVE-2023-26159](https://access.redhat.com/security/cve/CVE-2023-26159)
* [CVE-2023-26364](https://access.redhat.com/security/cve/CVE-2023-26364)
* [CVE-2023-32359](https://access.redhat.com/security/cve/CVE-2023-32359)
* [CVE-2023-36479](https://access.redhat.com/security/cve/CVE-2023-36479)
* [CVE-2023-37328](https://access.redhat.com/security/cve/CVE-2023-37328)
* [CVE-2023-38469](https://access.redhat.com/security/cve/CVE-2023-38469)
* [CVE-2023-38470](https://access.redhat.com/security/cve/CVE-2023-38470)
* [CVE-2023-38471](https://access.redhat.com/security/cve/CVE-2023-38471)
* [CVE-2023-38472](https://access.redhat.com/security/cve/CVE-2023-38472)
* [CVE-2023-38473](https://access.redhat.com/security/cve/CVE-2023-38473)
* [CVE-2023-39928](https://access.redhat.com/security/cve/CVE-2023-39928)
* [CVE-2023-40414](https://access.redhat.com/security/cve/CVE-2023-40414)
* [CVE-2023-40745](https://access.redhat.com/security/cve/CVE-2023-40745)
* [CVE-2023-41175](https://access.redhat.com/security/cve/CVE-2023-41175)
* [CVE-2023-41983](https://access.redhat.com/security/cve/CVE-2023-41983)
* [CVE-2023-42852](https://access.redhat.com/security/cve/CVE-2023-42852)
* [CVE-2023-42883](https://access.redhat.com/security/cve/CVE-2023-42883)
* [CVE-2023-42890](https://access.redhat.com/security/cve/CVE-2023-42890)
* [CVE-2023-43785](https://access.redhat.com/security/cve/CVE-2023-43785)
* [CVE-2023-43786](https://access.redhat.com/security/cve/CVE-2023-43786)
* [CVE-2023-43787](https://access.redhat.com/security/cve/CVE-2023-43787)
* [CVE-2023-45857](https://access.redhat.com/security/cve/CVE-2023-45857)
* [CVE-2023-47038](https://access.redhat.com/security/cve/CVE-2023-47038)
* [CVE-2023-48631](https://access.redhat.com/security/cve/CVE-2023-48631)
* [CVE-2024-0727](https://access.redhat.com/security/cve/CVE-2024-0727)
* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1132](https://access.redhat.com/security/cve/CVE-2024-1132)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-2961](https://access.redhat.com/security/cve/CVE-2024-2961)
* [CVE-2024-21011](https://access.redhat.com/security/cve/CVE-2024-21011)
* [CVE-2024-21012](https://access.redhat.com/security/cve/CVE-2024-21012)
* [CVE-2024-21068](https://access.redhat.com/security/cve/CVE-2024-21068)
* [CVE-2024-21085](https://access.redhat.com/security/cve/CVE-2024-21085)
* [CVE-2024-21094](https://access.redhat.com/security/cve/CVE-2024-21094)
* [CVE-2024-22365](https://access.redhat.com/security/cve/CVE-2024-22365)
* [CVE-2024-23206](https://access.redhat.com/security/cve/CVE-2024-23206)
* [CVE-2024-23213](https://access.redhat.com/security/cve/CVE-2024-23213)
* [CVE-2024-25062](https://access.redhat.com/security/cve/CVE-2024-25062)
* [CVE-2024-25710](https://access.redhat.com/security/cve/CVE-2024-25710)
* [CVE-2024-26308](https://access.redhat.com/security/cve/CVE-2024-26308)
* [CVE-2024-28182](https://access.redhat.com/security/cve/CVE-2024-28182)
* [CVE-2024-28834](https://access.redhat.com/security/cve/CVE-2024-28834)
* [CVE-2024-28835](https://access.redhat.com/security/cve/CVE-2024-28835)
* [CVE-2024-28849](https://access.redhat.com/security/cve/CVE-2024-28849)
* [CVE-2024-29131](https://access.redhat.com/security/cve/CVE-2024-29131)
* [CVE-2024-29133](https://access.redhat.com/security/cve/CVE-2024-29133)
* [CVE-2024-29180](https://access.redhat.com/security/cve/CVE-2024-29180)
* [CVE-2024-32487](https://access.redhat.com/security/cve/CVE-2024-32487)
* [CVE-2024-33599](https://access.redhat.com/security/cve/CVE-2024-33599)
* [CVE-2024-33600](https://access.redhat.com/security/cve/CVE-2024-33600)
* [CVE-2024-33601](https://access.redhat.com/security/cve/CVE-2024-33601)
* [CVE-2024-33602](https://access.redhat.com/security/cve/CVE-2024-33602)

## References

* <https://access.redhat.com/security/updates/classification/#important>

## x86\_64

| mta/mta-hub-rhel9@sha256:325bec37f1ab499f8ae0abb38ca3929f66a0fe63b6ebdf60a1cdc3bbd79ad25e |
| --- |
| mta/mta-operator-bundle@sha256:a13643117c2867351718a872f7f1b2350c67855ca73a727a1dc140754ffe6589 |
| mta/mta-pathfinder-rhel9@sha256:851d4890717247af6aa9b0b6da9be95fe8aeb70183834e9de15a4302c487b9f0 |
| mta/mta-rhel8-operator@sha256:f588b869c3f273eb20c4c80a9aa5acd4a84c56c1dd85429a39a7d2d60f28d41e |
| mta/mta-ui-rhel9@sha256:0e0167affe099168142b9ebdce5520e972dea63ff6c7f3cda48e0bb4ae4cd0ec |
| mta/mta-windup-addon-rhel9@sha256:7884928eb3d01d4f9c8b5463ef9f6cec7d7df4d669e6d30cafe05af60202b003 |

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from access.redhat.com_1579a4ba_20250110_143645.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:4884 - Security Advisory

Issued:
2024-07-25
Updated:
2024-07-25
# RHSA-2024:4884 - Security Advisory

* [Overview](#overview)

## Synopsis

Important: Red Hat Build of Apache Camel 4.4.1 for Spring Boot security update.

## Type/Severity

Security Advisory: Important

## Topic

Red Hat build of Apache Camel 4.4.1 for Spring Boot release and security update is now available.

Red Hat Product Security has rated this update as having a security impact of Important. A Common Vulnerability Scoring System (CVSS) base score, which gives a detailed severity rating, is available for each vulnerability from the CVE link(s) in the References section.

## Description

Red Hat build of Apache Camel 4.4.1 for Spring Boot release and security update is now available.

The purpose of this text-only errata is to inform you about the security issues fixed.

Security Fix(es):

* undertow: response write hangs in case of Java 17 TLSv1.3 NewSessionTicket (CVE-2024-5971)
* pgjdbc: PostgreSQL JDBC Driver allows attacker to inject SQL if using PreferQueryMode=SIMPLE (CVE-2024-1597)
* vert.x: io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx (CVE-2024-1023)
* vertx-core: io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI supportd (CVE-2024-1300)
* undertow: url-encoded request path information can be broken on ajp-listener (CVE-2024-6162)
* jetty: stop accepting new connections from valid clients (CVE-2024-22201)
* threetenbp: null pointer exception (CVE-2024-23081)
* org.bouncycastle:bcprov-jdk18on: org.bouncycastle: Importing an EC certificate with crafted F2m parameters may lead to Denial of Service (CVE-2024-29857)
* org.bouncycastle-bcprov-jdk18on: bc-java: BouncyCastle vulnerable to a timing variant of Bleichenbacher (Marvin Attack) (CVE-2024-30171)
* org.bouncycastle:bcprov-jdk18on: Infinite loop in ED25519 verification in the ScalarUtil class (CVE-2024-30172)
* mvel: TimeOut error when calling ParseTools.subCompileExpression() function (CVE-2023-51079)

For more details about the security issue(s), including the impact, a CVSS score, acknowledgments, and other related information, refer to the CVE page(s) listed in the References section.

## Solution

Before applying this update, make sure all previously released errata
relevant to your system have been applied.

For details on how to apply this update, refer to:

<https://access.redhat.com/articles/11258>

## Affected Products

* Red Hat Integration - Camel for Spring Boot 1 x86\_64

## Fixes

* [BZ - 2256065](https://bugzilla.redhat.com/show_bug.cgi?id=2256065)
  - CVE-2023-51079 mvel: TimeOut error when calling ParseTools.subCompileExpression() function
* [BZ - 2260840](https://bugzilla.redhat.com/show_bug.cgi?id=2260840)
  - CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx
* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2266136](https://bugzilla.redhat.com/show_bug.cgi?id=2266136)
  - CVE-2024-22201 jetty: stop accepting new connections from valid clients
* [BZ - 2266523](https://bugzilla.redhat.com/show_bug.cgi?id=2266523)
  - CVE-2024-1597 pgjdbc: PostgreSQL JDBC Driver allows attacker to inject SQL if using PreferQueryMode=SIMPLE
* [BZ - 2274197](https://bugzilla.redhat.com/show_bug.cgi?id=2274197)
  - CVE-2024-23081 threetenbp: null pointer exception
* [BZ - 2276360](https://bugzilla.redhat.com/show_bug.cgi?id=2276360)
  - CVE-2024-30171 bc-java: BouncyCastle vulnerable to a timing variant of Bleichenbacher (Marvin Attack)
* [BZ - 2292211](https://bugzilla.redhat.com/show_bug.cgi?id=2292211)
  - CVE-2024-5971 undertow: response write hangs in case of Java 17 TLSv1.3 NewSessionTicket
* [BZ - 2293025](https://bugzilla.redhat.com/show_bug.cgi?id=2293025)
  - CVE-2024-30172 org.bouncycastle:bcprov-jdk18on: Infinite loop in ED25519 verification in the ScalarUtil class
* [BZ - 2293028](https://bugzilla.redhat.com/show_bug.cgi?id=2293028)
  - CVE-2024-29857 org.bouncycastle: Importing an EC certificate with crafted F2m parameters may lead to Denial of Service
* [BZ - 2293069](https://bugzilla.redhat.com/show_bug.cgi?id=2293069)
  - CVE-2024-6162 undertow: url-encoded request path information can be broken on ajp-listener

## CVEs

* [CVE-2023-51079](https://access.redhat.com/security/cve/CVE-2023-51079)
* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-1597](https://access.redhat.com/security/cve/CVE-2024-1597)
* [CVE-2024-5971](https://access.redhat.com/security/cve/CVE-2024-5971)
* [CVE-2024-6162](https://access.redhat.com/security/cve/CVE-2024-6162)
* [CVE-2024-22201](https://access.redhat.com/security/cve/CVE-2024-22201)
* [CVE-2024-23081](https://access.redhat.com/security/cve/CVE-2024-23081)
* [CVE-2024-29857](https://access.redhat.com/security/cve/CVE-2024-29857)
* [CVE-2024-30171](https://access.redhat.com/security/cve/CVE-2024-30171)
* [CVE-2024-30172](https://access.redhat.com/security/cve/CVE-2024-30172)

## References

* <https://access.redhat.com/security/updates/classification/#important>

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from access.redhat.com_9ec84157_20250110_143644.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:3527 - Security Advisory

Issued:
2024-05-30
Updated:
2024-05-30
# RHSA-2024:3527 - Security Advisory

* [Overview](#overview)

## Synopsis

Moderate: Red Hat AMQ Streams 2.7.0 release and security update

## Type/Severity

Security Advisory: Moderate

## Topic

Red Hat AMQ Streams 2.7.0 is now available from the Red Hat Customer Portal.

Red Hat Product Security has rated this update as having a security impact of Moderate. A Common Vulnerability Scoring System (CVSS) base score, which gives a detailed severity rating, is available for each vulnerability from the CVE link(s) in the References section.

## Description

Red Hat AMQ Streams, based on the Apache Kafka project, offers a distributed backbone that allows microservices and other applications to share data with extremely high throughput and extremely low latency.

This release of Red Hat AMQ Streams 2.7.0 serves as a replacement for Red Hat AMQ Streams 2.6.0, and includes security and bug fixes, and enhancements.

Security Fix(es):

* lz4: memory corruption due to an integer overflow bug caused by memmove argument (CVE-2021-3520)
* zstd: Race condition allows attacker to access world-readable destination file (CVE-2021-24032)
* RocksDB: zstd: mysql: buffer overrun in util.c (CVE-2022-4899)
* netty-codec-[http:](http://) Allocation of Resources Without Limits or Throttling (CVE-2024-29025)
* commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file (CVE-2024-25710)
* apache-commons-text: variable interpolation RCE (CVE-2022-42889)
* snappy-java: Missing upper bound check on chunk length in snappy-java can lead to Denial of Service (DoS) impact (CVE-2023-43642)
* json-smart: Uncontrolled Resource Consumption vulnerability in json-smart (Resource Exhaustion) (CVE-2023-1370)
* protobuf-java: timeout in parser leads to DoS (CVE-2022-3171)
* Apache-Commons-BCEL: arbitrary bytecode produced via out-of-bounds writing (CVE-2022-42920)
* bc-java: Out of memory while parsing ASN.1 crafted data in org.bouncycastle.openssl.PEMParser class (CVE-2023-33202)
* bouncycastle: potential blind LDAP injection attack using a self-signed certificate (CVE-2023-33201)
* json-path: stack-based buffer overflow in Criteria.parse method (CVE-2023-51074)
* guava: insecure temporary directory creation (CVE-2023-2976)
* io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support (CVE-2024-1300)
* io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx (CVE-2024-1023)
* quarkus-core: Leak of local configuration properties into Quarkus applications (CVE-2024-2700)

## Solution

Before applying this update, make sure all previously released errata
relevant to your system have been applied.

For details on how to apply this update, refer to:

<https://access.redhat.com/articles/11258>

## Affected Products

* Red Hat AMQ Streams 2 for RHEL 9 x86\_64
* Red Hat AMQ Streams 2 for RHEL 9 s390x
* Red Hat AMQ Streams 2 for RHEL 9 ppc64le
* Red Hat AMQ Streams 2 for RHEL 9 aarch64

## Fixes

* [BZ - 1928090](https://bugzilla.redhat.com/show_bug.cgi?id=1928090)
  - CVE-2021-24032 zstd: Race condition allows attacker to access world-readable destination file
* [BZ - 1954559](https://bugzilla.redhat.com/show_bug.cgi?id=1954559)
  - CVE-2021-3520 lz4: memory corruption due to an integer overflow bug caused by memmove argument
* [BZ - 2135435](https://bugzilla.redhat.com/show_bug.cgi?id=2135435)
  - CVE-2022-42889 apache-commons-text: variable interpolation RCE
* [BZ - 2137645](https://bugzilla.redhat.com/show_bug.cgi?id=2137645)
  - CVE-2022-3171 protobuf-java: timeout in parser leads to DoS
* [BZ - 2142707](https://bugzilla.redhat.com/show_bug.cgi?id=2142707)
  - CVE-2022-42920 Apache-Commons-BCEL: arbitrary bytecode produced via out-of-bounds writing
* [BZ - 2179864](https://bugzilla.redhat.com/show_bug.cgi?id=2179864)
  - CVE-2022-4899 zstd: mysql: buffer overrun in util.c
* [BZ - 2188542](https://bugzilla.redhat.com/show_bug.cgi?id=2188542)
  - CVE-2023-1370 json-smart: Uncontrolled Resource Consumption vulnerability in json-smart (Resource Exhaustion)
* [BZ - 2215229](https://bugzilla.redhat.com/show_bug.cgi?id=2215229)
  - CVE-2023-2976 guava: insecure temporary directory creation
* [BZ - 2215465](https://bugzilla.redhat.com/show_bug.cgi?id=2215465)
  - CVE-2023-33201 bouncycastle: potential blind LDAP injection attack using a self-signed certificate
* [BZ - 2241722](https://bugzilla.redhat.com/show_bug.cgi?id=2241722)
  - CVE-2023-43642 snappy-java: Missing upper bound check on chunk length in snappy-java can lead to Denial of Service (DoS) impact
* [BZ - 2251281](https://bugzilla.redhat.com/show_bug.cgi?id=2251281)
  - CVE-2023-33202 bc-java: Out of memory while parsing ASN.1 crafted data in org.bouncycastle.openssl.PEMParser class
* [BZ - 2256063](https://bugzilla.redhat.com/show_bug.cgi?id=2256063)
  - CVE-2023-51074 json-path: stack-based buffer overflow in Criteria.parse method
* [BZ - 2260840](https://bugzilla.redhat.com/show_bug.cgi?id=2260840)
  - CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx
* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2264988](https://bugzilla.redhat.com/show_bug.cgi?id=2264988)
  - CVE-2024-25710 commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file
* [BZ - 2272907](https://bugzilla.redhat.com/show_bug.cgi?id=2272907)
  - CVE-2024-29025 netty-codec-http: Allocation of Resources Without Limits or Throttling
* [BZ - 2273281](https://bugzilla.redhat.com/show_bug.cgi?id=2273281)
  - CVE-2024-2700 quarkus-core: Leak of local configuration properties into Quarkus applications
* [ENTMQST-5619](https://issues.redhat.com/browse/ENTMQST-5619)
  - [PROD] Create RHSA erratum for Streams 2.7.0
* [ENTMQST-5881](https://issues.redhat.com/browse/ENTMQST-5881)
  - CVE-2021-3520 a flaw in lz4
* [ENTMQST-5882](https://issues.redhat.com/browse/ENTMQST-5882)
  - CVE-2024-23944 Apache ZooKeeper: Information disclosure in persistent watcher handling
* [ENTMQST-5883](https://issues.redhat.com/browse/ENTMQST-5883)
  - CVE-2021-24032 flaw was found in zstd
* [ENTMQST-5884](https://issues.redhat.com/browse/ENTMQST-5884)
  - CVE-2022-4899 vulnerability was found in zstd v1.4.10
* [ENTMQST-5885](https://issues.redhat.com/browse/ENTMQST-5885)
  - CVE-2023-52428 Nimbus JOSE+JWT before 9.37.2
* [ENTMQST-5886](https://issues.redhat.com/browse/ENTMQST-5886)
  - CVE-2023-43642 flaw was found in SnappyInputStream in snappy-java

## CVEs

* [CVE-2021-3520](https://access.redhat.com/security/cve/CVE-2021-3520)
* [CVE-2021-24032](https://access.redhat.com/security/cve/CVE-2021-24032)
* [CVE-2022-3171](https://access.redhat.com/security/cve/CVE-2022-3171)
* [CVE-2022-4899](https://access.redhat.com/security/cve/CVE-2022-4899)
* [CVE-2022-42889](https://access.redhat.com/security/cve/CVE-2022-42889)
* [CVE-2022-42920](https://access.redhat.com/security/cve/CVE-2022-42920)
* [CVE-2023-1370](https://access.redhat.com/security/cve/CVE-2023-1370)
* [CVE-2023-2976](https://access.redhat.com/security/cve/CVE-2023-2976)
* [CVE-2023-33201](https://access.redhat.com/security/cve/CVE-2023-33201)
* [CVE-2023-33202](https://access.redhat.com/security/cve/CVE-2023-33202)
* [CVE-2023-43642](https://access.redhat.com/security/cve/CVE-2023-43642)
* [CVE-2023-51074](https://access.redhat.com/security/cve/CVE-2023-51074)
* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-2700](https://access.redhat.com/security/cve/CVE-2024-2700)
* [CVE-2024-25710](https://access.redhat.com/security/cve/CVE-2024-25710)
* [CVE-2024-29025](https://access.redhat.com/security/cve/CVE-2024-29025)

## References

* <https://access.redhat.com/security/updates/classification/#moderate>

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from access.redhat.com_ebba1ddb_20250110_143644.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:2833 - Security Advisory

Issued:
2024-05-14
Updated:
2024-05-14
# RHSA-2024:2833 - Security Advisory

* [Overview](#overview)

## Synopsis

Moderate: Service Registry (container images) release and security update [2.5.11 GA]

## Type/Severity

Security Advisory: Moderate

## Topic

An update to the images for Red Hat Integration - Service Registry is now available from the Red Hat Container Catalog. The purpose of this text-only errata is to inform you about the security issues fixed in this release.

Red Hat Product Security has rated this update as having a security impact of Moderate. A Common Vulnerability Scoring System (CVSS) base score, which gives a detailed severity rating, is available for each vulnerability from the CVE link(s) in the References section.

## Description

This release of Red Hat Integration - Service Registry 2.5.11 GA includes the following security fixes.

Security Fix(es):

* commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file [rhint-serv-2] (CVE-2024-25710)
* vert.x: io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx [rhint-serv-2] (CVE-2024-1023)
* vertx-core: io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support [rhint-serv-2] (CVE-2024-1300)
* commons-compress: OutOfMemoryError unpacking broken Pack200 file [rhint-serv-2] (CVE-2024-26308)
* netty-codec-[http:](http://) Allocation of Resources Without Limits or Throttling [rhint-serv-2] (CVE-2024-29025)

For more details about the security issue(s), including the impact, a CVSS score, acknowledgments, and other related information, refer to the CVE page(s) listed in the References section.

## Solution

Before applying this update, make sure all previously released errata
relevant to your system have been applied.

For details on how to apply this update, refer to:

<https://access.redhat.com/articles/11258>

## Affected Products

* Red Hat Integration - Service Registry 1 x86\_64

## Fixes

* [BZ - 2260840](https://bugzilla.redhat.com/show_bug.cgi?id=2260840)
  - CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx
* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2264988](https://bugzilla.redhat.com/show_bug.cgi?id=2264988)
  - CVE-2024-25710 commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file
* [BZ - 2264989](https://bugzilla.redhat.com/show_bug.cgi?id=2264989)
  - CVE-2024-26308 commons-compress: OutOfMemoryError unpacking broken Pack200 file
* [BZ - 2272907](https://bugzilla.redhat.com/show_bug.cgi?id=2272907)
  - CVE-2024-29025 netty-codec-http: Allocation of Resources Without Limits or Throttling

## CVEs

* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-25710](https://access.redhat.com/security/cve/CVE-2024-25710)
* [CVE-2024-26308](https://access.redhat.com/security/cve/CVE-2024-26308)
* [CVE-2024-29025](https://access.redhat.com/security/cve/CVE-2024-29025)

## References

* <https://access.redhat.com/security/updates/classification/#moderate>
* <https://access.redhat.com/documentation/en-us/red_hat_build_of_apicurio_registry/2.5>

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from access.redhat.com_0519b299_20250110_143645.html ===


[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

**We're sorry but cve-details doesn't work properly without JavaScript enabled. Please enable it to continue.**

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from access.redhat.com_d7053a80_20250110_143644.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:1923 - Security Advisory

Issued:
2024-04-18
Updated:
2024-04-18
# RHSA-2024:1923 - Security Advisory

* [Overview](#overview)
* [Updated Images](#containers)

## Synopsis

Moderate: Migration Toolkit for Runtimes security, bug fix and enhancement update

## Type/Severity

Security Advisory: Moderate

## Topic

Migration Toolkit for Runtimes 1.2.5 release

Red Hat Product Security has rated this update as having a security impact of
Moderate. A Common Vulnerability Scoring System (CVSS) base score, which gives a
detailed severity rating, is available for each vulnerability from the CVE
link(s) in the References section.

## Description

Migration Toolkit for Runtimes 1.2.5 Images

Security Fix(es):

* vertx-core: memory leak when a TCP server is configured with TLS and SNI support (CVE-2024-1300)
* commons-compress: OutOfMemoryError unpacking broken Pack200 file (CVE-2024-26308)

For more details about the security issue(s), including the impact, a CVSS
score, acknowledgments, and other related information, refer to the CVE page(s)
listed in the References section.

## Solution

Install the latest version of the Migration Toolkit for Runtimes from the Red Hat catalog in the OperatorHub page within your OpenShift instance.

## Affected Products

* Red Hat Migration Toolkit for Runtimes Advisory Metadata x86\_64

## Fixes

* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2264989](https://bugzilla.redhat.com/show_bug.cgi?id=2264989)
  - CVE-2024-26308 commons-compress: OutOfMemoryError unpacking broken Pack200 file
* [WINDUPRULE-1043](https://issues.redhat.com/browse/WINDUPRULE-1043)
  - EAP XP5 App Migration Issue: MP Metrics Replaced

## CVEs

* [CVE-2021-3468](https://access.redhat.com/security/cve/CVE-2021-3468)
* [CVE-2021-35937](https://access.redhat.com/security/cve/CVE-2021-35937)
* [CVE-2021-35938](https://access.redhat.com/security/cve/CVE-2021-35938)
* [CVE-2021-35939](https://access.redhat.com/security/cve/CVE-2021-35939)
* [CVE-2021-43618](https://access.redhat.com/security/cve/CVE-2021-43618)
* [CVE-2022-44638](https://access.redhat.com/security/cve/CVE-2022-44638)
* [CVE-2023-3446](https://access.redhat.com/security/cve/CVE-2023-3446)
* [CVE-2023-3817](https://access.redhat.com/security/cve/CVE-2023-3817)
* [CVE-2023-5678](https://access.redhat.com/security/cve/CVE-2023-5678)
* [CVE-2023-6135](https://access.redhat.com/security/cve/CVE-2023-6135)
* [CVE-2023-7104](https://access.redhat.com/security/cve/CVE-2023-7104)
* [CVE-2023-27043](https://access.redhat.com/security/cve/CVE-2023-27043)
* [CVE-2023-28322](https://access.redhat.com/security/cve/CVE-2023-28322)
* [CVE-2023-38469](https://access.redhat.com/security/cve/CVE-2023-38469)
* [CVE-2023-38470](https://access.redhat.com/security/cve/CVE-2023-38470)
* [CVE-2023-38471](https://access.redhat.com/security/cve/CVE-2023-38471)
* [CVE-2023-38472](https://access.redhat.com/security/cve/CVE-2023-38472)
* [CVE-2023-38473](https://access.redhat.com/security/cve/CVE-2023-38473)
* [CVE-2023-38546](https://access.redhat.com/security/cve/CVE-2023-38546)
* [CVE-2023-39615](https://access.redhat.com/security/cve/CVE-2023-39615)
* [CVE-2023-43804](https://access.redhat.com/security/cve/CVE-2023-43804)
* [CVE-2023-45803](https://access.redhat.com/security/cve/CVE-2023-45803)
* [CVE-2023-46218](https://access.redhat.com/security/cve/CVE-2023-46218)
* [CVE-2023-48795](https://access.redhat.com/security/cve/CVE-2023-48795)
* [CVE-2024-0553](https://access.redhat.com/security/cve/CVE-2024-0553)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-20918](https://access.redhat.com/security/cve/CVE-2024-20918)
* [CVE-2024-20919](https://access.redhat.com/security/cve/CVE-2024-20919)
* [CVE-2024-20921](https://access.redhat.com/security/cve/CVE-2024-20921)
* [CVE-2024-20926](https://access.redhat.com/security/cve/CVE-2024-20926)
* [CVE-2024-20945](https://access.redhat.com/security/cve/CVE-2024-20945)
* [CVE-2024-20952](https://access.redhat.com/security/cve/CVE-2024-20952)
* [CVE-2024-26308](https://access.redhat.com/security/cve/CVE-2024-26308)

## References

* <https://access.redhat.com/security/updates/classification/#moderate>

## aarch64

| mtr/mtr-operator-bundle@sha256:8f983034ba9454f79cc57f7a2d85dc50222638f576b454a1c8e9cd557665aaf3 |
| --- |
| mtr/mtr-rhel8-operator@sha256:3f19f1908b9e44ecebebe2c2fcd30f17632f2807275da0b766aeff9f44b88152 |
| mtr/mtr-web-executor-container-rhel8@sha256:b604d2e9dd393d52ba64cb39eec10cfab62d60a0b142df967de57734c87ff310 |

## ppc64le

| mtr/mtr-operator-bundle@sha256:da17b288e5503ff99d747b07062368879799b661e4a7a6354c7162da7427ea7c |
| --- |
| mtr/mtr-rhel8-operator@sha256:5e7df9c2c211b4a3230638efc87735fc702b01d42737eff48128150f02a6f204 |
| mtr/mtr-web-container-rhel8@sha256:86c57b36f6224c54305f7833c1452b9d3fe276f09b295978f8e95bc258593599 |
| mtr/mtr-web-executor-container-rhel8@sha256:f9607ef871579e739205639e31d22aad24dd777f0ae0959e9cf3a064d3d27ead |

## s390x

| mtr/mtr-operator-bundle@sha256:d12e0dacb99d6efa4cce47fe89f27eb6ebb3c64308d5b742d81b55fced08f63b |
| --- |
| mtr/mtr-rhel8-operator@sha256:92b03b5cccbdbf5394b4ea7a8521395d1b7fdcb1de4569dafe646f00c1c10d4c |
| mtr/mtr-web-container-rhel8@sha256:9052080bb46a5009e1497a198618b76311c6eefd386810da38d5d04ea05606c4 |
| mtr/mtr-web-executor-container-rhel8@sha256:1b09f65401896e35e4ad5bc4979baafb0600f83630ee97173033195f030271db |

## x86\_64

| mtr/mtr-operator-bundle@sha256:6818c3c795716c2cdb80050e705be0198aed6fef11d63fd28eeb8c21bf5fcb25 |
| --- |
| mtr/mtr-rhel8-operator@sha256:a3d0772c5ebda63371edf4f53b78f053bd9035498304e9f2091a0b76c6c26153 |
| mtr/mtr-web-container-rhel8@sha256:6eb6177323899560f965b9b142335be8577bcd1330d86185545d25dfa97796ca |
| mtr/mtr-web-executor-container-rhel8@sha256:b1076f9d028b653ff74926f09abb291395a0eb5d13c7e1522bc199fed9f68646 |

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from vertx.io_c62fb887_20250110_143648.html ===
[![Logo](data:image/svg+xml...)![Logo](data:image/svg+xml...)](/)[Docs](/docs/)[Resources](/resources/)[Blog](/blog/)[Community](/community/)4.5.115.0.0.CR34.5.114.4.94.3.84.2.74.1.84.0.33.9.16Search docs ...Core modulesVert.x Core

* [Documentation](/docs/)
* [How-tos](/docs/howtos/http-client-howto/)
* [Guides](/docs/guides/vertx-5-migration-guide/)

* Introduction
  + [Get started](/docs/)
  + [Intro to reactive](/docs/intro-to-reactive/)
  + [FAQ](/docs/faq/)
  + [App generator](https://start.vertx.io/)
* Core modules
  + [Vert.x Core](/docs/vertx-core/java/)
  + [Vert.x io\_uringIncubator](/docs/vertx-io_uring-incubator/java/)
* Web modules
  + [Vert.x Web](/docs/vertx-web/java/)
  + [Web Client](/docs/vertx-web-client/java/)
  + [Web Validation](/docs/vertx-web-validation/java/)
  + [Web API ServicePreview](/docs/vertx-web-api-service/java/)
  + [Web ProxyPreview](/docs/vertx-web-proxy/java/)
  + [GraphQL](/docs/vertx-web-graphql/java/)
* Clustering
  + [Hazelcast](/docs/vertx-hazelcast/java/)
  + [Infinispan](/docs/vertx-infinispan/java/)
  + [Apache Ignite](/docs/vertx-ignite/java/)
  + [Apache Zookeeper](/docs/vertx-zookeeper/java/)
* Testing
  + [JUnit 5](/docs/vertx-junit5/java/)
  + [Vert.x Unit](/docs/vertx-unit/java/)
* Standards
  + [JSON SchemaPreview](/docs/vertx-json-schema/java/)
  + [URI template](/docs/vertx-uri-template/java/)
  + [OpenAPIPreview](/docs/vertx-openapi/java/)
  + [Web OpenAPI RouterPreview](/docs/vertx-web-openapi-router/java/)
* Kotlin
  + [Vert.x for Kotlin](/docs/vertx-core/kotlin/)
  + [Kotlin coroutines](/docs/vertx-lang-kotlin-coroutines/kotlin/)
* Groovy
  + [Vert.x for Groovy](/docs/vertx-core/groovy/)
* Authentication and authorization
  + [Auth common](/docs/vertx-auth-common/java/)
  + [Oauth2](/docs/vertx-auth-oauth2/java/)
  + [JWT](/docs/vertx-auth-jwt/java/)
  + [OTP](/docs/vertx-auth-otp/java/)
  + [Webauthn](/docs/vertx-auth-webauthn/java/)
  + [SQL Client Auth](/docs/vertx-auth-sql-client/java/)
  + [MongoDB Auth](/docs/vertx-auth-mongo/java/)
  + [Properties Auth](/docs/vertx-auth-properties/java/)
  + [LDAP](/docs/vertx-auth-ldap/java/)
  + [.htpasswd](/docs/vertx-auth-htpasswd/java/)
  + [.htdigest](/docs/vertx-auth-htdigest/java/)
* Databases
  + [PostgreSQL](/docs/vertx-pg-client/java/)
  + [MySQL](/docs/vertx-mysql-client/java/)
  + [DB2](/docs/vertx-db2-client/java/)
  + [Oracle](/docs/vertx-oracle-client/java/)
  + [MSSQL](/docs/vertx-mssql-client/java/)
  + [SQL Client Templates](/docs/vertx-sql-client-templates/java/)
  + [MongoDB](/docs/vertx-mongo-client/java/)
  + [Redis](/docs/vertx-redis-client/java/)
  + [Cassandra](/docs/vertx-cassandra-client/java/)
  + [JDBC](/docs/vertx-jdbc-client/java/)
* Messaging
  + [Kafka](/docs/vertx-kafka-client/java/)
  + [AMQP](/docs/vertx-amqp-client/java/)
  + [RabbitMQ](/docs/vertx-rabbitmq-client/java/)
  + [MQTT](/docs/vertx-mqtt/java/)
* Integration
  + [Http ProxyPreview](/docs/vertx-http-proxy/java/)
  + [Mail Client](/docs/vertx-mail-client/java/)
  + [STOMP](/docs/vertx-stomp/java/)
  + [Consul client](/docs/vertx-consul-client/java/)
* Event bus bridges
  + [TCP Eventbus Bridge](/docs/vertx-tcp-eventbus-bridge/java/)
  + [Camel Bridge](/docs/vertx-camel-bridge/java/)
* Monitoring
  + [Zipkin](/docs/vertx-zipkin/java/)
  + [OpenTelemetry](/docs/vertx-opentelemetry/java/)
  + [OpenTracing](/docs/vertx-opentracing/java/)
  + [Metrics using Dropwizard](/docs/vertx-dropwizard-metrics/java/)
  + [Metrics using Micrometer](/docs/vertx-micrometer-metrics/java/)
  + [Health Check](/docs/vertx-health-check/java/)
* Services
  + [Service Proxies](/docs/vertx-service-proxy/java/)
  + [SockJS Service Proxies](/docs/vertx-sockjs-service-proxy/java/)
  + [gRPCPreview](/docs/vertx-grpc/java/)
  + [gRPC Netty](/docs/vertx-grpc-netty/java/)
* Reactive
  + [RxJava 3](/docs/vertx-rx/java3/)
  + [RxJava 2](/docs/vertx-rx/java2/)
  + [RxJava 1](/docs/vertx-rx/java/)
  + [Reactive Streams](/docs/vertx-reactive-streams/java/)
  + [Mutiny](https://smallrye.io/smallrye-mutiny)
* Microservices
  + [Service Discovery](/docs/vertx-service-discovery/java/)
  + [Config](/docs/vertx-config/java/)
  + [Circuit Breaker](/docs/vertx-circuit-breaker/java/)
* DevOps
  + [Shell](/docs/vertx-shell/java/)
Core modules[Examples](https://github.com/vert-x3/vertx-examples/tree/4.x/core-examples)[API docs](/docs/apidocs/)
# Vert.x Core Manual

At the heart of Vert.x is a set of Java APIs that we call **Vert.x Core**

[Repository](https://github.com/eclipse/vert.x).

Vert.x core provides functionality for things like:

* Writing TCP clients and servers
* Writing HTTP clients and servers including support for WebSockets
* The Event bus
* Shared data - local maps and clustered distributed maps
* Periodic and delayed actions
* Deploying and undeploying Verticles
* Datagram Sockets
* DNS client
* File system access
* Virtual threads
* High availability
* Native transports
* Clustering

The functionality in core is fairly low level - you won’t find stuff like database access, authorisation or high level web functionality here - that kind of stuff you’ll find in **Vert.x ext** (extensions).

Vert.x core is small and lightweight. You just use the parts you want. It’s also entirely embeddable in your existing applications - we don’t force you to structure your applications in a special way just so you can use Vert.x.

You can use core from any of the other languages that Vert.x supports. But here’s a cool bit - we don’t force you to use the Java API directly from, say, JavaScript or Ruby - after all, different languages have different conventions and idioms, and it would be odd to force Java idioms on Ruby developers (for example). Instead, we automatically generate an **idiomatic** equivalent of the core Java APIs for each language.

From now on we’ll just use the word **core** to refer to Vert.x core.

If you are using Maven or Gradle, add the following dependency to the *dependencies* section of your project descriptor to access the Vert.x Core API:

* Maven (in your `pom.xml`):

```
<dependency>
 <groupId>io.vertx</groupId>
 <artifactId>vertx-core</artifactId>
 <version>4.5.11</version>
</dependency>
```

* Gradle (in your `build.gradle` file):

```
dependencies {
 compile 'io.vertx:vertx-core:4.5.11'
}
```

Let’s discuss the different concepts and features in core.

## [In the beginning there was Vert.x](#_in_the_beginning_there_was_vert_x)

You can’t do much in Vert.x-land unless you can communicate with a `[Vertx](../../apidocs/io/vertx/core/Vertx.html)` object!

It’s the control centre of Vert.x and is how you do pretty much everything, including creating clients and servers, getting a reference to the event bus, setting timers, as well as many other things.

So how do you get an instance?

If you’re embedding Vert.x then you simply create an instance as follows:

```
Vertx vertx = Vertx.vertx();
```

|  | Most applications will only need a single Vert.x instance, but it’s possible to create multiple Vert.x instances if you require, for example, isolation between the event bus or different groups of servers and clients. |
| --- | --- |

### [Specifying options when creating a Vertx object](#_specifying_options_when_creating_a_vertx_object)

When creating a Vert.x object you can also specify options if the defaults aren’t right for you:

```
Vertx vertx = Vertx.vertx(new VertxOptions().setWorkerPoolSize(40));
```

The `[VertxOptions](../../apidocs/io/vertx/core/VertxOptions.html)` object has many settings and allows you to configure things like clustering, high availability, pool sizes and various other settings.

### [Creating a clustered Vert.x object](#_creating_a_clustered_vert_x_object)

If you’re creating a **clustered Vert.x** (See the section on the [event bus](#event_bus) for more information on clustering the event bus), then you will normally use the asynchronous variant to create the Vertx object.

This is because it usually takes some time (maybe a few seconds) for the different Vert.x instances in a cluster to group together. During that time, we don’t want to block the calling thread, so we give the result to you asynchronously.

## [Are you fluent?](#_are_you_fluent)

You may have noticed that in the previous examples a **fluent** API was used.

A fluent API is where multiple methods calls can be chained together. For example:

```
request.response().putHeader("Content-Type", "text/plain").end("some text");
```

This is a common pattern throughout Vert.x APIs, so get used to it.

Chaining calls like this allows you to write code that’s a little bit less verbose. Of course, if you don’t like the fluent approach **we don’t force you** to do it that way, you can happily ignore it if you prefer and write your code like this:

```
HttpServerResponse response = request.response();
response.putHeader("Content-Type", "text/plain");
response.write("some text");
response.end();
```

## [Don’t call us, we’ll call you.](#_dont_call_us_well_call_you)

The Vert.x APIs are largely *event driven*. This means that when things happen in Vert.x that you are interested in, Vert.x will call you by sending you events.

Some example events are:

* a timer has fired
* some data has arrived on a socket,
* some data has been read from disk
* an exception has occurred
* an HTTP server has received a request

You handle events by providing *handlers* to the Vert.x APIs. For example to receive a timer event every second you would do:

```
vertx.setPeriodic(1000, id -> {
  // This handler will get called every second
  System.out.println("timer fired!");
});
```

Or to receive an HTTP request:

```
server.requestHandler(request -> {
  // This handler will be called every time an HTTP request is received at the server
  request.response().end("hello world!");
});
```

Some time later when Vert.x has an event to pass to your handler Vert.x will call it **asynchronously**.

This leads us to some important concepts in Vert.x:

## [Don’t block me!](#_dont_block_me)

With very few exceptions (i.e. some file system operations ending in 'Sync'), none of the APIs in Vert.x block the calling thread.

If a result can be provided immediately, it will be returned immediately, otherwise you will usually provide a handler to receive events some time later.

Because none of the Vert.x APIs block threads that means you can use Vert.x to handle a lot of concurrency using just a small number of threads.

With a conventional blocking API the calling thread might block when:

* Reading data from a socket
* Writing data to disk
* Sending a message to a recipient and waiting for a reply.
* …​ Many other situations

In all the above cases, when your thread is waiting for a result it can’t do anything else - it’s effectively useless.

This means that if you want a lot of concurrency using blocking APIs then you need a lot of threads to prevent your application grinding to a halt.

Threads have overhead in terms of the memory they require (e.g. for their stack) and in context switching.

For the levels of concurrency required in many modern applications, a blocking approach just doesn’t scale.

## [Reactor and Multi-Reactor](#_reactor_and_multi_reactor)

We mentioned before that Vert.x APIs are event driven - Vert.x passes events to handlers when they are available.

In most cases Vert.x calls your handlers using a thread called an **event loop**.

As nothing in Vert.x or your application blocks, the event loop can merrily run around delivering events to different handlers in succession as they arrive.

Because nothing blocks, an event loop can potentially deliver huge amounts of events in a short amount of time. For example a single event loop can handle many thousands of HTTP requests very quickly.

We call this the [Reactor Pattern](https://en.wikipedia.org/wiki/Reactor_pattern).

You may have heard of this before - for example Node.js implements this pattern.

In a standard reactor implementation there is a **single event loop** thread which runs around in a loop delivering all events to all handlers as they arrive.

The trouble with a single thread is it can only run on a single core at any one time, so if you want your single threaded reactor application (e.g. your Node.js application) to scale over your multi-core server you have to start up and manage many different processes.

Vert.x works differently here. Instead of a single event loop, each Vertx instance maintains **several event loops**. By default we choose the number based on the number of available cores on the machine, but this can be overridden.

This means a single Vertx process can scale across your server, unlike Node.js.

We call this pattern the **Multi-Reactor Pattern** to distinguish it from the single threaded reactor pattern.

|  | Even though a Vertx instance maintains multiple event loops, any particular handler will never be executed concurrently, and in most cases (with the exception of [worker verticles](#worker_verticles)) will always be called using the **exact same event loop**. |
| --- | --- |

## [The Golden Rule - Don’t Block the Event Loop](#golden_rule)

We already know that the Vert.x APIs are non blocking and won’t block the event loop, but that’s not much help if you block the event loop **yourself** in a handler.

If you do that, then that event loop will not be able to do anything else while it’s blocked. If you block all of the event loops in Vertx instance then your application will grind to a complete halt!

So don’t do it! **You have been warned**.

Examples of blocking include:

* Thread.sleep()
* Waiting on a lock
* Waiting on a mutex or monitor (e.g. synchronized section)
* Doing a long lived database operation and waiting for a result
* Doing a complex calculation that takes some significant time.
* Spinning in a loop

If any of the above stop the event loop from doing anything else for a **significant amount of time** then you should go immediately to the naughty step, and await further instructions.

So…​ what is a **significant amount of time**?

How long is a piece of string? It really depends on your application and the amount of concurrency you require.

If you have a single event loop, and you want to handle 10000 http requests per second, then it’s clear that each request can’t take more than 0.1 ms to process, so you can’t block for any more time than that.

**The maths is not hard and shall be left as an exercise for the reader.**

If your application is not responsive it might be a sign that you are blocking an event loop somewhere. To help you diagnose such issues, Vert.x will automatically log warnings if it detects an event loop hasn’t returned for some time. If you see warnings like these in your logs, then you should investigate.

```
Thread vertx-eventloop-thread-3 has been blocked for 20458 ms
```

Vert.x will also provide stack traces to pinpoint exactly where the blocking is occurring.

If you want to turn off these warnings or change the settings, you can do that in the `[VertxOptions](../../apidocs/io/vertx/core/VertxOptions.html)` object before creating the Vertx object.

## [Future results](#_future_results)

Vert.x 4 use futures to represent asynchronous results.

Any asynchronous method returns a `[Future](../../apidocs/io/vertx/core/Future.html)` object for the result of the call: a *success* or a *failure*.

You cannot interact directly with the result of a future, instead you need to set a handler that will be called when the future completes and the result is available, like any other kind of event.

```
FileSystem fs = vertx.fileSystem();

Future<FileProps> future = fs.props("/my_file.txt");

future.onComplete((AsyncResult<FileProps> ar) -> {
  if (ar.succeeded()) {
    FileProps props = ar.result();
    System.out.println("File size = " + props.size());
  } else {
    System.out.println("Failure: " + ar.cause().getMessage());
  }
});
```

|  | Vert.x 3 provides a callback-only model. To allow an easy migration to Vert.x 4 we decided that each asynchronous method has also a callback version. The `props` method above has also a version `[props](../../apidocs/io/vertx/core/file/FileSystem.html#props-java.lang.String-io.vertx.core.Handler-)` with a callback as method argument. |
| --- | --- |

|  | Do not confuse *futures* with *promises*.   If futures represent the "read-side" of an asynchronous result, promises are the "write-side". They allow you to defer the action of providing a result.   In most cases, you don’t need to create promises yourself in a Vert.x application. [Future composition](#_future_composition) and [Future coordination](#_future_coordination) provide you with the tools to transform and merge asynchronous results.   However, if, in your codebase, you have legacy methods which use callbacks, you can leverage the fact that a promise extends `[io.vertx.core.Handler<io.vertx.core.AsyncResult>](../../apidocs/io/vertx/core/Handler.html)`:    ``` Promise<String> promise = Promise.promise(); legacyGreetAsync(promise); Future<String> greeting = promise.future(); ``` |
| --- | --- |

|  | Terminal operations like `onSuccess`, `onFailure` and `onComplete` provide no guarantee whatsoever regarding the invocation order of callbacks.   Consider a future on which 2 callbacks are registered:    ``` future.onComplete(ar -> {   // Do something }); future.onComplete(ar -> {   // May be invoked first }); ```    It is possible that the second callback is invoked before the first one.   If you need such guarantee, consider using [Future composition](#_future_composition) with `[andThen](../../apidocs/io/vertx/core/Future.html#andThen-io.vertx.core.Handler-)`. |
| --- | --- |

## [Future composition](#_future_composition)

`[compose](../../apidocs/io/vertx/core/Future.html#compose-java.util.function.Function-)` can be used for chaining futures:

* when the current future succeeds, apply the given function, that returns a future. When this returned future completes, the composition succeeds.
* when the current future fails, the composition fails

```
FileSystem fs = vertx.fileSystem();

Future<Void> future = fs
  .createFile("/foo")
  .compose(v -> {
    // When the file is created (fut1), execute this:
    return fs.writeFile("/foo", Buffer.buffer());
  })
  .compose(v -> {
    // When the file is written (fut2), execute this:
    return fs.move("/foo", "/bar");
  });
```

In this example, 3 operations are chained together:

1. a file is created
2. data is written in this file
3. the file is moved

When these 3 steps are successful, the final future (`future`) will succeed. However, if one of the steps fails, the final future will fail.

Beyond this, `[Future](../../apidocs/io/vertx/core/Future.html)` offers more: `map`, `recover`, `otherwise`, `andThen` and even a `flatMap` which is an alias of `compose`

## [Future coordination](#_future_coordination)

Coordination of multiple futures can be achieved with Vert.x `[futures](../../apidocs/io/vertx/core/Future.html)`. It supports concurrent composition (run several async operations in parallel) and sequential composition (chain async operations).

`[Future.all](../../apidocs/io/vertx/core/Future.html#all-io.vertx.core.Future-io.vertx.core.Future-)` takes several futures arguments (up to 6) and returns a future that is *succeeded* when all the futures are *succeeded* and *failed* when at least one of the futures is failed:

```
Future<HttpServer> httpServerFuture = httpServer.listen();

Future<NetServer> netServerFuture = netServer.listen();

Future.all(httpServerFuture, netServerFuture).onComplete(ar -> {
  if (ar.succeeded()) {
    // All servers started
  } else {
    // At least one server failed
  }
});
```

The operations run concurrently, the `[Handler](../../apidocs/io/vertx/core/Handler.html)` attached to the returned future is invoked upon completion of the composition. When one of the operation fails (one of the passed future is marked as a failure), the resulting future is marked as failed too. When all the operations succeed, the resulting future is completed with a success.

On success, the `resultAt` method guarantees the results in the same order specified in the call to `Future.all`. In the example above, regardless of which item completed first, the `httpServer` result can be accessed using `resultAt(0)` and the `netServer` result can be accessed using `resultAt(1)`.

Alternatively, you can pass a list (potentially empty) of futures:

```
Future.all(Arrays.asList(future1, future2, future3));
```

While the `all` composition *waits* until all futures are successful (or one fails), the `any` composition *waits* for the first succeeded future. `[Future.any](../../apidocs/io/vertx/core/Future.html#any-io.vertx.core.Future-io.vertx.core.Future-)` takes several futures arguments (up to 6) and returns a future that is succeeded when one of the futures is, and failed when all the futures are failed:

```
Future.any(future1, future2).onComplete(ar -> {
  if (ar.succeeded()) {
    // At least one is succeeded
  } else {
    // All failed
  }
});
```

A list of futures can be used also:

```
Future.any(Arrays.asList(f1, f2, f3));
```

The `join` composition *waits* until all futures are completed, either with a success or a failure. `[Future.join](../../apidocs/io/vertx/core/Future.html#join-io.vertx.core.Future-io.vertx.core.Future-)` takes several futures arguments (up to 6) and returns a future that is succeeded when all the futures are succeeded, and failed when all the futures are completed and at least one of them is failed:

```
Future.join(future1, future2, future3).onComplete(ar -> {
  if (ar.succeeded()) {
    // All succeeded
  } else {
    // All completed and at least one failed
  }
});
```

A list of futures can be used also:

```
Future.join(Arrays.asList(future1, future2, future3));
```

### [CompletionStage interoperability](#_completionstage_interoperability)

The Vert.x `Future` API offers compatibility *from* and *to* `CompletionStage` which is the JDK interface for composable asynchronous operations.

We can go from a Vert.x `Future` to a `CompletionStage` using the `[toCompletionStage](../../apidocs/io/vertx/core/Future.html#toCompletionStage--)` method, as in:

```
Future<String> future = vertx.createDnsClient().lookup("vertx.io");
future.toCompletionStage().whenComplete((ip, err) -> {
  if (err != null) {
    System.err.println("Could not resolve vertx.io");
    err.printStackTrace();
  } else {
    System.out.println("vertx.io => " + ip);
  }
});
```

We can conversely go from a `CompletionStage` to Vert.x `Future` using `[Future.fromCompletionStage](../../apidocs/io/vertx/core/Future.html#fromCompletionStage-java.util.concurrent.CompletionStage-)`. There are 2 variants:

1. the first variant takes just a `CompletionStage` and calls the `Future` methods from the thread that resolves the `CompletionStage` instance, and
2. the second variant takes an extra `[Context](../../apidocs/io/vertx/core/Context.html)` parameter to call the `Future` methods on a Vert.x context.

|  | In most cases the variant with a `CompletionStage` and a `Context` is the one you will want to use to respect the Vert.x threading model, since Vert.x `Future` are more likely to be used with Vert.x code, libraries and clients. |
| --- | --- |

Here is an example of going from a `CompletionStage` to a Vert.x `Future` and dispatching on a context:

```
Future.fromCompletionStage(completionStage, vertx.getOrCreateContext())
  .flatMap(str -> {
    String key = UUID.randomUUID().toString();
    return storeInDb(key, str);
  })
  .onSuccess(str -> {
    System.out.println("We have a result: " + str);
  })
  .onFailure(err -> {
    System.err.println("We have a problem");
    err.printStackTrace();
  });
```

## [Verticles](#_verticles)

Vert.x comes with a simple, scalable, *actor-like* deployment and concurrency model out of the box that you can use to save you writing your own.

**This model is entirely optional and Vert.x does not force you to create your applications in this way if you don’t want to.**.

The model does not claim to be a strict actor-model implementation, but it does share similarities especially with respect to concurrency, scaling and deployment.

To use this model, you write your code as set of **verticles**.

Verticles are chunks of code that get deployed and run by Vert.x. A Vert.x instance maintains N event loop threads (where N by default is core\*2) by default. Verticles can be written in any of the languages that Vert.x supports and a single application can include verticles written in multiple languages.

You can think of a verticle as a bit like an actor in the [Actor Model](https://en.wikipedia.org/wiki/Actor_model).

An application would typically be composed of many verticle instances running in the same Vert.x instance at the same time. The different verticle instances communicate with each other by sending messages on the [event bus](#event_bus).

### [Writing Verticles](#_writing_verticles)

Verticle classes must implement the `[Verticle](../../apidocs/io/vertx/core/Verticle.html)` interface.

They can implement it directly if you like but usually it’s simpler to extend the abstract class `[AbstractVerticle](../../apidocs/io/vertx/core/AbstractVerticle.html)`.

Here’s an example verticle:

```
public class MyVerticle extends AbstractVerticle {

 // Called when verticle is deployed
 public void start() {
 }

 // Optional - called when verticle is undeployed
 public void stop() {
 }

}
```

Normally you would override the start method like in the example above.

When Vert.x deploys the verticle it will call the start method, and when the method has completed the verticle will be considered started.

You can also optionally override the stop method. This will be called by Vert.x when the verticle is undeployed and when the method has completed the verticle will be considered stopped.

### [Asynchronous Verticle start and stop](#_asynchronous_verticle_start_and_stop)

Sometimes you want to do something in your verticle start-up which takes some time and you don’t want the verticle to be considered deployed until that happens. For example you might want to start an HTTP server in the start method and propagate the asynchronous result of the server `listen` method.

You can’t block waiting for the HTTP server to bind in your start method as that would break the [Golden Rule](#golden_rule).

So how can you do this?

The way to do it is to implement the **asynchronous** start method. This version of the method takes a Future as a parameter. When the method returns the verticle will **not** be considered deployed.

Some time later, after you’ve done everything you need to do (e.g. start the HTTP server), you can call complete on the Future (or fail) to signal that you’re done.

Here’s an example:

```
public class MyVerticle extends AbstractVerticle {

 private HttpServer server;

 @Override
 public void start(Promise<Void> startPromise) {
   server = vertx.createHttpServer().requestHandler(req -> {
     req.response()
       .putHeader("content-type", "text/plain")
       .end("Hello from Vert.x!");
     });

   // Now bind the server:
   server.listen(8080)
     .<Void>mapEmpty()
     .onComplete(startPromise);
 }
}
```

Similarly, there is an asynchronous version of the stop method too. You use this if you want to do some verticle cleanup that takes some time.

```
public class MyVerticle extends AbstractVerticle {

 @Override
 public void stop(Promise<Void> stopPromise) {
   doSomethingThatTakesTime()
     .<Void>mapEmpty()
     .onComplete(stopPromise);
 }
}
```

INFO: You don’t need to manually stop the HTTP server started by a verticle, in the verticle’s stop method. Vert.x will automatically stop any running server when the verticle is undeployed.

### [Verticle Types](#_verticle_types)

There are two different types of verticles:

   Standard Verticles

These are the most common and useful type - they are always executed using an event loop thread. We’ll discuss this more in the next section.

 Worker Verticles

These run using a thread from the worker pool. An instance is never executed concurrently by more than one thread.

### [Standard verticles](#_standard_verticles)

Standard verticles are assigned an event loop thread when they are created and the start method is called with that event loop. When you call any other methods that takes a handler on a core API from an event loop then Vert.x will guarantee that those handlers, when called, will be executed on the same event loop.

This means we can guarantee that all the code in your verticle instance is always executed on the same event loop (as long as you don’t create your own threads and call it!).

This means you can write all the code in your application as single threaded and let Vert.x worry about the threading and scaling. No more worrying about synchronized and volatile any more, and you also avoid many other cases of race conditions and deadlock so prevalent when doing hand-rolled 'traditional' multi-threaded application development.

### [Worker verticles](#worker_verticles)

A worker verticle is just like a standard verticle but it’s executed using a thread from the Vert.x worker thread pool, rather than using an event loop.

Worker verticles are designed for calling blocking code, as they won’t block any event loops.

If you don’t want to use a worker verticle to run blocking code, you can also run [inline blocking code](#blocking_code) directly while on an event loop.

If you want to deploy a verticle as a worker verticle you do that with `[setThreadingModel](../../apidocs/io/vertx/core/DeploymentOptions.html#setThreadingModel-io.vertx.core.ThreadingModel-)`.

```
DeploymentOptions options = new DeploymentOptions().setThreadingModel(ThreadingModel.WORKER);
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", options);
```

Worker verticle instances are never executed concurrently by Vert.x by more than one thread, but can executed by different threads at different times.

### [Virtual thread verticles](#_virtual_thread_verticles)

A virtual thread verticle is just like a standard verticle but it’s executed using virtual threads, rather than using an event loop.

Virtual thread verticles are designed to use an async/await model with Vert.x futures.

If you want to deploy a verticle as a [virtual thread verticle](#virtual_threads) you do that with `[setThreadingModel](../../apidocs/io/vertx/core/DeploymentOptions.html#setThreadingModel-io.vertx.core.ThreadingModel-)`.

```
DeploymentOptions options = new DeploymentOptions().setThreadingModel(ThreadingModel.VIRTUAL_THREAD);
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", options);
```

|  | this feature requires Java 21 |
| --- | --- |

### [Deploying verticles programmatically](#_deploying_verticles_programmatically)

You can deploy a verticle using one of the `[deployVerticle](../../apidocs/io/vertx/core/Vertx.html#deployVerticle-io.vertx.core.Verticle-)` method, specifying a verticle name or you can pass in a verticle instance you have already created yourself.

|  | Deploying Verticle **instances** is Java only. |
| --- | --- |

```
Verticle myVerticle = new MyVerticle();
vertx.deployVerticle(myVerticle);
```

You can also deploy verticles by specifying the verticle **name**.

The verticle name is used to look up the specific `[VerticleFactory](../../apidocs/io/vertx/core/spi/VerticleFactory.html)` that will be used to instantiate the actual verticle instance(s).

Different verticle factories are available for instantiating verticles in different languages and for various other reasons such as loading services and getting verticles from Maven at run-time.

This allows you to deploy verticles written in any language from any other language that Vert.x supports.

Here’s an example of deploying some different types of verticles:

```
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle");

// Deploy a JavaScript verticle
vertx.deployVerticle("verticles/myverticle.js");

// Deploy a Ruby verticle verticle
vertx.deployVerticle("verticles/my_verticle.rb");
```

### [Rules for mapping a verticle name to a verticle factory](#_rules_for_mapping_a_verticle_name_to_a_verticle_factory)

When deploying verticle(s) using a name, the name is used to select the actual verticle factory that will instantiate the verticle(s).

Verticle names can have a prefix - which is a string followed by a colon, which if present will be used to look-up the factory, e.g.

```
js:foo.js // Use the JavaScript verticle factory
groovy:com.mycompany.SomeGroovyCompiledVerticle // Use the Groovy verticle factory
service:com.mycompany:myorderservice // Uses the service verticle factory
```

If no prefix is present, Vert.x will look for a suffix and use that to lookup the factory, e.g.

```
foo.js // Will also use the JavaScript verticle factory
SomeScript.groovy // Will use the Groovy verticle factory
```

If no prefix or suffix is present, Vert.x will assume it’s a Java fully qualified class name (FQCN) and try and instantiate that.

### [How are Verticle Factories located?](#_how_are_verticle_factories_located)

Most Verticle factories are loaded from the classpath and registered at Vert.x startup.

You can also programmatically register and unregister verticle factories using `[registerVerticleFactory](../../apidocs/io/vertx/core/Vertx.html#registerVerticleFactory-io.vertx.core.spi.VerticleFactory-)` and `[unregisterVerticleFactory](../../apidocs/io/vertx/core/Vertx.html#unregisterVerticleFactory-io.vertx.core.spi.VerticleFactory-)` if you wish.

### [Waiting for deployment to complete](#_waiting_for_deployment_to_complete)

Verticle deployment is asynchronous and may complete some time after the call to deploy has returned.

If you want to be notified when deployment is complete you can deploy specifying a completion handler:

```
vertx
  .deployVerticle("com.mycompany.MyOrderProcessorVerticle")
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Deployment id is: " + res.result());
    } else {
      System.out.println("Deployment failed!");
    }
  });
```

The completion handler will be passed a result containing the deployment ID string, if deployment succeeded.

This deployment ID can be used later if you want to undeploy the deployment.

### [Undeploying verticle deployments](#_undeploying_verticle_deployments)

Deployments can be undeployed with `[undeploy](../../apidocs/io/vertx/core/Vertx.html#undeploy-java.lang.String-)`.

Un-deployment is itself asynchronous so if you want to be notified when un-deployment is complete you can deploy specifying a completion handler:

```
vertx
  .undeploy(deploymentID)
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Undeployed ok");
    } else {
      System.out.println("Undeploy failed!");
    }
  });
```

### [Specifying number of verticle instances](#_specifying_number_of_verticle_instances)

When deploying a verticle using a verticle name, you can specify the number of verticle instances that you want to deploy:

```
DeploymentOptions options = new DeploymentOptions().setInstances(16);
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", options);
```

This is useful for scaling easily across multiple cores. For example you might have a web-server verticle to deploy and multiple cores on your machine, so you want to deploy multiple instances to utilise all the cores.

### [Passing configuration to a verticle](#_passing_configuration_to_a_verticle)

Configuration in the form of JSON can be passed to a verticle at deployment time:

```
JsonObject config = new JsonObject().put("name", "tim").put("directory", "/blah");
DeploymentOptions options = new DeploymentOptions().setConfig(config);
vertx.deployVerticle("com.mycompany.MyOrderProcessorVerticle", options);
```

This configuration is then available via the `[Context](../../apidocs/io/vertx/core/Context.html)` object or directly using the `[config](../../apidocs/io/vertx/core/AbstractVerticle.html#config--)` method. The configuration is returned as a JSON object so you can retrieve data as follows:

```
System.out.println("Configuration: " + config().getString("name"));
```

### [Accessing environment variables in a Verticle](#_accessing_environment_variables_in_a_verticle)

Environment variables and system properties are accessible using the Java API:

```
System.getProperty("prop");
System.getenv("HOME");
```

### [High Availability](#_high_availability)

Verticles can be deployed with High Availability (HA) enabled. In that context, when a verticle is deployed on a vert.x instance that dies abruptly, the verticle is redeployed on another vert.x instance from the cluster.

To run an verticle with the high availability enabled, just append the `-ha` switch:

```
vertx run my-verticle.js -ha
```

When enabling high availability, no need to add `-cluster`.

More details about the high availability feature and configuration in the [High Availability and Fail-Over](#_high_availability_and_fail_over) section.

### [Running Verticles from the command line](#_running_verticles_from_the_command_line)

You can use Vert.x directly in your Maven or Gradle projects in the normal way by adding a dependency to the Vert.x core library and hacking from there.

However you can also run Vert.x verticles directly from the command line if you wish.

To do this you need to download and install a Vert.x distribution, and add the `bin` directory of the installation to your `PATH` environment variable. Also make sure you have a Java JDK on your `PATH`.

Vert.x supports Java from 8 to 17.

|  | The JDK is required to support on the fly compilation of Java code. |
| --- | --- |

You can now run verticles by using the `vertx run` command. Here are some examples:

```
# Run a JavaScript verticle
vertx run my_verticle.js

# Run a Ruby verticle
vertx run a_n_other_verticle.rb

# Run a Groovy script verticle, clustered
vertx run FooVerticle.groovy -cluster
```

You can even run Java source verticles without compiling them first!

```
vertx run SomeJavaSourceFile.java
```

Vert.x will compile the Java source file on the fly before running it. This is really useful for quickly prototyping verticles and great for demos. No need to set-up a Maven or Gradle build first to get going!

For full information on the various options available when executing `vertx` on the command line, type `vertx` at the command line.

### [Causing Vert.x to exit](#_causing_vert_x_to_exit)

Threads maintained by Vert.x instances are not daemon threads so they will prevent the JVM from exiting.

If you are embedding Vert.x and you have finished with it, you can call `[close](../../apidocs/io/vertx/core/Vertx.html#close--)` to close it down.

This will shut-down all internal thread pools and close other resources, and will allow the JVM to exit.

### [The Context object](#_the_context_object)

When Vert.x provides an event to a handler or calls the start or stop methods of a `[Verticle](../../apidocs/io/vertx/core/Verticle.html)`, the execution is associated with a `Context`. Usually a context is an **event-loop context** and is tied to a specific event loop thread. So executions for that context always occur on that exact same event loop thread. In the case of worker verticles and running inline blocking code a worker context will be associated with the execution which will use a thread from the worker thread pool.

To retrieve the context, use the `[getOrCreateContext](../../apidocs/io/vertx/core/Vertx.html#getOrCreateContext--)` method:

```
Context context = vertx.getOrCreateContext();
```

If the current thread has a context associated with it, it reuses the context object. If not a new instance of context is created. You can test the *type* of context you have retrieved:

```
Context context = vertx.getOrCreateContext();
if (context.isEventLoopContext()) {
  System.out.println("Context attached to Event Loop");
} else if (context.isWorkerContext()) {
  System.out.println("Context attached to Worker Thread");
} else if (! Context.isOnVertxThread()) {
  System.out.println("Context not attached to a thread managed by vert.x");
}
```

When you have retrieved the context object, you can run code in this context asynchronously. In other words, you submit a task that will be eventually run in the same context, but later:

```
vertx.getOrCreateContext().runOnContext( (v) -> {
  System.out.println("This will be executed asynchronously in the same context");
});
```

When several handlers run in the same context, they may want to share data. The context object offers methods to store and retrieve data shared in the context. For instance, it lets you pass data to some action run with `[runOnContext](../../apidocs/io/vertx/core/Context.html#runOnContext-io.vertx.core.Handler-)`:

```
final Context context = vertx.getOrCreateContext();
context.put("data", "hello");
context.runOnContext((v) -> {
  String hello = context.get("data");
});
```

The context object also let you access verticle configuration using the `[config](../../apidocs/io/vertx/core/Context.html#config--)` method. Check the [Passing configuration to a verticle](#_passing_configuration_to_a_verticle) section for more details about this configuration.

### [Executing periodic and delayed actions](#_executing_periodic_and_delayed_actions)

It’s very common in Vert.x to want to perform an action after a delay, or periodically.

In standard verticles you can’t just make the thread sleep to introduce a delay, as that will block the event loop thread.

Instead you use Vert.x timers. Timers can be **one-shot** or **periodic**. We’ll discuss both

#### [One-shot Timers](#_one_shot_timers)

A one shot timer calls an event handler after a certain delay, expressed in milliseconds.

To set a timer to fire once you use `[setTimer](../../apidocs/io/vertx/core/Vertx.html#setTimer-long-io.vertx.core.Handler-)` method passing in the delay and a handler

```
long timerID = vertx.setTimer(1000, id -> {
  System.out.println("And one second later this is printed");
});

System.out.println("First this is printed");
```

The return value is a unique timer id which can later be used to cancel the timer. The handler is also passed the timer id.

#### [Periodic Timers](#_periodic_timers)

You can also set a timer to fire periodically by using `[setPeriodic](../../apidocs/io/vertx/core/Vertx.html#setPeriodic-long-io.vertx.core.Handler-)`.

There will be an initial delay equal to the period.

The return value of `setPeriodic` is a unique timer id (long). This can be later used if the timer needs to be cancelled.

The argument passed into the timer event handler is also the unique timer id:

Keep in mind that the timer will fire on a periodic basis. If your periodic treatment takes a long amount of time to proceed, your timer events could run continuously or even worse : stack up.

In this case, you should consider using `[setTimer](../../apidocs/io/vertx/core/Vertx.html#setTimer-long-io.vertx.core.Handler-)` instead. Once your treatment has finished, you can set the next timer.

```
long timerID = vertx.setPeriodic(1000, id -> {
  System.out.println("And every second this is printed");
});

System.out.println("First this is printed");
```

#### [Cancelling timers](#_cancelling_timers)

To cancel a periodic timer, call `[cancelTimer](../../apidocs/io/vertx/core/Vertx.html#cancelTimer-long-)` specifying the timer id. For example:

```
vertx.cancelTimer(timerID);
```

#### [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles)

If you’re creating timers from inside verticles, those timers will be automatically closed when the verticle is undeployed.

### [Verticle worker pool](#_verticle_worker_pool)

Verticles use the Vert.x worker pool for executing blocking actions, i.e `[executeBlocking](../../apidocs/io/vertx/core/Context.html#executeBlocking-io.vertx.core.Handler-boolean-io.vertx.core.Handler-)` or worker verticle.

A different worker pool can be specified in deployment options:

```
vertx.deployVerticle("the-verticle", new DeploymentOptions().setWorkerPoolName("the-specific-pool"));
```

## [The Event Bus](#event_bus)

The `[event bus](../../apidocs/io/vertx/core/eventbus/EventBus.html)` is the **nervous system** of Vert.x.

There is a single event bus instance for every Vert.x instance and it is obtained using the method `[eventBus](../../apidocs/io/vertx/core/Vertx.html#eventBus--)`.

The event bus allows different parts of your application to communicate with each other, irrespective of what language they are written in, and whether they’re in the same Vert.x instance, or in a different Vert.x instance.

It can even be bridged to allow client-side JavaScript running in a browser to communicate on the same event bus.

The event bus forms a distributed peer-to-peer messaging system spanning multiple server nodes and multiple browsers.

The event bus supports publish/subscribe, point-to-point, and request-response messaging.

The event bus API is very simple. It basically involves registering handlers, unregistering handlers and sending and publishing messages.

First some theory:

### [The Theory](#_the_theory)

#### [Addressing](#_addressing)

Messages are sent on the event bus to an **address**.

Vert.x doesn’t bother with any fancy addressing schemes. In Vert.x an address is simply a string. Any string is valid. However, it is wise to use some kind of scheme, *e.g.* using periods to demarcate a namespace.

Some examples of valid addresses are europe.news.feed1, acme.games.pacman, sausages, and X.

#### [Handlers](#_handlers)

Messages are received by handlers. You register a handler at an address.

Many different handlers can be registered at the same address.

A single handler can be registered at many different addresses.

#### [Publish / subscribe messaging](#_publish_subscribe_messaging)

The event bus supports **publishing** messages.

Messages are published to an address. Publishing means delivering the message to all handlers that are registered at that address.

This is the familiar **publish/subscribe** messaging pattern.

#### [Point-to-point and Request-Response messaging](#_point_to_point_and_request_response_messaging)

The event bus also supports **point-to-point** messaging.

Messages are sent to an address. Vert.x will then route them to just one of the handlers registered at that address.

If there is more than one handler registered at the address, one will be chosen using a non-strict round-robin algorithm.

With point-to-point messaging, an optional reply handler can be specified when sending the message.

When a message is received by a recipient, and has been handled, the recipient can optionally decide to reply to the message. If they do so, the reply handler will be called.

When the reply is received back by the sender, it too can be replied to. This can be repeated *ad infinitum*, and allows a dialog to be set up between two different verticles.

This is a common messaging pattern called the **request-response** pattern.

#### [Best-effort delivery](#_best_effort_delivery)

Vert.x does its best to deliver messages and won’t consciously throw them away. This is called **best-effort** delivery.

However, in case of failure of all or parts of the event bus, there is a possibility messages might be lost.

If your application cares about lost messages, you should code your handlers to be idempotent, and your senders to retry after recovery.

#### [Types of messages](#_types_of_messages)

Out of the box Vert.x allows any primitive/simple type, String, or `[buffers](../../apidocs/io/vertx/core/buffer/Buffer.html)` to be sent as messages.

However, it’s a convention and common practice in Vert.x to send messages as [JSON](http://json.org/)

JSON is very easy to create, read and parse in all the languages that Vert.x supports, so it has become a kind of *lingua franca* for Vert.x.

However, you are not forced to use JSON if you don’t want to.

The event bus is very flexible and also supports sending arbitrary objects over the event bus. You can do this by defining a `[codec](../../apidocs/io/vertx/core/eventbus/MessageCodec.html)` for the objects you want to send.

### [The Event Bus API](#_the_event_bus_api)

Let’s jump into the API.

#### [Getting the event bus](#_getting_the_event_bus)

You get a reference to the event bus as follows:

```
EventBus eb = vertx.eventBus();
```

There is a single instance of the event bus per Vert.x instance.

#### [Registering Handlers](#_registering_handlers)

This simplest way to register a handler is using `[consumer](../../apidocs/io/vertx/core/eventbus/EventBus.html#consumer-java.lang.String-io.vertx.core.Handler-)`. Here’s an example:

```
EventBus eb = vertx.eventBus();

eb.consumer("news.uk.sport", message -> {
  System.out.println("I have received a message: " + message.body());
});
```

When a message arrives for your handler, your handler will be called, passing in the `[message](../../apidocs/io/vertx/core/eventbus/Message.html)`.

The object returned from call to consumer() is an instance of `[MessageConsumer](../../apidocs/io/vertx/core/eventbus/MessageConsumer.html)`.

This object can subsequently be used to unregister the handler, or use the handler as a stream.

Alternatively you can use `[consumer](../../apidocs/io/vertx/core/eventbus/EventBus.html#consumer-java.lang.String-io.vertx.core.Handler-)` to return a MessageConsumer with no handler set, and then set the handler on that. For example:

```
EventBus eb = vertx.eventBus();

MessageConsumer<String> consumer = eb.consumer("news.uk.sport");
consumer.handler(message -> {
  System.out.println("I have received a message: " + message.body());
});
```

When registering a handler on a clustered event bus, it can take some time for the registration to reach all nodes of the cluster.

If you want to be notified when this has completed, you can register a `[completion handler](../../apidocs/io/vertx/core/eventbus/MessageConsumer.html#completionHandler-io.vertx.core.Handler-)` on the MessageConsumer object.

```
consumer.completionHandler(res -> {
  if (res.succeeded()) {
    System.out.println("The handler registration has reached all nodes");
  } else {
    System.out.println("Registration failed!");
  }
});
```

#### [Un-registering Handlers](#_un_registering_handlers)

To unregister a handler, call `[unregister](../../apidocs/io/vertx/core/eventbus/MessageConsumer.html#unregister--)`.

If you are on a clustered event bus, un-registering can take some time to propagate across the nodes. If you want to be notified when this is complete, use `[unregister](../../apidocs/io/vertx/core/eventbus/MessageConsumer.html#unregister-io.vertx.core.Handler-)`.

```
consumer
  .unregister()
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("The handler un-registration has reached all nodes");
    } else {
      System.out.println("Un-registration failed!");
    }
  });
```

#### [Publishing messages](#_publishing_messages)

Publishing a message is simple. Just use `[publish](../../apidocs/io/vertx/core/eventbus/EventBus.html#publish-java.lang.String-java.lang.Object-)` specifying the address to publish it to.

```
eventBus.publish("news.uk.sport", "Yay! Someone kicked a ball");
```

That message will then be delivered to all handlers registered against the address news.uk.sport.

#### [Sending messages](#_sending_messages)

Sending a message will result in only one handler registered at the address receiving the message. This is the point-to-point messaging pattern. The handler is chosen in a non-strict round-robin fashion.

You can send a message with `[send](../../apidocs/io/vertx/core/eventbus/EventBus.html#send-java.lang.String-java.lang.Object-)`.

```
eventBus.send("news.uk.sport", "Yay! Someone kicked a ball");
```

#### [Setting headers on messages](#_setting_headers_on_messages)

Messages sent over the event bus can also contain headers. This can be specified by providing a `[DeliveryOptions](../../apidocs/io/vertx/core/eventbus/DeliveryOptions.html)` when sending or publishing:

```
DeliveryOptions options = new DeliveryOptions();
options.addHeader("some-header", "some-value");
eventBus.send("news.uk.sport", "Yay! Someone kicked a ball", options);
```

#### [Message ordering](#_message_ordering)

Vert.x will deliver messages to any particular handler in the same order they were sent from any particular sender.

#### [The Message object](#_the_message_object)

The object you receive in a message handler is a `[Message](../../apidocs/io/vertx/core/eventbus/Message.html)`.

The `[body](../../apidocs/io/vertx/core/eventbus/Message.html#body--)` of the message corresponds to the object that was sent or published.

The headers of the message are available with `[headers](../../apidocs/io/vertx/core/eventbus/Message.html#headers--)`.

#### [Acknowledging messages / sending replies](#_acknowledging_messages_sending_replies)

When using `[send](../../apidocs/io/vertx/core/eventbus/EventBus.html#send-java.lang.String-java.lang.Object-)` the event bus attempts to deliver the message to a `[MessageConsumer](../../apidocs/io/vertx/core/eventbus/MessageConsumer.html)` registered with the event bus.

In some cases it’s useful for the sender to know when the consumer has received the message and "processed" it using **request-response** pattern.

To acknowledge that the message has been processed, the consumer can reply to the message by calling `[reply](../../apidocs/io/vertx/core/eventbus/Message.html#reply-java.lang.Object-)`.

When this happens it causes a reply to be sent back to the sender and the reply handler is invoked with the reply.

An example will make this clear:

The receiver:

```
MessageConsumer<String> consumer = eventBus.consumer("news.uk.sport");
consumer.handler(message -> {
  System.out.println("I have received a message: " + message.body());
  message.reply("how interesting!");
});
```

The sender:

```
eventBus
  .request("news.uk.sport", "Yay! Someone kicked a ball across a patch of grass")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      System.out.println("Received reply: " + ar.result().body());
    }
  });
```

The reply can contain a message body which can contain useful information.

What the "processing" actually means is application-defined and depends entirely on what the message consumer does and is not something that the Vert.x event bus itself knows or cares about.

Some examples:

* A simple message consumer which implements a service which returns the time of the day would acknowledge with a message containing the time of day in the reply body
* A message consumer which implements a persistent queue, might acknowledge with `true` if the message was successfully persisted in storage, or `false` if not.
* A message consumer which processes an order might acknowledge with `true` when the order has been successfully processed so it can be deleted from the database

#### [Sending with timeouts](#_sending_with_timeouts)

When sending a message with a reply handler, you can specify a timeout in the `[DeliveryOptions](../../apidocs/io/vertx/core/eventbus/DeliveryOptions.html)`.

If a reply is not received within that time, the reply handler will be called with a failure.

The default timeout is 30 seconds.

#### [Send Failures](#_send_failures)

Message sends can fail for other reasons, including:

* There are no handlers available to send the message to
* The recipient has explicitly failed the message using `[fail](../../apidocs/io/vertx/core/eventbus/Message.html#fail-int-java.lang.String-)`

In all cases, the reply handler will be called with the specific failure.

#### [Message Codecs](#_message_codecs)

You can send any object you like across the event bus if you define and register a `[message codec](../../apidocs/io/vertx/core/eventbus/MessageCodec.html)` for it.

Message codecs have a name and you specify that name in the `[DeliveryOptions](../../apidocs/io/vertx/core/eventbus/DeliveryOptions.html)` when sending or publishing the message:

```
eventBus.registerCodec(myCodec);

DeliveryOptions options = new DeliveryOptions().setCodecName(myCodec.name());

eventBus.send("orders", new MyPOJO(), options);
```

If you always want the same codec to be used for a particular type then you can register a default codec for it, then you don’t have to specify the codec on each send in the delivery options:

```
eventBus.registerDefaultCodec(MyPOJO.class, myCodec);

eventBus.send("orders", new MyPOJO());
```

You unregister a message codec with `[unregisterCodec](../../apidocs/io/vertx/core/eventbus/EventBus.html#unregisterCodec-java.lang.String-)`.

Message codecs don’t always have to encode and decode as the same type. For example you can write a codec that allows a MyPOJO class to be sent, but when that message is sent to a handler it arrives as a MyOtherPOJO class.

Vert.x has built-in codecs for certain data types:

* basic types (string, byte array, byte, int, long, double, boolean, short, char), or
* some Vert.x data types (buffers, JSON array, JSON objects), or
* types implementing the `[ClusterSerializable](../../apidocs/io/vertx/core/shareddata/ClusterSerializable.html)` interface, or
* types implementing the `java.io.Serializable` interface.

|  | In clustered mode, `[ClusterSerializable](../../apidocs/io/vertx/core/shareddata/ClusterSerializable.html)` and `java.io.Serializable` objects are rejected by default, for security reasons.   You can define which classes are allowed for encoding and decoding by providing functions which inspect the name of the class:    * `[EventBus.clusterSerializableChecker()](../../apidocs/io/vertx/core/eventbus/EventBus.html#clusterSerializableChecker-java.util.function.Function-)`, and * `[EventBus.serializableChecker()](../../apidocs/io/vertx/core/eventbus/EventBus.html#serializableChecker-java.util.function.Function-)`. |
| --- | --- |

#### [Clustered Event Bus](#_clustered_event_bus)

The event bus doesn’t just exist in a single Vert.x instance. By clustering different Vert.x instances together on your network they can form a single, distributed event bus.

#### [Clustering programmatically](#_clustering_programmatically)

If you’re creating your Vert.x instance programmatically you get a clustered event bus by configuring the Vert.x instance as clustered;

```
VertxOptions options = new VertxOptions();
Vertx
  .clusteredVertx(options)
  .onComplete(res -> {
    if (res.succeeded()) {
      Vertx vertx = res.result();
      EventBus eventBus = vertx.eventBus();
      System.out.println("We now have a clustered event bus: " + eventBus);
    } else {
      System.out.println("Failed: " + res.cause());
    }
  });
```

You should also make sure you have a `[ClusterManager](../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html)` implementation on your classpath, for example the Hazelcast cluster manager.

#### [Clustering on the command line](#_clustering_on_the_command_line)

You can run Vert.x clustered on the command line with

```
vertx run my-verticle.js -cluster
```

### [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles_2)

If you’re registering event bus handlers from inside verticles, those handlers will be automatically unregistered when the verticle is undeployed.

## [Configuring the event bus](#_configuring_the_event_bus)

The event bus can be configured. It is particularly useful when the event bus is clustered. Under the hood the event bus uses TCP connections to send and receive messages, so the `[EventBusOptions](../../apidocs/io/vertx/core/eventbus/EventBusOptions.html)` let you configure all aspects of these TCP connections. As the event bus acts as a server and client, the configuration is close to `[NetClientOptions](../../apidocs/io/vertx/core/net/NetClientOptions.html)` and `[NetServerOptions](../../apidocs/io/vertx/core/net/NetServerOptions.html)`.

```
VertxOptions options = new VertxOptions()
    .setEventBusOptions(new EventBusOptions()
        .setSsl(true)
        .setKeyStoreOptions(new JksOptions().setPath("keystore.jks").setPassword("wibble"))
        .setTrustStoreOptions(new JksOptions().setPath("keystore.jks").setPassword("wibble"))
        .setClientAuth(ClientAuth.REQUIRED)
    );

Vertx
  .clusteredVertx(options)
  .onComplete(res -> {
    if (res.succeeded()) {
      Vertx vertx = res.result();
      EventBus eventBus = vertx.eventBus();
      System.out.println("We now have a clustered event bus: " + eventBus);
    } else {
      System.out.println("Failed: " + res.cause());
    }
  });
```

The previous snippet depicts how you can use SSL connections for the event bus, instead of plain TCP connections.

**WARNING**: to enforce the security in clustered mode, you **must** configure the cluster manager to use encryption or enforce security. Refer to the documentation of the cluster manager for further details.

The event bus configuration needs to be consistent in all the cluster nodes.

The `[EventBusOptions](../../apidocs/io/vertx/core/eventbus/EventBusOptions.html)` also lets you specify whether or not the event bus is clustered, the port and host.

When used in containers, you can also configure the public host and port:

```
VertxOptions options = new VertxOptions()
    .setEventBusOptions(new EventBusOptions()
        .setClusterPublicHost("whatever")
        .setClusterPublicPort(1234)
    );

Vertx
  .clusteredVertx(options)
  .onComplete(res -> {
    if (res.succeeded()) {
      Vertx vertx = res.result();
      EventBus eventBus = vertx.eventBus();
      System.out.println("We now have a clustered event bus: " + eventBus);
    } else {
      System.out.println("Failed: " + res.cause());
    }
  });
```

## [JSON](#_json)

Unlike some other languages, Java does not have first class support for [JSON](http://json.org/) so we provide two classes to make handling JSON in your Vert.x applications a bit easier.

### [JSON objects](#_json_objects)

The `[JsonObject](../../apidocs/io/vertx/core/json/JsonObject.html)` class represents JSON objects.

A JSON object is basically just a map which has string keys and values can be of one of the JSON supported types (string, number, boolean).

JSON objects also support null values.

#### [Creating JSON objects](#_creating_json_objects)

Empty JSON objects can be created with the default constructor.

You can create a JSON object from a string JSON representation as follows:

```
String jsonString = "{\"foo\":\"bar\"}";
JsonObject object = new JsonObject(jsonString);
```

You can create a JSON object from a map as follows:

```
Map<String, Object> map = new HashMap<>();
map.put("foo", "bar");
map.put("xyz", 3);
JsonObject object = new JsonObject(map);
```

#### [Putting entries into a JSON object](#_putting_entries_into_a_json_object)

Use the `[put](../../apidocs/io/vertx/core/json/JsonObject.html#put-java.lang.String-java.lang.Object-)` methods to put values into the JSON object.

The method invocations can be chained because of the fluent API:

```
JsonObject object = new JsonObject();
object.put("foo", "bar").put("num", 123).put("mybool", true);
```

#### [Getting values from a JSON object](#_getting_values_from_a_json_object)

You get values from a JSON object using the `getXXX` methods, for example:

```
String val = jsonObject.getString("some-key");
int intVal = jsonObject.getInteger("some-other-key");
```

#### [Mapping between JSON objects and Java objects](#_mapping_between_json_objects_and_java_objects)

You can create a JSON object from the fields of a Java object as follows:

You can instantiate a Java object and populate its fields from a JSON object as follows:

```
request.bodyHandler(buff -> {
  JsonObject jsonObject = buff.toJsonObject();
  User javaObject = jsonObject.mapTo(User.class);
});
```

Note that both of the above mapping directions use Jackson’s `ObjectMapper#convertValue()` to perform the mapping. See the Jackson documentation for information on the impact of field and constructor visibility, caveats on serialization and deserialization across object references, etc.

However, in the simplest case, both `mapFrom` and `mapTo` should succeed if all fields of the Java class are public (or have public getters/setters), and if there is a public default constructor (or no defined constructors).

Referenced objects will be transitively serialized/deserialized to/from nested JSON objects as long as the object graph is acyclic.

#### [Encoding a JSON object to a String](#_encoding_a_json_object_to_a_string)

You use `[encode](../../apidocs/io/vertx/core/json/JsonObject.html#encode--)` to encode the object to a String form.

### [JSON arrays](#_json_arrays)

The `[JsonArray](../../apidocs/io/vertx/core/json/JsonArray.html)` class represents JSON arrays.

A JSON array is a sequence of values (string, number, boolean).

JSON arrays can also contain null values.

#### [Creating JSON arrays](#_creating_json_arrays)

Empty JSON arrays can be created with the default constructor.

You can create a JSON array from a string JSON representation as follows:

```
String jsonString = "[\"foo\",\"bar\"]";
JsonArray array = new JsonArray(jsonString);
```

#### [Adding entries into a JSON array](#_adding_entries_into_a_json_array)

You add entries to a JSON array using the `[add](../../apidocs/io/vertx/core/json/JsonArray.html#add-java.lang.Object-)` methods.

```
JsonArray array = new JsonArray();
array.add("foo").add(123).add(false);
```

#### [Getting values from a JSON array](#_getting_values_from_a_json_array)

You get values from a JSON array using the `getXXX` methods, for example:

```
String val = array.getString(0);
Integer intVal = array.getInteger(1);
Boolean boolVal = array.getBoolean(2);
```

#### [Encoding a JSON array to a String](#_encoding_a_json_array_to_a_string)

You use `[encode](../../apidocs/io/vertx/core/json/JsonArray.html#encode--)` to encode the array to a String form.

#### [Creating arbitrary JSON](#_creating_arbitrary_json)

Creating JSON object and array assumes you are using valid string representation.

When you are unsure of the string validity then you should use instead `[Json.decodeValue](../../apidocs/io/vertx/core/json/Json.html#decodeValue-java.lang.String-)`

```
Object object = Json.decodeValue(arbitraryJson);
if (object instanceof JsonObject) {
  // That's a valid json object
} else if (object instanceof JsonArray) {
  // That's a valid json array
} else if (object instanceof String) {
  // That's valid string
} else {
  // etc...
}
```

## [Json Pointers](#_json_pointers)

Vert.x provides an implementation of [Json Pointers from RFC6901](https://tools.ietf.org/html/rfc6901). You can use pointers both for querying and for writing. You can build your `[JsonPointer](../../apidocs/io/vertx/core/json/pointer/JsonPointer.html)` using a string, a URI or manually appending paths:

```
JsonPointer pointer1 = JsonPointer.from("/hello/world");
// Build a pointer manually
JsonPointer pointer2 = JsonPointer.create()
  .append("hello")
  .append("world");
```

After instantiating your pointer, use `[queryJson](../../apidocs/io/vertx/core/json/pointer/JsonPointer.html#queryJson-java.lang.Object-)` to query a JSON value. You can update a Json Value using `[writeJson](../../apidocs/io/vertx/core/json/pointer/JsonPointer.html#writeJson-java.lang.Object-java.lang.Object-)`:

```
Object result1 = objectPointer.queryJson(jsonObject);
// Query a JsonArray
Object result2 = arrayPointer.queryJson(jsonArray);
// Write starting from a JsonObject
objectPointer.writeJson(jsonObject, "new element");
// Write starting from a JsonObject
arrayPointer.writeJson(jsonArray, "new element");
```

You can use Vert.x Json Pointer with any object model by providing a custom implementation of `[JsonPointerIterator](../../apidocs/io/vertx/core/json/pointer/JsonPointerIterator.html)`

## [Buffers](#_buffers)

Most data is shuffled around inside Vert.x using buffers.

A buffer is a sequence of zero or more bytes that can read from or written to and which expands automatically as necessary to accommodate any bytes written to it. You can perhaps think of a buffer as smart byte array.

### [Creating buffers](#_creating_buffers)

Buffers can create by using one of the static `[Buffer.buffer](../../apidocs/io/vertx/core/buffer/Buffer.html#buffer--)` methods.

Buffers can be initialised from strings or byte arrays, or empty buffers can be created.

Here are some examples of creating buffers:

Create a new empty buffer:

```
Buffer buff = Buffer.buffer();
```

Create a buffer from a String. The String will be encoded in the buffer using UTF-8.

```
Buffer buff = Buffer.buffer("some string");
```

Create a buffer from a String: The String will be encoded using the specified encoding, e.g:

```
Buffer buff = Buffer.buffer("some string", "UTF-16");
```

Create a buffer from a byte[]

```
byte[] bytes = new byte[] {1, 3, 5};
Buffer buff = Buffer.buffer(bytes);
```

Create a buffer with an initial size hint. If you know your buffer will have a certain amount of data written to it you can create the buffer and specify this size. This makes the buffer initially allocate that much memory and is more efficient than the buffer automatically resizing multiple times as data is written to it.

Note that buffers created this way **are empty**. It does not create a buffer filled with zeros up to the specified size.

```
Buffer buff = Buffer.buffer(10000);
```

### [Writing to a Buffer](#_writing_to_a_buffer)

There are two ways to write to a buffer: appending, and random access. In either case buffers will always expand automatically to encompass the bytes. It’s not possible to get an `IndexOutOfBoundsException` with a buffer.

#### [Appending to a Buffer](#_appending_to_a_buffer)

To append to a buffer, you use the `appendXXX` methods. Append methods exist for appending various different types.

The return value of the `appendXXX` methods is the buffer itself, so these can be chained:

```
Buffer buff = Buffer.buffer();

buff.appendInt(123).appendString("hello\n");

socket.write(buff);
```

#### [Random access buffer writes](#_random_access_buffer_writes)

You can also write into the buffer at a specific index, by using the `setXXX` methods. Set methods exist for various different data types. All the set methods take an index as the first argument - this represents the position in the buffer where to start writing the data.

The buffer will always expand as necessary to accommodate the data.

```
Buffer buff = Buffer.buffer();

buff.setInt(1000, 123);
buff.setString(0, "hello");
```

### [Reading from a Buffer](#_reading_from_a_buffer)

Data is read from a buffer using the `getXXX` methods. Get methods exist for various datatypes. The first argument to these methods is an index in the buffer from where to get the data.

```
Buffer buff = Buffer.buffer();
for (int i = 0; i < buff.length(); i += 4) {
  System.out.println("int value at " + i + " is " + buff.getInt(i));
}
```

### [Working with unsigned numbers](#_working_with_unsigned_numbers)

Unsigned numbers can be read from or appended/set to a buffer with the `getUnsignedXXX`, `appendUnsignedXXX` and `setUnsignedXXX` methods. This is useful when implementing a codec for a network protocol optimized to minimize bandwidth consumption.

In the following example, value 200 is set at specified position with just one byte:

```
Buffer buff = Buffer.buffer(128);
int pos = 15;
buff.setUnsignedByte(pos, (short) 200);
System.out.println(buff.getUnsignedByte(pos));
```

The console shows '200'.

### [Buffer length](#_buffer_length)

Use `[length](../../apidocs/io/vertx/core/buffer/Buffer.html#length--)` to obtain the length of the buffer. The length of a buffer is the index of the byte in the buffer with the largest index + 1.

### [Copying buffers](#_copying_buffers)

Use `[copy](../../apidocs/io/vertx/core/buffer/Buffer.html#copy--)` to make a copy of the buffer

### [Slicing buffers](#_slicing_buffers)

A sliced buffer is a new buffer which backs onto the original buffer, i.e. it does not copy the underlying data. Use `[slice](../../apidocs/io/vertx/core/buffer/Buffer.html#slice--)` to create a sliced buffers

### [Buffer re-use](#_buffer_re_use)

After writing a buffer to a socket or other similar place, they cannot be re-used.

## [Writing TCP servers and clients](#_writing_tcp_servers_and_clients)

Vert.x allows you to easily write non blocking TCP clients and servers.

### [Creating a TCP server](#_creating_a_tcp_server)

The simplest way to create a TCP server, using all default options is as follows:

```
NetServer server = vertx.createNetServer();
```

### [Configuring a TCP server](#_configuring_a_tcp_server)

If you don’t want the default, a server can be configured by passing in a `[NetServerOptions](../../apidocs/io/vertx/core/net/NetServerOptions.html)` instance when creating it:

```
NetServerOptions options = new NetServerOptions().setPort(4321);
NetServer server = vertx.createNetServer(options);
```

### [Start the Server Listening](#_start_the_server_listening)

To tell the server to listen for incoming requests you use one of the `[listen](../../apidocs/io/vertx/core/net/NetServer.html#listen--)` alternatives.

To tell the server to listen at the host and port as specified in the options:

```
NetServer server = vertx.createNetServer();
server.listen();
```

Or to specify the host and port in the call to listen, ignoring what is configured in the options:

```
NetServer server = vertx.createNetServer();
server.listen(1234, "localhost");
```

The default host is `0.0.0.0` which means 'listen on all available addresses' and the default port is `0`, which is a special value that instructs the server to find a random unused local port and use that.

The actual bind is asynchronous, so the server might not actually be listening until some time **after** the call to listen has returned.

If you want to be notified when the server is actually listening you can provide a handler to the `listen` call. For example:

```
NetServer server = vertx.createNetServer();
server
  .listen(1234, "localhost")
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Server is now listening!");
    } else {
      System.out.println("Failed to bind!");
    }
  });
```

### [Listening on a random port](#_listening_on_a_random_port)

If `0` is used as the listening port, the server will find an unused random port to listen on.

To find out the real port the server is listening on you can call `[actualPort](../../apidocs/io/vertx/core/net/NetServer.html#actualPort--)`.

```
NetServer server = vertx.createNetServer();
server
  .listen(0, "localhost")
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Server is now listening on actual port: " + server.actualPort());
    } else {
      System.out.println("Failed to bind!");
    }
  });
```

### [Getting notified of incoming connections](#_getting_notified_of_incoming_connections)

To be notified when a connection is made you need to set a `[connectHandler](../../apidocs/io/vertx/core/net/NetServer.html#connectHandler-io.vertx.core.Handler-)`:

```
NetServer server = vertx.createNetServer();
server.connectHandler(socket -> {
  // Handle the connection in here
});
```

When a connection is made the handler will be called with an instance of `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)`.

This is a socket-like interface to the actual connection, and allows you to read and write data as well as do various other things like close the socket.

### [Reading data from the socket](#_reading_data_from_the_socket)

To read data from the socket you set the `[handler](../../apidocs/io/vertx/core/net/NetSocket.html#handler-io.vertx.core.Handler-)` on the socket.

This handler will be called with an instance of `[Buffer](../../apidocs/io/vertx/core/buffer/Buffer.html)` every time data is received on the socket.

```
NetServer server = vertx.createNetServer();
server.connectHandler(socket -> {
  socket.handler(buffer -> {
    System.out.println("I received some bytes: " + buffer.length());
  });
});
```

### [Writing data to a socket](#_writing_data_to_a_socket)

You write to a socket using one of `[write](../../apidocs/io/vertx/core/streams/WriteStream.html#write-java.lang.Object-)`.

```
Buffer buffer = Buffer.buffer().appendFloat(12.34f).appendInt(123);
socket.write(buffer);

// Write a string in UTF-8 encoding
socket.write("some data");

// Write a string using the specified encoding
socket.write("some data", "UTF-16");
```

Write operations are asynchronous and may not occur until some time after the call to write has returned.

### [Closed handler](#_closed_handler)

If you want to be notified when a socket is closed, you can set a `[closeHandler](../../apidocs/io/vertx/core/net/NetSocket.html#closeHandler-io.vertx.core.Handler-)` on it:

```
socket.closeHandler(v -> {
  System.out.println("The socket has been closed");
});
```

### [Handling exceptions](#_handling_exceptions)

You can set an `[exceptionHandler](../../apidocs/io/vertx/core/net/NetSocket.html#exceptionHandler-io.vertx.core.Handler-)` to receive any exceptions that happen on the socket.

You can set an `[exceptionHandler](../../apidocs/io/vertx/core/net/NetServer.html#exceptionHandler-io.vertx.core.Handler-)` to receive any exceptions that happens before the connection is passed to the `[connectHandler](../../apidocs/io/vertx/core/net/NetServer.html#connectHandler-io.vertx.core.Handler-)` , e.g during the TLS handshake.

### [Event bus write handler](#_event_bus_write_handler)

Every socket can register a handler on the event bus, and when any buffers are received in this handler, it writes them to itself. Those are local subscriptions, not reachable from other clustered nodes.

This enables you to write data to a socket which is potentially in a completely different verticle by sending the buffer to the address of that handler.

This feature is disabled by default, however you can enable it using `[setRegisterWriteHandler](../../apidocs/io/vertx/core/net/NetServerOptions.html#setRegisterWriteHandler-boolean-)` or `[setRegisterWriteHandler](../../apidocs/io/vertx/core/net/NetClientOptions.html#setRegisterWriteHandler-boolean-)`.

The address of the handler is given by `[writeHandlerID](../../apidocs/io/vertx/core/net/NetSocket.html#writeHandlerID--)`.

### [Local and remote addresses](#_local_and_remote_addresses)

The local address of a `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` can be retrieved using `[localAddress](../../apidocs/io/vertx/core/net/NetSocket.html#localAddress--)`.

The remote address, (i.e. the address of the other end of the connection) of a `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` can be retrieved using `[remoteAddress](../../apidocs/io/vertx/core/net/NetSocket.html#remoteAddress--)`.

### [Sending files or resources from the classpath](#_sending_files_or_resources_from_the_classpath)

Files and classpath resources can be written to the socket directly using `[sendFile](../../apidocs/io/vertx/core/net/NetSocket.html#sendFile-java.lang.String-)`. This can be a very efficient way to send files, as it can be handled by the OS kernel directly where supported by the operating system.

Please see the chapter about [serving files from the classpath](#classpath) for restrictions of the classpath resolution or disabling it.

```
socket.sendFile("myfile.dat");
```

### [Streaming sockets](#_streaming_sockets)

Instances of `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` are also `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)` and `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` instances, so they can be used to pipe data to or from other read and write streams.

See the chapter on [streams](#streams)  for more information.

### [Upgrading connections to SSL/TLS](#_upgrading_connections_to_ssltls)

A non SSL/TLS connection can be upgraded to SSL/TLS using `[upgradeToSsl](../../apidocs/io/vertx/core/net/NetSocket.html#upgradeToSsl-io.vertx.core.Handler-)`.

The server or client must be configured for SSL/TLS for this to work correctly. Please see the [chapter on SSL/TLS](#ssl) for more information.

### [Closing a TCP Server](#_closing_a_tcp_server)

Call `[close](../../apidocs/io/vertx/core/net/NetServer.html#close--)` to close the server. Closing the server closes any open connections and releases all server resources.

The close is actually asynchronous and might not complete until some time after the call has returned. If you want to be notified when the actual close has completed then you can pass in a handler.

This handler will then be called when the close has fully completed.

```
server
  .close()
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Server is now closed");
    } else {
      System.out.println("close failed");
    }
  });
```

### [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles_3)

If you’re creating TCP servers and clients from inside verticles, those servers and clients will be automatically closed when the verticle is undeployed.

### [Scaling - sharing TCP servers](#_scaling_sharing_tcp_servers)

The handlers of any TCP server are always executed on the same event loop thread.

This means that if you are running on a server with a lot of cores, and you only have this one instance deployed then you will have at most one core utilised on your server.

In order to utilise more cores of your server you will need to deploy more instances of the server.

You can instantiate more instances programmatically in your code:

```
class MyVerticle extends AbstractVerticle {

  NetServer server;

  @Override
  public void start() throws Exception {
    server = vertx.createNetServer();
    server.connectHandler(socket -> {
      socket.handler(buffer -> {
        // Just echo back the data
        socket.write(buffer);
      });
    });
    server.listen(1234, "localhost");
  }
}

// Create a few instances so we can utilise cores
vertx.deployVerticle(MyVerticle.class, new DeploymentOptions().setInstances(10));
```

or, you can simply deploy more instances of your server verticle by using the `-instances` option on the command line:

```
>  vertx run com.mycompany.MyVerticle -instances 10
```

Once you do this you will find the echo server works functionally identically to before, but all your cores on your server can be utilised and more work can be handled.

At this point you might be asking yourself **'How can you have more than one server listening on the same host and port? Surely you will get port conflicts as soon as you try and deploy more than one instance?'**

*Vert.x does a little magic here.\**

When you deploy another server on the same host and port as an existing server it doesn’t actually try and create a new server listening on the same host/port.

Instead it internally maintains just a single server, and, as incoming connections arrive it distributes them in a round-robin fashion to any of the connect handlers.

Consequently Vert.x TCP servers can scale over available cores while each instance remains single threaded.

### [Creating a TCP client](#_creating_a_tcp_client)

The simplest way to create a TCP client, using all default options is as follows:

```
NetClient client = vertx.createNetClient();
```

### [Configuring a TCP client](#_configuring_a_tcp_client)

If you don’t want the default, a client can be configured by passing in a `[NetClientOptions](../../apidocs/io/vertx/core/net/NetClientOptions.html)` instance when creating it:

```
NetClientOptions options = new NetClientOptions().setConnectTimeout(10000);
NetClient client = vertx.createNetClient(options);
```

### [Making connections](#_making_connections)

To make a connection to a server you use `[connect](../../apidocs/io/vertx/core/net/NetClient.html#connect-int-java.lang.String-io.vertx.core.Handler-)`, specifying the port and host of the server and a handler that will be called with a result containing the `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` when connection is successful or with a failure if connection failed.

```
NetClientOptions options = new NetClientOptions().setConnectTimeout(10000);
NetClient client = vertx.createNetClient(options);
client
  .connect(4321, "localhost")
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Connected!");
      NetSocket socket = res.result();
    } else {
      System.out.println("Failed to connect: " + res.cause().getMessage());
    }
  });
```

### [Configuring connection attempts](#_configuring_connection_attempts)

A client can be configured to automatically retry connecting to the server in the event that it cannot connect. This is configured with `[setReconnectInterval](../../apidocs/io/vertx/core/net/NetClientOptions.html#setReconnectInterval-long-)` and `[setReconnectAttempts](../../apidocs/io/vertx/core/net/NetClientOptions.html#setReconnectAttempts-int-)`.

|  | Currently, Vert.x will not attempt to reconnect if a connection fails, reconnect attempts and interval only apply to creating initial connections. |
| --- | --- |

```
NetClientOptions options = new NetClientOptions().
  setReconnectAttempts(10).
  setReconnectInterval(500);

NetClient client = vertx.createNetClient(options);
```

By default, multiple connection attempts are disabled.

### [Logging network activity](#logging_network_activity)

For debugging purposes, network activity can be logged:

```
NetServerOptions options = new NetServerOptions().setLogActivity(true);

NetServer server = vertx.createNetServer(options);
```

Here is the output of a simple HTTP server

```
id: 0x359e3df6, L:/127.0.0.1:8080 - R:/127.0.0.1:65351] READ: 78B
        +-------------------------------------------------+
        |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 47 45 54 20 2f 20 48 54 54 50 2f 31 2e 31 0d 0a |GET / HTTP/1.1..|
|00000010| 48 6f 73 74 3a 20 6c 6f 63 61 6c 68 6f 73 74 3a |Host: localhost:|
|00000020| 38 30 38 30 0d 0a 55 73 65 72 2d 41 67 65 6e 74 |8080..User-Agent|
|00000030| 3a 20 63 75 72 6c 2f 37 2e 36 34 2e 31 0d 0a 41 |: curl/7.64.1..A|
|00000040| 63 63 65 70 74 3a 20 2a 2f 2a 0d 0a 0d 0a       |ccept: */*....  |
+--------+-------------------------------------------------+----------------+
[id: 0x359e3df6, L:/127.0.0.1:8080 - R:/127.0.0.1:65351] WRITE: 50B
        +-------------------------------------------------+
        |  0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f |
+--------+-------------------------------------------------+----------------+
|00000000| 48 54 54 50 2f 31 2e 31 20 32 30 30 20 4f 4b 0d |HTTP/1.1 200 OK.|
|00000010| 0a 63 6f 6e 74 65 6e 74 2d 6c 65 6e 67 74 68 3a |.content-length:|
|00000020| 20 31 31 0d 0a 0d 0a 48 65 6c 6c 6f 20 57 6f 72 | 11....Hello Wor|
|00000030| 6c 64                                           |ld              |
+--------+-------------------------------------------------+----------------+
[id: 0x359e3df6, L:/127.0.0.1:8080 - R:/127.0.0.1:65351] READ COMPLETE
[id: 0x359e3df6, L:/127.0.0.1:8080 - R:/127.0.0.1:65351] FLUSH
```

By default, binary data is logged in hex format.

You can reduce the data format verbosity to only print the buffer length instead of the entire data by setting the log data fomat.

```
NetServerOptions options = new NetServerOptions()
  .setLogActivity(true)
  .setActivityLogDataFormat(ByteBufFormat.SIMPLE);

NetServer server = vertx.createNetServer(options);
```

Here is the same output with simple buffer format

```
[id: 0xda8d41dc, L:/127.0.0.1:8080 - R:/127.0.0.1:65399] READ: 78B
[id: 0xda8d41dc, L:/127.0.0.1:8080 - R:/127.0.0.1:65399] WRITE: 50B
[id: 0xda8d41dc, L:/127.0.0.1:8080 - R:/127.0.0.1:65399] READ COMPLETE
[id: 0xda8d41dc, L:/127.0.0.1:8080 - R:/127.0.0.1:65399] FLUSH
[id: 0xda8d41dc, L:/127.0.0.1:8080 - R:/127.0.0.1:65399] READ COMPLETE
[id: 0xda8d41dc, L:/127.0.0.1:8080 ! R:/127.0.0.1:65399] INACTIVE
[id: 0xda8d41dc, L:/127.0.0.1:8080 ! R:/127.0.0.1:65399] UNREGISTERED
```

Clients can also log network activity

```
NetClientOptions options = new NetClientOptions().setLogActivity(true);

NetClient client = vertx.createNetClient(options);
```

Network activity is logged by Netty with the `DEBUG` level and with the `io.netty.handler.logging.LoggingHandler` name. When using network activity logging there are a few things to keep in mind:

* logging is not performed by Vert.x logging but by Netty
* this is **not** a production feature

You should read the [Netty logging](#netty-logging) section.

### [Throttling inbound and outbound bandwidth of TCP connections](#_throttling_inbound_and_outbound_bandwidth_of_tcp_connections)

TCP server (Net/Http) can be configured with traffic shaping options to enable bandwidth limiting. Both inbound and outbound bandwidth can be limited through `[TrafficShapingOptions](../../apidocs/io/vertx/core/net/TrafficShapingOptions.html)`. For NetServer, traffic shaping options can be set through `[NetServerOptions](../../apidocs/io/vertx/core/net/NetServerOptions.html)` and for HttpServer it can be set through `[HttpServerOptions](../../apidocs/io/vertx/core/http/HttpServerOptions.html)`.

```
NetServerOptions options = new NetServerOptions()
  .setHost("localhost")
  .setPort(1234)
  .setTrafficShapingOptions(new TrafficShapingOptions()
    .setInboundGlobalBandwidth(64 * 1024)
    .setOutboundGlobalBandwidth(128 * 1024));

NetServer server = vertx.createNetServer(options);
```

```
HttpServerOptions options = new HttpServerOptions()
  .setHost("localhost")
  .setPort(1234)
  .setTrafficShapingOptions(new TrafficShapingOptions()
    .setInboundGlobalBandwidth(64 * 1024)
    .setOutboundGlobalBandwidth(128 * 1024));

HttpServer server = vertx.createHttpServer(options);
```

These traffic shaping options can also be dynamically updated after server start.

```
NetServerOptions options = new NetServerOptions()
                             .setHost("localhost")
                             .setPort(1234)
                             .setTrafficShapingOptions(new TrafficShapingOptions()
                                                         .setInboundGlobalBandwidth(64 * 1024)
                                                         .setOutboundGlobalBandwidth(128 * 1024));
NetServer server = vertx.createNetServer(options);
TrafficShapingOptions update = new TrafficShapingOptions()
                                 .setInboundGlobalBandwidth(2 * 64 * 1024) // twice
                                 .setOutboundGlobalBandwidth(128 * 1024); // unchanged
server
  .listen(1234, "localhost")
  // wait until traffic shaping handler is created for updates
  .onSuccess(v -> server.updateTrafficShapingOptions(update));
```

```
HttpServerOptions options = new HttpServerOptions()
                              .setHost("localhost")
                              .setPort(1234)
                              .setTrafficShapingOptions(new TrafficShapingOptions()
                                                          .setInboundGlobalBandwidth(64 * 1024)
                                                          .setOutboundGlobalBandwidth(128 * 1024));
HttpServer server = vertx.createHttpServer(options);
TrafficShapingOptions update = new TrafficShapingOptions()
                                 .setInboundGlobalBandwidth(2 * 64 * 1024) // twice
                                 .setOutboundGlobalBandwidth(128 * 1024); // unchanged
server
  .listen(1234, "localhost")
  // wait until traffic shaping handler is created for updates
  .onSuccess(v -> server.updateTrafficShapingOptions(update));
```

### [Configuring servers and clients to work with SSL/TLS](#ssl)

TCP clients and servers can be configured to use [Transport Layer Security](https://en.wikipedia.org/wiki/Transport_Layer_Security) - earlier versions of TLS were known as SSL.

The APIs of the servers and clients are identical whether or not SSL/TLS is used, and it’s enabled by configuring the `[NetClientOptions](../../apidocs/io/vertx/core/net/NetClientOptions.html)` or `[NetServerOptions](../../apidocs/io/vertx/core/net/NetServerOptions.html)` instances used to create the servers or clients.

#### [Enabling SSL/TLS on the server](#_enabling_ssltls_on_the_server)

SSL/TLS is enabled with `[ssl](../../apidocs/io/vertx/core/net/NetServerOptions.html#setSsl-boolean-)`.

By default it is disabled.

#### [Specifying key/certificate for the server](#_specifying_keycertificate_for_the_server)

SSL/TLS servers usually provide certificates to clients in order verify their identity to clients.

Certificates/keys can be configured for servers in several ways:

The first method is by specifying the location of a Java key-store which contains the certificate and private key.

Java key stores can be managed with the [keytool](http://docs.oracle.com/javase/6/docs/technotes/tools/solaris/keytool.html) utility which ships with the JDK.

The password for the key store should also be provided:

```
NetServerOptions options = new NetServerOptions().setSsl(true).setKeyStoreOptions(
  new JksOptions().
    setPath("/path/to/your/server-keystore.jks").
    setPassword("password-of-your-keystore")
);
NetServer server = vertx.createNetServer(options);
```

Alternatively you can read the key store yourself as a buffer and provide that directly:

```
Buffer myKeyStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/server-keystore.jks");
JksOptions jksOptions = new JksOptions().
  setValue(myKeyStoreAsABuffer).
  setPassword("password-of-your-keystore");
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(jksOptions);
NetServer server = vertx.createNetServer(options);
```

Key/certificate in PKCS#12 format ([http://en.wikipedia.org/wiki/PKCS\_12](https://en.wikipedia.org/wiki/PKCS_12)), usually with the `.pfx` or the `.p12` extension can also be loaded in a similar fashion than JKS key stores:

```
NetServerOptions options = new NetServerOptions().setSsl(true).setPfxKeyCertOptions(
  new PfxOptions().
    setPath("/path/to/your/server-keystore.pfx").
    setPassword("password-of-your-keystore")
);
NetServer server = vertx.createNetServer(options);
```

Buffer configuration is also supported:

```
Buffer myKeyStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/server-keystore.pfx");
PfxOptions pfxOptions = new PfxOptions().
  setValue(myKeyStoreAsABuffer).
  setPassword("password-of-your-keystore");
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setPfxKeyCertOptions(pfxOptions);
NetServer server = vertx.createNetServer(options);
```

Another way of providing server private key and certificate separately using `.pem` files.

```
NetServerOptions options = new NetServerOptions().setSsl(true).setPemKeyCertOptions(
  new PemKeyCertOptions().
    setKeyPath("/path/to/your/server-key.pem").
    setCertPath("/path/to/your/server-cert.pem")
);
NetServer server = vertx.createNetServer(options);
```

Buffer configuration is also supported:

```
Buffer myKeyAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/server-key.pem");
Buffer myCertAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/server-cert.pem");
PemKeyCertOptions pemOptions = new PemKeyCertOptions().
  setKeyValue(myKeyAsABuffer).
  setCertValue(myCertAsABuffer);
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setPemKeyCertOptions(pemOptions);
NetServer server = vertx.createNetServer(options);
```

Vert.x supports reading of unencrypted RSA and/or ECC based private keys from PKCS8 PEM files. RSA based private keys can also be read from PKCS1 PEM files. X.509 certificates can be read from PEM files containing a textual encoding of the certificate as defined by [RFC 7468, Section 5](https://tools.ietf.org/html/rfc7468#section-5).

|  | Keep in mind that the keys contained in an unencrypted PKCS8 or a PKCS1 PEM file can be extracted by anybody who can read the file. Thus, make sure to put proper access restrictions on such PEM files in order to prevent misuse. |
| --- | --- |

Finally, you can also load generic Java keystore, it is useful for using other KeyStore implementations like Bouncy Castle:

```
NetServerOptions options = new NetServerOptions().setSsl(true).setKeyCertOptions(
  new KeyStoreOptions().
    setType("BKS").
    setPath("/path/to/your/server-keystore.bks").
    setPassword("password-of-your-keystore")
);
NetServer server = vertx.createNetServer(options);
```

#### [Specifying trust for the server](#_specifying_trust_for_the_server)

SSL/TLS servers can use a certificate authority in order to verify the identity of the clients.

Certificate authorities can be configured for servers in several ways:

Java trust stores can be managed with the [keytool](http://docs.oracle.com/javase/6/docs/technotes/tools/solaris/keytool.html) utility which ships with the JDK.

The password for the trust store should also be provided:

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setClientAuth(ClientAuth.REQUIRED).
  setTrustStoreOptions(
    new JksOptions().
      setPath("/path/to/your/truststore.jks").
      setPassword("password-of-your-truststore")
  );
NetServer server = vertx.createNetServer(options);
```

Alternatively you can read the trust store yourself as a buffer and provide that directly:

```
Buffer myTrustStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/truststore.jks");
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setClientAuth(ClientAuth.REQUIRED).
  setTrustStoreOptions(
    new JksOptions().
      setValue(myTrustStoreAsABuffer).
      setPassword("password-of-your-truststore")
  );
NetServer server = vertx.createNetServer(options);
```

Certificate authority in PKCS#12 format ([http://en.wikipedia.org/wiki/PKCS\_12](https://en.wikipedia.org/wiki/PKCS_12)), usually with the `.pfx` or the `.p12` extension can also be loaded in a similar fashion than JKS trust stores:

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setClientAuth(ClientAuth.REQUIRED).
  setPfxTrustOptions(
    new PfxOptions().
      setPath("/path/to/your/truststore.pfx").
      setPassword("password-of-your-truststore")
  );
NetServer server = vertx.createNetServer(options);
```

Buffer configuration is also supported:

```
Buffer myTrustStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/truststore.pfx");
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setClientAuth(ClientAuth.REQUIRED).
  setPfxTrustOptions(
    new PfxOptions().
      setValue(myTrustStoreAsABuffer).
      setPassword("password-of-your-truststore")
  );
NetServer server = vertx.createNetServer(options);
```

Another way of providing server certificate authority using a list `.pem` files.

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setClientAuth(ClientAuth.REQUIRED).
  setPemTrustOptions(
    new PemTrustOptions().
      addCertPath("/path/to/your/server-ca.pem")
  );
NetServer server = vertx.createNetServer(options);
```

Buffer configuration is also supported:

```
Buffer myCaAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/server-ca.pfx");
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setClientAuth(ClientAuth.REQUIRED).
  setPemTrustOptions(
    new PemTrustOptions().
      addCertValue(myCaAsABuffer)
  );
NetServer server = vertx.createNetServer(options);
```

#### [Enabling SSL/TLS on the client](#_enabling_ssltls_on_the_client)

Net Clients can also be easily configured to use SSL. They have the exact same API when using SSL as when using standard sockets.

To enable SSL on a NetClient the function setSSL(true) is called.

#### [Client trust configuration](#_client_trust_configuration)

If the `[trustALl](../../apidocs/io/vertx/core/net/ClientOptionsBase.html#setTrustAll-boolean-)` is set to true on the client, then the client will trust all server certificates. The connection will still be encrypted but this mode is vulnerable to 'man in the middle' attacks. I.e. you can’t be sure who you are connecting to. Use this with caution. Default value is false.

```
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setTrustAll(true);
NetClient client = vertx.createNetClient(options);
```

If `[trustAll](../../apidocs/io/vertx/core/net/ClientOptionsBase.html#setTrustAll-boolean-)` is not set then a client trust store must be configured and should contain the certificates of the servers that the client trusts.

By default, host verification is **not** configured on the client. This verifies the CN portion of the server certificate against the server hostname to avoid [Man-in-the-middle attacks](https://en.wikipedia.org/wiki/Man-in-the-middle_attack).

You must configure it explicitly on your client

* `""` (empty string) disables host verification
* `"HTTPS"` enables HTTP over TLS [verification](https://datatracker.ietf.org/doc/html/rfc2818#section-3.1)
* `LDAPS` enables LDAP v3 extension for TLS [verification](https://datatracker.ietf.org/doc/html/rfc2830#section-3.6)

```
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setHostnameVerificationAlgorithm(verificationAlgorithm);
NetClient client = vertx.createNetClient(options);
```

|  | the Vert.x HTTP client uses the TCP client and configures with `"HTTPS"` the verification algorithm. |
| --- | --- |

Like server configuration, the client trust can be configured in several ways:

The first method is by specifying the location of a Java trust-store which contains the certificate authority.

It is just a standard Java key store, the same as the key stores on the server side. The client trust store location is set by using the function `[path](../../apidocs/io/vertx/core/net/JksOptions.html#setPath-java.lang.String-)` on the `[jks options](../../apidocs/io/vertx/core/net/JksOptions.html)`. If a server presents a certificate during connection which is not in the client trust store, the connection attempt will not succeed.

```
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setTrustStoreOptions(
    new JksOptions().
      setPath("/path/to/your/truststore.jks").
      setPassword("password-of-your-truststore")
  );
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myTrustStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/truststore.jks");
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setTrustStoreOptions(
    new JksOptions().
      setValue(myTrustStoreAsABuffer).
      setPassword("password-of-your-truststore")
  );
NetClient client = vertx.createNetClient(options);
```

Certificate authority in PKCS#12 format ([http://en.wikipedia.org/wiki/PKCS\_12](https://en.wikipedia.org/wiki/PKCS_12)), usually with the `.pfx` or the `.p12` extension can also be loaded in a similar fashion than JKS trust stores:

```
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setPfxTrustOptions(
    new PfxOptions().
      setPath("/path/to/your/truststore.pfx").
      setPassword("password-of-your-truststore")
  );
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myTrustStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/truststore.pfx");
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setPfxTrustOptions(
    new PfxOptions().
      setValue(myTrustStoreAsABuffer).
      setPassword("password-of-your-truststore")
  );
NetClient client = vertx.createNetClient(options);
```

Another way of providing server certificate authority using a list `.pem` files.

```
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setPemTrustOptions(
    new PemTrustOptions().
      addCertPath("/path/to/your/ca-cert.pem")
  );
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myTrustStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/ca-cert.pem");
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setPemTrustOptions(
    new PemTrustOptions().
      addCertValue(myTrustStoreAsABuffer)
  );
NetClient client = vertx.createNetClient(options);
```

#### [Specifying key/certificate for the client](#_specifying_keycertificate_for_the_client)

If the server requires client authentication then the client must present its own certificate to the server when connecting. The client can be configured in several ways:

The first method is by specifying the location of a Java key-store which contains the key and certificate. Again it’s just a regular Java key store. The client keystore location is set by using the function `[path](../../apidocs/io/vertx/core/net/JksOptions.html#setPath-java.lang.String-)` on the `[jks options](../../apidocs/io/vertx/core/net/JksOptions.html)`.

```
NetClientOptions options = new NetClientOptions().setSsl(true).setKeyStoreOptions(
  new JksOptions().
    setPath("/path/to/your/client-keystore.jks").
    setPassword("password-of-your-keystore")
);
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myKeyStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/client-keystore.jks");
JksOptions jksOptions = new JksOptions().
  setValue(myKeyStoreAsABuffer).
  setPassword("password-of-your-keystore");
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setKeyStoreOptions(jksOptions);
NetClient client = vertx.createNetClient(options);
```

Key/certificate in PKCS#12 format ([http://en.wikipedia.org/wiki/PKCS\_12](https://en.wikipedia.org/wiki/PKCS_12)), usually with the `.pfx` or the `.p12` extension can also be loaded in a similar fashion than JKS key stores:

```
NetClientOptions options = new NetClientOptions().setSsl(true).setPfxKeyCertOptions(
  new PfxOptions().
    setPath("/path/to/your/client-keystore.pfx").
    setPassword("password-of-your-keystore")
);
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myKeyStoreAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/client-keystore.pfx");
PfxOptions pfxOptions = new PfxOptions().
  setValue(myKeyStoreAsABuffer).
  setPassword("password-of-your-keystore");
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setPfxKeyCertOptions(pfxOptions);
NetClient client = vertx.createNetClient(options);
```

Another way of providing server private key and certificate separately using `.pem` files.

```
NetClientOptions options = new NetClientOptions().setSsl(true).setPemKeyCertOptions(
  new PemKeyCertOptions().
    setKeyPath("/path/to/your/client-key.pem").
    setCertPath("/path/to/your/client-cert.pem")
);
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myKeyAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/client-key.pem");
Buffer myCertAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/client-cert.pem");
PemKeyCertOptions pemOptions = new PemKeyCertOptions().
  setKeyValue(myKeyAsABuffer).
  setCertValue(myCertAsABuffer);
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setPemKeyCertOptions(pemOptions);
NetClient client = vertx.createNetClient(options);
```

Keep in mind that pem configuration, the private key is not crypted.

#### [Updating SSL/TLS configuration](#_updating_ssltls_configuration)

You can use the `updateSSLOptions` method to update the key/certifications or trust on a TCP server or client (e.g. to implement certificate rotation).

```
Future<Boolean> fut = server.updateSSLOptions(new SSLOptions()
  .setKeyCertOptions(
    new JksOptions()
      .setPath("/path/to/your/server-keystore.jks").
      setPassword("password-of-your-keystore")));
```

When the update succeeds the new SSL configuration is used, otherwise the previous configuration is preserved.

|  | The options object is compared (using `equals`) against the existing options to prevent an update when the objects are equals since loading options can be costly. When object are equals, you can use the `force` parameter to force the update. |
| --- | --- |

#### [Self-signed certificates for testing and development purposes](#_self_signed_certificates_for_testing_and_development_purposes)

|  | Do not use this in production settings, and note that the generated keys are very insecure. |
| --- | --- |

It is very often the case that self-signed certificates are required, be it for unit / integration tests or for running a development version of an application.

`[SelfSignedCertificate](../../apidocs/io/vertx/core/net/SelfSignedCertificate.html)` can be used to provide self-signed PEM certificate helpers and give `[KeyCertOptions](../../apidocs/io/vertx/core/net/KeyCertOptions.html)` and `[TrustOptions](../../apidocs/io/vertx/core/net/TrustOptions.html)` configurations:

```
SelfSignedCertificate certificate = SelfSignedCertificate.create();

NetServerOptions serverOptions = new NetServerOptions()
  .setSsl(true)
  .setKeyCertOptions(certificate.keyCertOptions())
  .setTrustOptions(certificate.trustOptions());

vertx.createNetServer(serverOptions)
  .connectHandler(socket -> socket.end(Buffer.buffer("Hello!")))
  .listen(1234, "localhost");

NetClientOptions clientOptions = new NetClientOptions()
  .setSsl(true)
  .setKeyCertOptions(certificate.keyCertOptions())
  .setTrustOptions(certificate.trustOptions());

NetClient client = vertx.createNetClient(clientOptions);
client
  .connect(1234, "localhost")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      ar.result().handler(buffer -> System.out.println(buffer));
    } else {
      System.err.println("Woops: " + ar.cause().getMessage());
    }
  });
```

The client can also be configured to trust all certificates:

```
NetClientOptions clientOptions = new NetClientOptions()
  .setSsl(true)
  .setTrustAll(true);
```

Note that self-signed certificates also work for other TCP protocols like HTTPS:

```
SelfSignedCertificate certificate = SelfSignedCertificate.create();

vertx.createHttpServer(new HttpServerOptions()
  .setSsl(true)
  .setKeyCertOptions(certificate.keyCertOptions())
  .setTrustOptions(certificate.trustOptions()))
  .requestHandler(req -> req.response().end("Hello!"))
  .listen(8080);
```

#### [Revoking certificate authorities](#_revoking_certificate_authorities)

Trust can be configured to use a certificate revocation list (CRL) for revoked certificates that should no longer be trusted. The `[crlPath](../../apidocs/io/vertx/core/net/NetClientOptions.html#addCrlPath-java.lang.String-)` configures the crl list to use:

```
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setTrustStoreOptions(trustOptions).
  addCrlPath("/path/to/your/crl.pem");
NetClient client = vertx.createNetClient(options);
```

Buffer configuration is also supported:

```
Buffer myCrlAsABuffer = vertx.fileSystem().readFileBlocking("/path/to/your/crl.pem");
NetClientOptions options = new NetClientOptions().
  setSsl(true).
  setTrustStoreOptions(trustOptions).
  addCrlValue(myCrlAsABuffer);
NetClient client = vertx.createNetClient(options);
```

#### [Configuring the Cipher suite](#_configuring_the_cipher_suite)

By default, the TLS configuration will use the list of Cipher suites of the SSL engine:

* JDK SSL engine when `[JdkSSLEngineOptions](../../apidocs/io/vertx/core/net/JdkSSLEngineOptions.html)` is used
* OpenSSL engine when `[OpenSSLEngineOptions](../../apidocs/io/vertx/core/net/OpenSSLEngineOptions.html)` is used

This Cipher suite can be configured with a suite of enabled ciphers:

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(keyStoreOptions).
  addEnabledCipherSuite("ECDHE-RSA-AES128-GCM-SHA256").
  addEnabledCipherSuite("ECDHE-ECDSA-AES128-GCM-SHA256").
  addEnabledCipherSuite("ECDHE-RSA-AES256-GCM-SHA384").
  addEnabledCipherSuite("CDHE-ECDSA-AES256-GCM-SHA384");
NetServer server = vertx.createNetServer(options);
```

When the enabled cipher suites is defined (i.e not empty), it takes precedence over the default cipher suites of the SSL engine.

Cipher suite can be specified on the `[NetServerOptions](../../apidocs/io/vertx/core/net/NetServerOptions.html)` or `[NetClientOptions](../../apidocs/io/vertx/core/net/NetClientOptions.html)` configuration.

#### [Configuring TLS protocol versions](#_configuring_tls_protocol_versions)

By default, the default TLS configuration enables the following protocols: TLSv1.2 and TLSv1.3. Protocol versions can be enabled by explicitly adding them:

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(keyStoreOptions).
  addEnabledSecureTransportProtocol("TLSv1.1");
NetServer server = vertx.createNetServer(options);
```

They can also be removed:

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(keyStoreOptions).
  removeEnabledSecureTransportProtocol("TLSv1.2");
NetServer server = vertx.createNetServer(options);
```

Protocol versions can be specified on the `[NetServerOptions](../../apidocs/io/vertx/core/net/NetServerOptions.html)` or `[NetClientOptions](../../apidocs/io/vertx/core/net/NetClientOptions.html)` configuration.

|  | TLS 1.0 (TLSv1) and TLS 1.1 (TLSv1.1) are widely deprecated and have been disabled by default since Vert.x 4.4.0. |
| --- | --- |

#### [SSL engine](#_ssl_engine)

The engine implementation can be configured to use [OpenSSL](https://www.openssl.org) instead of the JDK implementation. Before JDK started to use hardware intrinsics (CPU instructions) for AES in Java 8 and for RSA in Java 9, OpenSSL provided much better performances and CPU usage than the JDK engine.

The engine options to use is

* the `[getSslEngineOptions](../../apidocs/io/vertx/core/net/TCPSSLOptions.html#getSslEngineOptions--)` options when it is set
* otherwise `[JdkSSLEngineOptions](../../apidocs/io/vertx/core/net/JdkSSLEngineOptions.html)`

```
NetServerOptions options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(keyStoreOptions);

// Use JDK SSL engine explicitly
options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(keyStoreOptions).
  setJdkSslEngineOptions(new JdkSSLEngineOptions());

// Use OpenSSL engine
options = new NetServerOptions().
  setSsl(true).
  setKeyStoreOptions(keyStoreOptions).
  setOpenSslEngineOptions(new OpenSSLEngineOptions());
```

#### [Server Name Indication (SNI)](#_server_name_indication_sni)

Server Name Indication (SNI) is a TLS extension by which a client specifies a hostname attempting to connect: during the TLS handshake the client gives a server name and the server can use it to respond with a specific certificate for this server name instead of the default deployed certificate. If the server requires client authentication the server can use a specific trusted CA certificate depending on the indicated server name.

When SNI is active the server uses

* the certificate CN or SAN DNS (Subject Alternative Name with DNS) to do an exact match, e.g `www.example.com`
* the certificate CN or SAN DNS certificate to match a wildcard name, e.g `*.example.com`
* otherwise the first certificate when the client does not present a server name or the presented server name cannot be matched

When the server additionally requires client authentication:

* if `[JksOptions](../../apidocs/io/vertx/core/net/JksOptions.html)` were used to set the trust options (`[options](../../apidocs/io/vertx/core/net/NetServerOptions.html#setTrustOptions-io.vertx.core.net.TrustOptions-)`) then an exact match with the trust store alias is done
* otherwise the available CA certificates are used in the same way as if no SNI is in place

You can enable SNI on the server by setting `[setSni](../../apidocs/io/vertx/core/net/NetServerOptions.html#setSni-boolean-)` to `true` and configured the server with multiple key/certificate pairs.

Java KeyStore files or PKCS12 files can store multiple key/cert pairs out of the box.

```
JksOptions keyCertOptions = new JksOptions().setPath("keystore.jks").setPassword("wibble");

NetServer netServer = vertx.createNetServer(new NetServerOptions()
    .setKeyStoreOptions(keyCertOptions)
    .setSsl(true)
    .setSni(true)
);
```

`[PemKeyCertOptions](../../apidocs/io/vertx/core/net/PemKeyCertOptions.html)` can be configured to hold multiple entries:

```
PemKeyCertOptions keyCertOptions = new PemKeyCertOptions()
    .setKeyPaths(Arrays.asList("default-key.pem", "host1-key.pem", "etc..."))
    .setCertPaths(Arrays.asList("default-cert.pem", "host2-key.pem", "etc...")
    );

NetServer netServer = vertx.createNetServer(new NetServerOptions()
    .setPemKeyCertOptions(keyCertOptions)
    .setSsl(true)
    .setSni(true)
);
```

The client implicitly sends the connecting host as an SNI server name for Fully Qualified Domain Name (FQDN).

You can provide an explicit server name when connecting a socket

```
NetClient client = vertx.createNetClient(new NetClientOptions()
    .setTrustStoreOptions(trustOptions)
    .setSsl(true)
);

// Connect to 'localhost' and present 'server.name' server name
client
  .connect(1234, "localhost", "server.name")
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Connected!");
      NetSocket socket = res.result();
    } else {
      System.out.println("Failed to connect: " + res.cause().getMessage());
    }
  });
```

It can be used for different purposes:

* present a server name different than the server host
* present a server name while connecting to an IP
* force to present a server name when using shortname

#### [Application-Layer Protocol Negotiation (ALPN)](#_application_layer_protocol_negotiation_alpn)

Application-Layer Protocol Negotiation (ALPN) is a TLS extension for application layer protocol negotiation. It is used by HTTP/2: during the TLS handshake the client gives the list of application protocols it accepts and the server responds with a protocol it supports.

Java TLS supports ALPN (Java 8 with the most recent versions).

##### [OpenSSL ALPN support](#_openssl_alpn_support)

OpenSSL also supports (native) ALPN.

OpenSSL requires to configure `[setOpenSslEngineOptions](../../apidocs/io/vertx/core/net/TCPSSLOptions.html#setOpenSslEngineOptions-io.vertx.core.net.OpenSSLEngineOptions-)` and use [netty-tcnative](http://netty.io/wiki/forked-tomcat-native.html) jar on the classpath. Using tcnative may require OpenSSL to be installed on your OS depending on the tcnative implementation.

### [Using a proxy for client connections](#_using_a_proxy_for_client_connections)

The `[NetClient](../../apidocs/io/vertx/core/net/NetClient.html)` supports either a HTTP/1.x *CONNECT*, *SOCKS4a* or *SOCKS5* proxy.

The proxy can be configured in the `[NetClientOptions](../../apidocs/io/vertx/core/net/NetClientOptions.html)` by setting a `[ProxyOptions](../../apidocs/io/vertx/core/net/ProxyOptions.html)` object containing proxy type, hostname, port and optionally username and password.

Here’s an example:

```
NetClientOptions options = new NetClientOptions()
  .setProxyOptions(new ProxyOptions().setType(ProxyType.SOCKS5)
    .setHost("localhost").setPort(1080)
    .setUsername("username").setPassword("secret"));
NetClient client = vertx.createNetClient(options);
```

The DNS resolution is always done on the proxy server, to achieve the functionality of a SOCKS4 client, it is necessary to resolve the DNS address locally.

You can use `[setNonProxyHosts](../../apidocs/io/vertx/core/net/NetClientOptions.html#setNonProxyHosts-java.util.List-)` to configure a list of host bypassing the proxy. The lists accepts `*` wildcard for matching domains:

```
NetClientOptions options = new NetClientOptions()
  .setProxyOptions(new ProxyOptions().setType(ProxyType.SOCKS5)
    .setHost("localhost").setPort(1080)
    .setUsername("username").setPassword("secret"))
  .addNonProxyHost("*.foo.com")
  .addNonProxyHost("localhost");
NetClient client = vertx.createNetClient(options);
```

### [Using HA PROXY protocol](#_using_ha_proxy_protocol)

[HA PROXY protocol](https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt) provides a convenient way to safely transport connection information such as a client’s address across multiple layers of NAT or TCP proxies.

HA PROXY protocol can be enabled by setting the option `[setUseProxyProtocol](../../apidocs/io/vertx/core/net/NetServerOptions.html#setUseProxyProtocol-boolean-)` and adding the following dependency in your classpath:

```
<dependency>
 <groupId>io.netty</groupId>
 <artifactId>netty-codec-haproxy</artifactId>
 <!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
```

```
NetServerOptions options = new NetServerOptions().setUseProxyProtocol(true);
NetServer server = vertx.createNetServer(options);
server.connectHandler(so -> {
  // Print the actual client address provided by the HA proxy protocol instead of the proxy address
  System.out.println(so.remoteAddress());

  // Print the address of the proxy
  System.out.println(so.localAddress());
});
```

## [Writing HTTP servers and clients](#_writing_http_servers_and_clients)

Vert.x allows you to easily write non blocking HTTP clients and servers.

Vert.x supports the HTTP/1.0, HTTP/1.1 and HTTP/2 protocols.

The base API for HTTP is the same for HTTP/1.x and HTTP/2, specific API features are available for dealing with the HTTP/2 protocol.

### [Creating an HTTP Server](#_creating_an_http_server)

The simplest way to create an HTTP server, using all default options is as follows:

```
HttpServer server = vertx.createHttpServer();
```

### [Configuring an HTTP server](#_configuring_an_http_server)

If you don’t want the default, a server can be configured by passing in a `[HttpServerOptions](../../apidocs/io/vertx/core/http/HttpServerOptions.html)` instance when creating it:

```
HttpServerOptions options = new HttpServerOptions().setMaxWebSocketFrameSize(1000000);

HttpServer server = vertx.createHttpServer(options);
```

### [Configuring an HTTP/2 server](#_configuring_an_http2_server)

Vert.x supports HTTP/2 over TLS `h2` and over TCP `h2c`.

* `h2` identifies the HTTP/2 protocol when used over TLS negotiated by [Application-Layer Protocol Negotiation](https://en.wikipedia.org/wiki/Application-Layer_Protocol_Negotiation) (ALPN)
* `h2c` identifies the HTTP/2 protocol when using in clear text over TCP, such connections are established either with an HTTP/1.1 upgraded request or directly

To handle `h2` requests, TLS must be enabled along with `[setUseAlpn](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setUseAlpn-boolean-)`:

```
HttpServerOptions options = new HttpServerOptions()
    .setUseAlpn(true)
    .setSsl(true)
    .setKeyStoreOptions(new JksOptions().setPath("/path/to/my/keystore"));

HttpServer server = vertx.createHttpServer(options);
```

ALPN is a TLS extension that negotiates the protocol before the client and the server start to exchange data.

Clients that don’t support ALPN will still be able to do a *classic* SSL handshake.

ALPN will usually agree on the `h2` protocol, although `http/1.1` can be used if the server or the client decides so.

To handle `h2c` requests, TLS must be disabled, the server will upgrade to HTTP/2 any request HTTP/1.1 that wants to upgrade to HTTP/2. It will also accept a direct `h2c` connection beginning with the `PRI * HTTP/2.0\r\nSM\r\n` preface.

|  | most browsers won’t support `h2c`, so for serving web sites you should use `h2` and not `h2c`. |
| --- | --- |

When a server accepts an HTTP/2 connection, it sends to the client its `[initial settings](../../apidocs/io/vertx/core/http/HttpServerOptions.html#getInitialSettings--)`. The settings define how the client can use the connection, the default initial settings for a server are:

* `[getMaxConcurrentStreams](../../apidocs/io/vertx/core/http/Http2Settings.html#getMaxConcurrentStreams--)`: `100` as recommended by the HTTP/2 RFC
* the default HTTP/2 settings values for the others

### [Configuring server supported HTTP versions](#_configuring_server_supported_http_versions)

Default supported HTTP versions depends on the server configuration.

* when TLS is disabled
* HTTP/1.1, HTTP/1.0
* HTTP/2 when `[isHttp2ClearTextEnabled](../../apidocs/io/vertx/core/http/HttpServerOptions.html#isHttp2ClearTextEnabled--)` is `true`
* when TLS is enabled and ALPN disabled
* HTTP/1.1 and HTTP/1.0
* when TLS is enabled and ALPN enabled
* the protocols defined by `[getAlpnVersions](../../apidocs/io/vertx/core/http/HttpServerOptions.html#getAlpnVersions--)`: by default HTTP/1.1 and HTTP/2

If you want to disable HTTP/2 on the server - when TLS is disabled, set `[setHttp2ClearTextEnabled](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setHttp2ClearTextEnabled-boolean-)` to `false` - when TLS is enabled - set (`[isUseAlpn](../../apidocs/io/vertx/core/net/TCPSSLOptions.html#isUseAlpn--)`) to `false` - *or* remove HTTP/2 from the `[getAlpnVersions](../../apidocs/io/vertx/core/http/HttpServerOptions.html#getAlpnVersions--)` list

### [Logging network server activity](#_logging_network_server_activity)

For debugging purposes, network activity can be logged.

```
HttpServerOptions options = new HttpServerOptions().setLogActivity(true);

HttpServer server = vertx.createHttpServer(options);
```

See the chapter on [logging network activity](#logging_network_activity) for a detailed explanation.

### [Start the Server Listening](#_start_the_server_listening_2)

To tell the server to listen for incoming requests you use one of the `[listen](../../apidocs/io/vertx/core/http/HttpServer.html#listen--)` alternatives.

To tell the server to listen at the host and port as specified in the options:

```
HttpServer server = vertx.createHttpServer();
server.listen();
```

Or to specify the host and port in the call to listen, ignoring what is configured in the options:

```
HttpServer server = vertx.createHttpServer();
server.listen(8080, "myhost.com");
```

The default host is `0.0.0.0` which means 'listen on all available addresses' and the default port is `80`.

The actual bind is asynchronous so the server might not actually be listening until some time **after** the call to listen has returned.

If you want to be notified when the server is actually listening you can provide a handler to the `listen` call. For example:

```
HttpServer server = vertx.createHttpServer();
server
  .listen(8080, "myhost.com")
  .onComplete(res -> {
    if (res.succeeded()) {
      System.out.println("Server is now listening!");
    } else {
      System.out.println("Failed to bind!");
    }
  });
```

### [Getting notified of incoming requests](#_getting_notified_of_incoming_requests)

To be notified when a request arrives you need to set a `[requestHandler](../../apidocs/io/vertx/core/http/HttpServer.html#requestHandler-io.vertx.core.Handler-)`:

```
HttpServer server = vertx.createHttpServer();
server.requestHandler(request -> {
  // Handle the request in here
});
```

### [Handling requests](#_handling_requests)

When a request arrives, the request handler is called passing in an instance of `[HttpServerRequest](../../apidocs/io/vertx/core/http/HttpServerRequest.html)`. This object represents the server side HTTP request.

The handler is called when the headers of the request have been fully read.

If the request contains a body, that body will arrive at the server some time after the request handler has been called.

The server request object allows you to retrieve the `[uri](../../apidocs/io/vertx/core/http/HttpServerRequest.html#uri--)`, `[path](../../apidocs/io/vertx/core/http/HttpServerRequest.html#path--)`, `[params](../../apidocs/io/vertx/core/http/HttpServerRequest.html#params--)` and `[headers](../../apidocs/io/vertx/core/http/HttpServerRequest.html#headers--)`, amongst other things.

Each server request object is associated with one server response object. You use `[response](../../apidocs/io/vertx/core/http/HttpServerRequest.html#response--)` to get a reference to the `[HttpServerResponse](../../apidocs/io/vertx/core/http/HttpServerResponse.html)` object.

Here’s a simple example of a server handling a request and replying with "hello world" to it.

```
vertx.createHttpServer().requestHandler(request -> {
  request.response().end("Hello world");
}).listen(8080);
```

#### [Request version](#_request_version)

The version of HTTP specified in the request can be retrieved with `[version](../../apidocs/io/vertx/core/http/HttpServerRequest.html#version--)`

#### [Request method](#_request_method)

Use `[method](../../apidocs/io/vertx/core/http/HttpServerRequest.html#method--)` to retrieve the HTTP method of the request. (i.e. whether it’s GET, POST, PUT, DELETE, HEAD, OPTIONS, etc).

#### [Request URI](#_request_uri)

Use `[uri](../../apidocs/io/vertx/core/http/HttpServerRequest.html#uri--)` to retrieve the URI of the request.

Note that this is the actual URI as passed in the HTTP request, and it’s almost always a relative URI.

The URI is as defined in [Section 5.1.2 of the HTTP specification - Request-URI](http://www.w3.org/Protocols/rfc2616/rfc2616-sec5.html)

#### [Request path](#_request_path)

Use `[path](../../apidocs/io/vertx/core/http/HttpServerRequest.html#path--)` to return the path part of the URI

For example, if the request URI was `a/b/c/page.html?param1=abc&param2=xyz

Then the path would be `/a/b/c/page.html`

#### [Request query](#_request_query)

Use `[query](../../apidocs/io/vertx/core/http/HttpServerRequest.html#query--)` to return the query part of the URI

For example, if the request URI was `a/b/c/page.html?param1=abc&param2=xyz`

Then the query would be `param1=abc&param2=xyz`

#### [Request headers](#_request_headers)

Use `[headers](../../apidocs/io/vertx/core/http/HttpServerRequest.html#headers--)` to return the headers of the HTTP request.

This returns an instance of `[MultiMap](../../apidocs/io/vertx/core/MultiMap.html)` - which is like a normal Map or Hash but allows multiple values for the same key - this is because HTTP allows multiple header values with the same key.

It also has case-insensitive keys, that means you can do the following:

```
MultiMap headers = request.headers();

// Get the User-Agent:
System.out.println("User agent is " + headers.get("user-agent"));

// You can also do this and get the same result:
System.out.println("User agent is " + headers.get("User-Agent"));
```

#### [Request authority](#_request_authority)

Use `[authority](../../apidocs/io/vertx/core/http/HttpServerRequest.html#authority--)` to return the authority of the HTTP request.

For HTTP/1.x requests the `host` header is returned, for HTTP/1 requests the `:authority` pseudo header is returned.

#### [Request parameters](#_request_parameters)

Use `[params](../../apidocs/io/vertx/core/http/HttpServerRequest.html#params--)` to return the parameters of the HTTP request.

Just like `[headers](../../apidocs/io/vertx/core/http/HttpServerRequest.html#headers--)` this returns an instance of `[MultiMap](../../apidocs/io/vertx/core/MultiMap.html)` as there can be more than one parameter with the same name.

Request parameters are sent on the request URI, after the path. For example if the URI was `/page.html?param1=abc&param2=xyz`

Then the parameters would contain the following:

```
param1: 'abc'
param2: 'xyz
```

Note that these request parameters are retrieved from the URL of the request. If you have form attributes that have been sent as part of the submission of an HTML form submitted in the body of a `multi-part/form-data` request then they will not appear in the params here.

#### [Remote address](#_remote_address)

The address of the sender of the request can be retrieved with `[remoteAddress](../../apidocs/io/vertx/core/http/HttpServerRequest.html#remoteAddress--)`.

#### [Absolute URI](#_absolute_uri)

The URI passed in an HTTP request is usually relative. If you wish to retrieve the absolute URI corresponding to the request, you can get it with `[absoluteURI](../../apidocs/io/vertx/core/http/HttpServerRequest.html#absoluteURI--)`

#### [End handler](#_end_handler)

The `[endHandler](../../apidocs/io/vertx/core/http/HttpServerRequest.html#endHandler-io.vertx.core.Handler-)` of the request is invoked when the entire request, including any body has been fully read.

#### [Reading Data from the Request Body](#_reading_data_from_the_request_body)

Often an HTTP request contains a body that we want to read. As previously mentioned the request handler is called when just the headers of the request have arrived so the request object does not have a body at that point.

This is because the body may be very large (e.g. a file upload) and we don’t generally want to buffer the entire body in memory before handing it to you, as that could cause the server to exhaust available memory.

To receive the body, you can use the `[handler](../../apidocs/io/vertx/core/http/HttpServerRequest.html#handler-io.vertx.core.Handler-)` on the request, this will get called every time a chunk of the request body arrives. Here’s an example:

```
request.handler(buffer -> {
  System.out.println("I have received a chunk of the body of length " + buffer.length());
});
```

The object passed into the handler is a `[Buffer](../../apidocs/io/vertx/core/buffer/Buffer.html)`, and the handler can be called multiple times as data arrives from the network, depending on the size of the body.

In some cases (e.g. if the body is small) you will want to aggregate the entire body in memory, so you could do the aggregation yourself as follows:

```
Buffer totalBuffer = Buffer.buffer();

request.handler(buffer -> {
  System.out.println("I have received a chunk of the body of length " + buffer.length());
  totalBuffer.appendBuffer(buffer);
});

request.endHandler(v -> {
  System.out.println("Full body received, length = " + totalBuffer.length());
});
```

This is such a common case, that Vert.x provides a `[bodyHandler](../../apidocs/io/vertx/core/http/HttpServerRequest.html#bodyHandler-io.vertx.core.Handler-)` to do this for you. The body handler is called once when all the body has been received:

```
request.bodyHandler(totalBuffer -> {
  System.out.println("Full body received, length = " + totalBuffer.length());
});
```

#### [Streaming requests](#_streaming_requests)

The request object is a `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)` so you can pipe the request body to any `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` instance.

See the chapter on [streams](#streams) for a detailed explanation.

#### [Handling HTML forms](#_handling_html_forms)

HTML forms can be submitted with either a content type of `application/x-www-form-urlencoded` or `multipart/form-data`.

For url encoded forms, the form attributes are encoded in the url, just like normal query parameters.

For multi-part forms they are encoded in the request body, and as such are not available until the entire body has been read from the wire.

Multi-part forms can also contain file uploads.

If you want to retrieve the attributes of a multi-part form you should tell Vert.x that you expect to receive such a form **before** any of the body is read by calling `[setExpectMultipart](../../apidocs/io/vertx/core/http/HttpServerRequest.html#setExpectMultipart-boolean-)` with `true`, and then you should retrieve the actual attributes using `[formAttributes](../../apidocs/io/vertx/core/http/HttpServerRequest.html#formAttributes--)` once the entire body has been read:

```
server.requestHandler(request -> {
  request.setExpectMultipart(true);
  request.endHandler(v -> {
    // The body has now been fully read, so retrieve the form attributes
    MultiMap formAttributes = request.formAttributes();
  });
});
```

Form attributes have a maximum size of `8192` bytes. When the client submits a form with an attribute size greater than this value, the file upload triggers an exception on `HttpServerRequest` exception handler. You can set a different maximum size with `[setMaxFormAttributeSize](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setMaxFormAttributeSize-int-)`.

#### [Handling form file uploads](#_handling_form_file_uploads)

Vert.x can also handle file uploads which are encoded in a multi-part request body.

To receive file uploads you tell Vert.x to expect a multi-part form and set an `[uploadHandler](../../apidocs/io/vertx/core/http/HttpServerRequest.html#uploadHandler-io.vertx.core.Handler-)` on the request.

This handler will be called once for every upload that arrives on the server.

The object passed into the handler is a `[HttpServerFileUpload](../../apidocs/io/vertx/core/http/HttpServerFileUpload.html)` instance.

```
server.requestHandler(request -> {
  request.setExpectMultipart(true);
  request.uploadHandler(upload -> {
    System.out.println("Got a file upload " + upload.name());
  });
});
```

File uploads can be large we don’t provide the entire upload in a single buffer as that might result in memory exhaustion, instead, the upload data is received in chunks:

```
request.uploadHandler(upload -> {
  upload.handler(chunk -> {
    System.out.println("Received a chunk of the upload of length " + chunk.length());
  });
});
```

The upload object is a `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)` so you can pipe the request body to any `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` instance. See the chapter on [streams](#streams) for a detailed explanation.

If you just want to upload the file to disk somewhere you can use `[streamToFileSystem](../../apidocs/io/vertx/core/http/HttpServerFileUpload.html#streamToFileSystem-java.lang.String-io.vertx.core.Handler-)`:

```
request.uploadHandler(upload -> {
  upload.streamToFileSystem("myuploads_directory/" + upload.filename());
});
```

|  | Make sure you check the filename in a production system to avoid malicious clients uploading files to arbitrary places on your filesystem. See [security notes](#_security_notes) for more information. |
| --- | --- |

#### [Handling cookies](#_handling_cookies)

You use `[getCookie](../../apidocs/io/vertx/core/http/HttpServerRequest.html#getCookie-java.lang.String-)` to retrieve a cookie by name, or use `[cookieMap](../../apidocs/io/vertx/core/http/HttpServerRequest.html#cookieMap--)` to retrieve all the cookies.

To remove a cookie, use `[removeCookie](../../apidocs/io/vertx/core/http/HttpServerResponse.html#removeCookie-java.lang.String-)`.

To add a cookie use `[addCookie](../../apidocs/io/vertx/core/http/HttpServerResponse.html#addCookie-io.vertx.core.http.Cookie-)`.

The set of cookies will be written back in the response automatically when the response headers are written so the browser can store them.

Cookies are described by instances of `[Cookie](../../apidocs/io/vertx/core/http/Cookie.html)`. This allows you to retrieve the name, value, domain, path and other normal cookie properties.

Same Site Cookies let servers require that a cookie shouldn’t be sent with cross-site (where Site is defined by the registrable domain) requests, which provides some protection against cross-site request forgery attacks. This kind of cookies are enabled using the setter: `[setSameSite](../../apidocs/io/vertx/core/http/Cookie.html#setSameSite-io.vertx.core.http.CookieSameSite-)`.

Same site cookies can have one of 3 values:

* None - The browser will send cookies with both cross-site requests and same-site requests.
* Strict - The browser will only send cookies for same-site requests (requests originating from the site that set the cookie). If the request originated from a different URL than the URL of the current location, none of the cookies tagged with the Strict attribute will be included.
* Lax - Same-site cookies are withheld on cross-site subrequests, such as calls to load images or frames, but will be sent when a user navigates to the URL from an external site; for example, by following a link.

Here’s an example of querying and adding cookies:

```
Cookie someCookie = request.getCookie("mycookie");
String cookieValue = someCookie.getValue();

// Do something with cookie...

// Add a cookie - this will get written back in the response automatically
request.response().addCookie(Cookie.cookie("othercookie", "somevalue"));
```

#### [Handling compressed body](#_handling_compressed_body)

Vert.x can handle compressed body payloads which are encoded by the client with the *deflate*, *gzip* or *brotli* algorithms.

To enable decompression set `[setDecompressionSupported](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setDecompressionSupported-boolean-)` on the options when creating the server.

You need to have Brotli4j on the classpath to decompress Brotli:

* Maven (in your `pom.xml`):

```
<dependency>
 <groupId>com.aayushatharva.brotli4j</groupId>
 <artifactId>brotli4j</artifactId>
 <version>${brotli4j.version}</version>
</dependency>
```

* Gradle (in your `build.gradle` file):

```
dependencies {
 implementation 'com.aayushatharva.brotli4j:brotli4j:${brotli4j.version}'
 runtimeOnly 'com.aayushatharva.brotli4j:native-$system-and-arch:${brotli4j.version}'
}
```

When using Gradle, you need to add the runtime native library manually depending on your OS and architecture. See [the Gradle section of Brotli4j](https://github.com/hyperxpro/Brotli4j#gradle) for more details.

By default, decompression is disabled.

#### [Receiving custom HTTP/2 frames](#_receiving_custom_http2_frames)

HTTP/2 is a framed protocol with various frames for the HTTP request/response model. The protocol allows other kind of frames to be sent and received.

To receive custom frames, you can use the `[customFrameHandler](../../apidocs/io/vertx/core/http/HttpServerRequest.html#customFrameHandler-io.vertx.core.Handler-)` on the request, this will get called every time a custom frame arrives. Here’s an example:

```
request.customFrameHandler(frame -> {

  System.out.println("Received a frame type=" + frame.type() +
      " payload" + frame.payload().toString());
});
```

HTTP/2 frames are not subject to flow control - the frame handler will be called immediately when a custom frame is received whether the request is paused or is not

### [Sending back responses](#_sending_back_responses)

The server response object is an instance of `[HttpServerResponse](../../apidocs/io/vertx/core/http/HttpServerResponse.html)` and is obtained from the request with `[response](../../apidocs/io/vertx/core/http/HttpServerRequest.html#response--)`.

You use the response object to write a response back to the HTTP client.

#### [Setting status code and message](#_setting_status_code_and_message)

The default HTTP status code for a response is `200`, representing `OK`.

Use `[setStatusCode](../../apidocs/io/vertx/core/http/HttpServerResponse.html#setStatusCode-int-)` to set a different code.

You can also specify a custom status message with `[setStatusMessage](../../apidocs/io/vertx/core/http/HttpServerResponse.html#setStatusMessage-java.lang.String-)`.

If you don’t specify a status message, the default one corresponding to the status code will be used.

|  | for HTTP/2 the status won’t be present in the response since the protocol won’t transmit the message to the client |
| --- | --- |

#### [Writing HTTP responses](#_writing_http_responses)

To write data to an HTTP response, you use one of the `[write](../../apidocs/io/vertx/core/streams/WriteStream.html#write-java.lang.Object-)` operations.

These can be invoked multiple times before the response is ended. They can be invoked in a few ways:

With a single buffer:

```
HttpServerResponse response = request.response();
response.write(buffer);
```

With a string. In this case the string will encoded using UTF-8 and the result written to the wire.

```
HttpServerResponse response = request.response();
response.write("hello world!");
```

With a string and an encoding. In this case the string will encoded using the specified encoding and the result written to the wire.

```
HttpServerResponse response = request.response();
response.write("hello world!", "UTF-16");
```

Writing to a response is asynchronous and always returns immediately after write has been queued.

If you are just writing a single string or buffer to the HTTP response you can write it and end the response in a single call to the `[end](../../apidocs/io/vertx/core/http/HttpServerResponse.html#end-java.lang.String-)`

The first call to write results in the response header being written to the response. Consequently, if you are not using HTTP chunking then you must set the `Content-Length` header before writing to the response, since it will be too late otherwise. If you are using HTTP chunking you do not have to worry.

#### [Ending HTTP responses](#_ending_http_responses)

Once you have finished with the HTTP response you should `[end](../../apidocs/io/vertx/core/streams/WriteStream.html#end-io.vertx.core.Handler-)` it.

This can be done in several ways:

With no arguments, the response is simply ended.

```
HttpServerResponse response = request.response();
response.write("hello world!");
response.end();
```

It can also be called with a string or buffer in the same way `write` is called. In this case it’s just the same as calling write with a string or buffer followed by calling end with no arguments. For example:

```
HttpServerResponse response = request.response();
response.end("hello world!");
```

#### [Closing the underlying connection](#_closing_the_underlying_connection)

You can close the underlying TCP connection with `[close](../../apidocs/io/vertx/core/http/HttpServerResponse.html#close--)`.

Non keep-alive connections will be automatically closed by Vert.x when the response is ended.

Keep-alive connections are not automatically closed by Vert.x by default. If you want keep-alive connections to be closed after an idle time, then you configure `[setIdleTimeout](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setIdleTimeout-int-)`.

HTTP/2 connections send a {@literal GOAWAY} frame before closing the response.

#### [Setting response headers](#_setting_response_headers)

HTTP response headers can be added to the response by adding them directly to the `[headers](../../apidocs/io/vertx/core/http/HttpServerResponse.html#headers--)`:

```
HttpServerResponse response = request.response();
MultiMap headers = response.headers();
headers.set("content-type", "text/html");
headers.set("other-header", "wibble");
```

Or you can use `[putHeader](../../apidocs/io/vertx/core/http/HttpServerResponse.html#putHeader-java.lang.String-java.lang.String-)`

```
HttpServerResponse response = request.response();
response.putHeader("content-type", "text/html").putHeader("other-header", "wibble");
```

Headers must all be added before any parts of the response body are written.

#### [Chunked HTTP responses and trailers](#_chunked_http_responses_and_trailers)

Vert.x supports [HTTP Chunked Transfer Encoding](https://en.wikipedia.org/wiki/Chunked_transfer_encoding).

This allows the HTTP response body to be written in chunks, and is normally used when a large response body is being streamed to a client and the total size is not known in advance.

You put the HTTP response into chunked mode as follows:

```
HttpServerResponse response = request.response();
response.setChunked(true);
```

Default is non-chunked. When in chunked mode, each call to one of the `[write](../../apidocs/io/vertx/core/streams/WriteStream.html#write-java.lang.Object-)` methods will result in a new HTTP chunk being written out.

When in chunked mode you can also write HTTP response trailers to the response. These are actually written in the final chunk of the response.

|  | chunked response has no effect for an HTTP/2 stream |
| --- | --- |

To add trailers to the response, add them directly to the `[trailers](../../apidocs/io/vertx/core/http/HttpServerResponse.html#trailers--)`.

```
HttpServerResponse response = request.response();
response.setChunked(true);
MultiMap trailers = response.trailers();
trailers.set("X-wibble", "woobble").set("X-quux", "flooble");
```

Or use `[putTrailer](../../apidocs/io/vertx/core/http/HttpServerResponse.html#putTrailer-java.lang.String-java.lang.String-)`.

```
HttpServerResponse response = request.response();
response.setChunked(true);
response.putTrailer("X-wibble", "woobble").putTrailer("X-quux", "flooble");
```

#### [Serving files directly from disk or the classpath](#_serving_files_directly_from_disk_or_the_classpath)

If you were writing a web server, one way to serve a file from disk would be to open it as an `[AsyncFile](../../apidocs/io/vertx/core/file/AsyncFile.html)` and pipe it to the HTTP response.

Or you could load it it one go using `[readFile](../../apidocs/io/vertx/core/file/FileSystem.html#readFile-java.lang.String-io.vertx.core.Handler-)` and write it straight to the response.

Alternatively, Vert.x provides a method which allows you to serve a file from disk or the filesystem to an HTTP response in one operation. Where supported by the underlying operating system this may result in the OS directly transferring bytes from the file to the socket without being copied through user-space at all.

This is done by using `[sendFile](../../apidocs/io/vertx/core/http/HttpServerResponse.html#sendFile-java.lang.String-)`, and is usually more efficient for large files, but may be slower for small files.

Here’s a very simple web server that serves files from the file system using sendFile:

```
vertx.createHttpServer().requestHandler(request -> {
  String file = "";
  if (request.path().equals("/")) {
    file = "index.html";
  } else if (!request.path().contains("..")) {
    file = request.path();
  }
  request.response().sendFile("web/" + file);
}).listen(8080);
```

Sending a file is asynchronous and may not complete until some time after the call has returned. If you want to be notified when the file has been written you can use `[sendFile](../../apidocs/io/vertx/core/http/HttpServerResponse.html#sendFile-java.lang.String-io.vertx.core.Handler-)`

Please see the chapter about [serving files from the classpath](#classpath) for restrictions about the classpath resolution or disabling it.

|  | If you use `sendFile` while using HTTPS it will copy through user-space, since if the kernel is copying data directly from disk to socket it doesn’t give us an opportunity to apply any encryption. |
| --- | --- |

|  | If you’re going to write web servers directly using Vert.x be careful that users cannot exploit the path to access files outside the directory from which you want to serve them or the classpath It may be safer instead to use Vert.x Web. |
| --- | --- |

When there is a need to serve just a segment of a file, say starting from a given byte, you can achieve this by doing:

```
vertx.createHttpServer().requestHandler(request -> {
  long offset = 0;
  try {
    offset = Long.parseLong(request.getParam("start"));
  } catch (NumberFormatException e) {
    // error handling...
  }

  long end = Long.MAX_VALUE;
  try {
    end = Long.parseLong(request.getParam("end"));
  } catch (NumberFormatException e) {
    // error handling...
  }

  request.response().sendFile("web/mybigfile.txt", offset, end);
}).listen(8080);
```

You are not required to supply the length if you want to send a file starting from an offset until the end, in this case you can just do:

```
vertx.createHttpServer().requestHandler(request -> {
  long offset = 0;
  try {
    offset = Long.parseLong(request.getParam("start"));
  } catch (NumberFormatException e) {
    // error handling...
  }

  request.response().sendFile("web/mybigfile.txt", offset);
}).listen(8080);
```

#### [Piping responses](#_piping_responses)

The server response is a `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` so you can pipe to it from any `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)`, e.g. `[AsyncFile](../../apidocs/io/vertx/core/file/AsyncFile.html)`, `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)`, `[WebSocket](../../apidocs/io/vertx/core/http/WebSocket.html)` or `[HttpServerRequest](../../apidocs/io/vertx/core/http/HttpServerRequest.html)`.

Here’s an example which echoes the request body back in the response for any PUT methods. It uses a pipe for the body, so it will work even if the HTTP request body is much larger than can fit in memory at any one time:

```
vertx.createHttpServer().requestHandler(request -> {
  HttpServerResponse response = request.response();
  if (request.method() == HttpMethod.PUT) {
    response.setChunked(true);
    request.pipeTo(response);
  } else {
    response.setStatusCode(400).end();
  }
}).listen(8080);
```

You can also use the `[send](../../apidocs/io/vertx/core/http/HttpServerResponse.html#send-io.vertx.core.streams.ReadStream-)` method to send a `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)`.

Sending a stream is a pipe operation, however as this is a method of `[HttpServerResponse](../../apidocs/io/vertx/core/http/HttpServerResponse.html)`, it will also take care of chunking the response when the `content-length` is not set.

```
vertx.createHttpServer().requestHandler(request -> {
  HttpServerResponse response = request.response();
  if (request.method() == HttpMethod.PUT) {
    response.send(request);
  } else {
    response.setStatusCode(400).end();
  }
}).listen(8080);
```

#### [Writing HTTP/2 frames](#_writing_http2_frames)

HTTP/2 is a framed protocol with various frames for the HTTP request/response model. The protocol allows other kind of frames to be sent and received.

To send such frames, you can use the `[writeCustomFrame](../../apidocs/io/vertx/core/http/HttpServerResponse.html#writeCustomFrame-int-int-io.vertx.core.buffer.Buffer-)` on the response. Here’s an example:

```
int frameType = 40;
int frameStatus = 10;
Buffer payload = Buffer.buffer("some data");

// Sending a frame to the client
response.writeCustomFrame(frameType, frameStatus, payload);
```

These frames are sent immediately and are not subject to flow control - when such frame is sent there it may be done before other {@literal DATA} frames.

#### [Stream reset](#_stream_reset)

HTTP/1.x does not allow a clean reset of a request or a response stream, for example when a client uploads a resource already present on the server, the server needs to accept the entire response.

HTTP/2 supports stream reset at any time during the request/response:

```
request.response().reset();
```

By default, the `NO_ERROR` (0) error code is sent, another code can sent instead:

```
request.response().reset(8);
```

The HTTP/2 specification defines the list of [error codes](http://httpwg.org/specs/rfc7540.html#ErrorCodes) one can use.

The request handler are notified of stream reset events with the `[request handler](../../apidocs/io/vertx/core/http/HttpServerRequest.html#exceptionHandler-io.vertx.core.Handler-)` and `[response handler](../../apidocs/io/vertx/core/http/HttpServerResponse.html#exceptionHandler-io.vertx.core.Handler-)`:

```
request.response().exceptionHandler(err -> {
  if (err instanceof StreamResetException) {
    StreamResetException reset = (StreamResetException) err;
    System.out.println("Stream reset " + reset.getCode());
  }
});
```

#### [Server push](#_server_push)

Server push is a new feature of HTTP/2 that enables sending multiple responses in parallel for a single client request.

When a server process a request, it can push a request/response to the client:

```
HttpServerResponse response = request.response();

// Push main.js to the client
response
  .push(HttpMethod.GET, "/main.js")
  .onComplete(ar -> {

    if (ar.succeeded()) {

      // The server is ready to push the response
      HttpServerResponse pushedResponse = ar.result();

      // Send main.js response
      pushedResponse.
        putHeader("content-type", "application/json").
        end("alert(\"Push response hello\")");
    } else {
      System.out.println("Could not push client resource " + ar.cause());
    }
  });

// Send the requested resource
response.sendFile("<html><head><script src=\"/main.js\"></script></head><body></body></html>");
```

When the server is ready to push the response, the push response handler is called and the handler can send the response.

The push response handler may receive a failure, for instance the client may cancel the push because it already has `main.js` in its cache and does not want it anymore.

The `[push](../../apidocs/io/vertx/core/http/HttpServerResponse.html#push-io.vertx.core.http.HttpMethod-java.lang.String-java.lang.String-io.vertx.core.Handler-)` method must be called before the initiating response ends, however the pushed response can be written after.

#### [Handling exceptions](#_handling_exceptions_2)

You can set an `[exceptionHandler](../../apidocs/io/vertx/core/http/HttpServer.html#exceptionHandler-io.vertx.core.Handler-)` to receive any exceptions that happens before the connection is passed to the `[requestHandler](../../apidocs/io/vertx/core/http/HttpServer.html#requestHandler-io.vertx.core.Handler-)` or to the `[webSocketHandler](../../apidocs/io/vertx/core/http/HttpServer.html#webSocketHandler-io.vertx.core.Handler-)`, e.g. during the TLS handshake.

#### [Handling invalid requests](#_handling_invalid_requests)

Vert.x will handle invalid HTTP requests and provides a default handler that will handle the common case appropriately, e.g. it does respond with `REQUEST_HEADER_FIELDS_TOO_LARGE` when a request header is too long.

You can set your own `[invalidRequestHandler](../../apidocs/io/vertx/core/http/HttpServer.html#invalidRequestHandler-io.vertx.core.Handler-)` to process invalid requests. Your implementation can handle specific cases and delegate other cases to to `[HttpServerRequest.DEFAULT_INVALID_REQUEST_HANDLER](../../apidocs/io/vertx/core/http/HttpServerRequest.html#DEFAULT_INVALID_REQUEST_HANDLER)`.

### [HTTP Compression](#_http_compression)

Vert.x comes with support for HTTP Compression out of the box.

This means you are able to automatically compress the body of the responses before they are sent back to the client.

If the client does not support HTTP compression the responses are sent back without compressing the body.

This allows to handle Client that support HTTP Compression and those that not support it at the same time.

To enable compression use can configure it with `[setCompressionSupported](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setCompressionSupported-boolean-)`.

By default, compression is not enabled.

When HTTP compression is enabled the server will check if the client includes an `Accept-Encoding` header which includes the supported compressions. Commonly used are deflate and gzip. Both are supported by Vert.x.

If such a header is found the server will automatically compress the body of the response with one of the supported compressions and send it back to the client.

Whenever the response needs to be sent without compression you can set the header `content-encoding` to `identity`:

```
request.response()
  .putHeader(HttpHeaders.CONTENT_ENCODING, HttpHeaders.IDENTITY)
  .sendFile("/path/to/image.jpg");
```

Be aware that compression may be able to reduce network traffic but is more CPU-intensive.

To address this latter issue Vert.x allows you to tune the 'compression level' parameter that is native of the gzip/deflate compression algorithms.

Compression level allows to configure gizp/deflate algorithms in terms of the compression ratio of the resulting data and the computational cost of the compress/decompress operation.

The compression level is an integer value ranged from '1' to '9', where '1' means lower compression ratio but fastest algorithm and '9' means maximum compression ratio available but a slower algorithm.

Using compression levels higher that 1-2 usually allows to save just some bytes in size - the gain is not linear, and depends on the specific data to be compressed - but it comports a non-trascurable cost in term of CPU cycles required to the server while generating the compressed response data ( Note that at moment Vert.x doesn’t support any form caching of compressed response data, even for static files, so the compression is done on-the-fly at every request body generation ) and in the same way it affects client(s) while decoding (inflating) received responses, operation that becomes more CPU-intensive the more the level increases.

By default - if compression is enabled via `[setCompressionSupported](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setCompressionSupported-boolean-)` - Vert.x will use '6' as compression level, but the parameter can be configured to address any case with `[setCompressionLevel](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setCompressionLevel-int-)`.

### [HTTP compression algorithms](#_http_compression_algorithms)

Vert.x supports out of the box deflate and gzip.

Brotli and zstandard can also be used.

```
new HttpServerOptions()
  .addCompressor(io.netty.handler.codec.compression.StandardCompressionOptions.gzip())
  .addCompressor(io.netty.handler.codec.compression.StandardCompressionOptions.deflate())
  .addCompressor(io.netty.handler.codec.compression.StandardCompressionOptions.brotli())
  .addCompressor(io.netty.handler.codec.compression.StandardCompressionOptions.zstd());
```

|  | use `[StandardCompressionOptions](../../apidocs/io/netty/handler/codec/compression/StandardCompressionOptions.html)` static methods to create `[CompressionOptions](../../apidocs/io/netty/handler/codec/compression/CompressionOptions.html)` |
| --- | --- |

Brotli and zstandard libraries need to be added to the classpath.

* Maven (in your `pom.xml`):

```
<dependency>
 <groupId>com.aayushatharva.brotli4j</groupId>
 <artifactId>brotli4j</artifactId>
 <version>${brotli4j.version}</version>
</dependency>
<dependency>
 <groupId>com.github.luben</groupId>
 <artifactId>zstd-jni</artifactId>
 <version>${zstd-jini.version}</version>
</dependency>
```

* Gradle (in your `build.gradle` file):

```
dependencies {
 implementation 'com.aayushatharva.brotli4j:brotli4j:${brotli4j.version}'
 runtimeOnly 'com.aayushatharva.brotli4j:native-$system-and-arch:${brotli4j.version}'
 implementation 'com.github.luben:zstd-jni:${zstd-jini.version}'
}
```

When using Gradle, you need to add the runtime native library manually depending on your OS and architecture. See [the Gradle section of Brotli4j](https://github.com/hyperxpro/Brotli4j#gradle) for more details.

You can configure compressors according to your needs

```
GzipOptions gzip = StandardCompressionOptions.gzip(6, 15, 8);
```

### [Creating an HTTP client](#_creating_an_http_client)

You create an `[HttpClient](../../apidocs/io/vertx/core/http/HttpClient.html)` instance with default options as follows:

```
HttpClient client = vertx.createHttpClient();
```

If you want to configure options for the client, you create it as follows:

```
HttpClientOptions options = new HttpClientOptions().setKeepAlive(false);
HttpClient client = vertx.createHttpClient(options);
```

Vert.x supports HTTP/2 over TLS `h2` and over TCP `h2c`.

By default, the http client performs HTTP/1.1 requests, to perform HTTP/2 requests the `[setProtocolVersion](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setProtocolVersion-io.vertx.core.http.HttpVersion-)` must be set to `[HTTP_2](../../apidocs/io/vertx/core/http/HttpVersion.html#HTTP_2)`.

For `h2` requests, TLS must be enabled with *Application-Layer Protocol Negotiation*:

```
HttpClientOptions options = new HttpClientOptions().
    setProtocolVersion(HttpVersion.HTTP_2).
    setSsl(true).
    setUseAlpn(true).
    setTrustAll(true);

HttpClient client = vertx.createHttpClient(options);
```

For `h2c` requests, TLS must be disabled, the client will do an HTTP/1.1 requests and try an upgrade to HTTP/2:

```
HttpClientOptions options = new HttpClientOptions().setProtocolVersion(HttpVersion.HTTP_2);

HttpClient client = vertx.createHttpClient(options);
```

`h2c` connections can also be established directly, i.e. connection started with a prior knowledge, when `[setHttp2ClearTextUpgrade](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setHttp2ClearTextUpgrade-boolean-)` options is set to false: after the connection is established, the client will send the HTTP/2 connection preface and expect to receive the same preface from the server.

The http server may not support HTTP/2, the actual version can be checked with `[version](../../apidocs/io/vertx/core/http/HttpResponseHead.html#version--)` when the response arrives.

When a clients connects to an HTTP/2 server, it sends to the server its `[initial settings](../../apidocs/io/vertx/core/http/HttpClientOptions.html#getInitialSettings--)`. The settings define how the server can use the connection, the default initial settings for a client are the default values defined by the HTTP/2 RFC.

### [Pool configuration](#_pool_configuration)

For performance purpose, the client uses connection pooling when interacting with HTTP/1.1 servers. The pool creates up to 5 connections per server. You can override the pool configuration like this:

```
PoolOptions options = new PoolOptions().setHttp1MaxSize(10);
HttpClient client = vertx.createHttpClient(options);
```

You can configure various pool `[options](../../apidocs/io/vertx/core/http/PoolOptions.html)` as follows

* `[options#setHttp1MaxSize](../../apidocs/io/vertx/core/http/PoolOptions.html)` the maximum number of opened per HTTP/1.x server (5 by default)
* `[options#setHttp2MaxSize](../../apidocs/io/vertx/core/http/PoolOptions.html)` the maximum number of opened per HTTP/2 server (1 by default), you **should** not change this value since a single HTTP/2 connection is capable of delivering the same performance level than multiple HTTP/1.x connections
* `[options#setCleanerPeriod](../../apidocs/io/vertx/core/http/PoolOptions.html)` the period in milliseconds at which the pool checks expired connections (1 second by default)
* `[options#setEventLoopSize](../../apidocs/io/vertx/core/http/PoolOptions.html)` sets the number of event loops the pool use (0 by default)
* a value of 0 configures the pool to use the event loop of the caller
* a positive value configures the pool load balance the creation of connection over a list of event loops determined by the value
* `[options#setMaxWaitQueueSize](../../apidocs/io/vertx/core/http/PoolOptions.html)` the maximum number of HTTP requests waiting until a connection is available, when the queue is full, the request is rejected

### [Logging network client activity](#_logging_network_client_activity)

For debugging purposes, network activity can be logged.

```
HttpClientOptions options = new HttpClientOptions().setLogActivity(true);
HttpClient client = vertx.createHttpClient(options);
```

See the chapter on [logging network activity](#logging_network_activity) for a detailed explanation.

### [Advanced HTTP client creation](#_advanced_http_client_creation)

You can pass options `[createHttpClient](../../apidocs/io/vertx/core/Vertx.html#createHttpClient-io.vertx.core.http.HttpClientOptions-io.vertx.core.http.PoolOptions-)` methods to configure the HTTP client.

Alternatively you can build a client with the builder `[API](../../apidocs/io/vertx/core/http/HttpClientBuilder.html)` :

```
HttpClient build = vertx
  .httpClientBuilder()
  .with(options)
  .build();
```

In addition to `[HttpClientOptions](../../apidocs/io/vertx/core/http/HttpClientOptions.html)` and `[PoolOptions](../../apidocs/io/vertx/core/http/PoolOptions.html)`, you can set

* a connection event handler notified when the client [connects](#_client_connections) to a server
* a redirection handler to implement an alternative HTTP [redirect](#_30x_redirection_handling) behavior

### [Making requests](#_making_requests)

The http client is very flexible and there are various ways you can make requests with it.

The first step when making a request is obtaining an HTTP connection to the remote server:

```
client
  .request(HttpMethod.GET, 8080, "myserver.mycompany.com", "/some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {
      // Connected to the server
    }
  });
```

The client will connect to the remote server or reuse an available connection from the client connection pool.

#### [Default host and port](#_default_host_and_port)

Often you want to make many requests to the same host/port with an http client. To avoid you repeating the host/port every time you make a request you can configure the client with a default host/port:

```
HttpClientOptions options = new HttpClientOptions().setDefaultHost("wibble.com");

// Can also set default port if you want...
HttpClient client = vertx.createHttpClient(options);
client
  .request(HttpMethod.GET, "/some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {
      HttpClientRequest request = ar1.result();
      request
        .send()
        .onComplete(ar2 -> {
          if (ar2.succeeded()) {
            HttpClientResponse response = ar2.result();
            System.out.println("Received response with status code " + response.statusCode());
          }
        });
    }
  });
```

#### [Writing request headers](#_writing_request_headers)

You can write headers to a request using the `[HttpHeaders](../../apidocs/io/vertx/core/http/HttpHeaders.html)` as follows:

```
HttpClient client = vertx.createHttpClient();

// Write some headers using the headers multi-map
MultiMap headers = HttpHeaders.set("content-type", "application/json").set("other-header", "foo");

client
  .request(HttpMethod.GET, "some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {
      if (ar1.succeeded()) {
        HttpClientRequest request = ar1.result();
        request.headers().addAll(headers);
        request
          .send()
          .onComplete(ar2 -> {
            HttpClientResponse response = ar2.result();
            System.out.println("Received response with status code " + response.statusCode());
          });
      }
    }
  });
```

The headers are an instance of `[MultiMap](../../apidocs/io/vertx/core/MultiMap.html)` which provides operations for adding, setting and removing entries. Http headers allow more than one value for a specific key.

You can also write headers using `[putHeader](../../apidocs/io/vertx/core/http/HttpClientRequest.html#putHeader-java.lang.String-java.lang.String-)`

```
request.putHeader("content-type", "application/json")
  .putHeader("other-header", "foo");
```

If you wish to write headers to the request you must do so before any part of the request body is written.

#### [Writing request and processing response](#_writing_request_and_processing_response)

The `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)` `request` methods connects to the remote server or reuse an existing connection. The request instance obtained is pre-populated with some data such like the host or the request URI, but you need to send this request to the server.

You can call `[send](../../apidocs/io/vertx/core/http/HttpClientRequest.html#send--)` to send a request such as an HTTP `GET` and process the asynchronous `[HttpClientResponse](../../apidocs/io/vertx/core/http/HttpClientResponse.html)`.

```
client
  .request(HttpMethod.GET, 8080, "myserver.mycompany.com", "/some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {
      HttpClientRequest request = ar1.result();

      // Send the request and process the response
      request
        .send()
        .onComplete(ar -> {
          if (ar.succeeded()) {
            HttpClientResponse response = ar.result();
            System.out.println("Received response with status code " + response.statusCode());
          } else {
            System.out.println("Something went wrong " + ar.cause().getMessage());
          }
        });
    }
  });
```

You can also send the request with a body.

`[send](../../apidocs/io/vertx/core/http/HttpClientRequest.html#send-java.lang.String-)` with a string, the `Content-Length` header will be set for you if it was not previously set.

```
client
  .request(HttpMethod.GET, 8080, "myserver.mycompany.com", "/some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {
      HttpClientRequest request = ar1.result();

      // Send the request and process the response
      request
        .send("Hello World")
        .onComplete(ar -> {
          if (ar.succeeded()) {
            HttpClientResponse response = ar.result();
            System.out.println("Received response with status code " + response.statusCode());
          } else {
            System.out.println("Something went wrong " + ar.cause().getMessage());
          }
        });
    }
  });
```

`[send](../../apidocs/io/vertx/core/http/HttpClientRequest.html#send-io.vertx.core.buffer.Buffer-)` with a buffer, the `Content-Length` header will be set for you if it was not previously set.

```
request
  .send(Buffer.buffer("Hello World"))
  .onComplete(ar -> {
    if (ar.succeeded()) {
      HttpClientResponse response = ar.result();
      System.out.println("Received response with status code " + response.statusCode());
    } else {
      System.out.println("Something went wrong " + ar.cause().getMessage());
    }
  });
```

`[send](../../apidocs/io/vertx/core/http/HttpClientRequest.html#send-io.vertx.core.streams.ReadStream-)` with a stream, if the `Content-Length` header was not previously set, the request is sent with a chunked `Content-Encoding`.

```
request
  .putHeader(HttpHeaders.CONTENT_LENGTH, "1000")
  .send(stream)
  .onComplete(ar -> {
    if (ar.succeeded()) {
      HttpClientResponse response = ar.result();
      System.out.println("Received response with status code " + response.statusCode());
    } else {
      System.out.println("Something went wrong " + ar.cause().getMessage());
    }
  });
```

#### [Streaming Request body](#_streaming_request_body)

The `send` method send requests at once.

Sometimes you’ll want to have low level control on how you write requests bodies.

The `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)` can be used to write the request body.

Here are some examples of writing a POST request with a body:

```
HttpClient client = vertx.createHttpClient();

client.request(HttpMethod.POST, "some-uri")
  .onSuccess(request -> {
    request.response().onSuccess(response -> {
      System.out.println("Received response with status code " + response.statusCode());
    });

    // Now do stuff with the request
    request.putHeader("content-length", "1000");
    request.putHeader("content-type", "text/plain");
    request.write(body);

    // Make sure the request is ended when you're done with it
    request.end();
  });
```

Methods exist to write strings in UTF-8 encoding and in any specific encoding and to write buffers:

```
request.write("some data");

// Write string encoded in specific encoding
request.write("some other data", "UTF-16");

// Write a buffer
Buffer buffer = Buffer.buffer();
buffer.appendInt(123).appendLong(245l);
request.write(buffer);
```

If you are just writing a single string or buffer to the HTTP request you can write it and end the request in a single call to the `end` function.

```
request.end("some simple data");

// Write buffer and end the request (send it) in a single call
Buffer buffer = Buffer.buffer().appendDouble(12.34d).appendLong(432l);
request.end(buffer);
```

When you’re writing to a request, the first call to `write` will result in the request headers being written out to the wire.

The actual write is asynchronous and might not occur until some time after the call has returned.

Non-chunked HTTP requests with a request body require a `Content-Length` header to be provided.

Consequently, if you are not using chunked HTTP then you must set the `Content-Length` header before writing to the request, as it will be too late otherwise.

If you are calling one of the `end` methods that take a string or buffer then Vert.x will automatically calculate and set the `Content-Length` header before writing the request body.

If you are using HTTP chunking a `Content-Length` header is not required, so you do not have to calculate the size up-front.

#### [Ending streamed HTTP requests](#_ending_streamed_http_requests)

Once you have finished with the HTTP request you must end it with one of the `[end](../../apidocs/io/vertx/core/http/HttpClientRequest.html#end-java.lang.String-)` operations.

Ending a request causes any headers to be written, if they have not already been written and the request to be marked as complete.

Requests can be ended in several ways. With no arguments the request is simply ended:

```
request.end();
```

Or a string or buffer can be provided in the call to `end`. This is like calling `write` with the string or buffer before calling `end` with no arguments

```
request.end("some-data");

// End it with a buffer
Buffer buffer = Buffer.buffer().appendFloat(12.3f).appendInt(321);
request.end(buffer);
```

#### [Using the request as a stream](#_using_the_request_as_a_stream)

An `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)` instance is also a `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` instance.

You can pipe to it from any `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)` instance.

For, example, you could pipe a file on disk to a http request body as follows:

```
request.setChunked(true);
file.pipeTo(request);
```

#### [Chunked HTTP requests](#_chunked_http_requests)

Vert.x supports [HTTP Chunked Transfer Encoding](https://en.wikipedia.org/wiki/Chunked_transfer_encoding) for requests.

This allows the HTTP request body to be written in chunks, and is normally used when a large request body is being streamed to the server, whose size is not known in advance.

You put the HTTP request into chunked mode using `[setChunked](../../apidocs/io/vertx/core/http/HttpClientRequest.html#setChunked-boolean-)`.

In chunked mode each call to write will cause a new chunk to be written to the wire. In chunked mode there is no need to set the `Content-Length` of the request up-front.

```
request.setChunked(true);

// Write some chunks
for (int i = 0; i < 10; i++) {
  request.write("this-is-chunk-" + i);
}

request.end();
```

#### [Request timeouts](#_request_timeouts)

You can set an idle timeout to prevent your application from unresponsive servers using `[setIdleTimeout](../../apidocs/io/vertx/core/http/RequestOptions.html#setIdleTimeout-long-)` or `[idleTimeout](../../apidocs/io/vertx/core/http/HttpClientRequest.html#idleTimeout-long-)`. When the request does not return any data within the timeout period an exception will fail the result and the request will be reset.

```
Future<Buffer> fut = client
  .request(new RequestOptions()
    .setHost(host)
    .setPort(port)
    .setURI(uri)
    .setIdleTimeout(timeoutMS))
  .compose(request -> request.send().compose(HttpClientResponse::body));
```

|  | the timeout starts when the `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)` is available, implying a connection was obtained from the pool. |
| --- | --- |

You can set a connect timeout to prevent your application from unresponsive busy client connection pool. The `Future<HttpClientRequest>` is failed when a connection is not obtained before the timeout delay.

The connect timeout option is not related to the TCP `[setConnectTimeout](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setConnectTimeout-int-)` option, when a request is made against a pooled HTTP client, the timeout applies to the duration to obtain a connection from the pool to serve the request, the timeout might fire because the server does not respond in time or the pool is too busy to serve a request.

You can configure both timeout using `[setTimeout](../../apidocs/io/vertx/core/http/RequestOptions.html#setTimeout-long-)`

```
Future<Buffer> fut = client
  .request(new RequestOptions()
    .setHost(host)
    .setPort(port)
    .setURI(uri)
    .setTimeout(timeoutMS))
  .compose(request -> request.send().compose(HttpClientResponse::body));
```

#### [Writing HTTP/2 frames](#_writing_http2_frames_2)

HTTP/2 is a framed protocol with various frames for the HTTP request/response model. The protocol allows other kind of frames to be sent and received.

To send such frames, you can use the `[write](../../apidocs/io/vertx/core/streams/WriteStream.html#write-java.lang.Object-)` on the request. Here’s an example:

```
int frameType = 40;
int frameStatus = 10;
Buffer payload = Buffer.buffer("some data");

// Sending a frame to the server
request.writeCustomFrame(frameType, frameStatus, payload);
```

#### [Stream reset](#_stream_reset_2)

HTTP/1.x does not allow a clean reset of a request or a response stream, for example when a client uploads a resource already present on the server, the server needs to accept the entire response.

HTTP/2 supports stream reset at any time during the request/response:

```
request.reset();
```

By default the NO\_ERROR (0) error code is sent, another code can sent instead:

```
request.reset(8);
```

The HTTP/2 specification defines the list of [error codes](http://httpwg.org/specs/rfc7540.html#ErrorCodes) one can use.

The request handler are notified of stream reset events with the `[request handler](../../apidocs/io/vertx/core/http/HttpClientRequest.html#exceptionHandler-io.vertx.core.Handler-)` and `[response handler](../../apidocs/io/vertx/core/http/HttpClientResponse.html#exceptionHandler-io.vertx.core.Handler-)`:

```
request.exceptionHandler(err -> {
  if (err instanceof StreamResetException) {
    StreamResetException reset = (StreamResetException) err;
    System.out.println("Stream reset " + reset.getCode());
  }
});
```

### [HTTP/2 RST flood protection](#_http2_rst_flood_protection)

An HTTP/2 server is protected against RST flood DDOS attacks (CVE-2023-44487): there is an upper bound to the number of RST frames a server can receive in a time window. The default configuration sets the upper bound to `200` for a duration of `30` seconds.

You can use `[setHttp2RstFloodMaxRstFramePerWindow](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setHttp2RstFloodMaxRstFramePerWindow-int-)` and `[setHttp2RstFloodWindowDuration](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setHttp2RstFloodWindowDuration-int-)` to override these settings.

### [Handling HTTP responses](#_handling_http_responses)

You receive an instance of `[HttpClientResponse](../../apidocs/io/vertx/core/http/HttpClientResponse.html)` into the handler that you specify in of the request methods or by setting a handler directly on the `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)` object.

You can query the status code and the status message of the response with `[statusCode](../../apidocs/io/vertx/core/http/HttpResponseHead.html#statusCode--)` and `[statusMessage](../../apidocs/io/vertx/core/http/HttpResponseHead.html#statusMessage--)`.

```
request
  .send()
  .onComplete(ar2 -> {
    if (ar2.succeeded()) {

      HttpClientResponse response = ar2.result();

      // the status code - e.g. 200 or 404
      System.out.println("Status code is " + response.statusCode());

      // the status message e.g. "OK" or "Not Found".
      System.out.println("Status message is " + response.statusMessage());
    }
  });
```

#### [Using the response as a stream](#_using_the_response_as_a_stream)

The `[HttpClientResponse](../../apidocs/io/vertx/core/http/HttpClientResponse.html)` instance is also a `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)` which means you can pipe it to any `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` instance.

#### [Response headers and trailers](#_response_headers_and_trailers)

Http responses can contain headers. Use `[headers](../../apidocs/io/vertx/core/http/HttpResponseHead.html#headers--)` to get the headers.

The object returned is a `[MultiMap](../../apidocs/io/vertx/core/MultiMap.html)` as HTTP headers can contain multiple values for single keys.

```
String contentType = response.headers().get("content-type");
String contentLength = response.headers().get("content-lengh");
```

Chunked HTTP responses can also contain trailers - these are sent in the last chunk of the response body.

You use `[trailers](../../apidocs/io/vertx/core/http/HttpClientResponse.html#trailers--)` to get the trailers. Trailers are also a `[MultiMap](../../apidocs/io/vertx/core/MultiMap.html)`.

#### [Reading the request body](#_reading_the_request_body)

The response handler is called when the headers of the response have been read from the wire.

If the response has a body this might arrive in several pieces some time after the headers have been read. We don’t wait for all the body to arrive before calling the response handler as the response could be very large and we might be waiting a long time, or run out of memory for large responses.

As parts of the response body arrive, the `[handler](../../apidocs/io/vertx/core/http/HttpClientResponse.html#handler-io.vertx.core.Handler-)` is called with a `[Buffer](../../apidocs/io/vertx/core/buffer/Buffer.html)` representing the piece of the body:

```
client
  .request(HttpMethod.GET, "some-uri")
  .onComplete(ar1 -> {

    if (ar1.succeeded()) {
      HttpClientRequest request = ar1.result();
      request
        .send()
        .onComplete(ar2 -> {
          HttpClientResponse response = ar2.result();
          response.handler(buffer -> {
            System.out.println("Received a part of the response body: " + buffer);
          });
        });
    }
  });
```

If you know the response body is not very large and want to aggregate it all in memory before handling it, you can either aggregate it yourself:

```
request
  .send()
  .onComplete(ar2 -> {

    if (ar2.succeeded()) {

      HttpClientResponse response = ar2.result();

      // Create an empty buffer
      Buffer totalBuffer = Buffer.buffer();

      response.handler(buffer -> {
        System.out.println("Received a part of the response body: " + buffer.length());

        totalBuffer.appendBuffer(buffer);
      });

      response.endHandler(v -> {
        // Now all the body has been read
        System.out.println("Total response body length is " + totalBuffer.length());
      });
    }
  });
```

Or you can use the convenience `[body](../../apidocs/io/vertx/core/http/HttpClientResponse.html#body-io.vertx.core.Handler-)` which is called with the entire body when the response has been fully read:

```
request
  .send()
  .onComplete(ar1 -> {

    if (ar1.succeeded()) {
      HttpClientResponse response = ar1.result();
      response
        .body()
        .onComplete(ar2 -> {

          if (ar2.succeeded()) {
            Buffer body = ar2.result();
            // Now all the body has been read
            System.out.println("Total response body length is " + body.length());
          }
        });
    }
  });
```

#### [Response end handler](#_response_end_handler)

The response `[endHandler](../../apidocs/io/vertx/core/http/HttpClientResponse.html#endHandler-io.vertx.core.Handler-)` is called when the entire response body has been read or immediately after the headers have been read and the response handler has been called if there is no body.

#### [Request and response composition](#_request_and_response_composition)

The client interface is very simple and follows this pattern:

1. `request` a connection
2. `send` or `write`/`end` the request to the server
3. handle the beginning of the `[HttpClientResponse](../../apidocs/io/vertx/core/http/HttpClientResponse.html)`
4. process the response events

You can use Vert.x future composition methods to make your code simpler, however the API is event driven, and you need to understand it otherwise you might experience possible data races (i.e. loosing events leading to corrupted data).

|  | [Vert.x Web Client](https://vertx.io/docs/vertx-web-client/java/) is a higher level API alternative (in fact it is built on top of this client) you might consider if this client is too low level for your use cases |
| --- | --- |

The client API intentionally does not return a `Future<HttpClientResponse>` because setting a completion handler on the future can be racy when this is set outside the event-loop.

```
Future<HttpClientResponse> get = client.get("some-uri");

// Assuming we have a client that returns a future response
// assuging this is *not* on the event-loop
// introduce a potential data race for the sake of this example
Thread.sleep(100);

get.onSuccess(response -> {

  // Response events might have happen already
  response
    .body()
    .onComplete(ar -> {

    });
});
```

Confining the `HttpClientRequest` usage within a verticle is the easiest solution as the Verticle will ensure that events are processed sequentially avoiding races.

```
vertx.deployVerticle(() -> new AbstractVerticle() {
 @Override
 public void start() {

   HttpClient client = vertx.createHttpClient();

   Future<HttpClientRequest> future = client.request(HttpMethod.GET, "some-uri");
 }
}, new DeploymentOptions());
```

When you are interacting with the client possibly outside a verticle then you can safely perform composition as long as you do not delay the response events, e.g. processing directly the response on the event-loop.

```
Future<JsonObject> future = client
  .request(HttpMethod.GET, "some-uri")
  .compose(request -> request
    .send()
    .compose(response -> {
      // Process the response on the event-loop which guarantees no races
      if (response.statusCode() == 200 &&
        response.getHeader(HttpHeaders.CONTENT_TYPE).equals("application/json")) {
        return response
          .body()
          .map(buffer -> buffer.toJsonObject());
      } else {
        return Future.failedFuture("Incorrect HTTP response");
      }
    }));

// Listen to the composed final json result
future.onSuccess(json -> {
  System.out.println("Received json result " + json);
}).onFailure(err -> {
  System.out.println("Something went wrong " + err.getMessage());
});
```

You can also guard the response body with [HTTP responses expectations](#response-expectations).

```
Future<JsonObject> future = client
  .request(HttpMethod.GET, "some-uri")
  .compose(request -> request
    .send()
    .expecting(HttpResponseExpectation.SC_OK.and(HttpResponseExpectation.JSON))
    .compose(response -> response
      .body()
      .map(buffer -> buffer.toJsonObject())));
// Listen to the composed final json result
future.onSuccess(json -> {
  System.out.println("Received json result " + json);
}).onFailure(err -> {
  System.out.println("Something went wrong " + err.getMessage());
});
```

If you need to delay the response processing then you need to `pause` the response or use a `pipe`, this might be necessary when another asynchronous operation is involved.

```
Future<Void> future = client
  .request(HttpMethod.GET, "some-uri")
  .compose(request -> request
    .send()
    .compose(response -> {
      // Process the response on the event-loop which guarantees no races
      if (response.statusCode() == 200) {

        // Create a pipe, this pauses the response
        Pipe<Buffer> pipe = response.pipe();

        // Write the file on the disk
        return fileSystem
          .open("/some/large/file", new OpenOptions().setWrite(true))
          .onFailure(err -> pipe.close())
          .compose(file -> pipe.to(file));
      } else {
        return Future.failedFuture("Incorrect HTTP response");
      }
    }));
```

#### [Response expectations](#response-expectations)

As seen above, you must perform sanity checks manually after the response is received.

You can trade flexibility for clarity and conciseness using *response expectations*.

`[Response expectations](../../apidocs/io/vertx/core/http/HttpResponseExpectation.html)` can guard the control flow when the response does not match a criteria.

The HTTP Client comes with a set of out of the box predicates ready to use:

```
Future<Buffer> fut = client
  .request(options)
  .compose(request -> request
    .send()
    .expecting(HttpResponseExpectation.SC_SUCCESS)
    .compose(response -> response.body()));
```

You can also create custom predicates when existing predicates don’t fit your needs:

```
HttpResponseExpectation methodsPredicate =
  resp -> {
    String methods = resp.getHeader("Access-Control-Allow-Methods");
    return methods != null && methods.contains("POST");
  };

// Send pre-flight CORS request
client
  .request(new RequestOptions()
    .setMethod(HttpMethod.OPTIONS)
    .setPort(8080)
    .setHost("myserver.mycompany.com")
    .setURI("/some-uri")
    .putHeader("Origin", "Server-b.com")
    .putHeader("Access-Control-Request-Method", "POST"))
  .compose(request -> request
    .send()
    .expecting(methodsPredicate))
  .onSuccess(res -> {
    // Process the POST request now
  })
  .onFailure(err ->
    System.out.println("Something went wrong " + err.getMessage()));
```

#### [Predefined expectations](#_predefined_expectations)

As a convenience, the HTTP Client ships a few predicates for common uses cases .

For status codes, e.g. `[HttpResponseExpectation.SC_SUCCESS](../../apidocs/io/vertx/core/http/HttpResponseExpectation.html#SC_SUCCESS)` to verify that the response has a `2xx` code, you can also create a custom one:

```
client
  .request(options)
  .compose(request -> request
    .send()
    .expecting(HttpResponseExpectation.status(200, 202)))
  .onSuccess(res -> {
    // ....
  });
```

For content types, e.g. `[HttpResponseExpectation.JSON](../../apidocs/io/vertx/core/http/HttpResponseExpectation.html#JSON)` to verify that the response body contains JSON data, you can also create a custom one:

```
client
  .request(options)
  .compose(request -> request
    .send()
    .expecting(HttpResponseExpectation.contentType("some/content-type")))
  .onSuccess(res -> {
    // ....
  });
```

Please refer to the `[HttpResponseExpectation](../../apidocs/io/vertx/core/http/HttpResponseExpectation.html)` documentation for a full list of predefined expectations.

#### [Creating custom failures](#_creating_custom_failures)

By default, expectations (including the predefined ones) conveys a simple error message. You can customize the exception class by changing the error converter:

```
Expectation<HttpResponseHead> expectation = HttpResponseExpectation.SC_SUCCESS
  .wrappingFailure((resp, err) -> new MyCustomException(resp.statusCode(), err.getMessage()));
```

|  | creating exception in Java can have a performance cost when it captures a stack trace, so you might want to create exceptions that do not capture the stack trace. By default exceptions are reported using an exception that does not capture the stack trace. |
| --- | --- |

#### [Reading cookies from the response](#_reading_cookies_from_the_response)

You can retrieve the list of cookies from a response using `[cookies](../../apidocs/io/vertx/core/http/HttpResponseHead.html#cookies--)`.

Alternatively you can just parse the `Set-Cookie` headers yourself in the response.

#### [30x redirection handling](#_30x_redirection_handling)

The client can be configured to follow HTTP redirections provided by the `Location` response header when the client receives:

* a `301`, `302`, `307` or `308` status code along with a HTTP GET or HEAD method
* a `303` status code, in addition the directed request perform an HTTP GET method

Here’s an example:

```
client
  .request(HttpMethod.GET, "some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {

      HttpClientRequest request = ar1.result();
      request.setFollowRedirects(true);
      request
        .send()
        .onComplete(ar2 -> {
          if (ar2.succeeded()) {

            HttpClientResponse response = ar2.result();
            System.out.println("Received response with status code " + response.statusCode());
          }
        });
    }
  });
```

The maximum redirects is `16` by default and can be changed with `[setMaxRedirects](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setMaxRedirects-int-)`.

```
HttpClient client = vertx.createHttpClient(
  new HttpClientOptions()
    .setMaxRedirects(32));

client
  .request(HttpMethod.GET, "some-uri")
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {

      HttpClientRequest request = ar1.result();
      request.setFollowRedirects(true);
      request
        .send()
        .onComplete(ar2 -> {
          if (ar2.succeeded()) {

            HttpClientResponse response = ar2.result();
            System.out.println("Received response with status code " + response.statusCode());
          }
        });
    }
  });
```

One size does not fit all and the default redirection policy may not be adapted to your needs.

The default redirection policy can changed with a custom implementation:

```
HttpClient client = vertx.httpClientBuilder()
  .withRedirectHandler(response -> {

    // Only follow 301 code
    if (response.statusCode() == 301 && response.getHeader("Location") != null) {

      // Compute the redirect URI
      String absoluteURI = resolveURI(response.request().absoluteURI(), response.getHeader("Location"));

      // Create a new ready to use request that the client will use
      return Future.succeededFuture(new RequestOptions().setAbsoluteURI(absoluteURI));
    }

    // We don't redirect
    return null;
  })
  .build();
```

The policy handles the original `[HttpClientResponse](../../apidocs/io/vertx/core/http/HttpClientResponse.html)` received and returns either `null` or a `Future<HttpClientRequest>`.

* when `null` is returned, the original response is processed
* when a future is returned, the request will be sent on its successful completion
* when a future is returned, the exception handler set on the request is called on its failure

The returned request must be unsent so the original request handlers can be sent and the client can send it after.

Most of the original request settings will be propagated to the new request:

* request headers, unless if you have set some headers
* request body unless the returned request uses a `GET` method
* response handler
* request exception handler
* request timeout

#### [100-Continue handling](#_100_continue_handling)

According to the [HTTP 1.1 specification](http://www.w3.org/Protocols/rfc2616/rfc2616-sec8.html) a client can set a header `Expect: 100-Continue` and send the request header before sending the rest of the request body.

The server can then respond with an interim response status `Status: 100 (Continue)` to signify to the client that it is ok to send the rest of the body.

The idea here is it allows the server to authorise and accept/reject the request before large amounts of data are sent. Sending large amounts of data if the request might not be accepted is a waste of bandwidth and ties up the server in reading data that it will just discard.

Vert.x allows you to set a `[continueHandler](../../apidocs/io/vertx/core/http/HttpClientRequest.html#continueHandler-io.vertx.core.Handler-)` on the client request object

This will be called if the server sends back a `Status: 100 (Continue)` response to signify that it is ok to send the rest of the request.

This is used in conjunction with `[sendHead](../../apidocs/io/vertx/core/http/HttpClientRequest.html#sendHead--)`to send the head of the request.

Here’s an example:

```
client.request(HttpMethod.PUT, "some-uri")
  .onSuccess(request -> {
    request.response().onSuccess(response -> {
      System.out.println("Received response with status code " + response.statusCode());
    });

    request.putHeader("Expect", "100-Continue");

    request.continueHandler(v -> {
      // OK to send rest of body
      request.write("Some data");
      request.write("Some more data");
      request.end();
    });

    request.sendHead();
  });
```

On the server side a Vert.x http server can be configured to automatically send back 100 Continue interim responses when it receives an `Expect: 100-Continue` header.

This is done by setting the option `[setHandle100ContinueAutomatically](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setHandle100ContinueAutomatically-boolean-)`.

If you’d prefer to decide whether to send back continue responses manually, then this property should be set to `false` (the default), then you can inspect the headers and call `[writeContinue](../../apidocs/io/vertx/core/http/HttpServerResponse.html#writeContinue--)` to have the client continue sending the body:

```
httpServer.requestHandler(request -> {
  if (request.getHeader("Expect").equalsIgnoreCase("100-Continue")) {

    // Send a 100 continue response
    request.response().writeContinue();

    // The client should send the body when it receives the 100 response
    request.bodyHandler(body -> {
      // Do something with body
    });

    request.endHandler(v -> {
      request.response().end();
    });
  }
});
```

You can also reject the request by sending back a failure status code directly: in this case the body should either be ignored or the connection should be closed (100-Continue is a performance hint and cannot be a logical protocol constraint):

```
httpServer.requestHandler(request -> {
  if (request.getHeader("Expect").equalsIgnoreCase("100-Continue")) {

    //
    boolean rejectAndClose = true;
    if (rejectAndClose) {

      // Reject with a failure code and close the connection
      // this is probably best with persistent connection
      request.response()
        .setStatusCode(405)
        .putHeader("Connection", "close")
        .end();
    } else {

      // Reject with a failure code and ignore the body
      // this may be appropriate if the body is small
      request.response()
        .setStatusCode(405)
        .end();
    }
  }
});
```

#### [Creating HTTP tunnels](#_creating_http_tunnels)

HTTP tunnels can be created with `[connect](../../apidocs/io/vertx/core/http/HttpClientRequest.html#connect-io.vertx.core.Handler-)`:

```
client.request(HttpMethod.CONNECT, "some-uri")
  .onSuccess(request -> {

    // Connect to the server
    request
      .connect()
      .onComplete(ar -> {
        if (ar.succeeded()) {
          HttpClientResponse response = ar.result();

          if (response.statusCode() != 200) {
            // Connect failed for some reason
          } else {
            // Tunnel created, raw buffers are transmitted on the wire
            NetSocket socket = response.netSocket();
          }
        }
      });
  });
```

The handler will be called after the HTTP response header is received, the socket will be ready for tunneling and will send and receive buffers.

`connect` works like `send`, but it reconfigures the transport to exchange raw buffers.

#### [Client push](#_client_push)

Server push is a new feature of HTTP/2 that enables sending multiple responses in parallel for a single client request.

A push handler can be set on a request to receive the request/response pushed by the server:

```
client.request(HttpMethod.GET, "/index.html")
  .onSuccess(request -> {

    request
      .response().onComplete(response -> {
        // Process index.html response
      });

    // Set a push handler to be aware of any resource pushed by the server
    request.pushHandler(pushedRequest -> {

      // A resource is pushed for this request
      System.out.println("Server pushed " + pushedRequest.path());

      // Set an handler for the response
      pushedRequest.response().onComplete(pushedResponse -> {
        System.out.println("The response for the pushed request");
      });
    });

    // End the request
    request.end();
});
```

If the client does not want to receive a pushed request, it can reset the stream:

```
request.pushHandler(pushedRequest -> {
  if (pushedRequest.path().equals("/main.js")) {
    pushedRequest.reset();
  } else {
    // Handle it
  }
});
```

When no handler is set, any stream pushed will be automatically cancelled by the client with a stream reset (`8` error code).

#### [Receiving custom HTTP/2 frames](#_receiving_custom_http2_frames_2)

HTTP/2 is a framed protocol with various frames for the HTTP request/response model. The protocol allows other kind of frames to be sent and received.

To receive custom frames, you can use the customFrameHandler on the request, this will get called every time a custom frame arrives. Here’s an example:

```
response.customFrameHandler(frame -> {

  System.out.println("Received a frame type=" + frame.type() +
      " payload" + frame.payload().toString());
});
```

### [Enabling compression on the client](#_enabling_compression_on_the_client)

The http client comes with support for HTTP Compression out of the box.

This means the client can let the remote http server know that it supports compression, and will be able to handle compressed response bodies.

An http server is free to either compress with one of the supported compression algorithms or to send the body back without compressing it at all. So this is only a hint for the Http server which it may ignore at will.

To tell the http server which compression is supported by the client it will include an `Accept-Encoding` header with the supported compression algorithm as value. Multiple compression algorithms are supported. In case of Vert.x this will result in the following header added:

Accept-Encoding: gzip, deflate

The server will choose then from one of these. You can detect if a server compressed the body by checking for the `Content-Encoding` header in the response sent back from it.

If the body of the response was compressed via gzip it will include for example the following header:

Content-Encoding: gzip

To enable compression set `[setDecompressionSupported](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setDecompressionSupported-boolean-)` on the options used when creating the client.

By default compression is disabled.

### [HTTP/1.x pooling and keep alive](#_http1_x_pooling_and_keep_alive)

Http keep alive allows http connections to be used for more than one request. This can be a more efficient use of connections when you’re making multiple requests to the same server.

For HTTP/1.x versions, the http client supports pooling of connections, allowing you to reuse connections between requests.

For pooling to work, keep alive must be true using `[setKeepAlive](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setKeepAlive-boolean-)` on the options used when configuring the client. The default value is true.

When keep alive is enabled. Vert.x will add a `Connection: Keep-Alive` header to each HTTP/1.0 request sent. When keep alive is disabled. Vert.x will add a `Connection: Close` header to each HTTP/1.1 request sent to signal that the connection will be closed after completion of the response.

The maximum number of connections to pool **for each server** is configured using `[setMaxPoolSize](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setMaxPoolSize-int-)`

When making a request with pooling enabled, Vert.x will create a new connection if there are less than the maximum number of connections already created for that server, otherwise it will add the request to a queue.

Keep alive connections will be closed by the client automatically after a timeout. The timeout can be specified by the server using the `keep-alive` header:

```
keep-alive: timeout=30
```

You can set the default timeout using `[setKeepAliveTimeout](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setKeepAliveTimeout-int-)` - any connections not used within this timeout will be closed. Please note the timeout value is in seconds not milliseconds.

### [HTTP/1.1 pipe-lining](#_http1_1_pipe_lining)

The client also supports pipe-lining of requests on a connection.

Pipe-lining means another request is sent on the same connection before the response from the preceding one has returned. Pipe-lining is not appropriate for all requests.

To enable pipe-lining, it must be enabled using `[setPipelining](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setPipelining-boolean-)`. By default, pipe-lining is disabled.

When pipe-lining is enabled requests will be written to connections without waiting for previous responses to return.

The number of pipe-lined requests over a single connection is limited by `[setPipeliningLimit](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setPipeliningLimit-int-)`. This option defines the maximum number of http requests sent to the server awaiting for a response. This limit ensures the fairness of the distribution of the client requests over the connections to the same server.

### [HTTP/2 multiplexing](#_http2_multiplexing)

HTTP/2 advocates to use a single connection to a server, by default the http client uses a single connection for each server, all the streams to the same server are multiplexed over the same connection.

When the clients needs to use more than a single connection and use pooling, the `[setHttp2MaxPoolSize](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setHttp2MaxPoolSize-int-)` shall be used.

When it is desirable to limit the number of multiplexed streams per connection and use a connection pool instead of a single connection, `[setHttp2MultiplexingLimit](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setHttp2MultiplexingLimit-int-)` can be used.

```
HttpClientOptions clientOptions = new HttpClientOptions().
    setHttp2MultiplexingLimit(10).
    setHttp2MaxPoolSize(3);

// Uses up to 3 connections and up to 10 streams per connection
HttpClient client = vertx.createHttpClient(clientOptions);
```

The multiplexing limit for a connection is a setting set on the client that limits the number of streams of a single connection. The effective value can be even lower if the server sets a lower limit with the `[SETTINGS_MAX_CONCURRENT_STREAMS](../../apidocs/io/vertx/core/http/Http2Settings.html#setMaxConcurrentStreams-long-)` setting.

HTTP/2 connections will not be closed by the client automatically. To close them you can call `[close](../../apidocs/io/vertx/core/http/HttpConnection.html#close--)` or close the client instance.

Alternatively you can set idle timeout using `[setIdleTimeout](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setIdleTimeout-int-)` - any connections not used within this timeout will be closed. Please note the idle timeout value is in seconds not milliseconds.

### [HTTP connections](#_http_connections)

The `[HttpConnection](../../apidocs/io/vertx/core/http/HttpConnection.html)` offers the API for dealing with HTTP connection events, lifecycle and settings.

HTTP/2 implements fully the `[HttpConnection](../../apidocs/io/vertx/core/http/HttpConnection.html)` API.

HTTP/1.x implements partially the `[HttpConnection](../../apidocs/io/vertx/core/http/HttpConnection.html)` API: only the close operation, the close handler and exception handler are implemented. This protocol does not provide semantics for the other operations.

#### [Server connections](#_server_connections)

The `[connection](../../apidocs/io/vertx/core/http/HttpServerRequest.html#connection--)` method returns the request connection on the server:

```
HttpConnection connection = request.connection();
```

A connection handler can be set on the server to be notified of any incoming connection:

```
HttpServer server = vertx.createHttpServer(http2Options);

server.connectionHandler(connection -> {
  System.out.println("A client connected");
});
```

#### [Client connections](#_client_connections)

The `[connection](../../apidocs/io/vertx/core/http/HttpClientRequest.html#connection--)` method returns the request connection on the client:

```
HttpConnection connection = request.connection();
```

A connection handler can be set on a client builder to be notified when a connection has been established happens:

```
vertx
  .httpClientBuilder()
  .with(options)
  .withConnectHandler(connection -> {
    System.out.println("Connected to the server");
  })
  .build();
```

#### [Connection settings](#_connection_settings)

The configuration of an HTTP/2 is configured by the `[Http2Settings](../../apidocs/io/vertx/core/http/Http2Settings.html)` data object.

Each endpoint must respect the settings sent by the other side of the connection.

When a connection is established, the client and the server exchange initial settings. Initial settings are configured by `[setInitialSettings](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setInitialSettings-io.vertx.core.http.Http2Settings-)` on the client and `[setInitialSettings](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setInitialSettings-io.vertx.core.http.Http2Settings-)` on the server.

The settings can be changed at any time after the connection is established:

```
connection.updateSettings(new Http2Settings().setMaxConcurrentStreams(100));
```

As the remote side should acknowledge on reception of the settings update, it’s possible to give a callback to be notified of the acknowledgment:

```
connection
  .updateSettings(new Http2Settings().setMaxConcurrentStreams(100))
  .onSuccess(v -> System.out.println("The settings update has been acknowledged "));
```

Conversely the `[remoteSettingsHandler](../../apidocs/io/vertx/core/http/HttpConnection.html#remoteSettingsHandler-io.vertx.core.Handler-)` is notified when the new remote settings are received:

```
connection.remoteSettingsHandler(settings -> {
  System.out.println("Received new settings");
});
```

|  | this only applies to the HTTP/2 protocol |
| --- | --- |

#### [Connection ping](#_connection_ping)

HTTP/2 connection ping is useful for determining the connection round-trip time or check the connection validity: `[ping](../../apidocs/io/vertx/core/http/HttpConnection.html#ping-io.vertx.core.buffer.Buffer-io.vertx.core.Handler-)` sends a {@literal PING} frame to the remote endpoint:

```
Buffer data = Buffer.buffer();
for (byte i = 0;i < 8;i++) {
  data.appendByte(i);
}
connection
  .ping(data)
  .onSuccess(pong -> System.out.println("Remote side replied"));
```

Vert.x will send automatically an acknowledgement when a {@literal PING} frame is received, an handler can be set to be notified for each ping received:

```
connection.pingHandler(ping -> {
  System.out.println("Got pinged by remote side");
});
```

The handler is just notified, the acknowledgement is sent whatsoever. Such feature is aimed for implementing protocols on top of HTTP/2.

|  | this only applies to the HTTP/2 protocol |
| --- | --- |

#### [Connection shutdown and go away](#_connection_shutdown_and_go_away)

Calling `[shutdown](../../apidocs/io/vertx/core/http/HttpConnection.html#shutdown--)` will send a {@literal GOAWAY} frame to the remote side of the connection, asking it to stop creating streams: a client will stop doing new requests and a server will stop pushing responses. After the {@literal GOAWAY} frame is sent, the connection waits some time (30 seconds by default) until all current streams closed and close the connection:

```
connection.shutdown();
```

The `[shutdownHandler](../../apidocs/io/vertx/core/http/HttpConnection.html#shutdownHandler-io.vertx.core.Handler-)` notifies when all streams have been closed, the connection is not yet closed.

It’s possible to just send a {@literal GOAWAY} frame, the main difference with a shutdown is that it will just tell the remote side of the connection to stop creating new streams without scheduling a connection close:

```
connection.goAway(0);
```

Conversely, it is also possible to be notified when {@literal GOAWAY} are received:

```
connection.goAwayHandler(goAway -> {
  System.out.println("Received a go away frame");
});
```

The `[shutdownHandler](../../apidocs/io/vertx/core/http/HttpConnection.html#shutdownHandler-io.vertx.core.Handler-)` will be called when all current streams have been closed and the connection can be closed:

```
connection.goAway(0);
connection.shutdownHandler(v -> {

  // All streams are closed, close the connection
  connection.close();
});
```

This applies also when a {@literal GOAWAY} is received.

|  | this only applies to the HTTP/2 protocol |
| --- | --- |

#### [Connection close](#_connection_close)

Connection `[close](../../apidocs/io/vertx/core/http/HttpConnection.html#close--)` closes the connection:

* it closes the socket for HTTP/1.x
* a shutdown with no delay for HTTP/2, the {@literal GOAWAY} frame will still be sent before the connection is closed. \*

The `[closeHandler](../../apidocs/io/vertx/core/http/HttpConnection.html#closeHandler-io.vertx.core.Handler-)` notifies when a connection is closed.

### [Client sharing](#_client_sharing)

You can share an HTTP client between multiple verticles or instances of the same verticle. Such client should be created outside of a verticle otherwise it will be closed when the verticle that created it is undeployed

```
HttpClient client = vertx.createHttpClient(new HttpClientOptions().setShared(true));
vertx.deployVerticle(() -> new AbstractVerticle() {
  @Override
  public void start() throws Exception {
    // Use the client
  }
}, new DeploymentOptions().setInstances(4));
```

You can also create a shared HTTP client in each verticle:

```
vertx.deployVerticle(() -> new AbstractVerticle() {
  HttpClient client;
  @Override
  public void start() {
    // Get or create a shared client
    // this actually creates a lease to the client
    // when the verticle is undeployed, the lease will be released automaticaly
    client = vertx.createHttpClient(new HttpClientOptions().setShared(true).setName("my-client"));
  }
}, new DeploymentOptions().setInstances(4));
```

The first time a shared client is created it will create and return a client. Subsequent calls will reuse this client and create a lease to this client. The client is closed after all leases have been disposed.

By default, a client reuses the current event-loop when it needs to create a TCP connection. The HTTP client will therefore randomly use event-loops of verticles using it in a safe fashion.

You can assign a number of event loop a client will use independently of the client using it

```
vertx.deployVerticle(() -> new AbstractVerticle() {
  HttpClient client;
  @Override
  public void start() {
    // The client creates and use two event-loops for 4 instances
    client = vertx.createHttpClient(new HttpClientOptions().setShared(true).setName("my-client"), new PoolOptions().setEventLoopSize(2));
  }
}, new DeploymentOptions().setInstances(4));
```

### [Server sharing](#_server_sharing)

When several HTTP servers listen on the same port, vert.x orchestrates the request handling using a round-robin strategy.

Let’s take a verticle creating a HTTP server such as:

  io.vertx.examples.http.sharing.HttpServerVerticle
```
vertx.createHttpServer().requestHandler(request -> {
  request.response().end("Hello from server " + this);
}).listen(8080);
```

This service is listening on the port 8080. So, when this verticle is instantiated multiple times as with: `vertx run io.vertx.examples.http.sharing.HttpServerVerticle -instances 2`, what’s happening ? If both verticles would bind to the same port, you would receive a socket exception. Fortunately, vert.x is handling this case for you. When you deploy another server on the same host and port as an existing server it doesn’t actually try and create a new server listening on the same host/port. It binds only once to the socket. When receiving a request it calls the server handlers following a round robin strategy.

Let’s now imagine a client such as:

```
vertx.setPeriodic(100, (l) -> {
  vertx
    .createHttpClient()
    .request(HttpMethod.GET, 8080, "localhost", "/")
    .onComplete(ar1 -> {
      if (ar1.succeeded()) {
        HttpClientRequest request = ar1.result();
        request
          .send()
          .onComplete(ar2 -> {
            if (ar2.succeeded()) {
              HttpClientResponse resp = ar2.result();
              resp.bodyHandler(body -> {
                System.out.println(body.toString("ISO-8859-1"));
              });
            }
          });
      }
    });
});
```

Vert.x delegates the requests to one of the server sequentially:

```
Hello from i.v.e.h.s.HttpServerVerticle@1
Hello from i.v.e.h.s.HttpServerVerticle@2
Hello from i.v.e.h.s.HttpServerVerticle@1
Hello from i.v.e.h.s.HttpServerVerticle@2
...
```

Consequently the servers can scale over available cores while each Vert.x verticle instance remains strictly single threaded, and you don’t have to do any special tricks like writing load-balancers in order to scale your server on your multi-core machine.

You can bind on a shared random ports using a negative port value, the first bind will pick a port randomly, subsequent binds on the same port value will share this random port.

  io.vertx.examples.http.sharing.HttpServerVerticle
```
vertx.createHttpServer().requestHandler(request -> {
  request.response().end("Hello from server " + this);
}).listen(-1);
```

### [Using HTTPS with Vert.x](#_using_https_with_vert_x)

Vert.x http servers and clients can be configured to use HTTPS in exactly the same way as net servers.

Please see [configuring net servers to use SSL](#ssl) for more information.

SSL can also be enabled/disabled per request with `[RequestOptions](../../apidocs/io/vertx/core/http/RequestOptions.html)` or when specifying a scheme with `[setAbsoluteURI](../../apidocs/io/vertx/core/http/RequestOptions.html#setAbsoluteURI-java.lang.String-)` method.

```
client
  .request(new RequestOptions()
    .setHost("localhost")
    .setPort(8080)
    .setURI("/")
    .setSsl(true))
  .onComplete(ar1 -> {
    if (ar1.succeeded()) {
      HttpClientRequest request = ar1.result();
      request
        .send()
        .onComplete(ar2 -> {
          if (ar2.succeeded()) {
            HttpClientResponse response = ar2.result();
            System.out.println("Received response with status code " + response.statusCode());
          }
        });
    }
  });
```

The `[setSsl](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setSsl-boolean-)` setting acts as the default client setting.

The `[setSsl](../../apidocs/io/vertx/core/http/RequestOptions.html#setSsl-java.lang.Boolean-)` overrides the default client setting

* setting the value to `false` will disable SSL/TLS even if the client is configured to use SSL/TLS
* setting the value to `true` will enable SSL/TLS even if the client is configured to not use SSL/TLS, the actual client SSL/TLS (such as trust, key/certificate, ciphers, ALPN, …​) will be reused

Likewise `[setAbsoluteURI](../../apidocs/io/vertx/core/http/RequestOptions.html#setAbsoluteURI-java.lang.String-)` scheme also overrides the default client setting.

#### [Server Name Indication (SNI)](#_server_name_indication_sni_2)

Vert.x http servers can be configured to use SNI in exactly the same way as {@linkplain io.vertx.core.net net servers}.

Vert.x http client will present the actual hostname as *server name* during the TLS handshake.

### [WebSockets](#_websockets)

[WebSockets](https://en.wikipedia.org/wiki/WebSocket) are a web technology that allows a full duplex socket-like connection between HTTP servers and HTTP clients (typically browsers).

Vert.x supports WebSockets on both the client and server-side.

#### [WebSockets on the server](#_websockets_on_the_server)

There are two ways of handling WebSockets on the server side.

##### [WebSocket handler](#_websocket_handler)

The first way involves providing a `[webSocketHandler](../../apidocs/io/vertx/core/http/HttpServer.html#webSocketHandler-io.vertx.core.Handler-)` on the server instance.

When a WebSocket connection is made to the server, the handler will be called, passing in an instance of `[ServerWebSocket](../../apidocs/io/vertx/core/http/ServerWebSocket.html)`.

```
server.webSocketHandler(webSocket -> {
  System.out.println("Connected!");
});
```

##### [Server WebSocket handshake](#_server_websocket_handshake)

By default, the server accepts any inbound WebSocket.

You can set a WebSocket handshake handler to control the outcome of a WebSocket handshake, i.e. accept or reject an incoming WebSocket.

You can choose to reject the WebSocket by calling `[accept](../../apidocs/io/vertx/core/http/ServerWebSocketHandshake.html#accept--)` or `[reject](../../apidocs/io/vertx/core/http/ServerWebSocketHandshake.html#reject--)`.

```
server
  .webSocketHandshakeHandler(handshake -> {
    if (handshake.path().equals("/myapi")) {
      handshake.reject();
    } else {
      handshake.accept();
    }
  })
  .webSocketHandler(webSocket -> {
    // Do something
  });
```

You can perform an asynchronous handshake:

```
server
  .webSocketHandshakeHandler(handshake -> {
    authenticate(handshake.headers(), ar -> {
      if (ar.succeeded()) {
        if (ar.result()) {
          // Terminate the handshake with the status code 101 (Switching Protocol)
          handshake.accept();
        } else {
          // Reject the handshake with 401 (Unauthorized)
          handshake.reject(401);
        }
      } else {
        // Will send a 500 error
        handshake.reject(500);
      }
    });
  })
  .webSocketHandler(webSocket -> {
    // Do something
});
```

|  | the WebSocket will be automatically accepted after the handler is called unless the WebSocket’s handshake has been set |
| --- | --- |

##### [Upgrading to WebSocket](#_upgrading_to_websocket)

The second way of handling WebSockets is to handle the HTTP Upgrade request that was sent from the client, and call `[toWebSocket](../../apidocs/io/vertx/core/http/HttpServerRequest.html#toWebSocket--)` on the server request.

```
server.requestHandler(request -> {
  if (request.path().equals("/myapi")) {

    Future<ServerWebSocket> fut = request.toWebSocket();
    fut.onSuccess(ws -> {
      // Do something
    });

  } else {
    // Reject
    request.response().setStatusCode(400).end();
  }
});
```

##### [The server WebSocket](#_the_server_websocket)

The `[ServerWebSocket](../../apidocs/io/vertx/core/http/ServerWebSocket.html)` instance enables you to retrieve the `[headers](../../apidocs/io/vertx/core/http/WebSocketBase.html#headers--)`, `[path](../../apidocs/io/vertx/core/http/ServerWebSocket.html#path--)`, `[query](../../apidocs/io/vertx/core/http/ServerWebSocket.html#query--)` and `[URI](../../apidocs/io/vertx/core/http/ServerWebSocket.html#uri--)` of the HTTP request of the WebSocket handshake.

#### [WebSockets on the client](#_websockets_on_the_client)

The Vert.x `[WebSocketClient](../../apidocs/io/vertx/core/http/WebSocketClient.html)` supports WebSockets.

You can connect a WebSocket to a server using one of the `[connect](../../apidocs/io/vertx/core/http/WebSocketClient.html#connect-int-java.lang.String-java.lang.String-io.vertx.core.Handler-)` operations.

The returned future will be completed with an instance of `[WebSocket](../../apidocs/io/vertx/core/http/WebSocket.html)` when the connection has been made:

```
WebSocketClient client = vertx.createWebSocketClient();

client
  .connect(80, "example.com", "/some-uri")
  .onComplete(res -> {
    if (res.succeeded()) {
      WebSocket ws = res.result();
      ws.textMessageHandler(msg -> {
        // Handle msg
      });
      System.out.println("Connected!");
    }
  });
```

When connecting from a non Vert.x thread, you can create a `[ClientWebSocket](../../apidocs/io/vertx/core/http/ClientWebSocket.html)`, configure its handlers and then connect to the server:

```
WebSocketClient client = vertx.createWebSocketClient();

client
  .webSocket()
  .textMessageHandler(msg -> {
    // Handle msg
  })
  .connect(80, "example.com", "/some-uri")
  .onComplete(res -> {
    if (res.succeeded()) {
      WebSocket ws = res.result();
    }
  });
```

By default, the client sets the `origin` header to the server host, e.g <http://www.example.com>. Some servers will refuse such request, you can configure the client to not set this header.

```
WebSocketConnectOptions options = new WebSocketConnectOptions()
  .setHost(host)
  .setPort(port)
  .setURI(requestUri)
  .setAllowOriginHeader(false);
client
  .connect(options)
  .onComplete(res -> {
    if (res.succeeded()) {
      WebSocket ws = res.result();
      System.out.println("Connected!");
    }
  });
```

You can also set a different header:

```
WebSocketConnectOptions options = new WebSocketConnectOptions()
  .setHost(host)
  .setPort(port)
  .setURI(requestUri)
  .addHeader(HttpHeaders.ORIGIN, origin);
client
  .connect(options)
  .onComplete(res -> {
    if (res.succeeded()) {
      WebSocket ws = res.result();
      System.out.println("Connected!");
    }
  });
```

|  | older versions of the WebSocket protocol use `sec-websocket-origin` instead |
| --- | --- |

#### [Writing messages to WebSockets](#_writing_messages_to_websockets)

If you wish to write a single WebSocket message to the WebSocket you can do this with `[writeBinaryMessage](../../apidocs/io/vertx/core/http/WebSocketBase.html#writeBinaryMessage-io.vertx.core.buffer.Buffer-)` or `[writeTextMessage](../../apidocs/io/vertx/core/http/WebSocketBase.html#writeTextMessage-java.lang.String-)` :

```
Buffer buffer = Buffer.buffer().appendInt(123).appendFloat(1.23f);
webSocket.writeBinaryMessage(buffer);

// Write a simple text message
String message = "hello";
webSocket.writeTextMessage(message);
```

If the WebSocket message is larger than the maximum WebSocket frame size as configured with `[setMaxWebSocketFrameSize](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setMaxWebSocketFrameSize-int-)` then Vert.x will split it into multiple WebSocket frames before sending it on the wire.

#### [Writing frames to WebSockets](#_writing_frames_to_websockets)

A WebSocket message can be composed of multiple frames. In this case the first frame is either a *binary* or *text* frame followed by zero or more *continuation* frames.

The last frame in the message is marked as *final*.

To send a message consisting of multiple frames you create frames using `[WebSocketFrame.binaryFrame](../../apidocs/io/vertx/core/http/WebSocketFrame.html#binaryFrame-io.vertx.core.buffer.Buffer-boolean-)` , `[WebSocketFrame.textFrame](../../apidocs/io/vertx/core/http/WebSocketFrame.html#textFrame-java.lang.String-boolean-)` or `[WebSocketFrame.continuationFrame](../../apidocs/io/vertx/core/http/WebSocketFrame.html#continuationFrame-io.vertx.core.buffer.Buffer-boolean-)` and write them to the WebSocket using `[writeFrame](../../apidocs/io/vertx/core/http/WebSocketBase.html#writeFrame-io.vertx.core.http.WebSocketFrame-)`.

Here’s an example for binary frames:

```
WebSocketFrame frame1 = WebSocketFrame.binaryFrame(buffer1, false);
webSocket.writeFrame(frame1);

WebSocketFrame frame2 = WebSocketFrame.continuationFrame(buffer2, false);
webSocket.writeFrame(frame2);

// Write the final frame
WebSocketFrame frame3 = WebSocketFrame.continuationFrame(buffer2, true);
webSocket.writeFrame(frame3);
```

In many cases you just want to send a WebSocket message that consists of a single final frame, so we provide a couple of shortcut methods to do that with `[writeFinalBinaryFrame](../../apidocs/io/vertx/core/http/WebSocketBase.html#writeFinalBinaryFrame-io.vertx.core.buffer.Buffer-)` and `[writeFinalTextFrame](../../apidocs/io/vertx/core/http/WebSocketBase.html#writeFinalTextFrame-java.lang.String-)`.

Here’s an example:

```
webSocket.writeFinalTextFrame("Geronimo!");

// Send a WebSocket message consisting of a single final binary frame:

Buffer buff = Buffer.buffer().appendInt(12).appendString("foo");

webSocket.writeFinalBinaryFrame(buff);
```

#### [Reading frames from WebSockets](#_reading_frames_from_websockets)

To read frames from a WebSocket you use the `[frameHandler](../../apidocs/io/vertx/core/http/WebSocket.html#frameHandler-io.vertx.core.Handler-)`.

The frame handler will be called with instances of `[WebSocketFrame](../../apidocs/io/vertx/core/http/WebSocketFrame.html)` when a frame arrives, for example:

```
webSocket.frameHandler(frame -> {
  System.out.println("Received a frame of size!");
});
```

#### [Closing WebSockets](#_closing_websockets)

Use `[close](../../apidocs/io/vertx/core/http/WebSocketBase.html#close--)` to close the WebSocket connection when you have finished with it.

#### [Piping WebSockets](#_piping_websockets)

The `[WebSocket](../../apidocs/io/vertx/core/http/WebSocket.html)` instance is also a `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)` and a `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)` so it can be used with pipes.

When using a WebSocket as a write stream or a read stream it can only be used with WebSockets connections that are used with binary frames that are no split over multiple frames.

#### [Event bus handlers](#_event_bus_handlers)

Every WebSocket can register two handlers on the event bus, and when any data are received in these handlers, it writes the data to itself. Those are local subscriptions, not reachable from other clustered nodes.

This enables you to write data to a WebSocket which is potentially in a completely different verticle sending data to the address of that handler.

This feature is disabled by default, however you can enable it using `[setRegisterWebSocketWriteHandlers](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setRegisterWebSocketWriteHandlers-boolean-)` or `[setRegisterWriteHandlers](../../apidocs/io/vertx/core/http/WebSocketConnectOptions.html#setRegisterWriteHandlers-boolean-)`.

The addresses of the handlers are given by `[binaryHandlerID](../../apidocs/io/vertx/core/http/WebSocketBase.html#binaryHandlerID--)` and `[textHandlerID](../../apidocs/io/vertx/core/http/WebSocketBase.html#textHandlerID--)`.

### [Using a proxy for HTTP/HTTPS connections](#_using_a_proxy_for_httphttps_connections)

The http client supports accessing http/https URLs via a HTTP proxy (e.g. Squid) or *SOCKS4a* or *SOCKS5* proxy. The CONNECT protocol uses HTTP/1.x but can connect to HTTP/1.x and HTTP/2 servers.

Connecting to h2c (unencrypted HTTP/2 servers) is likely not supported by http proxies since they will support HTTP/1.1 only.

The proxy can be configured in the `[HttpClientOptions](../../apidocs/io/vertx/core/http/HttpClientOptions.html)` by setting a `[ProxyOptions](../../apidocs/io/vertx/core/net/ProxyOptions.html)` object containing proxy type, hostname, port and optionally username and password.

Here’s an example of using an HTTP proxy:

```
HttpClientOptions options = new HttpClientOptions()
  .setProxyOptions(new ProxyOptions().setType(ProxyType.HTTP)
    .setHost("localhost").setPort(3128)
    .setUsername("username").setPassword("secret"));
HttpClient client = vertx.createHttpClient(options);
```

When the client connects to an http URL, it connects to the proxy server and provides the full URL in the HTTP request ("GET <http://www.somehost.com/path/file.html> HTTP/1.1").

When the client connects to an https URL, it asks the proxy to create a tunnel to the remote host with the CONNECT method.

For a SOCKS5 proxy:

```
HttpClientOptions options = new HttpClientOptions()
  .setProxyOptions(new ProxyOptions().setType(ProxyType.SOCKS5)
    .setHost("localhost").setPort(1080)
    .setUsername("username").setPassword("secret"));
HttpClient client = vertx.createHttpClient(options);
```

The DNS resolution is always done on the proxy server, to achieve the functionality of a SOCKS4 client, it is necessary to resolve the DNS address locally.

Proxy options can also be set per request:

```
client.request(new RequestOptions()
    .setHost("example.com")
    .setProxyOptions(proxyOptions))
  .compose(request -> request
    .send()
    .compose(HttpClientResponse::body))
  .onSuccess(body -> {
    System.out.println("Received response");
  });
```

|  | client connection pooling is aware of proxies (including authentication), consequently two requests to the same host through different proxies do not share the same pooled connection |
| --- | --- |

You can use `[setNonProxyHosts](../../apidocs/io/vertx/core/http/HttpClientOptions.html#setNonProxyHosts-java.util.List-)` to configure a list of host bypassing the proxy. The lists accept `*` wildcard for matching domains:

```
HttpClientOptions options = new HttpClientOptions()
  .setProxyOptions(new ProxyOptions().setType(ProxyType.SOCKS5)
    .setHost("localhost").setPort(1080)
    .setUsername("username").setPassword("secret"))
  .addNonProxyHost("*.foo.com")
  .addNonProxyHost("localhost");
HttpClient client = vertx.createHttpClient(options);
```

#### [Handling of other protocols](#_handling_of_other_protocols)

The HTTP proxy implementation supports getting ftp:// urls if the proxy supports that.

When the HTTP request URI contains the full URL then the client will not compute a full HTTP url and instead use the full URL specified in the request URI:

```
HttpClientOptions options = new HttpClientOptions()
  .setProxyOptions(new ProxyOptions().setType(ProxyType.HTTP));
HttpClient client = vertx.createHttpClient(options);
client
  .request(HttpMethod.GET, "ftp://ftp.gnu.org/gnu/")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      HttpClientRequest request = ar.result();
      request
        .send()
        .onComplete(ar2 -> {
          if (ar2.succeeded()) {
            HttpClientResponse response = ar2.result();
            System.out.println("Received response with status code " + response.statusCode());
          }
        });
    }
  });
```

### [Using HA PROXY protocol](#_using_ha_proxy_protocol_2)

[HA PROXY protocol](https://www.haproxy.org/download/1.8/doc/proxy-protocol.txt) provides a convenient way to safely transport connection information such as a client’s address across multiple layers of NAT or TCP proxies.

HA PROXY protocol can be enabled by setting the option `[setUseProxyProtocol](../../apidocs/io/vertx/core/http/HttpServerOptions.html#setUseProxyProtocol-boolean-)` and adding the following dependency in your classpath:

```
<dependency>
 <groupId>io.netty</groupId>
 <artifactId>netty-codec-haproxy</artifactId>
 <!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
```

```
HttpServerOptions options = new HttpServerOptions()
  .setUseProxyProtocol(true);

HttpServer server = vertx.createHttpServer(options);
server.requestHandler(request -> {
  // Print the actual client address provided by the HA proxy protocol instead of the proxy address
  System.out.println(request.remoteAddress());

  // Print the address of the proxy
  System.out.println(request.localAddress());
});
```

### [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles_4)

If you’re creating http servers and clients from inside verticles, those servers and clients will be automatically closed when the verticle is undeployed.

## [Using the SharedData API](#_using_the_shareddata_api)

As its name suggests, the `[SharedData](../../apidocs/io/vertx/core/shareddata/SharedData.html)` API allows you to safely share data between:

* different parts of your application, or
* different applications in the same Vert.x instance, or
* different applications across a cluster of Vert.x instances.

In practice, it provides:

* synchronous maps (local-only)
* asynchronous maps
* asynchronous locks
* asynchronous counters

|  | The behavior of the distributed data structure depends on the cluster manager you use. Backup (replication) and behavior when a network partition is faced are defined by the cluster manager and its configuration. Please refer to the cluster manager documentation as well as to the underlying framework manual. |
| --- | --- |

### [Local maps](#_local_maps)

`[Local maps](../../apidocs/io/vertx/core/shareddata/LocalMap.html)` allow you to share data safely between different event loops (e.g. different verticles) in the same Vert.x instance.

They only allow certain data types to be used as keys and values:

* immutable types (e.g. strings, booleans, …​ etc), or
* types implementing the `[Shareable](../../apidocs/io/vertx/core/shareddata/Shareable.html)` interface (buffers, JSON arrays, JSON objects, or your own shareable objects).

In the latter case the key/value will be copied before putting it into the map.

This way we can ensure there is no *shared access to mutable state* between different threads in your Vert.x application. And you won’t have to worry about protecting that state by synchronising access to it.

|  | As a convenience, objects implementing `[ClusterSerializable](../../apidocs/io/vertx/core/shareddata/ClusterSerializable.html)` or `java.io.Serializable` can be used as keys and values too. In this case, the key/value will be copied before putting it into the map by serializing/deserializing. Therefore, it is recommended to consider implementing `[Shareable](../../apidocs/io/vertx/core/shareddata/Shareable.html)` instead for better performance. |
| --- | --- |

Here’s an example of using a shared local map:

```
SharedData sharedData = vertx.sharedData();

LocalMap<String, String> map1 = sharedData.getLocalMap("mymap1");

map1.put("foo", "bar"); // Strings are immutable so no need to copy

LocalMap<String, Buffer> map2 = sharedData.getLocalMap("mymap2");

map2.put("eek", Buffer.buffer().appendInt(123)); // This buffer will be copied before adding to map

// Then... in another part of your application:

map1 = sharedData.getLocalMap("mymap1");

String val = map1.get("foo");

map2 = sharedData.getLocalMap("mymap2");

Buffer buff = map2.get("eek");
```

### [Asynchronous shared maps](#_asynchronous_shared_maps)

`[Asynchronous shared maps](../../apidocs/io/vertx/core/shareddata/AsyncMap.html)` allow data to be put in the map and retrieved locally or from any other node.

This makes them really useful for things like storing session state in a farm of servers hosting a Vert.x Web application.

They only allow certain data types to be used as keys and values:

* immutable types (e.g. strings, booleans, …​ etc), or
* types implementing the `[ClusterSerializable](../../apidocs/io/vertx/core/shareddata/ClusterSerializable.html)` interface (buffers, JSON arrays, JSON objects, or your own cluster serializable objects), or
* types implementing the `java.io.Serializable` interface.

Getting the map is asynchronous and the result is returned to you in the handler that you specify. Here’s an example:

```
SharedData sharedData = vertx.sharedData();

sharedData.
  <String, String>getAsyncMap("mymap")
  .onComplete(res -> {
    if (res.succeeded()) {
      AsyncMap<String, String> map = res.result();
    } else {
      // Something went wrong!
    }
  });
```

When Vert.x is clustered, data that you put into the map is accessible locally as well as on any of the other cluster members.

|  | In clustered mode, asynchronous shared maps rely on distributed data structures provided by the cluster manager. Beware that the latency relative to asynchronous shared map operations can be much higher in clustered than in local mode. |
| --- | --- |

If your application doesn’t need data to be shared with every other node, you can retrieve a local-only map:

```
SharedData sharedData = vertx.sharedData();

sharedData.
  <String, String>getLocalAsyncMap("mymap")
  .onComplete(res -> {
    if (res.succeeded()) {
      // Local-only async map
      AsyncMap<String, String> map = res.result();
    } else {
      // Something went wrong!
    }
  });
```

#### [Putting data in a map](#_putting_data_in_a_map)

You put data in a map with `[put](../../apidocs/io/vertx/core/shareddata/AsyncMap.html#put-java.lang.Object-java.lang.Object-io.vertx.core.Handler-)`.

The actual put is asynchronous and the handler is notified once it is complete:

```
map
  .put("foo", "bar")
  .onComplete(resPut -> {
    if (resPut.succeeded()) {
      // Successfully put the value
    } else {
      // Something went wrong!
    }
  });
```

#### [Getting data from a map](#_getting_data_from_a_map)

You get data from a map with `[get](../../apidocs/io/vertx/core/shareddata/AsyncMap.html#get-java.lang.Object-io.vertx.core.Handler-)`.

The actual get is asynchronous and the handler is notified with the result some time later:

```
map
  .get("foo")
  .onComplete(resGet -> {
    if (resGet.succeeded()) {
      // Successfully got the value
      Object val = resGet.result();
    } else {
      // Something went wrong!
    }
  });
```

##### [Other map operations](#_other_map_operations)

You can also remove entries from an asynchronous map, clear them and get the size.

See the `[API docs](../../apidocs/io/vertx/core/shareddata/AsyncMap.html)` for a detailed list of map operations.

### [Asynchronous locks](#_asynchronous_locks)

`[Asynchronous locks](../../apidocs/io/vertx/core/shareddata/Lock.html)` allow you to obtain exclusive locks locally or across the cluster. This is useful when you want to do something or access a resource on only one node of a cluster at any one time.

Asynchronous locks have an asynchronous API unlike most lock APIs which block the calling thread until the lock is obtained.

To obtain a lock use `[getLock](../../apidocs/io/vertx/core/shareddata/SharedData.html#getLock-java.lang.String-io.vertx.core.Handler-)`. This won’t block, but when the lock is available, the handler will be called with an instance of `[Lock](../../apidocs/io/vertx/core/shareddata/Lock.html)`, signalling that you now own the lock.

While you own the lock, no other caller, locally or on the cluster, will be able to obtain the lock.

When you’ve finished with the lock, you call `[release](../../apidocs/io/vertx/core/shareddata/Lock.html#release--)` to release it, so another caller can obtain it:

```
SharedData sharedData = vertx.sharedData();

sharedData
  .getLock("mylock")
  .onComplete(res -> {
    if (res.succeeded()) {
      // Got the lock!
      Lock lock = res.result();

      // 5 seconds later we release the lock so someone else can get it

      vertx.setTimer(5000, tid -> lock.release());

    } else {
      // Something went wrong
    }
  });
```

You can also get a lock with a timeout. If it fails to obtain the lock within the timeout the handler will be called with a failure:

```
SharedData sharedData = vertx.sharedData();

sharedData
  .getLockWithTimeout("mylock", 10000)
  .onComplete(res -> {
    if (res.succeeded()) {
      // Got the lock!
      Lock lock = res.result();

    } else {
      // Failed to get lock
    }
  });
```

See the `[API docs](../../apidocs/io/vertx/core/shareddata/Lock.html)` for a detailed list of lock operations.

|  | In clustered mode, asynchronous locks rely on distributed data structures provided by the cluster manager. Beware that the latency relative to asynchronous shared lock operations can be much higher in clustered than in local mode. |
| --- | --- |

If your application doesn’t need the lock to be shared with every other node, you can retrieve a local-only lock:

```
SharedData sharedData = vertx.sharedData();

sharedData
  .getLocalLock("mylock")
  .onComplete(res -> {
    if (res.succeeded()) {
      // Local-only lock
      Lock lock = res.result();

      // 5 seconds later we release the lock so someone else can get it

      vertx.setTimer(5000, tid -> lock.release());

    } else {
      // Something went wrong
    }
  });
```

### [Asynchronous counters](#_asynchronous_counters)

It’s often useful to maintain an atomic counter locally or across the different nodes of your application.

You can do this with `[Counter](../../apidocs/io/vertx/core/shareddata/Counter.html)`.

You obtain an instance with `[getCounter](../../apidocs/io/vertx/core/shareddata/SharedData.html#getCounter-java.lang.String-io.vertx.core.Handler-)`:

```
SharedData sharedData = vertx.sharedData();

sharedData
  .getCounter("mycounter")
  .onComplete(res -> {
    if (res.succeeded()) {
      Counter counter = res.result();
    } else {
      // Something went wrong!
    }
  });
```

Once you have an instance you can retrieve the current count, atomically increment it, decrement and add a value to it using the various methods.

See the `[API docs](../../apidocs/io/vertx/core/shareddata/Counter.html)` for a detailed list of counter operations.

|  | In clustered mode, asynchronous counters rely on distributed data structures provided by the cluster manager. Beware that the latency relative to asynchronous shared counter operations can be much higher in clustered than in local mode. |
| --- | --- |

If your application doesn’t need the counter to be shared with every other node, you can retrieve a local-only counter:

```
SharedData sharedData = vertx.sharedData();

sharedData
  .getLocalCounter("mycounter")
  .onComplete(res -> {
    if (res.succeeded()) {
      // Local-only counter
      Counter counter = res.result();
    } else {
      // Something went wrong!
    }
  });
```

## [Using the file system with Vert.x](#_using_the_file_system_with_vert_x)

The Vert.x `[FileSystem](../../apidocs/io/vertx/core/file/FileSystem.html)` object provides many operations for manipulating the file system.

There is one file system object per Vert.x instance, and you obtain it with `[fileSystem](../../apidocs/io/vertx/core/Vertx.html#fileSystem--)`.

A blocking and a non blocking version of each operation is provided. The non blocking versions take a handler which is called when the operation completes or an error occurs.

Here’s an example of an asynchronous copy of a file:

```
FileSystem fs = vertx.fileSystem();

// Copy file from foo.txt to bar.txt
fs.copy("foo.txt", "bar.txt")
  .onComplete(res -> {
    if (res.succeeded()) {
      // Copied ok!
    } else {
      // Something went wrong
    }
  });
```

The blocking versions are named `xxxBlocking` and return the results or throw exceptions directly. In many cases, depending on the operating system and file system, some of the potentially blocking operations can return quickly, which is why we provide them, but it’s highly recommended that you test how long they take to return in your particular application before using them from an event loop, so as not to break the Golden Rule.

Here’s the copy using the blocking API:

```
FileSystem fs = vertx.fileSystem();

// Copy file from foo.txt to bar.txt synchronously
fs.copyBlocking("foo.txt", "bar.txt");
```

Many operations exist to copy, move, truncate, chmod and many other file operations. We won’t list them all here, please consult the `[API docs](../../apidocs/io/vertx/core/file/FileSystem.html)` for the full list.

Let’s see a couple of examples using asynchronous methods:

```
vertx.fileSystem()
  .readFile("target/classes/readme.txt")
  .onComplete(result -> {
    if (result.succeeded()) {
      System.out.println(result.result());
    } else {
      System.err.println("Oh oh ..." + result.cause());
    }
  });

// Copy a file
vertx.fileSystem()
  .copy("target/classes/readme.txt", "target/classes/readme2.txt")
  .onComplete(result -> {
    if (result.succeeded()) {
      System.out.println("File copied");
    } else {
      System.err.println("Oh oh ..." + result.cause());
    }
  });

// Write a file
vertx.fileSystem()
  .writeFile("target/classes/hello.txt", Buffer.buffer("Hello"))
  .onComplete(result -> {
    if (result.succeeded()) {
      System.out.println("File written");
    } else {
      System.err.println("Oh oh ..." + result.cause());
    }
  });

// Check existence and delete
vertx.fileSystem()
  .exists("target/classes/junk.txt")
  .compose(exist -> {
    if (exist) {
      return vertx.fileSystem().delete("target/classes/junk.txt");
    } else {
      return Future.failedFuture("File does not exist");
    }
  }).onComplete(result -> {
    if (result.succeeded()) {
      System.out.println("File deleted");
    } else {
      System.err.println("Oh oh ... - cannot delete the file: " + result.cause().getMessage());
    }
  });
```

### [Asynchronous files](#_asynchronous_files)

Vert.x provides an asynchronous file abstraction that allows you to manipulate a file on the file system.

You open an `[AsyncFile](../../apidocs/io/vertx/core/file/AsyncFile.html)` as follows:

```
OpenOptions options = new OpenOptions();
fileSystem
  .open("myfile.txt", options)
  .onComplete(res -> {
    if (res.succeeded()) {
      AsyncFile file = res.result();
    } else {
      // Something went wrong!
    }
  });
```

`AsyncFile` implements `ReadStream` and `WriteStream` so you can *pipe* files to and from other stream objects such as net sockets, http requests and responses, and WebSockets.

They also allow you to read and write directly to them.

#### [Random access writes](#_random_access_writes)

To use an `AsyncFile` for random access writing you use the `[write](../../apidocs/io/vertx/core/file/AsyncFile.html#write-io.vertx.core.buffer.Buffer-long-io.vertx.core.Handler-)` method.

The parameters to the method are:

* `buffer`: the buffer to write.
* `position`: an integer position in the file where to write the buffer. If the position is greater or equal to the size of the file, the file will be enlarged to accommodate the offset.
* `handler`: the result handler

Here is an example of random access writes:

```
vertx.fileSystem()
  .open("target/classes/hello.txt", new OpenOptions())
  .onComplete(result -> {
    if (result.succeeded()) {
      AsyncFile file = result.result();
      Buffer buff = Buffer.buffer("foo");
      for (int i = 0; i < 5; i++) {
        file
          .write(buff, buff.length() * i)
          .onComplete(ar -> {
            if (ar.succeeded()) {
              System.out.println("Written ok!");
              // etc
            } else {
              System.err.println("Failed to write: " + ar.cause());
            }
          });
      }
    } else {
      System.err.println("Cannot open file " + result.cause());
    }
  });
```

#### [Random access reads](#_random_access_reads)

To use an `AsyncFile` for random access reads you use the `[read](../../apidocs/io/vertx/core/file/AsyncFile.html#read-io.vertx.core.buffer.Buffer-int-long-int-io.vertx.core.Handler-)` method.

The parameters to the method are:

* `buffer`: the buffer into which the data will be read.
* `offset`: an integer offset into the buffer where the read data will be placed.
* `position`: the position in the file where to read data from.
* `length`: the number of bytes of data to read
* `handler`: the result handler

Here’s an example of random access reads:

```
vertx.fileSystem()
  .open("target/classes/les_miserables.txt", new OpenOptions())
  .onComplete(result -> {
    if (result.succeeded()) {
      AsyncFile file = result.result();
      Buffer buff = Buffer.buffer(1000);
      for (int i = 0; i < 10; i++) {
        file
          .read(buff, i * 100, i * 100, 100)
          .onComplete(ar -> {
            if (ar.succeeded()) {
              System.out.println("Read ok!");
            } else {
              System.err.println("Failed to write: " + ar.cause());
            }
          });
      }
    } else {
      System.err.println("Cannot open file " + result.cause());
    }
  });
```

#### [Opening Options](#_opening_options)

When opening an `AsyncFile`, you pass an `[OpenOptions](../../apidocs/io/vertx/core/file/OpenOptions.html)` instance. These options describe the behavior of the file access. For instance, you can configure the file permissions with the `[setRead](../../apidocs/io/vertx/core/file/OpenOptions.html#setRead-boolean-)`, `[setWrite](../../apidocs/io/vertx/core/file/OpenOptions.html#setWrite-boolean-)` and `[setPerms](../../apidocs/io/vertx/core/file/OpenOptions.html#setPerms-java.lang.String-)` methods.

You can also configure the behavior if the open file already exists with `[setCreateNew](../../apidocs/io/vertx/core/file/OpenOptions.html#setCreateNew-boolean-)` and `[setTruncateExisting](../../apidocs/io/vertx/core/file/OpenOptions.html#setTruncateExisting-boolean-)`.

You can also mark the file to be deleted on close or when the JVM is shutdown with `[setDeleteOnClose](../../apidocs/io/vertx/core/file/OpenOptions.html#setDeleteOnClose-boolean-)`.

#### [Flushing data to underlying storage.](#_flushing_data_to_underlying_storage)

In the `OpenOptions`, you can enable/disable the automatic synchronisation of the content on every write using `[setDsync](../../apidocs/io/vertx/core/file/OpenOptions.html#setDsync-boolean-)`. In that case, you can manually flush any writes from the OS cache by calling the `[flush](../../apidocs/io/vertx/core/file/AsyncFile.html#flush--)` method.

This method can also be called with a handler which will be called when the flush is complete.

#### [Using AsyncFile as ReadStream and WriteStream](#_using_asyncfile_as_readstream_and_writestream)

`AsyncFile` implements `ReadStream` and `WriteStream`. You can then use them with a *pipe* to pipe data to and from other read and write streams. For example, this would copy the content to another `AsyncFile`:

```
final AsyncFile output = vertx.fileSystem().openBlocking("target/classes/plagiary.txt", new OpenOptions());

vertx.fileSystem()
  .open("target/classes/les_miserables.txt", new OpenOptions())
  .compose(file -> file
    .pipeTo(output)
    .eventually(v -> file.close()))
  .onComplete(result -> {
    if (result.succeeded()) {
      System.out.println("Copy done");
    } else {
      System.err.println("Cannot copy file " + result.cause().getMessage());
    }
  });
```

You can also use the *pipe* to write file content into HTTP responses, or more generally in any `WriteStream`.

#### [Accessing files from the classpath](#classpath)

When vert.x cannot find the file on the filesystem it tries to resolve the file from the class path. Note that classpath resource paths never start with a `/`.

Due to the fact that Java does not offer async access to classpath resources, the file is copied to the filesystem in a worker thread when the classpath resource is accessed the very first time and served from there asynchronously. When the same resource is accessed a second time, the file from the filesystem is served directly from the filesystem. The original content is served even if the classpath resource changes (e.g. in a development system).

This caching behaviour can be set on the `[setFileCachingEnabled](../../apidocs/io/vertx/core/file/FileSystemOptions.html#setFileCachingEnabled-boolean-)` option. The default value of this option is `true` unless the system property `vertx.disableFileCaching` is defined.

The path where the files are cached is `/tmp/vertx-cache-UUID` by default and can be customized by setting the system property `vertx.cacheDirBase`. When using this property, note that it should refer to a directory prefix in a process read/writeable location, for example: `-Dvertx.cacheDirBase=/tmp/my-vertx-cache` (Note that there’s no UUID).

Each vert.x process will append it’s own UUID in order to keep caches independently of different applications running on the same machine.

The whole classpath resolving feature can be disabled system-wide by setting the system property `vertx.disableFileCPResolving` to `true`.

|  | these system properties are evaluated once when the `io.vertx.core.file.FileSystemOptions` class is loaded, so these properties should be set before loading this class or as a JVM system property when launching it. |
| --- | --- |

If you want to disable classpath resolving for a particular application but keep it enabled by default system-wide, you can do so via the `[setClassPathResolvingEnabled](../../apidocs/io/vertx/core/file/FileSystemOptions.html#setClassPathResolvingEnabled-boolean-)` option.

#### [Closing an AsyncFile](#_closing_an_asyncfile)

To close an `AsyncFile` call the `[close](../../apidocs/io/vertx/core/file/AsyncFile.html#close--)` method. Closing is asynchronous and if you want to be notified when the close has been completed you can specify a handler function as an argument.

## [Datagram sockets (UDP)](#_datagram_sockets_udp)

Using User Datagram Protocol (UDP) with Vert.x is a piece of cake.

UDP is a connection-less transport which basically means you have no persistent connection to a remote peer.

Instead, you can send and receive packages and the remote address is contained in each of them.

Beside this UDP is not as safe as TCP to use, which means there are no guarantees that a send Datagram packet will receive it’s endpoint at all.

The only guarantee is that it will either receive complete or not at all.

Also, you usually can’t send data which is bigger then the MTU size of your network interface, this is because each packet will be send as one packet.

But, be aware even if the packet size is smaller then the MTU it may still fail.

At which size it will fail depends on the Operating System etc. So rule of thumb is to try to send small packets.

Because of the nature of UDP it is best fit for Applications where you are allowed to drop packets (like for example a monitoring application).

The benefits are that it has a lot less overhead compared to TCP, which can be handled by the NetServer and NetClient (see above).

### [Creating a DatagramSocket](#_creating_a_datagramsocket)

To use UDP you first need t create a `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)`. It does not matter here if you only want to send data or send and receive.

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());
```

The returned `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` will not be bound to a specific port. This is not a problem if you only want to send data (like a client), but more on this in the next section.

### [Sending Datagram packets](#_sending_datagram_packets)

As mentioned before, User Datagram Protocol (UDP) sends data in packets to remote peers but is not connected to them in a persistent fashion.

This means each packet can be sent to a different remote peer.

Sending packets is as easy as shown here:

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());
Buffer buffer = Buffer.buffer("content");
// Send a Buffer
socket
  .send(buffer, 1234, "10.0.0.1")
  .onComplete(asyncResult -> System.out.println("Send succeeded? " + asyncResult.succeeded()));
// Send a String
socket
  .send("A string used as content", 1234, "10.0.0.1")
  .onComplete(asyncResult -> System.out.println("Send succeeded? " + asyncResult.succeeded()));
```

### [Receiving Datagram packets](#_receiving_datagram_packets)

If you want to receive packets you need to bind the `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` by calling `listen(…​)}` on it.

This way you will be able to receive `[DatagramPacket](../../apidocs/io/vertx/core/datagram/DatagramPacket.html)`s that were sent to the address and port on which the `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` listens.

Beside this you also want to set a `Handler` which will be called for each received `[DatagramPacket](../../apidocs/io/vertx/core/datagram/DatagramPacket.html)`.

The `[DatagramPacket](../../apidocs/io/vertx/core/datagram/DatagramPacket.html)` has the following methods:

* `[sender](../../apidocs/io/vertx/core/datagram/DatagramPacket.html#sender--)`: The InetSocketAddress which represent the sender of the packet
* `[data](../../apidocs/io/vertx/core/datagram/DatagramPacket.html#data--)`: The Buffer which holds the data which was received.

So to listen on a specific address and port you would do something like shown here:

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());
socket
  .handler(packet -> {
    // Do something with the packet
  })
  .listen(1234, "0.0.0.0")
  .onComplete(asyncResult -> System.out.println("Send succeeded? " + asyncResult.succeeded()));
;
```

Be aware that even if the {code AsyncResult} is successed it only means it might be written on the network stack, but gives no guarantee that it ever reached or will reach the remote peer at all.

If you need such a guarantee then you want to use TCP with some handshaking logic build on top.

### [Multicast](#_multicast)

#### [Sending Multicast packets](#_sending_multicast_packets)

Multicast allows multiple sockets to receive the same packets. This works by having the sockets join the same multicast group to which you can then send packets.

We will look at how you can join a Multicast Group and receive packets in the next section.

Sending multicast packets is not different from sending normal Datagram packets. The difference is that you pass in a multicast group address to the send method.

This is show here:

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());
Buffer buffer = Buffer.buffer("content");
// Send a Buffer to a multicast address
socket
  .send(buffer, 1234, "230.0.0.1")
  .onComplete(asyncResult -> System.out.println("Send succeeded? " + asyncResult.succeeded()));
```

All sockets that have joined the multicast group 230.0.0.1 will receive the packet.

##### [Receiving Multicast packets](#_receiving_multicast_packets)

If you want to receive packets for specific Multicast group you need to bind the `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` by calling `listen(…​)` on it to join the Multicast group.

This way you will receive DatagramPackets that were sent to the address and port on which the `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` listens and also to those sent to the Multicast group.

Beside this you also want to set a Handler which will be called for each received DatagramPacket.

The `[DatagramPacket](../../apidocs/io/vertx/core/datagram/DatagramPacket.html)` has the following methods:

* `sender()`: The InetSocketAddress which represent the sender of the packet
* `data()`: The Buffer which holds the data which was received.

So to listen on a specific address and port and also receive packets for the Multicast group 230.0.0.1 you would do something like shown here:

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());
socket
  .handler(packet -> {
    // Do something with the packet
  })
  .listen(1234, "0.0.0.0")
  .compose(v -> socket.listenMulticastGroup("230.0.0.1")) // join the multicast group
  .onComplete(asyncResult -> System.out.println("Listen succeeded? " + asyncResult.succeeded()));
```

##### [Unlisten / leave a Multicast group](#_unlisten_leave_a_multicast_group)

There are sometimes situations where you want to receive packets for a Multicast group for a limited time.

In this situations you can first start to listen for them and then later unlisten.

This is shown here:

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());
socket
  .handler(packet -> {
    // Do something with the packet
  })
  .listen(1234, "0.0.0.0")
  .compose(v -> socket.listenMulticastGroup("230.0.0.1")) // join the multicast group
  .onComplete(asyncResult -> {
    if (asyncResult.succeeded()) {
      // will now receive packets for group

      // do some work

      socket.unlistenMulticastGroup("230.0.0.1").onComplete(asyncResult2 -> {
        System.out.println("Unlisten succeeded? " + asyncResult2.succeeded());
      });
    } else {
      System.out.println("Listen failed" + asyncResult.cause());
    }
  });
```

##### [Blocking multicast](#_blocking_multicast)

Beside unlisten a Multicast address it’s also possible to just block multicast for a specific sender address.

Be aware this only work on some Operating Systems and kernel versions. So please check the Operating System documentation if it’s supported.

This an expert feature.

To block multicast from a specific address you can call `blockMulticastGroup(…​)` on the DatagramSocket like shown here:

```
DatagramSocket socket = vertx.createDatagramSocket(new DatagramSocketOptions());

// Some code

// This would block packets which are send from 10.0.0.2
socket
  .blockMulticastGroup("230.0.0.1", "10.0.0.2")
  .onComplete(asyncResult -> System.out.println("block succeeded? " + asyncResult.succeeded()));
```

#### [DatagramSocket properties](#_datagramsocket_properties)

When creating a `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` there are multiple properties you can set to change it’s behaviour with the `[DatagramSocketOptions](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html)` object. Those are listed here:

* `[setSendBufferSize](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setSendBufferSize-int-)` Sets the send buffer size in bytes.
* `[setReceiveBufferSize](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setReceiveBufferSize-int-)` Sets the TCP receive buffer size in bytes.
* `[setReuseAddress](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setReuseAddress-boolean-)` If true then addresses in TIME\_WAIT state can be reused after they have been closed.
* `[setTrafficClass](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setTrafficClass-int-)`
* `[setBroadcast](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setBroadcast-boolean-)` Sets or clears the SO\_BROADCAST socket option. When this option is set, Datagram (UDP) packets may be sent to a local interface’s broadcast address.
* `[setMulticastNetworkInterface](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setMulticastNetworkInterface-java.lang.String-)` Sets or clears the IP\_MULTICAST\_LOOP socket option. When this option is set, multicast packets will also be received on the local interface.
* `[setMulticastTimeToLive](../../apidocs/io/vertx/core/datagram/DatagramSocketOptions.html#setMulticastTimeToLive-int-)` Sets the IP\_MULTICAST\_TTL socket option. TTL stands for "Time to Live," but in this context it specifies the number of IP hops that a packet is allowed to go through, specifically for multicast traffic. Each router or gateway that forwards a packet decrements the TTL. If the TTL is decremented to 0 by a router, it will not be forwarded.

#### [DatagramSocket Local Address](#_datagramsocket_local_address)

You can find out the local address of the socket (i.e. the address of this side of the UDP Socket) by calling `[localAddress](../../apidocs/io/vertx/core/datagram/DatagramSocket.html#localAddress--)`. This will only return an `InetSocketAddress` if you bound the `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)` with `listen(…​)` before, otherwise it will return null.

#### [Closing a DatagramSocket](#_closing_a_datagramsocket)

You can close a socket by invoking the `[close](../../apidocs/io/vertx/core/datagram/DatagramSocket.html#close-io.vertx.core.Handler-)` method. This will close the socket and release all resources

## [DNS client](#_dns_client)

Often you will find yourself in situations where you need to obtain DNS informations in an asynchronous fashion. Unfortunally this is not possible with the API that is shipped with the Java Virtual Machine itself. Because of this Vert.x offers it’s own API for DNS resolution which is fully asynchronous.

To obtain a DnsClient instance you will create a new via the Vertx instance.

```
DnsClient client = vertx.createDnsClient(53, "10.0.0.1");
```

You can also create the client with options and configure the query timeout.

```
DnsClient client = vertx.createDnsClient(new DnsClientOptions()
  .setPort(53)
  .setHost("10.0.0.1")
  .setQueryTimeout(10000)
);
```

Creating the client with no arguments or omitting the server address will use the address of the server used internally for non blocking address resolution.

```
DnsClient client1 = vertx.createDnsClient();

// Just the same but with a different query timeout
DnsClient client2 = vertx.createDnsClient(new DnsClientOptions().setQueryTimeout(10000));
```

A client uses a single event loop for querying purposes, it can safely be used from any thread, including non Vert.x thread.

### [lookup](#_lookup)

Try to lookup the A (ipv4) or AAAA (ipv6) record for a given name. The first which is returned will be used, so it behaves the same way as you may be used from when using "nslookup" on your operation system.

To lookup the A / AAAA record for "vertx.io" you would typically use it like:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .lookup("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      System.out.println(ar.result());
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [lookup4](#_lookup4)

Try to lookup the A (ipv4) record for a given name. The first which is returned will be used, so it behaves the same way as you may be used from when using "nslookup" on your operation system.

To lookup the A record for "vertx.io" you would typically use it like:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .lookup4("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      System.out.println(ar.result());
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [lookup6](#_lookup6)

Try to lookup the AAAA (ipv6) record for a given name. The first which is returned will be used, so it behaves the same way as you may be used from when using "nslookup" on your operation system.

To lookup the A record for "vertx.io" you would typically use it like:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .lookup6("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      System.out.println(ar.result());
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [resolveA](#_resolvea)

Try to resolve all A (ipv4) records for a given name. This is quite similar to using "dig" on unix like operation systems.

To lookup all the A records for "vertx.io" you would typically do:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveA("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<String> records = ar.result();
      for (String record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [resolveAAAA](#_resolveaaaa)

Try to resolve all AAAA (ipv6) records for a given name. This is quite similar to using "dig" on unix like operation systems.

To lookup all the AAAAA records for "vertx.io" you would typically do:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveAAAA("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<String> records = ar.result();
      for (String record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [resolveCNAME](#_resolvecname)

Try to resolve all CNAME records for a given name. This is quite similar to using "dig" on unix like operation systems.

To lookup all the CNAME records for "vertx.io" you would typically do:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveCNAME("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<String> records = ar.result();
      for (String record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [resolveMX](#_resolvemx)

Try to resolve all MX records for a given name. The MX records are used to define which Mail-Server accepts emails for a given domain.

To lookup all the MX records for "vertx.io" you would typically do:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveMX("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<MxRecord> records = ar.result();
      for (MxRecord record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

Be aware that the List will contain the `[MxRecord](../../apidocs/io/vertx/core/dns/MxRecord.html)` sorted by the priority of them, which means MX records with smaller priority coming first in the List.

The `[MxRecord](../../apidocs/io/vertx/core/dns/MxRecord.html)` allows you to access the priority and the name of the MX record by offer methods for it like:

```
record.priority();
record.name();
```

### [resolveTXT](#_resolvetxt)

Try to resolve all TXT records for a given name. TXT records are often used to define extra information for a domain.

To resolve all the TXT records for "vertx.io" you could use something along these lines:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveTXT("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<String> records = ar.result();
      for (String record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [resolveNS](#_resolvens)

Try to resolve all NS records for a given name. The NS records specify which DNS Server hosts the DNS informations for a given domain.

To resolve all the NS records for "vertx.io" you could use something along these lines:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveNS("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<String> records = ar.result();
      for (String record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [resolveSRV](#_resolvesrv)

Try to resolve all SRV records for a given name. The SRV records are used to define extra information like port and hostname of services. Some protocols need this extra information.

To lookup all the SRV records for "vertx.io" you would typically do:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolveSRV("vertx.io")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      List<SrvRecord> records = ar.result();
      for (SrvRecord record : records) {
        System.out.println(record);
      }
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

Be aware that the List will contain the SrvRecords sorted by the priority of them, which means SrvRecords with smaller priority coming first in the List.

The `[SrvRecord](../../apidocs/io/vertx/core/dns/SrvRecord.html)` allows you to access all information contained in the SRV record itself:

```
record.priority();
record.name();
record.weight();
record.port();
record.protocol();
record.service();
record.target();
```

Please refer to the API docs for the exact details.

### [resolvePTR](#_resolveptr)

Try to resolve the PTR record for a given name. The PTR record maps an ipaddress to a name.

To resolve the PTR record for the ipaddress 10.0.0.1 you would use the PTR notion of "1.0.0.10.in-addr.arpa"

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .resolvePTR("1.0.0.10.in-addr.arpa")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      String record = ar.result();
      System.out.println(record);
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [reverseLookup](#_reverselookup)

Try to do a reverse lookup for an ipaddress. This is basically the same as resolve a PTR record, but allows you to just pass in the ipaddress and not a valid PTR query string.

To do a reverse lookup for the ipaddress 10.0.0.1 do something similar like this:

```
DnsClient client = vertx.createDnsClient(53, "9.9.9.9");
client
  .reverseLookup("10.0.0.1")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      String record = ar.result();
      System.out.println(record);
    } else {
      System.out.println("Failed to resolve entry" + ar.cause());
    }
  });
```

### [Error handling](#_error_handling)

As you saw in previous sections the DnsClient allows you to pass in a Handler which will be notified with an AsyncResult once the query was complete. In case of an error it will be notified with a DnsException which will hole a `[DnsResponseCode](../../apidocs/io/vertx/core/dns/DnsResponseCode.html)` that indicate why the resolution failed. This DnsResponseCode can be used to inspect the cause in more detail.

Possible DnsResponseCodes are:

* `[NOERROR](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#NOERROR)` No record was found for a given query
* `[FORMERROR](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#FORMERROR)` Format error
* `[SERVFAIL](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#SERVFAIL)` Server failure
* `[NXDOMAIN](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#NXDOMAIN)` Name error
* `[NOTIMPL](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#NOTIMPL)` Not implemented by DNS Server
* `[REFUSED](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#REFUSED)` DNS Server refused the query
* `[YXDOMAIN](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#YXDOMAIN)` Domain name should not exist
* `[YXRRSET](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#YXRRSET)` Resource record should not exist
* `[NXRRSET](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#NXRRSET)` RRSET does not exist
* `[NOTZONE](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#NOTZONE)` Name not in zone
* `[BADVERS](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#BADVERS)` Bad extension mechanism for version
* `[BADSIG](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#BADSIG)` Bad signature
* `[BADKEY](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#BADKEY)` Bad key
* `[BADTIME](../../apidocs/io/vertx/core/dns/DnsResponseCode.html#BADTIME)` Bad timestamp

All of those errors are "generated" by the DNS Server itself.

You can obtain the DnsResponseCode from the DnsException like:

```
DnsClient client = vertx.createDnsClient(53, "10.0.0.1");
client
  .lookup("nonexisting.vert.xio")
  .onComplete(ar -> {
    if (ar.succeeded()) {
      String record = ar.result();
      System.out.println(record);
    } else {
      Throwable cause = ar.cause();
      if (cause instanceof DnsException) {
        DnsException exception = (DnsException) cause;
        DnsResponseCode code = exception.code();
        // ...
      } else {
        System.out.println("Failed to resolve entry" + ar.cause());
      }
    }
  });
```

## [Vert.x Virtual Threads](#virtual_threads)

Use virtual threads to write Vert.x code that looks like it is synchronous.

You still write the traditional Vert.x code processing events, but you have the opportunity to write synchronous code for complex workflows and use thread locals in such workflows.

### [Introduction](#_introduction)

The non-blocking nature of Vert.x leads to asynchronous APIs. Asynchronous APIs can take various forms including callback style, promises and reactive extensions.

In some cases, programming using asynchronous APIs can be more challenging than using a direct synchronous style, in particular if you have several operations that you want to do sequentially. Also, error propagation is often more complex when using asynchronous APIs.

Virtual thread support allows you to work with asynchronous APIs, but using a direct synchronous style that you’re already familiar with.

It does this by using Java 21 [virtual threads](https://openjdk.org/jeps/444). Virtual threads are very lightweight threads that do not correspond to underlying kernel threads. When they are blocked they do not block a kernel thread.

### [Using virtual threads](#_using_virtual_threads)

You can deploy virtual thread verticles.

A virtual thread verticle is capable of awaiting Vert.x futures and gets the result synchronously.

When the verticle **awaits** a result, the verticle can still process events like an event-loop verticle.

```
AbstractVerticle verticle = new AbstractVerticle() {
  @Override
  public void start() {
    HttpClient client = vertx.createHttpClient();
    HttpClientRequest req = Future.await(client.request(
      HttpMethod.GET,
      8080,
      "localhost",
      "/"));
    HttpClientResponse resp = Future.await(req.send());
    int status = resp.statusCode();
    Buffer body = Future.await(resp.body());
  }
};

// Run the verticle a on virtual thread
vertx.deployVerticle(verticle, new DeploymentOptions().setThreadingModel(ThreadingModel.VIRTUAL_THREAD));
```

|  | Using virtual threads requires Java 21 or above. |
| --- | --- |

#### [Blocking within a virtual thread verticle](#_blocking_within_a_virtual_thread_verticle)

You can use `[Future.await](../../apidocs/io/vertx/core/Future.html#await-io.vertx.core.Future-)` to suspend the current virtual thread until the awaited result is available.

The virtual thread is effectively blocked, but the application can still process events.

When a virtual thread awaits for a result and the verticle needs to process a task, a new virtual thread is created to handle this task.

When the result is available, the virtual thread execution is resumed and scheduled after the current task is suspended or finished.

|  | Like any verticle at most one task is executed at the same time. |
| --- | --- |

You can await on a Vert.x `Future`

```
Buffer body = Future.await(response.body());
```

or on a JDK `CompletionStage`

```
Buffer body = Future.await(Future.fromCompletionStage(completionStage));
```

#### [Field visibility](#_field_visibility)

A virtual thread verticle can interact safely with fields before an `await` call. However, if you are reading a field before an `await` call and reusing the value after the call, you should keep in mind that this value might have changed.

```
int value = counter;
value += Future.await(getRemoteValue());
// the counter value might have changed
counter = value;
```

You should read/write fields before calling `await` to avoid this.

```
counter += Future.await(getRemoteValue());
```

|  | this is the same behavior with an event-loop verticle |
| --- | --- |

#### [Awaiting multiple futures](#_awaiting_multiple_futures)

When you need to await multiple futures, you can use Vert.x `[CompositeFuture](../../apidocs/io/vertx/core/CompositeFuture.html)`:

```
Future<String> f1 = getRemoteString();
Future<Integer> f2 = getRemoteValue();
CompositeFuture res = Future.await(Future.all(f1, f2));
String v1 = res.resultAt(0);
Integer v2 = res.resultAt(1);
```

#### [Blocking without await](#_blocking_without_await)

When your application blocks without using `await`, e.g. using `ReentrantLock#lock`, the Vert.x scheduler is not aware of it and cannot schedule events on the verticle: it behaves like a worker verticle, yet using virtual threads.

This use case is not encouraged yet not forbidden, however the verticle should be deployed with several instances to deliver the desired concurrency, like a worker verticle.

#### [Thread local support](#_thread_local_support)

Thread locals are only reliable within the execution of a context task.

```
ThreadLocal<String> local = new ThreadLocal();
local.set(userId);
HttpClientRequest req = Future.await(client.request(HttpMethod.GET, 8080, "localhost", "/"));
HttpClientResponse resp = Future.await(req.send());
```

## [Streams](#streams)

There are several objects in Vert.x that allow items to be read from and written.

In Vert.x, write calls return immediately, and writes are queued internally.

It’s not hard to see that if you write to an object faster than it can actually write the data to its underlying resource, then the write queue can grow unbounded - eventually resulting in memory exhaustion.

To solve this problem a simple flow control (*back-pressure*) capability is provided by some objects in the Vert.x API.

Any flow control aware object that can be *written-to* implements `[WriteStream](../../apidocs/io/vertx/core/streams/WriteStream.html)`, while any flow control object that can be *read-from* is said to implement `[ReadStream](../../apidocs/io/vertx/core/streams/ReadStream.html)`.

Let’s take an example where we want to read from a `ReadStream` then write the data to a `WriteStream`.

A very simple example would be reading from a `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` then writing back to the same `NetSocket` - since `NetSocket` implements both `ReadStream` and `WriteStream`. Note that this works between any `ReadStream` and `WriteStream` compliant object, including HTTP requests, HTTP responses, async files I/O, WebSockets, etc.

A naive way to do this would be to directly take the data that has been read and immediately write it to the `NetSocket`:

```
NetServer server = vertx.createNetServer(
    new NetServerOptions().setPort(1234).setHost("localhost")
);
server.connectHandler(sock -> {
  sock.handler(buffer -> {
    // Write the data straight back
    sock.write(buffer);
  });
}).listen();
```

There is a problem with the example above: if data is read from the socket faster than it can be written back to the socket, it will build up in the write queue of the `NetSocket`, eventually running out of RAM. This might happen, for example if the client at the other end of the socket wasn’t reading fast enough, effectively putting back-pressure on the connection.

Since `NetSocket` implements `WriteStream`, we can check if the `WriteStream` is full before writing to it:

```
NetServer server = vertx.createNetServer(
    new NetServerOptions().setPort(1234).setHost("localhost")
);
server.connectHandler(sock -> {
  sock.handler(buffer -> {
    if (!sock.writeQueueFull()) {
      sock.write(buffer);
    }
  });

}).listen();
```

This example won’t run out of RAM but we’ll end up losing data if the write queue gets full. What we really want to do is pause the `NetSocket` when the write queue is full:

```
NetServer server = vertx.createNetServer(
    new NetServerOptions().setPort(1234).setHost("localhost")
);
server.connectHandler(sock -> {
  sock.handler(buffer -> {
    sock.write(buffer);
    if (sock.writeQueueFull()) {
      sock.pause();
    }
  });
}).listen();
```

We’re almost there, but not quite. The `NetSocket` now gets paused when the file is full, but we also need to unpause it when the write queue has processed its backlog:

```
NetServer server = vertx.createNetServer(
    new NetServerOptions().setPort(1234).setHost("localhost")
);
server.connectHandler(sock -> {
  sock.handler(buffer -> {
    sock.write(buffer);
    if (sock.writeQueueFull()) {
      sock.pause();
      sock.drainHandler(done -> {
        sock.resume();
      });
    }
  });
}).listen();
```

And there we have it. The `[drainHandler](../../apidocs/io/vertx/core/streams/WriteStream.html#drainHandler-io.vertx.core.Handler-)` event handler will get called when the write queue is ready to accept more data, this resumes the `NetSocket` that allows more data to be read.

Wanting to do this is quite common while writing Vert.x applications, so we added the `[pipeTo](../../apidocs/io/vertx/core/streams/ReadStream.html#pipeTo-io.vertx.core.streams.WriteStream-)` method that does all of this hard work for you. You just feed it the `WriteStream` and use it:

```
NetServer server = vertx.createNetServer(
  new NetServerOptions().setPort(1234).setHost("localhost")
);
server.connectHandler(sock -> {
  sock.pipeTo(sock);
}).listen();
```

This does exactly the same thing as the more verbose example, plus it handles stream failures and termination: the destination `WriteStream` is ended when the pipe completes with success or a failure.

You can be notified when the operation completes:

```
server.connectHandler(sock -> {

  // Pipe the socket providing an handler to be notified of the result
  sock
    .pipeTo(sock)
    .onComplete(ar -> {
      if (ar.succeeded()) {
        System.out.println("Pipe succeeded");
      } else {
        System.out.println("Pipe failed");
      }
    });
}).listen();
```

When you deal with an asynchronous destination, you can create a `[Pipe](../../apidocs/io/vertx/core/streams/Pipe.html)` instance that pauses the source and resumes it when the source is piped to the destination:

```
server.connectHandler(sock -> {

  // Create a pipe to use asynchronously
  Pipe<Buffer> pipe = sock.pipe();

  // Open a destination file
  fs.open("/path/to/file", new OpenOptions())
    .onComplete(ar -> {
      if (ar.succeeded()) {
        AsyncFile file = ar.result();

        // Pipe the socket to the file and close the file at the end
        pipe.to(file);
      } else {
        sock.close();
      }
  });
}).listen();
```

When you need to abort the transfer, you need to close it:

```
vertx.createHttpServer()
  .requestHandler(request -> {

    // Create a pipe that to use asynchronously
    Pipe<Buffer> pipe = request.pipe();

    // Open a destination file
    fs.open("/path/to/file", new OpenOptions())
      .onComplete(ar -> {
        if (ar.succeeded()) {
          AsyncFile file = ar.result();

          // Pipe the socket to the file and close the file at the end
          pipe.to(file);
        } else {
          // Close the pipe and resume the request, the body buffers will be discarded
          pipe.close();

          // Send an error response
          request.response().setStatusCode(500).end();
        }
      });
  }).listen(8080);
```

When the pipe is closed, the streams handlers are unset and the `ReadStream` resumed.

As seen above, by default the destination is always ended when the stream completes, you can control this behavior on the pipe object:

* `[endOnFailure](../../apidocs/io/vertx/core/streams/Pipe.html#endOnFailure-boolean-)` controls the behavior when a failure happens
* `[endOnSuccess](../../apidocs/io/vertx/core/streams/Pipe.html#endOnSuccess-boolean-)` controls the behavior when the read stream ends
* `[endOnComplete](../../apidocs/io/vertx/core/streams/Pipe.html#endOnComplete-boolean-)` controls the behavior in all cases

Here is a short example:

```
src.pipe()
  .endOnSuccess(false)
  .to(dst)
  .onComplete(rs -> {
    // Append some text and close the file
    dst.end(Buffer.buffer("done"));
  });
```

Let’s now look at the methods on `ReadStream` and `WriteStream` in more detail:

### [ReadStream](#_readstream)

`ReadStream` is implemented by `[HttpClientResponse](../../apidocs/io/vertx/core/http/HttpClientResponse.html)`, `[DatagramSocket](../../apidocs/io/vertx/core/datagram/DatagramSocket.html)`, `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)`, `[HttpServerFileUpload](../../apidocs/io/vertx/core/http/HttpServerFileUpload.html)`, `[HttpServerRequest](../../apidocs/io/vertx/core/http/HttpServerRequest.html)`, `[MessageConsumer](../../apidocs/io/vertx/core/eventbus/MessageConsumer.html)`, `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)`, `[WebSocket](../../apidocs/io/vertx/core/http/WebSocket.html)`, `[AsyncFile](../../apidocs/io/vertx/core/file/AsyncFile.html)`.

* `[handler](../../apidocs/io/vertx/core/streams/ReadStream.html#handler-io.vertx.core.Handler-)`: set a handler which will receive items from the ReadStream.
* `[pause](../../apidocs/io/vertx/core/streams/ReadStream.html#pause--)`: pause the stream. When paused no items will be received in the handler.
* `[fetch](../../apidocs/io/vertx/core/streams/ReadStream.html#fetch-long-)`: fetch a specified amount of item from the stream. The handler will be called if any item arrives. Fetches are cumulative.
* `[resume](../../apidocs/io/vertx/core/streams/ReadStream.html#resume--)`: resume the stream. The handler will be called if any item arrives. Resuming is equivalent of fetching `Long.MAX_VALUE` items.
* `[exceptionHandler](../../apidocs/io/vertx/core/streams/ReadStream.html#exceptionHandler-io.vertx.core.Handler-)`: called when an exception occurs on the ReadStream.
* `[endHandler](../../apidocs/io/vertx/core/streams/ReadStream.html#endHandler-io.vertx.core.Handler-)`: called when the end of stream is reached. This might be when EOF is reached if the ReadStream represents a file, or when end of request is reached if it’s an HTTP request, or when the connection is closed if it’s a TCP socket.

A read stream is either in *flowing* or *fetch* mode

* initially the stream is in <i>flowing</i> mode
* when the stream is in *flowing* mode, elements are delivered to the handler
* when the stream is in *fetch* mode, only the number of requested elements will be delivered to the handler

`[pause](../../apidocs/io/vertx/core/streams/ReadStream.html#pause--)`, `[resume](../../apidocs/io/vertx/core/streams/ReadStream.html#resume--)` and `[fetch](../../apidocs/io/vertx/core/streams/ReadStream.html#fetch-long-)` change the mode

* `resume()` sets the *flowing* mode
* `pause()` sets the *fetch* mode and resets the demand to `0`
* `fetch(long)` requests a specific amount of elements and adds it to the actual demand

### [WriteStream](#_writestream)

`WriteStream` is implemented by `[HttpClientRequest](../../apidocs/io/vertx/core/http/HttpClientRequest.html)`, `[HttpServerResponse](../../apidocs/io/vertx/core/http/HttpServerResponse.html)` `[WebSocket](../../apidocs/io/vertx/core/http/WebSocket.html)`, `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` and `[AsyncFile](../../apidocs/io/vertx/core/file/AsyncFile.html)`.

Functions:

* `[write](../../apidocs/io/vertx/core/streams/WriteStream.html#write-java.lang.Object-)`: write an object to the WriteStream. This method will never block. Writes are queued internally and asynchronously written to the underlying resource.
* `[setWriteQueueMaxSize](../../apidocs/io/vertx/core/streams/WriteStream.html#setWriteQueueMaxSize-int-)`: set the number of object at which the write queue is considered *full*, and the method `[writeQueueFull](../../apidocs/io/vertx/core/streams/WriteStream.html#writeQueueFull--)` returns `true`. Note that, when the write queue is considered full, if write is called the data will still be accepted and queued. The actual number depends on the stream implementation, for `[Buffer](../../apidocs/io/vertx/core/buffer/Buffer.html)` the size represents the actual number of bytes written and not the number of buffers.
* `[writeQueueFull](../../apidocs/io/vertx/core/streams/WriteStream.html#writeQueueFull--)`: returns `true` if the write queue is considered full.
* `[exceptionHandler](../../apidocs/io/vertx/core/streams/WriteStream.html#exceptionHandler-io.vertx.core.Handler-)`: Will be called if an exception occurs on the `WriteStream`.
* `[drainHandler](../../apidocs/io/vertx/core/streams/WriteStream.html#drainHandler-io.vertx.core.Handler-)`: The handler will be called if the `WriteStream` is considered no longer full.

### [Reducing streams](#_reducing_streams)

Java collectors can reduce a `ReadStream` to a result in a similar fashion `java.util.Stream` does, yet in an asynchronous fashion.

```
Future<Long> result = stream.collect(Collectors.counting());

result.onSuccess(count -> System.out.println("Stream emitted " + count + " elements"));
```

Note that `collect` overrides any previously handler set on the stream.

## [Record Parser](#_record_parser)

The record parser allows you to easily parse protocols which are delimited by a sequence of bytes, or fixed size records. It transforms a sequence of input buffer to a sequence of buffer structured as configured (either fixed size or separated records).

For example, if you have a simple ASCII text protocol delimited by '\n' and the input is the following:

```
buffer1:HELLO\nHOW ARE Y
buffer2:OU?\nI AM
buffer3: DOING OK
buffer4:\n
```

The record parser would produce

```
buffer1:HELLO
buffer2:HOW ARE YOU?
buffer3:I AM DOING OK
```

Let’s see the associated code:

```
final RecordParser parser = RecordParser.newDelimited("\n", h -> {
  System.out.println(h.toString());
});

parser.handle(Buffer.buffer("HELLO\nHOW ARE Y"));
parser.handle(Buffer.buffer("OU?\nI AM"));
parser.handle(Buffer.buffer("DOING OK"));
parser.handle(Buffer.buffer("\n"));
```

You can also produce fixed sized chunks as follows:

```
RecordParser.newFixed(4, h -> {
  System.out.println(h.toString());
});
```

For more details, check out the `[RecordParser](../../apidocs/io/vertx/core/parsetools/RecordParser.html)` class.

## [Json Parser](#_json_parser)

You can easily parse JSON structures but that requires to provide the JSON content at once, but it may not be convenient when you need to parse very large structures.

The non-blocking JSON parser is an event driven parser able to deal with very large structures. It transforms a sequence of input buffer to a sequence of JSON parse events.

```
JsonParser parser = JsonParser.newParser();

// Set handlers for various events
parser.handler(event -> {
  switch (event.type()) {
    case START_OBJECT:
      // Start an objet
      break;
    case END_OBJECT:
      // End an objet
      break;
    case START_ARRAY:
      // Start an array
      break;
    case END_ARRAY:
      // End an array
      break;
    case VALUE:
      // Handle a value
      String field = event.fieldName();
      if (field != null) {
        // In an object
      } else {
        // In an array or top level
        if (event.isString()) {

        } else {
          // ...
        }
      }
      break;
  }
});
```

The parser is non-blocking and emitted events are driven by the input buffers.

```
JsonParser parser = JsonParser.newParser();

// start array event
// start object event
// "firstName":"Bob" event
parser.handle(Buffer.buffer("[{\"firstName\":\"Bob\","));

// "lastName":"Morane" event
// end object event
parser.handle(Buffer.buffer("\"lastName\":\"Morane\"},"));

// start object event
// "firstName":"Luke" event
// "lastName":"Lucky" event
// end object event
parser.handle(Buffer.buffer("{\"firstName\":\"Luke\",\"lastName\":\"Lucky\"}"));

// end array event
parser.handle(Buffer.buffer("]"));

// Always call end
parser.end();
```

Event driven parsing provides more control but comes at the price of dealing with fine grained events, which can be inconvenient sometimes. The JSON parser allows you to handle JSON structures as values when it is desired:

```
JsonParser parser = JsonParser.newParser();

parser.objectValueMode();

parser.handler(event -> {
  switch (event.type()) {
    case START_ARRAY:
      // Start the array
      break;
    case END_ARRAY:
      // End the array
      break;
    case VALUE:
      // Handle each object
      break;
  }
});

parser.handle(Buffer.buffer("[{\"firstName\":\"Bob\"},\"lastName\":\"Morane\"),...]"));
parser.end();
```

The value mode can be set and unset during the parsing allowing you to switch between fine grained events or JSON object value events.

```
JsonParser parser = JsonParser.newParser();

parser.handler(event -> {
  // Start the object

  switch (event.type()) {
    case START_OBJECT:
      // Set object value mode to handle each entry, from now on the parser won't emit start object events
      parser.objectValueMode();
      break;
    case VALUE:
      // Handle each object
      // Get the field in which this object was parsed
      String id = event.fieldName();
      System.out.println("User with id " + id + " : " + event.value());
      break;
    case END_OBJECT:
      // Set the object event mode so the parser emits start/end object events again
      parser.objectEventMode();
      break;
  }
});

parser.handle(Buffer.buffer("{\"39877483847\":{\"firstName\":\"Bob\"},\"lastName\":\"Morane\"),...}"));
parser.end();
```

You can do the same with arrays as well

```
JsonParser parser = JsonParser.newParser();

parser.handler(event -> {
  // Start the object

  switch (event.type()) {
    case START_OBJECT:
      // Set array value mode to handle each entry, from now on the parser won't emit start array events
      parser.arrayValueMode();
      break;
    case VALUE:
      // Handle each array
      // Get the field in which this object was parsed
      System.out.println("Value : " + event.value());
      break;
    case END_OBJECT:
      // Set the array event mode so the parser emits start/end object events again
      parser.arrayEventMode();
      break;
  }
});

parser.handle(Buffer.buffer("[0,1,2,3,4,...]"));
parser.end();
```

You can also decode POJOs

```
parser.handler(event -> {
  // Handle each object
  // Get the field in which this object was parsed
  String id = event.fieldName();
  User user = event.mapTo(User.class);
  System.out.println("User with id " + id + " : " + user.firstName + " " + user.lastName);
});
```

Whenever the parser fails to process a buffer, an exception will be thrown unless you set an exception handler:

```
JsonParser parser = JsonParser.newParser();

parser.exceptionHandler(err -> {
  // Catch any parsing or decoding error
});
```

The parser also parses json streams:

* concatenated json streams: `{"temperature":30}{"temperature":50}`
* line delimited json streams: `{"an":"object"}\r\n3\r\n"a string"\r\nnull`

For more details, check out the `[JsonParser](../../apidocs/io/vertx/core/parsetools/JsonParser.html)` class.

## [Thread safety](#_thread_safety)

Most Vert.x objects are safe to access from different threads. *However* performance is optimised when they are accessed from the same context they were created from.

For example if you have deployed a verticle which creates a `[NetServer](../../apidocs/io/vertx/core/net/NetServer.html)` which provides `[NetSocket](../../apidocs/io/vertx/core/net/NetSocket.html)` instances in it’s handler, then it’s best to always access that socket instance from the event loop of the verticle.

If you stick to the standard Vert.x verticle deployment model and avoid sharing objects between verticles then this should be the case without you having to think about it.

## [Running blocking code](#blocking_code)

In a perfect world, there will be no war or hunger, all APIs will be written asynchronously and bunny rabbits will skip hand-in-hand with baby lambs across sunny green meadows.

**But…​ the real world is not like that. (Have you watched the news lately?)**

Fact is, many, if not most libraries, especially in the JVM ecosystem have synchronous APIs and many of the methods are likely to block. A good example is the JDBC API - it’s inherently synchronous, and no matter how hard it tries, Vert.x cannot sprinkle magic pixie dust on it to make it asynchronous.

We’re not going to rewrite everything to be asynchronous overnight so we need to provide you a way to use "traditional" blocking APIs safely within a Vert.x application.

As discussed before, you can’t call blocking operations directly from an event loop, as that would prevent it from doing any other useful work. So how can you do this?

It’s done by calling `[executeBlocking](../../apidocs/io/vertx/core/Vertx.html#executeBlocking-io.vertx.core.Handler-boolean-io.vertx.core.Handler-)` with blocking code to execute, as return you get a future completed with the result of the blocking code execution.

```
vertx.executeBlocking(() -> {
  // Call some blocking API that takes a significant amount of time to return
  return someAPI.blockingMethod("hello");
}).onComplete(res -> {
  System.out.println("The result is: " + res.result());
});
```

|  | Blocking code should block for a reasonable amount of time (i.e no more than a few seconds). Long blocking operations or polling operations (i.e a thread that spin in a loop polling events in a blocking fashion) are precluded. When the blocking operation lasts more than the 10 seconds, a message will be printed on the console by the blocked thread checker. Long blocking operations should use a dedicated thread managed by the application, which can interact with verticles using the event-bus or `[runOnContext](../../apidocs/io/vertx/core/Context.html#runOnContext-io.vertx.core.Handler-)` |
| --- | --- |

By default, if executeBlocking is called several times from the same context (e.g. the same verticle instance) then the different executeBlocking are executed *serially* (i.e. one after another).

If you don’t care about ordering you can call `[executeBlocking](../../apidocs/io/vertx/core/Vertx.html#executeBlocking-java.util.concurrent.Callable-boolean-)` specifying `false` as the argument to `ordered`. In this case any executeBlocking may be executed in parallel on the worker pool.

An alternative way to run blocking code is to use a [worker verticle](#worker_verticles)

A worker verticle is always executed with a thread from the worker pool.

By default blocking code is executed on the Vert.x worker pool, configured with `[setWorkerPoolSize](../../apidocs/io/vertx/core/VertxOptions.html#setWorkerPoolSize-int-)`.

Additional pools can be created for different purposes:

```
WorkerExecutor executor = vertx.createSharedWorkerExecutor("my-worker-pool");
executor.executeBlocking(() -> {
  // Call some blocking API that takes a significant amount of time to return
  return someAPI.blockingMethod("hello");
}).onComplete(res -> {
  System.out.println("The result is: " + res.result());
});
```

The worker executor must be closed when it’s not necessary anymore:

```
executor.close();
```

When several workers are created with the same name, they will share the same pool. The worker pool is destroyed when all the worker executors using it are closed.

When an executor is created in a Verticle, Vert.x will close it automatically for you when the Verticle is undeployed.

Worker executors can be configured when created:

```
int poolSize = 10;

// 2 minutes
long maxExecuteTime = 2;
TimeUnit maxExecuteTimeUnit = TimeUnit.MINUTES;

WorkerExecutor executor = vertx.createSharedWorkerExecutor("my-worker-pool", poolSize, maxExecuteTime, maxExecuteTimeUnit);
```

|  | the configuration is set when the worker pool is created |
| --- | --- |

## [Vert.x SPI](#_vert_x_spi)

A Vert.x instance has a few extension points knows as *SPI* (Service Provider Interface).

Such SPI are often loaded from the classpath using Java’s `ServiceLoader` mechanism.

### [Metrics and tracing SPI](#_metrics_and_tracing_spi)

By default, Vert.x does not record any metrics nor does any tracing. Instead, it provides an SPI for others to implement which can be added to the classpath. The metrics SPI is a feature which allows implementers to capture events from Vert.x in order to collect and report metrics, likewise the tracing SPI does the same for traces.

For more information on this, please consult <https://vertx.io/docs/#monitoring>

### [Cluster Manager SPI](#cluster_manager_spi)

In Vert.x a cluster manager is used for various functions including:

* Discovery and group membership of Vert.x nodes in a cluster
* Maintaining cluster wide topic subscriber lists (so we know which nodes are interested in which event bus addresses)
* Distributed Map support
* Distributed Locks
* Distributed Counters

Cluster managers *do not* handle the event bus inter-node transport, this is done directly by Vert.x with TCP connections.

The default cluster manager used in the Vert.x distributions is one that uses [Hazelcast](http://hazelcast.com) but this can be easily replaced by a different implementation as Vert.x cluster managers are pluggable.

A cluster manager must implement the interface `[ClusterManager](../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html)`. Vert.x locates cluster managers at run-time by using the Java [Service Loader](https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html) functionality to locate instances of `[ClusterManager](../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html)` on the classpath.

If you are using Vert.x at the command line and you want to use clustering you should make sure the `lib` directory of the Vert.x installation contains your cluster manager jar.

If you are using Vert.x from a Maven or Gradle project just add the cluster manager jar as a dependency of your project.

For more information on this, please consult <https://vertx.io/docs/#clustering>

### [Programmatic SPI selection and configuration](#_programmatic_spi_selection_and_configuration)

The `[VertxBuilder](../../apidocs/io/vertx/core/VertxBuilder.html)` gives you more control over the SPI selection and configuration.

```
Vertx vertx = Vertx.builder()
  .with(options)
  .withMetrics(metricsFactory)
  .build();
```

Clustered instances can also be created.

```
Future<Vertx> vertx = Vertx.builder()
  .with(options)
  .withClusterManager(clusterManager)
  .buildClustered();
```

## [The 'vertx' command line](#_the_vertx_command_line)

The `vertx` command is used to interact with Vert.x from the command line. It’s main use is to run Vert.x verticles. To do this you need to download and install a Vert.x distribution, and add the `bin` directory of the installation to your `PATH` environment variable. Also make sure you have a Java JDK on your `PATH`.

Vert.x supports Java from 8 to 17.

|  | The JDK is required to support on the fly compilation of Java code. |
| --- | --- |

### [Run verticles](#_run_verticles)

You can run raw Vert.x verticles directly from the command line using `vertx run`. Here is a couple of examples of the `run` *command*:

```
vertx run my-verticle.js                                 (1)
vertx run my-verticle.groovy                             (2)
vertx run my-verticle.rb                                 (3)

vertx run io.vertx.example.MyVerticle                    (4)
vertx run io.vertx.example.MVerticle -cp my-verticle.jar (5)

vertx run MyVerticle.java                                (6)
```

1. Deploys a JavaScript verticle
2. Deploys a Groovy verticle
3. Deploys a Ruby verticle
4. Deploys an already compiled Java verticle. Classpath root is the current directory
5. Deploys a verticle packaged in a Jar, the jar need to be in the classpath
6. Compiles the Java source and deploys it

As you can see in the case of Java, the name can either be the fully qualified class name of the verticle, or you can specify the Java Source file directly and Vert.x compiles it for you.

You can also prefix the verticle with the name of the language implementation to use. For example if the verticle is a compiled Groovy class, you prefix it with `groovy:` so that Vert.x knows it’s a Groovy class not a Java class.

```
vertx run groovy:io.vertx.example.MyGroovyVerticle
```

The `vertx run` command can take a few optional parameters, they are:

* `-options <options>` - Provides the Vert.x options. `options` is the name of a JSON file that represents the Vert.x options, or a JSON string. This is optional.
* `-conf <config>` - Provides some configuration to the verticle. `config` is the name of a JSON file that represents the configuration for the verticle, or a JSON string. This is optional.
* `-cp <path>` - The path on which to search for the verticle and any other resources used by the verticle. This defaults to `.` (current directory). If your verticle references other scripts, classes or other resources (e.g. jar files) then make sure these are on this path. The path can contain multiple path entries separated by `:` (colon) or `;` (semi-colon) depending on the operating system. Each path entry can be an absolute or relative path to a directory containing scripts, or absolute or relative filenames for jar or zip files. An example path might be `-cp classes:lib/otherscripts:jars/myjar.jar:jars/otherjar.jar`. Always use the path to reference any resources that your verticle requires. Do **not** put them on the system classpath as this can cause isolation issues between deployed verticles.
* `-instances <instances>` - The number of instances of the verticle to instantiate. Each verticle instance is strictly single threaded so to scale your application across available cores you might want to deploy more than one instance. If omitted a single instance will be deployed.
* `-worker` - This option determines whether the verticle is a worker verticle or not.
* `-cluster` - This option determines whether the Vert.x instance will attempt to form a cluster with other Vert.x instances on the network. Clustering Vert.x instances allows Vert.x to form a distributed event bus with other nodes. Default is `false` (not clustered).
* `-cluster-port` - If the `cluster` option has also been specified then this determines which port will be bound for cluster communication with other Vert.x instances. Default is `0` - which means '*choose a free random port*'. You don’t usually need to specify this parameter unless you really need to bind to a specific port.
* `-cluster-host` - If the `cluster` option has also been specified then this determines which host address will be bound for cluster communication with other Vert.x instances. If not set, the clustered eventbus tries to bind to the same host as the underlying cluster manager. As a last resort, an address will be picked among the available network interfaces.
* `-cluster-public-port` - If the `cluster` option has also been specified then this determines which port will be advertised for cluster communication with other Vert.x instances. Default is `-1`, which means same as `cluster-port`.
* `-cluster-public-host` - If the `cluster` option has also been specified then this determines which host address will be advertised for cluster communication with other Vert.x instances. If not specified, Vert.x uses the value of `cluster-host`.
* `-ha` - if specified the verticle will be deployed as high availability (HA) deployment. See related section for more details
* `-quorum` - used in conjunction with `-ha`. It specifies the minimum number of nodes in the cluster for any *HA deploymentIDs* to be active. Defaults to 0.
* `-hagroup` - used in conjunction with `-ha`. It specifies the HA group this node will join. There can be multiple HA groups in a cluster. Nodes will only failover to other nodes in the same group. The default value is ` \_\_DEFAULT\_\_`

You can also set system properties using: `-Dkey=value`.

Here are some more examples:

Run a JavaScript verticle server.js with default settings

```
vertx run server.js
```

Run 10 instances of a pre-compiled Java verticle specifying classpath

```
vertx run com.acme.MyVerticle -cp "classes:lib/myjar.jar" -instances 10
```

Run 10 instances of a Java verticle by source *file*

```
vertx run MyVerticle.java -instances 10
```

Run 20 instances of a ruby worker verticle

```
vertx run order_worker.rb -instances 20 -worker
```

Run two JavaScript verticles on the same machine and let them cluster together with each other and any other servers on the network

```
vertx run handler.js -cluster
vertx run sender.js -cluster
```

Run a Ruby verticle passing it some config

```
vertx run my_verticle.rb -conf my_verticle.conf
```

Where `my_verticle.conf` might contain something like:

```
{
"name": "foo",
"num_widgets": 46
}
```

The config will be available inside the verticle via the core API.

When using the high-availability feature of vert.x you may want to create a *bare* instance of vert.x. This instance does not deploy any verticles when launched, but will receive a verticle if another node of the cluster dies. To create a *bare* instance, launch:

```
vertx bare
```

Depending on your cluster configuration, you may have to append the `cluster-host` and `cluster-port` parameters.

### [Executing a Vert.x application packaged as a fat jar](#_executing_a_vert_x_application_packaged_as_a_fat_jar)

A *fat jar* is an executable jar embedding its dependencies. This means you don’t have to have Vert.x pre-installed on the machine on which you execute the jar. Like any executable Java jar it can be executed with.

```
java -jar my-application-fat.jar
```

There is nothing really Vert.x specific about this, you could do this with any Java application

You can either create your own main class and specify that in the manifest, but it’s recommended that you write your code as verticles and use the Vert.x `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` class (`io.vertx.core.Launcher`) as your main class. This is the same main class used when running Vert.x at the command line and therefore allows you to specify command line arguments, such as `-instances` in order to scale your application more easily.

To deploy your verticle in a *fatjar* like this you must have a *manifest* with:

* `Main-Class` set to `io.vertx.core.Launcher`
* `Main-Verticle` specifying the main verticle (fully qualified class name or script file name)

You can also provide the usual command line arguments that you would pass to `vertx run`:

```
java -jar my-verticle-fat.jar -cluster -conf myconf.json
java -jar my-verticle-fat.jar -cluster -conf myconf.json -cp path/to/dir/conf/cluster_xml
```

|  | Please consult the Maven/Gradle simplest and Maven/Gradle verticle examples in the examples repository for examples of building applications as fatjars. |
| --- | --- |

A fat jar executes the `run` command, by default.

### [Displaying version of Vert.x](#_displaying_version_of_vert_x)

To display the vert.x version, just launch:

```
vertx version
```

### [Other commands](#_other_commands)

The `vertx` command line and the `Launcher` also provide other *commands* in addition to `run` and `version`:

You can create a `bare` instance using:

```
vertx bare
# or
java -jar my-verticle-fat.jar bare
```

You can also start an application in background using:

```
java -jar my-verticle-fat.jar start --vertx-id=my-app-name
```

If `my-app-name` is not set, a random id will be generated, and printed on the command prompt. You can pass `run` options to the `start` command:

```
java -jar my-verticle-fat.jar start —-vertx-id=my-app-name -cluster
```

Once launched in background, you can stop it with the `stop` command:

```
java -jar my-verticle-fat.jar stop my-app-name
```

You can also list the vert.x application launched in background using:

```
java -jar my-verticle-fat.jar list
```

The `start`, `stop` and `list` command are also available from the `vertx` tool. The start` command supports a couple of options:

* `vertx-id` : the application id, uses a random UUID if not set
* `java-opts` : the Java Virtual Machine options, uses the `JAVA_OPTS` environment variable if not set.
* `redirect-output` : redirect the spawned process output and error streams to the parent process streams.

If option values contain spaces, don’t forget to wrap the value between `""` (double-quotes).

As the `start` command spawns a new process, the java options passed to the JVM are not propagated, so you **must** use `java-opts` to configure the JVM (`-X`, `-D`…​). If you use the `CLASSPATH` environment variable, be sure it contains all the required jars (vertx-core, your jars and all the dependencies).

The set of commands is extensible, refer to the [Extending the vert.x Launcher](#_extending_the_vert_x_launcher) section.

### [Live Redeploy](#_live_redeploy)

When developing it may be convenient to automatically redeploy your application upon file changes. The `vertx` command line tool and more generally the `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` class offers this feature. Here are some examples:

```
vertx run MyVerticle.groovy --redeploy="**/*.groovy" --launcher-class=io.vertx.core.Launcher
vertx run MyVerticle.groovy --redeploy="**/*.groovy,**/*.rb"  --launcher-class=io.vertx.core.Launcher
java io.vertx.core.Launcher run org.acme.MyVerticle --redeploy="**/*.class"  --launcher-class=io.vertx.core
.Launcher -cp ...
```

The redeployment process is implemented as follows. First your application is launched as a background application (with the `start` command). On matching file changes, the process is stopped and the application is restarted. This avoids leaks, as the process is restarted.

To enable the live redeploy, pass the `--redeploy` option to the `run` command. The `--redeploy` indicates the set of file to *watch*. This set can use Ant-style patterns (with `**`, `*` and `?`). You can specify several sets by separating them using a comma (`,`). Patterns are relative to the current working directory.

Parameters passed to the `run` command are passed to the application. Java Virtual Machine options can be configured using `--java-opts`. For instance, to pass the `conf` parameter or a system property, you need to use: `--java-opts="-conf=my-conf.json -Dkey=value"`

The `--launcher-class` option determine with with *main* class the application is launcher. It’s generally `[Launcher](../../apidocs/io/vertx/core/Launcher.html)`, but you have use you own *main*.

The redeploy feature can be used in your IDE:

* Eclipse - create a *Run* configuration, using the `io.vertx.core.Launcher` class a *main class*. In the *Program arguments* area (in the *Arguments* tab), write `run your-verticle-fully-qualified-name --redeploy=**/*.java --launcher-class=io.vertx.core.Launcher`. You can also add other parameters. The redeployment works smoothly as Eclipse incrementally compiles your files on save.
* IntelliJ - create a *Run* configuration (*Application*), set the *Main class* to `io.vertx.core.Launcher`. In the Program arguments write: `run your-verticle-fully-qualified-name --redeploy=**/*.class --launcher-class=io.vertx.core.Launcher`. To trigger the redeployment, you need to *make* the project or the module explicitly (*Build* menu → *Make project*).

To debug your application, create your run configuration as a remote application and configure the debugger using `--java-opts`. However, don’t forget to re-plug the debugger after every redeployment as a new process is created every time.

You can also hook your build process in the redeploy cycle:

```
java -jar target/my-fat-jar.jar --redeploy="**/*.java" --on-redeploy="mvn package"
java -jar build/libs/my-fat-jar.jar --redeploy="src/**/*.java" --on-redeploy='./gradlew shadowJar'
```

The "on-redeploy" option specifies a command invoked after the shutdown of the application and before the restart. So you can hook your build tool if it updates some runtime artifacts. For instance, you can launch `gulp` or `grunt` to update your resources. Don’t forget that passing parameters to your application requires the `--java-opts` param:

```
java -jar target/my-fat-jar.jar --redeploy="**/*.java" --on-redeploy="mvn package" --java-opts="-Dkey=val"
java -jar build/libs/my-fat-jar.jar --redeploy="src/**/*.java" --on-redeploy='./gradlew shadowJar' --java-opts="-Dkey=val"
```

The redeploy feature also supports the following settings:

* `redeploy-scan-period` : the file system check period (in milliseconds), 250ms by default
* `redeploy-grace-period` : the amount of time (in milliseconds) to wait between 2 re-deployments, 1000ms by default
* `redeploy-termination-period` : the amount of time to wait after having stopped the application (before launching user command). This is useful on Windows, where the process is not killed immediately. The time is given in milliseconds. 0 ms by default.

## [Cluster Managers](#_cluster_managers)

In Vert.x a cluster manager is used for various functions including:

* Discovery and group membership of Vert.x nodes in a cluster
* Maintaining cluster wide topic subscriber lists (so we know which nodes are interested in which event bus addresses)
* Distributed Map support
* Distributed Locks
* Distributed Counters

Cluster managers *do not* handle the event bus inter-node transport, this is done directly by Vert.x with TCP connections.

The default cluster manager used in the Vert.x distributions is one that uses [Hazelcast](http://hazelcast.com) but this can be easily replaced by a different implementation as Vert.x cluster managers are pluggable.

A cluster manager must implement the interface `[ClusterManager](../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html)`. Vert.x locates cluster managers at run-time by using the Java [Service Loader](https://docs.oracle.com/javase/8/docs/api/java/util/ServiceLoader.html) functionality to locate instances of `[ClusterManager](../../apidocs/io/vertx/core/spi/cluster/ClusterManager.html)` on the classpath.

If you are using Vert.x at the command line and you want to use clustering you should make sure the `lib` directory of the Vert.x installation contains your cluster manager jar.

If you are using Vert.x from a Maven or Gradle project just add the cluster manager jar as a dependency of your project.

You can also specify cluster managers [programmatically](#cluster_manager_spi) if embedding Vert.x.

## [Logging](#_logging)

Vert.x logs using its internal logging API and supports various logging backends.

The logging backend is selected as follows:

1. the backend denoted by the `vertx.logger-delegate-factory-class-name` system property if present or,
2. JDK logging when a `vertx-default-jul-logging.properties` file is in the classpath or,
3. a backend present in the classpath, in the following order of preference:

   1. SLF4J
   2. Log4J2

Otherwise Vert.x defaults to JDK logging.

### [Configuring with the system property](#_configuring_with_the_system_property)

Set the `vertx.logger-delegate-factory-class-name` system property to:

* `io.vertx.core.logging.SLF4JLogDelegateFactory` for SLF4J or,
* `io.vertx.core.logging.Log4j2LogDelegateFactory` for Log4J2 or,
* `io.vertx.core.logging.JULLogDelegateFactory` for JDK logging

### [Automatic configuration](#_automatic_configuration)

When no `vertx.logger-delegate-factory-class-name` system property is set, Vert.x will try to find the most appropriate logger:

* use SLF4J when available on the classpath with an actual implementation (i.e. `LoggerFactory.getILoggerFactory()` is not an instance of `NOPLoggerFactory`)
* otherwise use Log4j2 when available on the classpath
* otherwise use JUL

### [Configuring JUL logging](#_configuring_jul_logging)

A JUL logging configuration file can be specified in the normal JUL way, by providing a system property named `java.util.logging.config.file` with the value being your configuration file. For more information on this and the structure of a JUL config file please consult the JDK logging documentation.

Vert.x also provides a slightly more convenient way to specify a configuration file without having to set a system property. Just provide a JUL config file with the name `vertx-default-jul-logging.properties` on your classpath (e.g. inside your fatjar) and Vert.x will use that to configure JUL.

### [Netty logging](#netty-logging)

Netty does not rely on external logging configuration (e.g system properties). Instead, it implements a logging configuration based on the logging libraries visible from the Netty classes:

* use `SLF4J` library if it is visible
* otherwise use `Log4j` if it is visible
* otherwise use `Log4j2` if it is visible
* otherwise fallback to `java.util.logging`

|  | The eagle eyes among you might have noticed that Vert.x follows the same order of preference. |
| --- | --- |

The logger implementation can be forced to a specific implementation by setting Netty’s internal logger implementation directly on `io.netty.util.internal.logging.InternalLoggerFactory`:

```
// Force logging to Log4j 2
InternalLoggerFactory.setDefaultFactory(Log4J2LoggerFactory.INSTANCE);
```

### [Troubleshooting](#_troubleshooting)

#### [SLF4J warning at startup](#_slf4j_warning_at_startup)

If, when you start your application, you see the following message:

```
SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder".
SLF4J: Defaulting to no-operation (NOP) logger implementation
SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details.
```

It means that you have SLF4J-API in your classpath but no actual binding. Messages logged with SLF4J will be dropped. You should add a binding to your classpath. Check <https://www.slf4j.org/manual.html#swapping> to pick a binding and configure it.

Be aware that Netty looks for the SLF4-API jar and uses it by default.

#### [Connection reset by peer](#_connection_reset_by_peer)

If your logs show a bunch of:

```
io.vertx.core.net.impl.ConnectionBase
SEVERE: java.io.IOException: Connection reset by peer
```

It means that the client is resetting the HTTP connection instead of closing it. This message also indicates that you may have not consumed the complete payload (the connection was cut before you were able to).

## [Host name resolution](#_host_name_resolution)

Vert.x uses an an address resolver for resolving host name into IP addresses instead of the JVM built-in blocking resolver.

An host name resolves to an IP address using:

* the *hosts* file of the operating system
* otherwise DNS queries against a list of servers

By default it will use the list of the system DNS server addresses from the environment, if that list cannot be retrieved it will use Google’s public DNS servers `"8.8.8.8"` and `"8.8.4.4"`.

DNS servers can be also configured when creating a `[Vertx](../../apidocs/io/vertx/core/Vertx.html)` instance:

```
Vertx vertx = Vertx.vertx(new VertxOptions().
    setAddressResolverOptions(
        new AddressResolverOptions().
            addServer("192.168.0.1").
            addServer("192.168.0.2:40000"))
);
```

The default port of a DNS server is `53`, when a server uses a different port, this port can be set using a colon delimiter: `192.168.0.2:40000`.

|  | sometimes it can be desirable to use the JVM built-in resolver, the JVM system property *-Dvertx.disableDnsResolver=true* activates this behavior |
| --- | --- |

### [Failover](#_failover)

When a server does not reply in a timely manner, the resolver will try the next one from the list, the search is limited by `[setMaxQueries](../../apidocs/io/vertx/core/dns/AddressResolverOptions.html#setMaxQueries-int-)` (the default value is `4` queries).

A DNS query is considered as failed when the resolver has not received a correct answer within `[getQueryTimeout](../../apidocs/io/vertx/core/dns/AddressResolverOptions.html#getQueryTimeout--)` milliseconds (the default value is `5` seconds).

### [Server list rotation](#_server_list_rotation)

By default the dns server selection uses the first one, the remaining servers are used for failover.

You can configure `[setRotateServers](../../apidocs/io/vertx/core/dns/AddressResolverOptions.html#setRotateServers-boolean-)` to `true` to let the resolver perform a round-robin selection instead. It spreads the query load among the servers and avoids all lookup to hit the first server of the list.

Failover still applies and will use the next server in the list.

### [Hosts mapping](#_hosts_mapping)

The *hosts* file of the operating system is used to perform an hostname lookup for an ipaddress.

An alternative *hosts* file can be used instead:

```
Vertx vertx = Vertx.vertx(new VertxOptions().
    setAddressResolverOptions(
        new AddressResolverOptions().
            setHostsPath("/path/to/hosts"))
);
```

### [Search domains](#_search_domains)

By default the resolver will use the system DNS search domains from the environment. Alternatively an explicit search domain list can be provided:

```
Vertx vertx = Vertx.vertx(new VertxOptions().
    setAddressResolverOptions(
        new AddressResolverOptions().addSearchDomain("foo.com").addSearchDomain("bar.com"))
);
```

When a search domain list is used, the threshold for the number of dots is `1` or loaded from `/etc/resolv.conf` on Linux, it can be configured to a specific value with `[setNdots](../../apidocs/io/vertx/core/dns/AddressResolverOptions.html#setNdots-int-)`.

### [MacOS configuration](#_macos_configuration)

MacOS has a specific native extension to get the name server configuration of the system based on <a href="https://opensource.apple.com/tarballs/mDNSResponder/">Apple’s open source mDNSResponder</a>. When this extension is not present, Netty logs the following warning.

```
[main] WARN io.netty.resolver.dns.DnsServerAddressStreamProviders - Can not find io.netty.resolver.dns.macos.MacOSDnsServerAddressStreamProvider in the classpath, fallback to system defaults. This may result in incorrect DNS resolutions on MacOS.
```

This extension is not required as its absence does not prevent Vert.x to execute, yet is **recommended**.

You can use add it to your classpath to improve the integration and remove the warning.

  Intel-based Mac
```
<profile>
 <id>mac-intel</id>
 <activation>
   <os>
     <family>mac</family>
     <arch>x86_64</arch>
   </os>
 </activation>
 <dependencies>
   <dependency>
     <groupId>io.netty</groupId>
     <artifactId>netty-resolver-dns-native-macos</artifactId>
     <classifier>osx-x86_64</classifier>
     <!--<version>Should align with netty version that Vert.x uses</version>-->
   </dependency>
 </dependencies>
</profile>
```
   M1/M2 Mac
```
<profile>
 <id>mac-silicon</id>
 <activation>
   <os>
     <family>mac</family>
     <arch>aarch64</arch>
   </os>
 </activation>
 <dependencies>
   <dependency>
     <groupId>io.netty</groupId>
     <artifactId>netty-resolver-dns-native-macos</artifactId>
     <classifier>osx-aarch_64</classifier>
     <!--<version>Should align with netty version that Vert.x uses</version>-->
   </dependency>
 </dependencies>
</profile>
```

## [High Availability and Fail-Over](#_high_availability_and_fail_over)

Vert.x allows you to run your verticles with high availability (HA) support. In that case, when a vert.x instance running a verticle dies abruptly, the verticle is migrated to another vertx instance. The vert.x instances must be in the same cluster.

### [Automatic failover](#_automatic_failover)

When vert.x runs with *HA* enabled, if a vert.x instance where a verticle runs fails or dies, the verticle is redeployed automatically on another vert.x instance of the cluster. We call this *verticle fail-over*.

To run vert.x with the *HA* enabled, just add the `-ha` flag to the command line:

```
vertx run my-verticle.js -ha
```

Now for HA to work, you need more than one Vert.x instances in the cluster, so let’s say you have another Vert.x instance that you have already started, for example:

```
vertx run my-other-verticle.js -ha
```

If the Vert.x instance that is running `my-verticle.js` now dies (you can test this by killing the process with `kill -9`), the Vert.x instance that is running `my-other-verticle.js` will automatic deploy `my-verticle .js` so now that Vert.x instance is running both verticles.

|  | the migration is only possible if the second vert.x instance has access to the verticle file (here `my-verticle.js`). |
| --- | --- |

|  | Please note that cleanly closing a Vert.x instance will not cause failover to occur, e.g. `CTRL-C` or `kill -SIGINT` |
| --- | --- |

You can also start *bare* Vert.x instances - i.e. instances that are not initially running any verticles, they will also failover for nodes in the cluster. To start a bare instance you simply do:

```
vertx run -ha
```

When using the `-ha` switch you do not need to provide the `-cluster` switch, as a cluster is assumed if you want HA.

|  | depending on your cluster configuration, you may need to customize the cluster manager configuration (Hazelcast by default), and/or add the `cluster-host` and `cluster-port` parameters. |
| --- | --- |

### [HA groups](#_ha_groups)

When running a Vert.x instance with HA you can also optional specify a *HA group*. A HA group denotes a logical group of nodes in the cluster. Only nodes with the same HA group will failover onto one another. If you don’t specify a HA group the default group `__DEFAULT__` is used.

To specify an HA group you use the `-hagroup` switch when running the verticle, e.g.

```
vertx run my-verticle.js -ha -hagroup my-group
```

Let’s look at an example:

In a first terminal:

```
vertx run my-verticle.js -ha -hagroup g1
```

In a second terminal, let’s run another verticle using the same group:

```
vertx run my-other-verticle.js -ha -hagroup g1
```

Finally, in a third terminal, launch another verticle using a different group:

```
vertx run yet-another-verticle.js -ha -hagroup g2
```

If we kill the instance in terminal 1, it will fail over to the instance in terminal 2, not the instance in terminal 3 as that has a different group.

If we kill the instance in terminal 3, it won’t get failed over as there is no other vert.x instance in that group.

### [Dealing with network partitions - Quorum](#_dealing_with_network_partitions_quorum)

The HA implementation also supports quorum. A quorum is the minimum number of votes that a distributed transaction has to obtain in order to be allowed to perform an operation in a distributed system.

When starting a Vert.x instance you can instruct it that it requires a `quorum` before any HA deployments will be deployed. In this context, a quorum is a minimum number of nodes for a particular group in the cluster. Typically you chose your quorum size to `Q = 1 + N/2` where `N` is the number of nodes in the group. If there are less than `Q` nodes in the cluster the HA deployments will undeploy. They will redeploy again if/when a quorum is re-attained. By doing this you can prevent against network partitions, a.k.a. *split brain*.

There is more information on quorum [here](https://en.wikipedia.org/wiki/Quorum_%28distributed_computing%29).

To run vert.x instances with a quorum you specify `-quorum` on the command line, e.g.

In a first terminal:

```
vertx run my-verticle.js -ha -quorum 3
```

At this point the Vert.x instance will start but not deploy the module (yet) because there is only one node in the cluster, not 3.

In a second terminal:

```
vertx run my-other-verticle.js -ha -quorum 3
```

At this point the Vert.x instance will start but not deploy the module (yet) because there are only two nodes in the cluster, not 3.

In a third console, you can start another instance of vert.x:

```
vertx run yet-another-verticle.js -ha -quorum 3
```

Yay! - we have three nodes, that’s a quorum. At this point the modules will automatically deploy on all instances.

If we now close or kill one of the nodes the modules will automatically undeploy on the other nodes, as there is no longer a quorum.

Quorum can also be used in conjunction with ha groups. In that case, quorum are resolved for each particular group.

## [Native transports](#_native_transports)

Vert.x can run with [native transports](http://netty.io/wiki/native-transports.html) (when available) on BSD (OSX) and Linux:

```
Vertx vertx = Vertx.vertx(new VertxOptions().
  setPreferNativeTransport(true)
);

// True when native is available
boolean usingNative = vertx.isNativeTransportEnabled();
System.out.println("Running with native: " + usingNative);
```

|  | preferring native transport will not prevent the application to execute (for example if a JAR is missing). If your application requires native transport, you need to check `[isNativeTransportEnabled](../../apidocs/io/vertx/core/Vertx.html#isNativeTransportEnabled--)`. |
| --- | --- |

### [Native Linux Transport](#_native_linux_transport)

You need to add the following dependency in your classpath:

```
<dependency>
 <groupId>io.netty</groupId>
 <artifactId>netty-transport-native-epoll</artifactId>
 <classifier>linux-x86_64</classifier>
 <!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
```

Native on Linux gives you extra networking options:

* `SO_REUSEPORT`
* `TCP_QUICKACK`
* `TCP_CORK`
* `TCP_FASTOPEN`
* `TCP_USER_TIMEOUT`

```
vertx.createHttpServer(new HttpServerOptions()
  .setTcpFastOpen(fastOpen)
  .setTcpCork(cork)
  .setTcpQuickAck(quickAck)
  .setReusePort(reusePort)
);
```

### [Native BSD Transport](#_native_bsd_transport)

You need to add the following dependency in your classpath:

  Intel-based Mac
```
<dependency>
 <groupId>io.netty</groupId>
 <artifactId>netty-transport-native-kqueue</artifactId>
 <classifier>osx-x86_64</classifier>
 <!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
```
   M1/M2 Mac
```
<dependency>
<groupId>io.netty</groupId>
<artifactId>netty-transport-native-kqueue</artifactId>
<classifier>osx-aarch_64</classifier>
<!--<version>Should align with netty version that Vert.x uses</version>-->
</dependency>
```

MacOS Sierra and above are supported.

Native on BSD gives you extra networking options:

* `SO_REUSEPORT`

```
vertx.createHttpServer(new HttpServerOptions().setReusePort(reusePort));
```

### [Domain sockets](#_domain_sockets)

Natives provide domain sockets support for servers:

```
vertx.createNetServer().connectHandler(so -> {
  // Handle application
}).listen(SocketAddress.domainSocketAddress("/var/tmp/myservice.sock"));
```

or for http:

```
vertx.createHttpServer()
  .requestHandler(req -> {
    // Handle application
  })
  .listen(SocketAddress.domainSocketAddress("/var/tmp/myservice.sock"))
  .onComplete(ar -> {
    if (ar.succeeded()) {
      // Bound to socket
    } else {
      ar.cause().printStackTrace();
    }
  });
```

As well as clients:

```
NetClient netClient = vertx.createNetClient();

// Only available on BSD and Linux
SocketAddress addr = SocketAddress.domainSocketAddress("/var/tmp/myservice.sock");

// Connect to the server
netClient
  .connect(addr)
  .onComplete(ar -> {
    if (ar.succeeded()) {
      // Connected
    } else {
      ar.cause().printStackTrace();
    }
  });
```

or for http:

```
HttpClient httpClient = vertx.createHttpClient();

// Only available on BSD and Linux
SocketAddress addr = SocketAddress.domainSocketAddress("/var/tmp/myservice.sock");

// Send request to the server
httpClient.request(new RequestOptions()
  .setServer(addr)
  .setHost("localhost")
  .setPort(8080)
  .setURI("/"))
  .onSuccess(request -> {
    request.send().onComplete(response -> {
      // Process response
    });
  });
```

## [Security notes](#_security_notes)

Vert.x is a toolkit, not an opinionated framework where we force you to do things in a certain way. This gives you great power as a developer but with that comes great responsibility.

As with any toolkit, it’s possible to write insecure applications, so you should always be careful when developing your application especially if it’s exposed to the public (e.g. over the internet).

### [Web applications](#_web_applications)

If writing a web application it’s highly recommended that you use Vert.x-Web instead of Vert.x core directly for serving resources and handling file uploads.

Vert.x-Web normalises the path in requests to prevent malicious clients from crafting URLs to access resources outside of the web root.

Similarly for file uploads Vert.x-Web provides functionality for uploading to a known place on disk and does not rely on the filename provided by the client in the upload which could be crafted to upload to a different place on disk.

Vert.x core itself does not provide such checks so it would be up to you as a developer to implement them yourself.

### [Clustered event bus traffic](#_clustered_event_bus_traffic)

When clustering the event bus between different Vert.x nodes on a network, the traffic is sent un-encrypted across the wire, so do not use this if you have confidential data to send and your Vert.x nodes are not on a trusted network.

### [Standard security best practices](#_standard_security_best_practices)

Any service can have potentially vulnerabilities whether it’s written using Vert.x or any other toolkit so always follow security best practice, especially if your service is public facing.

For example you should always run them in a DMZ and with an user account that has limited rights in order to limit the extent of damage in case the service was compromised.

## [Vert.x Command Line Interface API](#_vert_x_command_line_interface_api)

Vert.x Core provides an API for parsing command line arguments passed to programs. It’s also able to print help messages detailing the options available for a command line tool. Even if such features are far from the Vert.x core topics, this API is used in the `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` class that you can use in *fat-jar* and in the `vertx` command line tools. In addition, it’s polyglot (can be used from any supported language) and is used in Vert.x Shell.

Vert.x CLI provides a model to describe your command line interface, but also a parser. This parser supports different types of syntax:

* POSIX like options (ie. `tar -zxvf foo.tar.gz`)
* GNU like long options (ie. `du --human-readable --max-depth=1`)
* Java like properties (ie. `java -Djava.awt.headless=true -Djava.net.useSystemProxies=true Foo`)
* Short options with value attached (ie. `gcc -O2 foo.c`)
* Long options with single hyphen (ie. `ant -projecthelp`)

Using the CLI api is a 3-steps process:

1. The definition of the command line interface
2. The parsing of the user command line
3. The query / interrogation

### [Definition Stage](#_definition_stage)

Each command line interface must define the set of options and arguments that will be used. It also requires a name. The CLI API uses the `[Option](../../apidocs/io/vertx/core/cli/Option.html)` and `[Argument](../../apidocs/io/vertx/core/cli/Argument.html)` classes to describe options and arguments:

```
CLI cli = CLI.create("copy")
    .setSummary("A command line interface to copy files.")
    .addOption(new Option()
        .setLongName("directory")
        .setShortName("R")
        .setDescription("enables directory support")
        .setFlag(true))
    .addArgument(new Argument()
        .setIndex(0)
        .setDescription("The source")
        .setArgName("source"))
    .addArgument(new Argument()
        .setIndex(1)
        .setDescription("The destination")
        .setArgName("target"));
```

As you can see, you can create a new `[CLI](../../apidocs/io/vertx/core/cli/CLI.html)` using `[CLI.create](../../apidocs/io/vertx/core/cli/CLI.html#create-java.lang.String-)`. The passed string is the name of the CLI. Once created you can set the summary and description. The summary is intended to be short (one line), while the description can contain more details. Each option and argument are also added on the `CLI` object using the `[addArgument](../../apidocs/io/vertx/core/cli/CLI.html#addArgument-io.vertx.core.cli.Argument-)` and `[addOption](../../apidocs/io/vertx/core/cli/CLI.html#addOption-io.vertx.core.cli.Option-)` methods.

#### [Options](#_options)

An `[Option](../../apidocs/io/vertx/core/cli/Option.html)` is a command line parameter identified by a *key* present in the user command line. Options must have at least a long name or a short name. Long name are generally used using a `--` prefix, while short names are used with a single `-`. Names are case-sensitive; however, case-insensitive name matching will be used during the [Query / Interrogation Stage](#query_interrogation_stage) if no exact match is found. Options can get a description displayed in the usage (see below). Options can receive 0, 1 or several values. An option receiving 0 values is a `flag`, and must be declared using `[setFlag](../../apidocs/io/vertx/core/cli/Option.html#setFlag-boolean-)`. By default, options receive a single value, however, you can configure the option to receive several values using `[setMultiValued](../../apidocs/io/vertx/core/cli/Option.html#setMultiValued-boolean-)`:

```
CLI cli = CLI.create("some-name")
    .setSummary("A command line interface illustrating the options valuation.")
    .addOption(new Option()
        .setLongName("flag").setShortName("f").setFlag(true).setDescription("a flag"))
    .addOption(new Option()
        .setLongName("single").setShortName("s").setDescription("a single-valued option"))
    .addOption(new Option()
        .setLongName("multiple").setShortName("m").setMultiValued(true)
        .setDescription("a multi-valued option"));
```

Options can be marked as mandatory. A mandatory option not set in the user command line throws an exception during the parsing:

```
CLI cli = CLI.create("some-name")
    .addOption(new Option()
        .setLongName("mandatory")
        .setRequired(true)
        .setDescription("a mandatory option"));
```

Non-mandatory options can have a *default value*. This value would be used if the user does not set the option in the command line:

```
CLI cli = CLI.create("some-name")
    .addOption(new Option()
        .setLongName("optional")
        .setDefaultValue("hello")
        .setDescription("an optional option with a default value"));
```

An option can be *hidden* using the `[setHidden](../../apidocs/io/vertx/core/cli/Option.html#setHidden-boolean-)` method. Hidden option are not listed in the usage, but can still be used in the user command line (for power-users).

If the option value is constrained to a fixed set, you can set the different acceptable choices:

```
CLI cli = CLI.create("some-name")
    .addOption(new Option()
        .setLongName("color")
        .setDefaultValue("green")
        .addChoice("blue").addChoice("red").addChoice("green")
        .setDescription("a color"));
```

Options can also be instantiated from their JSON form.

#### [Arguments](#_arguments)

Unlike options, arguments do not have a *key* and are identified by their *index*. For example, in `java com.acme.Foo`, `com.acme.Foo` is an argument.

Arguments do not have a name, there are identified using a 0-based index. The first parameter has the index `0`:

```
CLI cli = CLI.create("some-name")
    .addArgument(new Argument()
        .setIndex(0)
        .setDescription("the first argument")
        .setArgName("arg1"))
    .addArgument(new Argument()
        .setIndex(1)
        .setDescription("the second argument")
        .setArgName("arg2"));
```

If you don’t set the argument indexes, it computes it automatically by using the declaration order.

```
CLI cli = CLI.create("some-name")
    // will have the index 0
    .addArgument(new Argument()
        .setDescription("the first argument")
        .setArgName("arg1"))
    // will have the index 1
    .addArgument(new Argument()
        .setDescription("the second argument")
        .setArgName("arg2"));
```

The `argName` is optional and used in the usage message.

As options, `[Argument](../../apidocs/io/vertx/core/cli/Argument.html)` can:

* be hidden using `[setHidden](../../apidocs/io/vertx/core/cli/Argument.html#setHidden-boolean-)`
* be mandatory using `[setRequired](../../apidocs/io/vertx/core/cli/Argument.html#setRequired-boolean-)`
* have a default value using `[setDefaultValue](../../apidocs/io/vertx/core/cli/Argument.html#setDefaultValue-java.lang.String-)`
* receive several values using `[setMultiValued](../../apidocs/io/vertx/core/cli/Argument.html#setMultiValued-boolean-)` - only the last argument can be multi-valued.

Arguments can also be instantiated from their JSON form.

#### [Usage generation](#_usage_generation)

Once your `[CLI](../../apidocs/io/vertx/core/cli/CLI.html)` instance is configured, you can generate the *usage* message:

```
CLI cli = CLI.create("copy")
    .setSummary("A command line interface to copy files.")
    .addOption(new Option()
        .setLongName("directory")
        .setShortName("R")
        .setDescription("enables directory support")
        .setFlag(true))
    .addArgument(new Argument()
        .setIndex(0)
        .setDescription("The source")
        .setArgName("source"))
    .addArgument(new Argument()
        .setIndex(0)
        .setDescription("The destination")
        .setArgName("target"));

StringBuilder builder = new StringBuilder();
cli.usage(builder);
```

It generates a usage message like this one:

```
Usage: copy [-R] source target

A command line interface to copy files.

 -R,--directory   enables directory support
```

If you need to tune the usage message, check the `[UsageMessageFormatter](../../apidocs/io/vertx/core/cli/UsageMessageFormatter.html)` class.

### [Parsing Stage](#_parsing_stage)

Once your `[CLI](../../apidocs/io/vertx/core/cli/CLI.html)` instance is configured, you can parse the user command line to evaluate each option and argument:

```
CommandLine commandLine = cli.parse(userCommandLineArguments);
```

The `[parse](../../apidocs/io/vertx/core/cli/CLI.html#parse-java.util.List-)` method returns a `[CommandLine](../../apidocs/io/vertx/core/cli/CommandLine.html)` object containing the values. By default, it validates the user command line and checks that each mandatory options and arguments have been set as well as the number of values received by each option. You can disable the validation by passing `false` as second parameter of `[parse](../../apidocs/io/vertx/core/cli/CLI.html#parse-java.util.List-boolean-)`. This is useful if you want to check an argument or option is present even if the parsed command line is invalid.

You can check whether or not the `[CommandLine](../../apidocs/io/vertx/core/cli/CommandLine.html)` is valid using `[isValid](../../apidocs/io/vertx/core/cli/CommandLine.html#isValid--)`.

### [Query / Interrogation Stage](#query_interrogation_stage)

Once parsed, you can retrieve the values of the options and arguments from the `[CommandLine](../../apidocs/io/vertx/core/cli/CommandLine.html)` object returned by the `[parse](../../apidocs/io/vertx/core/cli/CLI.html#parse-java.util.List-)` method:

```
CommandLine commandLine = cli.parse(userCommandLineArguments);
String opt = commandLine.getOptionValue("my-option");
boolean flag = commandLine.isFlagEnabled("my-flag");
String arg0 = commandLine.getArgumentValue(0);
```

One of your options can be marked as "help". If a user command line enabled a "help" option, the validation won’t fail, but you have the opportunity to check if the user asks for help:

```
CLI cli = CLI.create("test")
    .addOption(
        new Option().setLongName("help").setShortName("h").setFlag(true).setHelp(true))
    .addOption(
        new Option().setLongName("mandatory").setRequired(true));

CommandLine line = cli.parse(Collections.singletonList("-h"));

// The parsing does not fail and let you do:
if (!line.isValid() && line.isAskingForHelp()) {
  StringBuilder builder = new StringBuilder();
  cli.usage(builder);
  stream.print(builder.toString());
}
```

### [Typed options and arguments](#_typed_options_and_arguments)

The described `[Option](../../apidocs/io/vertx/core/cli/Option.html)` and `[Argument](../../apidocs/io/vertx/core/cli/Argument.html)` classes are *untyped*, meaning that the only get String values. `[TypedOption](../../apidocs/io/vertx/core/cli/TypedOption.html)` and `[TypedArgument](../../apidocs/io/vertx/core/cli/TypedArgument.html)` let you specify a *type*, so the (String) raw value is converted to the specified type.

Instead of `[Option](../../apidocs/io/vertx/core/cli/Option.html)` and `[Argument](../../apidocs/io/vertx/core/cli/Argument.html)`, use `[TypedOption](../../apidocs/io/vertx/core/cli/TypedOption.html)` and `[TypedArgument](../../apidocs/io/vertx/core/cli/TypedArgument.html)` in the `[CLI](../../apidocs/io/vertx/core/cli/CLI.html)` definition:

```
CLI cli = CLI.create("copy")
    .setSummary("A command line interface to copy files.")
    .addOption(new TypedOption<Boolean>()
        .setType(Boolean.class)
        .setLongName("directory")
        .setShortName("R")
        .setDescription("enables directory support")
        .setFlag(true))
    .addArgument(new TypedArgument<File>()
        .setType(File.class)
        .setIndex(0)
        .setDescription("The source")
        .setArgName("source"))
    .addArgument(new TypedArgument<File>()
        .setType(File.class)
        .setIndex(0)
        .setDescription("The destination")
        .setArgName("target"));
```

Then you can retrieve the converted values as follows:

```
CommandLine commandLine = cli.parse(userCommandLineArguments);
boolean flag = commandLine.getOptionValue("R");
File source = commandLine.getArgumentValue("source");
File target = commandLine.getArgumentValue("target");
```

The vert.x CLI is able to convert to classes:

* having a constructor with a single `[String](../../apidocs/java/lang/String.html)` argument, such as `[File](../../apidocs/java/io/File.html)` or `[JsonObject](../../apidocs/io/vertx/core/json/JsonObject.html)`
* with a static `from` or `fromString` method
* with a static `valueOf` method, such as primitive types and enumeration

In addition, you can implement your own `[Converter](../../apidocs/io/vertx/core/cli/converters/Converter.html)` and instruct the CLI to use this converter:

```
CLI cli = CLI.create("some-name")
    .addOption(new TypedOption<Person>()
        .setType(Person.class)
        .setConverter(new PersonConverter())
        .setLongName("person"));
```

For booleans, the boolean values are evaluated to `true`: `on`, `yes`, `1`, `true`.

If one of your option has an `enum` as type, it computes the set of choices automatically.

### [Using annotations](#_using_annotations)

You can also define your CLI using annotations. Definition is done using annotation on the class and on *setter* methods:

```
@Name("some-name")
@Summary("some short summary.")
@Description("some long description")
public class AnnotatedCli {

 private boolean flag;
 private String name;
 private String arg;

@Option(shortName = "f", flag = true)
public void setFlag(boolean flag) {
  this.flag = flag;
}

@Option(longName = "name")
public void setName(String name) {
  this.name = name;
}

@Argument(index = 0)
public void setArg(String arg) {
 this.arg = arg;
}
}
```

Once annotated, you can define the `[CLI](../../apidocs/io/vertx/core/cli/CLI.html)` and inject the values using:

```
CLI cli = CLI.create(AnnotatedCli.class);
CommandLine commandLine = cli.parse(userCommandLineArguments);
AnnotatedCli instance = new AnnotatedCli();
CLIConfigurator.inject(commandLine, instance);
```

## [The vert.x Launcher](#_the_vert_x_launcher)

The vert.x `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` is used in *fat jar* as main class, and by the `vertx` command line utility. It executes a set of *commands* such as *run*, *bare*, *start*…​

### [Extending the vert.x Launcher](#_extending_the_vert_x_launcher)

You can extend the set of command by implementing your own `[Command](../../apidocs/io/vertx/core/spi/launcher/Command.html)` (in Java only):

```
@Name("my-command")
@Summary("A simple hello command.")
public class MyCommand extends DefaultCommand {

 private String name;

 @Option(longName = "name", required = true)
 public void setName(String n) {
   this.name = n;
 }

 @Override
 public void run() throws CLIException {
   System.out.println("Hello " + name);
 }
}
```

You also need an implementation of `[CommandFactory](../../apidocs/io/vertx/core/spi/launcher/CommandFactory.html)`:

```
public class HelloCommandFactory extends DefaultCommandFactory<HelloCommand> {
 public HelloCommandFactory() {
  super(HelloCommand.class);
 }
}
```

Then, create the `src/main/resources/META-INF/services/io.vertx.core.spi.launcher.CommandFactory` and add a line indicating the fully qualified name of the factory:

```
io.vertx.core.launcher.example.HelloCommandFactory
```

Builds the jar containing the command. Be sure to includes the SPI file (`META-INF/services/io.vertx.core.spi.launcher.CommandFactory`).

Then, place the jar containing the command into the classpath of your fat-jar (or include it inside) or in the `lib` directory of your vert.x distribution, and you would be able to execute:

```
vertx hello vert.x
java -jar my-fat-jar.jar hello vert.x
```

### [Using the Launcher in fat jars](#_using_the_launcher_in_fat_jars)

To use the `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` class in a *fat-jar* just set the `Main-Class` of the *MANIFEST* to `io.vertx.core.Launcher`. In addition, set the `Main-Verticle` *MANIFEST* entry to the name of your main verticle.

By default, it executed the `run` command. However, you can configure the default command by setting the `Main-Command` *MANIFEST* entry. The default command is used if the *fat jar* is launched without a command.

### [Sub-classing the Launcher](#_sub_classing_the_launcher)

You can also create a sub-class of `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` to start your application. The class has been designed to be easily extensible.

A `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` sub-class can:

* customize the vert.x configuration in `[beforeStartingVertx](../../apidocs/io/vertx/core/Launcher.html#beforeStartingVertx-io.vertx.core.VertxOptions-)`
* retrieve the vert.x instance created by the "run" or "bare" command by overriding `[afterStartingVertx](../../apidocs/io/vertx/core/Launcher.html#afterStartingVertx-io.vertx.core.Vertx-)`
* configure the default verticle and command with `[getMainVerticle](../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#getMainVerticle--)` and `[getDefaultCommand](../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#getDefaultCommand--)`
* add / remove commands using `[register](../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#register-java.lang.Class-)` and `[unregister](../../apidocs/io/vertx/core/impl/launcher/VertxCommandLauncher.html#unregister-java.lang.String-)`

### [Launcher and exit code](#_launcher_and_exit_code)

When you use the `[Launcher](../../apidocs/io/vertx/core/Launcher.html)` class as main class, it uses the following exit code:

* `0` if the process ends smoothly, or if an uncaught error is thrown
* `1` for general purpose error
* `11` if Vert.x cannot be initialized
* `12` if a spawn process cannot be started, found or stopped. This error code is used by the `start` and `stop` command
* `14` if the system configuration is not meeting the system requirement (shc as java not found)
* `15` if the main verticle cannot be deployed

## [Configuring Vert.x cache](#_configuring_vert_x_cache)

When Vert.x needs to read a file from the classpath (embedded in a fat jar, in a jar form the classpath or a file that is on the classpath), it copies it to a cache directory. The reason behind this is simple: reading a file from a jar or from an input stream is blocking. So to avoid to pay the price every time, Vert.x copies the file to its cache directory and reads it from there every subsequent read. This behavior can be configured.

First, by default, Vert.x uses `$CWD/.vertx` as cache directory. It creates a unique directory inside this one to avoid conflicts. This location can be configured by using the `vertx.cacheDirBase` system property. For instance if the current working directory is not writable (such as in an immutable container context), launch your application with:

```
vertx run my.Verticle -Dvertx.cacheDirBase=/tmp/vertx-cache
# or
java -jar my-fat.jar vertx.cacheDirBase=/tmp/vertx-cache
```

|  | the directory must be **writable**. |
| --- | --- |

When you are editing resources such as HTML, CSS or JavaScript, this cache mechanism can be annoying as it serves only the first version of the file (and so you won’t see your edits if you reload your page). To avoid this behavior, launch your application with `-Dvertx.disableFileCaching=true`. With this setting, Vert.x still uses the cache, but always refresh the version stored in the cache with the original source. So if you edit a file served from the classpath and refresh your browser, Vert.x reads it from the classpath, copies it to the cache directory and serves it from there. Do not use this setting in production, it can kill your performances.

Finally, you can disable completely the cache by using `-Dvertx.disableFileCPResolving=true`. This setting is not without consequences. Vert.x would be unable to read any files from the classpath (only from the file system). Be very careful when using this settings.

  [FAQ](/docs/faq/)[Vert.x io\_uring](/docs/vertx-io_uring-incubator/java/)On this page

* [In the beginning there was Vert.x](#_in_the_beginning_there_was_vert_x)

+ [Specifying options when creating a Vertx object](#_specifying_options_when_creating_a_vertx_object)
+ [Creating a clustered Vert.x object](#_creating_a_clustered_vert_x_object)

* [Are you fluent?](#_are_you_fluent)
* [Don’t call us, we’ll call you.](#_dont_call_us_well_call_you)
* [Don’t block me!](#_dont_block_me)
* [Reactor and Multi-Reactor](#_reactor_and_multi_reactor)
* [The Golden Rule - Don’t Block the Event Loop](#golden_rule)
* [Future results](#_future_results)
* [Future composition](#_future_composition)
* [Future coordination](#_future_coordination)

+ [CompletionStage interoperability](#_completionstage_interoperability)

* [Verticles](#_verticles)

+ [Writing Verticles](#_writing_verticles)
+ [Asynchronous Verticle start and stop](#_asynchronous_verticle_start_and_stop)
+ [Verticle Types](#_verticle_types)
+ [Standard verticles](#_standard_verticles)
+ [Worker verticles](#worker_verticles)
+ [Virtual thread verticles](#_virtual_thread_verticles)
+ [Deploying verticles programmatically](#_deploying_verticles_programmatically)
+ [Rules for mapping a verticle name to a verticle factory](#_rules_for_mapping_a_verticle_name_to_a_verticle_factory)
+ [How are Verticle Factories located?](#_how_are_verticle_factories_located)
+ [Waiting for deployment to complete](#_waiting_for_deployment_to_complete)
+ [Undeploying verticle deployments](#_undeploying_verticle_deployments)
+ [Specifying number of verticle instances](#_specifying_number_of_verticle_instances)
+ [Passing configuration to a verticle](#_passing_configuration_to_a_verticle)
+ [Accessing environment variables in a Verticle](#_accessing_environment_variables_in_a_verticle)
+ [High Availability](#_high_availability)
+ [Running Verticles from the command line](#_running_verticles_from_the_command_line)
+ [Causing Vert.x to exit](#_causing_vert_x_to_exit)
+ [The Context object](#_the_context_object)
+ [Executing periodic and delayed actions](#_executing_periodic_and_delayed_actions)
+ [Verticle worker pool](#_verticle_worker_pool)

* [The Event Bus](#event_bus)

+ [The Theory](#_the_theory)
+ [The Event Bus API](#_the_event_bus_api)
+ [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles_2)

* [Configuring the event bus](#_configuring_the_event_bus)
* [JSON](#_json)

+ [JSON objects](#_json_objects)
+ [JSON arrays](#_json_arrays)

* [Json Pointers](#_json_pointers)
* [Buffers](#_buffers)

+ [Creating buffers](#_creating_buffers)
+ [Writing to a Buffer](#_writing_to_a_buffer)
+ [Reading from a Buffer](#_reading_from_a_buffer)
+ [Working with unsigned numbers](#_working_with_unsigned_numbers)
+ [Buffer length](#_buffer_length)
+ [Copying buffers](#_copying_buffers)
+ [Slicing buffers](#_slicing_buffers)
+ [Buffer re-use](#_buffer_re_use)

* [Writing TCP servers and clients](#_writing_tcp_servers_and_clients)

+ [Creating a TCP server](#_creating_a_tcp_server)
+ [Configuring a TCP server](#_configuring_a_tcp_server)
+ [Start the Server Listening](#_start_the_server_listening)
+ [Listening on a random port](#_listening_on_a_random_port)
+ [Getting notified of incoming connections](#_getting_notified_of_incoming_connections)
+ [Reading data from the socket](#_reading_data_from_the_socket)
+ [Writing data to a socket](#_writing_data_to_a_socket)
+ [Closed handler](#_closed_handler)
+ [Handling exceptions](#_handling_exceptions)
+ [Event bus write handler](#_event_bus_write_handler)
+ [Local and remote addresses](#_local_and_remote_addresses)
+ [Sending files or resources from the classpath](#_sending_files_or_resources_from_the_classpath)
+ [Streaming sockets](#_streaming_sockets)
+ [Upgrading connections to SSL/TLS](#_upgrading_connections_to_ssltls)
+ [Closing a TCP Server](#_closing_a_tcp_server)
+ [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles_3)
+ [Scaling - sharing TCP servers](#_scaling_sharing_tcp_servers)
+ [Creating a TCP client](#_creating_a_tcp_client)
+ [Configuring a TCP client](#_configuring_a_tcp_client)
+ [Making connections](#_making_connections)
+ [Configuring connection attempts](#_configuring_connection_attempts)
+ [Logging network activity](#logging_network_activity)
+ [Throttling inbound and outbound bandwidth of TCP connections](#_throttling_inbound_and_outbound_bandwidth_of_tcp_connections)
+ [Configuring servers and clients to work with SSL/TLS](#ssl)
+ [Using a proxy for client connections](#_using_a_proxy_for_client_connections)
+ [Using HA PROXY protocol](#_using_ha_proxy_protocol)

* [Writing HTTP servers and clients](#_writing_http_servers_and_clients)

+ [Creating an HTTP Server](#_creating_an_http_server)
+ [Configuring an HTTP server](#_configuring_an_http_server)
+ [Configuring an HTTP/2 server](#_configuring_an_http2_server)
+ [Configuring server supported HTTP versions](#_configuring_server_supported_http_versions)
+ [Logging network server activity](#_logging_network_server_activity)
+ [Start the Server Listening](#_start_the_server_listening_2)
+ [Getting notified of incoming requests](#_getting_notified_of_incoming_requests)
+ [Handling requests](#_handling_requests)
+ [Sending back responses](#_sending_back_responses)
+ [HTTP Compression](#_http_compression)
+ [HTTP compression algorithms](#_http_compression_algorithms)
+ [Creating an HTTP client](#_creating_an_http_client)
+ [Pool configuration](#_pool_configuration)
+ [Logging network client activity](#_logging_network_client_activity)
+ [Advanced HTTP client creation](#_advanced_http_client_creation)
+ [Making requests](#_making_requests)
+ [HTTP/2 RST flood protection](#_http2_rst_flood_protection)
+ [Handling HTTP responses](#_handling_http_responses)
+ [Enabling compression on the client](#_enabling_compression_on_the_client)
+ [HTTP/1.x pooling and keep alive](#_http1_x_pooling_and_keep_alive)
+ [HTTP/1.1 pipe-lining](#_http1_1_pipe_lining)
+ [HTTP/2 multiplexing](#_http2_multiplexing)
+ [HTTP connections](#_http_connections)
+ [Client sharing](#_client_sharing)
+ [Server sharing](#_server_sharing)
+ [Using HTTPS with Vert.x](#_using_https_with_vert_x)
+ [WebSockets](#_websockets)
+ [Using a proxy for HTTP/HTTPS connections](#_using_a_proxy_for_httphttps_connections)
+ [Using HA PROXY protocol](#_using_ha_proxy_protocol_2)
+ [Automatic clean-up in verticles](#_automatic_clean_up_in_verticles_4)

* [Using the SharedData API](#_using_the_shareddata_api)

+ [Local maps](#_local_maps)
+ [Asynchronous shared maps](#_asynchronous_shared_maps)
+ [Asynchronous locks](#_asynchronous_locks)
+ [Asynchronous counters](#_asynchronous_counters)

* [Using the file system with Vert.x](#_using_the_file_system_with_vert_x)

+ [Asynchronous files](#_asynchronous_files)

* [Datagram sockets (UDP)](#_datagram_sockets_udp)

+ [Creating a DatagramSocket](#_creating_a_datagramsocket)
+ [Sending Datagram packets](#_sending_datagram_packets)
+ [Receiving Datagram packets](#_receiving_datagram_packets)
+ [Multicast](#_multicast)

* [DNS client](#_dns_client)

+ [lookup](#_lookup)
+ [lookup4](#_lookup4)
+ [lookup6](#_lookup6)
+ [resolveA](#_resolvea)
+ [resolveAAAA](#_resolveaaaa)
+ [resolveCNAME](#_resolvecname)
+ [resolveMX](#_resolvemx)
+ [resolveTXT](#_resolvetxt)
+ [resolveNS](#_resolvens)
+ [resolveSRV](#_resolvesrv)
+ [resolvePTR](#_resolveptr)
+ [reverseLookup](#_reverselookup)
+ [Error handling](#_error_handling)

* [Vert.x Virtual Threads](#virtual_threads)

+ [Introduction](#_introduction)
+ [Using virtual threads](#_using_virtual_threads)

* [Streams](#streams)

+ [ReadStream](#_readstream)
+ [WriteStream](#_writestream)
+ [Reducing streams](#_reducing_streams)

* [Record Parser](#_record_parser)
* [Json Parser](#_json_parser)
* [Thread safety](#_thread_safety)
* [Running blocking code](#blocking_code)
* [Vert.x SPI](#_vert_x_spi)

+ [Metrics and tracing SPI](#_metrics_and_tracing_spi)
+ [Cluster Manager SPI](#cluster_manager_spi)
+ [Programmatic SPI selection and configuration](#_programmatic_spi_selection_and_configuration)

* [The 'vertx' command line](#_the_vertx_command_line)

+ [Run verticles](#_run_verticles)
+ [Executing a Vert.x application packaged as a fat jar](#_executing_a_vert_x_application_packaged_as_a_fat_jar)
+ [Displaying version of Vert.x](#_displaying_version_of_vert_x)
+ [Other commands](#_other_commands)
+ [Live Redeploy](#_live_redeploy)

* [Cluster Managers](#_cluster_managers)
* [Logging](#_logging)

+ [Configuring with the system property](#_configuring_with_the_system_property)
+ [Automatic configuration](#_automatic_configuration)
+ [Configuring JUL logging](#_configuring_jul_logging)
+ [Netty logging](#netty-logging)
+ [Troubleshooting](#_troubleshooting)

* [Host name resolution](#_host_name_resolution)

+ [Failover](#_failover)
+ [Server list rotation](#_server_list_rotation)
+ [Hosts mapping](#_hosts_mapping)
+ [Search domains](#_search_domains)
+ [MacOS configuration](#_macos_configuration)

* [High Availability and Fail-Over](#_high_availability_and_fail_over)

+ [Automatic failover](#_automatic_failover)
+ [HA groups](#_ha_groups)
+ [Dealing with network partitions - Quorum](#_dealing_with_network_partitions_quorum)

* [Native transports](#_native_transports)

+ [Native Linux Transport](#_native_linux_transport)
+ [Native BSD Transport](#_native_bsd_transport)
+ [Domain sockets](#_domain_sockets)

* [Security notes](#_security_notes)

+ [Web applications](#_web_applications)
+ [Clustered event bus traffic](#_clustered_event_bus_traffic)
+ [Standard security best practices](#_standard_security_best_practices)

* [Vert.x Command Line Interface API](#_vert_x_command_line_interface_api)

+ [Definition Stage](#_definition_stage)
+ [Parsing Stage](#_parsing_stage)
+ [Query / Interrogation Stage](#query_interrogation_stage)
+ [Typed options and arguments](#_typed_options_and_arguments)
+ [Using annotations](#_using_annotations)

* [The vert.x Launcher](#_the_vert_x_launcher)

+ [Extending the vert.x Launcher](#_extending_the_vert_x_launcher)
+ [Using the Launcher in fat jars](#_using_the_launcher_in_fat_jars)
+ [Sub-classing the Launcher](#_sub_classing_the_launcher)
+ [Launcher and exit code](#_launcher_and_exit_code)

* [Configuring Vert.x cache](#_configuring_vert_x_cache)

[Edit this page on GitHub](https://github.com/eclipse-vertx/vert.x/tree/master/vertx-core/src/main/asciidoc) [![Vert.x Logo](data:image/svg+xml...)![Vert.x Logo](data:image/svg+xml...)](/)
##### Eclipse Vert.x

* [Docs](/docs/)
* [How-tos](/docs/howtos/http-client-howto/)
* [Guides](/docs/guides/vertx-5-migration-guide/)
* [Blog](/blog/)
* [Community](/community/)
##### Resources

* [Download](/download/)
* [Channels](/resources/#channels)
* [GitHub](https://github.com/eclipse-vertx/vert.x)
* [App Generator](https://start.vertx.io/)
* [security.txt](/.well-known/security.txt)
##### Eclipse

* [Eclipse Foundation](https://www.eclipse.org/)
* [Privacy Policy](https://www.eclipse.org/legal/privacy.php)
* [Terms of Use](https://www.eclipse.org/legal/termsofuse.php)
* [Copyright Agent](https://www.eclipse.org/legal/copyright.php)
* [Legal Resources](https://www.eclipse.org/legal/)
### Eclipse Vert.x

### Resources

### Eclipse

© 2025 Eclipse Vert.x™
Eclipse Vert.x™ is open source and dual-licensed under the [Eclipse Public License 2.0](https://www.eclipse.org/legal/epl-2.0/) and the [Apache License 2.0](https://www.apache.org/licenses/LICENSE-2.0.html).
Website design by [Michel Krämer](https://michelkraemer.com).[![Eclipse foundation Logo](data:image/svg+xml...)![Eclipse foundation Logo](data:image/svg+xml...)](https://www.eclipse.org/)

=== Content from access.redhat.com_ebef4938_20250110_143644.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:2088 - Security Advisory

Issued:
2024-04-29
Updated:
2024-04-29
# RHSA-2024:2088 - Security Advisory

* [Overview](#overview)
* [Updated Images](#containers)

## Synopsis

Important: Red Hat build of Cryostat security update

## Type/Severity

Security Advisory: Important

## Topic

An update is now available for the Red Hat build of Cryostat 2 on RHEL 8.

Red Hat Product Security has rated this update as having a security impact of Important. A Common Vulnerability Scoring System (CVSS) base score, which gives a detailed severity rating, is available for each vulnerability from the CVE link(s) in the References section.

## Description

An update is now available for the Red Hat build of Cryostat 2 on RHEL 8.

Security Fix(es):

* vert.x: io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx (CVE-2024-1023)
* vertx-core: io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support (CVE-2024-1300)
* golang: net/[http:](http://) memory exhaustion in Request.ParseMultipartForm (CVE-2023-45290)
* golang: crypto/x509: Verify panics on certificates with an unknown public key algorithm (CVE-2024-24783)
* golang: net/http, x/net/http2: unlimited number of CONTINUATION frames causes DoS (CVE-2023-45288)
* netty-codec-[http:](http://) Allocation of Resources Without Limits or Throttling (CVE-2024-29025)

For more details about the security issue(s), including the impact, a CVSS score, acknowledgments, and other related information, refer to the CVE page(s) listed in the References section.

## Solution

Before applying this update, make sure all previously released errata relevant to your system have been applied.

For details on how to apply this update, refer to:

<https://access.redhat.com/articles/11258>

## Affected Products

* Cryostat 2 x86\_64

## Fixes

* [BZ - 2260840](https://bugzilla.redhat.com/show_bug.cgi?id=2260840)
  - CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx
* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2268017](https://bugzilla.redhat.com/show_bug.cgi?id=2268017)
  - CVE-2023-45290 golang: net/http: memory exhaustion in Request.ParseMultipartForm
* [BZ - 2268019](https://bugzilla.redhat.com/show_bug.cgi?id=2268019)
  - CVE-2024-24783 golang: crypto/x509: Verify panics on certificates with an unknown public key algorithm
* [BZ - 2268273](https://bugzilla.redhat.com/show_bug.cgi?id=2268273)
  - CVE-2023-45288 golang: net/http, x/net/http2: unlimited number of CONTINUATION frames causes DoS
* [BZ - 2272907](https://bugzilla.redhat.com/show_bug.cgi?id=2272907)
  - CVE-2024-29025 netty-codec-http: Allocation of Resources Without Limits or Throttling

## CVEs

* [CVE-2021-35937](https://access.redhat.com/security/cve/CVE-2021-35937)
* [CVE-2021-35938](https://access.redhat.com/security/cve/CVE-2021-35938)
* [CVE-2021-35939](https://access.redhat.com/security/cve/CVE-2021-35939)
* [CVE-2021-43618](https://access.redhat.com/security/cve/CVE-2021-43618)
* [CVE-2023-6135](https://access.redhat.com/security/cve/CVE-2023-6135)
* [CVE-2023-28322](https://access.redhat.com/security/cve/CVE-2023-28322)
* [CVE-2023-38546](https://access.redhat.com/security/cve/CVE-2023-38546)
* [CVE-2023-45288](https://access.redhat.com/security/cve/CVE-2023-45288)
* [CVE-2023-45290](https://access.redhat.com/security/cve/CVE-2023-45290)
* [CVE-2023-46218](https://access.redhat.com/security/cve/CVE-2023-46218)
* [CVE-2023-48795](https://access.redhat.com/security/cve/CVE-2023-48795)
* [CVE-2023-52425](https://access.redhat.com/security/cve/CVE-2023-52425)
* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-1394](https://access.redhat.com/security/cve/CVE-2024-1394)
* [CVE-2024-21011](https://access.redhat.com/security/cve/CVE-2024-21011)
* [CVE-2024-21012](https://access.redhat.com/security/cve/CVE-2024-21012)
* [CVE-2024-21068](https://access.redhat.com/security/cve/CVE-2024-21068)
* [CVE-2024-21094](https://access.redhat.com/security/cve/CVE-2024-21094)
* [CVE-2024-24783](https://access.redhat.com/security/cve/CVE-2024-24783)
* [CVE-2024-28834](https://access.redhat.com/security/cve/CVE-2024-28834)
* [CVE-2024-29025](https://access.redhat.com/security/cve/CVE-2024-29025)

## References

* <https://access.redhat.com/security/updates/classification/#important>

## aarch64

| cryostat-tech-preview/cryostat-grafana-dashboard-rhel8@sha256:c6f6accf2843a8d682184c4856ed4a33718598ac93f408a6ae176499afebb98c |
| --- |
| cryostat-tech-preview/cryostat-operator-bundle@sha256:a737d333ff2270d1c4c5cdee31395840118f8845f1721215a0ed3339d6c0bfc7 |
| cryostat-tech-preview/cryostat-reports-rhel8@sha256:59d2392e2a211b2abfe7d7f077037a3b7d6a5a6300c993d8dd11ab6a833cdaed |
| cryostat-tech-preview/cryostat-rhel8@sha256:d8b2fe76c91ac7bfc781cb4b73289dfe88f3add9a9e3d2f452c9e1034d83a2c8 |
| cryostat-tech-preview/cryostat-rhel8-operator@sha256:ecbc8c12eb93ba51d9f20bc53f6d83b730e0fd3a48facc3331daa34bd38fefdf |
| cryostat-tech-preview/jfr-datasource-rhel8@sha256:9b0de728776daa581545cce4c7ffac8ee35374b65968125dea89f5e896a958a7 |

## x86\_64

| cryostat-tech-preview/cryostat-grafana-dashboard-rhel8@sha256:ce37e72beb00a9eb2653cf6c248abf4d569cf3a708f83a67a0d4639f4893b31e |
| --- |
| cryostat-tech-preview/cryostat-operator-bundle@sha256:818f32bf078b473ea3d3e414134d55b196333b179db54371c7a283e20ae720be |
| cryostat-tech-preview/cryostat-reports-rhel8@sha256:007cd4be45dbe9627b80ae749b78b751fe9846da0659f2a4f73e801a7207c663 |
| cryostat-tech-preview/cryostat-rhel8@sha256:99dab409d9e80a951f39c80f3429fa34ab1ed99f68d41f15fedf63cb33eb5c29 |
| cryostat-tech-preview/cryostat-rhel8-operator@sha256:734054cf4f9b68b186ae2024caf7401321c14c63a70188f771617cc3ae83dc64 |
| cryostat-tech-preview/jfr-datasource-rhel8@sha256:f28d25a215222f8d1e19b59ea479dc22b71380cd8c3ffa99ae562727fbb1b487 |

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)



=== Content from bugzilla.redhat.com_cbaf7b04_20250110_143646.html ===


* Login
  + Log in using an SSO provider:- [Fedora Account System](saml2_login.cgi?idp=Fedora%20Account%20System&target=show_bug.cgi%3Fid%3D2263139)
    - [Red Hat Associate](saml2_login.cgi?idp=Red%20Hat%20Associate&target=show_bug.cgi%3Fid%3D2263139)
    - [Red Hat Customer](saml2_login.cgi?idp=Red%20Hat%20Customer&target=show_bug.cgi%3Fid%3D2263139)+ Login using a Red Hat Bugzilla account
  + Forgot Password
  + [Create an Account](createaccount.cgi)

Red Hat Bugzilla – Bug 2263139

* [Home](./)
* [New](enter_bug.cgi)
* Search
  + [Simple Search](query.cgi?format=specific)
  + [Advanced Search](query.cgi?format=advanced)
* My Links
  + [Browse](describecomponents.cgi)
  + [Requests](request.cgi)
  + Reports
  + Current State
    - [Search](query.cgi)
    - [Tabular reports](query.cgi?format=report-table)
    - [Graphical reports](query.cgi?format=report-graph)
    - [Duplicates](duplicates.cgi)
  + Other Reports
    - [User Changes](https://bugzilla.redhat.com/page.cgi?id=user_activity.html)
  + Plotly Reports
    - [Bug Status](https://bugzilla.redhat.com/page.cgi?id=bug_status.html)
    - [Bug Severity](https://bugzilla.redhat.com/page.cgi?id=bug_severity.html)
    - [Non-Defaults](https://bugzilla.redhat.com/page.cgi?id=non_defaults.html)
* [Product Dashboard](page.cgi?id=productdashboard.html)

- Help
  * [Page Help!](docs/en/html/using/understanding.html)
  * [Bug Writing Guidelines](page.cgi?id=bug-writing.html)
  * [What's new](page.cgi?id=whats-new.html)
  * [Browser Support Policy](https://access.redhat.com/help/browsers)
  * [5.0.4.rh103 Release notes](page.cgi?id=release-notes.html)
  * [FAQ](page.cgi?id=faq.html)
  * [Guides index](docs/en/html/index.html)
  * [User guide](docs/en/html/using/index.html)
  * [Web Services](docs/en/html/integrating/api/Bugzilla/WebService/Bug.html)
  * [Contact](page.cgi?id=redhat/contact.html)
  * [Legal](page.cgi?id=terms-conditions.html)
- [[?]](page.cgi?id=quicksearch.html "Quicksearch Help")

This site requires JavaScript to be enabled to function correctly, please enable it.

[**Bug 2263139**](show_bug.cgi?id=2263139)
(CVE-2024-1300)
- [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300) io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support

[Summary:](page.cgi?id=fields.html#short_desc "The bug summary is a short sentence which succinctly describes what the bug is about.")
CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configure...

| | [Keywords](describekeywords.cgi): | Security | | --- | --- | | [Status](page.cgi?id=fields.html#bug_status): | NEW | | [Alias:](page.cgi?id=fields.html#alias "A short, unique name assigned to a bug in order to assist with looking it up and referring to it in other places in Bugzilla.") | CVE-2024-1300 | | [Product:](describecomponents.cgi "Bugs are categorised into Products and Components. Select a Classification to narrow down this list.") | Security Response | | [Classification:](page.cgi?id=fields.html#classification "Bugs are categorised into Classifications, Products and Components. classifications is the top-level categorisation.") | Other | | [Component:](describecomponents.cgi?product=Security Response "Components are second-level categories; each belongs to a particular Product. Select a Product to narrow down this list.") | vulnerability | | [Sub Component:](page.cgi?id=fields.html#rh_sub_components "The sub component of a specific component") | --- | | [Version:](page.cgi?id=fields.html#version "The version field defines the version of the software the bug was found in.") | unspecified | | [Hardware:](page.cgi?id=fields.html#rep_platform "The hardware platform the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | All | | [OS:](page.cgi?id=fields.html#op_sys "The operating system the bug was observed on. Note: When searching, selecting the option \"All\" only finds bugs whose value for this field is literally the word \"All\".") | Linux | | [Priority:](page.cgi?id=fields.html#priority) | medium | | [Severity:](page.cgi?id=fields.html#bug_severity) | medium | | [Target Milestone:](page.cgi?id=fields.html#target_milestone "The Target Milestone field is used to define when the engineer the bug is assigned to expects to fix it.") | --- | | [Assignee:](page.cgi?id=fields.html#assigned_to "The person in charge of resolving the bug.") | Product Security | | [QA Contact:](page.cgi?id=fields.html#qa_contact "The person responsible for confirming this bug if it is unconfirmed, and for verifying the fix once the bug has been resolved.") |  | | [Docs Contact:](page.cgi?id=fields.html#docs_contact "The person responsible for documenting once the bug has been resolved.") |  | | [URL:](page.cgi?id=fields.html#bug_file_loc "Bugs can have a URL associated with them - for example, a pointer to a web site where the problem is seen.") |  | | [Whiteboard:](page.cgi?id=fields.html#status_whiteboard "Each bug has a free-form single line text entry box for adding tags and status information.") |  | | [Depends On:](page.cgi?id=fields.html#dependson "The bugs listed here must be resolved before this bug can be resolved.") |  | | [Blocks:](page.cgi?id=fields.html#blocked "This bug must be resolved before the bugs listed in this field can be resolved.") | [2263142](show_bug.cgi?id=2263142) | | TreeView+ | [depends on](buglist.cgi?bug_id=2263139&bug_id_type=anddependson&format=tvp) / [blocked](buglist.cgi?bug_id=2263139&bug_id_type=andblocked&format=tvp&tvp_dir=blocked) |  | |  | | [Reported:](page.cgi?id=fields.html#reporter) | 2024-02-07 07:18 UTC by TEJ RATHI | | --- | --- | | [Modified:](page.cgi?id=fields.html#modified) | 2024-11-19 20:06 UTC ([History](show_activity.cgi?id=2263139)) | | [CC List:](page.cgi?id=fields.html#cclist) | 103 users (show)  aazores adupliak aileenc anstephe asoldano ataylor avibelli bbaranow bgeorges bmaxwell boliveir brian.stansberry cdewolf chazlett chfoley clement.escoffier cmah cmiranda dandread darran.lofthouse dhanak dkreling dosoudil dpalmer drichtar dsimansk eaguilar ebaron ecerquei eric.wittmann fjuma fmariani fmongiar gmalinko gsmet hbraun ibek istudens ivassile iweiss janstey jkang jkoops jmartisk jnethert jolong jpallich jpoth jrokos jross jscholz kingland kverlaen lgao lthon manderse matzew max.andersen mnovotny mosmerov msochure mstefank msvehla mulliken nipatil nwallace olubyans pantinor pcongius pdelbell pdrozd peholase pgallagh pierdipi pjindal pmackay porcelli probinso pskopek rguimara rhuss rjohnson rkieley rkubis rmartinc rowaters rruss rstancel rstepani rsvoboda saroy sausingh sbiarozk sdouglas sfroberg skontopo smaestri sthorger swoodman tcunning tom.jenkinson tqvarnst yfang | | Fixed In Version: |  | | | Doc Type: | If docs needed, set a value | | | Doc Text: | A vulnerability in the Eclipse Vert.x toolkit causes a memory leak in TCP servers configured with TLS and SNI support. When processing an unknown SNI server name assigned the default certificate instead of a mapped certificate, the SSL context is erroneously cached in the server name map, leading to memory exhaustion. This flaw allows attackers to send TLS client hello messages with fake server names, triggering a JVM out-of-memory error. | | | Clone Of: |  | | | Environment: |  | | | Last Closed: |  | | | Embargoed: |  | | |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |
| --- | | |

| | Attachments | [(Terms of Use)](page.cgi?id=terms-conditions.html) | | | --- | --- | --- | |  | | |    Links | System | ID | Private | Priority | Status | Summary | Last Updated | | Red Hat Product Errata | [RHSA-2024:1662](https://access.redhat.com/errata/RHSA-2024%3A1662) | 0 | None | None | None | 2024-04-03 10:53:12 UTC | | Red Hat Product Errata | [RHSA-2024:1923](https://access.redhat.com/errata/RHSA-2024%3A1923) | 0 | None | None | None | 2024-04-18 11:43:26 UTC | | Red Hat Product Errata | [RHSA-2024:2088](https://access.redhat.com/errata/RHSA-2024%3A2088) | 0 | None | None | None | 2024-04-29 02:26:55 UTC | | Red Hat Product Errata | [RHSA-2024:2833](https://access.redhat.com/errata/RHSA-2024%3A2833) | 0 | None | None | None | 2024-05-14 09:08:16 UTC | | Red Hat Product Errata | [RHSA-2024:3527](https://access.redhat.com/errata/RHSA-2024%3A3527) | 0 | None | None | None | 2024-05-30 20:25:49 UTC | | Red Hat Product Errata | [RHSA-2024:3989](https://access.redhat.com/errata/RHSA-2024%3A3989) | 0 | None | None | None | 2024-06-20 00:36:14 UTC | | Red Hat Product Errata | [RHSA-2024:4884](https://access.redhat.com/errata/RHSA-2024%3A4884) | 0 | None | None | None | 2024-07-25 19:26:18 UTC | |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- | --- |

| [Description](show_bug.cgi?id=2263139#c0)  TEJ RATHI    2024-02-07 07:18:17 UTC  ``` Since Vert.x 4.3.4 that leads to a memory leak when a TCP server is configured with TLS and SNI support: when such server processes an unknown SNI server name, that is a server name that would be assigned the default certificate instead of a server name mapped certificate, the SSL context will be cached in the server name map. This map should only contain server names for which the configuration provides a valid certificate. As a consequence, this can be exploited by client sending TLS client hello message with the server name extension indicating spurious server names and eventually trigger a JVM out of memory error.   This affects only TLS servers with SNI enabled <https://vertx.io/docs/vertx-core/java/#_server_name_indication_sni>.  It affects the maven artifact io.vertx:vertx-core versions 4.3.4,4.3.5,4.3.6,4.3.7,4.3.8,4.4.0,4.4.1,4.4.2,4.4.3,4.4.4,4.4.5,4.4.6,4.4.7,4.5.0,4.5.1,4.5.2  <https://github.com/eclipse-vertx/vert.x/pull/5101> [Master] <https://github.com/eclipse-vertx/vert.x/pull/5100> [4.x] <https://github.com/eclipse-vertx/vert.x/pull/5099> [4.3]   ```  [Comment 9](show_bug.cgi?id=2263139#c9)  errata-xmlrpc    2024-04-03 10:53:09 UTC  ``` This issue has been addressed in the following products:    Red Hat build of Quarkus 3.2.11  Via RHSA-2024:1662 [https://access.redhat.com/errata/RHSA-2024:1662](https://access.redhat.com/errata/RHSA-2024%3A1662)   ```  [Comment 11](show_bug.cgi?id=2263139#c11)  errata-xmlrpc    2024-04-18 11:43:21 UTC  ``` This issue has been addressed in the following products:    Migration Toolkit for Runtimes 1 on RHEL 8  Via RHSA-2024:1923 [https://access.redhat.com/errata/RHSA-2024:1923](https://access.redhat.com/errata/RHSA-2024%3A1923)   ```  [Comment 12](show_bug.cgi?id=2263139#c12)  errata-xmlrpc    2024-04-29 02:26:52 UTC  ``` This issue has been addressed in the following products:    Cryostat 2 on RHEL 8  Via RHSA-2024:2088 [https://access.redhat.com/errata/RHSA-2024:2088](https://access.redhat.com/errata/RHSA-2024%3A2088)   ```  [Comment 15](show_bug.cgi?id=2263139#c15)  errata-xmlrpc    2024-05-14 09:08:12 UTC  ``` This issue has been addressed in the following products:    RHINT Service Registry 2.5.11 GA  Via RHSA-2024:2833 [https://access.redhat.com/errata/RHSA-2024:2833](https://access.redhat.com/errata/RHSA-2024%3A2833)   ```  [Comment 18](show_bug.cgi?id=2263139#c18)  errata-xmlrpc    2024-05-30 20:25:43 UTC  ``` This issue has been addressed in the following products:    Red Hat AMQ Streams 2.7.0  Via RHSA-2024:3527 [https://access.redhat.com/errata/RHSA-2024:3527](https://access.redhat.com/errata/RHSA-2024%3A3527)   ```  [Comment 19](show_bug.cgi?id=2263139#c19)  errata-xmlrpc    2024-06-20 00:36:08 UTC  ``` This issue has been addressed in the following products:    MTA-6.2-RHEL-9   MTA-6.2-RHEL-8  Via RHSA-2024:3989 [https://access.redhat.com/errata/RHSA-2024:3989](https://access.redhat.com/errata/RHSA-2024%3A3989)   ```  [Comment 21](show_bug.cgi?id=2263139#c21)  errata-xmlrpc    2024-07-25 19:26:13 UTC  ``` This issue has been addressed in the following products:    Red Hat build of Apache Camel 4.4.1 for Spring Boot  Via RHSA-2024:4884 [https://access.redhat.com/errata/RHSA-2024:4884](https://access.redhat.com/errata/RHSA-2024%3A4884)   ``` |  |
| --- | --- |

---

| Note You need to [log in](show_bug.cgi?id=2263139&GoAheadAndLogIn=1) before you can comment on or make changes to this bug. |
| --- |

---

[Privacy](page.cgi?id=redhat/privacy.html)
[Contact](page.cgi?id=redhat/contact.html)
[FAQ](page.cgi?id=faq.html)
[Legal](page.cgi?id=terms-conditions.html)



=== Content from access.redhat.com_906cf442_20250110_143643.html ===

Note: Our personalized web services require that your browser be enabled for JavaScript and cookies

[Skip to navigation](#pfe-navigation)
[Skip to main content](#cp-main)
### Utilities

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)

[![Red Hat Customer Portal](https://access.redhat.com/chrome_themes/nimbus/img/red-hat-customer-portal.svg)](https://access.redhat.com/)

* [Subscriptions](https://access.redhat.com/management/)
* [Downloads](https://access.redhat.com/downloads/)
* [Red Hat Console](//console.redhat.com/)
* [Get Support](https://access.redhat.com/support/)
* [Products](https://access.redhat.com/)
  ### Top Products

  + [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
  + [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
  + [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
  [All Products](https://access.redhat.com/products/)

  ### Downloads and Containers

  + [Downloads](https://access.redhat.com/downloads/)
  + [Packages](https://access.redhat.com/downloads/content/package-browser)
  + [Containers](https://catalog.redhat.com/software/containers/explore/)
  ### Top Resources

  + [Documentation](//docs.redhat.com/)
  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Product Compliance](https://access.redhat.com/articles/1202803)
  + [Errata](https://access.redhat.com/errata/)
* [Knowledge](https://access.redhat.com/labs/)
  ### Red Hat Knowledge Center

  + [Knowledgebase Solutions](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Solution)
  + [Knowledgebase Articles](https://access.redhat.com/search/?q=*&p=1&rows=10&documentKind=Article)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Errata](https://access.redhat.com/errata/)
  ### Top Product Docs

  + [Red Hat Enterprise Linux](//docs.redhat.com/en/documentation/red_hat_enterprise_linux/)
  + [Red Hat OpenShift](//docs.redhat.com/en/documentation/openshift_container_platform/)
  + [Red Hat Ansible Automation Platform](//docs.redhat.com/en/documentation/red_hat_ansible_automation_platform/)
  [All Product Docs](//docs.redhat.com/en/products)

  ### [Training and Certification](//www.redhat.com/en/services/training-and-certification)

  + [About](//www.redhat.com/en/services/training-and-certification)
  + [Course Index](//www.redhat.com/en/services/training/all-courses-exams)
  + [Certification Index](//www.redhat.com/en/services/certifications)
  + [Skill Assessment](//skills.ole.redhat.com/)
* [Security](https://access.redhat.com/security/)
  ### [Red Hat Product Security Center](https://access.redhat.com/security)

  + [Security Updates](https://access.redhat.com/security)
  + [Security Advisories](https://access.redhat.com/security/security-updates/#/security-advisories)
  + [Red Hat CVE Database](https://access.redhat.com/security/security-updates/#/cve)
  + [Errata](https://access.redhat.com/errata/)
  ### References

  + [Security Bulletins](https://access.redhat.com/security/vulnerabilities)
  + [Security Measurement](https://www.redhat.com/security/data/metrics/)
  + [Severity Ratings](https://access.redhat.com/security/updates/classification/)
  + [Security Data](https://access.redhat.com/security/data)
  ### Top Resources

  + [Security Labs](https://access.redhat.com/security/security-updates/#/security-labs)
  + [Backporting Policies](https://access.redhat.com/security/updates/backporting/)
  + [Security Blog](//redhat.com/en/blog/channel/security)
* [Support](https://access.redhat.com/support/)
  ### [Red Hat Support](https://access.redhat.com/support/)

  + [Support Cases](https://access.redhat.com/support/cases/)
  + [Troubleshoot](https://access.redhat.com/support/cases/#/troubleshoot)
  + [Get Support](https://access.redhat.com/support/)
  + [Contact Red Hat Support](https://access.redhat.com/support/contact/)
  ### [Red Hat Community Support](https://access.redhat.com/community)

  + [Customer Portal Community](https://access.redhat.com/community/)
  + [Community Discussions](https://access.redhat.com/discussions/)
  + [Red Hat Accelerator Program](https://access.redhat.com/accelerators/)
  ### Top Resources

  + [Product Life Cycles](https://access.redhat.com/product-life-cycles/)
  + [Customer Portal Labs](https://access.redhat.com/labs/)
  + [Red Hat JBoss Supported Configurations](https://access.redhat.com/support/configurations/jboss)
  + [Red Hat Insights](https://cloud.redhat.com/insights)

Or [troubleshoot an issue](/support/cases/#/troubleshoot).

English

## Select Your Language

* [English](https://access.redhat.com/changeLanguage?language=en)
* [Français](https://access.redhat.com/changeLanguage?language=fr)
* [한국어](https://access.redhat.com/changeLanguage?language=ko)
* [日本語](https://access.redhat.com/changeLanguage?language=ja)
* [中文 (中国)](https://access.redhat.com/changeLanguage?language=zh_CN)

### Infrastructure and Management

* [Red Hat Enterprise Linux](https://access.redhat.com/products/red-hat-enterprise-linux/)
* [Red Hat Satellite](https://access.redhat.com/products/red-hat-satellite/)
* [Red Hat Subscription Management](https://access.redhat.com/products/red-hat-subscription-management/)
* [Red Hat Insights](https://access.redhat.com/products/red-hat-insights/)
* [Red Hat Ansible Automation Platform](https://access.redhat.com/products/red-hat-ansible-automation-platform/)
### Cloud Computing

* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform)
* [Red Hat OpenStack Platform](https://access.redhat.com/products/red-hat-openstack-platform/)
* [Red Hat OpenShift](https://access.redhat.com/products/red-hat-openshift-container-platform/)
* [Red Hat OpenShift AI](https://access.redhat.com/products/red-hat-openshift-ai/)
* [Red Hat OpenShift Dedicated](https://access.redhat.com/products/openshift-dedicated-red-hat/)
* [Red Hat Advanced Cluster Security for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-security-for-kubernetes/)
* [Red Hat Advanced Cluster Management for Kubernetes](https://access.redhat.com/products/red-hat-advanced-cluster-management-for-kubernetes/)
* [Red Hat Quay](https://access.redhat.com/products/red-hat-quay/)
* [Red Hat OpenShift Dev Spaces](https://access.redhat.com/products/red-hat-openshift-dev-spaces)
* [Red Hat OpenShift Service on AWS](https://access.redhat.com/products/red-hat-openshift-service-aws)
### Storage

* [Red Hat Gluster Storage](https://access.redhat.com/products/red-hat-storage/)
* [Red Hat Hyperconverged Infrastructure](https://access.redhat.com/products/red-hat-hyperconverged-infrastructure/)
* [Red Hat Ceph Storage](https://access.redhat.com/products/red-hat-ceph-storage/)
* [Red Hat OpenShift Data Foundation](https://access.redhat.com/products/red-hat-openshift-data-foundation)
### Runtimes

* [Red Hat Runtimes](https://access.redhat.com/products/red-hat-runtimes/)
* [Red Hat JBoss Enterprise Application Platform](https://access.redhat.com/products/red-hat-jboss-enterprise-application-platform/)
* [Red Hat Data Grid](https://access.redhat.com/products/red-hat-data-grid/)
* [Red Hat JBoss Web Server](https://access.redhat.com/products/red-hat-jboss-web-server/)
* [Red Hat build of Keycloak](https://access.redhat.com/products/red-hat-build-of-keycloak/)
* [Red Hat support for Spring Boot](https://access.redhat.com/products/spring-boot/)
* [Red Hat build of Node.js](https://access.redhat.com/products/nodejs/)
* [Red Hat build of Quarkus](https://access.redhat.com/products/quarkus/)
### Integration and Automation

* [Red Hat Application Foundations](https://access.redhat.com/products/red-hat-application-foundations/)
* [Red Hat Fuse](https://access.redhat.com/products/red-hat-fuse/)
* [Red Hat AMQ](https://access.redhat.com/products/red-hat-amq/)
* [Red Hat 3scale API Management](https://access.redhat.com/products/red-hat-3scale/)

[All Products](https://access.redhat.com/products/)

[Red Hat Product Errata](/errata)
RHSA-2024:1662 - Security Advisory

Issued:
2024-04-03
Updated:
2024-04-03
# RHSA-2024:1662 - Security Advisory

* [Overview](#overview)

## Synopsis

Important: Red Hat build of Quarkus 3.2.11 release and security update

## Type/Severity

Security Advisory: Important

## Topic

An update is now available for Red Hat build of Quarkus.

Red Hat Product Security has rated this update as having a security impact of
Important. A Common Vulnerability Scoring System (CVSS) base score, which gives
a
detailed severity rating, is available for each vulnerability. For more
information, see the CVE links in the References section.

## Description

This release of Red Hat build of Quarkus 3.2.11 includes security updates,
bug fixes, and enhancements. For more information, see the release notes page
listed in the References section.

Security Fix(es):

* CVE-2024-1597 org.postgresql/postgresql: pgjdbc: PostgreSQL JDBC Driver allows attacker to inject SQL if using PreferQueryMode=SIMPLE [quarkus-3.2]
* CVE-2024-1979 io.quarkus/quarkus-kubernetes-deployment: quarkus: information leak in annotation [quarkus-3.2]
* CVE-2024-1726 io.quarkus.resteasy.reactive/resteasy-reactive: quarkus: security checks for some inherited endpoints performed after serialization in RESTEasy Reactive may trigger a denial of service [quarkus-3.2]
* CVE-2024-25710 org.apache.commons/commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file [quarkus-3.2]
* CVE-2024-26308 org.apache.commons/commons-compress: OutOfMemoryError unpacking broken Pack200 file [quarkus-3.2]
* CVE-2024-1300 io.vertx/vertx-core: io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support [quarkus-3.2]
* CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx [quarkus-3.2]

## Solution

Before applying this update, make sure all previously released errata
relevant to your system have been applied.

For details on how to apply this update, refer to:

<https://access.redhat.com/articles/11258>

## Affected Products

* Red Hat build of Quarkus Text-Only Advisories x86\_64

## Fixes

* [BZ - 2260840](https://bugzilla.redhat.com/show_bug.cgi?id=2260840)
  - CVE-2024-1023 io.vertx/vertx-core: memory leak due to the use of Netty FastThreadLocal data structures in Vertx
* [BZ - 2263139](https://bugzilla.redhat.com/show_bug.cgi?id=2263139)
  - CVE-2024-1300 io.vertx:vertx-core: memory leak when a TCP server is configured with TLS and SNI support
* [BZ - 2264988](https://bugzilla.redhat.com/show_bug.cgi?id=2264988)
  - CVE-2024-25710 commons-compress: Denial of service caused by an infinite loop for a corrupted DUMP file
* [BZ - 2264989](https://bugzilla.redhat.com/show_bug.cgi?id=2264989)
  - CVE-2024-26308 commons-compress: OutOfMemoryError unpacking broken Pack200 file
* [BZ - 2265158](https://bugzilla.redhat.com/show_bug.cgi?id=2265158)
  - CVE-2024-1726 quarkus: security checks for some inherited endpoints performed after serialization in RESTEasy Reactive may trigger a denial of service
* [BZ - 2266523](https://bugzilla.redhat.com/show_bug.cgi?id=2266523)
  - CVE-2024-1597 pgjdbc: PostgreSQL JDBC Driver allows attacker to inject SQL if using PreferQueryMode=SIMPLE
* [BZ - 2266690](https://bugzilla.redhat.com/show_bug.cgi?id=2266690)
  - CVE-2024-1979 quarkus: information leak in annotation
* [QUARKUS-4022](https://issues.redhat.com/browse/QUARKUS-4022)
  - OpenTelemetry Scope not closed correctly
* [QUARKUS-4036](https://issues.redhat.com/browse/QUARKUS-4036)
  - Update smallrye-jwt to the latest version (4.4.0)
* [QUARKUS-4097](https://issues.redhat.com/browse/QUARKUS-4097)
  - Log when a RestEasy Reactive client close method is called
* [QUARKUS-4103](https://issues.redhat.com/browse/QUARKUS-4103)
  - Include RowSet properties file in native image
* [QUARKUS-4104](https://issues.redhat.com/browse/QUARKUS-4104)
  - Register JDBC RowSet required bundle
* [QUARKUS-4106](https://issues.redhat.com/browse/QUARKUS-4106)
  - Bump smallrye-jwt version to 4.4.0

## CVEs

* [CVE-2024-1023](https://access.redhat.com/security/cve/CVE-2024-1023)
* [CVE-2024-1300](https://access.redhat.com/security/cve/CVE-2024-1300)
* [CVE-2024-1597](https://access.redhat.com/security/cve/CVE-2024-1597)
* [CVE-2024-1726](https://access.redhat.com/security/cve/CVE-2024-1726)
* [CVE-2024-1979](https://access.redhat.com/security/cve/CVE-2024-1979)
* [CVE-2024-25710](https://access.redhat.com/security/cve/CVE-2024-25710)
* [CVE-2024-26308](https://access.redhat.com/security/cve/CVE-2024-26308)

## References

* <https://access.redhat.com/security/updates/classification/#important>
* <https://access.redhat.com/documentation/en-us/red_hat_build_of_quarkus/3.2/>
* <https://access.redhat.com/articles/4966181>

The Red Hat security contact is secalert@redhat.com.
More contact details at <https://access.redhat.com/security/team/contact/>.

[![Red Hat](https://static.redhat.com/libs/redhat/brand-assets/2/corp/logo--on-dark.svg)](https://redhat.com/en)
[X (formerly Twitter)](https://twitter.com/RedHat)
### Quick Links

* [Downloads](https://access.redhat.com/downloads/)
* [Subscriptions](https://access.redhat.com/management)
* [Support Cases](https://access.redhat.com/support)
* [Customer Service](https://access.redhat.com/support/customer-service)
* [Product Documentation](//docs.redhat.com/)

### Help

* [Contact Us](https://access.redhat.com/support/contact/)
* [Customer Portal FAQ](https://access.redhat.com/articles/33844)
* [Log-in Assistance](https://access.redhat.com/help/login_assistance)

### Site Info

* [Trust Red Hat](https://www.redhat.com/en/trust)
* [Browser Support Policy](https://www.redhat.com/en/about/browser-support)
* [Accessibility](https://www.redhat.com/en/about/digital-accessibility)
* [Awards and Recognition](https://access.redhat.com/recognition/)
* [Colophon](https://access.redhat.com/help/colophon/)

### Related Sites

* [redhat.com](https://www.redhat.com/)
* [developers.redhat.com](http://developers.redhat.com/)
* [connect.redhat.com](https://connect.redhat.com/)
* [cloud.redhat.com](https://cloud.redhat.com/)

### Red Hat legal and privacy links

* [About Red Hat](https://redhat.com/en/about/company)
* [Jobs](https://redhat.com/en/jobs)
* [Events](https://redhat.com/en/events)
* [Locations](https://redhat.com/en/about/office-locations)
* [Contact Red Hat](https://redhat.com/en/contact)
* [Red Hat Blog](https://redhat.com/en/blog)
* [Diversity, equity, and inclusion](https://redhat.com/en/about/our-culture/diversity-equity-inclusion)
* [Cool Stuff Store](https://coolstuff.redhat.com/)
* [Red Hat Summit](https://www.redhat.com/en/summit)

 © 2024 Red Hat, Inc.
### Red Hat legal and privacy links

* [Privacy statement](https://redhat.com/en/about/privacy-policy)
* [Terms of use](https://redhat.com/en/about/terms-use)
* [All policies and guidelines](https://redhat.com/en/about/all-policies-guidelines)
* [Digital accessibility](https://redhat.com/en/about/digital-accessibility)


