```json
{
  "vulnerability_details": {
    "root_cause": "The `load` function in the `ClusteringModel` class within `flair.models.clustering` does not perform sufficient security validation when loading model data files, allowing for command injection.",
    "weaknesses": [
      "Code injection vulnerability due to lack of input validation during model loading.",
       "Insecure deserialization of model data."
    ],
    "impact": "Arbitrary command execution can be achieved when a malicious model data file is loaded by the vulnerable application.",
    "attack_vectors": "The attacker crafts a malicious model data file, which when loaded using the `load` function in `flair.models.clustering.ClusteringModel`, triggers command execution on the server or machine running the application.",
    "attacker_capabilities": "The attacker needs to be able to provide/supply a maliciously crafted model file to the vulnerable function. This could be achieved by convincing a user to load a model, supplying a model via a malicious website, or any other method to get a model file loaded into the application."
  },
  "affected_product": {
    "name": "flairNLP flair",
    "version": "0.14.0"
  },
  "additional_notes": "The vulnerability exists in the `load` function on line 72 of `flair/models/clustering.py`. A proof of concept and malicious files are available in the provided github repository. The provided information is more descriptive than the CVE description placeholder."
}
```