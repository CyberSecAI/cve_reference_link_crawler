
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fsdca_internal.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  835](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
/
# sdca\_internal.cc

 Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/master/tensorflow/core/kernels/sdca_internal.cc)595 lines (550 loc) · 25.6 KB master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
/
# sdca\_internal.cc

Top
## File metadata and controls

* Code
* Blame

595 lines (550 loc) · 25.6 KB[Raw](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/kernels/sdca_internal.cc)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595/\* Copyright 2016 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#define EIGEN\_USE\_THREADS
#include "tensorflow/core/kernels/sdca\_internal.h"
#include <limits>#include <numeric>#include <random>
#include "unsupported/Eigen/CXX11/Tensor" // from @eigen\_archive#include "tensorflow/core/lib/gtl/flatset.h"#include "tensorflow/core/lib/math/math\_util.h"#include "tensorflow/core/lib/random/simple\_philox.h"
#if defined(TENSORFLOW\_USE\_CUSTOM\_CONTRACTION\_KERNEL)#include "xla/tsl/framework/contraction/eigen\_contraction\_kernel.h"#endif
namespace tensorflow {namespace sdca {
using UnalignedFloatVector = TTypes<const float>::UnalignedConstVec;using UnalignedInt64Vector = TTypes<const int64\_t>::UnalignedConstVec;
void FeatureWeightsDenseStorage::UpdateDenseDeltaWeights( const Eigen::ThreadPoolDevice& device, const Example::DenseVector& dense\_vector, const std::vector<double>& normalized\_bounded\_dual\_delta) { const size\_t num\_weight\_vectors = normalized\_bounded\_dual\_delta.size(); if (num\_weight\_vectors == 1) { deltas\_.device(device) = deltas\_ + dense\_vector.RowAsMatrix() \* deltas\_.constant(normalized\_bounded\_dual\_delta[0]); } else { // Transform the dual vector into a column matrix. const Eigen::TensorMap<Eigen::Tensor<const double, 2, Eigen::RowMajor>> dual\_matrix(normalized\_bounded\_dual\_delta.data(), num\_weight\_vectors, 1); const Eigen::array<Eigen::IndexPair<int>, 1> product\_dims = { Eigen::IndexPair<int>(1, 0)}; // This computes delta\_w += delta\_vector / \lamdba \* N. deltas\_.device(device) = (deltas\_.cast<double>() + dual\_matrix.contract(dense\_vector.RowAsMatrix().cast<double>(), product\_dims)) .cast<float>(); }}
void FeatureWeightsSparseStorage::UpdateSparseDeltaWeights( const Eigen::ThreadPoolDevice& device, const Example::SparseFeatures& sparse\_features, const std::vector<double>& normalized\_bounded\_dual\_delta) { for (int64\_t k = 0; k < sparse\_features.indices->size(); ++k) { const double feature\_value = sparse\_features.values == nullptr ? 1.0 : (\*sparse\_features.values)(k); auto it = indices\_to\_id\_.find((\*sparse\_features.indices)(k)); for (size\_t l = 0; l < normalized\_bounded\_dual\_delta.size(); ++l) { deltas\_(l, it->second) += feature\_value \* normalized\_bounded\_dual\_delta[l]; } }}
void ModelWeights::UpdateDeltaWeights( const Eigen::ThreadPoolDevice& device, const Example& example, const std::vector<double>& normalized\_bounded\_dual\_delta) { // Sparse weights. for (size\_t j = 0; j < sparse\_weights\_.size(); ++j) { sparse\_weights\_[j].UpdateSparseDeltaWeights( device, example.sparse\_features\_[j], normalized\_bounded\_dual\_delta); }
 // Dense weights. for (size\_t j = 0; j < dense\_weights\_.size(); ++j) { dense\_weights\_[j].UpdateDenseDeltaWeights( device, \*example.dense\_vectors\_[j], normalized\_bounded\_dual\_delta); }}
absl::Status ModelWeights::Initialize(OpKernelContext\* const context) { OpInputList sparse\_indices\_inputs; TF\_RETURN\_IF\_ERROR( context->input\_list("sparse\_indices", &sparse\_indices\_inputs)); OpInputList sparse\_weights\_inputs; TF\_RETURN\_IF\_ERROR( context->input\_list("sparse\_weights", &sparse\_weights\_inputs)); if (sparse\_indices\_inputs.size() != sparse\_weights\_inputs.size()) return errors::InvalidArgument( "sparse\_indices and sparse\_weights must have the same length, got ", sparse\_indices\_inputs.size(), " and ", sparse\_weights\_inputs.size()); OpInputList dense\_weights\_inputs; TF\_RETURN\_IF\_ERROR( context->input\_list("dense\_weights", &dense\_weights\_inputs));
 OpOutputList sparse\_weights\_outputs; TF\_RETURN\_IF\_ERROR(context->output\_list("out\_delta\_sparse\_weights", &sparse\_weights\_outputs)); if (sparse\_weights\_outputs.size() != sparse\_weights\_inputs.size()) return errors::InvalidArgument( "out\_delta\_sparse\_weights and sparse\_weights must have the same " "length, got ", sparse\_weights\_outputs.size(), " and ", sparse\_weights\_inputs.size());
 OpOutputList dense\_weights\_outputs; TF\_RETURN\_IF\_ERROR( context->output\_list("out\_delta\_dense\_weights", &dense\_weights\_outputs)); if (dense\_weights\_outputs.size() != dense\_weights\_inputs.size()) return errors::InvalidArgument( "out\_delta\_dense\_weights and dense\_weights must have the same length, " "got ", dense\_weights\_outputs.size(), " and ", dense\_weights\_inputs.size());
 for (int i = 0; i < sparse\_weights\_inputs.size(); ++i) { Tensor\* delta\_t; TF\_RETURN\_IF\_ERROR(sparse\_weights\_outputs.allocate( i, sparse\_weights\_inputs[i].shape(), &delta\_t)); // Convert the input vector to a row matrix in internal representation. auto deltas = delta\_t->shaped<float, 2>({1, delta\_t->NumElements()}); deltas.setZero(); sparse\_weights\_.emplace\_back(FeatureWeightsSparseStorage{ sparse\_indices\_inputs[i].flat<int64\_t>(), sparse\_weights\_inputs[i].shaped<float, 2>( {1, sparse\_weights\_inputs[i].NumElements()}), deltas}); }
 // Reads in the weights, and allocates and initializes the delta weights. const auto initialize\_weights = [&](const OpInputList& weight\_inputs, OpOutputList\* const weight\_outputs, std::vector<FeatureWeightsDenseStorage>\* const feature\_weights) { for (int i = 0; i < weight\_inputs.size(); ++i) { Tensor\* delta\_t; TF\_RETURN\_IF\_ERROR( weight\_outputs->allocate(i, weight\_inputs[i].shape(), &delta\_t)); // Convert the input vector to a row matrix in internal // representation. auto deltas = delta\_t->shaped<float, 2>({1, delta\_t->NumElements()}); deltas.setZero(); feature\_weights->emplace\_back(FeatureWeightsDenseStorage{ weight\_inputs[i].shaped<float, 2>( {1, weight\_inputs[i].NumElements()}), deltas}); } return absl::OkStatus(); };
 return initialize\_weights(dense\_weights\_inputs, &dense\_weights\_outputs, &dense\_weights\_);}
// Computes the example statistics for given example, and model. Defined here// as we need definition of ModelWeights and Regularizations.const ExampleStatistics Example::ComputeWxAndWeightedExampleNorm( const int num\_loss\_partitions, const ModelWeights& model\_weights, const Regularizations& regularization, const int num\_weight\_vectors) const { ExampleStatistics result(num\_weight\_vectors);
 result.normalized\_squared\_norm = squared\_norm\_ / regularization.symmetric\_l2();
 // Compute w \dot x and prev\_w \dot x. // This is for sparse features contribution to the logit. for (size\_t j = 0; j < sparse\_features\_.size(); ++j) { const Example::SparseFeatures& sparse\_features = sparse\_features\_[j]; const FeatureWeightsSparseStorage& sparse\_weights = model\_weights.sparse\_weights()[j];
 for (int64\_t k = 0; k < sparse\_features.indices->size(); ++k) { const int64\_t feature\_index = (\*sparse\_features.indices)(k); const double feature\_value = sparse\_features.values == nullptr ? 1.0 : (\*sparse\_features.values)(k); for (int l = 0; l < num\_weight\_vectors; ++l) { const float sparse\_weight = sparse\_weights.nominals(l, feature\_index); const double feature\_weight = sparse\_weight + sparse\_weights.deltas(l, feature\_index) \* num\_loss\_partitions; result.prev\_wx[l] += feature\_value \* regularization.Shrink(sparse\_weight); result.wx[l] += feature\_value \* regularization.Shrink(feature\_weight); } } }
 // Compute w \dot x and prev\_w \dot x. // This is for dense features contribution to the logit. for (size\_t j = 0; j < dense\_vectors\_.size(); ++j) { const Example::DenseVector& dense\_vector = \*dense\_vectors\_[j]; const FeatureWeightsDenseStorage& dense\_weights = model\_weights.dense\_weights()[j];
 const Eigen::Tensor<float, 2, Eigen::RowMajor> feature\_weights = dense\_weights.nominals() + dense\_weights.deltas() \* dense\_weights.deltas().constant(num\_loss\_partitions); if (num\_weight\_vectors == 1) { const Eigen::Tensor<float, 0, Eigen::RowMajor> prev\_prediction = (dense\_vector.Row() \* regularization.EigenShrinkVector( Eigen::TensorMap<Eigen::Tensor<const float, 1, Eigen::RowMajor>>( dense\_weights.nominals().data(), dense\_weights.nominals().dimension(1)))) .sum(); const Eigen::Tensor<float, 0, Eigen::RowMajor> prediction = (dense\_vector.Row() \* regularization.EigenShrinkVector( Eigen::TensorMap<Eigen::Tensor<const float, 1, Eigen::RowMajor>>( feature\_weights.data(), feature\_weights.dimension(1)))) .sum(); result.prev\_wx[0] += prev\_prediction(); result.wx[0] += prediction(); } else { const Eigen::array<Eigen::IndexPair<int>, 1> product\_dims = { Eigen::IndexPair<int>(1, 1)}; const Eigen::Tensor<float, 2, Eigen::RowMajor> prev\_prediction = regularization.EigenShrinkMatrix(dense\_weights.nominals()) .contract(dense\_vector.RowAsMatrix(), product\_dims); const Eigen::Tensor<float, 2, Eigen::RowMajor> prediction = regularization.EigenShrinkMatrix(feature\_weights) .contract(dense\_vector.RowAsMatrix(), product\_dims); // The result of "tensor contraction" (multiplication) in the code // above is of dimension num\_weight\_vectors \* 1. for (int l = 0; l < num\_weight\_vectors; ++l) { result.prev\_wx[l] += prev\_prediction(l, 0); result.wx[l] += prediction(l, 0); } } }
 return result;}
// Examples contains all the training examples that SDCA uses for a mini-batch.absl::Status Examples::SampleAdaptiveProbabilities( const int num\_loss\_partitions, const Regularizations& regularization, const ModelWeights& model\_weights, const TTypes<float>::Matrix example\_state\_data, const std::unique\_ptr<DualLossUpdater>& loss\_updater, const int num\_weight\_vectors) { if (num\_weight\_vectors != 1) { return errors::InvalidArgument( "Adaptive SDCA only works with binary SDCA, " "where num\_weight\_vectors should be 1."); } // Compute the probabilities for (int example\_id = 0; example\_id < num\_examples(); ++example\_id) { const Example& example = examples\_[example\_id]; const double example\_weight = example.example\_weight(); float label = example.example\_label(); const absl::Status conversion\_status = loss\_updater->ConvertLabel(&label); const ExampleStatistics example\_statistics = example.ComputeWxAndWeightedExampleNorm(num\_loss\_partitions, model\_weights, regularization, num\_weight\_vectors); const double kappa = example\_state\_data(example\_id, 0) + loss\_updater->PrimalLossDerivative( example\_statistics.wx[0], label, 1.0); probabilities\_[example\_id] = example\_weight \* sqrt(examples\_[example\_id].squared\_norm\_ + regularization.symmetric\_l2() \* loss\_updater->SmoothnessConstant()) \* std::abs(kappa); }
 // Sample the index random::DistributionSampler sampler(probabilities\_); GuardedPhiloxRandom generator; generator.Init(0, 0); auto local\_gen = generator.ReserveSamples32(num\_examples()); random::SimplePhilox random(&local\_gen); std::random\_device rd; std::mt19937 gen(rd()); std::uniform\_real\_distribution<> dis(0, 1);
 // We use a decay of 10: the probability of an example is divided by 10 // once that example is picked. A good approximation of that is to only // keep a picked example with probability (1 / 10) ^ k where k is the // number of times we already picked that example. We add a num\_retries // to avoid taking too long to sample. We then fill the sampled\_index with // unseen examples sorted by probabilities. int id = 0; int num\_retries = 0; while (id < num\_examples() && num\_retries < num\_examples()) { int picked\_id = sampler.Sample(&random); if (dis(gen) > MathUtil::IPow(0.1, sampled\_count\_[picked\_id])) { num\_retries++; continue; } sampled\_count\_[picked\_id]++; sampled\_index\_[id++] = picked\_id; }
 std::vector<std::pair<int, float>> examples\_not\_seen; examples\_not\_seen.reserve(num\_examples()); for (int i = 0; i < num\_examples(); ++i) { if (sampled\_count\_[i] == 0) examples\_not\_seen.emplace\_back(sampled\_index\_[i], probabilities\_[i]); } std::sort( examples\_not\_seen.begin(), examples\_not\_seen.end(), [](const std::pair<int, float>& lhs, const std::pair<int, float>& rhs) { return lhs.second > rhs.second; }); for (int i = id; i < num\_examples(); ++i) { sampled\_count\_[i] = examples\_not\_seen[i - id].first; } return absl::OkStatus();}
void Examples::RandomShuffle() { std::iota(sampled\_index\_.begin(), sampled\_index\_.end(), 0);
 std::random\_device rd; std::mt19937 rng(rd()); std::shuffle(sampled\_index\_.begin(), sampled\_index\_.end(), rng);}
// TODO(sibyl-Aix6ihai): Refactor/shorten this function.absl::Status Examples::Initialize(OpKernelContext\* const context, const ModelWeights& weights, const int num\_sparse\_features, const int num\_sparse\_features\_with\_values, const int num\_dense\_features) { num\_features\_ = num\_sparse\_features + num\_dense\_features;
 OpInputList sparse\_example\_indices\_inputs; TF\_RETURN\_IF\_ERROR(context->input\_list("sparse\_example\_indices", &sparse\_example\_indices\_inputs)); if (sparse\_example\_indices\_inputs.size() != num\_sparse\_features) return errors::InvalidArgument( "Expected ", num\_sparse\_features, " tensors in sparse\_example\_indices but got ", sparse\_example\_indices\_inputs.size()); OpInputList sparse\_feature\_indices\_inputs; TF\_RETURN\_IF\_ERROR(context->input\_list("sparse\_feature\_indices", &sparse\_feature\_indices\_inputs)); if (sparse\_feature\_indices\_inputs.size() != num\_sparse\_features) return errors::InvalidArgument( "Expected ", num\_sparse\_features, " tensors in sparse\_feature\_indices but got ", sparse\_feature\_indices\_inputs.size()); OpInputList sparse\_feature\_values\_inputs; if (num\_sparse\_features\_with\_values > 0) { TF\_RETURN\_IF\_ERROR(context->input\_list("sparse\_feature\_values", &sparse\_feature\_values\_inputs)); if (sparse\_feature\_values\_inputs.size() != num\_sparse\_features\_with\_values) return errors::InvalidArgument( "Expected ", num\_sparse\_features\_with\_values, " tensors in sparse\_feature\_values but got ", sparse\_feature\_values\_inputs.size()); }
 const Tensor\* example\_weights\_t; TF\_RETURN\_IF\_ERROR(context->input("example\_weights", &example\_weights\_t)); auto example\_weights = example\_weights\_t->flat<float>();
 if (example\_weights.size() >= std::numeric\_limits<int>::max()) { return errors::InvalidArgument(strings::Printf( "Too many examples in a mini-batch: %zu > %d", example\_weights.size(), std::numeric\_limits<int>::max())); }
 // The static\_cast here is safe since num\_examples can be at max an int. const int num\_examples = static\_cast<int>(example\_weights.size()); const Tensor\* example\_labels\_t; TF\_RETURN\_IF\_ERROR(context->input("example\_labels", &example\_labels\_t)); auto example\_labels = example\_labels\_t->flat<float>(); if (example\_labels.size() != num\_examples) { return errors::InvalidArgument("Expected ", num\_examples, " example labels but got ", example\_labels.size()); }
 OpInputList dense\_features\_inputs; TF\_RETURN\_IF\_ERROR( context->input\_list("dense\_features", &dense\_features\_inputs)); for (int i = 0; i < dense\_features\_inputs.size(); ++i) { if (!TensorShapeUtils::IsMatrix(dense\_features\_inputs[i].shape())) { return errors::InvalidArgument("Dense features at index ", i, " must be rank 2 but is rank ", dense\_features\_inputs[i].dims()); } }
 examples\_.clear(); examples\_.resize(num\_examples); probabilities\_.resize(num\_examples); sampled\_index\_.resize(num\_examples); sampled\_count\_.resize(num\_examples); for (int example\_id = 0; example\_id < num\_examples; ++example\_id) { Example\* const example = &examples\_[example\_id]; example->sparse\_features\_.resize(num\_sparse\_features); example->dense\_vectors\_.resize(num\_dense\_features); example->example\_weight\_ = example\_weights(example\_id); example->example\_label\_ = example\_labels(example\_id); } const DeviceBase::CpuWorkerThreads& worker\_threads = \*context->device()->tensorflow\_cpu\_worker\_threads(); TF\_RETURN\_IF\_ERROR(CreateSparseFeatureRepresentation( worker\_threads, num\_examples, num\_sparse\_features, weights, sparse\_example\_indices\_inputs, sparse\_feature\_indices\_inputs, sparse\_feature\_values\_inputs, &examples\_)); TF\_RETURN\_IF\_ERROR(CreateDenseFeatureRepresentation( worker\_threads, num\_examples, num\_dense\_features, weights, dense\_features\_inputs, &examples\_)); TF\_RETURN\_IF\_ERROR(ComputeSquaredNormPerExample( worker\_threads, num\_examples, num\_sparse\_features, num\_dense\_features, &examples\_)); return absl::OkStatus();}
absl::Status Examples::CreateSparseFeatureRepresentation( const DeviceBase::CpuWorkerThreads& worker\_threads, const int num\_examples, const int num\_sparse\_features, const ModelWeights& weights, const OpInputList& sparse\_example\_indices\_inputs, const OpInputList& sparse\_feature\_indices\_inputs, const OpInputList& sparse\_feature\_values\_inputs, std::vector<Example>\* const examples) { mutex mu; absl::Status result; // Guarded by mu auto parse\_partition = [&](const int64\_t begin, const int64\_t end) { // The static\_cast here is safe since begin and end can be at most // num\_examples which is an int. for (int i = static\_cast<int>(begin); i < end; ++i) { auto example\_indices = sparse\_example\_indices\_inputs[i].template flat<int64\_t>(); auto feature\_indices = sparse\_feature\_indices\_inputs[i].template flat<int64\_t>(); if (example\_indices.size() != feature\_indices.size()) { mutex\_lock l(mu); result = errors::InvalidArgument( "Found mismatched example\_indices and feature\_indices [", example\_indices, "] vs [", feature\_indices, "]"); return; }
 // Parse features for each example. Features for a particular example // are at the offsets (start\_id, end\_id] int start\_id = -1; int end\_id = 0; for (int example\_id = 0; example\_id < num\_examples; ++example\_id) { start\_id = end\_id; while (end\_id < example\_indices.size() && example\_indices(end\_id) == example\_id) { ++end\_id; } Example::SparseFeatures\* const sparse\_features = &(\*examples)[example\_id].sparse\_features\_[i]; if (start\_id < example\_indices.size() && example\_indices(start\_id) == example\_id) { sparse\_features->indices.reset(new UnalignedInt64Vector( &(feature\_indices(start\_id)), end\_id - start\_id)); if (sparse\_feature\_values\_inputs.size() > i) { auto feature\_weights = sparse\_feature\_values\_inputs[i].flat<float>(); sparse\_features->values.reset(new UnalignedFloatVector( &(feature\_weights(start\_id)), end\_id - start\_id)); } // If features are non empty. if (end\_id - start\_id > 0) { // TODO(sibyl-Aix6ihai): Write this efficiently using vectorized // operations from eigen. for (int64\_t k = 0; k < sparse\_features->indices->size(); ++k) { const int64\_t feature\_index = (\*sparse\_features->indices)(k); if (!weights.SparseIndexValid(i, feature\_index)) { mutex\_lock l(mu); result = errors::InvalidArgument( "Found sparse feature indices out of valid range: ", (\*sparse\_features->indices)(k)); return; } } } } else { // Add a Tensor that has size 0. sparse\_features->indices.reset( new UnalignedInt64Vector(&(feature\_indices(0)), 0)); // If values exist for this feature group. if (sparse\_feature\_values\_inputs.size() > i) { auto feature\_weights = sparse\_feature\_values\_inputs[i].flat<float>(); sparse\_features->values.reset( new UnalignedFloatVector(&(feature\_weights(0)), 0)); } } } } }; // For each column, the cost of parsing it is O(num\_examples). We use // num\_examples here, as empirically Shard() creates the right amount of // threads based on the problem size. // TODO(sibyl-Aix6ihai): Tune this as a function of dataset size. const int64\_t kCostPerUnit = num\_examples; Shard(worker\_threads.num\_threads, worker\_threads.workers, num\_sparse\_features, kCostPerUnit, parse\_partition); return result;}
absl::Status Examples::CreateDenseFeatureRepresentation( const DeviceBase::CpuWorkerThreads& worker\_threads, const int num\_examples, const int num\_dense\_features, const ModelWeights& weights, const OpInputList& dense\_features\_inputs, std::vector<Example>\* const examples) { mutex mu; absl::Status result; // Guarded by mu auto parse\_partition = [&](const int64\_t begin, const int64\_t end) { // The static\_cast here is safe since begin and end can be at most // num\_examples which is an int. for (int i = static\_cast<int>(begin); i < end; ++i) { auto dense\_features = dense\_features\_inputs[i].template matrix<float>(); for (int example\_id = 0; example\_id < num\_examples; ++example\_id) { (\*examples)[example\_id].dense\_vectors\_[i].reset( new Example::DenseVector{dense\_features, example\_id}); } if (!weights.DenseIndexValid(i, dense\_features.dimension(1) - 1)) { mutex\_lock l(mu); result = errors::InvalidArgument( "More dense features than we have parameters for: ", dense\_features.dimension(1)); return; } } }; // TODO(sibyl-Aix6ihai): Tune this as a function of dataset size. const int64\_t kCostPerUnit = num\_examples; Shard(worker\_threads.num\_threads, worker\_threads.workers, num\_dense\_features, kCostPerUnit, parse\_partition); return result;}
absl::Status Examples::ComputeSquaredNormPerExample( const DeviceBase::CpuWorkerThreads& worker\_threads, const int num\_examples, const int num\_sparse\_features, const int num\_dense\_features, std::vector<Example>\* const examples) { mutex mu; absl::Status result; // Guarded by mu // Compute norm of examples. auto compute\_example\_norm = [&](const int64\_t begin, const int64\_t end) { // The static\_cast here is safe since begin and end can be at most // num\_examples which is an int. gtl::FlatSet<int64\_t> previous\_indices; for (int example\_id = static\_cast<int>(begin); example\_id < end; ++example\_id) { double squared\_norm = 0; Example\* const example = &(\*examples)[example\_id]; for (int j = 0; j < num\_sparse\_features; ++j) { const Example::SparseFeatures& sparse\_features = example->sparse\_features\_[j]; previous\_indices.clear(); for (int64\_t k = 0; k < sparse\_features.indices->size(); ++k) { const int64\_t feature\_index = (\*sparse\_features.indices)(k); if (previous\_indices.insert(feature\_index).second == false) { mutex\_lock l(mu); result = errors::InvalidArgument("Duplicate index in sparse vector."); return; } const double feature\_value = sparse\_features.values == nullptr ? 1.0 : (\*sparse\_features.values)(k); squared\_norm += feature\_value \* feature\_value; } } for (int j = 0; j < num\_dense\_features; ++j) { const Eigen::Tensor<float, 0, Eigen::RowMajor> sn = example->dense\_vectors\_[j]->Row().square().sum(); squared\_norm += sn(); } example->squared\_norm\_ = squared\_norm; } }; // TODO(sibyl-Aix6ihai): Compute the cost optimally. const int64\_t kCostPerUnit = num\_dense\_features + num\_sparse\_features; Shard(worker\_threads.num\_threads, worker\_threads.workers, num\_examples, kCostPerUnit, compute\_example\_norm); return result;}
} // namespace sdca} // namespace tensorflow

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

