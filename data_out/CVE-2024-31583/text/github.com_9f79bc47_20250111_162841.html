
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fpytorch%2Fpytorch%2Fblob%2Fv2.1.2%2Ftorch%2Fcsrc%2Fjit%2Fmobile%2Finterpreter.cpp)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fpytorch%2Fpytorch%2Fblob%2Fv2.1.2%2Ftorch%2Fcsrc%2Fjit%2Fmobile%2Finterpreter.cpp)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=pytorch%2Fpytorch)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[pytorch](/pytorch)
/
**[pytorch](/pytorch/pytorch)**
Public

* [Notifications](/login?return_to=%2Fpytorch%2Fpytorch) You must be signed in to change notification settings
* [Fork
  23.1k](/login?return_to=%2Fpytorch%2Fpytorch)
* [Star
   85.7k](/login?return_to=%2Fpytorch%2Fpytorch)

* [Code](/pytorch/pytorch/tree/v2.1.2)
* [Issues
  5k+](/pytorch/pytorch/issues)
* [Pull requests
  1k](/pytorch/pytorch/pulls)
* [Actions](/pytorch/pytorch/actions)
* [Projects
  12](/pytorch/pytorch/projects)
* [Wiki](/pytorch/pytorch/wiki)
* [Security](/pytorch/pytorch/security)
* [Insights](/pytorch/pytorch/pulse)

Additional navigation options

* [Code](/pytorch/pytorch/tree/v2.1.2)
* [Issues](/pytorch/pytorch/issues)
* [Pull requests](/pytorch/pytorch/pulls)
* [Actions](/pytorch/pytorch/actions)
* [Projects](/pytorch/pytorch/projects)
* [Wiki](/pytorch/pytorch/wiki)
* [Security](/pytorch/pytorch/security)
* [Insights](/pytorch/pytorch/pulse)

## Files

 v2.1.2
## Breadcrumbs

1. [pytorch](/pytorch/pytorch/tree/v2.1.2)
2. /[torch](/pytorch/pytorch/tree/v2.1.2/torch)
3. /[csrc](/pytorch/pytorch/tree/v2.1.2/torch/csrc)
4. /[jit](/pytorch/pytorch/tree/v2.1.2/torch/csrc/jit)
5. /[mobile](/pytorch/pytorch/tree/v2.1.2/torch/csrc/jit/mobile)
/
# interpreter.cpp

Copy path Blame  Blame
## Latest commit

## History

[History](/pytorch/pytorch/commits/v2.1.2/torch/csrc/jit/mobile/interpreter.cpp)377 lines (359 loc) · 11.8 KB v2.1.2
## Breadcrumbs

1. [pytorch](/pytorch/pytorch/tree/v2.1.2)
2. /[torch](/pytorch/pytorch/tree/v2.1.2/torch)
3. /[csrc](/pytorch/pytorch/tree/v2.1.2/torch/csrc)
4. /[jit](/pytorch/pytorch/tree/v2.1.2/torch/csrc/jit)
5. /[mobile](/pytorch/pytorch/tree/v2.1.2/torch/csrc/jit/mobile)
/
# interpreter.cpp

Top
## File metadata and controls

* Code
* Blame

377 lines (359 loc) · 11.8 KB[Raw](https://github.com/pytorch/pytorch/raw/refs/tags/v2.1.2/torch/csrc/jit/mobile/interpreter.cpp)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377#include <torch/csrc/jit/mobile/interpreter.h>
#include <ATen/core/class\_type.h>#include <ATen/core/dynamic\_type.h>#include <ATen/core/function.h>#include <ATen/core/jit\_type.h>#include <ATen/core/operator\_name.h>#include <ATen/record\_function.h>#include <c10/util/Exception.h>#include <c10/util/irange.h>#include <torch/csrc/jit/backends/backend\_exception.h>#include <torch/csrc/jit/mobile/function.h>#include <torch/csrc/jit/mobile/observer.h>#include <torch/csrc/jit/mobile/promoted\_prim\_ops.h>#include <torch/csrc/jit/runtime/jit\_exception.h>#include <torch/csrc/jit/runtime/vararg\_functions.h>
namespace torch {namespace jit {char const\* toString(OpCode op);std::ostream& operator<<(std::ostream& out, Instruction inst);namespace mobile {InterpreterState::InterpreterState(const Code& code) { enterFrame(code);}
namespace {static thread\_local std::vector<DebugHandle> exception\_debug\_handles\_;void createObject(Stack& stack, const at::ClassTypePtr& type) { auto userObj = c10::ivalue::Object::create( c10::StrongTypePtr(type->compilation\_unit(), type), type->numAttributes()); push(stack, std::move(userObj));}
void isinstance(Stack& stack, at::ArrayRef<at::TypePtr> types) { at::TypePtr ty = pop(stack).type<c10::DynamicType>(); for (const at::TypePtr& candidate : types) { if (ty->isSubtypeOf(\*candidate)) { push(stack, true); return; } } push(stack, false);}} // namespace
using namespace at;
const std::vector<DebugHandle>& getInterpretersExceptionDebugHandles() { return exception\_debug\_handles\_;}
void InterpreterState::enterFrame(const Code& code) { frames\_.emplace\_back(code); registers\_.resize(registers\_.size() + code.register\_size\_);}
void InterpreterState::leaveFrame() { registers\_.resize( registers\_.size() - frames\_.back().getCode().register\_size\_); frames\_.pop\_back();}
void InterpreterState::saveExceptionDebugHandles() { std::vector<DebugHandle> exception\_debug\_handles; for (auto frame = frames\_.crbegin(); frame != frames\_.crend(); frame++) { size\_t pc = frame->getPC() - (frame != frames\_.crbegin() ? 1 : 0); if (auto handle = frame->getDebugHandle(pc)) { exception\_debug\_handles.push\_back(\*handle); } else { exception\_debug\_handles.push\_back(-1); } } exception\_debug\_handles\_ = std::move(exception\_debug\_handles);}
void InterpreterState::callFunction(torch::jit::Function& f, Stack& stack) { bool newFrame = f.call(stack, [&](const mobile::Code& code) { enterFrame(code); }); (frames\_.rbegin() + (newFrame ? 1 : 0))->step();}
bool InterpreterState::run(Stack& stack) { while (true) { try { auto& frame = frames\_.back(); const auto& code = frame.getCode(); const auto pc = frame.getPC(); auto inst = frame.getInstruction(); // If no valid debug handle found then just log pc. // This is possible when we did not save debug handles
 DebugHandle debug\_handle = pc; if (auto handle = frame.getDebugHandle()) { debug\_handle = \*handle; }
 // std::cout << "RUNNING " << pc << " " << code.instructions\_[pc]; // if (inst.op == OP) { // std::cout << ", " << code.op\_names\_[inst.X].name; // if (!code.op\_names\_[inst.X].overload\_name.empty()) { // std::cout << "." << code.op\_names\_[inst.X].overload\_name; // } // } // std::cout << std::endl;
 // TODO(iliacher): remove the workaround after RecordFunction is in // Dispatcher // Check with iliacher if has been done. // Plus this is not safe as if you throw exception record function will be // left enabled. That is a TODO // NOTE: this recordFunction logic takes up ~2-3% of cpu cycles in some // workflows. do we need it and/or can we opt-out of // isRecordFunctionEnabled with a macro? if we delete it, things appear to // work just fine. bool prev\_value = isRecordFunctionEnabled(); if (!prev\_value) { // enable only for the RecordFunction enableRecordFunction(true); } switch (inst.op) { case OP: { if (at::hasGlobalCallbacks()) { if (auto\* mobile\_debug\_info = static\_cast<MobileDebugInfo\*>( c10::ThreadLocalDebugInfo::get( c10::DebugInfoKind::MOBILE\_RUNTIME\_INFO))) { mobile\_debug\_info->setOpIdx(pc); } }
 RECORD\_EDGE\_SCOPE\_WITH\_DEBUG\_HANDLE\_AND\_INPUTS( code.op\_names\_[inst.X].name, debug\_handle, stack); code.operators\_[inst.X](stack); frame.step(); } break; case OPN: { stack.emplace\_back(inst.N); RECORD\_EDGE\_SCOPE\_WITH\_DEBUG\_HANDLE\_AND\_INPUTS( code.op\_names\_[inst.X].name, debug\_handle, stack); code.operators\_[inst.X](stack); frame.step(); } break; case CALL: { auto& function = \*frame.getCode().functions\_.at(inst.X); callFunction(function, stack); } break; case INTERFACE\_CALL: { torch::jit::Function& method = peek(stack, 0, inst.N) .toObject() ->type() ->getMethod(code.constants\_[inst.X].toStringRef()); RECORD\_EDGE\_SCOPE\_WITH\_DEBUG\_HANDLE\_AND\_INPUTS( method.name(), debug\_handle, stack); callFunction(method, stack); } break; case LOAD: stack.emplace\_back(reg(inst.X)); frame.step(); break; case MOVE: stack.emplace\_back(std::move(reg(inst.X))); frame.step(); break; case STORE: reg(inst.X) = pop(stack); frame.step(); break; case STOREN: for (size\_t i = inst.N; i > 0; --i) { reg(inst.X + i - 1) = pop(stack); } frame.step(); break; case DROP: pop(stack); frame.step(); break; case DROPR: reg(inst.X) = IValue(); frame.step(); break; case LOADC: stack.emplace\_back(code.constants\_[inst.X]); frame.step(); break; case GET\_ATTR: { auto userObj = pop(stack).toObject(); auto value = userObj->getSlot(inst.X); push(stack, std::move(value)); frame.step(); } break; case SET\_ATTR: { auto v = pop(stack); auto userObj = pop(stack).toObject(); // Mobile only: since the number of slots is not known, resize the // numAttributes before setSlot. while (static\_cast<int>(userObj->type()->numAttributes()) <= inst.X) { std::stringstream ss; ss << userObj->type()->numAttributes(); userObj->type()->addAttribute(ss.str(), c10::NoneType::get()); } userObj->setSlot(inst.X, std::move(v)); frame.step(); } break; case JF: frame.jump(pop(stack).toBool() ? 1 : inst.X); break; case JMP: frame.jump(inst.X); break; case LOOP: { // stack: iteration\_count, max\_iter, cond, loop\_carried\_deps... auto sframe = stack.end() - (inst.N + 1); int64\_t trip\_count = sframe[0].toInt(); int64\_t max\_trip\_count = sframe[1].toInt(); bool cond = sframe[2].toBool(); if (trip\_count < max\_trip\_count && cond) { sframe[2] = trip\_count; sframe[0] = trip\_count + 1; frame.step(); } else { size\_t n\_loop\_carried = inst.N - 2; for (const auto i : c10::irange(n\_loop\_carried)) { sframe[i] = std::move(sframe[i + 3]); } drop(stack, 3); // iteration\_count, max\_iter, cond frame.jump(inst.X); } } break; case RET: leaveFrame(); if (!frames\_.empty()) { continue; } return false; case LIST\_CONSTRUCT: { listConstruct(stack, \*code.types\_.at(inst.X), inst.N); frame.step(); } break; case LIST\_UNPACK: { listUnpack(stack, inst.X); frame.step(); } break; case TUPLE\_CONSTRUCT: { tupleConstruct(stack, inst.X); frame.step(); } break; case TUPLE\_SLICE: { tupleSlice(stack, inst.X, inst.X + inst.N); frame.step(); } break; case TUPLE\_INDEX: { tupleIndex(stack); frame.step(); } break; case RAISE\_EXCEPTION: { raiseExceptionWithMessage(stack); frame.step(); } break; case \_\_IS\_\_: { is(stack); frame.step(); } break; case UN\_INITIALIZED: { unInitialized(stack); frame.step(); } break; case \_\_ISNOT\_\_: { isNot(stack); frame.step(); } break; case FORMAT: { format(stack, inst.X); frame.step(); } break; case DEVICE: { device(stack); frame.step(); } break; case DTYPE: { dtype(stack); frame.step(); } break; case DIM: { dim(stack); frame.step(); } break; case \_\_NOT\_\_: { \_not(stack); frame.step(); } break; case DICT\_INDEX: { dictIndex(stack); frame.step(); } break; case TO\_LIST: { toList(stack); frame.step(); } break; case NUM\_TO\_TENSOR: { numToTensorScalar(stack); frame.step(); } break; case IS\_CUDA: { isCuda(stack); frame.step(); } break; case DICT\_CONSTRUCT: { dictConstruct(stack, \*code.types\_.at(inst.X), inst.N); frame.step(); } break; case NAMED\_TUPLE\_CONSTRUCT: { namedTupleConstruct(stack, code.types\_.at(inst.X), inst.N); frame.step(); } break; case CREATE\_OBJECT: { auto type = code.types\_.at(inst.X)->expect<c10::ClassType>(); createObject(stack, type); frame.step(); } break; case ISINSTANCE: { at::ArrayRef<TypePtr> types(&code.types\_.at(inst.X), inst.N); isinstance(stack, types); frame.step(); } break; case WARN: { drop(stack, 1); // Note: Please don't move the pop(stack) code below into the // TORCH\_WARN macro since TORCH\_WARN fails to evaluate its arguments // when STRIP\_ERROR\_MESSAGES is defined (which happens for production // mobile builds). This will cause the stack to be in an inconsistent // state. It has previously resulted in a SEV (S22350). const auto& sref = stack.back().toStringRef(); TORCH\_WARN(sref); stack.pop\_back(); frame.step(); } break; default: AT\_ERROR(toString(inst.op), " is invalid."); }
 if (!prev\_value) { enableRecordFunction(false); } // This exception must be caught first as it derived from c10::Error } catch (c10::BackendRuntimeException& e) { saveExceptionDebugHandles(); TORCH\_RETHROW(e); } catch (c10::Error& error) { // Reason for catching and rethrowing the error is so that we can // set the exception pc that is queried later saveExceptionDebugHandles(); TORCH\_RETHROW(error); } catch (...) { saveExceptionDebugHandles(); throw; } // for (auto val : stack) { // if (val.isTensor()) { // std::cout << val.toTensor().sizes() << std::endl; // } else { // std::cout << val << std::endl; // } // } } return false;}
IValue& InterpreterState::reg(size\_t reg) { return \*(registers\_.end() - reg);}
} // namespace mobile} // namespace jit} // namespace torch

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

