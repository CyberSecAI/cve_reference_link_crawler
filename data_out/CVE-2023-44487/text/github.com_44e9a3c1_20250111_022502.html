
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fapache%2Fhttpd%2Fblob%2Fafcdbeebbff4b0c50ea26cdd16e178c0d1f24152%2Fmodules%2Fhttp2%2Fh2_mplx.c)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fapache%2Fhttpd%2Fblob%2Fafcdbeebbff4b0c50ea26cdd16e178c0d1f24152%2Fmodules%2Fhttp2%2Fh2_mplx.c)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=apache%2Fhttpd)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[apache](/apache)
/
**[httpd](/apache/httpd)**
Public

* [Notifications](/login?return_to=%2Fapache%2Fhttpd) You must be signed in to change notification settings
* [Fork
  1.1k](/login?return_to=%2Fapache%2Fhttpd)
* [Star
   3.6k](/login?return_to=%2Fapache%2Fhttpd)

* [Code](/apache/httpd)
* [Pull requests
  72](/apache/httpd/pulls)
* [Actions](/apache/httpd/actions)
* [Projects
  0](/apache/httpd/projects)
* [Security](/apache/httpd/security)
* [Insights](/apache/httpd/pulse)

Additional navigation options

* [Code](/apache/httpd)
* [Pull requests](/apache/httpd/pulls)
* [Actions](/apache/httpd/actions)
* [Projects](/apache/httpd/projects)
* [Security](/apache/httpd/security)
* [Insights](/apache/httpd/pulse)

## Files

 afcdbee
## Breadcrumbs

1. [httpd](/apache/httpd/tree/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152)
2. /[modules](/apache/httpd/tree/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules)
3. /[http2](/apache/httpd/tree/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules/http2)
/
# h2\_mplx.c

Copy path Blame  Blame
## Latest commit

## History

[History](/apache/httpd/commits/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules/http2/h2_mplx.c)1247 lines (1071 loc) · 40.6 KB afcdbee
## Breadcrumbs

1. [httpd](/apache/httpd/tree/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152)
2. /[modules](/apache/httpd/tree/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules)
3. /[http2](/apache/httpd/tree/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules/http2)
/
# h2\_mplx.c

Top
## File metadata and controls

* Code
* Blame

1247 lines (1071 loc) · 40.6 KB[Raw](https://github.com/apache/httpd/raw/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules/http2/h2_mplx.c)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000/\* Licensed to the Apache Software Foundation (ASF) under one or more \* contributor license agreements. See the NOTICE file distributed with \* this work for additional information regarding copyright ownership. \* The ASF licenses this file to You under the Apache License, Version 2.0 \* (the "License"); you may not use this file except in compliance with \* the License. You may obtain a copy of the License at \* \* http://www.apache.org/licenses/LICENSE-2.0 \* \* Unless required by applicable law or agreed to in writing, software \* distributed under the License is distributed on an "AS IS" BASIS, \* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. \* See the License for the specific language governing permissions and \* limitations under the License. \*/ #include <assert.h>#include <stddef.h>#include <stdlib.h>
#include <apr\_atomic.h>#include <apr\_thread\_mutex.h>#include <apr\_thread\_cond.h>#include <apr\_strings.h>#include <apr\_time.h>
#include <httpd.h>#include <http\_core.h>#include <http\_connection.h>#include <http\_log.h>#include <http\_protocol.h>
#include <mpm\_common.h>
#include "mod\_http2.h"
#include "h2.h"#include "h2\_private.h"#include "h2\_bucket\_beam.h"#include "h2\_config.h"#include "h2\_c1.h"#include "h2\_conn\_ctx.h"#include "h2\_protocol.h"#include "h2\_mplx.h"#include "h2\_request.h"#include "h2\_stream.h"#include "h2\_session.h"#include "h2\_c2.h"#include "h2\_workers.h"#include "h2\_util.h"
/\* utility for iterating over ihash stream sets \*/typedef struct { h2\_mplx \*m; h2\_stream \*stream; apr\_time\_t now; apr\_size\_t count;} stream\_iter\_ctx;
static conn\_rec \*c2\_prod\_next(void \*baton, int \*phas\_more);static void c2\_prod\_done(void \*baton, conn\_rec \*c2);static void workers\_shutdown(void \*baton, int graceful);
static void s\_mplx\_be\_happy(h2\_mplx \*m, conn\_rec \*c, h2\_conn\_ctx\_t \*conn\_ctx);static void m\_be\_annoyed(h2\_mplx \*m);
static apr\_status\_t mplx\_pollset\_create(h2\_mplx \*m);static apr\_status\_t mplx\_pollset\_poll(h2\_mplx \*m, apr\_interval\_time\_t timeout, stream\_ev\_callback \*on\_stream\_input, stream\_ev\_callback \*on\_stream\_output, void \*on\_ctx);
static apr\_pool\_t \*pchild;
/\* APR callback invoked if allocation fails. \*/static int abort\_on\_oom(int retcode){ ap\_abort\_on\_oom(); return retcode; /\* unreachable, hopefully. \*/}
apr\_status\_t h2\_mplx\_c1\_child\_init(apr\_pool\_t \*pool, server\_rec \*s){ pchild = pool; return APR\_SUCCESS;}
#define H2\_MPLX\_ENTER(m) \ do { apr\_status\_t rv\_lock; if ((rv\_lock = apr\_thread\_mutex\_lock(m->lock)) != APR\_SUCCESS) {\ return rv\_lock;\ } } while(0)
#define H2\_MPLX\_LEAVE(m) \ apr\_thread\_mutex\_unlock(m->lock) #define H2\_MPLX\_ENTER\_ALWAYS(m) \ apr\_thread\_mutex\_lock(m->lock)
#define H2\_MPLX\_ENTER\_MAYBE(m, dolock) \ if (dolock) apr\_thread\_mutex\_lock(m->lock)
#define H2\_MPLX\_LEAVE\_MAYBE(m, dolock) \ if (dolock) apr\_thread\_mutex\_unlock(m->lock)
static void c1\_input\_consumed(void \*ctx, h2\_bucket\_beam \*beam, apr\_off\_t length){ h2\_stream\_in\_consumed(ctx, length);}
static int stream\_is\_running(h2\_stream \*stream){ h2\_conn\_ctx\_t \*conn\_ctx = h2\_conn\_ctx\_get(stream->c2); return conn\_ctx && apr\_atomic\_read32(&conn\_ctx->started) != 0 && apr\_atomic\_read32(&conn\_ctx->done) == 0;}
int h2\_mplx\_c1\_stream\_is\_running(h2\_mplx \*m, h2\_stream \*stream){ int rv;
 H2\_MPLX\_ENTER(m); rv = stream\_is\_running(stream); H2\_MPLX\_LEAVE(m); return rv;}
static void c1c2\_stream\_joined(h2\_mplx \*m, h2\_stream \*stream){ ap\_assert(!stream\_is\_running(stream));  h2\_ihash\_remove(m->shold, stream->id); APR\_ARRAY\_PUSH(m->spurge, h2\_stream \*) = stream;}
static void m\_stream\_cleanup(h2\_mplx \*m, h2\_stream \*stream){ h2\_conn\_ctx\_t \*c2\_ctx = h2\_conn\_ctx\_get(stream->c2);
 ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup, unsubscribing from beam events")); if (c2\_ctx) { if (c2\_ctx->beam\_out) { h2\_beam\_on\_was\_empty(c2\_ctx->beam\_out, NULL, NULL); } if (c2\_ctx->beam\_in) { h2\_beam\_on\_send(c2\_ctx->beam\_in, NULL, NULL); h2\_beam\_on\_received(c2\_ctx->beam\_in, NULL, NULL); h2\_beam\_on\_eagain(c2\_ctx->beam\_in, NULL, NULL); h2\_beam\_on\_consumed(c2\_ctx->beam\_in, NULL, NULL); } }
 ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup, removing from registries")); ap\_assert(stream->state == H2\_SS\_CLEANUP); h2\_stream\_cleanup(stream); h2\_ihash\_remove(m->streams, stream->id); h2\_iq\_remove(m->q, stream->id);
 if (c2\_ctx) { if (!stream\_is\_running(stream)) { ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup, c2 is done, move to spurge")); /\* processing has finished \*/ APR\_ARRAY\_PUSH(m->spurge, h2\_stream \*) = stream; } else { ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup, c2 is running, abort")); /\* c2 is still running \*/ h2\_c2\_abort(stream->c2, m->c1); ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup, c2 is done, move to shold")); h2\_ihash\_add(m->shold, stream); } } else { /\* never started \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup, never started, move to spurge")); APR\_ARRAY\_PUSH(m->spurge, h2\_stream \*) = stream; }}
static h2\_c2\_transit \*c2\_transit\_create(h2\_mplx \*m){ apr\_allocator\_t \*allocator; apr\_pool\_t \*ptrans; h2\_c2\_transit \*transit; apr\_status\_t rv;
 /\* We create a pool with its own allocator to be used for \* processing a request. This is the only way to have the processing \* independent of its parent pool in the sense that it can work in \* another thread. \*/
 rv = apr\_allocator\_create(&allocator); if (rv == APR\_SUCCESS) { apr\_allocator\_max\_free\_set(allocator, ap\_max\_mem\_free); rv = apr\_pool\_create\_ex(&ptrans, m->pool, NULL, allocator); } if (rv != APR\_SUCCESS) { /\* maybe the log goes through, maybe not. \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_ERR, rv, m->c1, APLOGNO(10004) "h2\_mplx: create transit pool"); ap\_abort\_on\_oom(); return NULL; /\* should never be reached. \*/ }
 apr\_allocator\_owner\_set(allocator, ptrans); apr\_pool\_abort\_set(abort\_on\_oom, ptrans); apr\_pool\_tag(ptrans, "h2\_c2\_transit");
 transit = apr\_pcalloc(ptrans, sizeof(\*transit)); transit->pool = ptrans; transit->bucket\_alloc = apr\_bucket\_alloc\_create(ptrans); return transit;}
static void c2\_transit\_destroy(h2\_c2\_transit \*transit){ apr\_pool\_destroy(transit->pool);}
static h2\_c2\_transit \*c2\_transit\_get(h2\_mplx \*m){ h2\_c2\_transit \*\*ptransit = apr\_array\_pop(m->c2\_transits); if (ptransit) { return \*ptransit; } return c2\_transit\_create(m);}
static void c2\_transit\_recycle(h2\_mplx \*m, h2\_c2\_transit \*transit){ if (m->c2\_transits->nelts >= APR\_INT32\_MAX || (apr\_uint32\_t)m->c2\_transits->nelts >= m->max\_spare\_transits) { c2\_transit\_destroy(transit); } else { APR\_ARRAY\_PUSH(m->c2\_transits, h2\_c2\_transit\*) = transit; }}
/\*\* \* A h2\_mplx needs to be thread-safe \*and\* if will be called by \* the h2\_session thread \*and\* the h2\_worker threads. Therefore: \* - calls are protected by a mutex lock, m->lock \* - the pool needs its own allocator, since apr\_allocator\_t are  \* not re-entrant. The separate allocator works without a  \* separate lock since we already protect h2\_mplx itself. \* Since HTTP/2 connections can be expected to live longer than \* their HTTP/1 cousins, the separate allocator seems to work better \* than protecting a shared h2\_session one with an own lock. \*/h2\_mplx \*h2\_mplx\_c1\_create(int child\_num, apr\_uint32\_t id, h2\_stream \*stream0, server\_rec \*s, apr\_pool\_t \*parent, h2\_workers \*workers){ h2\_conn\_ctx\_t \*conn\_ctx; apr\_status\_t status = APR\_SUCCESS; apr\_allocator\_t \*allocator; apr\_thread\_mutex\_t \*mutex = NULL; h2\_mplx \*m = NULL;  m = apr\_pcalloc(parent, sizeof(h2\_mplx)); m->stream0 = stream0; m->c1 = stream0->c2; m->s = s; m->child\_num = child\_num; m->id = id;
 /\* We create a pool with its own allocator to be used for \* processing secondary connections. This is the only way to have the \* processing independent of its parent pool in the sense that it \* can work in another thread. Also, the new allocator needs its own \* mutex to synchronize sub-pools. \*/ status = apr\_allocator\_create(&allocator); if (status != APR\_SUCCESS) { allocator = NULL; goto failure; }
 apr\_allocator\_max\_free\_set(allocator, ap\_max\_mem\_free); apr\_pool\_create\_ex(&m->pool, parent, NULL, allocator); if (!m->pool) goto failure;
 apr\_pool\_tag(m->pool, "h2\_mplx"); apr\_allocator\_owner\_set(allocator, m->pool);
 status = apr\_thread\_mutex\_create(&mutex, APR\_THREAD\_MUTEX\_DEFAULT, m->pool); if (APR\_SUCCESS != status) goto failure; apr\_allocator\_mutex\_set(allocator, mutex);
 status = apr\_thread\_mutex\_create(&m->lock, APR\_THREAD\_MUTEX\_DEFAULT, m->pool); if (APR\_SUCCESS != status) goto failure;
 m->max\_streams = h2\_config\_sgeti(s, H2\_CONF\_MAX\_STREAMS); m->stream\_max\_mem = h2\_config\_sgeti(s, H2\_CONF\_STREAM\_MAX\_MEM);
 m->streams = h2\_ihash\_create(m->pool, offsetof(h2\_stream,id)); m->shold = h2\_ihash\_create(m->pool, offsetof(h2\_stream,id)); m->spurge = apr\_array\_make(m->pool, 10, sizeof(h2\_stream\*)); m->q = h2\_iq\_create(m->pool, m->max\_streams);
 m->workers = workers; m->processing\_max = H2MIN(h2\_workers\_get\_max\_workers(workers), m->max\_streams); m->processing\_limit = 6; /\* the original h1 max parallel connections \*/ m->last\_mood\_change = apr\_time\_now(); m->mood\_update\_interval = apr\_time\_from\_msec(100);
 status = mplx\_pollset\_create(m); if (APR\_SUCCESS != status) { ap\_log\_cerror(APLOG\_MARK, APLOG\_ERR, status, m->c1, APLOGNO(10308) "nghttp2: could not create pollset"); goto failure; } m->streams\_ev\_in = apr\_array\_make(m->pool, 10, sizeof(h2\_stream\*)); m->streams\_ev\_out = apr\_array\_make(m->pool, 10, sizeof(h2\_stream\*));
 m->streams\_input\_read = h2\_iq\_create(m->pool, 10); m->streams\_output\_written = h2\_iq\_create(m->pool, 10); status = apr\_thread\_mutex\_create(&m->poll\_lock, APR\_THREAD\_MUTEX\_DEFAULT, m->pool); if (APR\_SUCCESS != status) goto failure;
 conn\_ctx = h2\_conn\_ctx\_get(m->c1); if (conn\_ctx->pfd.reqevents) { apr\_pollset\_add(m->pollset, &conn\_ctx->pfd); }
 m->max\_spare\_transits = 3; m->c2\_transits = apr\_array\_make(m->pool, (int)m->max\_spare\_transits, sizeof(h2\_c2\_transit\*));
 m->producer = h2\_workers\_register(workers, m->pool, apr\_psprintf(m->pool, "h2-%u", (unsigned int)m->id), c2\_prod\_next, c2\_prod\_done, workers\_shutdown, m); return m;
failure: if (m->pool) { apr\_pool\_destroy(m->pool); } else if (allocator) { apr\_allocator\_destroy(allocator); } return NULL;}
int h2\_mplx\_c1\_shutdown(h2\_mplx \*m){ int max\_stream\_id\_started = 0;  H2\_MPLX\_ENTER(m);
 max\_stream\_id\_started = m->max\_stream\_id\_started; /\* Clear schedule queue, disabling existing streams from starting \*/  h2\_iq\_clear(m->q);
 H2\_MPLX\_LEAVE(m); return max\_stream\_id\_started;}
typedef struct { h2\_mplx\_stream\_cb \*cb; void \*ctx;} stream\_iter\_ctx\_t;
static int m\_stream\_iter\_wrap(void \*ctx, void \*stream){ stream\_iter\_ctx\_t \*x = ctx; return x->cb(stream, x->ctx);}
apr\_status\_t h2\_mplx\_c1\_streams\_do(h2\_mplx \*m, h2\_mplx\_stream\_cb \*cb, void \*ctx){ stream\_iter\_ctx\_t x;  x.cb = cb; x.ctx = ctx;
 H2\_MPLX\_ENTER(m);
 h2\_ihash\_iter(m->streams, m\_stream\_iter\_wrap, &x);  H2\_MPLX\_LEAVE(m); return APR\_SUCCESS;}
typedef struct { int stream\_count; int stream\_want\_send;} stream\_iter\_aws\_t;
static int m\_stream\_want\_send\_data(void \*ctx, void \*stream){ stream\_iter\_aws\_t \*x = ctx; ++x->stream\_count; if (h2\_stream\_wants\_send\_data(stream)) ++x->stream\_want\_send; return 1;}
int h2\_mplx\_c1\_all\_streams\_want\_send\_data(h2\_mplx \*m){ stream\_iter\_aws\_t x; x.stream\_count = 0; x.stream\_want\_send = 0; H2\_MPLX\_ENTER(m); h2\_ihash\_iter(m->streams, m\_stream\_want\_send\_data, &x); H2\_MPLX\_LEAVE(m); return x.stream\_count && (x.stream\_count == x.stream\_want\_send);}
static int m\_report\_stream\_iter(void \*ctx, void \*val) { h2\_mplx \*m = ctx; h2\_stream \*stream = val; h2\_conn\_ctx\_t \*conn\_ctx = h2\_conn\_ctx\_get(stream->c2); ap\_log\_cerror(APLOG\_MARK, APLOG\_WARNING, 0, m->c1, H2\_STRM\_MSG(stream, "started=%d, scheduled=%d, ready=%d, out\_buffer=%ld"), !!stream->c2, stream->scheduled, h2\_stream\_is\_ready(stream), (long)(stream->output? h2\_beam\_get\_buffered(stream->output) : -1)); if (conn\_ctx) { ap\_log\_cerror(APLOG\_MARK, APLOG\_DEBUG, 0, m->c1, /\* NO APLOGNO \*/ H2\_STRM\_MSG(stream, "->03198: %s %s %s" "[started=%u/done=%u]"), conn\_ctx->request->method, conn\_ctx->request->authority, conn\_ctx->request->path, apr\_atomic\_read32(&conn\_ctx->started), apr\_atomic\_read32(&conn\_ctx->done)); } else { ap\_log\_cerror(APLOG\_MARK, APLOG\_DEBUG, 0, m->c1, /\* NO APLOGNO \*/ H2\_STRM\_MSG(stream, "->03198: not started")); } return 1;}
static int m\_unexpected\_stream\_iter(void \*ctx, void \*val) { h2\_mplx \*m = ctx; h2\_stream \*stream = val; ap\_log\_cerror(APLOG\_MARK, APLOG\_WARNING, 0, m->c1, /\* NO APLOGNO \*/ H2\_STRM\_MSG(stream, "unexpected, started=%d, scheduled=%d, ready=%d"),  !!stream->c2, stream->scheduled, h2\_stream\_is\_ready(stream)); return 1;}
static int m\_stream\_cancel\_iter(void \*ctx, void \*val) { h2\_mplx \*m = ctx; h2\_stream \*stream = val;
 /\* take over event monitoring \*/ h2\_stream\_set\_monitor(stream, NULL); /\* Reset, should transit to CLOSED state \*/ h2\_stream\_rst(stream, H2\_ERR\_NO\_ERROR); /\* All connection data has been sent, simulate cleanup \*/ h2\_stream\_dispatch(stream, H2\_SEV\_EOS\_SENT); m\_stream\_cleanup(m, stream);  return 0;}
static void c1\_purge\_streams(h2\_mplx \*m);
void h2\_mplx\_c1\_destroy(h2\_mplx \*m){ apr\_status\_t status; unsigned int i, wait\_secs = 60; int old\_aborted;
 ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_MPLX\_MSG(m, "start release")); /\* How to shut down a h2 connection: \* 0. abort and tell the workers that no more work will come from us \*/ m->shutdown = m->aborted = 1;
 H2\_MPLX\_ENTER\_ALWAYS(m);
 /\* While really terminating any c2 connections, treat the master \* connection as aborted. It's not as if we could send any more data \* at this point. \*/ old\_aborted = m->c1->aborted; m->c1->aborted = 1;
 /\* How to shut down a h2 connection: \* 1. cancel all streams still active \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_MPLX\_MSG(m, "release, %u/%u/%d streams (total/hold/purge), %d streams"), h2\_ihash\_count(m->streams), h2\_ihash\_count(m->shold), m->spurge->nelts, m->processing\_count); while (!h2\_ihash\_iter(m->streams, m\_stream\_cancel\_iter, m)) { /\* until empty \*/ }  /\* 2. no more streams should be scheduled or in the active set \*/ ap\_assert(h2\_ihash\_empty(m->streams)); ap\_assert(h2\_iq\_empty(m->q));  /\* 3. while workers are busy on this connection, meaning they \* are processing streams from this connection, wait on them finishing \* in order to wake us and let us check again.  \* Eventually, this has to succeed. \*/ if (!m->join\_wait) { apr\_thread\_cond\_create(&m->join\_wait, m->pool); }
 for (i = 0; h2\_ihash\_count(m->shold) > 0; ++i) { status = apr\_thread\_cond\_timedwait(m->join\_wait, m->lock, apr\_time\_from\_sec(wait\_secs));  if (APR\_STATUS\_IS\_TIMEUP(status)) { /\* This can happen if we have very long running requests \* that do not time out on IO. \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_DEBUG, 0, m->c1, APLOGNO(03198) H2\_MPLX\_MSG(m, "waited %u sec for %u streams"), i\*wait\_secs, h2\_ihash\_count(m->shold)); h2\_ihash\_iter(m->shold, m\_report\_stream\_iter, m); } }
 H2\_MPLX\_LEAVE(m); h2\_workers\_join(m->workers, m->producer); H2\_MPLX\_ENTER\_ALWAYS(m);
 /\* 4. With all workers done, all streams should be in spurge \*/ ap\_assert(m->processing\_count == 0); if (!h2\_ihash\_empty(m->shold)) { ap\_log\_cerror(APLOG\_MARK, APLOG\_WARNING, 0, m->c1, APLOGNO(03516) H2\_MPLX\_MSG(m, "unexpected %u streams in hold"), h2\_ihash\_count(m->shold)); h2\_ihash\_iter(m->shold, m\_unexpected\_stream\_iter, m); }
 c1\_purge\_streams(m);
 m->c1->aborted = old\_aborted; H2\_MPLX\_LEAVE(m);
 ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_MPLX\_MSG(m, "released"));}
apr\_status\_t h2\_mplx\_c1\_stream\_cleanup(h2\_mplx \*m, h2\_stream \*stream, unsigned int \*pstream\_count){ H2\_MPLX\_ENTER(m);  ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, m->c1, H2\_STRM\_MSG(stream, "cleanup")); m\_stream\_cleanup(m, stream); \*pstream\_count = h2\_ihash\_count(m->streams); H2\_MPLX\_LEAVE(m); return APR\_SUCCESS;}
const h2\_stream \*h2\_mplx\_c2\_stream\_get(h2\_mplx \*m, int stream\_id){ h2\_stream \*s = NULL;  H2\_MPLX\_ENTER\_ALWAYS(m); s = h2\_ihash\_get(m->streams, stream\_id); H2\_MPLX\_LEAVE(m);
 return s;}
static void c1\_purge\_streams(h2\_mplx \*m){ h2\_stream \*stream; int i;
 for (i = 0; i < m->spurge->nelts; ++i) { stream = APR\_ARRAY\_IDX(m->spurge, i, h2\_stream\*); ap\_assert(stream->state == H2\_SS\_CLEANUP);
 if (stream->input) { h2\_beam\_destroy(stream->input, m->c1); stream->input = NULL; } if (stream->c2) { conn\_rec \*c2 = stream->c2; h2\_conn\_ctx\_t \*c2\_ctx = h2\_conn\_ctx\_get(c2); h2\_c2\_transit \*transit;
 stream->c2 = NULL; ap\_assert(c2\_ctx); transit = c2\_ctx->transit; h2\_c2\_destroy(c2); /\* c2\_ctx is gone as well \*/ if (transit) { c2\_transit\_recycle(m, transit); } } h2\_stream\_destroy(stream); } apr\_array\_clear(m->spurge);}
void h2\_mplx\_c1\_going\_keepalive(h2\_mplx \*m){ H2\_MPLX\_ENTER\_ALWAYS(m); if (m->spurge->nelts) { c1\_purge\_streams(m); } H2\_MPLX\_LEAVE(m);}
apr\_status\_t h2\_mplx\_c1\_poll(h2\_mplx \*m, apr\_interval\_time\_t timeout, stream\_ev\_callback \*on\_stream\_input, stream\_ev\_callback \*on\_stream\_output, void \*on\_ctx){ apr\_status\_t rv;
 H2\_MPLX\_ENTER(m);
 if (m->aborted) { rv = APR\_ECONNABORTED; goto cleanup; } /\* Purge (destroy) streams outside of pollset processing. \* Streams that are registered in the pollset, will be removed \* when they are destroyed, but the pollset works on copies \* of these registrations. So, if we destroy streams while \* processing pollset events, we might access freed memory. \*/ if (m->spurge->nelts) { c1\_purge\_streams(m); } rv = mplx\_pollset\_poll(m, timeout, on\_stream\_input, on\_stream\_output, on\_ctx);
cleanup: H2\_MPLX\_LEAVE(m); return rv;}
apr\_status\_t h2\_mplx\_c1\_reprioritize(h2\_mplx \*m, h2\_stream\_pri\_cmp\_fn \*cmp, h2\_session \*session){ apr\_status\_t status;  H2\_MPLX\_ENTER(m);
 if (m->aborted) { status = APR\_ECONNABORTED; } else { h2\_iq\_sort(m->q, cmp, session); ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_MPLX\_MSG(m, "reprioritize streams")); status = APR\_SUCCESS; }
 H2\_MPLX\_LEAVE(m); return status;}
static apr\_status\_t c1\_process\_stream(h2\_mplx \*m, h2\_stream \*stream, h2\_stream\_pri\_cmp\_fn \*cmp, h2\_session \*session){ apr\_status\_t rv = APR\_SUCCESS;
 if (m->aborted) { rv = APR\_ECONNABORTED; goto cleanup; } if (!stream->request) { rv = APR\_EINVAL; goto cleanup; } if (APLOGctrace1(m->c1)) { const h2\_request \*r = stream->request; ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_STRM\_MSG(stream, "process %s%s%s %s%s%s%s"), r->protocol? r->protocol : "", r->protocol? " " : "", r->method, r->scheme? r->scheme : "", r->scheme? "://" : "", r->authority, r->path? r->path: ""); }
 stream->scheduled = 1; h2\_ihash\_add(m->streams, stream); if (h2\_stream\_is\_ready(stream)) { /\* already have a response \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_STRM\_MSG(stream, "process, ready already")); } else { /\* last chance to set anything up before stream is processed \* by worker threads. \*/ rv = h2\_stream\_prepare\_processing(stream); if (APR\_SUCCESS != rv) goto cleanup; h2\_iq\_add(m->q, stream->id, cmp, session); ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_STRM\_MSG(stream, "process, added to q")); }
cleanup: return rv;}
void h2\_mplx\_c1\_process(h2\_mplx \*m, h2\_iqueue \*ready\_to\_process, h2\_stream\_get\_fn \*get\_stream, h2\_stream\_pri\_cmp\_fn \*stream\_pri\_cmp, h2\_session \*session, unsigned int \*pstream\_count){ apr\_status\_t rv; int sid;
 H2\_MPLX\_ENTER\_ALWAYS(m);
 while ((sid = h2\_iq\_shift(ready\_to\_process)) > 0) { h2\_stream \*stream = get\_stream(session, sid); if (stream) { ap\_assert(!stream->scheduled); rv = c1\_process\_stream(session->mplx, stream, stream\_pri\_cmp, session); if (APR\_SUCCESS != rv) { h2\_stream\_rst(stream, H2\_ERR\_INTERNAL\_ERROR); } } else { ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, m->c1, H2\_MPLX\_MSG(m, "stream %d not found to process"), sid); } } if ((m->processing\_count < m->processing\_limit) && !h2\_iq\_empty(m->q)) { H2\_MPLX\_LEAVE(m); rv = h2\_workers\_activate(m->workers, m->producer); H2\_MPLX\_ENTER\_ALWAYS(m); if (rv != APR\_SUCCESS) { ap\_log\_cerror(APLOG\_MARK, APLOG\_ERR, rv, m->c1, APLOGNO(10021) H2\_MPLX\_MSG(m, "activate at workers")); } } \*pstream\_count = h2\_ihash\_count(m->streams);
#if APR\_POOL\_DEBUG do { apr\_size\_t mem\_g, mem\_m, mem\_s, mem\_c1;
 mem\_g = pchild? apr\_pool\_num\_bytes(pchild, 1) : 0; mem\_m = apr\_pool\_num\_bytes(m->pool, 1); mem\_s = apr\_pool\_num\_bytes(session->pool, 1); mem\_c1 = apr\_pool\_num\_bytes(m->c1->pool, 1); ap\_log\_cerror(APLOG\_MARK, APLOG\_INFO, 0, m->c1, H2\_MPLX\_MSG(m, "child mem=%ld, mplx mem=%ld, session mem=%ld, c1=%ld"), (long)mem\_g, (long)mem\_m, (long)mem\_s, (long)mem\_c1);
 } while (0);#endif
 H2\_MPLX\_LEAVE(m);}
static void c2\_beam\_input\_write\_notify(void \*ctx, h2\_bucket\_beam \*beam){ conn\_rec \*c = ctx; h2\_conn\_ctx\_t \*conn\_ctx = h2\_conn\_ctx\_get(c);
 (void)beam; if (conn\_ctx && conn\_ctx->stream\_id && conn\_ctx->pipe\_in[H2\_PIPE\_IN]) { apr\_file\_putc(1, conn\_ctx->pipe\_in[H2\_PIPE\_IN]); }}
static void add\_stream\_poll\_event(h2\_mplx \*m, int stream\_id, h2\_iqueue \*q){ apr\_thread\_mutex\_lock(m->poll\_lock); if (h2\_iq\_append(q, stream\_id) && h2\_iq\_count(q) == 1) { /\* newly added first \*/ apr\_pollset\_wakeup(m->pollset); } apr\_thread\_mutex\_unlock(m->poll\_lock);}
static void c2\_beam\_input\_read\_notify(void \*ctx, h2\_bucket\_beam \*beam){ conn\_rec \*c = ctx; h2\_conn\_ctx\_t \*conn\_ctx = h2\_conn\_ctx\_get(c);
 if (conn\_ctx && conn\_ctx->stream\_id) { add\_stream\_poll\_event(conn\_ctx->mplx, conn\_ctx->stream\_id, conn\_ctx->mplx->streams\_input\_read); }}
static void c2\_beam\_input\_read\_eagain(void \*ctx, h2\_bucket\_beam \*beam){ conn\_rec \*c = ctx; h2\_conn\_ctx\_t \*conn\_ctx = h2\_conn\_ctx\_get(c); /\* installed in the input bucket beams when we use pipes. \* Drain the pipe just before the beam returns APR\_EAGAIN. \* A clean state for allowing polling on the pipe to rest \* when the beam is empty \*/ if (conn\_ctx && conn\_ctx->pipe\_in[H2\_PIPE\_OUT]) { h2\_util\_drain\_pipe(conn\_ctx->pipe\_in[H2\_PIPE\_OUT]); }}
static void c2\_beam\_output\_write\_notify(void \*ctx, h2\_bucket\_beam \*beam){ conn\_rec \*c = ctx; h2\_conn\_ctx\_t \*conn\_ctx = h2\_conn\_ctx\_get(c);
 if (conn\_ctx && conn\_ctx->stream\_id) { add\_stream\_poll\_event(conn\_ctx->mplx, conn\_ctx->stream\_id, conn\_ctx->mplx->streams\_output\_written); }}
static apr\_status\_t c2\_setup\_io(h2\_mplx \*m, conn\_rec \*c2, h2\_stream \*stream, h2\_c2\_transit \*transit){ h2\_conn\_ctx\_t \*conn\_ctx; apr\_status\_t rv = APR\_SUCCESS; const char \*action = "init";
 rv = h2\_conn\_ctx\_init\_for\_c2(&conn\_ctx, c2, m, stream, transit); if (APR\_SUCCESS != rv) goto cleanup;
 if (!conn\_ctx->beam\_out) { action = "create output beam"; rv = h2\_beam\_create(&conn\_ctx->beam\_out, c2, conn\_ctx->req\_pool, stream->id, "output", 0, c2->base\_server->timeout); if (APR\_SUCCESS != rv) goto cleanup;
 h2\_beam\_buffer\_size\_set(conn\_ctx->beam\_out, m->stream\_max\_mem); h2\_beam\_on\_was\_empty(conn\_ctx->beam\_out, c2\_beam\_output\_write\_notify, c2); }
 memset(&conn\_ctx->pipe\_in, 0, sizeof(conn\_ctx->pipe\_in)); if (stream->input) { conn\_ctx->beam\_in = stream->input; h2\_beam\_on\_send(stream->input, c2\_beam\_input\_write\_notify, c2); h2\_beam\_on\_received(stream->input, c2\_beam\_input\_read\_notify, c2); h2\_beam\_on\_consumed(stream->input, c1\_input\_consumed, stream);#if H2\_USE\_PIPES action = "create input write pipe"; rv = apr\_file\_pipe\_create\_pools(&conn\_ctx->pipe\_in[H2\_PIPE\_OUT], &conn\_ctx->pipe\_in[H2\_PIPE\_IN], APR\_READ\_BLOCK, c2->pool, c2->pool); if (APR\_SUCCESS != rv) goto cleanup;#endif h2\_beam\_on\_eagain(stream->input, c2\_beam\_input\_read\_eagain, c2); if (!h2\_beam\_empty(stream->input)) c2\_beam\_input\_write\_notify(c2, stream->input); }
cleanup: stream->output = (APR\_SUCCESS == rv)? conn\_ctx->beam\_out : NULL; if (APR\_SUCCESS != rv) { ap\_log\_cerror(APLOG\_MARK, APLOG\_ERR, rv, c2, H2\_STRM\_LOG(APLOGNO(10309), stream, "error %s"), action); } return rv;}
static conn\_rec \*s\_next\_c2(h2\_mplx \*m){ h2\_stream \*stream = NULL; apr\_status\_t rv = APR\_SUCCESS; apr\_uint32\_t sid; conn\_rec \*c2 = NULL; h2\_c2\_transit \*transit = NULL;
 while (!m->aborted && !stream && (m->processing\_count < m->processing\_limit) && (sid = h2\_iq\_shift(m->q)) > 0) { stream = h2\_ihash\_get(m->streams, sid); }
 if (!stream) { if (m->processing\_count >= m->processing\_limit && !h2\_iq\_empty(m->q)) { ap\_log\_cerror(APLOG\_MARK, APLOG\_DEBUG, 0, m->c1, H2\_MPLX\_MSG(m, "delaying request processing. " "Current limit is %d and %d workers are in use."), m->processing\_limit, m->processing\_count); } goto cleanup; }
 if (sid > m->max\_stream\_id\_started) { m->max\_stream\_id\_started = sid; }
 transit = c2\_transit\_get(m);#if AP\_HAS\_RESPONSE\_BUCKETS c2 = ap\_create\_secondary\_connection(transit->pool, m->c1, transit->bucket\_alloc);#else c2 = h2\_c2\_create(m->c1, transit->pool, transit->bucket\_alloc);#endif if (!c2) goto cleanup; ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE3, 0, m->c1, H2\_STRM\_MSG(stream, "created new c2"));
 rv = c2\_setup\_io(m, c2, stream, transit); if (APR\_SUCCESS != rv) goto cleanup;
 stream->c2 = c2; ++m->processing\_count;
cleanup: if (APR\_SUCCESS != rv && c2) { h2\_c2\_destroy(c2); c2 = NULL; } if (transit && !c2) { c2\_transit\_recycle(m, transit); } return c2;}
static conn\_rec \*c2\_prod\_next(void \*baton, int \*phas\_more){ h2\_mplx \*m = baton; conn\_rec \*c = NULL;
 H2\_MPLX\_ENTER\_ALWAYS(m); if (!m->aborted) { c = s\_next\_c2(m); \*phas\_more = (c != NULL && !h2\_iq\_empty(m->q)); } H2\_MPLX\_LEAVE(m); return c;}
static void s\_c2\_done(h2\_mplx \*m, conn\_rec \*c2, h2\_conn\_ctx\_t \*conn\_ctx){ h2\_stream \*stream;
 ap\_assert(conn\_ctx); ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, 0, c2, "h2\_mplx(%s-%d): c2 done", conn\_ctx->id, conn\_ctx->stream\_id);
 AP\_DEBUG\_ASSERT(apr\_atomic\_read32(&conn\_ctx->done) == 0); apr\_atomic\_set32(&conn\_ctx->done, 1); conn\_ctx->done\_at = apr\_time\_now(); ++c2->keepalives; /\* From here on, the final handling of c2 is done by c1 processing. \* Which means we can give it c1's scoreboard handle for updates. \*/ c2->sbh = m->c1->sbh;
 ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, c2, "h2\_mplx(%s-%d): request done, %f ms elapsed", conn\_ctx->id, conn\_ctx->stream\_id, (conn\_ctx->done\_at - conn\_ctx->started\_at) / 1000.0);  if (!conn\_ctx->has\_final\_response) { ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, conn\_ctx->last\_err, c2, "h2\_c2(%s-%d): processing finished without final response", conn\_ctx->id, conn\_ctx->stream\_id); c2->aborted = 1; if (conn\_ctx->beam\_out) h2\_beam\_abort(conn\_ctx->beam\_out, c2); } else if (!conn\_ctx->beam\_out || !h2\_beam\_is\_complete(conn\_ctx->beam\_out)) { ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE1, conn\_ctx->last\_err, c2, "h2\_c2(%s-%d): processing finished with incomplete output", conn\_ctx->id, conn\_ctx->stream\_id); c2->aborted = 1; h2\_beam\_abort(conn\_ctx->beam\_out, c2); } else if (!c2->aborted) { s\_mplx\_be\_happy(m, c2, conn\_ctx); }  stream = h2\_ihash\_get(m->streams, conn\_ctx->stream\_id); if (stream) { /\* stream not done yet. trigger a potential polling on the output \* since nothing more will happening here. \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, c2, H2\_STRM\_MSG(stream, "c2\_done, stream open")); c2\_beam\_output\_write\_notify(c2, NULL); } else if ((stream = h2\_ihash\_get(m->shold, conn\_ctx->stream\_id)) != NULL) { /\* stream is done, was just waiting for this. \*/ ap\_log\_cerror(APLOG\_MARK, APLOG\_TRACE2, 0, c2, H2\_STRM\_MSG(stream, "c2\_done, in hold")); c1c2\_stream\_joined(m, stream); } else { int i;
 for (i = 0; i < m->spurge->nelts; ++i) { if (stream == APR\_ARRAY\_IDX(m->spurge, i, h2\_stream\*)) { ap\_log\_cerror(APLOG\_MARK, APLOG\_WARNING, 0, c2, H2\_STRM\_LOG(APLOGNO(03517), stream, "already in spurge")); ap\_assert("stream should not be in spurge" == NULL);[View remainder of file in raw view](https://github.com/apache/httpd/raw/afcdbeebbff4b0c50ea26cdd16e178c0d1f24152/modules/http2/h2_mplx.c)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

