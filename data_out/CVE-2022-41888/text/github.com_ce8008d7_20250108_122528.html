
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fimage%2Fgenerate_box_proposals_op.cu.cc)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fimage%2Fgenerate_box_proposals_op.cu.cc)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  835](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
5. /[image](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels/image)
/
# generate\_box\_proposals\_op.cu.cc

 Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/master/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc)567 lines (522 loc) · 25.3 KB master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
5. /[image](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels/image)
/
# generate\_box\_proposals\_op.cu.cc

Top
## File metadata and controls

* Code
* Blame

567 lines (522 loc) · 25.3 KB[Raw](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/kernels/image/generate_box_proposals_op.cu.cc)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567/\* Copyright 2019 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#if GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM#define EIGEN\_USE\_GPU
#include <algorithm>#include <vector>
#include "unsupported/Eigen/CXX11/Tensor" // from @eigen\_archive#include "tensorflow/core/framework/numeric\_types.h"#include "tensorflow/core/framework/op\_kernel.h"#include "tensorflow/core/framework/tensor\_types.h"#include "tensorflow/core/kernels/gpu\_prim.h"#include "tensorflow/core/kernels/image/non\_max\_suppression\_op.h"#include "tensorflow/core/lib/core/errors.h"#include "tensorflow/core/platform/logging.h"#include "tensorflow/core/platform/stream\_executor.h"#include "tensorflow/core/platform/types.h"#include "tensorflow/core/util/gpu\_kernel\_helper.h"#include "tensorflow/core/util/gpu\_launch\_config.h"
namespace tensorflow {typedef Eigen::GpuDevice GPUDevice;
namespace {
// Decode d\_bbox\_deltas with respect to anchors into absolute coordinates,// clipping if necessary.// prenms\_nboxes maximum number of boxes per image to decode.// d\_boxes\_keep\_flags mask for boxes to consider in NMS.// min\_size is the lower bound of the shortest edge for the boxes to consider.// bbox\_xform\_clip is the upper bound of encoded width and height.\_\_global\_\_ void GeneratePreNMSUprightBoxesKernel( const Gpu2DLaunchConfig config, const int\* d\_sorted\_scores\_keys, const float4\* d\_bbox\_deltas, const float4\* d\_anchors, const int height, const int width, const int num\_anchors, const float min\_size, const float\* d\_img\_info\_vec, // Input "image\_info" to the op [N,5] const float bbox\_xform\_clip, float4\* d\_out\_boxes, const int prenms\_nboxes, // leading dimension of out\_boxes char\* d\_boxes\_keep\_flags) { // constants to calculate offsets in to the input and output arrays. const int anchor\_stride = height \* width; // Stride of Anchor const int height\_stride = width \* num\_anchors; // Stride of height const int image\_stride = anchor\_stride \* num\_anchors; // Stride of image CUDA\_AXIS\_KERNEL\_LOOP(image\_index, config.virtual\_thread\_count.y, Y) { CUDA\_AXIS\_KERNEL\_LOOP(ibox, config.virtual\_thread\_count.x, X) { // box\_conv\_index : # of the same box, but indexed in the // scores from the conv layer, of shape (height,width,num\_anchors) the // num\_images dimension was already removed box\_conv\_index = // a\*image\_stride + h\*width + w const int box\_conv\_index = d\_sorted\_scores\_keys[image\_index \* image\_stride + ibox];
 // We want to decompose box\_conv\_index in (h,w,a) // such as box\_conv\_index = h\*width\*num\_anchors + width\*num\_anchors + a // (avoiding modulos in the process) int remaining = box\_conv\_index; const int delta\_height = height\_stride; // stride of height const int h = remaining / delta\_height; remaining -= h \* delta\_height; const int delta\_width = num\_anchors; // stride of width const int w = remaining / delta\_width; remaining -= w \* delta\_width; // Loading the anchor a // float4 is a struct with float x,y,z,w const float4 anchor = d\_anchors[box\_conv\_index]; // x1,y1,x2,y2 :coordinates of anchor a, shifted for position (h,w) float x1 = anchor.y; float x2 = anchor.w; float y1 = anchor.x; float y2 = anchor.z;
 // TODO use fast math when possible
 // Deltas of shape (N,height,width,num\_anchors x 4) int deltas\_idx = box\_conv\_index + image\_index \* image\_stride; float4 deltas = d\_bbox\_deltas[deltas\_idx]; float dx = deltas.y; float dy = deltas.x; float dw = deltas.w; float dh = deltas.z; // Upper bound on dw,dh dw = fmin(dw, bbox\_xform\_clip); dh = fmin(dh, bbox\_xform\_clip);
 // Applying the deltas float width = x2 - x1; const float ctr\_x = x1 + 0.5f \* width; const float pred\_ctr\_x = ctr\_x + width \* dx; // TODO fuse madd const float pred\_w = width \* expf(dw); x1 = pred\_ctr\_x - 0.5f \* pred\_w; x2 = pred\_ctr\_x + 0.5f \* pred\_w;
 float height = y2 - y1; const float ctr\_y = y1 + 0.5f \* height; const float pred\_ctr\_y = ctr\_y + height \* dy; const float pred\_h = height \* expf(dh); y1 = pred\_ctr\_y - 0.5f \* pred\_h; y2 = pred\_ctr\_y + 0.5f \* pred\_h;
 // Clipping box to image const float img\_height = d\_img\_info\_vec[5 \* image\_index + 0]; const float img\_width = d\_img\_info\_vec[5 \* image\_index + 1]; const float min\_size\_scaled = min\_size \* d\_img\_info\_vec[5 \* image\_index + 2]; x1 = fmax(fmin(x1, img\_width), 0.0f); y1 = fmax(fmin(y1, img\_height), 0.0f); x2 = fmax(fmin(x2, img\_width), 0.0f); y2 = fmax(fmin(y2, img\_height), 0.0f);
 // Filter boxes // Removing boxes with one dim < min\_size // (center of box is in image, because of previous step) width = x2 - x1; // may have changed height = y2 - y1; bool keep\_box = fmin(width, height) >= min\_size\_scaled;
 // We are not deleting the box right now even if !keep\_box // we want to keep the relative order of the elements stable // we'll do it in such a way later // d\_boxes\_keep\_flags size: (num\_images,prenms\_nboxes) // d\_out\_boxes size: (num\_images,prenms\_nboxes) const int out\_index = image\_index \* prenms\_nboxes + ibox;
 d\_boxes\_keep\_flags[out\_index] = keep\_box; d\_out\_boxes[out\_index] = {x1, y1, x2, y2}; } }}
// Copy the selected boxes and scores to output tensors.//\_\_global\_\_ void WriteUprightBoxesOutput( const GpuLaunchConfig nboxes, const float4\* d\_image\_boxes, const float\* d\_image\_scores, const int\* d\_image\_boxes\_keep\_list, const int n\_rois, float\* d\_image\_out\_rois, float\* d\_image\_out\_rois\_probs) { CUDA\_1D\_KERNEL\_LOOP(i, nboxes.virtual\_thread\_count) { if (i < n\_rois) { // copy rois to output const int ibox = d\_image\_boxes\_keep\_list[i]; const float4 box = d\_image\_boxes[ibox]; const float score = d\_image\_scores[ibox]; // Scattered memory accesses // postnms\_nboxes is small anyway d\_image\_out\_rois\_probs[i] = score; const int base\_idx = 4 \* i; d\_image\_out\_rois[base\_idx + 0] = box.y; d\_image\_out\_rois[base\_idx + 1] = box.x; d\_image\_out\_rois[base\_idx + 2] = box.w; d\_image\_out\_rois[base\_idx + 3] = box.z; } else { // set trailing entries to 0 d\_image\_out\_rois\_probs[i] = 0.; const int base\_idx = 4 \* i; d\_image\_out\_rois[base\_idx + 0] = 0.; d\_image\_out\_rois[base\_idx + 1] = 0.; d\_image\_out\_rois[base\_idx + 2] = 0.; d\_image\_out\_rois[base\_idx + 3] = 0.; } }}
template <typename T>Status ResetTensor(Tensor\* t, const Eigen::GpuDevice& d) { GpuLaunchConfig zconfig = GetGpuLaunchConfig(t->NumElements(), d); return GpuLaunchKernel(SetZero<T>, zconfig.block\_count, zconfig.thread\_per\_block, 0, d.stream(), zconfig.virtual\_thread\_count, (\*t).flat<T>().data());}// Allocate scratch spaces that are needed for operation//
Status AllocateGenerationTempTensors( OpKernelContext\* context, Tensor\* d\_conv\_layer\_indexes, Tensor\* d\_image\_offset, Tensor\* d\_cub\_temp\_buffer, Tensor\* d\_sorted\_conv\_layer\_indexes, Tensor\* d\_sorted\_scores, Tensor\* dev\_boxes, Tensor\* dev\_boxes\_keep\_flags, int num\_images, int conv\_layer\_nboxes, size\_t cub\_temp\_storage\_bytes, int num\_boxes\_to\_generate, int box\_dim) { auto d = context->eigen\_gpu\_device(); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT32, TensorShape({num\_images, conv\_layer\_nboxes}), d\_conv\_layer\_indexes)); TF\_RETURN\_IF\_ERROR(ResetTensor<int>(d\_conv\_layer\_indexes, d)); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT32, TensorShape({num\_images + 1}), d\_image\_offset)); TF\_RETURN\_IF\_ERROR(ResetTensor<int>(d\_image\_offset, d)); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT8, TensorShape({(int64)cub\_temp\_storage\_bytes}), d\_cub\_temp\_buffer)); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT32, TensorShape({num\_images, conv\_layer\_nboxes}), d\_sorted\_conv\_layer\_indexes)); TF\_RETURN\_IF\_ERROR(ResetTensor<int32>(d\_sorted\_conv\_layer\_indexes, d)); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_FLOAT, TensorShape({num\_images, conv\_layer\_nboxes}), d\_sorted\_scores)); TF\_RETURN\_IF\_ERROR(ResetTensor<float>(d\_sorted\_scores, d)); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_FLOAT, TensorShape({num\_images, box\_dim \* num\_boxes\_to\_generate}), dev\_boxes)); TF\_RETURN\_IF\_ERROR(ResetTensor<float>(dev\_boxes, d)); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT8, TensorShape({num\_images, num\_boxes\_to\_generate}), dev\_boxes\_keep\_flags)); TF\_RETURN\_IF\_ERROR(ResetTensor<int8>(dev\_boxes\_keep\_flags, d)); return OkStatus();}
// Allocate workspace for NMS operationStatus AllocatePreNMSTempTensors( OpKernelContext\* context, Tensor\* dev\_image\_prenms\_boxes, Tensor\* dev\_image\_prenms\_scores, Tensor\* dev\_image\_boxes\_keep\_list, Tensor\* dev\_postnms\_rois, Tensor\* dev\_postnms\_rois\_probs, Tensor\* dev\_prenms\_nboxes, int num\_images, int num\_boxes\_to\_generate, int box\_dim, int post\_nms\_topn, int pre\_nms\_topn) { auto d = context->eigen\_gpu\_device(); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_FLOAT, TensorShape({box\_dim \* num\_boxes\_to\_generate}), dev\_image\_prenms\_boxes)); TF\_RETURN\_IF\_ERROR(ResetTensor<float>(dev\_image\_prenms\_boxes, d));
 TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_FLOAT, TensorShape({num\_boxes\_to\_generate}), dev\_image\_prenms\_scores)); TF\_RETURN\_IF\_ERROR(ResetTensor<float>(dev\_image\_prenms\_scores, d));
 TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT32, TensorShape({num\_boxes\_to\_generate}), dev\_image\_boxes\_keep\_list)); TF\_RETURN\_IF\_ERROR(ResetTensor<int32>(dev\_image\_boxes\_keep\_list, d));
 const int max\_postnms\_nboxes = std::min(num\_boxes\_to\_generate, post\_nms\_topn); TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_FLOAT, TensorShape({box\_dim \* num\_images \* max\_postnms\_nboxes}), dev\_postnms\_rois)); TF\_RETURN\_IF\_ERROR(ResetTensor<float>(dev\_postnms\_rois, d));
 TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_FLOAT, TensorShape({num\_images \* max\_postnms\_nboxes}), dev\_postnms\_rois\_probs)); TF\_RETURN\_IF\_ERROR(ResetTensor<float>(dev\_postnms\_rois\_probs, d));
 TF\_RETURN\_IF\_ERROR(context->allocate\_temp( DataType::DT\_INT32, TensorShape({num\_images}), dev\_prenms\_nboxes)); TF\_RETURN\_IF\_ERROR(ResetTensor<int32>(dev\_prenms\_nboxes, d));
 return OkStatus();}
// Initialize index and offset arrays.// num\_images is the batch size.\_\_global\_\_ void InitializeDataKernel(const Gpu2DLaunchConfig config, int\* d\_image\_offsets, int\* d\_boxes\_keys\_iota) { const int image\_size = config.virtual\_thread\_count.x; const int num\_images = config.virtual\_thread\_count.y; CUDA\_AXIS\_KERNEL\_LOOP(img\_idx, config.virtual\_thread\_count.y, Y) { CUDA\_AXIS\_KERNEL\_LOOP(box\_idx, config.virtual\_thread\_count.x, X) { d\_boxes\_keys\_iota[img\_idx \* image\_size + box\_idx] = box\_idx;
 // One 1D line sets the 1D data if (box\_idx == 0) { d\_image\_offsets[img\_idx] = image\_size \* img\_idx; // One thread sets the last+1 offset if (img\_idx == 0) d\_image\_offsets[num\_images] = image\_size \* num\_images; } } }}
} // namespace
class GenerateBoundingBoxProposals : public tensorflow::OpKernel { public: explicit GenerateBoundingBoxProposals( tensorflow::OpKernelConstruction\* context) : OpKernel(context) { OP\_REQUIRES\_OK(context, context->GetAttr("post\_nms\_topn", &post\_nms\_topn\_)); OP\_REQUIRES(context, post\_nms\_topn\_ > 0, errors::InvalidArgument("post\_nms\_topn can't be 0 or less")); bbox\_xform\_clip\_default\_ = log(1000.0 / 16.); }
 template <typename T> Status GetScalarValue(OpKernelContext\* context, int input, T\* value) { const Tensor& scalar\_tensor = context->input(input); if (!TensorShapeUtils::IsScalar(scalar\_tensor.shape())) { return errors::InvalidArgument("Expected a scalar in input ", input, "but got shape ", scalar\_tensor.shape().DebugString()); } \*value = scalar\_tensor.scalar<T>()(); return OkStatus(); }
 void Compute(tensorflow::OpKernelContext\* context) override { VLOG(1) << "Starting Compute " << name(); const auto scores = context->input(0); const auto bbox\_deltas = context->input(1); const auto image\_info = context->input(2); const auto anchors = context->input(3);
 OP\_REQUIRES(context, scores.dims() == 4, errors::InvalidArgument("`scores` must be rank 4 but is rank ", scores.dims())); OP\_REQUIRES( context, bbox\_deltas.dims() == 4, errors::InvalidArgument("`bbox\_deltas` must be rank 4 but is rank ", bbox\_deltas.dims())); OP\_REQUIRES( context, image\_info.dims() == 2, errors::InvalidArgument("`image\_info` must be rank 2 but is rank ", image\_info.dims())); OP\_REQUIRES(context, anchors.dims() == 3, errors::InvalidArgument("`anchors` must be rank 3 but is rank ", anchors.dims()));
 const auto num\_images = scores.dim\_size(0); const auto num\_anchors = scores.dim\_size(3); const auto height = scores.dim\_size(1); const auto width = scores.dim\_size(2); const auto box\_dim = anchors.dim\_size(2) / num\_anchors; OP\_REQUIRES(context, box\_dim == 4, errors::OutOfRange("Box dimensions need to be 4")); // TODO(skama): make sure that inputs are ok. const int image\_stride = height \* width; const int conv\_layer\_nboxes = image\_stride \* num\_anchors; // total number of boxes when decoded on anchors. // The following calls to CUB primitives do nothing // (because the first arg is nullptr) // except setting cub\_\*\_temp\_storage\_bytes float nms\_threshold; int pre\_nms\_topn; float min\_size; OP\_REQUIRES\_OK(context, GetScalarValue(context, 4, &nms\_threshold)); if (nms\_threshold < 0 || nms\_threshold > 1.0) { context->SetStatus(errors::InvalidArgument( "nms\_threshold should be between 0 and 1. Got ", nms\_threshold)); return; } OP\_REQUIRES\_OK(context, GetScalarValue(context, 5, &pre\_nms\_topn)); if (pre\_nms\_topn <= 0) { context->SetStatus(errors::InvalidArgument( "pre\_nms\_topn should be greater than 0", pre\_nms\_topn)); return; } OP\_REQUIRES\_OK(context, GetScalarValue(context, 6, &min\_size)); auto cuda\_stream = GetGpuStream(context); size\_t cub\_sort\_temp\_storage\_bytes = 0; float\* flt\_ptr = nullptr; int\* int\_ptr = nullptr; cudaError\_t cuda\_ret = gpuprim::DeviceSegmentedRadixSort::SortPairsDescending( nullptr, cub\_sort\_temp\_storage\_bytes, flt\_ptr, flt\_ptr, int\_ptr, int\_ptr, num\_images \* conv\_layer\_nboxes, num\_images, int\_ptr, int\_ptr, 0, 8 \* sizeof(float), // sort all bits cuda\_stream); TF\_OP\_REQUIRES\_CUDA\_SUCCESS(context, cuda\_ret); // get the size of select temp buffer size\_t cub\_select\_temp\_storage\_bytes = 0; char\* char\_ptr = nullptr; float4\* f4\_ptr = nullptr; TF\_OP\_REQUIRES\_CUDA\_SUCCESS( context, gpuprim::DeviceSelect::Flagged( nullptr, cub\_select\_temp\_storage\_bytes, f4\_ptr, char\_ptr, f4\_ptr, int\_ptr, image\_stride \* num\_anchors, cuda\_stream)); Tensor d\_conv\_layer\_indexes; // box indices on device Tensor d\_image\_offset; // starting offsets boxes for each image Tensor d\_cub\_temp\_buffer; // buffer for cub sorting Tensor d\_sorted\_conv\_layer\_indexes; // output of cub sorting, indices of // the sorted boxes Tensor dev\_sorted\_scores; // sorted scores, cub output Tensor dev\_boxes; // boxes on device Tensor dev\_boxes\_keep\_flags; // bitmask for keeping the boxes or rejecting // from output const int nboxes\_to\_generate = std::min(conv\_layer\_nboxes, pre\_nms\_topn); size\_t cub\_temp\_storage\_bytes = std::max(cub\_sort\_temp\_storage\_bytes, cub\_select\_temp\_storage\_bytes); OP\_REQUIRES\_OK( context, AllocateGenerationTempTensors( context, &d\_conv\_layer\_indexes, &d\_image\_offset, &d\_cub\_temp\_buffer, &d\_sorted\_conv\_layer\_indexes, &dev\_sorted\_scores, &dev\_boxes, &dev\_boxes\_keep\_flags, num\_images, conv\_layer\_nboxes, cub\_temp\_storage\_bytes, nboxes\_to\_generate, box\_dim)); const GPUDevice& d = context->eigen\_device<GPUDevice>(); Gpu2DLaunchConfig conf2d = GetGpu2DLaunchConfig(conv\_layer\_nboxes, num\_images, d); // create box indices and offsets for each image on device OP\_REQUIRES\_OK( context, GpuLaunchKernel(InitializeDataKernel, conf2d.block\_count, conf2d.thread\_per\_block, 0, d.stream(), conf2d, d\_image\_offset.flat<int>().data(), d\_conv\_layer\_indexes.flat<int>().data()));
 // sort boxes with their scores. // d\_sorted\_conv\_layer\_indexes will hold the pointers to old indices. TF\_OP\_REQUIRES\_CUDA\_SUCCESS( context, gpuprim::DeviceSegmentedRadixSort::SortPairsDescending( d\_cub\_temp\_buffer.flat<int8>().data(), cub\_temp\_storage\_bytes, scores.flat<float>().data(), dev\_sorted\_scores.flat<float>().data(), d\_conv\_layer\_indexes.flat<int>().data(), d\_sorted\_conv\_layer\_indexes.flat<int>().data(), num\_images \* conv\_layer\_nboxes, num\_images, d\_image\_offset.flat<int>().data(), d\_image\_offset.flat<int>().data() + 1, 0, 8 \* sizeof(float), // sort all bits cuda\_stream)); // Keeping only the topN pre\_nms conf2d = GetGpu2DLaunchConfig(nboxes\_to\_generate, num\_images, d);
 // create box y1,x1,y2,x2 from box\_deltas and anchors (decode the boxes) and // mark the boxes which are smaller that min\_size ignored. OP\_REQUIRES\_OK( context, GpuLaunchKernel( GeneratePreNMSUprightBoxesKernel, conf2d.block\_count, conf2d.thread\_per\_block, 0, d.stream(), conf2d, d\_sorted\_conv\_layer\_indexes.flat<int>().data(), reinterpret\_cast<const float4\*>(bbox\_deltas.flat<float>().data()), reinterpret\_cast<const float4\*>(anchors.flat<float>().data()), height, width, num\_anchors, min\_size, image\_info.flat<float>().data(), bbox\_xform\_clip\_default\_, reinterpret\_cast<float4\*>(dev\_boxes.flat<float>().data()), nboxes\_to\_generate, (char\*)dev\_boxes\_keep\_flags.flat<int8>().data())); const int nboxes\_generated = nboxes\_to\_generate; const int roi\_cols = box\_dim; Tensor dev\_image\_prenms\_boxes; Tensor dev\_image\_prenms\_scores; Tensor dev\_image\_boxes\_keep\_list; Tensor dev\_postnms\_rois; Tensor dev\_postnms\_rois\_probs; Tensor dev\_prenms\_nboxes; // Allocate workspaces needed for NMS OP\_REQUIRES\_OK( context, AllocatePreNMSTempTensors( context, &dev\_image\_prenms\_boxes, &dev\_image\_prenms\_scores, &dev\_image\_boxes\_keep\_list, &dev\_postnms\_rois, &dev\_postnms\_rois\_probs, &dev\_prenms\_nboxes, num\_images, nboxes\_generated, box\_dim, post\_nms\_topn\_, pre\_nms\_topn)); // get the pointers for temp storages int\* d\_prenms\_nboxes = dev\_prenms\_nboxes.flat<int>().data(); int h\_prenms\_nboxes = 0; char\* d\_cub\_temp\_storage = (char\*)d\_cub\_temp\_buffer.flat<int8>().data(); float\* d\_image\_prenms\_boxes = dev\_image\_prenms\_boxes.flat<float>().data(); float\* d\_image\_prenms\_scores = dev\_image\_prenms\_scores.flat<float>().data(); int\* d\_image\_boxes\_keep\_list = dev\_image\_boxes\_keep\_list.flat<int>().data();
 int nrois\_in\_output = 0; // get the pointers to boxes and scores char\* d\_boxes\_keep\_flags = (char\*)dev\_boxes\_keep\_flags.flat<int8>().data(); float\* d\_boxes = dev\_boxes.flat<float>().data(); float\* d\_sorted\_scores = dev\_sorted\_scores.flat<float>().data();
 // Create output tensors Tensor\* output\_rois = nullptr; Tensor\* output\_roi\_probs = nullptr; OP\_REQUIRES\_OK(context, context->allocate\_output( 0, TensorShape({num\_images, post\_nms\_topn\_, roi\_cols}), &output\_rois)); OP\_REQUIRES\_OK(context, context->allocate\_output( 1, TensorShape({num\_images, post\_nms\_topn\_}), &output\_roi\_probs)); float\* d\_postnms\_rois = (\*output\_rois).flat<float>().data(); float\* d\_postnms\_rois\_probs = (\*output\_roi\_probs).flat<float>().data(); gpuEvent\_t copy\_done; gpuEventCreate(&copy\_done);
 // Do per-image nms for (int image\_index = 0; image\_index < num\_images; ++image\_index) { // reset output workspaces OP\_REQUIRES\_OK(context, ResetTensor<int32>(&dev\_image\_boxes\_keep\_list, d)); // Sub matrices for current image // boxes const float\* d\_image\_boxes = &d\_boxes[image\_index \* nboxes\_generated \* box\_dim]; // scores const float\* d\_image\_sorted\_scores = &d\_sorted\_scores[image\_index \* image\_stride \* num\_anchors]; // keep flags char\* d\_image\_boxes\_keep\_flags = &d\_boxes\_keep\_flags[image\_index \* nboxes\_generated];
 // Output buffer for image float\* d\_image\_postnms\_rois = &d\_postnms\_rois[image\_index \* roi\_cols \* post\_nms\_topn\_]; float\* d\_image\_postnms\_rois\_probs = &d\_postnms\_rois\_probs[image\_index \* post\_nms\_topn\_];
 // Moving valid boxes (ie the ones with d\_boxes\_keep\_flags[ibox] == true) // to the output tensors TF\_OP\_REQUIRES\_CUDA\_SUCCESS( context, gpuprim::DeviceSelect::Flagged( d\_cub\_temp\_storage, cub\_temp\_storage\_bytes, reinterpret\_cast<const float4\*>(d\_image\_boxes), d\_image\_boxes\_keep\_flags, reinterpret\_cast<float4\*>(d\_image\_prenms\_boxes), d\_prenms\_nboxes, nboxes\_generated, d.stream())); TF\_OP\_REQUIRES\_CUDA\_SUCCESS( context, gpuprim::DeviceSelect::Flagged( d\_cub\_temp\_storage, cub\_temp\_storage\_bytes, d\_image\_sorted\_scores, d\_image\_boxes\_keep\_flags, d\_image\_prenms\_scores, d\_prenms\_nboxes, nboxes\_generated, d.stream())); d.memcpyDeviceToHost(&h\_prenms\_nboxes, d\_prenms\_nboxes, sizeof(int)); TF\_OP\_REQUIRES\_CUDA\_SUCCESS(context, gpuEventRecord(copy\_done, d.stream())); TF\_OP\_REQUIRES\_CUDA\_SUCCESS(context, gpuEventSynchronize(copy\_done)); // We know prenms\_boxes <= topN\_prenms, because nboxes\_generated <= // topN\_prenms. Calling NMS on the generated boxes const int prenms\_nboxes = h\_prenms\_nboxes; int nkeep; OP\_REQUIRES\_OK(context, NmsGpu(d\_image\_prenms\_boxes, prenms\_nboxes, nms\_threshold, d\_image\_boxes\_keep\_list, &nkeep, context, post\_nms\_topn\_)); // All operations done after previous sort were keeping the relative order // of the elements the elements are still sorted keep topN <=> truncate // the array const int postnms\_nboxes = std::min(nkeep, post\_nms\_topn\_); // Moving the out boxes to the output tensors, // adding the image\_index dimension on the fly GpuLaunchConfig config = GetGpuLaunchConfig(post\_nms\_topn\_, d); // make this single kernel OP\_REQUIRES\_OK( context, GpuLaunchKernel(WriteUprightBoxesOutput, config.block\_count, config.thread\_per\_block, 0, d.stream(), config, reinterpret\_cast<const float4\*>(d\_image\_prenms\_boxes), d\_image\_prenms\_scores, d\_image\_boxes\_keep\_list, postnms\_nboxes, d\_image\_postnms\_rois, d\_image\_postnms\_rois\_probs)); nrois\_in\_output += postnms\_nboxes; TF\_OP\_REQUIRES\_CUDA\_SUCCESS(context, cudaGetLastError()); } }
 private: int post\_nms\_topn\_; float bbox\_xform\_clip\_default\_;};
REGISTER\_KERNEL\_BUILDER(Name("GenerateBoundingBoxProposals") .Device(tensorflow::DEVICE\_GPU) .HostMemory("nms\_threshold") .HostMemory("min\_size") .HostMemory("pre\_nms\_topn"), tensorflow::GenerateBoundingBoxProposals);} // namespace tensorflow#endif

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

