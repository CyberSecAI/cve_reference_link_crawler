=== Content from jovanbulck.github.io_43fb3aa6_20250110_142501.html ===
Pandora: Principled Symbolic Validation of Intel SGX Enclave Runtimes

Fritz Alder1, Lesly-Ann Daniel1, David Oswald2, Frank Piessens1, and Jo Van Bulck1

1DistriNet, KU Leuven, Belgium, 2University of Birmingham, UK

Abstract—The popularity of Intel SGX technology in recent
years has given rise to a wide range of shielding runtimes to
transparently safeguard secure enclave applications against a
hostile operating system. Adequate validation of the crucial and
numerous shielding runtimes is, however, a multi-faceted and
fast-changing challenge, as new attack techniques against SGX
enclaves are discovered regularly and commonly necessitate
extensive software patches throughout the SGX ecosystem.

This paper proposes Pandora, a practical, enclave-aware
symbolic execution tool designed to address this challenge.
In contrast to existing tools, Pandora’s truthful and runtime-
agnostic symbolic execution of the exact attested enclave binary
for the first time allows to validate the critical enclave shield-
ing runtime itself. Furthermore, Pandora provides principled
foundations to deal with the moving-target nature of enclave
software security by implementing accurate taint tracking of
attacker inputs, a precise symbolic enclave memory model, and
support for pluggable vulnerability detectors.

We extensively evaluate Pandora on 11 different SGX
shielding runtimes with 4 detection plugins for a diverse set
of vulnerability types. Our experiments show that Pandora
can autonomously discover 200 new and 69 known vulnerable
code locations. Notably, Pandora is the first tool that allows a
wide-scale ecosystem investigation of recent pointer-alignment
software mitigations in real-world SGX enclave runtimes.

1. Introduction

Recent years have seen the rise of trusted execution
environments (TEEs) that provide strong, hardware-rooted
protection of small software components, called enclaves,
against hostile, possibly attacker-controlled system soft-
ware. With the release of the Software Guard Extensions
(SGX) [1], [2], included in selected Intel processors from
2015 onwards, TEE protection is readily available in today’s
mainstream computing platforms, and even more recent
technology, like the Trust Domain Extensions (TDX) [3] for
upcoming Intel server processors, continues to rely critically
on SGX enclaves. Thus, the widespread availability of SGX
has boosted ongoing interest in enclave applications and
limitations from both industry and academia.

While SGX hardware enforces that enclave memory can-
not be accessed from the outside, enclave software remains
ultimately responsible to be bug-free and should properly
sanitize registers and pointer arguments in the shared ad-
dress space. This non-trivial requirement has given rise to

a sizable ecosystem of SGX shielding runtimes that sup-
port diverse enclave applications. Modern SGX development
paradigms nowadays include (i) custom C/C++ software de-
velopment kits (SDKs) [4], [5] that directly expose a secure
function call abstraction; (ii) numerous SGX-tailored library
operating systems (libOSs) [6]–[10] to support lift-and-shift
protection of existing legacy applications; and (iii) enclaved
memory-safe language runtimes [11]–[14].

The popularity of Intel SGX has, furthermore, triggered
a long and ongoing line of attacks exploring limitations of
this technology [15]. In this respect, a clear trend has been
that, while some of the earlier SGX attacks [16]–[20] could
still be mitigated fully transparently at the hardware level
by means of CPU microcode patches, progressively more
stringent demands have been placed on enclave software
behavior to mitigate evermore specific vulnerabilities [20]–
[27] when interacting with the untrusted environment. This
has increasingly made secure enclave software development,
and especially the sanitization responsibilities for the numer-
ous SGX shielding runtimes, a moving target (cf. Section 2).
While software mitigations for transient-execution and
side-channel attacks have been widely studied for Intel
SGX, and presently various compiler-based solutions [24],
[28]–[33] exist, the crucial aspect of validating the security
of the enclave interface has received much less attention.
Researchers have only recently started to explore more sys-
tematic analyses through fuzzing [34]–[36] or symbolic exe-
cution [37]–[39]. However, existing approaches fall short in
that they focus on validating enclave application logic only,
without considering vulnerabilities in the crucial shielding
runtime, or even being compatible with diverse runtimes
beyond Intel’s SGX SDK. Furthermore, existing approaches
focus mainly on detecting memory-safety issues, without
considering more subtle types of shielding responsibilities,
such as untrusted pointer alignments [25], [26] and CPU
register sanitizations [21], [22], [27]. These approaches,
hence, are not fitted for the diverse and fast-changing SGX
software ecosystem, where a subtle sanitization oversight in
a shielding runtime may be the equivalent of a zero-day
rootkit vulnerability in a commodity OS kernel.

To address these challenges, the main objective of our
work is the development of a principled, tool-supported
approach to validate the security of enclave software binaries
using symbolic execution. We propose Pandora, an exten-
sible, enclave-aware symbolic execution tool that is built
upon the popular angr framework and extends it with several
technical contributions. Particularly, we accurately
novel

implement missing, SGX-specific x86 semantics, conceive a
proficient, enclave-aware symbolic memory model, and de-
velop a generic enclave memory extractor. Thus, Pandora for
the first time enables truthful and runtime-agnostic symbolic
exploration of full enclave binaries, identical to the attested
initial memory layout and including the crucial shielding
runtime itself. Furthermore, to deal with the moving-target
nature of secure enclave software development, we propose
pluggable vulnerability detectors, extending the notion of
angr breakpoints with SGX-specific memory-access and
control-flow events that allow rapid scripting of powerful
Pandora plugins.

Our extensive experimental evaluation on 11 different
shielding runtimes from research and industry, with 4 plu-
gins validating diverse sanitizations, highlights the delicacy
and complexity of present SGX software responsibilities.
We demonstrate the power of Pandora’s truthful symbolic
execution semantics by identifying several subtle vulnera-
bilities in commonly overlooked low-level enclave initializa-
tion and relocation code that cannot be analyzed with state-
of-the-art enclave symbolic-execution tools. We, further-
more, are the first to construct an automated tool for wide-
scale validation of intricate untrusted pointer-alignment soft-
ware mitigations [26], [40] recently deployed throughout the
SGX ecosystem in response to ÆPIC [25] attacks.

In the wider research landscape, we envision our open-
source tool as a solid foundation to enable future science on
validating the security of enclaved software, including low-
level and fast-changing SGX software shielding runtimes.

Contributions. In summary, our contributions are:

• We propose Pandora, an extensible, enclave-aware
symbolic execution framework for truthful and prin-
cipled validation of SGX binaries.

• Responding to the heterogeneity of the emerging SGX
software landscape, we propose a universal enclave
memory extractor and corresponding angr loader.

• Responding to the volatile and elusive SGX software
responsibilities, we propose pluggable detectors for
diverse vulnerabilities, from validating CPU register
cleansing over untrusted pointer sanitization and align-
ment constraints to control-flow transitions.

• In an extensive experimental evaluation on 11 different
SGX runtimes, Pandora autonomously confirmed 69
known and 200 new vulnerable code locations.

Disclosure and Artifacts. We responsibly disclosed all
findings to the respective vendors (tracked via 7 CVEs), pro-
viding them with comprehensive reports from our tool. We,
furthermore, included recommendations for software miti-
gations and assisted in validating the applied fixes, which
has uncovered remaining issues in at least one runtime.

In the spirit of open science, we provide a comprehen-
sive open-source artifact1 with self-contained HTML reports
of all vulnerabilities from Table 2, multiple runtimes to test
out Pandora, and documentation of how to reproduce our

1. Available at https://github.com/pandora-tee.

Figure 1. A shielding runtime transparently protects enclave applications
by 1 cleansing CPU registers upon entry or exit events; 2 finalizing
the initial memory layout, including any in-enclave relocations, upon first
entry; and 3 sanitizing pointer arguments before handing control over to
the application, which can call back via trusted standard library functions.

results. The artifact also includes the binaries of analyzed
shielding runtime versions (where allowed by licensing)
to provide a representative public data set of vulnerable
enclaves that can serve as a baseline for future research.

2. Background and Related Work

Enclave Shielding. Due to its strong attacker model, en-
clave software faces several additional security challenges
compared to traditional user-space software. In current prac-
tice, these additional challenges are primarily handled by a
shielding runtime that transparently intervenes on interac-
tions with the untrusted environment, as shown in Fig. 1.

Intel SGX enclaves are embedded as a contiguous vir-
tual address region within an untrusted, surrounding host
application. As in-enclave software is allowed to freely
dereference outside memory locations, the host application
can efficiently communicate through the enclave’s applica-
tion programming interface (API) by passing pointers to
arguments and return values in the shared virtual address
space. However, this also opens the door to an especially
powerful class of confused-deputy attacks, necessitating
that the enclave shielding runtime adequately sanitizes any
attacker-provided API pointers prior to dereference. Despite
this requirement being well-known and the availability of
automated methods—such as the edger8r tool to automat-
ically generate interface sanitization code from developer
annotations in the Intel SGX-SDK [4] and Open Enclave [5],
or the Rust type system leveraged in EDP [11]—a continu-
ous stream of vulnerabilities [21], [34], [37]–[39] has proven
SGX pointer sanitization vulnerabilities to be particularly
elusive and widespread in practice. As an example, Listing 1
illustrates how adequately sanitizing an elementary pointer-
to-pointer argument can be non-trivial in practice.

to the

Moreover,

in response

recently disclosed
ÆPIC [25] and related memory-mapped I/O (MMIO) [26]
stale data vulnerabilities in Intel processors, enclave soft-
ware requirements for sanitizing untrusted pointer arguments
have been considerably complicated. That is, not only does
enclave software nowadays need to ensure that attacker-
provided pointers properly fall entirely outside the protected
enclave range, but any subsequent pointer dereferences also
need to proceed at a certain alignment and size or need to be
preceded and followed by fragile x86 instruction sequences

EnclaveBoundaryEnclave RuntimeEntryExitApplicationRuntimelibraryInitEENTERvoid encl_get_from_addr(struct user_arg *op) {

assert(is_outside_enclave(op, sizeof(*op)));
// Copy op->addr to avoid TOCTOU attacks
volatile char* ptr = (char*) op->addr;
assert(is_outside_enclave(ptr, 1));
g_state = *ptr; }

Listing 1. Example of API sanitization: the highlighted lines enforce that
all attacker-controlled pointers lie outside the enclave prior to dereference.

the CPU
to cleanse microarchitectural buffers and stall
pipeline. These successive refinements of software respon-
sibilities hence necessitated extensive and ongoing changes
throughout the heterogeneous SGX software ecosystem.

A parallel moving-target evolution can be observed at
the level of the application binary interface (ABI). An
initial comprehensive study [21] has shown that secure
initialization was widely overlooked for certain crucial CPU
configuration flags, such as the x86 direction flag that
may introduce memory-safety violations in otherwise secure
code. Similar issues have since been shown for stack-pointer
initialization in SGX enclave exception handlers [23] and
for x87 and SSE floating-point configuration registers [22].
The latter was most recently refined once again in an Intel
advisory [27] with additional SSE sanitizations to protect
against certain operand-dependent floating-point instruction
timing channels in otherwise constant-time code. A recent
overview study [41] has documented how these ABI vulner-
ability disclosures necessitated several rounds of widespread
patches throughout popular SGX shielding runtimes.

Symbolic Execution. Symbolic execution [42] statically
interprets a program using symbolic inputs (i.e., mathe-
matical terms) and collects constraints (i.e., mathematical
formulas over these terms) encoding programs paths. These
constraints can be solved with an SMT solver to generate
concrete inputs exercising the path or check security as-
sertions. Its ability to systematically explore program paths
and generate concrete inputs has made symbolic execution
a tool of choice for intensive testing [43] and vulnerability
analysis [44]. More recently, researchers have also started
to apply symbolic execution to the specific context of Intel
SGX enclaves [37]–[39]. We provide an extensive compari-
son of Pandora to these existing tools in Section 3.1. Some
works [20], [45] have, furthermore, focused on detecting
microarchitectural side-channel vulnerabilities in enclave
applications using symbolic execution, but their goal is or-
thogonal to our scope of validating shielding responsibilities.

Fuzzing. A well-known, complementary approach to static
analysis via symbolic execution is dynamic concrete ex-
ecution via fuzz testing. An orthogonal and concurrent
line of work [34], [35], [46], [47] has started to explore
such fuzzing for Intel SGX enclave applications. Compared
to symbolic execution, fuzzing can more easily scale to
complex code bases by quickly generating test cases and
may find bugs with fewer false positives. However, unlike
symbolic execution, fuzzing requires carefully crafted test
cases to investigate convoluted execution paths. Hence, in

line with existing surveys [48], [49], we regard fuzzing-
based approaches as complementary to symbolic validation.

3. Problem Statement and Overview

The combination of a varied and evolving Intel SGX
runtime ecosystem with the frequent discovery of new attack
techniques that necessitate additional software sanitizations
makes the problem of principled enclave software validation
particularly challenging and, indeed, largely unexplored for
the fundamental shielding runtimes themselves. Therefore,
we set the following goals:
G1 Truthful symbolic exploration. Enclave-aware symbolic
execution should closely mimic the real SGX hard-
ware. Particularly, to not miss vulnerabilities in the
runtime itself, the symbolic exploration should (a) start
from the very first entry instruction without skipping
initialization procedures or stubbing runtime library
functions; and (b) operate on the exact initial memory
contents, as remotely attested via MRENCLAVE [50],
while accurately detecting and symbolizing any subse-
quent accesses to untrusted or unmeasured memory.
G2 Runtime-agnostic. Validation should not be limited to
enclaves developed with any specific single shielding
runtime. The heterogeneous SGX ecosystem with ill-
documented and varying enclave binary formats calls
for a lightweight conversion approach to a unified
format capturing the exact enclave memory layout.
G3 Extensible validation policies. The system should sup-
port prompt reactions to evolving sanitization responsi-
bilities by adding new or modified vulnerability detec-
tion plugins. This calls for an approach that decouples
validation policies from enclave-aware symbolic exe-
cution mechanisms, such that plugins can solely focus
on elegantly expressing the required software security
invariants to be validated for explored paths.

In addition to these three research goals, we define the
following secondary design challenge:
D1 Accessibility. The tool should be open-source and easy
to use, including on closed-source binary targets. Re-
ports should be easily interpretable by human analysts.

3.1. Research Gap

Initially, SGX software vulnerability research was
mainly guided through manual code review [21]–[23], [41],
whereas automated enclave analysis through symbolic exe-
cution has only more recently started to be explored [37]–
[39]. Table 1 compares Pandora to these existing tools. In
summary, existing approaches are mostly focused on appli-
cation bug detection instead of principled validation of the
absence of shielding runtime vulnerabilities. This means that
they are inherently insufficient for truthful symbolic explo-
ration (G1), as the focus is on analyzing enclave application
logic only, while (largely) skipping the underlying shielding
runtime and operating on inaccurate initial memory con-
tents. Moreover, existing tools are ill-fitted for the diverse

TABLE 1. COMPARISON OF SYMBOLIC-EXECUTION TOOLS FOR SGX.

Tool

App SDK Entry Init

Runtime

Binary

D u m p

R eentry

Plugins

Ptr ABI ÆPIC Jmp Open

TEEREX [37]
Guardian [38]
COIN [39]
Pandora

Intel
Intel
Intel
any

(cid:32)
(cid:32)
(cid:32)
(cid:32)

Features can be fully (

(cid:35)
(cid:32)
(cid:35)
(cid:32)
), partially (

(cid:35) (cid:32) (cid:35) (cid:71)(cid:35) (cid:71)(cid:35) (cid:35)
(cid:35) (cid:71)(cid:35) (cid:35) (cid:35) (cid:71)(cid:35) (cid:71)(cid:35)
(cid:35) (cid:35) (cid:35) (cid:35) (cid:71)(cid:35) (cid:35)
(cid:32) (cid:32) (cid:32) (cid:32) (cid:32) (cid:32)

(cid:35)
(cid:35)
(cid:35)
(cid:32)
) supported. Columns 4–7 denote

), or not (

(cid:71)(cid:35)
(cid:71)(cid:35)
(cid:35)
(cid:32)

(cid:35)
(cid:32)
(cid:32)
(cid:32)

whether the tool executes the runtime entry and initialization phases; can handle
binaries without additional specification; and uses the exact memory layout (dump).

(cid:35)

(cid:71)(cid:35)

(cid:32)

SGX ecosystem (G2), as they all make runtime-specific
assumptions that strictly limit them to enclaves developed
with Intel’s SGX SDK only. Finally, existing tools focus
mainly on a narrow set of classical memory-safety issues
for pointers without principally supporting more intricate
shielding responsibilities (G3), such as recently rolled out
pointer-alignment ÆPIC mitigations [25], [26].

TEERex. TEEREX [37] is a closed-source prototype to
detect memory corruption vulnerabilities in enclave applica-
tions developed with the Intel SGX SDK. Similarly to our
work, TEEREX is based on angr [48], a popular symbolic
execution tool for binary code, and performs taint tracking of
untrusted attacker arguments and memory accesses outside
the enclave using unconstrained symbolic values.

In contrast

to Pandora, however, TEEREX does not
support truthful symbolic exploration (vs. G1a), as it entirely
skips analysis of the whole trusted runtime and directly
performs symbolic execution of enclave application entry
points, called ecalls. Moreover, TEEREX is inherently
runtime-specific (vs. G2), as it relies on Intel SGX SDK-
specifics to identify addresses of ecall functions, to hook
specific pointer validation functions, and to set up an approx-
imate, non-truthful initial memory layout (vs. G1b). Con-
cerning vulnerability detection (G3), TEEREX only reports
unconstrained and NULL-pointer dereferences and cannot
detect more subtle pointer issues, or ABI and ÆPIC issues.
Particularly, by hooking the crucial validation functions
(e.g., is_outside_enclave in Listing 1), TEEREX may
miss logical partial validation errors [21] that will be caught
by Pandora’s precise enclave-aware memory model (cf. Sec-
tion 7). TEEREX is not openly available (vs. D1).

Guardian. Guardian [38] is similarly based on angr and can
partially check API and ABI shielding policies. Regarding
truthful exploration (G1a), Guardian is the only prior work
that starts at the enclave entry point within the trusted run-
time, but it nevertheless skips the complex enclave initial-
ization phase, which may still contain critical vulnerabilities
(cf. Section 7). Furthermore, similar to TEEREX, Guardian
is constrained to binaries developed with specific versions of
the Intel SGX SDK (vs. G2) and only constructs an approx-
imate, non-truthful initial memory layout (vs. G1b). As to
vulnerability detection (G3), Guardian validates a principled,
yet fundamentally incomplete orderliness policy, where the
developer is required to manually annotate execution phases
(vs. D1). Guardian validates that, after the entry phase, an

Figure 2. Overview of the Pandora architecture.

(incomplete) blocklist of ABI configuration registers has
been cleared, and that untrusted memory outside the enclave
is only accessible during execution of the shielding runtime,
but not during the application phase. This simplified permis-
sion state-machine model may be overly conservative for
applications and, more problematically, remains inherently
insufficient to detect critical vulnerabilities (e.g., CVE-2018-
3626 [21]) in the shielding runtime itself, as the latter is
allowed unrestricted access to the full address space.

in enclave

COIN. COIN [39] uses concolic execution to find
applications.
memory-safety vulnerabilities
COIN specifically targets applications developed on top
of the Intel SGX SDK (vs. G2) and requires the enclave
source code (vs. D1) for extracting the parameters of
ecalls in order to set up an approximate, non-truthful
initial state (vs. G1b). Regarding vulnerability detection
(G3), COIN is largely orthogonal to our work by focusing
on traditional memory-safety application vulnerabilities
instead of nuanced, enclave-specific shielding issues and
skipping analysis of the runtime itself (vs. G1a).

Finally, upon finalization of our paper, a concurrent study
called SymGX [51] was published, focusing on detecting
cross-boundary pointer vulnerabilities in the source code of
Intel SGX applications.

3.2. Solution Overview

Figure 2 depicts a high-level overview of the Pandora
software architecture, which we implemented in 5,934 lines
of extensible Python code (as measured by sloccount).
At Pandora’s core, the engine component 1 augments the

pointersabiintel_sdkPluginsSDKlinux_selftestUI + Reportsangrsconeenclave_dumpcontrolflowaepicDynamic PhaseSGX-Tracer+EnclavebinaryMemorydumpJson layoutEnclave-Aware ExplorationEnclave memorySGX instructionsEnclave reentryExploration limiterPandora Engineunderlying symbolic execution library angr 2 [52] with ac-
curate SGX semantics and drives the enclave-aware truthful
symbolic exploration 3 (G1), described in Section 4. The
engine is primed with the exact initial enclave image via a
novel, runtime-agnostic dynamic memory extraction phase
4 (G2) detailed in Section 5. As such, Pandora is the first
symbolic-execution tool that can find vulnerabilities before
the application code, i.e., in the runtime entry procedures
and in the low-level enclave initialization phase.

5

While symbolically executing a binary, the Pandora en-
(G3), de-
gine triggers vulnerability-detection plugins
scribed in Section 6, that are based on subscribable events
exposed by the SGX-aware exploration. After a completed
run, Pandora formats the findings of each plugin into con-
venient and interactive HTML reports 6 (D1), shown in
Appendix A, including severity levels, descriptions, disas-
sembly, register dumps, and full basic-block backtraces to
enable human analysts to investigate the reported issues.

4. Enclave-Aware Symbolic Execution (G1)

4.1. Modeling x86 Instruction Semantics

The underlying VEX representation used by angr does
not have a symbolic model for many x86 instructions that
commonly occur in enclave binaries. Most prominently,
the ENCLU user leaf instructions [53] are used inside the
tasks, such as creating
enclave to perform architectural
a local attestation report (EREPORT), generating crypto-
graphic keys (EGETKEY), or exiting the enclave (EEXIT).
While prior work faced similar angr limitations and either
did not execute [37] or merely hooked and skipped [38]
over these instructions, Pandora truthfully emulates used
enclave instructions as closely as possible. For example,
in EREPORT, we copy the relevant SGX enclave control
structure (SECS) fields provided by the enclave loader,
including the processor extended features request mask, into
the generated report structure. When specific fields are not
available and no sane defaults can be provided, values are
symbolized to ensure that all possible paths are explored.

Furthermore, in response to advanced ABI attacks [22],
[27], instructions like XSAVE and XRSTOR or their variants
are commonly used to save and restore extended x86 register
on enclave context switches. In contrast to prior work [37],
[38], Pandora carefully emulates their behavior as closely
as possible. Where necessary, we add dedicated shadow
registers to keep track of special x86 registers, such as
MXCSR, which are not normally part of angr’s execution
model. As shown in Section 7, this precise register view
enables Pandora plugins to accurately uncover subtle over-
sights, e.g., attacker-controlled registers when switching to
enclave functions or insecure MXCSR configuration values.

4.2. Taint Tracking of Attacker Inputs

In order to accurately deal with attacker-controlled in-
puts, Pandora comes with a capable symbolic taint-tracking

mechanism. Specifically, initial register contents on enclave
entry, as well as memory reads from outside the enclave or
from uninitialized unmeasured pages inside the enclave (cf.
Section 4.3), are transparently replaced with unconstrained
symbolic values. Thus,
the symbolic execution initially
makes no assumptions about attacker-provided inputs, until
specific constraints are added by any subsequent sanitiza-
tions performed by the enclave code. Pandora, furthermore,
uses angr’s annotation system to mark attacker-controlled
symbolic values with an attacker-taint, which is conser-
vatively propagated during symbolic execution and can be
conveniently queried by plugins. For instance, plugins can
check that values are properly sanitized (e.g., Section 6.1) or
react differently based on whether a value is attacker-tainted
or not (e.g., Section 6.2).

Pandora’s taint tracking mechanism only tracks explicit
data flows. Any implicit flows that result from attacker-
controlled control flow are ignored (e.g., Pandora does not
propagate the taint from x to y in if(x == 1){ y = 1 }).
While tracking only explicit flows may, in principle, lead
to false negatives, it brings a large increase in practical-
ity [54] and is common in taint-tracking-based vulnerability
detection [55].

4.3. Enclave-Aware Memory Model

Pandora features a fully enclave-aware memory model
that truthfully simulates the enclave address space in a more
accurate and expressive way than prior work, while also in-
cluding reasonable performance optimizations. Particularly,
we are the first to realize a precise, runtime-agnostic enclave
memory model that properly recognizes attacker-controlled
symbolic addresses and sizes and that takes into account
novel attack surface from unmeasured SGX enclave pages.

4.3.1. Address-Space Partitioning. At its core, we im-
plemented our enclave-aware memory model as an angr
MemoryMixin extension that performs rigorous checks on
every memory access. Particularly, we use angr’s constraint
solver to unambiguously decide for every accessed buffer
with a possibly symbolic address and size whether it is re-
stricted to (i) lie fully inside the enclave; (ii) lie fully outside
the enclave; or (iii) partially touch the protected enclave
range. Accesses to memory inside or outside the enclave will
be handled differently, as outline below. Pandora plugins
can, furthermore, subscribe to these respective events to
check and report specific vulnerabilities (cf. Section 6).

Note that the above accurate classification is non-trivial
to implement, and prior work side-stepped these intricacies
by either hooking runtime-specific pointer-validation func-
tions [37] or ignoring the (possibly symbolic and attacker-
controlled) size of memory reads [38]. Our fully symbolic
memory model, on the other hand, allows to meticulously
detect subtle oversights or logical errors in the crucial valida-
tion functions themselves. For instance, Section 7 discusses
a particularly intricate finding where overflow protection
logic was silently optimized away by the compiler.

4.3.2. Untrusted Memory Accesses. For accesses falling
outside the protected enclave range, we model the strongest
type of adversary that utilizes tools such as SGX-Step [56]
to perform instruction-granular time-of-check to time-of-
use attacks. For example, an enclave checking an external
pointer that resides in untrusted memory, before accessing
this pointer again at a later time (as in Listing 1) may
realistically receive two different values. Pandora truthfully
simulates this by ignoring untrusted memory writes and
fully symbolizing all untrusted memory reads with a fresh
attacker-tainted symbolic value on every access.

4.3.3. Enclave Memory Accesses.
In close accordance
with the SGX specification [53], we distinguish two types
of memory inside the enclave: measured and unmeasured
pages. Measured enclave pages are attested as part of
the MRENCLAVE enclave identity and are, hence, always
demonstrably initialized to the exact value provided by the
enclave loader. Unmeasured enclave pages, on the other
hand, are protected from enclave creation time onwards, but
their initial content is not attested as part of the MREN-
CLAVE enclave identity. These unmeasured enclave pages
have many uses in enclaves, for example to reserve heap
memory or to load additional code or data during execution
that did not exist at enclave creation time yet. As the initial
value of these pages is not part of the enclave identity, and
thus under attacker control, enclave software must always
securely overwrite these pages before first use. However,
to the best of our knowledge, to date no sanitizer exists to
validate this critical security property. To enable this with
Pandora, we ensure that any read from unmeasured enclave
memory initially returns an attacker-tainted symbolic value.
Only when unmeasured bytes are securely initialized, we
create an angr memory backing and the newly written secure
values will be taken into account for future reads.

Pandora, furthermore,

implements two types of safe
performance optimizations. First, we remove measured and
initialized unmeasured enclave memory that consists of
all-zero bytes from the angr backend. Any reads from
such regions will statically return zero bytes until they are
overwritten with non-zero data. Second, only for source
and destination buffers that are constrained to fall entirely
inside the enclave, we optionally hook common memory-
management functions (memcpy and memset) and x86
rep string operations with custom SimProcedures that
eliminate loop overhead, while still taking care to trigger
any relevant angr mixins and breakpoints.

4.4. Enclave Entry and Reentry

During enclave lifetime, EEXIT and EENTER instruc-
tions can switch execution to and from the untrusted envi-
ronment. Prior work [37]–[39] relied on parsing runtime-
specific and fragile data structures to find out the supported
ecalls in order to skip the crucial runtime entry and/or
initialization phases entirely and immediately start executing
at the respective application ecall function.

4.4.1. Enclave Entry. To truthfully execute entry into the
enclave, we parse the actual thread control structure (TCS)
from enclave memory to retrieve the entry point location
and fill registers with the exact same values that they would
receive from the architecture, such as the TCS address and
FS and GS base addresses. All other registers are filled with
unconstrained, attacker-tainted symbolic values to initiate
Pandora’s taint-tracking mechanism (cf. Section 4.2).

4.4.2. Enclave Exit. Pandora allows to truthfully build up
enclave state by emulating a new EENTER with the same
accumulated memory view after a symbolic path reached
the EEXIT instruction. Hence, the enclave entry code in
the runtime itself will perform any necessary checks and au-
tonomously decide whether the entry request is an ecall or
an ocall return and dispatch this request accordingly. The
strength of this approach is that subtle attack vectors, like
dereferencing a function pointer before in-enclave relocation
(cf. Section 7) or returning from an ocall where no prior
ocall was executed [21], can in principle be detected.

4.5. Path Exploration and State Reduction

Pandora’s unique focus on truthful symbolic exploration
of the entire enclave binary, including low-level shielding
runtime code, comes with the potential cost of state explo-
sion. To reduce memory consumption for individual explo-
rations, Pandora optionally supports depth-first exploration
in addition to breadth-first exploration.

With regard to reentry, every path that reached EEXIT
would have to be reentered in a naive approach, because
the enclave may have accumulated relevant global state.
However, we observed that many paths result in a clean
failure that
is reported to the untrusted world with the
request to restart the enclave with correct parameters. To
avoid redundantly exploring all these semantically equiva-
lent traces, we implement a novel state uniqueness reduction
before reentering enclave exploration. That is, two symbolic
EEXIT states are different from each other only if they have
made different changes to the internal memory of the en-
clave. For example, two enclave traces that both result in no
changes to the enclave except setting a specific bit indicating
that the enclave failed, are equivalent and reentering both
would be redundant. With this uniqueness criterion, we thus
remove all non-unique enclave traces before preparing them
for reentry, i.e., before Pandora executes on them again. Note
that this approach is a safe over-approximation, e.g., states
may still be semantically equivalent even though they differ
in some de-allocated stack variables. However, we found
that our state uniqueness reduction is sufficient to greatly
reduce the state space without risking that unique states
may be lost. The impact of this optimization ultimately
depends on the runtime, i.e., on the number of individual
paths that lead to enclave exits. Specifically, for the runtimes
investigated in this work, this state reduction has an efficacy
between 14% (EnclaveOS, 13 of 93 exit states pruned) and
60% (Occlum, 1694 of 2811 exit states pruned).

5. Runtime-Agnostic Enclave Loading (G2)

in contrast

Truthful symbolic execution naturally starts with an
accurate representation of the initial enclave memory lay-
out (G1b). Unfortunately, however,
to well-
established standards like the executable and linkable format
(ELF) for Linux binaries, there exists no standardized format
to distribute SGX binaries. Hence, over the last years, all
SGX shielding runtimes have adopted their own custom
formats to describe the additional information needed to
correctly load the enclave, e.g., often by encoding opaque
blobs into additional ELF metadata sections [4], [5]. This is
especially problematic as Intel SGX requires a particularly
involved, multi-stage loading process [1], [53].

First, the untrusted system software constructs the initial
enclave memory layout, containing regions for code and
data, and also including several unique enclave-specific
data structures. The two most prominent data structures are
the SECS structure describing, among others, the enclave
load address and size, as well as the TCSs, describing
the enclave entry point and thread-local data storage. Fur-
thermore, as SGX enclaves are commonly compiled as
position-independent code and loaded as dynamic libraries,
the MRENCLAVE identity must be independent of the load
address. Hence, the enclave cannot rely on the untrusted
loader to perform any remaining ELF relocations (e.g., for
dynamic function-pointer tables). Thus, as a second loading
step, enclave shielding runtimes generally include in-enclave
code to perform any necessary ELF relocations upon the first
enclave entry, i.e., after the enclave has already been created
and loaded into memory.

Static Analysis. Notably, all prior works [37]–[39] on SGX-
aware symbolic execution entirely side-step the aforemen-
tioned intricacies by restricting themselves to one particular
runtime, specifically the Intel SGX SDK, and by load-
ing the enclave largely as a normal ELF file. Particularly,
existing approaches only take care to create approximate
space for stack and heap and either skip to the application
directly [37], or they manually patch fragile and version-
specific global data structures to falsely mark the symbolic
enclave as initialized and skip over the costly, low-level
runtime initialization and relocation phases [38]. Thus, prior
works simulate an inaccurate enclave memory layout (vs.
G1b) and are, moreover, only compatible with one specific
version of one specific runtime (vs. G2).

it

We argue that, with ample code review or reverse-
engineering efforts,
is in principle possible to devise
an approach that accurately mimics the runtime-specific
loading process to construct a truthful initial memory layout,
satisfying G1b. Indeed, Appendix B describes such optional
support we added to Pandora to load enclave binaries from
selected runtimes based on static analysis of a given en-
clave binary. We found, however, that such a purely static-
analysis approach is highly labor-intensive and inherently
fragile, requiring to implement a custom loader for every
studied enclave runtime, possibly even with changes across
runtime versions. This would evidently limit the scope and

not satisfy our vision of runtime-agnostic analysis for the
sprawling SGX ecosystem that has become heterogeneous
both in runtime capabilities as well as in programming
languages available to the enclave developer.

Dynamic Enclave Memory Extraction. To overcome the
labor-intensity and inherent fragility of the above pure static
analysis approach with runtime-specific loaders, Pandora
supports a more powerful approach that requires a short-
lived dynamic execution phase to load the binary-under-test
once. Specifically, we developed a minimal standalone pro-
gram, called SGX-TRACER, to passively observe the loading
process of an enclave binary on actual Intel SGX hardware.2
SGX-TRACER consists of about 400 lines of C code and uses
the ptrace Linux system call to attach to the untrusted
enclave host process and intercept all calls to the (in-kernel
or out-of-tree) Intel SGX driver. SGX-TRACER can thus
fully transparently (i) detect enclave creation via ECREATE
and record crucial enclave SECS metadata, including load
address and size; (ii) record the exact memory contents of all
pages that are subsequently added via EADD; and (iii) track
additional metadata and permissions for these pages, as
well as locate special pages like TCSs, before the enclave
identity is finalized via EINIT. This allows SGX-TRACER
to accurately extract the exact initial enclave memory (G1b),
as attested by MRENCLAVE, for any SGX process (G2).

The output by SGX-TRACER is stored as a binary dump
and accompanying JSON file and can subsequently be
used on non-SGX hardware by Pandora. Particularly, we
developed a minimal angr loader to reconstruct a truth-
ful symbolic memory view, including permissions of each
page and whether the page is measured or unmeasured (cf.
Section 4.3). This inherently runtime-agnostic loader makes
Pandora compatible with any enclave dump extracted via
SGX-TRACER, regardless of runtime-specific loading details.
One downside of utilizing an enclave memory dump for
symbolic execution is that this process loses all debug sym-
bols, including function names. Pandora can run without any
of these symbols, but upon finding a potential vulnerability,
the generated reports may be less understandable for human
analysts (vs. D1). Hence, we implemented a custom symbol
handler that can augment a plain memory dump extracted
by SGX-TRACER with symbol information from the original
ELF file, if optionally provided via a Pandora command-line
option (together with a static offset).

6. Pluggable Vulnerability Detection (G3)

During symbolic exploration, angr

triggers a set of
breakpoints that can be hooked to investigate the symbolic
state. Exemplary angr breakpoints are memory or register
accesses and function calls. Pandora extends the legacy angr
events with a set of eight new enclave-specific breakpoints
(cf. Appendix C). Specifically, Pandora exposes breakpoints
before and after enclave entry and exit, as well as break-
points before and after symbolic memory reads and writes

2. Real SGX hardware may not even be a strict requirement, as SGX-

TRACER could, in principle, also spoof the existence of the SGX driver.

that are restricted to resolve fully inside, fully outside, or
partially overlapping with the enclave memory range.

Pandora’s enclave-aware breakpoints form the basis for
our notion of pluggable vulnerability detection (G3). Specif-
ically, specialized plugins can subscribe to relevant enclave
events, as well as legacy angr breakpoints, to accurately vali-
date certain software invariants during symbolic exploration.
We created 4 plugins for a diverse set of enclave shielding
runtime responsibilities at the levels of ABI register cleans-
ing, API-level pointer arguments, ÆPIC-style pointer align-
ment considerations, and attacker-controlled control flows.
Plugins can, furthermore, make use of Pandora’s built-in
reporting interface (D1) to conveniently summarize any find-
ings in human-readable HTML reports that are automatically
annotated with all relevant information, e.g., a severity score
and description of the issue and how to reach the vulnerable
state (cf. Appendix A).

6.1. ABI-Level CPU Register Sanitization

Enclaves share the CPU register set with their untrusted
surrounding host process. An important responsibility of the
shielding runtime is, therefore, to securely initialize any low-
level configurations registers on enclave entry. Due to the
intricacies of these low-level register manipulations, those
sanitizations have to be carefully implemented in a fragile,
hand-written assembly stub before a jump into higher-level
languages can be securely made, compliant with ABI ex-
pectations [57], [58] by the compiler.

While the general concept of ABI-level sanitization is
relatively well-understood across SGX shielding runtimes,
an ongoing line of manually discovered vulnerabilities [21]–
[23], [27], [41] has underlined the intricacies and chal-
lenges for secure register initialization in the complex x86
instruction set. Prior work on automated enclave software
vulnerability detection has either fully ignored CPU register
sanitization by focusing on API validation only [34], [37],
[39], or resorted to a simplistic and incomplete blocklist
approach that merely checks whether selected CPU regis-
ters have certain concrete safe values [38]. On the other
hand, Pandora’s ABISan plugin proposes a more principled
approach based on taint tracking, which can autonomously
discover insufficient register initialization or cleansing.

6.1.1. Attacker-Tainted Configuration Registers. The
ABISan plugin hooks all angr register read events and relies
on Pandora’s taint-tracking mechanism (cf. Section 4.2) to
detect when unsanitized CPU configuration registers are
read. To avoid evident false positives, ABISan only requires
a concise allowlist for the x86 data registers, i.e., the 16
general-purpose registers, 16 vector registers, and floating-
point unit (FPU) register stack, which do not contain control
or status bits and, hence, are allowed to be tainted with
attacker inputs. Any other attacker-tainted register reads will
be automatically reported as critical policy violations.

Our systematic taint-tracking approach has two main
strengths compared to simply checking that an incomplete
subset of registers has been initialized to certain values [38].

First, ABISan can autonomously track all relevant occur-
rences where the attacker has influence over the result
of a computation through control registers.3 This may, in
principle, even include yet unknown ABI attack avenues.
For instance, we experimentally validated that ABISan
can fully autonomously discover attacker-tainted reads from
individual bits in the RFLAGS [21] register, e.g., the crucial
direction flag for x86 REP string instructions, as well as
a particularly subtle oversight for floating-point operations
that required several rounds of patches in Rust-EDP and
OpenEnclave to make sure that not only the x87 FPU control
word is initialized, but also the internal x87 tag word [22].
Second, ABISan also enables tracking advanced attack vec-
tors where the enclave would inadvertently restore tainted
control registers prior to using them in a computation.

6.1.2. Enclave Entry Sanitization. Our ABISan plugin
inspects the complete register state when reaching the first
CALL instruction inside the enclave. Indeed, the first func-
tion call inside the enclave revealed to be a surprisingly
effective heuristic for the switch from assembly sanitization
code to the higher-level, compiler-generated API entry point:
across the 11 investigated runtimes, only a single runtime
performed a CALL from inside assembly code before jump-
ing to C code, which we accommodated in our heuristic.
Upon reaching the API entry point, ABISan warns for every
control and data register that has not been entirely cleared
of attacker-tainted data.

Thanks to Pandora’s powerful taint-tracking mechanism
and enclave-aware execution model, we were able to express
the entire ABISan policy in only 142 lines of Python code.
It is important to note that the flexible nature of our plugins
allows for quickly reacting to the ever-changing landscape
of recommendations to ABI sanitization responsibilities for
Intel SGX. For example, initial research [22] first inves-
tigated issues with incomplete sanitization of floating-point
control registers and recommended setting the MXCSR regis-
ter to the ABI-specified value of 0x1F80 on enclave entry.
More recently, however, Intel [27] further nuanced secure
MXCSR initialization by recommending the value 0x1FBF,
which additionally sets all floating-point exception status
flags, to protect against subtle, one-cycle timing differences
dependent on (possibly secret) floating-point operand values.
We were able to swiftly incorporate this latest recommen-
dation into ABISan’s validation policy. This demonstrates
that our plugin system can react flexibly and promptly to
such updated recommendations, which, as we will show in
Section 7, require changes that propagate slowly throughout
the Intel SGX software ecosystem.

6.2. Untrusted Pointer Value Sanitization

We implemented a capable PTRSan plugin in 120 lines
of Python code that proposes three expressive security in-

3. The only limitation here is that we are restricted to the subset of x86
behavior that is emulated by angr. For instance, angr does not consider the
alignment-check flag in RFLAGS and largely ignores floating-point precision
configuration bits in the underlying VEX symbolic-execution engine.

variants to catch the pervasive issues of confused-deputy
attacks via untrusted pointer arguments in the shared ad-
dress space. Note that,
to prior work [37]–
[39], PTRSan is entirely independent of the runtime-specific
sanitization function, solely relying on Pandora’s built-in
taint tracking and enclave-aware memory model. Hence, as
demonstrated in Section 7, PTRSan for the first time allows
to find subtle logical errors in the sanitization logic itself.

in contrast

6.2.1. Address Inside or Outside Enclave. Any symbolic
memory access that crosses the enclave boundary, even
partially, violates the trusted-untrusted memory division.
This case arises when, according to the constraint solver,
a symbolic address and size pair can have concrete values
that fall both inside and outside the enclave’s protected
address range. PTRSan, hence, always reports such cases
as a critical issue of a pointer that has not been sufficiently
constrained by the enclave software.

6.2.2. Tainted In-Enclave Address. Attacker-tainted ac-
cesses that are constrained to resolve entirely in untrusted
memory are clearly benign behavior of the enclave. On the
other hand, attacker-tainted accesses that are constrained to
always lie entirely in trusted enclave memory may still be
benign behavior, e.g., an attacker-controlled, yet constrained
index into an in-enclave array data structure. Hence, we
only report a warning in these cases and mark them as
potential issues that may warrant manual and application-
specific further inspection. To simplify such further analysis,
PTRSan reports the size and maximum address range of the
tainted memory access. This criterion to warn for tainted in-
enclave memory accesses thus ensures that no clear violation
of secure memory accesses can occur, at the potential burden
of occasional false-positive warnings. These false positive
are non-straightforward to eliminate generically, but we
discuss possible enhancements and heuristics in Section 8.

6.2.3. Untainted Outside-Enclave Address. Untainted ac-
cesses that are constrained to always resolve entirely in
enclave memory are clearly benign behavior of the enclave.
However, if untrusted memory is ever accessed with an
address that is not tainted by the attacker, PTRSan sees
this as a critical issue hinting at unexpected behavior, e.g.,
an uninitialized or NULL pointer dereference.

6.3. Untrusted Pointer Alignment Sanitization

The recently disclosed ÆPIC [25] and MMIO stale data
leakage [26] attacks on Intel SGX platforms have shown
that enclave secrets may propagate from microarchitectural
fill buffers into architectural, software-visible registers when
dereferencing unaligned pointers to MMIO devices. While
CPU microcode updates have since been released to trans-
parently cleanse fill buffers upon enclave exits on affected
processors, additional software mitigations are still neces-
sary to prevent confused-deputy exploitation of these issues
during enclave execution [26], [40]. That is, even when
the enclave shielding runtime has properly checked that

untrusted, attacker-tainted pointer arguments fall entirely
outside the enclave memory range, as can be validated by
PTRSan, SGX enclaves have no way of knowing whether
these untrusted memory locations refer to vulnerable MMIO
regions. Indeed, privileged adversaries can trivially map un-
trusted memory pages to arbitrary MMIO devices, including
the x86 APIC configuration registers [56]. As such, deref-
erencing untrusted pointers during enclave execution may
unintentionally expose secret stale data, and Intel explicitly
advises that SGX shielding runtimes should additionally
constrain untrusted pointer dereferences to certain safe com-
binations of alignments and lengths [26], [40]. Note that this
holds both for outside-enclave reads and writes, through the
shared buffers data read (SBDR) and device register partial
write (DRPW) processor vulnerabilities, respectively.

In response to these dynamic challenges, we developed a
specialized ÆPICSan plugin, which investigates the align-
ment of each symbolic memory access that may resolve
outside the enclave. Specifically, in accordance with Intel’s
intricate software security guidance [26], [40], we validate
that every untrusted read or write access resolving outside
the enclave is minimally 8-byte aligned, i.e., has the lower
three address bits cleared. We, furthermore, ensure that
untrusted read accesses have a size that is always maximally
eight bytes at a time, whereas untrusted writes should be in
chunks of multiples of eight bytes at a time [26]. Finally,
when detecting unaligned untrusted writes, ÆPICSan parses
the disassembly of the current basic block to filter out safe
cases where the vulnerable write is preceded by the VERW
instruction to cleanse leaky microarchitectural buffers and
directly followed by an LFENCE; MFENCE instruction pair
to avoid inadvertent transient refills, as per Intel’s software
security guidance [26].

Our complete ÆPICSan validator requires only 103
lines of Python code, where the majority of code concerns
parsing the disassembly. This clearly shows the strength
of exposing Pandora’s enclave-aware memory model (cf.
Section 4.3) to individual plugins that may have partially
overlapping functionality, e.g., PTRSan vs. ÆPICSan.

The recent SBDR/DRPW disclosures required extensive
manual software mitigations, frequently encompassing sev-
eral rounds of commits and pull requests, throughout the
SGX runtime ecosystem. We are the first to provide any
form of toolchain support for automatically detecting and
validating SGX pointer-alignment considerations, and we
are the first to perform a wide-scale investigation of such
issues remaining in real-world enclaves (cf. Section 7).

6.4. Control-Flow Hijacking Validation

Lastly, Pandora includes a CFSan plugin, implemented
in 110 lines of Python code, that validates enclave control-
flow events. This plugin reports insecure jump targets ac-
cording to the location of the target and whether the target
is attacker-tainted.

First, similar to prior work [37], [38], we report a critical
security issue when the attacker can arbitrarily control a
jump target inside the enclave. Furthermore, similar to the

false-positive heuristic for CFSan, we only report a warning
when attacker-tainted jump targets are constrained to always
fall entirely inside the enclave.

In addition to this first criterion, partially covered by
prior work, CFSan also includes novel rules to detect
any enclave jumps to attacker-controlled memory contents.
Specifically, we found that several shielding runtimes fea-
ture unmeasured and executable memory pages, so as to
dynamically load (encrypted) code at runtime. As explained
in Section 4.3, this type of enclave memory is not part
of the attested MRENCLAVE measurement and is, as such,
initially attacker-controlled until
initialized by
enclave software. Thus, any enclave jumps to unmeasured
memory that has not yet been initialized are reported as a
critical security issue. While, apart from validation on our
own test enclaves, we have not encountered such instances
in our evaluation on real-world enclave binaries, we are the
first to formulate and write a sanitizer for this nuanced class
of novel unmeasured enclave vulnerabilities.

is first

it

Finally, note that, in line with our goal of truthful sym-
bolic execution, the Pandora base engine already intercepts
any jumps to outside the enclave memory range or to non-
executable pages inside the enclave, regardless of CFSan.
We simply abort the symbolic execution paths for these
cases, as both of these events would result in a runtime
exception on real SGX hardware and would, hence, not be
an exploitable vulnerability besides denial-of-service.

7. Evaluation

We evaluated the efficacy of Pandora and its vulner-
ability detection plugins in two distinct ways. First, we
developed a concise unit-test validation framework, loosely
based on the existing Linux selftest enclave [59], to pre-
cisely diagnose (known) vulnerabilities in small benchmark
enclaves compiled with increasing levels of mitigations. Sec-
ond, we performed a comprehensive ecosystem analysis on
11 relevant, real-world SGX shielding runtimes, uncovering
over 200 newly found vulnerable code locations, tracked via
7 common vulnerabilities and exposure (CVE) identifiers.
Additionally, further demonstrating the versatility of Pan-
dora, we made our symbolic-execution tool autonomously
reproduce over 69 previously known vulnerable code loca-
tions from the literature in older versions of the investigated
runtimes.

Table 2 provides an overview of all reported and re-
produced issues, whereas a more detailed breakdown is
included in Table 4 in Appendix D. Notably, among all
the listed vulnerabilities, only one could potentially have
been uncovered with existing state-of-the-art SGX symbolic
execution tools (cf. Table 4) — due to either lack of support
for the required runtime, low-level initialization or entry
code, or the specific vulnerability type.

7.1. Selftest Validation Framework

The Linux kernel natively includes drivers for Intel SGX
since the 5.11 release [59]. As part of this effort, Linux

TABLE 2. EVIDENCE OF PANDORA FINDING AND REPRODUCING
VULNERABILITIES BOTH IN PRODUCTION AND RESEARCH RUNTIMES.

Runtime

Version Prod Src Plugin

Instances CVE

Newly found vulnerabilities in shielding runtimes (total 200 instances)
EnclaveOS
EnclaveOS
EnclaveOS
EnclaveOS
GoTEE
GoTEE
GoTEE
Gramine
Intel SDK
Intel SDK
Occlum

3.28
3.28
3.28
3.28
b35f
b35f
b35f
1.4
2.15.1
2.19
0.29.4

CVE-2023-38022
CVE-2023-38021

CVE-2022-26509

✓ ✗† ABISan 1
✓ ✗† PTRSan 15
✓ ✗† ÆPICSan 33
✓ ✗† CFSan
2
✗ ✓ PTRSan 31
✗ ✓ ÆPICSan 18
✗ ✓ CFSan
1
✓ ✓ ABISan 1
✓ ✓ PTRSan 2
✓ ✓ ÆPICSan 22
✓ ✓ ÆPICSan 11
✗ ✓ ABISan 1
✓ ✓ ABISan 1
✗ ✓ ABISan 1
✗ ✓ PTRSan 5
✓ ✓ PTRSan 17
✗ ✓ PTRSan 2
✗ ✓ CFSan
1
✗ ✓ CFSan
1
✓ ✓ ABISan 2
✓ ✓ ABISan 1

DCAP
Inclavare

Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
0.6.2

DCAP
Inclavare

Inclavare

Open Enclave 0.19.0
Rust EDP
SCONE
SCONE
SCONE
SCONE

1.71
5.7 / 5.8 ✓ ✗
5.7 / 5.8 ✓ ✗
5.7 / 5.8 ✓ ✗
✓ ✗
5.8

ABISan 2 / 1
PTRSan 10 / 3
ÆPICSan 11 / 3
CFSan

1

CVE-2023-37479

CVE-2022-46487
CVE-2022-46486
CVE-2023-38023

b35f
1.2
2.1.1
2.13.3

Reproduced vulnerabilities in older versions (total 69 instances)
GoTEE
Gramine
Intel SDK
Intel SDK
Open Enclave 0.4.1
Open Enclave 0.4.1
Open Enclave 0.4.1
1.63
Rust EDP

✗ ✓ ABISan 1
✓ ✓ ÆPICSan 10
✓ ✓ ABISan 1
✓ ✓ ÆPICSan 28
✓ ✓ ABISan 1
✓ ✓ PTRSan 13
✓ ✓ ÆPICSan 13
✓ ✓ ÆPICSan 2

CVE-2019-14565

CVE-2019-1370
CVE-2019-0876

Legend: † Source code was made privately available;

Based on above runtime.

also contains a bare-metal selftest enclave that provides
a minimal example to test the loading and execution of
an enclave binary without relying on any particular SGX
shielding runtime. This Linux selftest enclave consists of
hand-crafted assembly routines for entry and exit, plus an
ecall dispatcher that calls C functions. While this selftest
enclave is not intended to be a production runtime, Linux
developers have noted that its code may be copied and
provides a “great starting point if you want to do things from
scratch” [60]. Indeed, we found that at least two real-world
SGX projects directly built on the Linux selftest enclave to
date: Alibaba Inclavare Containers [61] uses it as a skeleton
example of best-practice enclave runtime integration and
Intel’s Data Center Attestation Primitives (DCAP) [62] for
Windows more critically uses it as the base for a custom
launch enclave that gets access to an SGX platform-specific
cryptographic key to decide which application enclaves can
be ran on the system. We report Pandora’s findings on these
bare-metal enclaves in the next section.

We developed a unit-test framework based on the Linux
selftest enclave. This test suite contains individually crafted
enclave binaries featuring multiple levels of ABI register
cleansing and input pointer(-to-pointer) sanitizations. These
enclaves, thus, provide a controlled test environment to craft

arbitrarily complex and challenging scenarios to validate
the efficacy of our plugins and Pandora’s enclave-aware
symbolic memory model. Furthermore, they allow to pro-
totype conceivable vulnerabilities that have not (yet) been
encountered “in the wild”, e.g., jumps to unmeasured and
uninitialized pages (cf. Section 6.4).

7.2. SGX Runtime Ecosystem Analysis

Runtime Selection. To explore the vulnerability landscape
for real-world enclave software, we evaluated Pandora on
a diverse set of 8 production-quality and 3 research-grade
Intel SGX shielding runtimes. Note that, as discussed in
Section 3, we opted to focus on validating the vital enclave
shielding runtime itself, including indispensable, low-level
initialization and entry code, rather than the more acces-
sible challenge of validating higher-level application logic
as explored in complementary prior work [34], [37], [38].
While the latter typically only affects a single (research) ap-
plication that makes incorrect use of shielding abstractions,
e.g., unchecked user_check pointers [4], [5], production-
quality shielding runtimes are supposed to be thoroughly
vetted and any vulnerabilities found would affect universally
all applications developed on top.

Our runtime selection includes diverse enclave program-
ming paradigms, including 2 SDKs (Intel SGX SDK [4] and
Microsoft Open Enclave [5]), 4 libOSs (EnclaveOS [63],
SCONE [64], Occlum [10], and Gramine [65]), 2 secured
language runtimes (Rust-EDP [11] and Go-TEE [12]), and
3 bare-metal enclaves (Linux selftest [59], Inclavare [61],
and DCAP [62]). We included the bare-metal enclaves, as
well as the academic Go-TEE research prototype runtime,
to complement the insights from the more mature produc-
tion ecosystem. Furthermore, while the majority of SGX
shielding runtimes are developed as open-source software,
our selection also includes two proprietary runtimes: En-
claveOS, with source code privately provided by the vendor,
and SCONE, with only binaries available.

Due to the intricacies involved in building old runtime
versions with often complex dependencies, we opted to
limit our choice of known vulnerabilities to a representative
sample across major runtimes. We see a systematic overview
of the vulnerability landscape of past runtimes as an inter-
esting and feasible direction for future work and believe that
Pandora could aid in such a survey. In the following, after
describing our experimental setup, we highlight the most
interesting findings of each plugin.

Experimental Setup. We extracted exact enclave dumps
via SGX-TRACER and ran Pandora on all runtimes with a
time budget of 12 hours and a memory budget of 256 GB,
whichever occurred first. Cloud instances with such memory
budget are commercially available beginning at 4 $ per hour,
making this limit feasible for occasional extensive validation
with Pandora, e.g., as part of continuous integration (CI) for
releases (as at least one vendor privately expressed interest
in). Each runtime was explored twice: once with a default

breadth-first exploration strategy and once with a depth-first
strategy that eagerly followed the longest paths.

We note that in our experiments, the 256 GB memory
limit was only hit twice, namely for the Intel SGX SDK 2.19
when using breadth-first search after approximately 8 hours,
and for GoTEE as the enclave memory dump is exceedingly
large at 64 GB. In all other cases, the memory consump-
tion varied between 24.6 GB and 196.7 GB for breadth-first
search and from 4.9 GB to 154.7 GB for depth-first search.
In some rare cases, our Pandora prototype crashed before
reaching these limits due to remaining unsupported x86
instructions or due to crashes in the underlying angr and
z3 solver. For EnclaveOS specifically, we manually guided
Pandora to skip two functions that either contain still unsup-
ported AES-NI instructions, or execute a waiting loop that
expects a second thread to fill data before continuing. For the
DCAP bare-metal launch enclave, we similarly instrumented
Pandora to skip two functions with unsupported AES-NI
instructions.

7.2.1. ABI Sanitization Issues. Following a
recent
overview study [41], Pandora promptly confirmed known
ABI issues in older Intel SGX SDK and Open Enclave
binaries, which have since been evidently mitigated (cf.
Table 2). Nonetheless, Pandora found that the proprietary
SCONE runtime still lacked any sanitization code for x87
and SSE floating-point configuration registers. We experi-
mentally demonstrated that this lack of ABI sanitization,
can be exploited in practice via a proof-of-concept exploit
that successfully introduces rounding errors in an elemen-
tary “sconified” floating-point application. Following our re-
sponsible disclosure, tracked under CVE-2022-46487, these
issues have been patched in the latest SCONE release 5.8.0.
Additionally, ABISan found that the academic GoTEE
runtime, as well as the Linux selftest, Inclavare, and DCAP
bare-metal enclaves, universally lack ABI entry sanitiza-
tions for RFLAGS and floating-point configuration registers.
Interestingly, Inclavare and DCAP took care to cleanse
extended processor state on enclave exit, but not on en-
try. Highlighting the strength of ABISan’s taint policy,
the plugin autonomously discovered attacker-tainted reads
from the x86 direction flag for compiler-emitted REP string
instructions that could be fatally corrupted in the DCAP
launch enclave, and notably found that GoTEE even lacks
secure stack pointer initialization, which could be exploited
to obtain full code execution in this runtime (cf. as also
reported by both CFSan and PTRSan). The issues in DCAP
are mitigated in version 1.19 and onward.

Our systematic analysis, furthermore, identified an inter-
esting case of regression in Open Enclave, which was as-
signed CVE-2023-37479 by Microsoft and mitigated in re-
lease 0.19.3. Particularly, in response to prior research [21],
commit efe7504 in Open Enclave included a patch to
properly sanitize the x86 alignment-check flag. However,
ABISan discovered that in current versions of Open En-
clave, the alignment-check flag was no longer properly san-
itized after the initial enclave sanitization routines have com-
pleted. Upon further investigation, we were able to conclude

that Open Enclave accidentally reintroduced the once-fixed
vulnerability with commit 16efbd6 in 2021, in a patch set
to mitigate another attack [23] that places more stringent de-
mands on stack-pointer initialization for exception handlers.
This instance of unintended regression thus provides a clear
illustration of the complexity of shielding responsibilities
and the potential value of including an automated tool like
Pandora in CI pipelines to test against known vulnerabilities
before releasing new software versions.

A final and particularly widespread line of ABI sanitiza-
tion issues follows from Intel’s recent MXCSR configuration-
dependent
timing (MCDT) software guidance [27]. Par-
ticularly, Intel recommends that shielding runtimes set all
floating-point exception status flags in the MXCSR register
for the lifetime of the enclave to avoid subtle, operand-
dependent
timing differences in otherwise constant-time
code on affected processors. Notably, this refined guidance
did not result from an academic publication or security
advisory and may have been easily missed by runtime
developers. Indeed, ABISan detected that only the Intel
SGX SDK and the dependent Occlum runtime properly set
MXCSR according to the new recommendation, and all other
runtimes did not. Following our disclosure, this has since
been patched in Open Enclave (0.19.3), Rust-EDP (1.71.0),
and EnclaveOS (3.30), and will be patched in the upcoming
SCONE 5.9.0 release.

7.2.2. Pointer Sanitization Issues. The strength of the
PTRSan plugin is to rigorously investigate issues with
pointer dereferences across many enclave runtimes.

In the SCONE production runtime, PTRSan uncovered
10 unique critical issues: 8 entirely unconstrained, attacker-
tainted pointer dereferences and 2 untainted outside-enclave
reads. Although the source code was not available, Pan-
dora was able to generate precise basic-block backtraces
annotated with ELF symbols, aiding in our investigation
and even the development of proof-of-concept exploits.
We reported each issue, tracked as a bundle under CVE-
2022-46486, to the SCONE developers who confirmed our
findings and included patches in the latest release 5.8.0.
However, PTRSan’s subsequent analysis on SCONE 5.8.0
revealed two more remaining vulnerabilities: an entirely un-
constrained attacker-tainted pointer and an untainted outside
enclave read, to be mitigated in the upcoming 5.9.0 release.
In EnclaveOS, PTRSan was able to detect a particularly
subtle instance of an untrusted pointer dereference as part
of a string length calculation, which is logically correct but
can be abused as a capable side-channel oracle to precisely
locate all null bytes in enclave memory [21]. Fortanix gave
a high severity rating for this finding, tracked under CVE-
2023-38022, and mitigated it in version 3.29. As a sec-
ond notable finding in EnclaveOS, Pandora autonomously
detected that overflow protections were missing in the un-
trusted pointer validation logic of the enclave binary. Upon
closer examination, we found that existing source-level over-
flow checks were silently optimized away by the compiler.
Specifically, the source code utilized void* pointer arith-
metic, which, unfortunately, is undefined behavior in C, lead-

ing to the compiler removing this check completely. Pandora
correctly reported that, with this check missing, the attacker
can cause untrusted pointers to wrap the address space via an
unsigned integer overflow. This issue highlights the strength
of Pandora’s binary-level validation and accurate symbolic
constraint solving of not only untrusted pointer values but
also their sizes, and is also mitigated in version 3.29.

Furthermore, as part of this research, PTRSan addi-
tionally confirmed an untrusted pointer dereference in the
protected code loader of the Intel SGX SDK version 2.15.1,
tracked via CVE-2022-26509 and patched in later versions.
This issue underlines the importance of validating low-level
runtime initialization code, as this pointer check was missing
before any in-enclave relocations, including global variables
containing the enclave base address and size needed in the
validation function itself, had been performed.

In the GoTEE research runtime, PTRSan discovered
numerous (31) unconstrained pointer dereferences, high-
lighting that even safe languages are not immune to over-
sights in pointer validation for SGX’s unique attacker model.
Furthermore, all bare-metal enclaves were found especially
vulnerable without any pointer sanitization measures (as
reported both by PTRSan and ÆPICSan). For the DCAP
launch enclave, Pandora reported 17 unique critical issues,
of which 11 were unconstrained, attacker-controlled reads
and 6 were unconstrained writes to arbitrary in-enclave
locations (mitigated in version 1.19). Likewise, the Inclavare
enclave contains several vulnerable invocations of memcpy
with unconstrained source and destination parameters, and
the Linux selftest enclave contains 5 entirely unconstrained,
attacker-tainted pointer dereference locations that can be
trivially exploited to leak or corrupt arbitrary in-enclave
memory locations.

Finally, for the known-vulnerable version 0.4.1 of Mi-
crosoft Open Enclave, Pandora correctly identified CVE-
2019-0876 [21], which highlights the power of multiple
reentries, as the vulnerability can only be triggered after
the enclave has been initialized. In addition, PTRSan also
reported a (presumably unknown) issue in this old runtime
version,
indicating a lack of pointer sanitization in the
oe_initialize_cpuid() function.

7.2.3. ÆPIC Sanitization Issues. Pandora is the first tool
to support automated analysis and validation of ÆPIC-
style untrusted pointer alignment vulnerabilities in SGX
thus, employed our novel ÆPICSan plu-
enclaves. We,
gin to perform a large-scale, automated analysis to assess
the completeness of Intel’s particularly complex and error-
prone software mitigation guidelines [26], [40] in real-
world enclave shielding runtimes. As result of this sys-
tematic analysis, Pandora found that SBDR and DRPW
mitigations were missing entirely in GoTEE (18 unique
instances), SCONE (11 instances; tracked via CVE-2022-
46487 and partially mitigated in version 5.8.0), and En-
claveOS (33 instances; tracked via CVE-2023-38021 and
mitigated in release 3.32). Furthermore, when analyzing
the latest SCONE 5.8.0 release, Pandora found that the
in-enclave memcpy function was not properly patched to

exclude SBDR issues which will be fixed in 5.9.0. Existing
mitigations in Gramine, Rust-EDP, and Open Enclave were
found sufficient, but ÆPICSan autonomously discovered a
missing SBDR sanitization in the enclave initialization phase
of the latest version of the Intel SGX SDK (also inherited by
the derived Occlum runtime), highlighting that adequately
restricting untrusted pointer alignments is challenging even
for mature runtime developers.

As expected, we additionally confirmed that ÆPICSan
can automatically reproduce ample SBDR and DRPW issues
in older versions of Gramine, Rust-EDP, Open Enclave, and
the Intel SGX SDK without mitigations.

7.2.4. Control Flow Issues. The CFSan plugin found a
delicate issue in EnclaveOS where the global offset table
(GOT) is incorrectly accessed before relocation of the en-
clave has completed. The GOT is used to jump to functions
in position-independent code and has to be securely initial-
ized, i.e., relocated, before it can be used inside enclaves.
The issue found by Pandora, and confirmed and fixed by
Fortanix in version 3.31, concerns an unusual trace where
an error occurs during initialization, which results in the
code calling a debug logging function. A similarly evasive
GOT relocation issue in an early-error path was reported by
CFSan for SCONE 5.8.0, to be patched in 5.9.0.

Furthermore, CFSan found that Inclavare’s bare-metal
enclave assembly entry stub incorrectly uses a signed JGE
x86 jump instruction, instead of a proper unsigned JAE con-
dition to sanitize the attacker-provided index into the ecall
function-pointer table. Critically, this subtle oversight ulti-
mately allows arbitrary control-flow hijacking by passing a
large negative index into the ecall table and loading the
function pointer from untrusted, attacker-controlled memory.
Likewise, CFSan found that, depending on the optimization
level, in-enclave relocation code for the ecall table was
missing in the dispatcher of the Linux selftest enclave.

Finally, due to the lack of secure stack switching in

GoTEE, CFSan reported unconstrained RET targets.

8. Discussion

We see Pandora as a mature prototype of an enclave-
aware symbolic execution tool that can serve as a basis for
future science. In particular, we designed Pandora with great
care for usability,
through a well-documented command
line interface and detailed HTML reports, and reusability
through our plugin-based approach that makes it easy to
implement additional security analyses. Pandora has demon-
strated its usefulness by automatically finding vulnerabilities
in production runtimes. Hence, we believe that Pandora is a
valuable step forward in vulnerability detection for enclaves.

Coverage. We consider the main limitation of Pandora to
be incomplete coverage, i.e., the infeasibility to explore a
binary as a whole with symbolic execution. This is due to
the fact that Pandora, as any symbolic-execution tool, suffers
from the well-known limitation of state explosion, which can
make exhaustive exploration of larger binaries practically

infeasible. Hence, vulnerabilities can still remain undetected
in unexplored paths. We implemented novel, enclave-aware
performance optimizations, including uninitialized memory
and state-uniqueness reductions (cf. Section 4.5), and we
utilized both breadth-first and depth-first exploration in our
evaluation to cover more enclave behavior.

Our choice for angr [52] as the underlying symbolic-
execution engine may also in itself be a source of in-
complete coverage, as angr is not guaranteed to be sound
and may concretize values during symbolic execution. To
avoid missing program behavior, we adopted the most con-
servative approach whenever possible and tried to refrain
from unnecessary concretization of symbolic values. Despite
these limitations, angr is particularly powerful for rapid
development of vulnerability plugins in comparison to fully
fledged code verification tools.

A further possible technical, but not inherent, limitation
concerns Pandora’s coverage of any encrypted code that
would be loaded at runtime to execute a confidential enclave
application. Such code could be transparently supported by
providing Pandora with the decryption key, which could then
be used by the symbolic execution engine to automatically
decrypt and execute the code. That being said, the primary
focus of Pandora are runtimes, which are usually not utiliz-
ing such encrypted code loading themselves.

We consider the fact that Pandora was able to automati-
cally uncover vulnerabilities in production runtimes as clear
evidence for the practicality of our approach to validate
enclave shielding runtimes. The (orthogonal) extension of
Pandora’s truthful enclave-aware symbolic-exploration to
also analyze arbitrary (and potentially larger and deeper)
enclave application logic would require further scaling that
could conceivably benefit from optimizations proposed in
previous work [37], [39].

Accuracy. As any automatic vulnerability scanner, Pandora
may report false-positive issues, which could lead to overly
exhaustive outputs. We attempt to limit the strain on the
human analyst via two steps. First, potential issues are clas-
sified into multiple levels of criticality, and the reports are
formatted in modern HTML forms that allow to filter criti-
cality levels. Second, plugins may downgrade the severity of
issues via sensible heuristics, e.g., Section 6.2 explained how
PTRSan downgrades attacker-tainted pointers when they are
constrained to a region entirely inside the enclave, closely
resembling the benign pattern of an attacker-controlled index
in a trusted enclave buffer. All critical issues found by
Pandora listed in Table 2 were reported to the vendors who
acknowledged the vulnerabilities. Hence, we are not aware
of any false-positive results for these critical issues. Beyond
this, Pandora heuristically downgraded 124 of 452 (27 %)
vulnerabilities to warnings, where we are not aware of any
of those being exploitable.

Regarding false negatives, there is unfortunately no stan-
dardized ground truth of existing vulnerabilities for Intel
SGX runtimes, and a direct comparison of Pandora to re-
lated approaches is not feasible as their target (i.e., enclave
application logic) is orthogonal. Therefore, we followed a

best-effort approach and let Pandora successfully reproduce
known runtime vulnerabilities (cf. Table 2). Our analysis
clearly shows that Pandora reproduced all known vulner-
abilities from selected work [21], [22] and even found
an overlooked issue (cf. §7.2.2). We consider the main
limitation to be incomplete coverage, which may lead to
vulnerabilities on unexplored paths not being detected (e.g.,
CVE-2021-44421 in Occlum).

Future Work. Potential future extensions of Pandora con-
cern novel vulnerability-detection plugins, as well as the
investigation of transient execution access patterns in en-
claves [66]–[68]. Furthermore, we see Pandora as a useful
tool for a broad ecosystem analysis of the Intel SGX land-
scape and how fast vulnerability patches propagate across
runtimes. Ultimately, future work could even explore au-
tomated exploit generation and binary patching using Pan-
dora’s precise vulnerability reports.

There are additionally some performance improvements
that could allow Pandora to explore enclaves in more depth.
While we already implemented a depth-first extension to
Pandora that severely limits the memory use necessary
during exploration, angr still only uses one single CPU
core. Future work could thus investigate how angr symbolic
exploration can be split up onto multiple cores while re-
taining the same enclave-aware characteristics of Pandora
that are necessary to e.g., identify enclave boundaries. Ad-
ditionally, to mitigate path explosion, we could also adopt
state-merging [69] or path prioritization strategies [49], [70].

9. Conclusion

In recent years, a sizable ecosystem of Intel SGX enclave
shielding runtimes has emerged. However, writing secure
SGX software has proven to be particularly challenging due
to the moving nature of the threat landscape, and not even
well-designed and vetted shielding runtimes have been im-
mune to missing nuanced attack vectors or to reintroducing
already known vulnerabilities into their code. The research
community has only recently started to look into SGX-aware
symbolic execution, but has focused on application logic
only, while largely skipping the crucial enclave shielding
runtime itself. In this work, we presented Pandora,
the
first enclave-aware and pluggable symbolic-execution tool
that allows truthfully validating arbitrary enclave binaries,
including low-level runtime initialization and entry phases.
With 4 diverse prototype plugins, we found 200 new and
69 known vulnerable code locations across a wide selection
of 11 SGX runtimes. Ultimately, we envision Pandora not
only as a practical validation tool for real-world enclave run-
times today, but also as a solid, extensible and open-source
foundation for future science on SGX software validation
of enclave shielding runtimes.

Acknowledgments. This research is partially funded by
grants of the Research Foundation – Flanders (FWO), un-
der grant numbers 11E5120N, 1261222N, 12B2A24N and

G081322N, and by the Flemish Research Programme Cyber-
security. This research was supported by the UK Engineer-
ing and Physical Sciences Research Council (EPSRC) under
grants EP/R012598/1, EP/V000454/1, and EP/S030867/1.
The results feed into DsbDtech. Some computations de-
scribed in this paper were performed using the University
of Birmingham’s BlueBEAR HPC service, which provides
a High Performance Computing service to the University’s
research community.

References

[1] V. Costan and S. Devadas, “Intel SGX explained.” IACR Cryptology

ePrint Archive, vol. 2016, no. 086, 2016.

[2]

F. McKeen, I. Alexandrovich, A. Berenzon, C. V. Rozas, H. Shafi,
V. Shanbhogue, and U. R. Savagaonkar, “Innovative instructions and
software model for isolated execution,” in Proceedings of the 2nd
International Workshop on Hardware and Architectural Support for
Security and Privacy. ACM, 2013.

[3]

Intel, “Intel Trust Domain Extensions,” Feb. 2022.
Available: https://cdrdv2.intel.com/v1/dl/getContent/690419

[Online].

[4] ——, “Intel Software Guard Extensions – Get Started with the SDK,”

2023. [Online]. Available: https://software.intel.com/en-us/sgx/sdk

[5] Microsoft,

“Open Enclave SDK,” 2023.

[Online]. Available:

https://openenclave.io/

[6] A. Baumann, M. Peinado, and G. Hunt, “Shielding applications
from an untrusted cloud with haven,” in Proceedings of the 11th
USENIX conference on Operating Systems Design and Implementa-
tion. USENIX Association, 2014.

[7]

S. Arnautov, B. Trach, F. Gregor, T. Knauth, A. Martin, C. Priebe,
J. Lind, D. Muthukumaran, D. O’Keeffe, M. L. Stillwell et al.,
“SCONE: Secure Linux containers with Intel SGX,” in 12th USENIX
Symposium on Operating Systems Design and Implementation.
USENIX Association, 2016.

[8] C.-C. Tsai, D. E. Porter, and M. Vij, “Graphene-SGX: A practical
library OS for unmodified applications on SGX,” in USENIX Annual
Technical Conference (ATC), 2017.

[9] C. Priebe, D. Muthukumaran, J. Lind, H. Zhu, S. Cui, V. A. Sartakov,
and P. Pietzuch, “SGX-LKL: securing the host OS interface for trusted
execution,” arXiv preprint arXiv:1908.11143, 2019.

[10] Y. Shen, H. Tian, Y. Chen, K. Chen, R. Wang, Y. Xu, Y. Xia, and
S. Yan, “Occlum: Secure and efficient multitasking inside a single
enclave of intel sgx,” in Proceedings of the Twenty-Fifth International
Conference on Architectural Support for Programming Languages
and Operating Systems, 2020.

[11] Fortanix, “Fortanix enclave development platform – rust edp,” 2023.

[Online]. Available: https://edp.fortanix.com/

[12] A. Ghosn, J. R. Larus, and E. Bugnion, “Secured routines: Language-
based construction of trusted execution environments,” in USENIX
Annual Technical Conference (ATC), 2019.

[13] Enarx Project, “Enarx: Webassembly + confidential computing,”

https://enarx.dev/, 2023.

[14] Edgeless Systems, “Edgeless RT,” https://github.com/edgelesssys/

edgelessrt, 2022.

[15] A. Nilsson, P. N. Bideh, and J. Brorsson, “A survey of published
attacks on intel sgx,” arXiv preprint arXiv:2006.13598, 2020.

[16] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci,
F. Piessens, M. Silberstein, T. F. Wenisch, Y. Yarom, and R. Strackx,
“Foreshadow: Extracting the keys to the Intel SGX kingdom with
transient out-of-order execution,” in Proceedings of the 27th USENIX
Security Symposium, Aug. 2018.

[17] M. Schwarz, M. Lipp, D. Moghimi, J. Van Bulck, J. Stecklina,
T. Prescher, and D. Gruss, “ZombieLoad: Cross-privilege-boundary
data sampling,” in Proceedings of the 26th ACM Conference on
Computer and Communications Security (CCS’19).
ACM, Nov.
2019.

[18] K. Murdock, D. Oswald, F. D. Garcia, J. Van Bulck, D. Gruss,
and F. Piessens, “Plundervolt: Software-based fault injection attacks
against Intel SGX,” in Proceedings of the 41th IEEE Symposium on
Security and Privacy (S&P’20), May 2020.

[19] S. van Schaik, A. Milburn, S. ¨Osterlund, P. Frigo, G. Maisuradze,
K. Razavi, H. Bos, and C. Giuffrida, “RIDL: Rogue in-flight data
load,” in S&P, May 2019.

[20] G. Chen, S. Chen, Y. Xiao, Y. Zhang, Z. Lin, and T. H. Lai,
“SgxPectre attacks: Stealing Intel secrets from SGX enclaves via
speculative execution,” in 4th IEEE European Symposium on Security
and Privacy (Euro S&P).
IEEE, 2019.

[21] J. Van Bulck, D. Oswald, E. Marin, A. Aldoseri, F. D. Garcia, and
F. Piessens, “A tale of two worlds: Assessing the vulnerability of
enclave shielding runtimes,” in 26th ACM Conference on Computer
and Communications Security (CCS), Nov. 2019.

[22] F. Alder, J. Van Bulck, D. Oswald, and F. Piessens, “Faulty point
unit: ABI poisoning attacks on Intel SGX,” in 36th Annual Computer
Security Applications Conference (ACSAC), Dec. 2020.

[23] J. Cui, J. Z. Yu, S. Shinde, P. Saxena, and Z. Cai, “Smashex:
Smashing sgx enclaves using exceptions,” in 28th ACM Conference
on Computer and Communications Security (CCS), 2021.

[24] Intel Corporation, “Deep dive: Load value injection,” 2020.

[25] P. Borrello, A. Kogler, M. Schwarzl, M. Lipp, D. Gruss, and
M. Schwarz, “ÆPIC Leak: Architecturally leaking uninitialized data
from the microarchitecture,” in 31st USENIX Security Symposium
(USENIX Security 22), 2022.

[26] Intel, “Processor MMIO stale data vulnerabilities,” June 2022.
https://www.intel.com/content/www/us/en/

[Online].
developer/articles/technical/software-security-guidance/technical-
documentation/processor-mmio-stale-data-vulnerabilities.html

Available:

[27] ——, “Mxcsr configuration dependent timing,” Aug. 2022. [Online].
https://www.intel.com/content/www/us/en/developer/

Available:
articles/technical/software-security-guidance/best-practices/mxcsr-
configuration-dependent-timing.html

[28] J. Van Bulck, D. Moghimi, M. Schwarz, M. Lipp, M. Minkin,
D. Genkin, Y. Yuval, B. Sunar, D. Gruss, and F. Piessens, “LVI: Hi-
jacking transient execution through microarchitectural load value in-
jection,” in 41st IEEE Symposium on Security and Privacy (S&P’20),
May 2020.

[29] A. Kogler, D. Gruss, and M. Schwarz, “Minefield: A software-only
protection for SGX enclaves against DVFS attacks,” in 31st USENIX
Security Symposium (USENIX Security 22), 2022.

[30] L. Giner, A. Kogler, C. Canella, M. Schwarz, and D. Gruss, “Repur-
posing segmentation as a practical LVI-NULL mitigation in SGX,”
in 31st USENIX Security Symposium (USENIX Security 22), 2022.

[31] M.-W. Shih, S. Lee, T. Kim, and M. Peinado, “T-SGX: Eradicating
controlled-channel attacks against enclave programs,” in Proceedings
of the 2017 Annual Network and Distributed System Security Sympo-
sium (NDSS), San Diego, CA, Feb. 2017.

[32] S. Hosseinzadeh, H. Liljestrand, V. Lepp¨anen, and A. Paverd, “Miti-
gating branch-shadowing attacks on intel sgx using control flow ran-
domization,” in Proceedings of the 3rd Workshop on System Software
for Trusted Execution, 2018.

[33] F. Brasser, S. Capkun, A. Dmitrienko, T. Frassetto, K. Kostiainen, and
A.-R. Sadeghi, “Dr. SGX: automated and adjustable side-channel pro-
tection for SGX using data location randomization,” in Proceedings
of the 35th Annual Computer Security Applications Conference, 2019.

[35] R. Cui, L. Zhao, and D. Lie, “Emilia: Catching iago in legacy code.”

in NDSS, 2021.

[36] M. Orenbach, B. Raveh, A. Berkenstadt, Y. Michalevsky, S. Itzhaky,
and M. Silberstein, “Securing access to untrusted services from TEEs
with GateKeeper,” arXiv preprint arXiv:2211.07185, 2022.

[37] T. Cloosters, M. Rodler, and L. Davi, “Teerex: Discovery and ex-
ploitation of memory corruption vulnerabilities in SGX enclaves,” in
Proceedings of the 29th USENIX Security Symposium, 2020.

[38] P. Antonino, W. A. Woloszyn, and A. Roscoe, “Guardian: Symbolic
validation of orderliness in sgx enclaves,” in Proceedings of the 2021
on Cloud Computing Security Workshop, 2021.

[39] M. R. Khandaker, Y. Cheng, Z. Wang, and T. Wei, “COIN Attacks: On
Insecurity of Enclave Untrusted Interfaces in SGX,” in Proceedings of
the Twenty-Fifth International Conference on Architectural Support
for Programming Languages and Operating Systems, 2020.

[40] Intel, “Stale data read from legacy xAPIC,” Aug. 2022. [Online].
https://www.intel.com/content/www/us/en/developer/

Available:
articles/technical/software-security-guidance/advisory-guidance/
stale-data-read-from-xapic.html

[41] J. Van Bulck, F. Alder, and F. Piessens, “A case for unified ABI
shielding in Intel SGX runtimes,” in 5th Workshop on System Software
for Trusted Execution (SysTEX). ACM, Mar. 2022.

[42] J. C. King, “Symbolic execution and program testing,” Commun.

ACM, vol. 19, no. 7, 1976.

[43] P. Godefroid, M. Y. Levin, and D. A. Molnar, “SAGE: whitebox

fuzzing for security testing,” Commun. ACM, vol. 55, no. 3, 2012.

[44] S. K. Cha, T. Avgerinos, A. Rebert, and D. Brumley, “Unleashing
mayhem on binary code,” in IEEE Symposium on Security and
Privacy, SP 2012, 21-23 May 2012, San Francisco, California, USA.
IEEE Computer Society, 2012.

[45] T. Yavuz, F. Fowze, G. Hernandez, K. Y. Bai, K. R. Butler, and
D. J. Tian, “ENCIDER: Detecting Timing and Cache Side Channels
in SGX Enclaves and Cryptographic APIs,” IEEE Transactions on
Dependable and Secure Computing, 2022.

[46] G. Duan, Y. Fu, B. Zhang, P. Deng, J. Sun, H. Chen, and Z. Chen,
“Teefuzzer: A fuzzing framework for trusted execution environments
with heuristic seed mutation,” Future Generation Computer Systems,
2023.

[47] A. Khan, M. Zou, K. Kim, D. Xu, A. Bianchi, and D. J. Tian,
“Fuzzing sgx enclaves via host program mutations,” in 8th European
Symposium on Security and Privacy (EuroS&P).

IEEE, 2023.

[48] Y. Shoshitaishvili, R. Wang, C. Salls, N. Stephens, M. Polino,
A. Dutcher, J. Grosen, S. Feng, C. Hauser, C. Kruegel, and G. Vigna,
“SoK: (State of) The Art of War: Offensive Techniques in Binary
Analysis,” in IEEE Symposium on Security and Privacy, 2016.

[49] R. Baldoni, E. Coppa, D. C. D’Elia, C. Demetrescu, and I. Finocchi,
“A survey of symbolic execution techniques,” ACM Comput. Surv.,
vol. 51, no. 3, 2018.

[50] I. Anati, S. Gueron, S. Johnson, and V. Scarlata, “Innovative tech-
nology for CPU based attestation and sealing,” in Proceedings of the
2nd international workshop on hardware and architectural support
for security and privacy, vol. 13, 2013.

[51] Y. Wang, Z. Zhang, N. He, Z. Zhong, S. Guo, Q. Bao, D. Li,
Y. Guo, and X. Chen, “Symgx: Detecting cross-boundary pointer
vulnerabilities of sgx applications via static symbolic execution,” in
30th ACM Conference on Computer and Communications Security
(CCS), 2023, p. 2710–2724.

[52] F. Wang and Y. Shoshitaishvili, “Angr-the next generation of binary

analysis,” in Cybersecurity Development (SecDev).

IEEE, 2017.

[53] Intel Corporation, Intel 64 and IA-32 architectures software devel-

oper’s manual, 2020, reference no. 325462-062US.

[34] T. Cloosters, J. Willbold, T. Holz, and L. Davi, “SGXFuzz: Efficiently
synthesizing nested structures for SGX enclave fuzzing,” in 31st
USENIX Security Symposium (USENIX Security 22), 2022.

[54] D. Schoepe, M. Balliu, B. C. Pierce, and A. Sabelfeld, “Explicit
secrecy: A policy for taint tracking,” in 2016 IEEE European Sym-
posium on Security and Privacy (EuroS&P).

IEEE, 2016.

[55] W. Xu, S. Bhatkar, and R. Sekar, “Taint-enhanced policy enforcement:
A practical approach to defeat a wide range of attacks,” in 15th
USENIX Security Symposium, 2006.

[56] J. Van Bulck, F. Piessens, and R. Strackx, “SGX-Step: A practical
attack framework for precise enclave execution control,” in 2nd
Workshop on System Software for Trusted Execution (SysTEX 2017).
ACM, Oct. 2017.

[57] H. Lu, D. L. Kreitzer, M. Girkar, and Z. Ansari, “System V appli-
cation binary interface,” Intel386 Architecture Processor Supplement,
Version 1.1, December 2015.

[58] A. Fog, “Calling conventions for different c++ compilers and operat-
ing systems,” http://www.agner.org/optimize/calling conventions.pdf,
Apr. 2018.

[59] L. Torvalds, “Linux operating system,” kernel.org, 2023.

[60] J. Sakkinen and N. McCallum, “selftests/x86: Add a selftest
for sgx,” Mar. 2020. [Online]. Available: https://lkml.kernel.org/lkml/
04362c0cf66bf66e8f7c25a531830b9f294d2d09.camel@linux.intel.com/

[61] AliBaba,

“Inclavare

cloud-
confidential
[Online]. Avail-
Jun.
https://www.alibabacloud.com/blog/inclavare-containers-the-

native
able:
future-of-cloud-native-confidential-computing 598992

computing,”

containers:

future

2022.

The

of

[62] V. Scarlata, S. Johnson, J. Beaney, and P. Zmijewski, “Supporting
third party attestation for Intel SGX with Intel data center attestation
primitives,” White paper, 2018.

[63] Fortanix, “Fortanix runtime encryption platform and enclaveos,” https:

//www.fortanix.com/platform/runtime-encryption, 2023.

[64] Scontain GmbH, “Scone – a secure container environment,” 2023.

[Online]. Available: https://scontain.com/

[65] The Gramine Workgroup, “Gramine – a library os for unmodified

applications,” https://gramineproject.io/, 2023.

[66] M. Guarnieri, B. K¨opf, J. F. Morales, J. Reineke, and A. S´anchez,
“Spectector: Principled detection of speculative information flows,”
in IEEE Symposium on Security and Privacy.

IEEE, 2020.

[67] L. Daniel, S. Bardin, and T. Rezk, “Hunting the haunter - efficient
relational symbolic execution for spectre with haunted relse,” in
NDSS. The Internet Society, 2021.

[68] S. Cauligi, C. Disselkoen, K. von Gleissenthall, D. M. Tullsen,
D. Stefan, T. Rezk, and G. Barthe, “Constant-time foundations for
the new spectre era,” in PLDI. ACM, 2020.

[69] V. Kuznetsov, J. Kinder, S. Bucur, and G. Candea, “Efficient state

merging in symbolic execution,” in PLDI. ACM, 2012.

[70] Y. Li, Z. Su, L. Wang, and X. Li, “Steering symbolic execution to
less traveled paths,” SIGPLAN Not., vol. 48, no. 10, oct 2013.

Appendix A.
Pandora CLI and Report Generation (D1)

We designed Pandora with great care for usability (D1),
through a well-documented command line interface (CLI)
and detailed HTML reports. Figure 3 shows an example of a
human-readable, interactive HTML report from the PTRSan
plugin discovering unconstrained pointer dereferences in the
Linux selftest enclave (cf. Section 7.1). Figure 4 shows a
part of the interactive command line interface of Pandora,
which is intended to be highly usable for both rapid proto-
typing of new plugins and for long, unattended exploration
runs. Issues are reported on the command line during a run,
but are also logged in a JSON file that can later be expanded
into the fully-fledged HTML reports visible in Figure 3. If
the human analyst wishes, multiple breakpoints regarding

Figure 3. Example of an HTML report generated by Pandora.

the exploration and the plugins are readily available from
the command line, i.e., to interrupt execution on interesting
events and switch into a Python shell. This allows to quickly
implement and troubleshoot plugins. Lastly, several options
of Pandora are, in addition to the CLI, exposed via config-
uration files, allowing to define long-lasting analysis setups
that can be controlled by changing few program options.

We leave it for future work to rigorously investigate
to what extent Pandora achieved D1, e.g., by means of
a comprehensive and unbiased user study. Such a user
study should investigate whether the reporting generated by
Pandora is factually useful for a human analyst, and perform
a quantitative analysis on the benefit of additional CLI and
reporting features.

Appendix B.
Static Analysis of Enclave Runtimes

This appendix describes optional support we added to
Pandora to load enclave binaries from selected runtimes with
purely static analysis only, i.e., without first requiring the
SGX-TRACER dynamic memory extraction phase described

TRACER enclave memory extractor approach as the default
runtime-agnostic and truthful loader in Pandora, as also used
in the evaluation of Section 7.

Linux Selftest Enclave. First,
the Linux selftest en-
clave [59] is a minimal, self-contained enclave that has a
fixed memory layout, with the TCS always being stored
at the start of the enclave range. This makes it an ideal
baseline runtime as no enclave initialization is necessary
and all relevant addresses are statically known at compile
time. The Linux selftest enclave serves as the foundation
for Pandora’s unit-test validation framework, discussed in
Section 7.1.

Intel SGX SDK. Second, the Intel SGX SDK [4] encodes
all
information for the loading process in an additional
ELF metadata section. Based on manual analysis of the
open-source code of the Intel SGX SDK enclave loader,
we added full support in Pandora to decode this opaque
blob and extract the expected locations of TCSs, stack and
heap regions, and patches to initialize enclave global data
structures. We implemented mature support to perform these
steps in Intel SGX SDK version 2.18.1 and also validated
backwards compatibility and added support for version-
specific fields in versions 2.18 and 2.17.1.

SCONE. Lastly, we show that, in principle, the static en-
clave loading approach is even feasible without access to
source code by implementing an elementary (incomplete)
static loader for the proprietary SCONE [7] runtime. Specifi-
cally, we manually reverse engineered the enclave layout and
location of TCS data structures and thread-local memory
using a debugger. Based on this partial layout, our static
loader inserts the required data structures into the symbolic
memory layout when loading the SCONE runtime binary
ELF file.

Appendix C.
Pandora Breakpoints

Table 3 lists all enclave-aware breakpoints added by
Pandora. To accommodate various investigation scenarios,
all breakpoints can be triggered before and after the event
happened, i.e., to investigate an event both before or after it
had an impact on a Pandora state. For example, Pandora
memory read breakpoint, similarly to angr memory read
breakpoints, can be triggered before the read has happened,
exposing, among other, its address and size; or after the read
has happened, additionally exposing its value.

Appendix D.
Vulnerability Details

Table 4 provides a more detailed breakdown of the
vulnerable code locations found by Pandora, as also sum-
marized in Table 2 and discussed in Section 7.

Figure 4. Part of the command line interface of Pandora depicting helpful
command options to the user.

in Section 5. The difficulty in adequately supporting arbi-
trary enclave runtimes in this way lies in parsing opaque
enclave memory layout metadata from the binary and load-
ing SGX-specific data structures into the symbolic execu-
tion memory after the ELF file has been loaded. Although
inherently fragile and version-specific, we show that it is
in principle possible to implement such support entirely
statically for three exemplary runtime loaders.

While we consider some of these static loaders to be
mature and satisfying our truthful initial memory layout cri-
terion (G1b), we note that this highly labor-intensive static-
analysis approach is evidently not runtime-agnostic (vs.
G2). Furthermore, even for the individual runtimes that are
supported, the static-analysis approach remains inherently
fragile, as new versions of these runtimes may completely
break or change the way runtime-specific data structures
are utilized in the enclave.4 Thus, we use our novel SGX-

4. Examples of such changes in the past were versions 2.4, 2.14, and 2.17
of the Intel SGX SDK when the internal _global_data_t C structure
was modified which resulted in altered offsets for the address of the enclave
base address, a crucial piece of information to properly resolve addresses
inside the enclave.

TABLE 3. LIST OF BREAKPOINTS ADDED BY PANDORA. PLUGINS CAN HOOK THESE NEW BREAKPOINTS, IN ADDITION TO ALL LEGACY ANGR
BREAKPOINTS, TO INVESTIGATE SPECIFIC EVENTS DURING EXPLORATION. ALL EVENTS CAN BE HOOKED BEFORE AND AFTER THEY ARE EXPLORED.
INDIVIDUAL BREAKPOINTS MAY ADDITIONALLY EXPOSE SPECIFIC ARGUMENTS, E.G., SYMBOLIC MEMORY ADDRESSES AND SIZES.

Breakpoint event

Triggered by Pandora module

Description

eenter
eexit
untrusted_mem_read
trusted_mem_read
inside_or_outside_mem_read
untrusted_mem_write
trusted_mem_write
inside_or_outside_mem_write

Enclave (Re)entry
SGX Instructions
Enclave Memory
Enclave Memory
Enclave Memory
Enclave Memory
Enclave Memory
Enclave Memory

A state is prepared to (re)enter the enclave
An EEXIT ENCLU is executed
Reads that fully lie in untrusted memory
Reads that fully lie in enclave memory
Reads that may lie in either region
Writes that fully lie in untrusted memory
Writes that fully lie in enclave memory
Writes that may lie in either region

TABLE 4. DETAILED EVIDENCE OF PANDORA FINDING AND REPRODUCING VULNERABILITIES BOTH IN PRODUCTION AND RESEARCH RUNTIMES,
WHERE THE “DEPTH” COLUMN LISTS THE NUMBER OF BASIC BLOCKS EXPLORED BEFORE THE VULNERABILITY (MIN–MAX); “L” INDICATES THE
LOCATION (ENTRY, INITIALIZATION, APPLICATION) OF THE VULNERABILITY; AND COLUMN “O” INDICATES WHETHER THE VULNERABILITY COULD
HAVE BEEN FOUND BY EXISTING, STATE-OF-THE-ART SGX SYMBOLIC-EXECUTION TOOLS [37], [38].

Runtime

Version Prod Src Plugin

L Depth

Instances Description

O

DCAP
Inclavare

Newly found vulnerabilities in shielding runtimes (total 200 instances)
1
EnclaveOS
EnclaveOS
10
EnclaveOS
EnclaveOS
EnclaveOS
GoTEE
GoTEE
GoTEE
Gramine
Intel SDK
Intel SDK
Occlum

3.28
3.28
3.28
3.28
3.28
014b35f
014b35f
014b35f
1.4
2.15.1
2.19
0.29.4

✓ ✗† ABISan
8
E
✓ ✗† PTRSan
14–48
E
✓ ✗† PTRSan
15495–15521 5
I
✓ ✗† ÆPICSan I
33
14–100
✓ ✗† CFSan
2
I
51
✗ ✓ PTRSan
31
E/I 2–82
✗ ✓ ÆPICSan E/I 2–82
18
✗ ✓ CFSan
I
1
✓ ✓ ABISan
E
1
✓ ✓ PTRSan
2
I
✓ ✓ ÆPICSan I
22
✓ ✓ ÆPICSan I
11
✗ ✓ ABISan
1
E
✓ ✓ ABISan
1
E
✗ ✓ ABISan
1
E
✗ ✓ PTRSan A 4–7
5
✓ ✓ PTRSan A 3–1075
17
✗ ✓ PTRSan A 8–539
2
✗ ✓ CFSan
A 5
1
✗ ✓ CFSan
3
E
1
✓ ✓ ABISan
11
E
1
✓ ✓ ABISan
11
E
1
✓ ✓ ABISan
7
E
1
✓ ✗
ABISan
3
E
1
✓ ✗
PTRSan
10
25–1827
I
✓ ✗
ÆPICSan I
11
25–1827
✓ ✗
ABISan
1
5
I
✓ ✗
ÆPICSan I
3
1342–1624
✓ ✗
PTRSan
3
1621
I
✓ ✗
CFSan
1
864
I

Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
1.16
0.6.2
Linux selftest 5.18
0.6.2
Open Enclave 0.19.0
Open Enclave 0.19.0
Rust EDP
SCONE
SCONE
SCONE
SCONE
SCONE
SCONE
SCONE

82
8
29–30
234
17222
1
1
1

1.71
5.7.0
5.7.0
5.7.0
5.8.0
5.8.0
5.8.0
5.8.0

DCAP
Inclavare

Inclavare

SBDR inherited

Unsanitized AC/DF, MXCSR, and FPU

✗
MXCSR dependent timing
✗
Compiler removed overflow check
strlen on unconstrained ptr (CVE-2023-38022) ✗
✗
Various SBDR issues (CVE-2023-38021)
✗
PIC jump before relocation
✗
Various unconstrained pointers
✗
Various SBDR/DRPW issues
✗
Unconstrained RET targets
✗
MXCSR dependent timing
✗
Unconstrained pointer (CVE-2022-26509)
✗
SBDR in enclave initialization
✗
✗
✗
Missing sanitization on entry
✗
Missing sanitization on entry
✗
Various unconstrained pointers
✗
Various unconstrained pointers
✗
Unconstrained src/dst addresses in memcpy
✗
PIC jump before relocation
Unsigned jump target comparison in ecall array ✗
✗
Unsanitized AC (regression) (CVE-2023-37479)
✗
MXCSR dependent timing
✗
MXCSR dependent timing
✗
Unsanitized FPU (CVE-2022-46487)
✗
Various pointer issues (CVE-2022-46486)
✗
Various SBDR/DRPW issues (CVE-2023-38023)
✗
MXCSR dependent timing
✗
Various SBDR issues
✗
Unconstrained read
✗
PIC jump before relocation

014b35f
1.2
2.1.1
2.13.3

Reproduced vulnerabilities in older versions (total 69 instances)
GoTEE
Gramine
Intel SDK
Intel SDK
Open Enclave 0.4.1
Open Enclave 0.4.1
Open Enclave 0.4.1
1.63
Rust EDP

✗ ✓ ABISan
E
✓ ✓ ÆPICSan I
✓ ✓ ABISan
E
✓ ✓ ÆPICSan I
✓ ✓ ABISan
E
✓ ✓ PTRSan
I
✓ ✓ ÆPICSan I
✓ ✓ ÆPICSan I

3
22–55
3
207–6198
4
402–1712
442–1712
1041–1043

1
10
1
28
1
13
13
2

Unsanitized FPU [22]
Various SBDR/DRPW issues
Unsanitized DF/AC [21]; FPU [22]
Various SBDR/DRPW issues
Unsanitized DF [21]
Unconstrained pointers [21]
Various SBDR/DRPW issues
Various SBDR/DRPW issues

✗
✗
✓
✗
✗
✗
✗
✗

Legend: † Not open source, but source code was made privately available;

Based on above runtime.

Appendix E.
Meta-Review

The following meta-review was prepared by the program
committee for the 2024 IEEE Symposium on Security and
Privacy (S&P) as part of the review process as detailed in
the call for papers.

E.1. Summary

This paper introduces Pandora, a symbolic execution
tool that analyzes the security of enclave runtimes. The de-
sign of Pandora is focused on providing end-to-end analysis
(including low-level runtime initialization and entry phases)
and being runtime agnostic, extensible, and accessible. Pan-
dora is shown to provide for the first time a comprehensive
analysis of enclave shielding runtimes, discovering 200 new
vulnerabilities across 11 widely used enclave shielding run-
times.

E.2. Scientific Contributions

• Creates a new tool to enable future science
• Identifies an impactful vulnerability
• Provides a valuable step forward in an established field

E.3. Reasons for Acceptance

1) The paper introduces Pandora, a symbolic execution
tool for enclave shielding runtimes. The central goal
of Pandora is on truthful validation of SGX binaries,
considering critical initialization code that prior sys-
tems have overlooked. The tool is runtime agnostic and
therefore applicable to many enclave applications.
2) The paper identifies several new vulnerabilities. The ex-
periments demonstrate the Pandora discovers 200 new
vulnerabilities across 11 widely used enclave shielding
runtimes.

3) The paper provides a valuable step forward in the study
of enclave security. The paper describes the challenges
associated with a sound end-to-end analysis of enclave
interfaces, and the results show that there is still a
significant amount of work to be done to improve the
security of enclave applications.



=== Content from jovanbulck.github.io_3535c37c_20250110_142458.html ===
A Tale of Two Worlds: Assessing the Vulnerability of Enclave
Shielding Runtimes

Jo Van Bulck
imec-DistriNet, KU Leuven
jo.vanbulck@cs.kuleuven.be

David Oswald
The University of Birmingham, UK
d.f .oswald@cs.bham.ac.uk

Eduard Marin
The University of Birmingham, UK
e.marin@cs.bham.ac.uk

Abdulla Aldoseri
The University of Birmingham, UK
axa1170@student.bham.ac.uk

Flavio D. Garcia
The University of Birmingham, UK
f .garcia@cs.bham.ac.uk

Frank Piessens
imec-DistriNet, KU Leuven
frank.piessens@cs.kuleuven.be

ABSTRACT
This paper analyzes the vulnerability space arising in Trusted Ex-
ecution Environments (TEEs) when interfacing a trusted enclave
application with untrusted, potentially malicious code. Consider-
able research and industry effort has gone into developing TEE
runtime libraries with the purpose of transparently shielding en-
clave application code from an adversarial environment. However,
our analysis reveals that shielding requirements are generally not
well-understood in real-world TEE runtime implementations. We
expose several sanitization vulnerabilities at the level of the Ap-
plication Binary Interface (ABI) and the Application Programming
Interface (API) that can lead to exploitable memory safety and side-
channel vulnerabilities in the compiled enclave. Mitigation of these
vulnerabilities is not as simple as ensuring that pointers are out-
side enclave memory. In fact, we demonstrate that state-of-the-art
mitigation techniques such as Intel’s edger8r, Microsoft’s “deep
copy marshalling”, or even memory-safe languages like Rust fail
to fully eliminate this attack surface. Our analysis reveals 35 en-
clave interface sanitization vulnerabilities in 8 major open-source
shielding frameworks for Intel SGX, RISC-V, and Sancus TEEs. We
practically exploit these vulnerabilities in several attack scenarios
to leak secret keys from the enclave or enable remote code reuse.
We have responsibly disclosed our findings, leading to 5 desig-
nated CVE records and numerous security patches in the vulnerable
open-source projects, including the Intel SGX-SDK, Microsoft Open
Enclave, Google Asylo, and the Rust compiler.

KEYWORDS
Trusted execution, TEE, Intel SGX, memory safety, side-channels

ACM Reference Format:
Jo Van Bulck, David Oswald, Eduard Marin, Abdulla Aldoseri, Flavio D.
Garcia, and Frank Piessens. 2019. A Tale of Two Worlds: Assessing the Vul-
nerability of Enclave Shielding Runtimes. In 2019 ACM SIGSAC Conference
on Computer and Communications Security (CCS ’19), November 11–15, 2019,

Permission to make digital or hard copies of all or part of this work for personal or
classroom use is granted without fee provided that copies are not made or distributed
for profit or commercial advantage and that copies bear this notice and the full citation
on the first page. Copyrights for components of this work owned by others than the
author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or
republish, to post on servers or to redistribute to lists, requires prior specific permission
and/or a fee. Request permissions from permissions@acm.org.
CCS ’19, November 11–15, 2019, London, UK
© 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.
ACM ISBN 978-1-4503-6747-9/19/11. . . $15.00
https://doi.org/10.1145/3319535.3363206

London, UK. ACM, New York, NY, USA, 18 pages. https://doi.org/10.1145/
3319535.3363206

1 INTRODUCTION
Minimization of the Trusted Computing Base (TCB) has always
been one of the key principles underlying the field of computer se-
curity. With an ongoing stream of vulnerabilities in mainstream op-
erating system and privileged hypervisor software layers, Trusted
Execution Environments (TEEs) [28] have been developed as a
promising new security paradigm to establish strong hardware-
backed security guarantees. TEEs such as Intel SGX [8], ARM Trust-
Zone [34], RISC-V Keystone [21], or Sancus [32] realize isolation
and attestation of secure application compartments, called enclaves.
Essentially, TEEs enforce a dual-world view, where even compro-
mised or malicious system software in the normal world cannot
gain access to the memory space of enclaves running in an iso-
lated secure world on the same processor. This property allows
for drastic TCB reduction: only the code running in the secure
world needs to be trusted for enclaved computation results. Nev-
ertheless, TEEs merely offer a relatively coarse-grained memory
isolation primitive at the hardware level, leaving it up to the enclave
developer to maintain useful security properties at the software
level. This can become particularly complex when dealing with
interactions between the untrusted host OS and the secure enclave,
e.g., sending or receiving data to or from the enclave. For this rea-
son, recent research and industry efforts have developed several
TEE runtime libraries that transparently shield enclave applications
by maintaining a secure interface between the normal and secure
worlds. Prominent examples of such runtimes include Intel’s SGX-
SDK [19], Microsoft’s Open Enclave SDK [29], Graphene-SGX [43],
SGX-LKL [35], Google’s Asylo [13], and Fortanix’s Rust-EDP [11].
There are some differences in the way each trusted runtime
handles input/output data to and from the enclave. At the system
level, all TEEs offer some form of ecall/ocall mechanism to switch
from the normal to the secure word (and vice versa). Building on
this hardware-level isolation primitive, TEE runtimes aim to ease
enclave development by offering a higher level of abstraction to
the enclave programmer. Particularly, commonly used production-
quality SDKs [19, 29] offer a secure function call abstraction, where
untrusted code is allowed to only call explicitly annotated ecall
entry points within the enclave. Furthermore, at this level of ab-
straction the enclave application code can call back to the untrusted
world by means of specially crafted ocall functions. It is the TEE

runtime’s responsibility to safeguard the secure function call ab-
straction by sanitizing low-level ABI state and marshalling input
and output buffers when switching to and from enclave mode. How-
ever, the SDK-based approach still leaves it up to the developer to
manually partition secure application logic and design the enclave
interface. As an alternative to such specifically written enclave code,
one line of research [1, 2, 42, 43] has developed dedicated enclave
library OSs that seamlessly enforce the ecall/ocall abstraction at
the system call level. Ultimately, this approach holds the promise
to securely running unmodified executables inside an enclave and
fully transparently applying TEE security guarantees.

Over the last years, security analysis of enclaved execution has
received considerable attention from a microarchitectural side-
channel [24, 26, 30, 45, 46] and more recently also transient execu-
tion perspective [5, 20, 44]. However, in the era where our commu-
nity is focusing on patching enclave software against very advanced
Spectre-type attacks, comparably little effort has gone into explor-
ing how resilient commonly used trusted runtimes are against plain
architectural memory-safety style attacks. Previous research [3, 22]
has mainly focused on developing techniques to efficiently exploit
traditional memory safety vulnerabilities in an enclave setting, but
has not addressed the question how prevalent such vulnerabilities
are across TEE runtimes. More importantly, it remains largely un-
explored whether there are new types of vulnerabilities or attack
surfaces that are specific to the unique enclave protection model
(e.g., ABI-level misbehavior, or API-level pointer poisoning in the
shared address space). Clearly, the enclave interface represents an
important attack surface that so far has not received the necessary
attention and thus is the focus of this paper.

Our contribution. In this paper, we study the question of how
a TEE trusted runtime can securely “bootstrap” from an initial
attacker-controlled machine state to a point where execution can be
safely handed over to the actual application written by the enclave
developer. We start from the observation that TEE runtimes hold
the critical responsibility of shielding an enclave application at
all times to preserve its intended program semantics in a hostile
environment. As part of our analysis, we conclude that the complex
shielding requirement for an enclave runtime can be broken down
into at least two distinct tiers of responsibilities.

In a first ABI-level tier, we consider that upon enclave entry,
the adversary usually controls a significant portion of the low-
level machine state (e.g., CPU registers). This requires sanitization,
typically implemented through a carefully crafted enclave entry
assembly routine to establish a trustworthy ABI state as expected
by the compiled application code. Examples of trusted runtime
responsibilities at this level include switching to a private call stack,
clearing status register flags that may adversely affect program
execution, or scrubbing residual machine state before enclave exit.
Secondly, we consider that the enclaved binary itself makes cer-
tain API-level assumptions. Here we pay particular attention to
pointers and size arguments, because in many TEE designs [8, 21,
32], at least part of the enclave’s address space is shared with un-
trusted adversary-controlled code. Hence, the enclaved binary may
assume that untrusted pointer arguments are properly sanitized to
point outside of trusted memory, or that ocall return values have
been scrutinized. Our main contributions are:

• We categorize enclave interface shielding responsibilities into
10 distinct classes, across the ABI and API tiers (cf. Table 1).
• We analyze 8 widely used enclave runtimes, revealing a recur-
ring vulnerability landscape, ranging from subtle side-channel
leakage to more grave types of memory safety infringements.
• We practically demonstrate according attacks in various ap-
plication scenarios by extracting full cryptographic keys, and
triggering controlled enclave memory corruptions.

• We show that state-of-the-art automated enclave interface san-
itization approaches such as edger8r, or even the use of safe
languages like Rust, fail to fully prevent our attacks, highlight-
ing the need for more principled mitigation strategies.

Responsible disclosure. All of the security vulnerabilities de-
scribed in this work have been responsibly disclosed through the
proper channels for each affected TEE runtime. In each case, the
issues have been verified and acknowledged by the developers. In
the case of Intel, this can be tracked via CVE-2018-3626 and CVE-
2019-14565, and for Microsoft via CVE-2019-0876, CVE-2019-1369,
and CVE-2019-1370. The weakness found in Fortanix-EDP led to a
security patch in the Rust compiler. For other open-source projects,
our reports have been acknowledged in the respective commits or
issues on GitHub. We worked with the maintainers of said projects
to ensure mitigation of the problems reported in this paper.

To ensure the reproducibility of our work, and to provide the
community with a relevant sample of vulnerable enclave programs
for evaluating future attacks and defenses, we published all of our
attack code at https://github.com/jovanbulck/0xbadc0de.

2 BACKGROUND AND RELATED WORK
This section reviews enclave operation and TEE design, introduces
the trusted runtime libraries we analyzed in this work, and finally
summarizes related work on TEE memory corruption attacks.

2.1 Enclave entry and exit

TEE design. The mechanisms to interface with enclaves vary
depending on the underlying TEE being used. Figure 1 shows how,
from an architectural point of view, we distinguish two types of TEE
designs: those that rely on a single-address-space model (e.g., Intel
SGX [8] and Sancus [32]) vs. the ones that follow a two-world view
(e.g., ARM TrustZone [34] and Keystone [21]). In the former case,
enclaves are embedded in the address space of an unprivileged host
application. The processor orchestrates enclave entry/exit events,
and enforces that enclave memory can never be accessed from
outside the enclave. Since the trusted code inside the enclave is
allowed to freely access unprotected memory locations outside the
enclave, bulk input/output data transfers are supported by simply
passing pointers in the shared address space.

In the case of a two-world design, on the other hand, the CPU
is logically divided into a “normal world” and a “secure world”. A
privileged security monitor software layer acts as a bridge between
both worlds. The processor enforces that normal world code cannot
access secure world memory and resources, and may only call a
predefined entry point in the security monitor. Since the security
monitor has unrestricted access to memory of both worlds, an
explicit “world-shared memory” region can typically be setup to
pass data from the untrusted OS into the enclave (and vica versa).

Figure 1: Enclave interactions in a single-address-space TEE
design (left) vs. two-world design (right). The software com-
ponents we study are bold, and the TCB is green (solid lines).

Enclave entry/exit. Given that the runtimes we studied focus
mainly on Intel SGX (cf. Section 3.2), we now describe ecall/ocall
and exception handling following SGX terminology [8]. Note that
other TEEs feature similar mechanisms, the key difference for a two-
world design being that some of the enclave entry/exit functionality
may be implemented in the privileged security monitor software
layer instead of in the processor.

In order to enter the enclave, the untrusted runtime executes the
eenter instruction, which switches the processor into enclave mode
and transfers execution to a predefined entry point in the enclave’s
Trusted Runtime System (TRTS). Any meta data information, in-
cluding the requested ecall interface function to be invoked, can
be passed as untrusted parameters in CPU registers. TRTS first san-
itizes CPU state and untrusted parameters before passing control
to the ecall function to be executed. Subsequently, TRTS issues an
eexit instruction to perform a synchronous enclave exit back to
the untrusted runtime, again passing any parameters through CPU
registers. The process for ocalls takes place in reverse order. When
the enclave application calls into TRTS to perform an ocall, the
trusted CPU context is first stored before switching to the untrusted
world, and restored on subsequent enclave re-entry.

When encountering interrupts or exceptions during enclaved
execution, the processor executes an Asynchronous Enclave eXit
(AEX) procedure. AEX first saves CPU state to a secure Save State
Area (SSA) memory location inside the enclave, before scrubbing
registers and handing control to the untrusted OS. The enclave can
subsequently be resumed through the eresume instruction. Alter-
natively, the untrusted runtime may optionally first call a special
ecall which allows the enclave’s TRTS to internally handle the
exception by inspecting and/or modifying the saved SSA state.

2.2 TEE shielding runtimes

Intel SGX-SDK. With the release of the open-source SGX-SDK,
Intel [19] supports a secure function call abstraction to enable pro-
duction enclave development in C/C++. Apart from pre-built trusted
runtime libraries, a key component of the SDK is the edger8r tool,
which parses a developer-provided Enclave Description Language
(EDL) file in order to automatically generate trusted and untrusted
proxy functions to be executed when crossing enclave boundaries.

only supports Intel SGX applications, but in the future TrustZone-
based TEEs will also be supported through OP-TEE bindings [29].
The OE runtime includes a custom fork of Intel’s edger8r tool.

Google Asylo. Google aims to provide a higher-level, platform-
agnostic C++ API to develop production enclaves in a Remote Pro-
cedure Call (RPC)-like fashion [13]. While the Asylo specification
aims to generalize over multiple TEEs, presently only a single SGX
back-end is supported, which internally uses Intel’s SGX-SDK. From
a practical perspective, the Asylo runtime can thus be regarded as
an additional abstraction layer on top of the Intel SGX-SDK.

Fortanix Rust-EDP. As an alternative to Intel’s and Microsoft’s
SDKs written in C/C++, Fortanix released a production-quality SGX
toolchain to develop enclaves in the safe Rust language [11]. The
combination of SGX’s isolation guarantees with Rust’s type sys-
tem aims to rule out memory safety attacks against the trusted
enclave code. Similar to libOS-based approaches, Rust-EDP hides
the enclave interface completely from the programmer and trans-
parently redirects all outside world interactions in the standard
library through a compact and scrutinized ocall interface.

Graphene-SGX. This open-source library OS approach allows
to run unmodified Linux binaries inside SGX enclaves [43]. The
trusted Graphene-SGX runtime transparently takes care of all en-
clave boundary interactions. For this, the libOS offers a limited
ecall interface to launch the application, and translates all system
calls made by the shielded application binary into untrusted ocalls.
While Graphene was originally developed as a research project, it
is currently meeting increasing industry adaption and thrives to
become a standard solution in the Intel SGX landscape [36].

SGX-LKL. This open-source research project offers a trusted
in-enclave library OS that allows to run unmodified Linux binaries
inside SGX enclaves [35]. Similarly to Graphene-SGX, SGX-LKL
intercepts all system calls in the shielded application binary, but the
libOS layer is internally based on the Linux Kernel Library (LKL).

Keystone. Keystone [21] is an open-source research framework
for developing customized TEEs in RISC-V processors. Keystone
adopts a “secure world” view similar to ARM TrustZone [34] where
a privileged security monitor software layer separates enclaves in
their own address spaces, potentially including explicit shared mem-
ory regions. Keystone enclaves feature a trusted runtime which in-
tercepts system calls and transparently tunnels all untrusted world
interactions through the underlying security monitor.

Sancus. The Sancus research TEE [32] offers lightweight en-
clave isolation and attestation on an embedded 16-bit TI MSP430
processor featuring a plain single-address-space without virtual
memory. A dedicated C compiler automates enclave creation and in-
cludes a small trusted runtime library that is transparently invoked
on enclave entry/exit. Trusted software may additionally provide
code confidentiality [14] or authentic execution [31] guarantees.

2.3 Related work

Microsoft Open Enclave SDK. Microsoft developed the open-
source Open Enclave (OE) SDK with the purpose of facilitating
TEE-agnostic production enclave development [29]. Currently, OE

OS system call interface. During the last decade, significant
research efforts have been made to discover and mitigate vulnera-
bilities in OS kernels, such as missing pointer checks, uninitialized

OSHardwareSecurity monitorHardwareOSAppSharedmemoryURTSHost application (shared memory)TRTSEnclaved	binarySSAEnclaved	binaryTRTSSecure worldNormal worlddata leakage, or buffer and integer overflows [6]. By exploiting
a single vulnerability in a kernel, unprivileged adversaries may
read or write arbitrary memory and gain root access. While these
vulnerabilities continue to be relevant in modern kernels, they are
generally well understood by the OS security community. However,
they have received less attention in the context of TEEs.

Checkoway et al. [4] first demonstrated that an untrusted OS can
perform so called Iago attacks to compromise legacy applications
by supplying maliciously crafted pointers or lengths as the return
value of a traditionally trusted system call like malloc(). These
attacks are closely related to a small subset of the vulnerabilities
described in this work, specifically attack vector #9, which exploits
that pointers or buffer sizes returned by untrusted ocalls may
not be properly sanitized (cf. Section 5.5). Our work generalizes
Iago attacks from the OS system call interface to ocalls in general,
and more broadly shows that Iago attacks are but one instance
of adversarial OS interactions. We show for instance that legacy
applications may also make implicit assumptions on the validity of
argv and envp pointers, which are not the result of system calls.

Memory corruption attacks on ARM TrustZone. ARM Trust-
Zone [34] was one of the first widely deployed TEEs, particularly
in mobile devices, and hence received considerable attention from
security researchers. The code running in the secure world largely
depends on the device manufacturer, with widely used runtimes
including Trustonic Kinibi, Qualcomm’s QSEE, Google’s Trusty,
and the open-source project OP-TEE. Over the past years, several
vulnerabilities [33, 34] have been discovered in TrustZone runtimes
caused by e.g., missing or incorrect pointer range or length checks,
or incorrect handling of integer arithmetic. Often, these vulnera-
bilities rely on the existence of a shared memory region for data
exchange between the normal and secure worlds: if an adversary
passes a pointer into trusted memory where a pointer to shared
memory is expected, memory corruption or disclosure may occur
when the pointer is not properly validated by the trusted runtime.
Machiry et al. [27] presented a related class of Boomerang attacks,
which leverage the fact that TrustZone’s secure world OS has full
access to untrusted memory, including the regions used by the
untrusted OS. Boomerang exploits that trusted pointer sanitization
logic may only validate that pointers lie outside of secure memory,
allowing unprivileged code executing in the normal world to read
or write memory locations belonging to other applications or the
untrusted OS. In a sense, Boomerang vulnerabilities are orthogonal
to a subset of the vulnerabilities described in this paper: both target
incorrect pointer checks within trusted code, but while Boomerang
attacks relate to checks of pointers into untrusted memory, we focus
on pointers into trusted memory.

Memory corruption attacks on Intel SGX. Lee et al. [22] were
the first to execute a completely blind memory corruption attack
against SGX by augmenting code reuse attack techniques [41] with
several side-channel oracles. To successfully mount this attack, ad-
versaries require kernel privileges and a static enclave memory lay-
out. Recently, these techniques were improved by Biondo et al. [3]
to allow even non-privileged adversaries to hijack vulnerable en-
claves in the presence of fine-grained address space randomiza-
tion [40]. Their approach is furthermore made application-agnostic
by leveraging gadgets found in the trusted runtime library of the

official Intel SGX-SDK. In a perpendicular line of research, Schwarz
et al. [38] criticized SGX’s design choice of providing enclaves with
unlimited access to untrusted memory outside the enclave. They
demonstrated that malware code executing inside an SGX enclave
can mount stealthy code reuse attacks to hijack control flow in the
untrusted host application.

Importantly, all previous SGX memory safety research focused
on contributing novel exploitation techniques while assuming the
prior presence of a vulnerability in the enclave code itself. Hence,
those results are complementary to the vulnerabilities described in
this work. We have indeed demonstrated control flow hijacking for
some of the pointer sanitization issues below, and these may further
benefit from exploitation techniques developed in prior work.

3 METHODOLOGY AND ADVERSARY MODEL
3.1 Attacker model
We consider systems with hardware support for a TEE and where
a trusted runtime supports the secure, shielded execution of an en-
claved binary produced by the application developer. With enclaved
binary, we specifically mean that the binary is the output of a stan-
dard compiler, which is not aware of the TEE. It is the responsibility
of the shielding runtime to preserve intended program semantics
in a hostile environment. We focus exclusively on vulnerabilities
in the TEE runtime and assume that there are no application-level
memory safety vulnerabilities in the enclaved binary.

We assume the standard TEE attacker model [28], where ad-
versaries have full control over all software executing outside the
hardware-protected memory region. This is a powerful attacker
model, allowing the adversary to, for instance, modify page table
entries [47, 54], or precisely execute the victim enclave one instruc-
tion at a time [45]; yet, this is the attacker that TEEs are designed
to defend against. It is important to note that some of the attacks
we discuss can also be launched by significantly less privileged
attackers, i.e., with just user-level privileges to invoke the enclave.

3.2 Research methodology
Our objective is to pinpoint enclave shielding responsibilities, and to
find vulnerabilities where real-world TEE runtimes fail to safeguard
implicit interface assumptions made by the enclaved binary.

TEE runtime code review. We base our research on manual
code review, and hence limited our study to open-source TEE run-
times. After reviewing the literature and code repositories, we
selected 8 popular runtimes to be audited. Our resulting selection
allows to compare tendencies in (i) production vs. research code
bases; (ii) SDK vs. libOS-based shielding abstractions; (iii) unsafe
C/C++ vs. safe Rust programming languages; and (iv) underly-
ing TEE design dependencies. Note that we opted not to include
baidu-rust-sgx, as it is merely a layer on top of Intel SGX-SDK (and
hence inherits all vulnerabilities of the latter). After reviewing prior
research [33] and relevant code, we found that sanitization in the
TrustZone runtime OP-TEE has already been thoroughly vetted
and we hence decided not to systematically audit this runtime. For
each of the selected TEE runtime implementations, we then re-
viewed the sanitizations and defensive checks implemented by the
trusted runtime between entering the TEE and transferring control

Table 1: Enclave runtime vulnerability assessment (our contribution, highlighted) and comparison to related work on OSs and
TEEs. Symbols indicate whether a vulnerability was successfully exploited (⋆); acknowledged but without proof-of-concept
) indicate that improper sanitization only leads to side-channel leakage.
(

). Half-filled symbols (⋆,

); or not found to apply (

(cid:32)

Vulnerability

(cid:35)

Runtime

(cid:71)(cid:35)

S D K
O p

X -

G

S

c l a

n

E

n

e

e

v

p

a

G r

e

h

n

e

S

G

L

X -

K

L

R

u

s t -

E D P
A s

y l o

o

s t

y

e

K

n

e

S

a

s

u

c

n

Tier1
(ABI)

#1 Entry status flags sanitization
#2 Entry stack pointer restore
#3 Exit register leakage

Tier2
(API)

#4 Missing pointer range check
#5 Null-terminated string handling
#6 Integer overflow in range check
#7 Incorrect pointer range check
#8 Double fetch untrusted pointer
#9 Ocall return value not checked
#10 Uninitialized padding leakage

⋆

(cid:35)
(cid:35)

⋆
(cid:35)

(cid:35)
(cid:35)
(cid:35)
[23]
(cid:35)

⋆

(cid:35)
(cid:35)
⋆
⋆

(cid:35)
(cid:35)
⋆
(cid:35)
⋆

⋆
(cid:71)(cid:35)

(cid:35)
⋆

(cid:35)
(cid:32)
(cid:32)
⋆
(cid:32)

(cid:35)

(cid:32)
⋆
(cid:32)

⋆

(cid:35)
(cid:35)
(cid:35)
⋆
(cid:35)

(cid:32)

(cid:71)(cid:35)
(cid:35)
(cid:35)

(cid:35)
(cid:35)
(cid:32)
(cid:35)
(cid:35)
(cid:35)
(cid:35)

(cid:32)
(cid:35)
(cid:35)

(cid:32)
(cid:35)
(cid:35)
(cid:32)
(cid:35)
(cid:32)
(cid:32)

(cid:35)
(cid:35)
(cid:35)

(cid:35)
(cid:35)
(cid:32)
(cid:35)
⋆
(cid:35)
⋆

⋆
(cid:35)

(cid:35)
⋆

(cid:35)
(cid:32)
(cid:32)
(cid:35)
⋆
(cid:35)

x

u

L i n

[9]

(cid:35)
(cid:35)
[6]
[6]
[6]

Prior TEE attack research

SGX Dark-ROP exploitation [3, 22]

TrustZone exploits [33, 34]

TrustZone exploits [33, 34]

[37, 53]
(cid:35)
–
[7]

SGX AsyncShock framework [50]
Iago attacks (Linux system call interface) [4]
SGX-SDK edger8r struct leakage [23]

to the enclaved binary, and the symmetrical path when exiting the
TEE. We found new vulnerabilities in all studied runtimes. Table 1
summarizes our findings, structured according to the respective
vulnerability classes, and relating to similar vulnerabilities in the
Linux kernel and prior TEE research. Our systematization revealed
10 distinct attack vectors across 2 subsequent tiers of TEE shielding
responsibilities, explored in Sections 4 and 5, respectively.

In our code review, we focus our attention on the assumptions
that an enclaved binary makes about two key interfaces, and we
consider both integrity and confidentiality concerns. A first level of
interface sanitization we inspect is the ABI, which unambiguously
specifies function calling conventions regarding the low-level ma-
chine state expected by the compiler [10]. We manually locate the
trusted runtime entry point, and review how the compact assembly
routine establishes a trustworthy ABI state on entry, and similarly
scrubs residual CPU state on exit. The second key interface, that
we refer to as the API, is the functional interface of the enclaved
binary. We review how the TEE runtime validates different kinds
of arguments passed in through an ecall or as the return value
of an ocall. We focus in particular on the handling of pointers
and strings, where it is the TEE runtime’s responsibility to ensure
that variable-sized buffers lie entirely outside the enclave before
copying them inside and transferring execution to the enclaved
binary. For confidentiality, we check again that all memory copied
outside the TEE only contains explicit return values, and that no
avoidable side-channel leakage is introduced.

TEE design considerations. The communication between en-
clave and untrusted code for all TEE runtimes considered in this
paper relies on some form of “world-shared memory”, i.e., a mem-
ory region that is accessible to both trusted and untrusted code.
Depending on the specific TEE design (cf. Fig. 1), this can be re-
alized by either embedding the enclave in the address space of
a surrounding host process, as in Intel SGX [8] or Sancus [32],
or by explicitly mapping a dedicated virtual memory region into
both worlds as in ARM TrustZone [34] and Keystone [21]. Prior
research has mainly explored interface sanitization vulnerabilities
in ARM TrustZone TEEs (cf. Section 2.3). Given the prevalence of
SGX in contemporary Intel processors, our study focuses largely

on SGX-style single-address-space TEE designs as used in 7 out of 8
considered runtimes. However, the example of Keystone, and prior
research on ARM TrustZone [33, 34], shows that the attack surface
studied here is not necessarily limited to TEEs using the single-
address-space approach taken by SGX. As part of our analysis, we
found that certain TEE-specific design considerations may some-
times significantly impact exploitability. When applicable, such
TEE design considerations are discussed throughout the paper.

4 ESTABLISHING A TRUSTED ABI
Similarly to traditional user/kernel isolation, TEE-enabled proces-
sors typically only take care of switching to a fixed entry point
and thereafter leave it up to trusted runtime software to securely
bootstrap the enclaved execution. In practice, this implies that ad-
versaries may still control a large fraction of the low-level machine
state (e.g., CPU registers) on enclave entry. Hence, a trusted as-
sembly entry routine is responsible to establish an ABI-compliant
machine state when transferring control to the shielded application,
and to save and scrub low-level machine state on enclave exit.

4.1 Sanitizing machine state on entry
After reviewing well-documented ABI-level calling conventions [10]
expected by popular C compilers, we concluded that most CPU reg-
isters can be left unmodified, apart from the stack pointer explored
in the next section. However, a more subtle concern relates to the
expected state of certain status register flags on function entry.

Attack vector #1 (status flags): Entry code should sanitize register flags
that may adversely impact program execution. ▷ Prevalent in production
and research runtimes, but exclusively Intel SGX (x86 CISC).

TEE design. The underlying processor architecture used in the
specific TEE design may greatly impact the resulting ABI-level at-
tack surface. That is, in comparison to Intel’s notoriously complex
x86 CISC architecture [8], simpler RISC-based TEEs such as San-
cus [32], Keystone [21], or ARM TrustZone [34] tend to impose less
obligations for trusted software to sanitize low-level machine state.
For instance, we found that the Sancus runtime should only take
care to clear the interrupt flag. Likewise, TrustZone even transpar-
ently takes care to save/restore secure world stack pointer registers.

Our analysis further reveals the trade-offs for implementing register
and status flag clearing in either hardware or software. For instance,
we show that the Intel SGX design leaves this responsibility largely
to software, exposing a larger attack surface.

We methodically examined all the software-visible flags in the
x86 flags register [17] and discovered two potentially dangerous
flags that may adversely impact enclaved execution if not properly
cleared. First, the Alignment Check (AC) flag may be set before
entering the enclave in order to be deterministically notified of
every unaligned memory access performed by the trusted enclave
software. This novel side-channel attack vector is closely related to
well known page fault [54] or segmentation fault [15] controlled-
channels, but this time abuses x86 #AC alignment-check exceptions.
Also, note that #PF side-channels ultimately reflect fundamental
hardware-level TEE design decisions that cannot be avoided in soft-
ware, whereas we argue that #AC leakage originates from the trusted
runtime’s failure to clear the associated status register control flag.
A second and more dangerous ABI-level attack vector arises from
the Direction Flag (DF), which can be set to change the loop behav-
ior of x86 string instructions (e.g., rep movs) from auto-increment to
auto-decrement. Commonly used x86 ABIs [10] allow for compiler
optimizations by mandating that DF shall always be cleared on func-
tion call/return. However, in case this subtle ABI requirement is not
explicitly enforced in the assembly entry routine, SGX adversaries
may change DF to an unexpected “decrement” direction before the
ecall and thereby hijack the intended direction of all subsequent
x86 string instructions executed by the enclave. This opens a severe
vulnerability that can be successfully exploited to trigger enclave
memory corruption and erroneous computation results.

Intel SGX-SDK. We experimentally confirmed that the trusted
runtime in Intel’s official SGX-SDK [19] does not clear AC or DF on
enclave entry. The latter can be tracked via CVE-2019-14565 (Intel
SA-00293), leading to enclave TCB recovery.

While unaligned data accesses (e.g., fetching a 16-bit word at an
odd byte address) are explicitly supported in the x86 architecture,
the processor may optionally be forced to generate an exception
for such accesses when software sets the AC bit in the flags reg-
ister. We developed a minimal sample enclave to showcase how
#AC exceptions may in certain scenarios reveal secret-dependent
data accesses at an enhanced byte-level granularity as compared
to state-of-the-art SGX side-channel attacks that are restricted to a
coarser-grained 64 B cacheline [39] or 4 KiB page-level [47, 54] gran-
ularity. Figure 2 illustrates the key idea behind the attack, where
a 16-bit word is loaded by specifying a byte-granular index in a
small lookup table that has been explicitly aligned to a cacheline
boundary (e.g., as might also be performed in a streamed data or
string processing enclave application). In the example, secret index
0 returns the data AB, whereas secret index 1 returns BC. Our exploit
deterministically reconstructs the intra-cacheline secret-dependent
data access by observing whether or not the enclaved execution
generates an #AC alignment-check exception. One of the challenges
we encountered is to make the enclave progress after returning
from the untrusted signal handler. Since the processor automati-
cally restores the previous value of the flags register (including
the set AC bit) from enclave-private SSA memory when resuming
the enclave [8], the unaligned data access will never be allowed to

Figure 2: Misaligned, intra-cacheline secret data access.

complete. To overcome this challenge, we make use of the adver-
sary’s root privileges to load a simple kernel module that clears the
processor’s Alignment Mask (CR0.AM) to temporarily disable align-
ment checking. Combined with a single-stepping attack primitive
like SGX-Step [45], this approach allows to determine noise-free
alignment side-channel information for every single instruction in
the victim enclave.

It should be noted that the oversight of not clearing the AC flag
in the trusted runtime merely leaks address-related side-channel
information, which falls explicitly outside of SGX’s threat model [8].
However, this is distinctly not the case for the DF flag, which di-
rectly intervenes with the semantics of the enclaved execution. We
confirmed that the popular gcc v5.4 compiler replaces for instance
common strlen() and memset() invocations with inlined x86 string
instructions at optimization level -Os. We developed a start-to-end
attack scenario to show how forcibly inverting the direction of such
string operations when entering the enclave through an ecall can
lead to controlled heap corruption and memory disclosure. Our
PoC exploit targets edger8r bridge code that is automatically gen-
erated to copy input and output buffers to and from the enclave
(cf. Section 5.1 and Fig. 3). Particularly, we abuse that edger8r code
allocates the output buffers on the enclave heap and thereafter uses
memset() to securely initialize the newly allocated buffer to all-zero.
However, setting DF before the ecall causes the memset() direction
to be inverted and any preceding heap memory to be corrupted (i.e.,
zeroed). Due to the way the SGX-SDK enclave heap is organized,
this will ultimately lead to a crash on the next free() invocation in
the edger8r code. Every heap frame is preceded by a size field and
a pointer to a meta-data bookkeeping structure. Such pointers are
stored in xor-ed form with a randomly generated secret constant
to harden the code against traditional heap corruption attacks. We
confirmed that after erroneously zeroing the preceding heap frames,
the resulting pointer will most likely end up as a non-canonical
64-bit address and halt the enclave by means of a general protec-
tion fault. However, before finally calling free() and detecting the
heap corruption, the trusted edger8r-generated code still copies the
allocated output buffer outside the enclave, potentially leading to
secret disclosure (as this buffer has never been properly zeroed).
We note that the heap corruption in itself may also be leveraged in
application-specific scenarios, e.g., zeroing out a cryptographic key
residing in the preceding heap frame.

Microsoft Open Enclave SDK. We experimentally confirmed
that OE suffers from the same DF vulnerability described above
(tracked via CVE-2019-1370). However, we found that after enter-
ing the enclave with the DF flag set, the trusted runtime already
crashes early-on in the entry path. The reason for this is that on
our machines (gcc v5.4 using the default Makefile), one of the
compiled entry functions uses a rep string instruction to initialize a
local variable on the call stack. Hence, setting DF leads to memory

unaligned data access #AC exception64B cacheline   ABDindex (secret)C; % RDI = attacker arg

1

2

cmp $RETURN_FROM_OCALL , % rdi
je .Lreturn_from_ocall
...

3
4 .Lreturn_from_ocall
5 ⭑ mov % gs : SGX_LAST_STACK , % rsp
6

...
ret

7

Listing 1: Low-level ocall return path in Graphene-SGX.

corruption by overwriting a piece of the trusted call stack with
zeroes. We have not attempted to further exploit this behavior.

Other SGX runtimes. When reviewing the assembly entry rou-
tines of the other SGX-based shielding systems (cf. Table 1), we
found that none of them sanitizes AC, whereas interestingly both
Rust-EDP and Graphene-SGX clear DF on enclave entry. Note that
Google’s Asylo framework is built on top of the Intel SGX-SDK and
hence inherits all of the vulnerabilities described above.

4.2 Maintaining the call stack abstraction
In order to safeguard enclave confidentiality and integrity, it is
essential that enclaves features their own private call stack. When
exiting the TEE by means of an ocall, the trusted stack pointer
should be stored and control flow should continue at a location
outside the enclave. After having performed an ocall, upon receiv-
ing the next ecall, the private call stack should be restored so the
runtime can “return” into the shielded application.

Attack vector #2 (call stack): Entry code should safeguard the call stack
abstraction for ecalls and ocalls. ▷ Not applicable to TrustZone, well-
understood in production SGX-SDKs, but not always in research code.

TEE design. We observed that TEE-specific design decisions
may largely impact the attack surface arising from call stack switch-
ing. That is, in ARM TrustZone [34] the stack pointer CPU register is
duplicated and fully transparently stored/restored on secure world
context switches. More versatile TEE designs like Intel SGX [8]
or Sancus [32], on the other hand, support multiple mutually dis-
trusting enclaves and leave it up to trusted runtime software to
store and restore the stack pointer across enclave boundaries. An-
other illustration of the trade-offs between hardware and software
responsibilities arises in SGX’s eexit instruction, which was de-
signed to explicitly fault when supplying in-enclave continuation
addresses [8]. Alternative TEE designs like Sancus [32], on the other
hand, expect such continuation pointer checks to be performed by
the trusted software, leaving a larger attack surface.

Graphene-SGX. After scrutinizing Graphene’s low-level boot-
strapping code, we discovered that enclave_entry.S does not prop-
erly safeguard the ocall return abstraction. Listing 1 shows how
the code unconditionally jumps to the stack pointer restore logic
after merely receiving an unchecked magic value in the %rdi register.
We experimentally confirmed that this can be abused to illegally
“return” into an enclave thread that is not waiting for a previous
ocall return. An adversary can exploit this weakness to erroneously
initialize the trusted in-enclave stack pointer of a newly started
thread with the value of the last ocall. The memory content at
these locations determine the values popped into registers, and
ultimately ret control flow.

SGX-LKL. We found a highly similar vulnerability in the way
SGX-LKL’s low-level entry code distinguishes different ecall types.
Specifically, we noticed that the unchecked parameter in %rdi can be
poisoned to trick the entry routine into erroneously calling a signal
handler for a thread that was never interrupted. This is especially
problematic as the signal handler code will then illegally restore
the stack pointer register from an uninitialized memory location.

Sancus. We reviewed the assembly code inserted at the entry
point of a Sancus enclave, and noticed that the Sancus TEE suffers
from similar call stack switching vulnerabilities. Particularly, we
experimentally confirmed that it is possible to supply illegal CPU
register arguments and trick the enclave into “returning” into a
thread that was not waiting for a previous ocall return. In such a
case, the enclave stack will be falsely restored to the value of the
last valid ocall, leading to memory-safety violations from incorrect
control flow and register values. Sancus’s enclave entry assembly
routine further expects a CPU register parameter to specify the
address where execution is continued after leaving the enclave. The
software does not properly validate this parameter. Unlike SGX’s
eexit hardware primitive, which refuses to jump to illegal continu-
ation addresses, Sancus enclaves are exited by means of an ordinary
jmp instruction. We experimentally confirmed the possibility of
code reuse attacks [41] by forcing the vulnerable entry routine to
jump to an arbitrary in-enclave continuation address.

4.3 Storing and scrubbing machine state on exit
Prior to exiting the TEE, the trusted runtime’s assembly routine
should save and clear all CPU registers that are not part of the
calling convention, and restore them on subsequent enclave re-
entry. This is highly similar to how a traditional operating system
needs to context switch between processes, and hence we found
this to be a generally well-understood requirement.

Attack vector #3 (register state): Exit code should save and scrub CPU
registers. ▷ Generally well-understood across runtimes and architectures.

TEE design. Similar to parameter passing across traditional
user/kernel boundaries, widespread TEE designs commonly pre-
serve CPU register contents when context switching between the
normal and secure worlds. Prior research [3, 22] on exploiting mem-
ory safety vulnerabilities in SGX enclaves has for instance exploited
that the eexit instruction does not clear register values, leaving this
as an explicit software responsibility. Further, while scrubbing CPU
registers on enclave interrupt is a hardware responsibility in the In-
tel SGX design [8], we found that the AEX operation in current SGX
processors does not clear the x86 DF flag (cf. Section 4.1). We ex-
perimentally confirmed that this can be exploited as a side-channel
to learn the direction of private in-enclave string operations.

SGX-LKL. When reviewing the respective assembly routines,
we noticed that SGX-LKL is the only SGX runtime which does not
properly scrub registers before invoking eexit. The reason for this
oversight is that LKL attempts to leverage the setjmp/longjmp stan-
dard C library functions to easily store and restore the execution
state on enclave entry/exit without needing dedicated assembly
code. While indeed functionally correct, i.e., the integrity of CPU
registers is preserved across enclave calls, the approach cannot
guarantee confidentiality. This is because setjmp() still behaves

as a normal C function, which—adhering to calling conventions—
does not clear all CPU state. We therefore advise to use a dedicated
assembly routine which overwrites confidential CPU registers be-
fore invoking eexit. This issue highlights the necessity to explicate
and properly separate ABI and API-level shielding concerns in
consecutive stages of the trusted runtime (cf. Section 3). We exper-
imentally confirmed this vulnerability by loading an elementary
AES-NI application binary inside SGX-LKL, and modifying the un-
trusted runtime to dump x86 xmm registers—including the AES state
and round keys—after enclave exit.

5 SANITIZING THE ENCLAVE API
Once a trustworthy ABI state has been established, the trusted
bootstrapping assembly code can safely transfer control to ma-
chine code emitted by a compiler from a program description
written in a higher-level language. Remarkably, almost all run-
times [13, 19, 21, 29, 32, 35, 43] we studied are written in C or C++,
with the notable exception of Fortanix’s EDP platform [11], which
is written in the memory-safe Rust language. While the use of safe
languages is indeed preferable to rule out an important class of
application-level memory-safety vulnerabilities in the trusted run-
time implementation, we show that safe languages by themselves
cannot guarantee that the enclave interface is safe.

That is, it remains the responsibility of the trusted runtime im-
plementation to marshal and scrutinize untrusted input parameters
before passing them on to the shielded application written by the
enclave developer. Depending on the specific runtime, develop-
ers may communicate trusted API sanitization and marshalling
requirements explicitly (e.g., using a domain-specific language like
in Intel’s edger8r or Microsoft’s oeedger8r), or the enclave interface
may be completely hidden from the programmer (e.g., libOS-based
approaches).

In this section, we analyze shielding requirements for API san-
itization based on the different types of arguments that can be
passed across the enclave boundary. We pay particular attention
to pointers and (variable-sized) input buffers, given the prevalent
weaknesses found in real-world code.

5.1 Validating pointer arguments
Whenever untrusted side and enclave share at least part of their
address spaces, an important new attack surface arises: malicious
(untrusted) code can pass in a pointer to enclave memory where a
pointer to untrusted memory is expected. Therefore, it is the respon-
sibility of the shielding system to be careful in never dereferencing
untrusted input pointers that fall outside of the shared memory
region and point into the enclave. In case such sanity checks are
missing, the trusted enclave software may unintentionally disclose
and/or corrupt enclave memory locations. This is an instance of the
well-known “confused deputy” [16] security problem: the attacker
is architecturally prohibited from accessing secure enclave mem-
ory, but tricks a more privileged enclaved program to inadvertently
dereference a secure memory location chosen by the attacker.

Attack vector #4 (pointers): Runtimes should sanitize input pointers to
lie inside the expected shared memory region. ▷ Generally understood,
but critical oversights prevalent across research and production code.

Figure 3: Automatically generated edger8r bridge code han-
dles shielding of application input and output buffers.

TEE design. TEEs commonly support some form of shared mem-
ory which allows trusted in-enclave code to directly read or write
an untrusted memory region outside the enclave (cf. Section 3.2).
Input and output data transfers can now easily be achieved by
bulk-copying into the shared memory region and passing pointers.
Pointer sanitization is a relatively well-known requirement for
enclave applications, and even bears some similarity with tradi-
tional user-to-kernel system call validation concerns [6]. However,
the kernel system call interface remains largely invisible, fairly
stable, and is only modified by a select group of expert developers.
SDK-based enclave development frameworks on the other hand
expose ecalls and ocalls much more directly to the application
developer by means of a secure function call abstraction.

Intel SGX-SDK. In line with trusted runtime shielding require-
ments, pointer sanitization should preferably not be left to the
application developer’s end responsibility. As part of the official
SGX-SDK, Intel [19] therefore developed a convenient tool called
edger8r, which transparently generates trusted proxy bridge code
to take care of validating pointer arguments and copying input and
output buffers to/from the enclave. The tool automatically gener-
ates C code based on ecall/ocall function prototypes and explicit
programmer annotations that specify pointer directions and sizes
in a custom, domain-specific Enclave Definition Language (EDL).
Figure 3 gives an overview of the high-level operation of the
trusted edger8r bridge code. After entering the enclave, the trusted
runtime establishes a trusted ABI (cf. Section 4), locates the ecall
function to be called, and finally 1⃝ hands over control to the cor-
responding edger8r-generated bridge code. At this point, all in-
put buffer pointers are validated to fall completely outside the
enclave, before being copied 2⃝ from untrusted shared memory to
a sufficiently-sized shadow buffer allocated on the enclave heap. Fi-
nally, the edger8r bridge transfers control 3⃝ to the code written by
the application developer, which can now safely operate 4⃝ on the
cloned buffer in enclave memory. A symmetrical path is followed
when returning or performing ocalls to the untrusted code outside
the enclave.

Microsoft Open Enclave SDK. Microsoft [29] adopted the san-
itization strategy from the Intel SGX-SDK by means of their own
oeedger8r fork. Interestingly, OE uses a “deep copy” marshalling
scheme to generalize to TEEs where the enclave cannot directly
access host memory and every interaction needs to be mediated in
a security kernel with access to an explicit shared memory region
(cf. Fig. 1). With deep copy marshalling, instead of passing the en-
clave pointers to the input buffer, the contents of the buffer are first

EnclaveEENTERTrusted runtimeEdger8r bridgeApplication Input buffer(shared memory)Cloned buffer(trusted memory)EDLC12431 OE_ECALL void ecall_hello ( hello_args_t * p_host_args ) {
2

oe_result_t __result = OE_FAILURE ;
if (! p_host_args || ! oe_is_outside_enclave ( p_host_args ,

sizeof (* p_host_args )) )

goto done ;

...
done :

if ( p_host_args ) p_host_args -> _result = __result ;

3

4

5

6

7
8 ⭑
9 }

Listing 2: Proxy function generated by oeedger8r (simplified)
with illegal write to arbitrary in-enclave pointer on failure.

copied into the marshalling structure and then cloned into enclave
memory. The pointers in the argument structure are then modified
such that they point to the corresponding (cloned) memory buffer.
Nevertheless, we discovered several flaws in the way OE handles
pointer validation (tracked via CVE-2019-0876). A first subtle issue
was found by reviewing the oeedger8r-generated code skeleton
itself. Listing 2 shows a simplified snippet of the trusted bridge
code generated for an elementary hello() entry point. The code
attempts to properly verify that the untrusted p_host_args structure
lies outside the enclave, and indeed rejects the ecall when detecting
a pointer poisoning attempt. However, in the done branch at line 8,
an error code is still written into the p_host_args structure, even
if it was found earlier to illegally point inside the enclave. At the
time of our review, this could only be exploited when calling the
enclave through a legacy ecall dispatcher that had unfortunately
not been removed from OE’s trusted code base (cf. Appendix A.1).
Secondly, we found that enclaves built with OE feature a small
number of “built-in” ecall entry points for infrastructural function-
ality directly serviced in the trusted runtime without forwarding
to the shielded application. Notably, OE developers decided not to
route these entry points through oeedger8r-generated bridges, but
instead opted to manually scrutinize arguments for these special
ecalls. We audited all eight built-in entry points, and confirmed
that most of them were carefully written to prevent pointer sanitiza-
tion issues, as well as more subtle attack vectors like TOCTOU and
speculative execution side-channels. However, we found a critical
issue in the built-in _handle_get_sgx_report() ecall involved in
crucial attestation functionality (see Appendix A.2 for full code).
This function copies the untrusted report input buffer into enclave
memory, but never validates whether the argument pointer passed
by the untrusted runtime actually lies outside the enclave. This
evidently leads to corruption of trusted memory, e.g., when writing
the return value in the fall-through branch similar to the oeedger8r-
generated code discussed above.

Both of the above vulnerabilities allow to write a fixed fail-
ure code (0x03000000 and 0x01000000) to an arbitrary in-enclave
memory location. We developed a PoC based on an existing file-
encryptor OE example application, and successfully exploited the
above vulnerabilities to forcefully overwrite the first round keys of
the AES cipher. This could be extended by overwriting all but the
final round keys with known values to perform full key extraction.

Google Asylo. Because Google’s Asylo [13] framework is built
on top the existing Intel SGX-SDK, it also inherits Intel’s edger8r-
based input sanitization scheme. Particularly, the Asylo trusted
runtime features a small number of predefined ecall entry points,
specified in EDL, that implement the necessary functionality to

present a higher-level, RPC-like message passing abstraction to the
application programmer. Considering that Asylo’s runtime extends
the trusted computing base on top of Intel’s existing SGX-SDK, we
were interested to assess whether the extra abstraction level may
also bring additional attack surface. This may for instance be the
case when making use of the unsafe [user_check] EDL attribute [19]
that explicitly weakens edger8r guarantees and puts the burden of
pointer validation on the programmer (e.g., to allow for application-
specific optimizations in performance-critical scenarios). Manually
scrutinizing the EDL specifications of Asylo’s trusted runtime, we
found 14 instances of the problematic [user_check] attribute. We
reviewed these instances and alarmingly found that several of them
lacked proper pointer validation, leaving critical vulnerabilities in
the compiled enclave (e.g., a write-zero primitive). Notably, the
developers took care to validate second-level input buffers in the
untrusted argument structure, but failed to validate the argument
pointer itself (cf. Appendix A.3 for a relevant sample).

Graphene-SGX. While Graphene-SGX’s [43] untrusted world
interaction and pointer validation concerns are largely limited to
ocalls (cf. Sections 5.3 and 5.5), our inspection of the narrow ecall
interface revealed a rather subtle type of implicit pointer passing
that was overlooked. Namely, Graphene’s trusted runtime never
validates the argv and envp pointers, which are passed from the
untrusted runtime all the way into the main function of the shielded
application binary. As a result, adversaries can for instance leak
arbitrary in-enclave memory when the trusted application outputs
argv values (e.g., in case of an unknown command line argument).
We experimentally confirmed this attack by means of an elemen-
tary echo program, which unknowingly prints in-enclave secrets
after overriding argv[1] in the untrusted runtime. With respect to
mitigations, note that properly sanitizing string arguments can be
non-trivial in itself, as explored in Section 5.2.

We also found that the special enclave_ecall_thread_start()
trusted runtime function unconditionally redirects control flow,
without performing any validation on the provided untrusted func-
tion pointer. We successfully exploited this to jump to arbitrary
in-enclave locations, hence allowing code reuse attacks [41].

SGX-LKL. Our analysis of the open-source SGX-LKL ecall in-
terface revealed the exact same vulnerability. That is, the trusted __s
gx_init_enclave() libOS function passes the untrusted argv pointer
directly to the shielded application without any prior sanitization.
We experimentally confirmed that this vulnerability can be abused
for information leakage, similar to the above exploit.

Further, the in-enclave signal handler ecall entry point does not
check that the siginfo struct pointer provided by the untrusted
runtime lies outside the enclave. This vulnerability can be abused in
certain scenarios to leak in-enclave memory contents. For instance,
we describe a full exploit for the SIGILL signal in Appendix A.4.

Sancus. To demonstrate that untrusted pointer dereference vul-
nerabilities are not limited to advanced virtual memory-based archi-
tectures, we also reviewed the trusted runtime and infrastructural
enclaves of the low-end open-source Sancus [32] TEE for embedded
TI MSP430 devices. As with the above runtimes, we focused our
security audit on the enclave boundary code only.

A first critical vulnerability was found in a recent extension [31]
to the Sancus compiler infrastructure, which implements a high-
level authenticated message passing abstraction to develop dis-
tributed event-driven enclave programs. Much like Intel’s edger8r,
the Sancus compiler fully automatically generates ecall bridge code
to transparently marshal, decrypt, and authenticate input buffers,
which can be subsequently processed by the shielded application.
We found that the compiler-generated bridge code does not sani-
tize untrusted pointer arguments (cf. Appendix A.5). This may be
exploited to forcefully decrypt enclave secrets.

A second input pointer validation vulnerability was found in
an infrastructural trusted loader enclave [14] that decrypts third-
party application enclaves to preserve code confidentiality. We
noticed that the trusted loader enclave code lacks any input pointer
validation checks, allowing us to build an arbitrary write primitive
in enclave memory. We successfully exploited this vulnerability in
a PoC that launches a ROP-style [41] control flow hijacking attack
by corrupting the loader enclave call stack.

5.2 Validating string arguments
In case the enclave interface is written in a low-level language like
C, string arguments do not carry an explicit length and may not
even have been properly null-terminated. Thus, shielding runtimes
need to first determine the expected length and always include a
null terminator when copying the string inside the enclave.

Attack vector #5 (strings): Runtimes should avoid computing untrusted
string sizes, and always include a null byte at the expected end. ▷ At least
one related instance repeated across two production SDKs.

TEE design. We show below how computing on unchecked
string pointers may leak enclave secrets through side-channels,
even if the ecall is eventually rejected. While side-channels are
generally a known issue across TEE technologies [8, 21, 34, 46] and
may even be observed by non-privileged adversaries, for example
by measuring overall execution time [30] or attacker-induced cache
evictions [26, 39], we show that TEE-specific design decisions can
still largely affect the overall exploitability of subtle side-channel
vulnerabilities. Particularly, we develop a highly practical attack
that abuses several privileged adversary capabilities that have previ-
ously been proven notorious in the Intel SGX design, e.g., untrusted
page tables [47, 54], interrupts [24, 45, 46], and storing interrupted
CPU register contents in SSA memory frames [5, 44].

Intel SGX-SDK. We discovered that edger8r-generated code
may be tricked into operating on unchecked in-enclave pointers
when computing the size of a variable-length input buffer. While
such illegal ecall attempts will always be properly rejected, we
found that adversaries can exploit the unintended size computa-
tion as a deterministic oracle that reveals side-channel information
about arbitrary in-enclave memory locations. This vulnerability is
tracked via CVE-2018-3626 (Intel SA-00117), leading to enclave TCB
recovery and changes in the EDL specification [18]. Prior to our dis-
closure, EDL allowed programmers to specify a custom [sizefunc]
attribute that takes as an argument an unchecked pointer to an
application-specific structure, and returns its size. Likewise, there
is a dedicated [string] EDL attribute to specify null-terminated

1 static sgx_status_t SGX_CDECL sgx_my_ecall ( void * pms )
2 {
3

CHECK_REF_POINTER ( pms , sizeof ( ms_my_ecall_t ));
ms_my_ecall_t * ms = SGX_CAST ( ms_my_ecall_t *, pms );
char * _tmp_s = ms -> ms_s ;

4

5

6
7 ⭑ size_t _len_s = _tmp_s ? strlen ( _tmp_s ) + 1 : 0;
8

char * _in_s = NULL ;

9

10

11

12

CHECK_UNIQUE_POINTER ( _tmp_s , _len_s );
__builtin_ia32_lfence () ; // fence after pointer checks
...

Listing 3: Proxy function generated by edger8r for the EDL
specification: public void my_ecall([in,string] char *s).

string arguments. Essentially, this special case comes down to
[sizefunc=strlen].

Consider the code skeleton generated by edger8r in Listing 3
for an ecall that expects a single string pointer argument. In or-
der to verify that the complete string is outside the enclave, the
trusted edge routine first computes the size of the argument buffer
(through either strlen() or a dedicated sizefunc in general), and
only thereafter checks whether the entire buffer falls outside of the
enclave. It is intended that the edge code first determines the length
in untrusted memory, but we made the crucial observation that the
strlen() invocation at line 7 operates on an arbitrary unchecked
pointer, potentially pointing into enclave memory. Any pointer
poisoning attempts will subsequently be rejected at line 10, but
the unintended computation may have already leaked information
through various side-channels [24, 45]. In general, leakage occurs
whenever there is secret-dependent control or data flow in the
specified sizefunc. This is most obviously the case for the common
[string] EDL attribute, since the amount of loop operations per-
formed by strlen() reveals the number of non-zero bytes following
the specified in-enclave pointer.

Our attack builds on top of the open-source SGX-Step [45] en-
clave interrupt framework to turn the subtle strlen() side-channel
leakage into a fully deterministic oracle that reveals the exact po-
sition of all 0x00 bytes in enclave private memory (thereby for
instance fully breaking the confidentiality of booleans or providing
valuable information for cryptanalysis). Particularly, we use SGX-
Step to reliably step the strlen() execution, one instruction at a
time, leveraging the “accessed” bit in the page table entry of the
targeted in-enclave memory location as a noise-free oracle that is
deterministically set by the processor for every strlen() loop itera-
tion [47]. We confirmed that our single-stepping oracle continues to
work reliably even when the victim enclave was compiled to a sin-
gle, extremely compact rep movsb instruction (x86 string operations
can indeed be interrupted in between every loop iteration [17]).

We developed a practical end-to-end AES-NI key extraction PoC
in an application enclave built with a vulnerable version of edger8r.
Our victim enclave provides a single, multi-threaded ecall entry
point that encrypts the first 16 bytes of a given string using side-
channel resistant AES-NI instructions with a secret in-enclave key.
Since AES-NI operates exclusively on CPU registers (e.g., xmm0) and
due to the limited nature of the strlen() side-channel, we cannot
perform key extraction by directly targeting the AES state or key
in memory. Instead, our attack uses repeated encryption ecalls,
assuming varying (but not necessarily known) plaintext and known

Algorithm 1 strlen() oracle AES key recovery where S (⋅) denotes the
AES SBox and S R (p) the position of byte p after AES ShiftRows.

while not full key K recovered do

(P, C, L) ← random plaintext, associated ciphertext, strlen oracle
if L < 16 then

K [S R (L)] ← C [S R(L)] ⊕ S (0)

end if
end while

pointers before they are architecturally rejected. However, our
attack is immune to such countermeasures because we directly
observe side effects of normal, non-speculative execution. Further,
early rejecting the ecall when detecting that the start pointer falls
inside the enclave does not suffice in general. In such a case, adver-
saries might still pass pointers below the enclave base address, and
observe secret-dependent behavior based on the first bytes of the
enclave. Intel implemented our recommended mitigation strategy
by dropping support for the superfluous [sizefunc] EDL attribute
entirely, and further abstaining from computing untrusted buffer
sizes inside the enclave. Instead, alleged buffer sizes are computed
outside the enclave, and passed as an untrusted argument, such that
the CHECK_UNIQUE_POINTER test can take place immediately. For the
strlen() case, the untrusted memory can simply be copied inside,
and an extra null byte inserted at the alleged end. This solution con-
veniently moves all secret-dependent control flow from the enclave
into the untrusted application context.

Microsoft Open Enclave SDK. After Intel had properly patched
the strlen() side-channel vulnerability in the SGX-SDK, OE ap-
pears to have tried to adopt our proposed mitigation strategy of
passing an untrusted alleged string length into the enclave. How-
ever, after reviewing the generated code, we found that oeedger8r
fails to include a 0x00 terminator byte after copying the untrusted
string inside enclave memory (cf. Appendix A.6). This critical over-
sight can be exploited to trick the shielded enclave application into
operating on non-null-terminated strings. The trusted user function
will incorrectly assume that the string is properly terminated and
may perform out-of-bounds memory read/writes, hence turning a
mitigation for a subtle and functionally correct side-channel issue
into a more dangerous source of enclave memory corruption. This
OE vulnerability is tracked via CVE-2019-0876 and specific to en-
claves that expect EDL string arguments, and output or manipulate
them in-place (e.g., strcpy()).

We experimentally demonstrated this vulnerability by means
of a minimal PoC application enclave which overwrites all non-
alphanumeric chars in a string with 0x20, until the null terminator
is encountered. If this enclave operates on an unterminated string,
the length field of the subsequent heap frame is corrupted, which
subsequently can be further leveraged in more complex exploits.

5.3 Validating variable-sized buffers
Multi-byte input buffers are commonly specified by passing a pointer
to the start of the buffer and an associated size. In order to properly
validate such buffers, the trusted runtime should first compute the
end pointer by adding the alleged size argument, and thereafter
assert that the complete input buffer address range falls outside the
enclave. However, since the buffer size is an adversary-controlled

Figure 4: Overview of the key extraction attack exploiting
strlen() side-channel leakage in Intel SGX-SDK.

ciphertext. We further abuse that the Intel SGX architecture enables
a privileged adversary to precisely interrupt a victim enclave at
a chosen instruction-level granularity [45], thereby forcing the
processor to write the register state to a fixed SSA location in
enclave memory (this includes the xmm registers that are part of
the XSAVE region of the SSA frame). Figure 4 depicts the high-level
phases of the attack flow, using two threads A and B:
(a) Invoke the encryption ecall from thread A 1⃝ and interrupt
the enclave 2⃝ before the final round of the AES (i.e., before the
aesenclast instruction). To keep the PoC simple, we achieve this
requirement by inserting an access to a dummy page at the ap-
propriate point, and catching accesses to this page in a signal
handler on the untrusted side. Note that in a real-world attack,
the single-stepping feature of SGX-Step could be used to execute
the victim enclave exactly up to this point, without relying on a
more coarse-grained page fault for interruption.
(b) While the ecall in thread A is interrupted, prepare the timer
used by SGX-Step 3⃝ and launch a second thread B 4⃝ to probe
the position of the first zero byte (if any) in the intermediate AES
state. Concretely, this involves a second ecall to the same entry
point, but this time supplying an illegal in-enclave target address
pointing to the fixed memory location containing the xmm0 register
in the SSA frame of the interrupted thread A. Each time when a
timer interrupt arrives 5⃝, we monitor and clear 6⃝ the “accessed”
bit of the targeted SSA page table entry.
(c) After the strlen() probing has finished, the obtained leakage
is stored alongside the corresponding ciphertext, and thread A is
resumed by restoring read/write access to the dummy page.

(d) Repeat from step (a) with a different plaintext until the full key

has been recovered (see Algorithm 1).

Experimentally, we determined that this attack succeeds with
881 AES invocations on average (over 1000 runs with random keys,
minimum: 306, maximum: 3346), given a deterministic, noise-free
strlen() oracle. Note that this attack could also be adapted to work
with noisy measurements, using the so-called zero-value model
known from hardware side-channel attacks [12]. Besides, the attack
would also be applicable when targeting the first round of the AES
in a known-plaintext scenario.

Properly closing this side-channel requires profound changes in
the way edger8r works. Notably, the bridge code includes an lfence
instruction at line 11 to rule out advanced Spectre-v1 misspecula-
tion attacks that might still speculatively compute on unchecked

EnclaveIRQ1encryptString(){		aesenc	k[8],	%xmm0		aesenc	k[9],	%xmm0		//Interruption		aesenclast	k[10],%xmm0}SSAThread ATHREAD ATHREAD B4Ecall (SSA_frame+ XMM0_OFFSET)2AEX Thread AHost ApplicationEdger8rEcall(msg){		...		strlen(msg)}Ecall (message)SSAThread B5AEX Thread B3Conﬁgtimer6Check accessed bitHardwareparameter, care should be taken to prevent the pointer addition
from overflowing and silently wrapping around the address space.

Attack vector #6 (integer overflow): Runtimes should use safe arith-
metics when computing addresses in a buffer with untrusted size. ▷ Rela-
tively well-understood in production SDKs, not in research code.

TEE design. We found that the address-related vulnerabilities
in this section are significantly more exploitable in TEE designs
that provide increased attacker control over the shared memory
and enclave memory layouts. For instance, some integer overflow
vulnerabilities require the adversary to control the enclave base
address in a shared address space, as is the case for the Intel SGX [8]
and Sancus [32] designs, but not for ARM TrustZone [34] or Key-
stone [21]. Further, we found that logical errors may arise when
checking variable sized buffers in a shared address space. As de-
tailed below, the exploitability of such logic bugs depends heavily
on the ability of the adversary to trigger certain edge cases (e.g.,
passing a pointer that lies just before the enclave base address),
which might also be considerably easier in single-address space
TEE designs like Intel SGX or Sancus.

Fortanix Rust-EDP. In contrast to the other runtimes described
in this paper, Fortanix’s EDP [11] leverages the type system of
the safe Rust language to disallow inadvertent untrusted pointer
dereferences apart from the dedicated UserSafe type, which trans-
parently sanitizes any pointers passed into the enclave. Rust-EDP’s
shielding system has been explicitly designed to avoid known en-
clave boundary attacks and implements libOS-like functionality
through a deliberately very narrow ocall interface that is kept
invisible to the application programmer. However, our analysis
shows that the promising approach of enforcing pointer sanitiza-
tion through the use of a type system may evidently still suffer from
security issues if the implementation in the type itself is incorrect.
We manually scrutinized the implementation of the confined
UserSafe type (part of the Rust compiler’s SGX-EDP target [11])
and found a potentially exploitable integer overflow vulnerability
in the pointer validation logic. Listing 4 shows the relevant is_use
r_range() function, which checks whether an untrusted memory
range specified by a pointer and length falls completely outside the
enclave. Concretely, we observed that the 64-bit integer addition to
compute the end pointer at line 4 may overflow. Note that Rust can
automatically detect integer overflows, but these runtime checks
are only enabled in debug mode, meaning that in production builds
(e.g., rustc -C debug-assertions=off), integer overflows do not
cause an error by default [25].

We confirmed (after isolating the validation function in a dummy
Rust test program) that said function can be made to early-out
and return true at line 5 even when passing an illegal in-enclave
pointer if the enclave base is near the top of the address space.
Note that Intel SGX leaves the enclave base address under explicit
attacker control [8], so this requirement may be satisfied by real-
world attackers. For example, the untrusted runtime can return
a specially-crafted pointer from the alloc() usercall, potentially
leading to in-enclave memory disclosure or corruption, depending
on how the pointer is further used within the enclave. After our
disclosure, the EDP trusted runtime now explicitly asserts that
untrusted sizes returned by alloc() do not overflow.

1 // / ` true ` if the specified memory range is in userspace .
2 pub fn is_user_range (p: * const u8 , len : usize ) -> bool {
3
4 ⭑ let end = start + ( len as u64 );
5

end <= image_base () || start >= image_base () + ( unsafe {

let start = p as u64 ;

ENCLAVE_SIZE } as u64 ) // unsafe ok : link - time constant

6 }

Listing 4: Pointer validation in the Rust-EDP UserSafe type.

Google Asylo. Apart from the aforementioned [user_check] is-
sues, the entry points in Asylo’s trusted runtime take care to vali-
date all second-level input buffers. However, our code review also
revealed a subtle logic mistake in the input validation logic itself.
That is, we observed that many of the trusted runtime functions (cf.
Appendix A.3 for a relevant sample) rely on the TrustedPrimitive
s::IsTrustedExtent(input,input_size) library function returning
true to reject the ecall attempt when detecting that an untrusted
input buffer is completely contained within enclave memory.

While this function itself translates to the corresponding sgx_is
_within_enclave() primitive from the SGX-SDK, which is indeed
correct and free from integer overflow vulnerabilities, the logic
mistake occurs when considering malicious input buffers that only
partly overlap with untrusted and enclave memory. For instance,
IsTrustedExtent() will properly return false and the ecall will
still be allowed when passing a lengthy adversarial input buffer
that starts one byte before the enclave base address but continues
into the enclave memory range. Evidently, this may subsequently
lead to trusted enclave memory corruption or disclosure. Hence,
the trusted runtime should instead make use of the proper sgx_is_
outside_enclave() SGX-SDK primitive.

Attack vector #7 (outside ≠ ¬inside): In a shared address space, input
buffers should not fall partially inside the trusted memory region. ▷ Gen-
erally understood in production SDKs, not always in research code.

Graphene-SGX. We discovered a critical integer overflow vul-
nerability in the widely used pointer range validation function
that often computes on untrusted attacker-provided sizes (simi-
lar to the Rust-EDP issue described above). We further found that
Graphene-SGX suffers from the same subtle logic mistake that we
spotted in the Asylo code base: at the time of our review, there
was no sgx_is_outside_enclave() primitive, and all instances of
the intended “abort if not completely outside” were erroneously
checked for “abort if completely inside enclave” (cf. Listing 5 for a
relevant sample). A related type of pointer validation vulnerabili-
ties arises when the libOS allocates variable-sized output buffers in
untrusted memory outside the enclave to be able to exchange data
for ocall arguments and return values. For performance reasons,
Graphene-SGX allocates such shared memory buffers directly on
the untrusted host stack. While the untrusted host stack pointer
is indeed validated to lie outside of enclave memory upon enclave
entry, we observed that the trusted libOS does not properly check
whether the untrusted stack does not overflow into enclave memory
after allocating a new shared memory buffer in the widely used OC
ALLOC macro. Depending on the specific ocall implementation, the
enclave will subsequently copy data to/from the inappropriately
allocated buffer, leading to information disclosure and/or memory
corruption.

Keystone. While Keystone [21] is still a research prototype and
lacked essential functionality when we reviewed its code, we dis-
covered and reported a potential integer overflow vulnerability (cf.
Appendix A.7) in the trusted security monitor’s detect_region_ove
rlap() function, which is used during the creation of an enclave.
However, this overflow was not directly exploitable due to certain
restrictions on region sizes in the Keystone codebase.

Sancus. We found both logical errors and integer overflow vul-
nerabilities in the sancus_is_outside_sm() function provided by the
trusted runtime. Particularly, the current implementation does not
properly detect an untrusted buffer that spans the entire enclave
address range, or a carefully crafted length specifier that triggers
an integer overflow to wrap around the 16-bit address space.

5.4 Pointer-to-pointer validation pitfalls
While the previous sections have focussed on the spatial aspect of
untrusted pointer dereferencing, we also found more subtle vulner-
abilities related to the temporal aspect. That is, whenever a pointer
points to an untrusted address or size (as it is often the case, for
instance, in marshalling structs), the runtime should take care to
first copy the second-level pointer value to a trusted location in
enclave memory before applying the sanitization logic. If this is
not the case, adversaries may overwrite the second-level pointer
in untrusted memory after the validation has succeeded but before
the pointer is dereferenced in the enclave code. This class of vul-
nerabilities is also referred to as “double fetch” bugs in operating
system kernels [37, 53].

Attack vector #8 (double fetch): Untrusted pointer values should be
copied inside the enclave before validation to avoid time-of-check time-of-
use. ▷ Relatively well-understood (once pointer sanitization is applied).

TEE design. Double fetch bugs typically rely on a very nar-
row vulnerability time window and hence can be notoriously hard
to exploit in traditional user-to-kernel contexts. However, recent
research demonstrated how some TEE design decisions may con-
siderably simplify exploitation of synchronization bugs in enclaves.
AsyncShock [50] exploits that Intel SGX adversaries may provoke
page faults in the enclaved execution, and SGX-Step [45] similarly
abuses that privileged SGX adversaries may abuse system timers to
very precisely interrupt a victim enclave after every single instruc-
tion. Finally, Schwarz et al. [37] use a cache side-channel to expose
double fetch bugs in both Intel SGX and ARM TrustZone TEEs.

Graphene-SGX. Scrutinizing Graphene-SGX’s ocall interface,
we found several instances of exploitable double fetch vulnerabili-
ties. Listing 5 provides a relevant code snippet that attempts to sani-
tize the result of the sock_accept system call. First, at line 1, a buffer
ms is allocated in untrusted memory outside the enclave. The struct
buffer pointed to by ms contains another pointer ms->ms_addr that
will be initialized by the untrusted runtime to point to the socket
address returned by the system call. As ms->ms_addr is an untrusted
pointer, the libOS shielding system attempts to properly validate
that it lies outside the enclave at line 5 (modulo the logic bug de-
scribed in Section 5.3) before dereferencing ms->ms_addr a second
time when copying the socket address buffer inside at line 11. How-
ever, since the parent ms struct was allocated in untrusted memory
and has never been copied inside, SGX adversaries can interrupt

1

2

3

4
5 ⭑
6

7

8

9

10
11 ⭑

OCALLOC (ms , ms_ocall_sock_accept_t *, sizeof (* ms ));
...
retval = SGX_OCALL ( OCALL_SOCK_ACCEPT , ms );
if ( retval >= 0) {

if ( len && ( sgx_is_within_enclave (ms -> ms_addr , len )
|| ms -> ms_addrlen > len )) {

OCALL_EXIT () ;
return - PAL_ERROR_DENIED ;

}
...
COPY_FROM_USER ( addr , ms -> ms_addr , ms -> ms_addrlen );

Listing 5: Double fetch vulnerability in Graphene-SGX.

the enclave in between lines 5 and 11 and trivially overwrite the ms
_addr field with an arbitrary in-enclave address, potentially leading
to trusted memory disclosure.

5.5 Validating ocall return values
Apart from validating ecall arguments, the enclave trusted runtime
should also take care to properly scrutinize ocall return values
when passing pointers or sizes back into the enclave.

Attack vector #9 (Iago): Pointers or sizes returned through ocalls
should be scrutinized [4]. ▷ Understood, but still prevalent in research
libOSs that shield system calls; one instance in a production SDK.

TEE design. We found that the complexity of the shielding sys-
tem may largely affect this attack surface. That is, SDK-based ap-
proaches typically do not feature a large built-in ocall interface,
whereas libOSs should safeguard against Iago attacks [4] by scruti-
nizing return values from the complex system call interface before
passing them on to the shielded application.

Microsoft Open Enclave SDK. OE’s trusted runtime includes
a oe_get_report() function which is used to provide attestation
functionality to the enclaved binary. Internally, this function per-
forms the same ocall twice; the first time specifying the output
buffer as a null pointer in order to obtain the required quote size.
Based on this size, a buffer is allocated on the enclave heap, and
subsequently filled through a second ocall invocation. We found,
however, that the untrusted runtime can return different sizes for
the two ocall invocations (tracked via CVE-2019-1369). Particularly,
the in-enclave buffer is allocated based on the size obtained from
the first ocall, whereas the size returned by the second ocall is
passed on to the caller of oe_get_report(). Hence, returning an un-
expectedly large size in the second ocall invocation may cause the
enclave application to read or write out of bounds. We experimen-
tally confirmed that OE’s remote attestation example enclave can
leak up to 10 kB of trusted heap memory (this upper bound is due
to an internal limit), possibly at multiple heap locations depending
on other memory allocations.

LibOS-based runtimes. We discovered several exploitable in-
stances of Iago attacks [4] in Graphene-SGX’s ocall interface. For
example, an untrusted system call return value len is later used
to copy len bytes from untrusted memory into a fixed-size buffer
inside the enclave, leading to arbitrary write-past the in-enclave
buffer. To demonstrate this vulnerability, we developed a PoC where
the readdir() system call in the untrusted runtime returns an un-
expected length, causing an out-of-bounds write in the enclave.

Similarly, in SGX-LKL’s ocall interface, we found several in-
stances of Iago vulnerabilities where for example the untrusted
pointers returned by mmap() are not checked to lie outside of en-
clave memory, or the untrusted length returned by write() is passed
unsanitized back to the shielded application. To demonstrate how
this can be successfully exploited, we developed an elementary
victim application featuring a common programming idiom where
write() is used to output a buffer piecewise, each time advancing
a pointer with the number of bytes successfully written (i.e., the
system call’s return value). We modified the untrusted runtime to
unexpectedly increment the return value of the write() system call,
causing the shielded application binary to output secret enclave
memory beyond the buffer bounds. Finally, we also confirmed and
reported the existence of similar issues in Google Asylo.

Keystone. Similar to the above SGX runtimes, Keystone pro-
vides system call wrappers to simplify porting of existing code to
an enclave. While Keystone documentation indicates that the de-
velopers are aware of potential issues, the codebase currently lacks
mitigations against Iago attacks. Hence, we developed an exploit
using the write() system call, similar to the SGX-LKL PoC.

5.6 Scrubbing uninitialized structure padding
Apart from pointers and size arguments, enclaves may also pass
composite struct types to the untrusted world. While, as with all
output buffers, we assume that enclave applications do not inten-
tionally disclose secrets through the program-visible state (i.e., the
struct’s individual members), prior research on operating system
kernel [7] and SGX enclave [23] interfaces has shown that padding
bytes silently added by the compiler may still unintentionally leak
uninitialized secret memory.

Attack vector #10 (uninitialized padding): Scrubbing program-visible
state may not suffice for struct outputs [23]. ▷ Especially relevant for
production SDKs that expose the enclave interface to the programmer.

TEE design. This subtle attack vector cannot be easily mitigated
by sanitizing program-visible API state. Possible mitigations include
securely initializing the entire output struct using memset() and/or
doing a member-wise deep-copy, or declaring the output struct as
“packed” so the compiler does not unknowingly introduce padding.
However, both solutions require application-specific knowledge
about the exact struct types being passed. As an important insight,
we therefore found that this attack vector can only be transparently
shielded when the enclave interface is predefined and fixed. That
is, the fixed ocall interface in libOS-based runtimes can indeed be
manually scrutinized for this type of vulnerabilities. However, this
is not the case for SDK-based runtimes that offer a generic enclave
interface defined by the programmer, and hence (opposed to their
shielding responsibility) ultimately outsource the responsibility of
scrubbing uninitialized struct padding to the application developer.

SDK-based runtimes. Lee et al. [23] first demonstrated how
uninitialized struct padding may pose a subtle information leak-
age source in the edger8r-generated code of the Intel SGX-SDK.
Building on their findings, we generalized this attack vector to also
demonstrate its applicability to oeedger8r-generated code in Mi-
crosoft’s Open Enclave SDK, as well as in the Sancus TEE. Similarly,

we confirmed that padding leakage can also occur in Keystone, e.g.,
through the padding of calc_message_t in the demo enclave.

LibOS-based runtimes. We reviewed the ocall interfaces in
the libOS-based runtimes we studied (Graphene-SGX, LKL, Rust-
EDP). Rust-EDP appears to be free of such issues, and Graphene-
SGX explicitly enforces struct packing through a compiler #pragma.
However, SGX-LKL contains at least two instances of an ocall using
a struct with potentially vulnerable padding bytes (sigaction and
siginfo_t). In Google Asylo, most structs passed through an ocall
are explicitly declared as packed, however, we found one instance of
a padded struct BridgeSignalHandler used in the syscall interface.

6 DISCUSSION AND GENERAL MITIGATIONS
The most intuitive solution to defend against our attacks is to in-
corporate additional checks in the enclave code to properly sanitize
ABI state and API arguments/return values. When properly imple-
mented, such checks suffice to block all of the attacks described
in this work, and they have indeed been adopted by the various
projects we analyzed. However, leaving the decision of whether
(and how) to correctly implement numerous interface validation
checks to enclave developers, who are likely unaware of this class
of vulnerabilities, may be problematic. Moreover, even when de-
velopers think about inserting the necessary checks, our analysis
has revealed several recurring pitfalls, including subtle logical bugs,
side-channels, double fetches, and integer overflows. This high-
lights the need for more principled approaches to rule out this class
of vulnerabilities at large, as well as defense-in-depth code harden-
ing measures that may raise the bar for successful exploitation.

Code hardening. Interface sanitization vulnerabilities are closely
related to a wider class of memory safety issues [3, 22], and their
exploitation may hence be partially hindered by established tech-
niques such as heap obfuscation (cf. Section 4.1). Furthermore, SGX-
Shield [40] aims to obstruct memory corruption attacks by random-
izing the memory layout of enclaved binaries shielded by the Intel
SGX-SDK. However, prior research [3] has shown that SGX-Shield
does not randomize the trusted runtime, meaning that the code
we studied would still feature a deterministic and static memory
layout, and may offer numerous gadgets for mounting code reuse
attacks. Further, as the trusted runtime also forms an integral part
of SGX-Shield’s loader [40], any memory safety or side-channel
vulnerabilities in the trusted runtime itself may also be used to dis-
rupt the preliminary randomization stage. While randomizing the
memory layout of the trusted runtime would indeed be desirable,
this constitutes a non-trivial task [3, 40] given its low-level nature,
including hand-written assembly code and static memory addresses
expected by SGX’s eenter and eresume instructions. In this respect,
we want to emphasize that some of the attacks we presented are
free from non-static address dependencies, and hence remain inher-
ently immune to software randomization schemes. For example, the
SGX-SDK strlen() oracle in Fig. 4 depends solely on the fixed ad-
dress of the victim’s SSA frame, which is deterministically dictated
by the SGX hardware and immutable from software.

As a perpendicular code hardening avenue, we recommend to
implement more aggressive responses when detecting pointer vi-
olations in the trusted runtime. That is, most of the runtimes we

studied merely reject the ecall attempt when detecting pointer
poisoning. In the SGX-SDK strlen() oracle attack of Section 5.2,
we for example abused this to repeatedly call a victim enclave,
each time passing an illegal pointer and making side-channel ob-
servations before the ecall is eventually rejected. To rule out such
repeated attacks, and reflecting that in-enclave pointers represent
clear adversarial or buggy behavior, we recommend to immediately
destroy secrets and/or initiate an infinite loop upon detecting the
first pointer poisoning attempt in the trusted runtime.

Hardware-assisted solutions. As a more principled approach
to rule out the confused deputy attacks described in this paper,
solutions could leverage finer-grained memory protection features
in the processor. In particular, tagged memory [51] or capability
architectures [52] appear to be a promising approach to inherently
separate the memory domains of untrusted and trusted code. On
a capability machine [52], pointers are represented at run-time as
unforgeable objects carrying associated permissions and length
fields. The machine ensures that untrusted code can never create
a valid capability that points inside enclave-private memory and
pass it as an argument to an ecall, thereby eradicating an entire
class of pointer dereference vulnerabilities architecturally.

As an example of an alternative tagged memory design, the re-
cently proposed Timber-V [51] architecture provides lightweight
and strong enclaved execution on embedded RISC-V platforms.
Timber-V processors offer enhanced MPU isolation by keeping
track of a 2-bit tag for every memory word, allowing individual
memory locations to be associated with one out of 4 possible se-
curity domains. The CPU further restricts tag updates, and offers
checked memory load/store operations, which take an expected tag
as an argument and trap whenever the actual memory location
being dereferenced does not match the expected tag. Hence, any
pointer poisoning attempts by untrusted code outside the enclave
would be immediately caught by the hardware.

The untrusted pointer dereference issues we identified in this
work bear some similarities with how privileged OS kernel code
needs to properly sanitize user space pointers in e.g., system call
arguments. As a defense-in-depth mechanism, recent x86 proces-
sors support Supervisor Mode Access Protection (SMAP) features
to explicitly disallow unintended user space pointer dereferences
in kernel mode [17]. We encourage further research to investigate
porting such CPU features to enclave mode.

Safe programming languages. The combination of TEEs and
safe programming languages, such as Rust, has been proposed as a
promising research direction to safeguard enclave program seman-
tics, but still requires additional interface sanitizations [48]. The
approach of Fortanix’s Rust-EDP [11] shows how the compiler’s
type system can be automatically leveraged to limit the burden of
pointer sanitization concerns from a cross-cutting concern through-
out the enclave code base to the correct implementation of a single
untrusted pointer type. However, it is important to note that safe
languages by themselves are not a silver bullet solution to our
attacks. That is, the trusted runtime code remains responsible to
bootstrap memory safety guarantees by (i) establishing expected
ABI calling conventions in the low-level entry assembly code, and
(ii) providing a correct implementation of sanitization in the un-
trusted pointer type. In this respect, the subtle integer overflow

vulnerability in Fortantix’s EDP, presented in Section 5.3, demon-
strates that developing both the trusted runtime libraries and the
enclave in safe Rust may still not suffice to fully eradicate pointer
sanitization vulnerabilities.

Finally, as an alternative to Intel’s edger8r tool, the use of sep-
aration logic has been proposed to automatically generate secure
wrappers for SGX enclaves [49]. This approach aims to provide the
advantages of safe languages, and even formal verification guaran-
tees, but still relies on explicit developer annotations.

7 CONCLUSIONS AND FUTURE WORK
Our work highlights that the shielding responsibilities in today’s
TEE runtimes are not sufficiently understood, and that various
security issues exist in the respective trusted computing bases. We
showed that this attack surface is large and often overlooked: we
have identified 35 interface sanitization vulnerabilities in 8 open-
source TEE runtimes, including production-quality SDKs written
by security-savvy developer teams. Our analysis further reveals
that the entry points into this attack surface are more pervasive
than merely argument pointers: we contributed a classification of
10 recurring vulnerability classes spanning the ABI and API tiers.
In the defensive landscape, our work emphasizes the need to
research more principled interface sanitization strategies to safe-
guard the unique TEE shielding responsibilities. We particularly
encourage the development of static analysis tools, and fuzzing-
based vulnerability discovery and exploitation techniques to further
explore this attack surface.

ACKNOWLEDGMENTS
We thank Jethro Beekman (Fortanix), Job Noorman (KU Leuven),
and Johannes Götzfried for insightful discussions, and the anony-
mous reviewers for constructive feedback that helped improving
the paper. We further would like to thank the maintainers of the
open-source projects we studied for their contributions to the com-
munity and for promptly responding and working on mitigations.
This research is partially funded by the Research Fund KU Leu-
ven, and by the Agency for Innovation and Entrepreneurship (Flan-
ders). Jo Van Bulck is supported by a grant of the Research Foun-
dation – Flanders (FWO). This research is partially funded by the
Engineering and Physical Sciences Research Council (EPSRC) under
grants EP/R012598/1, EP/R008000/1 and by the European Union’s
Horizon 2020 research and innovation programme under grant
agreement No. 779391 (FutureTPM). Abdulla Aldoseri is supported
by a stipend from the University of Bahrain.

REFERENCES
[1] Sergei Arnautov, Bohdan Trach, Franz Gregor, Thomas Knauth, Andre Martin,
Christian Priebe, Joshua Lind, Divya Muthukumaran, Dan O’Keeffe, Mark L Still-
well, et al. 2016. SCONE: Secure Linux Containers with Intel SGX. In Proceedings
of the 12th USENIX Symposium on Operating Systems Design and Implementation.
USENIX Association, 689–703.

[2] Andrew Baumann, Marcus Peinado, and Galen Hunt. 2014. Shielding applications
from an untrusted cloud with Haven. In Proceedings of the 11th USENIX conference
on Operating Systems Design and Implementation. USENIX Association, 267–283.
[3] Andrea Biondo, Mauro Conti, Lucas Davi, Tommaso Frassetto, and Ahmad-Reza
Sadeghi. 2018. The Guard’s Dilemma: Efficient Code-Reuse Attacks Against Intel
SGX. In Proceedings of the 27th USENIX Security Symposium. 1213–1227.

[4] S. Checkoway and H. Shacham. 2013. Iago Attacks: Why the System Call API
is a Bad Untrusted RPC Interface. In International Conference on Architectural
Support for Programming Languages and Operating Systems (ASPLOS). 253–264.

[5] Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and
Ten H Lai. 2019. SgxPectre: Stealing Intel Secrets from SGX Enclaves Via Spec-
ulative Execution. In 2019 IEEE European Symposium on Security and Privacy
(EuroS&P). IEEE, 142–157.

[6] Haogang Chen, Yandong Mao, Xi Wang, Dong Zhou, Nickolai Zeldovich, and
M Frans Kaashoek. 2011. Linux kernel vulnerabilities: State-of-the-art defenses
and open problems. In Proceedings of the Second Asia-Pacific Workshop on Systems.
ACM, 5:1–5:5.

[7] J. Corbet. 2010. Structure holes and information leaks. online, accessed 2019-08-06:

https://lwn.net/Articles/417989/. (December 2010).

[34] S. Pinto and N. Santos. 2019. Demystifying Arm TrustZone: A Comprehensive

Survey. ACM Computing Surveys (CSUR) 51, 6 (2019), 130.

[35] Christian Priebe, Divya Muthukumaran, Joshua Lind, Huanzhou Zhu, Shujie Cui,
Vasily A Sartakov, and Peter Pietzuch. 2019. SGX-LKL: Securing the Host OS
Interface for Trusted Execution. arXiv preprint arXiv:1908.11143 (2019).

[36] Graphene Project. 2019. Graphene: a Library OS for Unmodified Applications.

online, accessed 2019-08-30: https://grapheneproject.io/. (2019).

[37] M. Schwarz, D. Gruss, M. Lipp, C. Maurice, T. Schuster, A. Fogh, and S. Mangard.
2018. Automated detection, exploitation, and elimination of double-fetch bugs
using modern CPU features. In Asia CCS 2018. 587–600.

[8] V. Costan and S. Devadas. 2016. Intel SGX Explained. IACR Cryptology ePrint

[38] M. Schwarz, Samuel Weiser, and Daniel Gruss. 2019. Practical enclave malware

Archive 2016, 086 (2016), 1–118.

with Intel SGX. In DIMVA. 177–196.

[9] J. Edge. 2008. CVE-2008-1367 Kernel doesn’t clear DF for signal handlers.

[39] M. Schwarz, S. Weiser, D. Gruss, C. Maurice, and S. Mangard. 2017. Malware

https://bugzilla.redhat.com/show_bug.cgi?id=437312. (March 2008).

guard extension: using SGX to conceal cache attacks. In DIMVA. 3–24.

[10] A. Fog. 2018. Calling conventions for different C++ compilers and operating
systems. http://www.agner.org/optimize/calling_conventions.pdf. (April 2018).
[11] Fortanix. 2019. Fortanix Enclave Development Platform – Rust EDP. online,

[40] J. Seo, B. Lee, S. Min Kim, M.W Shih, I. Shin, D. Han, and T. Kim. 2017. SGX-Shield:
Enabling Address Space Layout Randomization for SGX Programs.. In NDSS 2017.
[41] H. Shacham et al. 2007. The geometry of innocent flesh on the bone: return-into-

accessed 2019-08-30: https://edp.fortanix.com/. (2019).

[12] J. D. Golić and C. Tymen. 2003. Multiplicative Masking and Power Analysis of
AES. In Cryptographic Hardware and Embedded Systems (CHES). 198–212.
[13] Google. 2019. Asylo: An open and flexible framework for enclave applications.

online, accessed 2019-08-06: https://asylo.dev/. (2019).

[14] J. Götzfried, T. Müller, R. De Clercq, P. Maene, F. Freiling, and I. Verbauwhede.
2015. Soteria: Offline software protection within low-cost embedded devices. In
Annual Computer Security Applications Conference (ACSAC). 241–250.

[15] Jago Gyselinck, Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2018. Off-limits:
Abusing legacy x86 memory segmentation to spy on enclaved execution. In
International Symposium on Engineering Secure Software and Systems (ESSoS ’18).
Springer, 44–60.

[16] N. Hardy. 1988. The Confused Deputy (or why capabilities might have been

invented). ACM SIGOPS Operating Systems Review 22, 4 (1988), 36–38.

[17] Intel. 2016.

Intel 64 and IA-32 Architectures Software Developer’s Manual,

Volume 3 (3A, 3B & 3C): System Programming Guide. 325384 (2016).

libc without function calls (on the x86).. In ACM CCS 2007. 552–561.

[42] S. Shinde, D. Le Tien, S. Tople, and P. Saxena. 2017. Panoply: Low-TCB Linux

Applications With SGX Enclaves. In NDSS 2017.

[43] C.C Tsai, D. E Porter, and M. Vij. 2017. Graphene-SGX: A practical library OS for

unmodified applications on SGX. In USENIX ATC.

[44] J. Van Bulck, M. Minkin, O. Weisse, D. Genkin, B. Kasikci, F. Piessens, M. Sil-
berstein, T. F. Wenisch, Y. Yarom, and R. Strackx. 2018. Foreshadow: Extracting
the keys to the Intel SGX kingdom with transient out-of-order execution. In
Proceedings of the 27th USENIX Security Symposium.

[45] J. Van Bulck, F. Piessens, and R. Strackx. 2017. SGX-Step: A practical attack

framework for precise enclave execution control. In SysTEX. 4:1–4:6.

[46] J. Van Bulck, F. Piessens, and R. Strackx. 2018. Nemesis: Studying microarchitec-
tural timing Leaks in rudimentary CPU interrupt logic. In ACM CCS 2018.
[47] J. Van Bulck, N. Weichbrodt, R. Kapitza, F. Piessens, and R. Strackx. 2017. Telling
your secrets without page faults: Stealthy page table-based attacks on enclaved
execution. In Proceedings of the 26th USENIX Security Symposium. 1041–1056.

[18] Intel. 2018. Intel Software Guard Extensions (SGX) SW Development Guidance for

[48] N. van Ginkel, R. Strackx, T. Mühlberg, and F. Piessens. 2016. Towards safe

Potential Edger8r Generated Code Side Channel Exploits. Revision 1.0.

enclaves. In Hot Issues in Security Principles and Trust (HotSpot). 1–16.

[19] Intel. 2019. Intel Software Guard Extensions – Get Started with the SDK. online,

accessed 2019-05-10: https://software.intel.com/en-us/sgx/sdk. (2019).

[20] E. Mohammadian Koruyeh, K. N Khasawneh, C. Song, and N. Abu-Ghazaleh. 2018.
Spectre returns! speculation attacks using the return stack buffer. In USENIX
Workshop on Offensive Technologies (WOOT).

[21] D. Lee, D. Kohlbrenner, S. Shinde, D. Song, and K. Asanović. 2019. Keystone: A
Framework for Architecting TEEs. arXiv preprint arXiv:1907.10119 (2019).
[22] J. Lee, J. Jang, Y. Jang, N. Kwak, Y. Choi, C. Choi, T. Kim, M. Peinado, and
B. Byunghoon Kang. 2017. Hacking in Darkness: Return-oriented Programming
against Secure Enclaves. In Proceedings of the 26th USENIX Security Symposium.
523–539.

[23] S. Lee and T. Kim. 2017. Leaking Uninitialized Secure Enclave Memory via

Structure Padding. arXiv preprint arXiv:1710.09061 (2017).

[24] Sangho Lee, Ming-Wei Shih, Prasun Gera, Taesoo Kim, Hyesoon Kim, and Marcus
Peinado. 2017. Inferring Fine-grained Control Flow Inside SGX Enclaves with
Branch Shadowing. In Proceedings of the 26th USENIX Security Symposium. 557–
574.

[25] G. Lehel and N. Matsakis. 2017. rust-lang RFC: Integer overflows in Rust. online,
accessed 2019-05-10: https://github.com/rust-lang/rfcs/blob/9ef0c35/text/0560-
integer-overflow.md. (2017).

[26] M. Lipp, D. Gruss, R. Spreitzer, C. Maurice, and S. Mangard. 2016. Armageddon:
Cache attacks on mobile devices. In Proceedings of the 25th USENIX Security
Symposium. 549–564.

[27] A. Machiry, E. Gustafson, C. Spensky, C. Salls, N. Stephens, R. Wang, A. Bianchi,
Y. Ryn Choe, C. Kruegel, and G. Vigna. 2017. BOOMERANG: Exploiting the
Semantic Gap in Trusted Execution Environments. In NDSS 2017.

[28] Pieter Maene, Johannes Götzfried, Ruan De Clercq, Tilo Müller, Felix Freiling, and
Ingrid Verbauwhede. 2017. Hardware-Based Trusted Computing Architectures
for Isolation and Attestation. IEEE Trans. Comput. PP, 99 (2017).

[29] Microsoft. 2019. Open Enclave SDK.

online, accessed 2019-05-10: https:

//openenclave.io/sdk/. (2019).

[30] A. Moghimi, J. Wichelmann, T. Eisenbarth, and B. Sunar. 2019. Memjam: A false
dependency attack against constant-time crypto implementations. International
Journal of Parallel Programming 47, 4 (2019), 538–570.

[31] J. Noorman, J. Tobias Mühlberg, and F. Piessens. 2017. Authentic execution of

distributed event-driven applications with a small TCB. In STM. 55–71.

[32] J. Noorman, J. Van Bulck, J. Tobias Mühlberg, F. Piessens, P. Maene, B. Preneel, I.
Verbauwhede, J. Götzfried, T. Müller, and F. Freiling. 2017. Sancus 2.0: A low-cost
security architecture for IoT devices. ACM Transactions on Privacy and Security
(TOPS) 20, 3 (2017), 7:1–7:33.

[33] OP-TEE. 2019. Security Advisories. online, accessed 2019-08-29: https://www.op-

tee.org/security-advisories. (2019).

[49] N. van Ginkel, R. Strackx, and F. Piessens. 2017. Automatically generating
secure wrappers for SGX enclaves from separation logic specifications. In Asian
Symposium on Programming Languages and Systems. 105–123.

[50] N. Weichbrodt, A. Kurmus, P. Pietzuch, and R. Kapitza. 2016. AsyncShock:
Exploiting synchronisation bugs in Intel SGX enclaves. In European Symposium
on Research in Computer Security. 440–457.

[51] S. Weiser, M. Werner, F. Brasser, M. Malenko, S. Mangard, and A.-Reza Sadeghi.
2019. TIMBER-V: Tag-Isolated Memory Bringing Fine-grained Enclaves to RISC-V.
In NDSS 2019.

[52] J. Woodruff, R. NM Watson, D. Chisnall, S. W Moore, J. Anderson, B. Davis, B.
Laurie, P. G Neumann, R. Norton, and M. Roe. 2014. The CHERI capability model:
Revisiting RISC in an age of risk. In ISCA 2014. 457–468.

[53] M. Xu, C. Qian, K. Lu, M. Backes, and T. Kim. 2018. Precise and scalable detection
of double-fetch bugs in OS kernels. In IEEE Symposium on Security and Privacy.
661–678.

[54] Y. Xu, W. Cui, and M. Peinado. 2015. Controlled-channel attacks: Deterministic
side channels for untrusted operating systems. In IEEE Symposium on Security
and Privacy. 640–656.

A VULNERABLE CODE SAMPLES
A.1 OE legacy ecall dispatcher
The (legacy) ecall interface _handle_call_enclave() does not vali-
date that arg_in.args points outside the enclave. While this pointer
is subsequently checked by the oeedger8r-generated entry code,
an error code is still written to the in-enclave memory location on
failure (cf. Listing 2). After our report, the legacy handle_call_encl
ave() dispatcher has been removed completely.

1 static oe_result_t _handle_call_enclave ( uint64_t arg_in ) {
2

oe_call_enclave_args_t args , * args_ptr ;
...
if (! oe_is_outside_enclave (( void *) arg_in ,

OE_RAISE ( OE_INVALID_PARAMETER );

sizeof ( oe_call_enclave_args_t ) ))

args_ptr = ( oe_call_enclave_args_t *) arg_in ;
args = * args_ptr ;
...

9
10 ⭑ func ( args . args );

3

4

5

6

7

8

11

...

Listing 6: https://github.com/Microsoft/OpenEnclave/blob/
93ac313a/enclave/core/sgx/calls.c#L216

A.2 OE built-in attestation ecall
Evidently, a check that validates that arg_in points outside the
enclave was overlooked. We thus can overwrite in-enclave memory
through the write to host_arg->result. Note that the target buffer
has to have a certain size to avoid segfaults in the function _oe_g
et_local_report() that is called within _handle_get_sgx_report()
(this is because the parameter oe_get_sgx_report_args_t is a large
struct). Because of that, _oe_get_local_report() will very likely
fail with the return value OE_INVALID_PARAMETER (0x3) and overwrite
the first four bytes of the memory at host_arg with 0x03000000.

1 oe_result_t _handle_get_sgx_report ( uint64_t arg_in ) {
2

oe_result_t result = OE_UNEXPECTED ;
oe_get_sgx_report_args_t * host_arg =

( oe_get_sgx_report_args_t *) arg_in ;

oe_get_sgx_report_args_t enc_arg ;
size_t report_buffer_size = sizeof ( sgx_report_t );

if ( host_arg == NULL )

OE_RAISE ( OE_INVALID_PARAMETER );

3

4

5

6

7

8

9

10

// Validate and copy args to prevent TOCTOU issues .

11
12 ⭑ enc_arg = * host_arg ;
13

14

15

16

17

OE_CHECK ( _oe_get_local_report ( NULL , 0 ,

( enc_arg . opt_params_size != 0) ? enc_arg . opt_params : NULL ,
enc_arg . opt_params_size , ( uint8_t *) & enc_arg . sgx_report ,
& report_buffer_size ));

18
19 ⭑ * host_arg = enc_arg ;
result = OE_OK ;
20
21 done :
22
23 ⭑
24
25 }

return result ;

if ( host_arg )

host_arg -> result = result ;

Listing 7: https://github.com/microsoft/OpenEnclave/blob/
93ac313a/enclave/core/sgx/report.c#L388

A.3 Asylo ecall entry point
Asylo’s trusted ecall dispatcher is declared in Intel SGX-SDK EDL
specification as follows: public int ecall_dispatch_trusted_cal
l(uint64_t selector, [user_check] void *buffer). However, in
the code below, it becomes apparent that the [user_check] argu-
ment buffer is never properly validated before being unmarshalled.
This issue can most easily be mitigated by properly declaring the
argument buffer using edger8r’s [in] pointer attribute instead of
the problematic [user_check] attribute. Further, the validation logic
at line 16 contains a logic mistake which incorrectly assumes that
outside == ¬inside (cf. Section 5.3).

return asylo :: primitives :: asylo_enclave_call ( selector , buffer );

1 int ecall_dispatch_trusted_call ( uint64_t selector , void * buffer ) {
2
3 }
4
5 int asylo_enclave_call ( uint64_t selector , void * buffer ) {
6

SgxParams * const sgx_params = reinterpret_cast < SgxParams * >(

12

13

14

15
16 ⭑
17

18

19

void * output = nullptr ;
size_t output_size = 0;

if ( input ) {

if ( TrustedPrimitives :: IsTrustedExtent ( input , input_size )) {

PrimitiveStatus status { error :: GoogleError :: INVALID_ARGUMENT ,
" input should lie within untrusted memory ." };
return status . error_code () ;

}

Listing 8: https://github.com/google/asylo/blob/e4810bdbac/
asylo/platform/primitives/sgx/trusted_sgx.cc#L98

A.4 SGX-LKL SIGILL signal handler exploit
SGX-LKL intercepts the SIGILL (undefined instruction) to handle
instructions like rdtsc inside the enclave. In this case, the host exe-
cutes rdtsc and the result is passed back into the enclave through
the enclave’s signal handler interface. In case of SIGILL, an adver-
sary can change the untrusted siginfo argument to point into the
enclave, which will then yield the memory contents at that location
as the 64-bit result of rdtsc, as shown by our PoC. This specific
vulnerability can only be exploited if the target in-enclave memory
starts with 0x04000000 (i.e., siginfo->signum==SIGILL). In addition,
the rdtsc result needs to be outputted back to the untrusted side
(e.g., our PoC simply prints it to the terminal). Note that adversaries
can also use the in-enclave signal handler’s execution itself as a
side-channel. Depending on the contents of the memory pointed to
by siginfo->signum different code paths are taken, so established
side-channel approaches may reconstruct the secret-dependent con-
trol through differences in timing [30], page tables [47, 54], or other
microarchitectural elements [24, 46].

1 void __enclave_signal_handler ( gprsgx_t * regs ,
2

enclave_signal_info_t * siginfo ) {

3

4
5 ⭑
6
7 ⭑
8

9
10 ⭑
11

12

13

14

15

...
int ret ;
switch ( siginfo -> signum ) {
case SIGSEGV :

ret = handle_sigsegv ( regs , siginfo -> arg );
break ;

case SIGILL :

ret = handle_sigill ( regs , siginfo -> arg );
break ;

default :

ret = -1;

}
...

Listing 9: https://github.com/lsds/sgx-lkl/blob/664eb25a/src
/sgx/enclave_signal.c#L17

A.5 Sancus authentic execution stub
Passing a ciphertext pointer argument that points inside the enclave
may unintentionally decrypt enclave memory, potentially leading
to information disclosure. Interestingly, we observed that untrusted
array index arguments were properly sanitized to safeguard against
well-understood buffer overflow vulnerabilities.

1 void SM_ENTRY __sm_handle_input ( uint16_t conn_id ,
2
3 {
4

if ( conn_id >= SM_NUM_INPUTS ) return ;

const void * payload , size_t len )

buffer );

7
8 ⭑ const void * input = sgx_params -> input ;
9 ⭑ size_t input_size = sgx_params -> input_size ;
10 ⭑ sgx_params - > input = nullptr ;
11 ⭑ sgx_params - > input_size = 0;

5

size_t data_len = len - AD_SIZE - SANCUS_TAG_SIZE ;

6
7 ⭑ uint8_t * cipher = ( uint8_t *) payload + AD_SIZE ;
8 ⭑ uint8_t * tag = cipher + data_len ;
9

10

uint8_t * input_buffer = alloca ( data_len );

11
12 ⭑ if ( sancus_unwrap_with_key ( __sm_io_keys [ conn_id ],
13

payload , AD_SIZE , cipher ,
data_len , tag , input_buffer ))

__sm_input_callbacks [ conn_id ]( input_buffer , data_len );

14

15

16

17
18 }

{

}

Listing 10: https://github.com/sancus-pma/sancus-compiler
/blob/5d5cbff/src/stubs/sm_input.c#L7

A.6 OE string ecall edge wrapper
As part of OE’s “deep copy” marshalling scheme, the _handle_call
_enclave_function() from the trusted runtime properly copies the
entire marshalled input buffer into the enclave (including the string
argument and alleged length which are put into the serialized input
_buffer by the untrusted runtime). The oeedger8r bridge then takes
care to redirect all pointers to the marshalled input buffer. However,
when doing so the auto-generated oeedger8r entry code below does
not explicitly null-terminate the untrusted string argument. Hence,
the trusted user function will incorrectly assume that the string
is properly terminated and may perform out-of-bounds memory
read/writes beyond the end of the string.

1 void ecall_my_ecall ( uint8_t * input_buf ,
2

size_t input_buf_size , uint8_t * output_buf ,
size_t output_buf_size , size_t * output_bytes_written )

3
4 {
5

6

7

8

9

10

11

12

13

14

oe_result_t _result = OE_FAILURE ;
/* NOTE : output buf code removed for sake of space */
my_ecall_args_t * pargs_in =( my_ecall_args_t *) input_buf ;
size_t input_buf_offset = 0;

/* Make sure buffers lie within the enclave */
OE_ADD_SIZE ( input_buf_offset , sizeof (* pargs_in ));
if (! input_buf || ! oe_is_within_enclave ( input_buf ,

input_buf_size ))
goto done ;

/* OE_SET_IN_POINTER (s , s_len * sizeof ( char )) */
if ( pargs_in ->s) {

*( uint8_t **) & pargs_in ->s = input_buf + input_buf_offset ;
OE_ADD_SIZE ( input_buf_offset , ( size_t )( s_len * sizeof ( char ) ));
if ( input_buf_offset > input_buf_size ) {

_result = OE_BUFFER_TOO_SMALL ;
goto done ;

}

15

16
17 ⭑
18

19

20

21

22

23

/* lfence after checks */
/* Call user function */

}
oe_lfence () ;

24
25 ⭑ my_ecall ( pargs_in ->s);
26
27 }

...

Listing 11: Proxy function generated by oeedger8r for the
EDL specification: public void my_ecall([in,string] char *s).

A.7 Keystone integer overflow
We discovered a potential vulnerability that originates from an
integer overflow in the detect_region_overlap() function which
is used during the process of creating an enclave. Evidently, there
is no check to guarantee that the integer additions do not over-
flow. Suppose that epm_base=0x82800000 and epm_size=100000. If
one passes addr=0x1 and size=0xffffffffffffffff, there is an over-
lap between both regions. However, when these values are put
into the above condition, this evaluates to “no overlap” (zero). The
above issue was not exploitable at the time of discovery: various
constraints imposed on the size prevented the exploitation of this
issue, but it might have been problematic in the future if the overlap
check was used in different parts of the code.

1 static int detect_region_overlap ( uintptr_t addr , uintptr_t size )
2 {
3
4 ⭑ region_overlap |= (( uintptr_t ) epm_base < addr + size )
5

&& (( uintptr_t ) epm_base + epm_size > addr );

...

6

...

Listing 12: https://github.com/keystone-enclave/riscv-pk/
blob/e24d47c/sm/pmp.c#L71


