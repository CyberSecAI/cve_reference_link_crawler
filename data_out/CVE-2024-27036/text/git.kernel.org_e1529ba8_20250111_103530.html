

| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | David Howells <dhowells@redhat.com> | 2024-02-22 11:20:26 +0000 |
| --- | --- | --- |
| committer | Steve French <stfrench@microsoft.com> | 2024-03-10 19:33:58 -0500 |
| commit | [f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)) | |
| tree | [9b7407faa48195b8cd2d9566a52f3bcefbdbd5be](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c) | |
| parent | [1e5f4240714bb238d2d17c7e14e5fb45c9140665](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=1e5f4240714bb238d2d17c7e14e5fb45c9140665) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c&id2=1e5f4240714bb238d2d17c7e14e5fb45c9140665)) | |
| download | [linux-f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c.tar.gz) | |

cifs: Fix writeback data corruptioncifs writeback doesn't correctly handle the case where
cifs\_extend\_writeback() hits a point where it is considering an additional
folio, but this would overrun the wsize - at which point it drops out of
the xarray scanning loop and calls xas\_pause(). The problem is that
xas\_pause() advances the loop counter - thereby skipping that page.
What needs to happen is for xas\_reset() to be called any time we decide we
don't want to process the page we're looking at, but rather send the
request we are building and start a new one.
Fix this by copying and adapting the netfslib writepages code as a
temporary measure, with cifs writeback intending to be offloaded to
netfslib in the near future.
This also fixes the issue with the use of filemap\_get\_folios\_tag() causing
retry of a bunch of pages which the extender already dealt with.
This can be tested by creating, say, a 64K file somewhere not on cifs
(otherwise copy-offload may get underfoot), mounting a cifs share with a
wsize of 64000, copying the file to it and then comparing the original file
and the copy:
dd if=/dev/urandom of=/tmp/64K bs=64k count=1
mount //192.168.6.1/test /mnt -o user=...,pass=...,wsize=64000
cp /tmp/64K /mnt/64K
cmp /tmp/64K /mnt/64K
Without the fix, the cmp fails at position 64000 (or shortly thereafter).
Fixes: d08089f649a0 ("cifs: Change the I/O paths to use an iterator rather than a page list")
Signed-off-by: David Howells <dhowells@redhat.com>
cc: Steve French <sfrench@samba.org>
cc: Paulo Alcantara <pc@manguebit.com>
cc: Ronnie Sahlberg <ronniesahlberg@gmail.com>
cc: Shyam Prasad N <sprasad@microsoft.com>
cc: Tom Talpey <tom@talpey.com>
cc: Jeff Layton <jlayton@kernel.org>
cc: linux-cifs@vger.kernel.org
cc: samba-technical@lists.samba.org
cc: netfs@lists.linux.dev
cc: linux-fsdevel@vger.kernel.org
Signed-off-by: Steve French <stfrench@microsoft.com>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)

| -rw-r--r-- | [fs/smb/client/file.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/smb/client/file.c?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c) | 283 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 157 insertions, 126 deletions

| diff --git a/fs/smb/client/file.c b/fs/smb/client/file.cindex e5f891e43984d9..41d2985839806e 100644--- a/[fs/smb/client/file.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/smb/client/file.c?id=1e5f4240714bb238d2d17c7e14e5fb45c9140665)+++ b/[fs/smb/client/file.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/smb/client/file.c?id=f3dc1bdb6b0b0693562c7c54a6c28bafa608ba3c)@@ -2625,20 +2625,20 @@ static int cifs\_partialpagewrite(struct page \*page, unsigned from, unsigned to) \* dirty pages if possible, but don't sleep while doing so. \*/ static void cifs\_extend\_writeback(struct address\_space \*mapping,+ struct xa\_state \*xas, long \*\_count, loff\_t start, int max\_pages,- size\_t max\_len,- unsigned int \*\_len)+ loff\_t max\_len,+ size\_t \*\_len) { struct folio\_batch batch; struct folio \*folio;- unsigned int psize, nr\_pages;- size\_t len = \*\_len;- pgoff\_t index = (start + len) / PAGE\_SIZE;+ unsigned int nr\_pages;+ pgoff\_t index = (start + \*\_len) / PAGE\_SIZE;+ size\_t len; bool stop = true; unsigned int i;- XA\_STATE(xas, &mapping->i\_pages, index);  folio\_batch\_init(&batch); @@ -2649,54 +2649,64 @@ static void cifs\_extend\_writeback(struct address\_space \*mapping, \*/ rcu\_read\_lock(); - xas\_for\_each(&xas, folio, ULONG\_MAX) {+ xas\_for\_each(xas, folio, ULONG\_MAX) { stop = true;- if (xas\_retry(&xas, folio))+ if (xas\_retry(xas, folio)) continue; if (xa\_is\_value(folio)) break;- if (folio->index != index)+ if (folio->index != index) {+ xas\_reset(xas); break;+ }+ if (!folio\_try\_get\_rcu(folio)) {- xas\_reset(&xas);+ xas\_reset(xas); continue; } nr\_pages = folio\_nr\_pages(folio);- if (nr\_pages > max\_pages)+ if (nr\_pages > max\_pages) {+ xas\_reset(xas); break;+ }  /\* Has the page moved or been split? \*/- if (unlikely(folio != xas\_reload(&xas))) {+ if (unlikely(folio != xas\_reload(xas))) { folio\_put(folio);+ xas\_reset(xas); break; }  if (!folio\_trylock(folio)) { folio\_put(folio);+ xas\_reset(xas); break; }- if (!folio\_test\_dirty(folio) || folio\_test\_writeback(folio)) {+ if (!folio\_test\_dirty(folio) ||+ folio\_test\_writeback(folio)) { folio\_unlock(folio); folio\_put(folio);+ xas\_reset(xas); break; }  max\_pages -= nr\_pages;- psize = folio\_size(folio);- len += psize;+ len = folio\_size(folio); stop = false;- if (max\_pages <= 0 || len >= max\_len || \*\_count <= 0)- stop = true;  index += nr\_pages;+ \*\_count -= nr\_pages;+ \*\_len += len;+ if (max\_pages <= 0 || \*\_len >= max\_len || \*\_count <= 0)+ stop = true;+ if (!folio\_batch\_add(&batch, folio)) break; if (stop) break; } - if (!stop)- xas\_pause(&xas);+ xas\_pause(xas); rcu\_read\_unlock();  /\* Now, if we obtained any pages, we can shift them to being@@ -2713,16 +2723,12 @@ static void cifs\_extend\_writeback(struct address\_space \*mapping, if (!folio\_clear\_dirty\_for\_io(folio)) WARN\_ON(1); folio\_start\_writeback(folio);-- \*\_count -= folio\_nr\_pages(folio); folio\_unlock(folio); }  folio\_batch\_release(&batch); cond\_resched(); } while (!stop);-- \*\_len = len; }  /\*@@ -2730,8 +2736,10 @@ static void cifs\_extend\_writeback(struct address\_space \*mapping, \*/ static ssize\_t cifs\_write\_back\_from\_locked\_folio(struct address\_space \*mapping, struct writeback\_control \*wbc,+ struct xa\_state \*xas, struct folio \*folio,- loff\_t start, loff\_t end)+ unsigned long long start,+ unsigned long long end) { struct inode \*inode = mapping->host; struct TCP\_Server\_Info \*server;@@ -2740,17 +2748,18 @@ static ssize\_t cifs\_write\_back\_from\_locked\_folio(struct address\_space \*mapping, struct cifs\_credits credits\_on\_stack; struct cifs\_credits \*credits = &credits\_on\_stack; struct cifsFileInfo \*cfile = NULL;- unsigned int xid, wsize, len;- loff\_t i\_size = i\_size\_read(inode);- size\_t max\_len;+ unsigned long long i\_size = i\_size\_read(inode), max\_len;+ unsigned int xid, wsize;+ size\_t len = folio\_size(folio); long count = wbc->nr\_to\_write; int rc;  /\* The folio should be locked, dirty and not undergoing writeback. \*/+ if (!folio\_clear\_dirty\_for\_io(folio))+ WARN\_ON\_ONCE(1); folio\_start\_writeback(folio);  count -= folio\_nr\_pages(folio);- len = folio\_size(folio);  xid = get\_xid(); server = cifs\_pick\_channel(cifs\_sb\_master\_tcon(cifs\_sb)->ses);@@ -2780,9 +2789,10 @@ static ssize\_t cifs\_write\_back\_from\_locked\_folio(struct address\_space \*mapping, wdata->server = server; cfile = NULL; - /\* Find all consecutive lockable dirty pages, stopping when we find a- \* page that is not immediately lockable, is not dirty or is missing,- \* or we reach the end of the range.+ /\* Find all consecutive lockable dirty pages that have contiguous+ \* written regions, stopping when we find a page that is not+ \* immediately lockable, is not dirty or is missing, or we reach the+ \* end of the range. \*/ if (start < i\_size) { /\* Trim the write to the EOF; the extra data is ignored. Also@@ -2802,19 +2812,18 @@ static ssize\_t cifs\_write\_back\_from\_locked\_folio(struct address\_space \*mapping, max\_pages -= folio\_nr\_pages(folio);  if (max\_pages > 0)- cifs\_extend\_writeback(mapping, &count, start,+ cifs\_extend\_writeback(mapping, xas, &count, start, max\_pages, max\_len, &len); }- len = min\_t(loff\_t, len, max\_len); }-- wdata->bytes = len;+ len = min\_t(unsigned long long, len, i\_size - start);  /\* We now have a contiguous set of dirty pages, each with writeback \* set; the first page is still locked at this point, but all the rest \* have been unlocked. \*/ folio\_unlock(folio);+ wdata->bytes = len;  if (start < i\_size) { iov\_iter\_xarray(&wdata->iter, ITER\_SOURCE, &mapping->i\_pages,@@ -2865,102 +2874,118 @@ err\_xid: /\* \* write a region of pages back to the server \*/-static int cifs\_writepages\_region(struct address\_space \*mapping,- struct writeback\_control \*wbc,- loff\_t start, loff\_t end, loff\_t \*\_next)+static ssize\_t cifs\_writepages\_begin(struct address\_space \*mapping,+ struct writeback\_control \*wbc,+ struct xa\_state \*xas,+ unsigned long long \*\_start,+ unsigned long long end) {- struct folio\_batch fbatch;+ struct folio \*folio;+ unsigned long long start = \*\_start;+ ssize\_t ret; int skips = 0; - folio\_batch\_init(&fbatch);- do {- int nr;- pgoff\_t index = start / PAGE\_SIZE;+search\_again:+ /\* Find the first dirty page. \*/+ rcu\_read\_lock(); - nr = filemap\_get\_folios\_tag(mapping, &index, end / PAGE\_SIZE,- PAGECACHE\_TAG\_DIRTY, &fbatch);- if (!nr)+ for (;;) {+ folio = xas\_find\_marked(xas, end / PAGE\_SIZE, PAGECACHE\_TAG\_DIRTY);+ if (xas\_retry(xas, folio) || xa\_is\_value(folio))+ continue;+ if (!folio) break; - for (int i = 0; i < nr; i++) {- ssize\_t ret;- struct folio \*folio = fbatch.folios[i];+ if (!folio\_try\_get\_rcu(folio)) {+ xas\_reset(xas);+ continue;+ } -redo\_folio:- start = folio\_pos(folio); /\* May regress with THPs \*/+ if (unlikely(folio != xas\_reload(xas))) {+ folio\_put(folio);+ xas\_reset(xas);+ continue;+ } - /\* At this point we hold neither the i\_pages lock nor the- \* page lock: the page may be truncated or invalidated- \* (changing page->mapping to NULL), or even swizzled- \* back from swapper\_space to tmpfs file mapping- \*/- if (wbc->sync\_mode != WB\_SYNC\_NONE) {- ret = folio\_lock\_killable(folio);- if (ret < 0)- goto write\_error;- } else {- if (!folio\_trylock(folio))- goto skip\_write;- }+ xas\_pause(xas);+ break;+ }+ rcu\_read\_unlock();+ if (!folio)+ return 0; - if (folio->mapping != mapping ||- !folio\_test\_dirty(folio)) {- start += folio\_size(folio);- folio\_unlock(folio);- continue;- }+ start = folio\_pos(folio); /\* May regress with THPs \*/ - if (folio\_test\_writeback(folio) ||- folio\_test\_fscache(folio)) {- folio\_unlock(folio);- if (wbc->sync\_mode == WB\_SYNC\_NONE)- goto skip\_write;+ /\* At this point we hold neither the i\_pages lock nor the page lock:+ \* the page may be truncated or invalidated (changing page->mapping to+ \* NULL), or even swizzled back from swapper\_space to tmpfs file+ \* mapping+ \*/+lock\_again:+ if (wbc->sync\_mode != WB\_SYNC\_NONE) {+ ret = folio\_lock\_killable(folio);+ if (ret < 0)+ return ret;+ } else {+ if (!folio\_trylock(folio))+ goto search\_again;+ } - folio\_wait\_writeback(folio);+ if (folio->mapping != mapping ||+ !folio\_test\_dirty(folio)) {+ start += folio\_size(folio);+ folio\_unlock(folio);+ goto search\_again;+ }++ if (folio\_test\_writeback(folio) ||+ folio\_test\_fscache(folio)) {+ folio\_unlock(folio);+ if (wbc->sync\_mode != WB\_SYNC\_NONE) {+ folio\_wait\_writeback(folio); #ifdef CONFIG\_CIFS\_FSCACHE- folio\_wait\_fscache(folio);+ folio\_wait\_fscache(folio); #endif- goto redo\_folio;- }-- if (!folio\_clear\_dirty\_for\_io(folio))- /\* We hold the page lock - it should've been dirty. \*/- WARN\_ON(1);-- ret = cifs\_write\_back\_from\_locked\_folio(mapping, wbc, folio, start, end);- if (ret < 0)- goto write\_error;-- start += ret;- continue;--write\_error:- folio\_batch\_release(&fbatch);- \*\_next = start;- return ret;+ goto lock\_again;+ } -skip\_write:- /\*- \* Too many skipped writes, or need to reschedule?- \* Treat it as a write error without an error code.- \*/+ start += folio\_size(folio);+ if (wbc->sync\_mode == WB\_SYNC\_NONE) { if (skips >= 5 || need\_resched()) { ret = 0;- goto write\_error;+ goto out; }-- /\* Otherwise, just skip that folio and go on to the next \*/ skips++;- start += folio\_size(folio);- continue; }+ goto search\_again;+ } - folio\_batch\_release(&fbatch); - cond\_resched();- } while (wbc->nr\_to\_write > 0);+ ret = cifs\_write\_back\_from\_locked\_folio(mapping, wbc, xas, folio, start, end);+out:+ if (ret > 0)+ \*\_start = start + ret;+ return ret;+} - \*\_next = start;- return 0;+/\*+ \* Write a region of pages back to the server+ \*/+static int cifs\_writepages\_region(struct address\_space \*mapping,+ struct writeback\_control \*wbc,+ unsigned long long \*\_start,+ unsigned long long end)+{+ ssize\_t ret;++ XA\_STATE(xas, &mapping->i\_pages, \*\_start / PAGE\_SIZE);++ do {+ ret = cifs\_writepages\_begin(mapping, wbc, &xas, \_start, end);+ if (ret > 0 && wbc->nr\_to\_write > 0)+ cond\_resched();+ } while (ret > 0 && wbc->nr\_to\_write > 0);++ return ret > 0 ? 0 : ret; }  /\*@@ -2969,7 +2994,7 @@ skip\_write: static int cifs\_writepages(struct address\_space \*mapping, struct writeback\_control \*wbc) {- loff\_t start, next;+ loff\_t start, end; int ret;  /\* We have to be careful as we can end up racing with setattr()@@ -2977,28 +3002,34 @@ static int cifs\_writepages(struct address\_space \*mapping, \* to prevent it. \*/ - if (wbc->range\_cyclic) {+ if (wbc->range\_cyclic && mapping->writeback\_index) { start = mapping->writeback\_index \* PAGE\_SIZE;- ret = cifs\_writepages\_region(mapping, wbc, start, LLONG\_MAX, &next);- if (ret == 0) {- mapping->writeback\_index = next / PAGE\_SIZE;- if (start > 0 && wbc->nr\_to\_write > 0) {- ret = cifs\_writepages\_region(mapping, wbc, 0,- start, &next);- if (ret == 0)- mapping->writeback\_index =- next / PAGE\_SIZE;- }+ ret = cifs\_writepages\_region(mapping, wbc, &start, LLONG\_MAX);+ if (ret < 0)+ goto out;++ if (wbc->nr\_to\_write <= 0) {+ mapping->writeback\_index = start / PAGE\_SIZE;+ goto out; }++ start = 0;+ end = mapping->writeback\_index \* PAGE\_SIZE;+ mapping->writeback\_index = 0;+ ret = cifs\_writepages\_region(mapping, wbc, &start, end);+ if (ret == 0)+ mapping->writeback\_index = start / PAGE\_SIZE; } else if (wbc->range\_start == 0 && wbc->range\_end == LLONG\_MAX) {- ret = cifs\_writepages\_region(mapping, wbc, 0, LLONG\_MAX, &next);+ start = 0;+ ret = cifs\_writepages\_region(mapping, wbc, &start, LLONG\_MAX); if (wbc->nr\_to\_write > 0 && ret == 0)- mapping->writeback\_index = next / PAGE\_SIZE;+ mapping->writeback\_index = start / PAGE\_SIZE; } else {- ret = cifs\_writepages\_region(mapping, wbc,- wbc->range\_start, wbc->range\_end, &next);+ start = wbc->range\_start;+ ret = cifs\_writepages\_region(mapping, wbc, &start, wbc->range\_end); } +out: return ret; } |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 10:34:07 +0000

