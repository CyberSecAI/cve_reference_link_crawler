
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fnltk%2Fnltk%2Fissues%2F3266)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fnltk%2Fnltk%2Fissues%2F3266)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fissues_fragments%2Fissue_layout&source=header-repo&source_repo=nltk%2Fnltk)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[nltk](/nltk)
/
**[nltk](/nltk/nltk)**
Public

* [Notifications](/login?return_to=%2Fnltk%2Fnltk) You must be signed in to change notification settings
* [Fork
  2.9k](/login?return_to=%2Fnltk%2Fnltk)
* [Star
   13.8k](/login?return_to=%2Fnltk%2Fnltk)

* [Code](/nltk/nltk)
* [Issues
  255](/nltk/nltk/issues)
* [Pull requests
  28](/nltk/nltk/pulls)
* [Actions](/nltk/nltk/actions)
* [Projects
  0](/nltk/nltk/projects)
* [Wiki](/nltk/nltk/wiki)
* [Security](/nltk/nltk/security)
* [Insights](/nltk/nltk/pulse)

Additional navigation options

* [Code](/nltk/nltk)
* [Issues](/nltk/nltk/issues)
* [Pull requests](/nltk/nltk/pulls)
* [Actions](/nltk/nltk/actions)
* [Projects](/nltk/nltk/projects)
* [Wiki](/nltk/nltk/wiki)
* [Security](/nltk/nltk/security)
* [Insights](/nltk/nltk/pulse)

New issue

**Have a question about this project?** Sign up for a free GitHub account to open an issue and contact its maintainers and the community.

 [Sign up for GitHub](/signup?return_to=%2Fnltk%2Fnltk%2Fissues%2Fnew%2Fchoose)

By clicking ‚ÄúSign up for GitHub‚Äù, you agree to our [terms of service](https://docs.github.com/terms) and
[privacy statement](https://docs.github.com/privacy). We‚Äôll occasionally send you account related emails.

Already on GitHub?
[Sign in](/login?return_to=%2Fnltk%2Fnltk%2Fissues%2Fnew%2Fchoose)
to your account

[Jump to bottom](#issue-comment-box)

# Remote code execution vulnerability in NLTK #3266

Closed

[Dunedan](/Dunedan) opened this issue
Jun 21, 2024
¬∑ 95 comments
 ¬∑ Fixed by [#3290](https://github.com/nltk/nltk/pull/3290)

Closed

# [Remote code execution vulnerability in NLTK](#top) #3266

[Dunedan](/Dunedan) opened this issue
Jun 21, 2024
¬∑ 95 comments
 ¬∑ Fixed by [#3290](https://github.com/nltk/nltk/pull/3290)

Assignees
[![@stevenbird](https://avatars.githubusercontent.com/u/55406?s=40&v=4)](/stevenbird)

Labels
[critical](/nltk/nltk/labels/critical)

## Comments

[![@Dunedan](https://avatars.githubusercontent.com/u/1735355?s=80&u=62062b19fd52f2f7ff24793d8ce164db65b7b2f4&v=4)](/Dunedan)

Copy link

### **[Dunedan](/Dunedan)** commented [Jun 21, 2024](#issue-2366230232)

| The current and earlier versions of NLTK are vulnerable to a remote code execution vulnerability when using the integrated data package download functionality. A man-in-the-middle attacker or an attacker with control over the NLTK data index can force users which use data packages with pickled Python code to download a new version of the package which executes arbitrary code upon unpickling.  Data packages which have been identified to be vulnerable are "averaged\_perceptron\_tagger" and "punkt". For code to be vulnerable it has to download a data package and use functionality in NLTK which causes the data package to be unpickled.  Here is an example of vulnerable code for the "averaged\_perceptron\_tagger" data package:  ``` import nltk nltk.download("averaged_perceptron_tagger") nltk.pos_tag(["hello", "world"]) ```  This vulnerability was reported together with POC code to exploit it multiple times to the NLTK team via the email address mentioned in <SECURITY.md> (and later directly to some maintainers as well). It was reported first on 2024-05-19. So far there has been no response from the NLTK maintainers to these reports.  [#2522](https://github.com/nltk/nltk/issues/2522) already pointed out the security implications of using pickled code a few years ago, but didn't receive a response either. |
| --- |
| The text was updated successfully, but these errors were encountered: |

 üëÄ
12
 DhenPadilla, JensMadsen, juhoinkinen, adivekar-utexas, yogeshmpandey, MichaelMcAleer, vavsab, vladsirenko-gl, yyzhang1005, RobinFrcd, and 2 more reacted with eyes emoji

All reactions

* üëÄ
  12 reactions

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jun 22, 2024](#issuecomment-2183825187)

| [@Dunedan](https://github.com/Dunedan), what would you suggest? Maybe print a warning and ask for confirmation before loading a pickle?  The pickles in question contain Python classes with executable functions. They are not data but programs. And,as a compiled format, they are not ideal for an open-source project.  But an eventual attacker needs to trick the user into loading a malicious pickle. |
| --- |

 üëé
5
 MichaelMcAleer, gessulat, dbIgel, Moe520, and AleFeri reacted with thumbs down emoji

All reactions

* üëé
  5 reactions

Sorry, something went wrong.

[![@Dunedan](https://avatars.githubusercontent.com/u/1735355?s=80&u=62062b19fd52f2f7ff24793d8ce164db65b7b2f4&v=4)](/Dunedan)

Copy link

Author

### **[Dunedan](/Dunedan)** commented [Jun 22, 2024](#issuecomment-2183952498)

| The short answer to solve this issue is to remove the download of code via network at runtime.  If that's not feasible for NLTK I have no clear answer how to solve this issue. However, there are some measures I'd implement, which would at least improve the situation: Remove use of pickled code wherever possible While I haven't checked what the code in in the data packages with pickled code does, I can imagine that it's not the code which is large, but rather data associated with it. Maybe the algorithms implemented in there can be moved into NLTK, removing the need for pickled code.  Also instead of using pickle, a domain-specific format could be used (depending on the use case something like ONNX (<https://onnx.ai/>) might fit for that). Make pickled code reproducible When an update for a data package with pickled code is issued, it's difficult to figure out what changed. Having the pickle files be reproducibly built would be helpful for assessing if they're legit. Make documentation clear for download once during setup While the documentation details various ways to install data packages right now, making it more prominent that data packages should be installed once during installation/setup, instead of including `Downloader.download()` in application code, could be helpful to make users aware of the implications downloading data packages in their application code has. Opt-in for auto-updating installed data packages Right now calling `Downloader().download()` always results in the data index being fetched and potential updates to already installed packages being downloaded and installed. Instead I believe the download functionality should by default only do network requests and install data packages if they're not already installed. Automatic updating could then be an additional parameter users have to explicitly set. Opt-in for installing data packages containing code Similar to having users explicitly opt-in for auto-updates, I'd do the same for downloads of data packages which contain code which is going to be executed.  In addition I'd always log a warning when a package with pickled code gets downloaded or used. Verify downloaded packages Right now the data index contains a checksum per package. However this checksum is only used to check whether a downloaded package differs from a previously downloaded version. It is not used right now to check if a downloaded package is the one referenced by the data index. This should be done together with the move to a cryptographical strong hash function for the checksums. |
| --- |

 üëç
6
 masterbayek, DhenPadilla, smttsp, 4c0n, fjcapdevila, and AleFeri reacted with thumbs up emoji

All reactions

* üëç
  6 reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jun 25, 2024](#issuecomment-2188099247) ‚Ä¢ edited Loading

| Thanks [@Dunedan](https://github.com/Dunedan) for your detailed suggestions.  Should this issue be labelled critical? I wonder if it could make NLTK deemed unsafe for use in schools, or inclusion in some software distributions. But on the other hand, has any exploit been reported since [#2522](https://github.com/nltk/nltk/issues/2522), back in 2020? When nobody else than the administrator controls nltk\_data, the pickles should be safe to load.  It could be nice to remove all the pickles completely, for ex. by moving the code into the classes of the corresponding corpus reader in NLTK, and reducing the data package, for ex. to CSV files for tabular data, and JSON or XML for complex data. |
| --- |

All reactions

Sorry, something went wrong.

[![@Dunedan](https://avatars.githubusercontent.com/u/1735355?s=80&u=62062b19fd52f2f7ff24793d8ce164db65b7b2f4&v=4)](/Dunedan)

Copy link

Author

### **[Dunedan](/Dunedan)** commented [Jun 28, 2024](#issuecomment-2197508142)

| This is now being tracked as [CVE-2024-39705](https://github.com/advisories/GHSA-cgvx-9447-vcch "CVE-2024-39705"). |
| --- |

All reactions

Sorry, something went wrong.

[![@stevenbird](https://avatars.githubusercontent.com/u/55406?s=40&u=cdeece592e934cacc2d86802d9ec0408492b3dca&v=4)](/stevenbird)
[stevenbird](/stevenbird)
self-assigned this
[Jun 28, 2024](#event-13336298536)

[![@stevenbird](https://avatars.githubusercontent.com/u/55406?s=40&u=cdeece592e934cacc2d86802d9ec0408492b3dca&v=4)](/stevenbird)
[stevenbird](/stevenbird)
added
the
[critical](/nltk/nltk/labels/critical)
label
[Jun 28, 2024](#event-13336301874)

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 1, 2024](#issuecomment-2199339541)

| In addition to the two packages already mentioned, the following also contain pickles:   * chunkers/maxent\_ne\_chunker.zip * help/tagsets.zip * taggers/maxent\_treebank\_pos\_tagger.zip   In total nltk\_data contains 52 pickles, where half are Python 2, which is not supported anymore, so these may just be deleted.  Starting at the easy end, the pickles in *help/tagsets.zip* are very easy to decompile, since they are just Python dictionaries that associate each tag symbol with a tuple consisting in the tag name, and a string of instances. This is just tabular data, that would fit very well in the CSV or TAB format. One may wonder what made it seem attractive to compile this data into pickles back then. |
| --- |

 üëç
1
 dbIgel reacted with thumbs up emoji

All reactions

* üëç
  1 reaction

Sorry, something went wrong.

[![@DhenPadilla](https://avatars.githubusercontent.com/u/28548633?s=80&u=ad1f1dc321766ea3260c4214979af7ad2acab630&v=4)](/DhenPadilla)

Copy link

### **[DhenPadilla](/DhenPadilla)** commented [Jul 1, 2024](#issuecomment-2199909171) ‚Ä¢ edited Loading

| Hey team!!!  Thanks for raising this [@Dunedan](https://github.com/Dunedan) and for the insightful thread [@ekaf](https://github.com/ekaf)!  We hit a critical dependabot alert regarding this vulnerability. So I'm now tracking this thread quite closely! I was trying to trace down into its sub dependencies but got super lost with where to be looking in order to verify that these vulnerable data packages are being loaded into our codebase;  Sorry for the silly questions here; but would love to understand this a little more;  A man-in-the-middle attacker or an attacker with control over the NLTK data index can force users which use data packages with pickled Python code to download a new version of the package which executes arbitrary code upon unpickling.   1. This is the first time I've heard of `pickling`! So thank you for raising this and introducing me to this new concept for me.    So, my understanding of the vulnerability here is that the pickled byte-stream can be manipulated before unpickling the content which may include malicious executable code? 2. We're currently using the `LazyCorpusLoader` and we download the `words` package. My understanding here is that the `download()` function is a main vulnerable entry-point here?    To add fuel to this fire; we use this within an AWS lambda function which means we would run a `download` every single run.. making this really open :/ - What's the best work around/fix here for us (if needed)? 3. How can I tell whether the `words` package is a pickled download? Or for a broader question; what's the best way to trace which datasets are prone to this vulnerability? |
| --- |

 üëÄ
1
 masterbayek reacted with eyes emoji

All reactions

* üëÄ
  1 reaction

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 1, 2024](#issuecomment-2200377569)

| ``` #!/bin/sh for f in ~/nltk_data/*/*zip do unzip -l $f | grep -i pickle >> Nltk_Pickles.txt done  ```  [Nltk\_Pickles.txt](https://github.com/user-attachments/files/16054731/Nltk_Pickles.txt) |
| --- |

All reactions

Sorry, something went wrong.

[![@mcepl](https://avatars.githubusercontent.com/u/198999?s=80&u=ef6e6aac164a70cfe57fee79b3a95be1fd38ce16&v=4)](/mcepl)

Copy link

### **[mcepl](/mcepl)** commented [Jul 1, 2024](#issuecomment-2200891883) via email

| On Mon Jul 1, 2024 at 1:35 PM CEST, DhenPadilla wrote: 1. This is the first time I've heard of `pickling`! So thank you for raising this and introducing me to this new concept for me. So, my understanding of the vulnerability here is that the pickled byte-stream can be manipulated before unpickling the content which may include malicious executable code? See <https://docs.python.org/3/library/pickle.html> and big red warning there. Pickle can contain ANY Python data including but not limited to executable functions. So, pickle should NEVER be used for data which are outside of your control. Especially, downloading pickles from Internet carries with itself serious risk of downloading and executing malicious code. |
| --- |

 üëç
2
 smttsp and dbIgel reacted with thumbs up emoji

All reactions

* üëç
  2 reactions

Sorry, something went wrong.

[![@mcepl](https://avatars.githubusercontent.com/u/198999?s=80&u=ef6e6aac164a70cfe57fee79b3a95be1fd38ce16&v=4)](/mcepl)

Copy link

### **[mcepl](/mcepl)** commented [Jul 2, 2024](#issuecomment-2204404662)

| I understand this is just an emergency maintenance brutal workaround, but would anything outside of the downloading stuff from Internet break with this patch?  ``` ---  nltk/app/chartparser_app.py    |   13 +++++++++++++  nltk/corpus/reader/util.py     |    2 ++  nltk/data.py                   |    2 ++  nltk/parse/transitionparser.py |    2 ++  nltk/tbl/demo.py               |    4 +++-  5 files changed, 22 insertions(+), 1 deletion(-)  --- a/nltk/app/chartparser_app.py +++ b/nltk/app/chartparser_app.py @@ -800,6 +800,10 @@ class ChartComparer:              showerror("Error Saving Chart", f"Unable to open file: {filename!r}\n{e}")        def load_chart_dialog(self, *args): +        showerror("Security Error", +                  "Due to gh#nltk/nltk#3266, deserializing from " + +                  "a pickle is forbidden.") +        return          filename = askopenfilename(              filetypes=self.CHART_FILE_TYPES, defaultextension=".pickle"          ) @@ -811,6 +815,8 @@ class ChartComparer:              showerror("Error Loading Chart", f"Unable to open file: {filename!r}\n{e}")        def load_chart(self, filename): +        raise RuntimeError("Due to gh#nltk/nltk#3266, deserializing from " + +                           "a pickle is forbidden.")          with open(filename, "rb") as infile:              chart = pickle.load(infile)          name = os.path.basename(filename) @@ -2268,6 +2274,10 @@ class ChartParserApp:          if not filename:              return          try: +            showerror("Security Error", +                      "Due to gh#nltk/nltk#3266, deserializing from " + +                      "a pickle is forbidden.") +            return              with open(filename, "rb") as infile:                  chart = pickle.load(infile)              self._chart = chart @@ -2306,6 +2316,9 @@ class ChartParserApp:              return          try:              if filename.endswith(".pickle"): +                showerror("Due to gh#nltk/nltk#3266, deserializing from " + +                          "a pickle is forbidden.") +                return                  with open(filename, "rb") as infile:                      grammar = pickle.load(infile)              else: --- a/nltk/corpus/reader/util.py +++ b/nltk/corpus/reader/util.py @@ -521,6 +521,8 @@ class PickleCorpusView(StreamBackedCorpu        def read_block(self, stream):          result = [] +        raise RuntimeError("Due to gh#nltk/nltk#3266, deserializing from " + +                           "a pickle is forbidden.")          for i in range(self.BLOCK_SIZE):              try:                  result.append(pickle.load(stream)) --- a/nltk/data.py +++ b/nltk/data.py @@ -752,6 +752,8 @@ def load(      if format == "raw":          resource_val = opened_resource.read()      elif format == "pickle": +        raise RuntimeError("Due to gh#nltk/nltk#3266, deserializing from " + +                           "a pickle is forbidden.")          resource_val = pickle.load(opened_resource)      elif format == "json":          import json --- a/nltk/parse/transitionparser.py +++ b/nltk/parse/transitionparser.py @@ -553,6 +553,8 @@ class TransitionParser(ParserI):          """          result = []          # First load the model +        raise RuntimeError("Due to gh#nltk/nltk#3266, deserializing from " + +                           "a pickle is forbidden.")          model = pickle.load(open(modelFile, "rb"))          operation = Transition(self._algorithm)   --- a/nltk/tbl/demo.py +++ b/nltk/tbl/demo.py @@ -253,6 +253,8 @@ def postag(                  )              )          with open(cache_baseline_tagger) as print_rules: +            raise RuntimeError("Due to gh#nltk/nltk#3266, deserializing from " + +                               "a pickle is forbidden.")              baseline_tagger = pickle.load(print_rules)              print(f"Reloaded pickled tagger from {cache_baseline_tagger}")      else: @@ -327,7 +329,7 @@ def postag(          with open(serialize_output) as print_rules:              brill_tagger_reloaded = pickle.load(print_rules)          print(f"Reloaded pickled tagger from {serialize_output}") -        taggedtest_reloaded = brill_tagger.tag_sents(testing_data) +        taggedtest_reloaded = brill_tagger_reloaded.tag_sents(testing_data)          if taggedtest == taggedtest_reloaded:              print("Reloaded tagger tried on test set, results identical")          else: ``` |
| --- |

All reactions

Sorry, something went wrong.

[![@cassneal](https://avatars.githubusercontent.com/u/106285572?s=80&v=4)](/cassneal)

Copy link

### **[cassneal](/cassneal)** commented [Jul 3, 2024](#issuecomment-2204859348)

| Hello, is there an ETA for a fix? |
| --- |

 üëç
12
 yogeshmpandey, kkannar-infinitusai, nicolaschaillan, MichaelMcAleer, pepastach, tsdaemon, sandimciin, vavsab, LemonDouble, nithishjv, and 2 more reacted with thumbs up emoji

All reactions

* üëç
  12 reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 3, 2024](#issuecomment-2205581836)

| Before getting too alarmed, we may want to wait for a sober analysis of this vulnerability, bearing in mind that it has been known for several years, without any known exploitation yet.  Still, pickles are not open source, which is in itself a good reason to avoid them. In addition to repackaging the data, a complete fix would require deep modifications in several Python files:  ```  #!/bin/sh  tree=nltk q=pickl of="$tree"_$q.txt echo -n > $of  mxd=`ls -R $tree|grep /|awk -F "/" '{print NF}'|sort -nr|head -1`   for f in `find -L $tree -maxdepth $mxd -name "*py"` do if [ -n "`grep pickle $f`" ] then echo $f >> $of  echo -------------------------------- >> $of grep -ni $q $f >> $of echo \\n--------------------------------------------------------------------- >> $of fi done   ```  [nltk\_pickl.txt](https://github.com/user-attachments/files/16081709/nltk_pickl.txt) |
| --- |

All reactions

Sorry, something went wrong.

[![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=80&u=6665beda6d017e09e4dba8bc07e8235f90017821&v=4)](/nicolaschaillan)

Copy link

### **[nicolaschaillan](/nicolaschaillan)** commented [Jul 3, 2024](#issuecomment-2207373921)

| We really need a fix on this. Lots of customers are fricking out when they see a High CVE finding... Any ETA? |
| --- |

 üëç
5
 mbanon, adumont, smttsp, AleFeri, and smythp reacted with thumbs up emoji

All reactions

* üëç
  5 reactions

Sorry, something went wrong.

[![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=80&u=6665beda6d017e09e4dba8bc07e8235f90017821&v=4)](/nicolaschaillan)

Copy link

### **[nicolaschaillan](/nicolaschaillan)** commented [Jul 3, 2024](#issuecomment-2207412914)

| Before getting too alarmed, we may want to wait for a sober analysis of this vulnerability, bearing in mind that it has been known for several years, without any known exploitation yet.  Still, pickles are not open source, which is in itself a good reason to avoid them. In addition to repackaging the data, a complete fix would require deep modifications in several Python files:  ```  #!/bin/sh  tree=nltk q=pickl of="$tree"_$q.txt echo -n > $of  mxd=`ls -R $tree|grep /|awk -F "/" '{print NF}'|sort -nr|head -1`   for f in `find -L $tree -maxdepth $mxd -name "*py"` do if [ -n "`grep pickle $f`" ] then echo $f >> $of  echo -------------------------------- >> $of grep -ni $q $f >> $of echo \\n--------------------------------------------------------------------- >> $of fi done  ```  [nltk\_pickl.txt](https://github.com/user-attachments/files/16081709/nltk_pickl.txt)  Now that it has a public NIST CVE, people will exploit it. This isn't something you "wait" on. This is something you address right away... |
| --- |

 üëç
10
 MichaelMcAleer, Daethyra, smttsp, gessulat, winlinshell, wadechia, lpi-tn, dbIgel, mbanon, and smythp reacted with thumbs up emoji

All reactions

* üëç
  10 reactions

Sorry, something went wrong.

[![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=80&u=6665beda6d017e09e4dba8bc07e8235f90017821&v=4)](/nicolaschaillan)

Copy link

### **[nicolaschaillan](/nicolaschaillan)** commented [Jul 4, 2024](#issuecomment-2207772018)

| ``` ```diff (testing_data) +        taggedtest_reloaded = brill_tagger_reloaded.tag_sents(testing_data)          if taggedtest == taggedtest_reloaded:              print("Reloaded tagger tried on test set, results identical")          else: ```  Could you share the .patch file by any chance? getting character issues when trying to apply.. |
| --- |

All reactions

Sorry, something went wrong.

[![@adivekar-utexas](https://avatars.githubusercontent.com/u/71379271?s=80&u=25e57725c02dc3adb49156f2faf94d4ff4695e6c&v=4)](/adivekar-utexas)

Copy link

### **[adivekar-utexas](/adivekar-utexas)** commented [Jul 4, 2024](#issuecomment-2208099279) ‚Ä¢ edited Loading

| +1 we need a fix on this...many repos on <https://github.com/amazon-science/> use `nltk` and are affected. |
| --- |

 üëç
1
 smttsp reacted with thumbs up emoji

All reactions

* üëç
  1 reaction

Sorry, something went wrong.

[![@Dunedan](https://avatars.githubusercontent.com/u/1735355?s=80&u=62062b19fd52f2f7ff24793d8ce164db65b7b2f4&v=4)](/Dunedan)

Copy link

Author

### **[Dunedan](/Dunedan)** commented [Jul 4, 2024](#issuecomment-2208159734)

| A possible mitigation is to not use NLTK's downloader functionality to download vulnerable data packages until this issue is fixed. Instead you could download the data packages your application needs manually once, verify they are legit and ship them bundled with your application. |
| --- |

 ‚ù§Ô∏è
2
 adumont and Harvey1976 reacted with heart emoji

All reactions

* ‚ù§Ô∏è
  2 reactions

Sorry, something went wrong.

[![@wallies](https://avatars.githubusercontent.com/u/561860?s=80&u=5c5ee898804d9a7d5cf644191a05e080a3594a29&v=4)](/wallies)

Copy link

### **[wallies](/wallies)** commented [Jul 4, 2024](#issuecomment-2208181098)

| As [@Dunedan](https://github.com/Dunedan) mentioned above. A workaround for now is to consider making your own package index. Considering the package index that is used is <https://github.com/nltk/nltk_data>. You can create your own fork and validate the packages you need and customise the mirror used by using --url |
| --- |

All reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 4, 2024](#issuecomment-2208886910)

| Now that it has a public NIST CVE, people will exploit it. This isn't something you "wait" on. This is something you address right away...  [@nicolaschaillan](https://github.com/nicolaschaillan), before even starting NLTK, you load Python, which already exposes the user to the risk of being tricked into downloading malicious pickles anyway. In that context, wouldn't a fix in NLTK only marginally improve the user's security? |
| --- |

 üëé
4
 smttsp, lucasgadams, dbIgel, and smythp reacted with thumbs down emoji

All reactions

* üëé
  4 reactions

Sorry, something went wrong.

[![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=80&u=6665beda6d017e09e4dba8bc07e8235f90017821&v=4)](/nicolaschaillan)

Copy link

### **[nicolaschaillan](/nicolaschaillan)** commented [Jul 4, 2024](#issuecomment-2208922303)

| Now that it has a public NIST CVE, people will exploit it. This isn't something you "wait" on. This is something you address right away...  [@nicolaschaillan](https://github.com/nicolaschaillan), before even starting NLTK, you load Python, which already exposes the user to the risk of being tricked into downloading malicious pickles anyway. In that context, wouldn't a fix in NLTK only marginally improve the user's security?  this isn't a discussion to see if there are other ways to get into something. Python has no such finding open at this time. This is a discussion to fix this CVE. This feature should be DISABLED unless the administrator explicitly enables it, with a narrow whitelist of resources.  At the end of the day, while I understand this could seem like an "expected behavior" and you can go fight that fight with NVD, you should have an option to enable this with basic ENV variable (disabled by default) or something like this.  Not sure why your contributors are making all this more difficult than it got to be. a CVE is a big deal for enterprises. You AI people seem not to understand cyber 101. |
| --- |

 üëç
6
 Daethyra, smttsp, dbIgel, acompa, dave-v, and smythp reacted with thumbs up emoji

All reactions

* üëç
  6 reactions

Sorry, something went wrong.

[![@adivekar-utexas](https://avatars.githubusercontent.com/u/71379271?s=80&u=25e57725c02dc3adb49156f2faf94d4ff4695e6c&v=4)](/adivekar-utexas)

Copy link

### **[adivekar-utexas](/adivekar-utexas)** commented [Jul 4, 2024](#issuecomment-2208984277) ‚Ä¢ edited Loading

| [@ekaf](https://github.com/ekaf) I agree with [@nicolaschaillan](https://github.com/nicolaschaillan) and let me explain that I've gotten a high-severity ticket (both internally at Amazon and [from GitHub's dependabot](https://github.com/amazon-science/synthesizrr/security/dependabot/6)) because of this vulnerability.  Given the options of (a) not resolving this ticket and (b) removing all dependencies on `nltk` from my codebase, I am **forced** to choose (b), in order to comply with my organization's security requirements. It's either that or take down my repository. |
| --- |

 üëç
8
 tomasz-h2o, MichaelMcAleer, Daethyra, smttsp, sandimciin, gessulat, pinacoelho, and smythp reacted with thumbs up emoji

All reactions

* üëç
  8 reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 4, 2024](#issuecomment-2209270349)

| I inspected a typical pickle in each series, looking at their type() and eventual \_\_dict\_\_.  The *tagsets* and *averaged\_perceptron\_tagger* packages contain only simple data structures, and can easily be translated to a text-based data format, which solves the problem radically.  The rest of the pickles contain complex classes. A good translation may only be possible with help from the original package authors, and would require more time.  So at this moment, users who find themselves in an emergency, and need very strict settings, may need to consider some of the mitigations suggested above, like [forbidding unpickling](https://github.com/nltk/nltk/issues/3266#issuecomment-2204404662), or using [their own secure fork](https://github.com/nltk/nltk/issues/3266#issuecomment-2208181098). |
| --- |

All reactions

Sorry, something went wrong.

[![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=80&u=6665beda6d017e09e4dba8bc07e8235f90017821&v=4)](/nicolaschaillan)

Copy link

### **[nicolaschaillan](/nicolaschaillan)** commented [Jul 4, 2024](#issuecomment-2209283748)

| I inspected a typical pickle in each series, looking at their type() and eventual **dict**.  The *tagsets* and *averaged\_perceptron\_tagger* packages contain only simple data structures, and can easily be translated to a text-based data format, which solves the problem radically.  The rest of the pickles contain complex classes. A good translation may only be possible with help from the original package authors, and would require more time.  So at this moment, users who find themselves in an emergency, and need very strict settings, may need to consider some of the mitigations suggested above, like [forbidding unpickling](https://github.com/nltk/nltk/issues/3266#issuecomment-2204404662), or using [their own secure fork](https://github.com/nltk/nltk/issues/3266#issuecomment-2208181098).  The solution is simple. Whitelist which pickles can be loaded. Give control to the tenant to decide which ones are fine or not. Maybe by name or something. Right now, the fear is that third party can manage to load some that are malicious. |
| --- |

All reactions

Sorry, something went wrong.

[![@mcepl](https://avatars.githubusercontent.com/u/198999?s=80&u=ef6e6aac164a70cfe57fee79b3a95be1fd38ce16&v=4)](/mcepl)

Copy link

### **[mcepl](/mcepl)** commented [Jul 4, 2024](#issuecomment-2209406577) ‚Ä¢ edited Loading

| The solution is simple. Whitelist which pickles can be loaded. Give control to the tenant to decide which ones are fine or not. Maybe by name or something. Right now, the fear is that third party can manage to load some that are malicious.  I don‚Äôt think, that‚Äôs good enough. As long as there is an opportunity how to make NLTK download pickle from the Internet (by using some internal undocumented functions, there are really no private and really inaccessible functions in Python), somebody can make a script to download malicious content from the Internet.  Pickle should really never be used on any content which is not 100% under the control of the admin of the machine. It really is meant to be used only for temporary caching, for serializing Python objects for `multiprocessing`, and similar very internal purposes, never for storage of the live content or even less for its exchange.  That‚Äôs the reason I suggested so [harsh solution as above](https://github.com/nltk/nltk/issues/3266#issuecomment-2204404662). |
| --- |

 üëç
2
 dbIgel and smythp reacted with thumbs up emoji

All reactions

* üëç
  2 reactions

Sorry, something went wrong.

[![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=80&u=6665beda6d017e09e4dba8bc07e8235f90017821&v=4)](/nicolaschaillan)

Copy link

### **[nicolaschaillan](/nicolaschaillan)** commented [Jul 5, 2024](#issuecomment-2209672773)

| The solution is simple. Whitelist which pickles can be loaded. Give control to the tenant to decide which ones are fine or not. Maybe by name or something. Right now, the fear is that third party can manage to load some that are malicious.  I don‚Äôt think, that‚Äôs good enough. As long as there is an opportunity how to make NLTK download pickle from the Internet (by using some internal undocumented functions, there are really no private and really inaccessible functions in Python), somebody can make a script to download malicious content from the Internet.  Pickle should really never be used on any content which is not 100% under the control of the admin of the machine. It really is meant to be used only for temporary caching, for serializing Python objects for `multiprocessing`, and similar very internal purposes, never for storage of the live content or even less for its exchange.  That‚Äôs the reason I suggested so [harsh solution as above](https://github.com/nltk/nltk/issues/3266#issuecomment-2204404662).  To be clear, I was proposing to have a whitelist feature to block the pickle loading function from loading any pickle that wouldn't be whitelisted, that would also solve the internet problem you're mentioning. |
| --- |

All reactions

Sorry, something went wrong.

[![@adivekar-utexas](https://avatars.githubusercontent.com/u/71379271?s=80&u=25e57725c02dc3adb49156f2faf94d4ff4695e6c&v=4)](/adivekar-utexas)

Copy link

### **[adivekar-utexas](/adivekar-utexas)** commented [Jul 5, 2024](#issuecomment-2210158303) ‚Ä¢ edited Loading

| I think whitelist/allowlist is not that useful, since it's a bit cumbersome to maintain. It becomes a file in the user's home directory, which hurts code portability (you need the file everywhere the code is run).  [HuggingFace in 2022 faced a similar remote code execution vulnerability](https://www.youtube.com/watch?v=2ethDz9KnLk). Their solution was in two parts:   1. Add a flag `trust_remote_code=True` at the model/tokenizer level, e.g. `AutoModelForCausalLM.from_pretrained('gpt2-xl', ..., trust_remote_code=True)` 2. Add a `TRUST_REMOTE_CODE` environment variable (defaulting to False), which allowed remote code execution for all modules. [Here is an example](https://huggingface.co/docs/transformers/main/en/model_doc/transfo-xl#transformer-xl)  ---   I feel like (1) is a better long-term fix, but it seems like it could take a while to implement, given the number of modules.  [@ekaf](https://github.com/ekaf) [@stevenbird](https://github.com/stevenbird) does (2) seem like a good idea and doable?  Concrete proposal: A single env variable `TRUST_REMOTE_NLTK_CODE`, which the user must manually enable in their code via `os.environ["TRUST_REMOTE_NLTK_CODE"] = "True"`, prior to calling `nltk` modules.   * If enabled, then module pickles can be downloaded as usual. * If not enabled, then remote code download/execution is blocked, using something like [the patch suggested](https://github.com/nltk/nltk/issues/3266#issuecomment-2204404662) by [@mcepl](https://github.com/mcepl). Already-downloaded code modules should be executable (but maybe you want to introduce a `STRICT_*` flag to control this).   I feel like this is a good solution because it gives users control on when to execute remote code, without changing more than 1 line of code.   * Experimentation code (in Jupyter notebooks) will probably be okay to set `TRUST_REMOTE_NLTK_CODE=True`. * Production code (running in Docker/etc) will probably pre-download the module pickles during the build phase, but run live using `TRUST_REMOTE_NLTK_CODE=False`.   Let me know what you think. |
| --- |

 üéâ
1
 Daethyra reacted with hooray emoji

All reactions

* üéâ
  1 reaction

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 5, 2024](#issuecomment-2210242494)

| [@alvations](https://github.com/alvations), it is great to hear that you believe in the "deep clean" solution, where the pickles are completely removed forever.  There is also excellent news from gpt-4o, suggesting to serialize the more complex data types using Python's *joblib* module: [chatgpt-4o-remedy.txt](https://github.com/user-attachments/files/16105434/chatgpt-4o-remedy.txt) That is much easier than previously believed, and I have verified that the serialization works on the three complex pickle classes used with *puntkt*, *maxent\_ne\_chunker*, and *maxent\_treebank\_pos\_tagger*. We need to verify that adjusted loaders can work as expected with the joblib dumps, and if everything goes well, it seems an ETA is within close reach now. |
| --- |

 üëç
1
 alvations reacted with thumbs up emoji

All reactions

* üëç
  1 reaction

Sorry, something went wrong.

[![@Dunedan](https://avatars.githubusercontent.com/u/1735355?s=80&u=62062b19fd52f2f7ff24793d8ce164db65b7b2f4&v=4)](/Dunedan)

Copy link

Author

### **[Dunedan](/Dunedan)** commented [Jul 5, 2024](#issuecomment-2210253897)

| There is also excellent news from gpt-4o, suggesting to serialize the more complex data types using Python's joblib module  `joblib` uses pickle under the hood as well, so this wouldn't solve the issue. |
| --- |

 üëç
5
 alvations, smttsp, ekaf, mcvincekova, and smythp reacted with thumbs up emoji

All reactions

* üëç
  5 reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Jul 5, 2024](#issuecomment-2210304466) ‚Ä¢ edited Loading

| joblib uses pickle under the hood as well, so this wouldn't solve the issue.  Thanks [@Dunedan](https://github.com/Dunedan)! Instead, there seems to be a possibility to translate the pickles into Protobuf messages, but it may not be the most convenient, so I guess a combination of Json and .py code would be better. |
| --- |

 üëç
2
 alvations and dbIgel reacted with thumbs up emoji

All reactions

* üëç
  2 reactions

Sorry, something went wrong.

74 hidden items

Load more‚Ä¶

[![@dbIgel](https://avatars.githubusercontent.com/u/168823094?s=80&v=4)](/dbIgel)

Copy link

### **[dbIgel](/dbIgel)** commented [Aug 16, 2024](#issuecomment-2293025491)

| The "fix"-release is now 3.9b1, see [#3301 (comment)](https://github.com/nltk/nltk/issues/3301#issuecomment-2292549011) for reference. |
| --- |

All reactions

Sorry, something went wrong.

[![@cbornet](https://avatars.githubusercontent.com/u/11633333?s=80&u=e13817e11b3fb8c3d209d747c77a0f0742d11138&v=4)](/cbornet)

Copy link

### **[cbornet](/cbornet)** commented [Aug 16, 2024](#issuecomment-2293318060)

| The "fix"-release is now 3.9b1, see [#3301 (comment)](https://github.com/nltk/nltk/issues/3301#issuecomment-2292549011) for reference.  Would it be possible to cut a "non-beta" release ? 3.9.0 ? |
| --- |

All reactions

Sorry, something went wrong.

[![@mars-lan](https://avatars.githubusercontent.com/u/24240669?s=40&v=4)](/mars-lan)
[mars-lan](/mars-lan)
mentioned this issue
[Aug 16, 2024](#ref-pullrequest-2470166274)

[Revert "Bump nltk from 3.8.1 to 3.8.2"
MetaphorData/connectors#951](/MetaphorData/connectors/pull/951)
 Merged

[![@stevenbird](https://avatars.githubusercontent.com/u/55406?s=80&u=cdeece592e934cacc2d86802d9ec0408492b3dca&v=4)](/stevenbird)

Copy link

Member

### **[stevenbird](/stevenbird)** commented [Aug 19, 2024](#issuecomment-2295883525)

| Please see 3.9.1 |
| --- |

 üöÄ
3
 cbornet, dbIgel, and AleFeri reacted with rocket emoji

All reactions

* üöÄ
  3 reactions

Sorry, something went wrong.

[![@InterferencePattern](https://avatars.githubusercontent.com/u/692898?s=80&u=0fbb48d65db35ece97ced776e354ed42c12d4af9&v=4)](/InterferencePattern)

Copy link

### **[InterferencePattern](/InterferencePattern)** commented [Aug 19, 2024](#issuecomment-2297051407) ‚Ä¢ edited Loading

| For 3.9.1 to address the NIST CVE, it would mean that the download of unsafe pickles is no longer possible, right? If that's the case, it wouldn't be necessary to start using `nltk.download("punkt_tab")`, right?  `nltk.download("punkt")` should now be pulling `punkt_tab` instead?  I see many projects bumping the version to 3.9.1 *and* changing the downloaded module name to "punkt\_tab" |
| --- |

All reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Aug 19, 2024](#issuecomment-2297523172)

| [@InterferencePattern](https://github.com/InterferencePattern), the package switching is only implemented for the *load()* method. But you need to download('punkt\_tab'). |
| --- |

All reactions

Sorry, something went wrong.

[jombooth](/jombooth)
added a commit
to HumanSignal/label-studio-client-generator
that referenced
this issue
[Aug 20, 2024](#ref-commit-fc11490)
[![@jombooth](https://avatars.githubusercontent.com/u/3943358?s=40&u=96543c6fa50b0fcade66277c1e74e3545cd01486&v=4)](/jombooth)

`[chore: Bump NLTK to ^3.9.1](/HumanSignal/label-studio-client-generator/commit/fc114907b569cf6df103daa3120af62b32b3b213 "chore: Bump NLTK to ^3.9.1

Upgrading the minimum version of NLTK required in the sdk since 3.8.1 is affected by a CVE: https://github.com/nltk/nltk/issues/3266")`
‚Ä¶

`[fc11490](/HumanSignal/label-studio-client-generator/commit/fc114907b569cf6df103daa3120af62b32b3b213)`

```
Upgrading the minimum version of NLTK required in the sdk since 3.8.1 is affected by a CVE: [nltk/nltk#3266](https://github.com/nltk/nltk/issues/3266)
```

[![@jombooth](https://avatars.githubusercontent.com/u/3943358?s=40&u=96543c6fa50b0fcade66277c1e74e3545cd01486&v=4)](/jombooth)
[jombooth](/jombooth)
mentioned this issue
[Aug 20, 2024](#ref-pullrequest-2476306658)

[chore: Bump NLTK to ^3.9.1
HumanSignal/label-studio-client-generator#20](/HumanSignal/label-studio-client-generator/pull/20)
 Merged

[aecio](/aecio)
added a commit
to aecio/valentine
that referenced
this issue
[Aug 20, 2024](#ref-commit-8e59d6c)
[![@aecio](https://avatars.githubusercontent.com/u/150570?s=40&u=4f2228529e20fa69c4dfd2ad694177be58e055b3&v=4)](/aecio)

`[Upgrade to nltk 3.9.1 to address](/aecio/valentine/commit/8e59d6c85509b5256363b8af9a5598f53e625a26 "Upgrade to nltk 3.9.1 to address CVE-2024-39705

The upgrade to nltk to version 3.9.1 is a BREAKING change. This change
downloads `punkt_tab` instead of `punkt` which has a critical security
vulnerability (CVE-2024-39705).
See e.g.:
- https://github.com/advisories/GHSA-cgvx-9447-vcch
- https://github.com/nltk/nltk/issues/3293
- https://github.com/nltk/nltk/issues/3266") [CVE-2024-39705](https://github.com/advisories/GHSA-cgvx-9447-vcch "CVE-2024-39705")`
‚Ä¶

`[8e59d6c](/aecio/valentine/commit/8e59d6c85509b5256363b8af9a5598f53e625a26)`

```
The upgrade to nltk to version 3.9.1 is a BREAKING change. This change
downloads `punkt_tab` instead of `punkt` which has a critical security
vulnerability ([CVE-2024-39705](https://github.com/advisories/GHSA-cgvx-9447-vcch "CVE-2024-39705")).
See e.g.:
- [GHSA-cgvx-9447-vcch](https://github.com/advisories/GHSA-cgvx-9447-vcch "GHSA-cgvx-9447-vcch")
- [nltk/nltk#3293](https://github.com/nltk/nltk/issues/3293)
- [nltk/nltk#3266](https://github.com/nltk/nltk/issues/3266)
```

[![@aecio](https://avatars.githubusercontent.com/u/150570?s=40&u=4f2228529e20fa69c4dfd2ad694177be58e055b3&v=4)](/aecio)
[aecio](/aecio)
mentioned this issue
[Aug 20, 2024](#ref-pullrequest-2476528322)

[Upgrade to nltk 3.9.1 to address CVE-2024-39705
delftdata/valentine#75](/delftdata/valentine/pull/75)
 Merged

[![@cornzz](https://avatars.githubusercontent.com/u/39997278?s=80&u=c9a237f8e50bf5eeb34f0ea7f06da32d0eeb551f&v=4)](/cornzz)

Copy link

### **[cornzz](/cornzz)** commented [Aug 22, 2024](#issuecomment-2304141835) ‚Ä¢ edited Loading

| Hi [@ekaf](https://github.com/ekaf), sorry to ask again but I am unclear on this... if I am simply using [`sent_tokenize()`](https://github.com/nltk/nltk/blob/develop/nltk/tokenize/__init__.py#L109) without explicitly downloading anything, do I have to take action too if I am on 3.8.1? That function also uses the punkt tokenizer but I couldn't quite understand if it also downloads a pickle when initializing the [`PunktTokenizer`](https://github.com/nltk/nltk/blob/develop/nltk/tokenize/punkt.py#L1737) and is therefore affected by this vulnerability...  Also, what do I have to pay attention to when moving to 3.9.1, are there breaking changes? Do I have to change `nltk.download("punkt")`? There are no necessary migration steps outlined on <https://www.nltk.org/news.html>, but it does seem from your last comment I would have to change the call to `nltk.download("punkt_tab")`? It would be helpful to have a migration guide outlining what has to be done moving from 3.8.1 to 3.9.1.  Thanks for all your work |
| --- |

All reactions

Sorry, something went wrong.

[![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=80&u=f1e6f891d38b5e1331822b27be17566212ce4248&v=4)](/ekaf)

Copy link

Contributor

### **[ekaf](/ekaf)** commented [Aug 22, 2024](#issuecomment-2304940298) ‚Ä¢ edited Loading

| Yes [@cornzz](https://github.com/cornzz), sent\_tokenize() used to rely on a pickle, and was thus vulnerable to a potentially lethal attack. So nobody should be on 3.8.1. You need to upgrade to NLTK 3.9.1.  Concerning a migration guide, if you use high-level functions nothing changes, [as shown in these examples](https://github.com/nltk/nltk/pull/3283#issuecomment-2264705572). What changes is that users who want more low-level control, no longer call *load* directly, but now import the corresponding class instead. For examples of that, please have a look at how the switch\_\* functions in *data.py* are called (L818-829) and implemented (L667-731). |
| --- |

 üëç
1
 cornzz reacted with thumbs up emoji

All reactions

* üëç
  1 reaction

Sorry, something went wrong.

[![@nikky78](https://avatars.githubusercontent.com/u/29562101?s=80&v=4)](/nikky78)

Copy link

### **[nikky78](/nikky78)** commented [Aug 23, 2024](#issuecomment-2306954309)

| I would like to use langchain UnstructuredMarkdownLoader like this:  ``` from langchain.document_loaders import UnstructuredMarkdownLoader loader = UnstructuredMarkdownLoader(markdown_path) documents = loader.load()  ```  But I get the error:  ```   Resource punkt_tab not found.   Please use the NLTK Downloader to obtain the resource:  ```  Is there a way with the new version to do nltk.download('punkt\_tab') ? |
| --- |

All reactions

Sorry, something went wrong.

[![@wallies](https://avatars.githubusercontent.com/u/561860?s=80&u=5c5ee898804d9a7d5cf644191a05e080a3594a29&v=4)](/wallies)

Copy link

### **[wallies](/wallies)** commented [Aug 23, 2024](#issuecomment-2307078156)

| I would like to use langchain UnstructuredMarkdownLoader like this:  ``` from langchain.document_loaders import UnstructuredMarkdownLoader loader = UnstructuredMarkdownLoader(markdown_path) documents = loader.load()  ```  But I get the error:  ```   Resource punkt_tab not found.   Please use the NLTK Downloader to obtain the resource:  ```  Is there a way with the new version to do nltk.download('punkt\_tab') ?  [@nikky78](https://github.com/nikky78) Did you get a similar error mentioned here [langchain-ai/langchain#25609](https://github.com/langchain-ai/langchain/issues/25609)  nltk.download('punkt\_tab') should work. |
| --- |

All reactions

Sorry, something went wrong.

[![@nikky78](https://avatars.githubusercontent.com/u/29562101?s=80&v=4)](/nikky78)

Copy link

### **[nikky78](/nikky78)** commented [Aug 23, 2024](#issuecomment-2307281555) ‚Ä¢ edited Loading

| I would like to use langchain UnstructuredMarkdownLoader like this:  ``` from langchain.document_loaders import UnstructuredMarkdownLoader loader = UnstructuredMarkdownLoader(markdown_path) documents = loader.load()  ```  But I get the error:  ```   Resource punkt_tab not found.   Please use the NLTK Downloader to obtain the resource:  ```  Is there a way with the new version to do nltk.download('punkt\_tab') ?  [@nikky78](https://github.com/nikky78) Did you get a similar error mentioned here [langchain-ai/langchain#25609](https://github.com/langchain-ai/langchain/issues/25609)  nltk.download('punkt\_tab') should work.  Indeed, it worked ! thank ^^ |
| --- |

All reactions

Sorry, something went wrong.

[![@jonathangreen](https://avatars.githubusercontent.com/u/569437?s=40&v=4)](/jonathangreen)
[jonathangreen](/jonathangreen)
mentioned this issue
[Aug 26, 2024](#ref-pullrequest-2486926464)

[Bump up NLTK minimum version
sloria/TextBlob#469](/sloria/TextBlob/pull/469)
 Closed

This was referenced Aug 26, 2024

[Fix Groundedness by upgrading and fixing nltk version to >=3.8.2
truera/trulens#1382](/truera/trulens/pull/1382)
 Merged

[Bump nltk version from 3.8.2 to 3.9.1
truera/trulens#1383](/truera/trulens/pull/1383)
 Merged

[More resilient trivial exclusions.
truera/trulens#1384](/truera/trulens/pull/1384)
 Merged

[![@CommodoreEU](https://avatars.githubusercontent.com/u/73301780?s=40&v=4)](/CommodoreEU)
[CommodoreEU](/CommodoreEU)
mentioned this issue
[Aug 27, 2024](#ref-issue-2489168270)

[Custom pipeline failing NLTK download
open-webui/pipelines#240](/open-webui/pipelines/issues/240)

Closed

This was referenced Sep 12, 2024

[Support nltk>=3.9 to fix vulnerability
huggingface/evaluate#628](/huggingface/evaluate/issues/628)

Closed

[Support nltk>=3.9 to fix vulnerability
huggingface/evaluate#629](/huggingface/evaluate/pull/629)
 Merged

[![@petfik](https://avatars.githubusercontent.com/u/28723099?s=80&u=82dc976b7546a422cd9d9751fbbbb092b21f0d29&v=4)](/petfik)

Copy link

### **[petfik](/petfik)** commented [Sep 12, 2024](#issuecomment-2345563578) ‚Ä¢ edited Loading

| Sharing my upgrade from 3.8.1 to 3.9.1, tokenizer use case:  NLTK 3.8.1:  ``` # download data import nltk nltk.download('punkt')  # put pickles to a local folder manually  # at runtime import nltk file_name = f'{NLTK_MODEL_PATH}/{lang}.pickle'  # lang e.g. 'english' tokenizer = nltk.data.load(file_name) tokenizer.tokenize(text) ```  NLTK 3.9.1:  ``` # download data import nltk nltk.download('punkt_tab')  # put the nltk_data folder contents (with folder structure preserved) to a local folder # e.g. local_path/tokenizers/punkt_tab/english/<four files here>  # at runtime import nltk from nltk.tokenize import PunktTokenizer nltk.data.path.append(NLTK_MODEL_PATH) tokenizer = PunktTokenizer(lang)  # lang e.g. 'english' tokenizer.tokenize(text) ``` |
| --- |

All reactions

Sorry, something went wrong.

[![@wallies](https://avatars.githubusercontent.com/u/561860?s=40&u=5c5ee898804d9a7d5cf644191a05e080a3594a29&v=4)](/wallies)
[wallies](/wallies)
mentioned this issue
[Sep 23, 2024](#ref-issue-2504637070)

[[airbyte-cd] upgrade nltk package `>3.8.1`
airbytehq/airbyte#45121](/airbytehq/airbyte/issues/45121)

Closed

[![@guidev](https://avatars.githubusercontent.com/u/1105813?s=40&v=4)](/guidev)
[guidev](/guidev)
mentioned this issue
[Sep 24, 2024](#ref-pullrequest-2486720394)

[Replace deprecated 'punkt' with 'punkt\_tab'
pinecone-io/pinecone-text#83](/pinecone-io/pinecone-text/pull/83)
 Open

7 tasks

[![@ncryptedV1](https://avatars.githubusercontent.com/u/15632467?s=40&v=4)](/ncryptedV1)
[ncryptedV1](/ncryptedV1)
mentioned this issue
[Sep 25, 2024](#ref-pullrequest-2548290071)

[fix: high-severity vulnerability in nltk 3.8.1
sidharthrajaram/StyleTTS2#26](/sidharthrajaram/StyleTTS2/pull/26)
 Open

[![@dayland](https://avatars.githubusercontent.com/u/48474707?s=40&v=4)](/dayland)
[dayland](/dayland)
mentioned this issue
[Oct 8, 2024](#ref-issue-2559135396)

[FileFormRecPollingPDF - An error occurred - code: 200
microsoft/PubSec-Info-Assistant#871](/microsoft/PubSec-Info-Assistant/issues/871)

Closed

[![@agmoore4](https://avatars.githubusercontent.com/u/138518878?s=40&v=4)](/agmoore4)
[agmoore4](/agmoore4)
mentioned this issue
[Oct 24, 2024](#ref-pullrequest-2612238923)

[Requiring nltk>=3.9.1; switch punkt to punkt\_tab
sandialabs/pvOps#102](/sandialabs/pvOps/pull/102)
 Merged

[![@FilippTrigub](https://avatars.githubusercontent.com/u/44036741?s=80&u=6a4706315b6b56f8118ea71264b2ea19e8522494&v=4)](/FilippTrigub)

Copy link

### **[FilippTrigub](/FilippTrigub)** commented [Nov 8, 2024](#issuecomment-2464301981)

| Hello! I've upgrade to 3.9.1, but still cant complete the download. Please suggest, what I might be missing!  [image](https://private-user-images.githubusercontent.com/44036741/384323674-2575d2d2-3a55-4573-a5bb-a175c89010f2.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY1ODIxODksIm5iZiI6MTczNjU4MTg4OSwicGF0aCI6Ii80NDAzNjc0MS8zODQzMjM2NzQtMjU3NWQyZDItM2E1NS00NTczLWE1YmItYTE3NWM4OTAxMGYyLnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTExVDA3NTEyOVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE1NDg3NTNhMzMzYjA5MDdjZmJjYmFlMzUwMjg5OGQ3NzNjNDdjODc1MDlkNWVlOGNjNTg3ZDEwY2JjYWFmY2UmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.s80p3M6nFvviAQvAInC_SeHBFk5WDv1IJiEbXrhM1a4) |
| --- |

All reactions

Sorry, something went wrong.

[![@davidanhip](https://avatars.githubusercontent.com/u/167113915?s=80&v=4)](/davidanhip)

Copy link

### **[davidanhip](/davidanhip)** commented [Nov 13, 2024](#issuecomment-2474175151)

| I'm on version 3.9.1 and I got confused because the .load method was no longer in PerceptronTagger. If the .load method isn't available, should the load=False flag still be supported in the **init**? I'm not sure if there are other use cases, but if calling PerceptronTagger(load=False) results in a class that will never be of use, the load flag should also be removed. |
| --- |

All reactions

Sorry, something went wrong.

[Sign up for free](/join?source=comment-repo)
**to join this conversation on GitHub**.
Already have an account?
[Sign in to comment](/login?return_to=https%3A%2F%2Fgithub.com%2Fnltk%2Fnltk%2Fissues%2F3266)

Assignees

[![@stevenbird](https://avatars.githubusercontent.com/u/55406?s=40&v=4)](/stevenbird) [stevenbird](/stevenbird)

Labels

[critical](/nltk/nltk/labels/critical)

Projects

None yet

Milestone

No milestone

Development

Successfully merging a pull request may close this issue.

 [Prevent data.load from unpickling classes or functions](/nltk/nltk/pull/3290)
 [ekaf/nltk](/ekaf/nltk)

34 participants

[![@digi604](https://avatars.githubusercontent.com/u/25490?s=52&v=4)](/digi604) [![@stevenbird](https://avatars.githubusercontent.com/u/55406?s=52&v=4)](/stevenbird) [![@mcepl](https://avatars.githubusercontent.com/u/198999?s=52&v=4)](/mcepl) [![@acompa](https://avatars.githubusercontent.com/u/272026?s=52&v=4)](/acompa) [![@wallies](https://avatars.githubusercontent.com/u/561860?s=52&v=4)](/wallies) [![@InterferencePattern](https://avatars.githubusercontent.com/u/692898?s=52&v=4)](/InterferencePattern) [![@Dunedan](https://avatars.githubusercontent.com/u/1735355?s=52&v=4)](/Dunedan) [![@chetanpadhye](https://avatars.githubusercontent.com/u/3863994?s=52&v=4)](/chetanpadhye) [![@ekaf](https://avatars.githubusercontent.com/u/4782556?s=52&v=4)](/ekaf) [![@OliverFarren](https://avatars.githubusercontent.com/u/5064282?s=52&v=4)](/OliverFarren) [![@nicolaschaillan](https://avatars.githubusercontent.com/u/5614214?s=52&v=4)](/nicolaschaillan) [![@cbornet](https://avatars.githubusercontent.com/u/11633333?s=52&v=4)](/cbornet) [![@ayushxx7](https://avatars.githubusercontent.com/u/16764027?s=52&v=4)](/ayushxx7) [![@sandimciin](https://avatars.githubusercontent.com/u/17505538?s=52&v=4)](/sandimciin) [![@jdwhitaker](https://avatars.githubusercontent.com/u/18294430?s=52&v=4)](/jdwhitaker) [![@sadra-barikbin](https://avatars.githubusercontent.com/u/22097587?s=52&v=4)](/sadra-barikbin) [![@DhenPadilla](https://avatars.githubusercontent.com/u/28548633?s=52&v=4)](/DhenPadilla) [![@petfik](https://avatars.githubusercontent.com/u/28723099?s=52&v=4)](/petfik) [![@cherylking](https://avatars.githubusercontent.com/u/29436451?s=52&v=4)](/cherylking) [![@nikky78](https://avatars.githubusercontent.com/u/29562101?s=52&v=4)](/nikky78) and others

## Footer

¬© 2025 GitHub,¬†Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can‚Äôt perform that action at this time.

