<!DOCTYPE html>
    <html xmlns="http://www.w3.org/1999/xhtml" lang="en-US"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title>Controlling access with Amazon Data Firehose - Amazon Data Firehose</title><meta name="viewport" content="width=device-width,initial-scale=1" /><meta name="assets_root" content="/assets" /><meta name="target_state" content="controlling-access" /><meta name="default_state" content="controlling-access" /><link rel="icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="shortcut icon" type="image/ico" href="/assets/images/favicon.ico" /><link rel="canonical" href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html" /><meta name="description" content="Control access to and from your Amazon Data Firehose resources by using IAM." /><meta name="deployment_region" content="IAD" /><meta name="product" content="Amazon Data Firehose" /><meta name="guide" content="Developer Guide" /><meta name="abstract" content="This is official Amazon Web Services (AWS) documentation for Amazon Data Firehose. Amazon Data Firehose is the easiest way to load streaming data into AWS. It can capture, transform, and load streaming data into Amazon Managed Service for Apache Flink, Amazon Simple Storage Service (Amazon S3), Amazon Redshift, and Amazon OpenSearch Service, enabling near real-time analytics with existing business intelligence tools and dashboards youâre already using today. Amazon Data Firehose is a fully managed service that automatically scales to match the throughput of your data and requires no ongoing administration. It can also batch, compress, and encrypt the data before loading it, minimizing the amount of storage used at the destination and increasing security. This guide provides a conceptual overview of Amazon Data Firehose and includes detailed instructions for using the service." /><meta name="guide-locale" content="en_us" /><meta name="tocs" content="toc-contents.json" /><link rel="canonical" href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/firehose/latest/dev/controlling-access.html" hreflang="id-id" /><link rel="alternative" href="https://docs.aws.amazon.com/id_id/firehose/latest/dev/controlling-access.html" hreflang="id" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/firehose/latest/dev/controlling-access.html" hreflang="de-de" /><link rel="alternative" href="https://docs.aws.amazon.com/de_de/firehose/latest/dev/controlling-access.html" hreflang="de" /><link rel="alternative" href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html" hreflang="en-us" /><link rel="alternative" href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html" hreflang="en" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/firehose/latest/dev/controlling-access.html" hreflang="es-es" /><link rel="alternative" href="https://docs.aws.amazon.com/es_es/firehose/latest/dev/controlling-access.html" hreflang="es" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/firehose/latest/dev/controlling-access.html" hreflang="fr-fr" /><link rel="alternative" href="https://docs.aws.amazon.com/fr_fr/firehose/latest/dev/controlling-access.html" hreflang="fr" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/firehose/latest/dev/controlling-access.html" hreflang="it-it" /><link rel="alternative" href="https://docs.aws.amazon.com/it_it/firehose/latest/dev/controlling-access.html" hreflang="it" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/firehose/latest/dev/controlling-access.html" hreflang="ja-jp" /><link rel="alternative" href="https://docs.aws.amazon.com/ja_jp/firehose/latest/dev/controlling-access.html" hreflang="ja" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/controlling-access.html" hreflang="ko-kr" /><link rel="alternative" href="https://docs.aws.amazon.com/ko_kr/firehose/latest/dev/controlling-access.html" hreflang="ko" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/firehose/latest/dev/controlling-access.html" hreflang="pt-br" /><link rel="alternative" href="https://docs.aws.amazon.com/pt_br/firehose/latest/dev/controlling-access.html" hreflang="pt" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_cn/firehose/latest/dev/controlling-access.html" hreflang="zh-cn" /><link rel="alternative" href="https://docs.aws.amazon.com/zh_tw/firehose/latest/dev/controlling-access.html" hreflang="zh-tw" /><link rel="alternative" href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html" hreflang="x-default" /><meta name="feedback-item" content="Firehose" /><meta name="this_doc_product" content="Amazon Data Firehose" /><meta name="this_doc_guide" content="Developer Guide" /><script defer="" src="/assets/r/vendor4.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor3.js?version=2021.12.02"></script><script defer="" src="/assets/r/vendor1.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-common.js?version=2021.12.02"></script><script defer="" src="/assets/r/awsdocs-doc-page.js?version=2021.12.02"></script><link href="/assets/r/vendor4.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-common.css?version=2021.12.02" rel="stylesheet" /><link href="/assets/r/awsdocs-doc-page.css?version=2021.12.02" rel="stylesheet" /><script async="" id="awsc-panorama-bundle" type="text/javascript" src="https://prod.pa.cdn.uis.awsstatic.com/panorama-nav-init.js" data-config="{'appEntity':'aws-documentation','region':'us-east-1','service':'firehose'}"></script><meta id="panorama-serviceSubSection" value="Developer Guide" /><meta id="panorama-serviceConsolePage" value="Controlling access with Amazon Data Firehose" /></head><body class="awsdocs awsui"><div class="awsdocs-container"><awsdocs-header></awsdocs-header><awsui-app-layout id="app-layout" class="awsui-util-no-gutters" ng-controller="ContentController as $ctrl" header-selector="awsdocs-header" navigation-hide="false" navigation-width="$ctrl.navWidth" navigation-open="$ctrl.navOpen" navigation-change="$ctrl.onNavChange($event)" tools-hide="$ctrl.hideTools" tools-width="$ctrl.toolsWidth" tools-open="$ctrl.toolsOpen" tools-change="$ctrl.onToolsChange($event)"><div id="guide-toc" dom-region="navigation"><awsdocs-toc></awsdocs-toc></div><div id="main-column" dom-region="content" tabindex="-1"><awsdocs-view class="awsdocs-view"><div id="awsdocs-content"><head><title>Controlling access with Amazon Data Firehose - Amazon Data Firehose</title><meta name="pdf" content="/pdfs/firehose/latest/dev/firehose-dg.pdf#controlling-access" /><meta name="rss" content="akf-release-notes.rss" /><meta name="forums" content="https://repost.aws/tags/TAlzNnJ8YlTgK0QRrL6ikdrg" /><meta name="feedback" content="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Firehose&amp;topic_url=https://docs.aws.amazon.com/en_us/firehose/latest/dev/controlling-access.html" /><meta name="feedback-yes" content="feedbackyes.html?topic_url=https://docs.aws.amazon.com/en_us/firehose/latest/dev/controlling-access.html" /><meta name="feedback-no" content="feedbackno.html?topic_url=https://docs.aws.amazon.com/en_us/firehose/latest/dev/controlling-access.html" /><meta name="keywords" content="Firehose,Amazon Data Firehose,Firehose stream,Firehose streams,AWS,Cloud security,Security Amazon Data Firehose,Amazon Data Firehose Permissions,Controlling access,Private Amazon MSK Cluster permissions,Assume IAM Role,AWS Glue Data Format Conversion,Amazon S3 Destination permissions,Destination permissions,Amazon Redshift permissions,Access Public OpenSearch Service,Splunk VPC,Cross-Account Delivery,VPC flow logs,Flow Log subscription,understand network traffic,diagnosing security group" /><script type="application/ld+json">
{
    "@context" : "https://schema.org",
    "@type" : "BreadcrumbList",
    "itemListElement" : [
      {
        "@type" : "ListItem",
        "position" : 1,
        "name" : "AWS",
        "item" : "https://aws.amazon.com"
      },
      {
        "@type" : "ListItem",
        "position" : 2,
        "name" : "Amazon Data Firehose",
        "item" : "https://docs.aws.amazon.com/firehose/index.html"
      },
      {
        "@type" : "ListItem",
        "position" : 3,
        "name" : "Developer Guide",
        "item" : "https://docs.aws.amazon.com/firehose/latest/dev"
      },
      {
        "@type" : "ListItem",
        "position" : 4,
        "name" : "Security in Amazon Data Firehose",
        "item" : "https://docs.aws.amazon.com/firehose/latest/dev/security.html"
      },
      {
        "@type" : "ListItem",
        "position" : 5,
        "name" : "Controlling access with Amazon Data Firehose",
        "item" : "https://docs.aws.amazon.com/firehose/latest/dev/security.html"
      }
    ]
}
</script></head><body><div id="main"><div style="display: none"><a href="/pdfs/firehose/latest/dev/firehose-dg.pdf#controlling-access" target="_blank" rel="noopener noreferrer" title="Open PDF"></a></div><div id="breadcrumbs" class="breadcrumb"><a href="https://aws.amazon.com">AWS</a><a href="/index.html">Documentation</a><a href="/firehose/index.html">Amazon Data Firehose</a><a href="what-is-this-service.html">Developer Guide</a></div><div id="page-toc-src"><a href="#access-to-firehose">Grant access to your Firehose resources</a><a href="#access-to-msk">Grant Firehose access to your private Amazon MSK cluster</a><a href="#firehose-assume-role">Allow Firehose to assume an IAM role</a><a href="#using-iam-glue">Grant Firehose access to AWS Glue for data format
                conversion</a><a href="#using-iam-s3">Grant Firehose access to an Amazon S3 destination</a><a href="#using-s3-tables">Grant Firehose access to Amazon S3 Tables</a><a href="#using-iam-iceberg">Grant Firehose access to an Apache Iceberg Tables
                destination</a><a href="#using-iam-rs">Grant Firehose access to an Amazon Redshift destination </a><a href="#using-iam-es">Grant Firehose access to a public OpenSearch Service destination</a><a href="#using-iam-es-vpc">Grant Firehose access to an OpenSearch Service destination in a
                VPC</a><a href="#using-iam-serverless">Grant Firehose access to a public OpenSearch
                Serverless destination</a><a href="#using-iam-serverless-vpc">Grant Firehose access to an OpenSearch
                Serverless destination in a VPC</a><a href="#using-iam-splunk">Grant Firehose access to a Splunk destination</a><a href="#using-iam-splunk-vpc">Accessing Splunk in VPC</a><a href="#vpc-splunk-tutorial">Tutorial: Ingest VPC flow logs into Splunk using Amazon Data Firehose</a><a href="#using-snowflake-http-endpoint">Accessing Snowflake or HTTP end
                point</a><a href="#using-iam-snowflake">Grant Firehose access to a Snowflake
                destination</a><a href="#using-iam-snowflake-vpc">Accessing Snowflake in VPC</a><a href="#using-iam-http">Grant Firehose access to an HTTP endpoint
                destination</a><a href="#cross-account-delivery-msk">Cross-account delivery from Amazon MSK</a><a href="#cross-account-delivery-s3">Cross-account delivery to an Amazon S3
                destination</a><a href="#cross-account-delivery-es">Cross-account delivery to an OpenSearch Service
                destination</a><a href="#tag-based-access-control">Using tags to control access</a></div><div id="main-content" class="awsui-util-container"><div id="main-col-body"><awsdocs-language-banner data-service="$ctrl.pageService"></awsdocs-language-banner><h1 class="topictitle" id="controlling-access">Controlling access with Amazon Data Firehose</h1><div class="awsdocs-page-header-container"><awsdocs-page-header></awsdocs-page-header><awsdocs-filter-selector id="awsdocs-filter-selector"></awsdocs-filter-selector></div><p>The following sections cover how to control access to and from your Amazon Data Firehose resources. The
        information they cover includes how to grant your application access so it can send data to
        your Firehose stream. They also describe how you can grant Amazon Data Firehose access to your
        Amazon Simple Storage Service (Amazon S3) bucket, Amazon Redshift cluster, or Amazon OpenSearch Service cluster, as well as the
        access permissions you need if you use Datadog, Dynatrace, LogicMonitor, MongoDB, New Relic,
        Splunk, or Sumo Logic as your destination. Finally, you'll find in this topic guidance on
        how to configure Amazon Data Firehose so it can deliver data to a destination that belongs to a different
        AWS account. The technology for managing all these forms of access is AWS Identity and Access Management (IAM).
        For more information about IAM, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/IAM_Introduction.html">What
            is IAM?</a>.</p><div class="highlights" id="inline-topiclist"><h6>Contents</h6><ul><li><a href="#access-to-firehose">Grant access to your Firehose resources</a></li><li><a href="#access-to-msk">Grant Firehose access to your private Amazon MSK cluster</a></li><li><a href="#firehose-assume-role">Allow Firehose to assume an IAM role</a></li><li><a href="#using-iam-glue">Grant Firehose access to AWS Glue for data format
                conversion</a></li><li><a href="#using-iam-s3">Grant Firehose access to an Amazon S3 destination</a></li><li><a href="#using-s3-tables">Grant Firehose access to Amazon S3 Tables</a></li><li><a href="#using-iam-iceberg">Grant Firehose access to an Apache Iceberg Tables
                destination</a></li><li><a href="#using-iam-rs">Grant Firehose access to an Amazon Redshift destination </a></li><li><a href="#using-iam-es">Grant Firehose access to a public OpenSearch Service destination</a></li><li><a href="#using-iam-es-vpc">Grant Firehose access to an OpenSearch Service destination in a
                VPC</a></li><li><a href="#using-iam-serverless">Grant Firehose access to a public OpenSearch
                Serverless destination</a></li><li><a href="#using-iam-serverless-vpc">Grant Firehose access to an OpenSearch
                Serverless destination in a VPC</a></li><li><a href="#using-iam-splunk">Grant Firehose access to a Splunk destination</a></li><li><a href="#using-iam-splunk-vpc">Accessing Splunk in VPC</a></li><li><a href="#vpc-splunk-tutorial">Ingest VPC flow logs into Splunk using Amazon Data Firehose</a></li><li><a href="#using-snowflake-http-endpoint">Accessing Snowflake or HTTP end
                point</a></li><li><a href="#using-iam-snowflake">Grant Firehose access to a Snowflake
                destination</a></li><li><a href="#using-iam-snowflake-vpc">Accessing Snowflake in VPC</a></li><li><a href="#using-iam-http">Grant Firehose access to an HTTP endpoint
                destination</a></li><li><a href="#cross-account-delivery-msk">Cross-account delivery from Amazon MSK</a></li><li><a href="#cross-account-delivery-s3">Cross-account delivery to an Amazon S3
                destination</a></li><li><a href="#cross-account-delivery-es">Cross-account delivery to an OpenSearch Service
                destination</a></li><li><a href="#tag-based-access-control">Using tags to control access</a></li></ul></div>
        <h2 id="access-to-firehose">Grant access to your Firehose resources</h2>
        <p>To give your application access to your Firehose stream, use a policy similar to
            this example. You can adjust the individual API operations to which you grant access by
            modifying the <code class="code">Action</code> section, or grant access to all operations with
                <code class="code">"firehose:*"</code>.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",
    "Statement": [
        <span>{</span>
            "Effect": "Allow",
            "Action": [
                "firehose:DeleteDeliveryStream",
                "firehose:PutRecord",
                "firehose:PutRecordBatch",
                "firehose:UpdateDestination"
            ],
            "Resource": [
                "arn:aws:firehose:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:deliverystream/<code class="replaceable">delivery-stream-name</code>"
            ]
        }
    ]
}</code></pre>
     
        <h2 id="access-to-msk">Grant Firehose access to your private Amazon MSK cluster</h2>
        <p>If the source of your Firehose stream is a private Amazon MSK cluster, then use a policy similar
            to this example.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
  "Version": "2012-10-17",
  "Statement": [
    <span>{</span>
      "Principal": <span>{</span>
        "Service": [
          "firehose.amazonaws.com"
        ]
    },
    "Effect": "Allow",
    "Action": [
      "kafka:CreateVpcConnection"
    ],
    "Resource": "cluster-arn"
    }
  ]
}</code></pre>
        <p>You must add a policy like this to the cluster's resource-based policy to grant Firehose
            service principal the permission to invoke the Amazon MSK <code class="code">CreateVpcConnection</code>
            API operation.</p>
     
        <h2 id="firehose-assume-role">Allow Firehose to assume an IAM role</h2>

        <p>This section describes the permissions and policies that grant Amazon Data Firehose
            access to ingest, process, and deliver data from source to destination.</p>

        <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>If you use the console to create a Firehose stream and choose the option to create
                a new role, AWS attaches the required trust policy to the role. If you want Amazon Data Firehose
                to use an existing IAM role or if you create a role on your own, attach the
                following trust policies to that role so that Amazon Data Firehose can assume it. Edit the policies
                to replace <code class="replaceable">account-id</code> with your AWS account ID. For
                information about how to modify the trust relationship of a role, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_manage_modify.html">Modifying a Role</a>.</p></div></div>

        <p>Amazon Data Firehose uses an IAM role for all the permissions that the Firehose stream needs to
            process and deliver data. Make sure that the following trust policies are attached to
            that role so that Amazon Data Firehose can assume it.</p>

        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
	"Version": "2012-10-17",
	"Statement": [<span>{</span>
		"Sid": "",
		"Effect": "Allow",
		"Principal": <span>{</span>
			"Service": "firehose.amazonaws.com"
		},
		"Action": "sts:AssumeRole",
		"Condition": <span>{</span>
			"StringEquals": <span>{</span>
				"sts:ExternalId": "account-id"
			}
		}
	}]
}</code></pre>
        <p>This policy uses the <code class="code">sts:ExternalId</code> condition context key to ensure that
            only Amazon Data Firehose activity originating from your AWS account can assume this IAM role. For
            more information about preventing unauthorized use of IAM roles, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html">The confused deputy
                problem</a> in the <em>IAM User Guide</em>.</p>

        <p>If you choose Amazon MSK as the source for your Firehose stream, you must specify
            another IAM role that grants Amazon Data Firehose permissions to ingest source data
            from the specified Amazon MSK cluster. Make sure that the following trust policies
            are attached to that role so that Amazon Data Firehose can assume it.</p>
        
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli ()--><code class="">
<span>{</span>
  "Version": "2012-10-17",
  "Statement": [
    <span>{</span>
      "Principal": <span>{</span>
        "Service": [
          "firehose.amazonaws.com"
        ]
      },
      "Effect": "Allow",
      "Action": "sts:AssumeRole"
    }
  ]
}
        </code></pre>
        
        <p>Make sure that this role that grants Amazon Data Firehose permissions to ingest source data
            from the specified Amazon MSK cluster grants the following permissions: </p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli ()--><code class="">
<span>{</span>
   "Version": "2012-10-17",      
   "Statement": [<span>{</span>
        "Effect":"Allow",
        "Action": [
           "kafka:GetBootstrapBrokers",
           "kafka:DescribeCluster",
           "kafka:DescribeClusterV2",
           "kafka-cluster:Connect"
         ],
         "Resource": "CLUSTER-ARN"
       },
       <span>{</span>
         "Effect":"Allow",
         "Action": [
           "kafka-cluster:DescribeTopic",
           "kafka-cluster:DescribeTopicDynamicConfiguration",
           "kafka-cluster:ReadData"
         ],
         "Resource": "TOPIC-ARN"
       }]
}
        </code></pre>
        
     
        <h2 id="using-iam-glue">Grant Firehose access to AWS Glue for data format
                conversion</h2>
        <p>If your Firehose stream performs data-format conversion, Amazon Data Firehose references table
            definitions stored in AWS Glue. To give Amazon Data Firehose the necessary access to AWS Glue, add the
            following statement to your policy. For information on how to find the ARN of the table,
            see <a href="https://docs.aws.amazon.com/glue/latest/dg/glue-specifying-resource-arns.html">Specifying AWS Glue Resource ARNs</a>.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON ">[<span>{</span>
    "Effect": "Allow",
    "Action": [
        "glue:GetTable",
        "glue:GetTableVersion",
        "glue:GetTableVersions"
    ],
    "Resource": "<code class="replaceable">table-arn</code>"
}, <span>{</span>
    "Sid": "GetSchemaVersion",
    "Effect": "Allow",
    "Action": [
        "glue:GetSchemaVersion"
    ],
    "Resource": ["*"]
}]</code></pre>
        <p>The recommended policy for getting schemas from schema registry has no resource restrictions. For more information, see <a href="https://docs.aws.amazon.com/glue/latest/dg/schema-registry-gs.html#schema-registry-gs1b">IAM examples for deserializers
        </a> in the AWS Glue Developer Guide.</p>
       
     
        <h2 id="using-iam-s3">Grant Firehose access to an Amazon S3 destination</h2>
        <p>When you're using an Amazon S3 destination, Amazon Data Firehose delivers data to your S3 bucket and can
            optionally use an AWS KMS key that you own for data encryption. If error logging is
            enabled, Amazon Data Firehose also sends data delivery errors to your CloudWatch log group and streams. You
            are required to have an IAM role when creating a Firehose stream. Amazon Data Firehose assumes that
            IAM role and gains access to the specified bucket, key, and CloudWatch log group and
            streams.</p>

        <p>Use the following access policy to enable Amazon Data Firehose to access your S3 bucket and AWS KMS
            key. If you don't own the S3 bucket, add <code class="code">s3:PutObjectAcl</code> to the list of
            Amazon S3 actions. This grants the bucket owner full access to the objects delivered by
            Amazon Data Firehose. </p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",  
    "Statement":
    [    
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"		    
            ]    
        },        
        <span>{</span>
            "Effect": "Allow",
            "Action": [
                "kinesis:DescribeStream",
                "kinesis:GetShardIterator",
                "kinesis:GetRecords",
                "kinesis:ListShards"
            ],
            "Resource": "arn:aws:kinesis:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:stream/<code class="replaceable">stream-name</code>"
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:key/<code class="replaceable">key-id</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.<code class="replaceable">region</code>.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket/prefix</code>*"
               }
           }
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:log-group:<code class="replaceable">log-group-name</code>:log-stream:<code class="replaceable">log-stream-name</code>"
           ]
        },
        <span>{</span>
           "Effect": "Allow", 
           "Action": [
               "lambda:InvokeFunction", 
               "lambda:GetFunctionConfiguration" 
           ],
           "Resource": [
               "arn:aws:lambda:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:function:<code class="replaceable">function-name</code>:<code class="replaceable">function-version</code>"
           ]
        }
    ]
}</code></pre>
        <p>The policy above also has a statement that allows access to Amazon Kinesis Data Streams. If you don't
            use Kinesis Data Streams as your data source, you can remove that statement. If you use Amazon MSK as
            your source, then you can substitute that statement with the following:</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli ()--><code class=""><span>{</span>
   "Sid":"",
   "Effect":"Allow",
   "Action":[
      "kafka:GetBootstrapBrokers",
      "kafka:DescribeCluster",
      "kafka:DescribeClusterV2",
      "kafka-cluster:Connect"
   ],
   "Resource":"arn:aws:kafka:<span>{</span><span>{</span>mskClusterRegion}}:<span>{</span><span>{</span>mskClusterAccount}}:cluster/<span>{</span><span>{</span>mskClusterName}}/<span>{</span><span>{</span>clusterUUID}}"
},
<span>{</span>
   "Sid":"",
   "Effect":"Allow",
   "Action":[
      "kafka-cluster:DescribeTopic",
      "kafka-cluster:DescribeTopicDynamicConfiguration",
      "kafka-cluster:ReadData"
   ],
   "Resource":"arn:aws:kafka:<span>{</span><span>{</span>mskClusterRegion}}:<span>{</span><span>{</span>mskClusterAccount}}:topic/<span>{</span><span>{</span>mskClusterName}}/<span>{</span><span>{</span>clusterUUID}}/<span>{</span><span>{</span>mskTopicName}}"
},
<span>{</span>
   "Sid":"",
   "Effect":"Allow",
   "Action":[
      "kafka-cluster:DescribeGroup"
   ],
   "Resource":"arn:aws:kafka:<span>{</span><span>{</span>mskClusterRegion}}:<span>{</span><span>{</span>mskClusterAccount}}:group/<span>{</span><span>{</span>mskClusterName}}/<span>{</span><span>{</span>clusterUUID}}/*"
}</code></pre>
        <p>For more information about allowing other AWS services to access your AWS
            resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating a
                Role to Delegate Permissions to an AWS Service</a> in the
                <em>IAM User Guide</em>.</p>
        <p>To learn how to grant Amazon Data Firehose access to an Amazon S3 destination in another account, see
                <a href="#cross-account-delivery-s3">Cross-account delivery to an Amazon S3
                destination</a>.</p>
     
        <h2 id="using-s3-tables">Grant Firehose access to Amazon S3 Tables</h2>
        <p>You must have an IAM role before you create a Firehose stream. Use the following steps
            to create a policy and an IAM role. Firehose assumes this IAM role and performs the
            required actions. </p>
        <p>Sign in to the AWS Management Console and open the IAM console at <a href="https://console.aws.amazon.com/iam/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/iam/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
        <p>Create a policy and choose <b>JSON</b> in the policy editor. Add the
            following inline policy that grants Amazon S3 permissions such as read/write permissions,
            permissions to update the table in the data catalog, and others. </p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
  "Version": "2012-10-17",
  "Statement": [
    <span>{</span>
      "Sid": "S3TableAccessViaGlueFederation",
      "Effect": "Allow",
      "Action": [
        "glue:GetTable",
        "glue:GetDatabase",
        "glue:UpdateTable"
      ],
      "Resource": [
        "arn:aws:glue:&lt;region&gt;:&lt;account-id&gt;:catalog/s3tablescatalog/*",
        "arn:aws:glue:&lt;region&gt;:&lt;account-id&gt;:catalog/s3tablescatalog",
        "arn:aws:glue:&lt;region&gt;:&lt;account-id&gt;:catalog",
        "arn:aws:glue:&lt;region&gt;:&lt;account-id&gt;:database/*",
        "arn:aws:glue:&lt;region&gt;:&lt;account-id&gt;:table/*/*"
      ]
    },
    <span>{</span>
      "Sid": "S3DeliveryErrorBucketPermission",
      "Effect": "Allow",
      "Action": [
        "s3:AbortMultipartUpload",
        "s3:GetBucketLocation",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:ListBucketMultipartUploads",
        "s3:PutObject"
      ],
      "Resource": [
        "arn:aws:s3:::&lt;error delivery bucket&gt;",
        "arn:aws:s3:::&lt;error delivery bucket&gt;/*"
      ]
    },
    <span>{</span>
      "Sid": "RequiredWhenUsingKinesisDataStreamsAsSource",
      "Effect": "Allow",
      "Action": [
        "kinesis:DescribeStream",
        "kinesis:GetShardIterator",
        "kinesis:GetRecords",
        "kinesis:ListShards"
      ],
      "Resource": "arn:aws:kinesis:&lt;region&gt;:&lt;account-id&gt;:stream/&lt;stream-name&gt;"
    },
    <span>{</span>
      "Sid": "RequiredWhenDoingMetadataReadsANDDataAndMetadataWriteViaLakeformation",
      "Effect": "Allow",
      "Action": [
        "lakeformation:GetDataAccess"
      ],
      "Resource": "*"
    },
    <span>{</span>
      "Sid": "RequiredWhenUsingKMSEncryptionForS3ErrorBucketDelivery",
      "Effect": "Allow",
      "Action": [
        "kms:Decrypt",
        "kms:GenerateDataKey"
      ],
      "Resource": [
        "arn:aws:kms:&lt;region&gt;:&lt;account-id&gt;:key/&lt;KMS-key-id&gt;"
      ],
      "Condition": <span>{</span>
        "StringEquals": <span>{</span>
          "kms:ViaService": "s3.&lt;region&gt;.amazonaws.com"
        },
        "StringLike": <span>{</span>
          "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::&lt;error delivery bucket&gt;/prefix*"
        }
      }
    },
    <span>{</span>
      "Sid": "LoggingInCloudWatch",
      "Effect": "Allow",
      "Action": [
        "logs:PutLogEvents"
      ],
      "Resource": [
        "arn:aws:logs:&lt;region&gt;:&lt;account-id&gt;:log-group:&lt;log-group-name&gt;:log-stream:&lt;log-stream-name&gt;"
      ]
    },
    <span>{</span>
      "Sid": "RequiredWhenAttachingLambdaToFirehose",
      "Effect": "Allow",
      "Action": [
        "lambda:InvokeFunction",
        "lambda:GetFunctionConfiguration"
      ],
      "Resource": [
        "arn:aws:lambda:&lt;region&gt;:&lt;account-id&gt;:function:&lt;function-name&gt;:&lt;function-version&gt;"
      ]
    }
  ]
}</code></pre>
        <p>The policy has statements that allows access to Amazon Kinesis Data Streams, invoking Lambda functions,
            and access to AWS KMS keys. If you don't use any of these resources, you can remove the
            respective statements. If error logging is enabled, Amazon Data Firehose also sends data delivery
            errors to your CloudWatch log group and streams. You must configure log group and log stream
            names to use this option. For log group and log stream names, see (Monitor Amazon Data
            Firehose Using CloudWatch Logs.)(need link).</p>
        <p>In the inline policies, replace <code class="code">&lt;error delivery bucket&gt;</code> with your Amazon S3
            bucket name, <code class="code">aws-account-id</code> and Region with a valid AWS account number
            and Region of the resource. </p>
        <p>After you create the policy, open the IAM console at  <a href="https://console.aws.amazon.com/iam/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/iam/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> and create
            an IAM role with <b>AWS service</b> as the <b>Trusted entity
                type</b>. </p>
        <p>For <b>Service or use case</b>, choose <b>Kinesis</b>. For
                <b>Use case </b>, choose <b>Kinesis Firehose</b>.</p>
        <p>On the next page, choose the policy created in the previous step to attach to this
            role. On the review page, you will find trust policy already attached to this role
            giving permissions to the Firehose service to assume this role. When you create the role,
            Amazon Data Firehose can assume it to perform required operations on AWS Glue and S3 buckets. Add the
            Firehose service principal to the trust policy of the role that is created. For more
            information, see <a href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#firehose-assume-role">Allow Firehose to assume an IAM role</a>.</p>
     
        <h2 id="using-iam-iceberg">Grant Firehose access to an Apache Iceberg Tables
                destination</h2>
        <p>You must have an IAM role before you create a Firehose stream and Apache Iceberg Tables
            using AWS Glue. Use the following steps to create a policy and an IAM role. Firehose assumes
            this IAM role and performs the required actions.</p>
        <div class="procedure"><ol><li>
                <p>Sign in to the AWS Management Console and open the IAM console at <a href="https://console.aws.amazon.com/iam/" rel="noopener noreferrer" target="_blank"><span>https://console.aws.amazon.com/iam/</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>
            </li><li>
                <p>Create a policy and choose <b>JSON</b> in policy editor.</p>
            </li><li>
                <p>Add the following inline policy that grants Amazon S3 permissions like the
                    read/write permissions, permissions to update the table in the data catalog etc. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",  
    "Statement":
    [    
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "glue:GetTable",
                "glue:GetDatabase",
                "glue:UpdateTable"
            ],      
            "Resource": [   
                "arn:aws:glue:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:catalog",
                "arn:aws:glue:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:database/*",
                "arn:aws:glue:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:table/*/*"             
            ]    
        },        
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject",
                "s3:DeleteObject"
            ],      
            "Resource": [   
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"              
            ]    
        },      
        <span>{</span>
            "Effect": "Allow",
            "Action": [
                "kinesis:DescribeStream",
                "kinesis:GetShardIterator",
                "kinesis:GetRecords",
                "kinesis:ListShards"
            ],
            "Resource": "arn:aws:kinesis:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:stream/<code class="replaceable">&lt;stream-name&gt;</code>"
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:key/<code class="replaceable">&lt;key-id&gt;</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/prefix*"
               }
           }
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:log-group:<code class="replaceable">&lt;log-group-name&gt;</code>:log-stream:<code class="replaceable">&lt;log-stream-name&gt;</code>"
           ]
        },
        <span>{</span>
           "Effect": "Allow", 
           "Action": [
               "lambda:InvokeFunction", 
               "lambda:GetFunctionConfiguration" 
           ],
           "Resource": [
               "arn:aws:lambda:<code class="replaceable">&lt;region&gt;:&lt;aws-account-id&gt;</code>:function:<code class="replaceable">&lt;function-name&gt;:&lt;function-version&gt;</code>"
           ]
        }
    ]
}</code></pre>
                <p>This policy has a statement that allows access to Amazon Kinesis Data Streams, invoking Lambda
                    functions,  and access to KMS keys. If you don't use any of these resources,
                    you can remove the respective statements. </p>
                <p>If error logging is enabled, Firehose also sends data delivery errors to your
                    CloudWatch log group and streams. For this you must configure log group and log stream
                    names. For log group and log stream names, see <a href="./monitoring-with-cloudwatch-logs.html">Monitor Amazon Data Firehose Using
                CloudWatch Logs</a>.</p>
            </li><li>
                <p>In the inline policies, replace <code class="replaceable">amzn-s3-demo-bucket</code>
                    with your Amazon S3 bucket name, aws-account-id and Region with a valid AWS account
                    number and Region of the resources. </p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>This role gives permission to all databases and tables in your data
                        catalog. If you want, you can give permissions only to specific tables and
                        databases. </p></div></div>
            </li><li>
                <p>After you create the policy, open the <a href="https://console.aws.amazon.com/iam/" rel="noopener noreferrer" target="_blank"><span>IAM console</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> and create an
                    IAM role with <b>AWS service</b> as the <b>Trusted entity
                        type</b>.</p>
            </li><li>
                <p>For <b>Service or use case</b>, choose
                        <b>Kinesis</b>. For <b>Use case</b> choose
                        <b>Kinesis Firehose</b>. </p>
            </li><li>
                <p>On the next page, choose the policy created in the previous step to attach to
                    this role. On the review page, you will find trust policy already attached to
                    this role giving permissions to Firehose service to assume this role. When you
                    create the role, Amazon Data Firehose can assume it to perform required operations on AWS Glue
                    and S3 buckets.</p>
            </li></ol></div>
     
        <h2 id="using-iam-rs">Grant Firehose access to an Amazon Redshift destination </h2>
        <p>Refer to the following when you are granting access to Amazon Data Firehose when using an Amazon Redshift
            destination.</p>
        <div class="highlights" id="inline-topiclist"><h6>Topics</h6><ul><li><a href="#using-iam-rs-policy">IAM role and access policy</a></li><li><a href="#using-iam-rs-vpc">VPC access to an Amazon Redshift provisioned cluster or
                    Amazon Redshift Serverless workgroup</a></li></ul></div>
         
            <h3 id="using-iam-rs-policy">IAM role and access policy</h3>
            <p>When you're using an Amazon Redshift destination, Amazon Data Firehose delivers data to your S3 bucket
                as an intermediate location. It can optionally use an AWS KMS key you own for data
                encryption. Amazon Data Firehose then loads the data from the S3 bucket to your Amazon Redshift
                provisioned cluster or Amazon Redshift Serverless workgroup. If error logging is enabled, Amazon Data Firehose
                also sends data delivery errors to your CloudWatch log group and streams. Amazon Data Firehose uses the
                specified Amazon Redshift user name and password to access your provisioned cluster or Amazon Redshift
                Serverless workgroup, and uses an IAM role to access the specified bucket, key,
                CloudWatch log group, and streams. You are required to have an IAM role when creating a
                Firehose stream.</p>
            <p>Use the following access policy to enable Amazon Data Firehose to access your S3 bucket and AWS KMS
                key. If you don't own the S3 bucket, add <code class="code">s3:PutObjectAcl</code> to the list of
                Amazon S3 actions, which grants the bucket owner full access to the objects delivered by
                Amazon Data Firehose. This policy also has a statement that allows access to Amazon Kinesis Data Streams. If you
                don't use Kinesis Data Streams as your data source, you can remove that statement.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
"Version": "2012-10-17",  
    "Statement":
    [    
        <span>{</span>      
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"		    
            ]    
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:key/<code class="replaceable">key-id</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.<code class="replaceable">region</code>.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket/prefix</code>*"
               }
           }
        },        
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:stream/<code class="replaceable">stream-name</code>"
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:log-group:<code class="replaceable">log-group-name</code>:log-stream:<code class="replaceable">log-stream-name</code>"
           ]
        },
        <span>{</span>
           "Effect": "Allow", 
           "Action": [
               "lambda:InvokeFunction", 
               "lambda:GetFunctionConfiguration" 
           ],
           "Resource": [
               "arn:aws:lambda:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:function:<code class="replaceable">function-name</code>:<code class="replaceable">function-version</code>"
           ]
        }
    ]
}</code></pre>
            <p>For more information about allowing other AWS services to access your AWS
                resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating
                    a Role to Delegate Permissions to an AWS Service</a> in the
                    <em>IAM User Guide</em>.</p>
         
         
            <h3 id="using-iam-rs-vpc">VPC access to an Amazon Redshift provisioned cluster or
                    Amazon Redshift Serverless workgroup</h3>
            <p>If your Amazon Redshift provisioned cluster or Amazon Redshift Serverless workgroup is in a virtual private
                cloud (VPC), it must be publicly accessible with a public IP address. Also, grant
                Amazon Data Firehose access to your Amazon Redshift provisioned cluster or Amazon Redshift Serverless workgroup by
                unblocking the Amazon Data Firehose IP addresses. Amazon Data Firehose currently uses one CIDR block for
                each available Region.</p>
            
            <div class="table-container"><div class="table-contents"><table id="w80aac33c17c21b9b5"><thead>
                        <tr>
                            <th>Region</th>
                            <th>CIDR blocks</th>
                        </tr>
                    </thead>
                        <tr>
                            <td tabindex="-1">US East (Ohio)</td>
                            <td tabindex="-1">
                                <p><code class="code">13.58.135.96/27</code></p>
                            </td>
                        </tr>
                        <tr>
                            <td tabindex="-1">US East (N. Virginia)</td>
                            <td tabindex="-1"><code class="code">52.70.63.192/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">US West (N. California)</td>
                            <td tabindex="-1"><code class="code">13.57.135.192/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">US West (Oregon)</td>
                            <td tabindex="-1"><code class="code">52.89.255.224/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">AWS GovCloud (US-East)</td>
                            <td tabindex="-1"><code class="code">18.253.138.96/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">AWS GovCloud (US-West)</td>
                            <td tabindex="-1"><code class="code">52.61.204.160/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Canada (Central)</td>
                            <td tabindex="-1"><code class="code">35.183.92.128/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Canada West (Calgary)</td>
                            <td tabindex="-1"><code class="code">40.176.98.192/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Hong Kong)</td>
                            <td tabindex="-1"><code class="code">18.162.221.32/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Mumbai)</td>
                            <td tabindex="-1"><code class="code">13.232.67.32/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Hyderabad)</td>
                            <td tabindex="-1"><code class="code">18.60.192.128/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Seoul)</td>
                            <td tabindex="-1"><code class="code">13.209.1.64/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Singapore)</td>
                            <td tabindex="-1"><code class="code">13.228.64.192/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Sydney)</td>
                            <td tabindex="-1"><code class="code">13.210.67.224/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Jakarta)</td>
                            <td tabindex="-1"><code class="code">108.136.221.64/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Tokyo)</td>
                            <td tabindex="-1"><code class="code">13.113.196.224/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Osaka)</td>
                            <td tabindex="-1"><code class="code">13.208.177.192/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">China (Beijing)</td>
                            <td tabindex="-1"><code class="code">52.81.151.32/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">China (Ningxia)</td>
                            <td tabindex="-1"><code class="code">161.189.23.64/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (Zurich)</td>
                            <td tabindex="-1"><code class="code">16.62.183.32/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (Frankfurt)</td>
                            <td tabindex="-1"><code class="code">35.158.127.160/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (Ireland)</td>
                            <td tabindex="-1"><code class="code">52.19.239.192/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (London)</td>
                            <td tabindex="-1"><code class="code">18.130.1.96/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (Paris)</td>
                            <td tabindex="-1"><code class="code">35.180.1.96/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (Stockholm)</td>
                            <td tabindex="-1"><code class="code">13.53.63.224/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Middle East (Bahrain)</td>
                            <td tabindex="-1"><code class="code">15.185.91.0/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">South America (SÃ£o Paulo)</td>
                            <td tabindex="-1"><code class="code">18.228.1.128/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Europe (Milan)</td>
                            <td tabindex="-1"><code class="code">15.161.135.128/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Africa (Cape Town)</td>
                            <td tabindex="-1"><code class="code">13.244.121.224/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Middle East (UAE)</td>
                            <td tabindex="-1"><code class="code">3.28.159.32/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Israel (Tel Aviv)</td>
                            <td tabindex="-1"><code class="code">51.16.102.0/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Melbourne)</td>
                            <td tabindex="-1"><code class="code">16.50.161.128/27</code></td>
                        </tr>
                        <tr>
                            <td tabindex="-1">Asia Pacific (Malaysia)</td>
                            <td tabindex="-1"><code class="code">43.216.58.0/27</code></td>
                        </tr>
                    </table></div></div>
            <p>For more information about how to unblock IP addresses, see the step <a href="https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-authorize-cluster-access.html">Authorize Access to the
                    Cluster</a> in the <em>Amazon Redshift Getting Started Guide</em> guide. </p>
         
     
        <h2 id="using-iam-es">Grant Firehose access to a public OpenSearch Service destination</h2>
        <p>When you're using an OpenSearch Service destination, Amazon Data Firehose delivers data to your
            OpenSearch Service cluster, and concurrently backs up failed or all documents to your S3
            bucket. If error logging is enabled, Amazon Data Firehose also sends data delivery errors to your CloudWatch
            log group and streams. Amazon Data Firehose uses an IAM role to access the specified OpenSearch
            Service domain, S3 bucket, AWS KMS key, and CloudWatch log group and streams. You are required
            to have an IAM role when creating a Firehose stream.</p>
        <p>Use the following access policy to enable Amazon Data Firehose to access your S3 bucket, OpenSearch
            Service domain, and AWS KMS key. If you do not own the S3 bucket, add
                <code class="code">s3:PutObjectAcl</code> to the list of Amazon S3 actions, which grants the bucket
            owner full access to the objects delivered by Amazon Data Firehose. This policy also has a statement
            that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your data source, you can
            remove that statement.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",  
    "Statement": [    
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"
            ]    
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:key/<code class="replaceable">key-id</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.<code class="replaceable">region</code>.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket/prefix</code>*"
               }
           }
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "es:DescribeDomain",
               "es:DescribeDomains",
               "es:DescribeDomainConfig",
               "es:ESHttpPost",
               "es:ESHttpPut"
           ],
          "Resource": [
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/*"
          ]
       },
       <span>{</span>
          "Effect": "Allow",
          "Action": [
              "es:ESHttpGet"
          ],
          "Resource": [
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/_all/_settings",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/_cluster/stats",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/<code class="replaceable">index-name</code>*/_mapping/<code class="replaceable">type-name</code>",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/_nodes",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/_nodes/stats",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/_nodes/*/stats",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/_stats",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/<code class="replaceable">index-name</code>*/_stats",
              "arn:aws:es:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:domain/<code class="replaceable">domain-name</code>/"
          ]
       },        
       <span>{</span>
          "Effect": "Allow",
          "Action": [
              "kinesis:DescribeStream",
              "kinesis:GetShardIterator",
              "kinesis:GetRecords",
              "kinesis:ListShards"
          ],
          "Resource": "arn:aws:kinesis:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:stream/<code class="replaceable">stream-name</code>"
       },
       <span>{</span>
          "Effect": "Allow",
          "Action": [
              "logs:PutLogEvents"
          ],
          "Resource": [
              "arn:aws:logs:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:log-group:<code class="replaceable">log-group-name</code>:log-stream:<code class="replaceable">log-stream-name</code>"
          ]
       },
       <span>{</span>
          "Effect": "Allow", 
          "Action": [
              "lambda:InvokeFunction", 
              "lambda:GetFunctionConfiguration" 
          ],
          "Resource": [
              "arn:aws:lambda:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:function:<code class="replaceable">function-name</code>:<code class="replaceable">function-version</code>"
          ]
       }
    ]
}</code></pre>
        <p>For more information about allowing other AWS services to access your AWS
            resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating a
                Role to Delegate Permissions to an AWS Service</a> in the
                <em>IAM User Guide</em>.</p>
        <p>To learn how to grant Amazon Data Firehose access to an OpenSearch Service cluster in another
            account, see <a href="#cross-account-delivery-es">Cross-account delivery to an OpenSearch Service
                destination</a>.</p>
     
        <h2 id="using-iam-es-vpc">Grant Firehose access to an OpenSearch Service destination in a
                VPC</h2>
        <p>If your OpenSearch Service domain is in a VPC, make sure you give Amazon Data Firehose the
            permissions that are described in the previous section. In addition, you need to give
            Amazon Data Firehose the following permissions to enable it to access your OpenSearch Service domain's
            VPC.</p>
        <div class="itemizedlist">
             
             
             
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><code class="code">ec2:DescribeVpcs</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeVpcAttribute</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeSubnets</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeSecurityGroups</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeNetworkInterfaces</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:CreateNetworkInterface</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:CreateNetworkInterfacePermission</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DeleteNetworkInterface</code></p>
            </li></ul></div>


       
        
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Do not revoke these permissions after you create the Firehose stream. If you revoke these
                permissions, your Firehose stream will be degraded or stop delivering data to your
                OpenSearch service domain whenever the service attempts to query or update
                ENIs.</p></div></div> 
            
            
            
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>When you specify subnets for delivering data to the destination in a private VPC, make sure you have enough number 
            of free IP addresses in chosen subnets. If there is no available free IP address in a specified subnet, Firehose cannot create or 
            add ENIs for the data delivery in the private VPC, and the delivery will be degraded or fail.
            
        </p></div></div>
        
        
        <p>When you create or update your Firehose stream, you specify a security group for Firehose to
            use when it sends data to your OpenSearch Service domain. You can use the same security
            group that the OpenSearch Service domain uses or a different one. If you specify a
            different security group, ensure that it allows outbound HTTPS traffic to the OpenSearch
            Service domain's security group. Also ensure that the OpenSearch Service domain's
            security group allows HTTPS traffic from the security group you specified when you
            configured your Firehose stream. If you use the same security group for both your Firehose stream
            and the OpenSearch Service domain, make sure the security group inbound rule allows
            HTTPS traffic. For more information about security group rules, see <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules">Security group rules</a> in the Amazon VPC documentation.</p>
     
        <h2 id="using-iam-serverless">Grant Firehose access to a public OpenSearch
                Serverless destination</h2>
        <p>When you're using an OpenSearch Serverless destination, Amazon Data Firehose delivers data to your
            OpenSearch Serverless collection, and concurrently backs up failed or all documents to
            your S3 bucket. If error logging is enabled, Amazon Data Firehose also sends data delivery errors to
            your CloudWatch log group and streams. Amazon Data Firehose uses an IAM role to access the specified
            OpenSearch Serverless collection, S3 bucket, AWS KMS key, and CloudWatch log group and streams.
            You are required to have an IAM role when creating a Firehose stream.</p>
        <p>Use the following access policy to enable Amazon Data Firehose to access your S3 bucket, OpenSearch
            Serverless domain, and AWS KMS key. If you do not own the S3 bucket, add
                <code class="code">s3:PutObjectAcl</code> to the list of Amazon S3 actions, which grants the bucket
            owner full access to the objects delivered by Amazon Data Firehose. This policy also has a statement
            that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your data source, you can
            remove that statement.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",  
    "Statement": [    
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"		    
            ]    
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:key/<code class="replaceable">key-id</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.<code class="replaceable">region</code>.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket/prefix</code>*"
               }
           }
        },    
       <span>{</span>
          "Effect": "Allow",
          "Action": [
              "kinesis:DescribeStream",
              "kinesis:GetShardIterator",
              "kinesis:GetRecords",
              "kinesis:ListShards"
          ],
          "Resource": "arn:aws:kinesis:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:stream/<code class="replaceable">stream-name</code>"
       },
       <span>{</span>
          "Effect": "Allow",
          "Action": [
              "logs:PutLogEvents"
          ],
          "Resource": [
              "arn:aws:logs:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:log-group:<code class="replaceable">log-group-name</code>:log-stream:<code class="replaceable">log-stream-name</code>"
          ]
       },
       <span>{</span>
          "Effect": "Allow", 
          "Action": [
              "lambda:InvokeFunction", 
              "lambda:GetFunctionConfiguration" 
          ],
          "Resource": [
              "arn:aws:lambda:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:function:<code class="replaceable">function-name</code>:<code class="replaceable">function-version</code>"
          ]
       },
       <span>{</span>
        "Effect": "Allow",
        "Action": "aoss:APIAccessAll",
        "Resource": "arn:aws:aoss:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:collection/<code class="replaceable">collection-id</code>"
      }
    ]
}</code></pre>
        <p>In addition to the policy above, you must also configure Amazon Data Firehose to have
            the following minimum permissions assigned in a data access policy:</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli ()--><code class="nohighlight">
[
   <span>{</span>
      "Rules":[
         <span>{</span>
            "ResourceType":"index",
            "Resource":[
               "index/target-collection/target-index"
            ],
            "Permission":[
               "aoss:WriteDocument",
               "aoss:UpdateIndex",
               "aoss:CreateIndex"
            ]
         }
      ],
      "Principal":[
         "arn:aws:sts::<code class="replaceable">account-id</code>:assumed-role/<code class="replaceable">firehose-delivery-role-name</code>/*"
      ]
   }
] </code></pre>
        <p>For more information about allowing other AWS services to access your AWS
            resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating a
                Role to Delegate Permissions to an AWS Service</a> in the
                <em>IAM User Guide</em>.</p>
     
        <h2 id="using-iam-serverless-vpc">Grant Firehose access to an OpenSearch
                Serverless destination in a VPC</h2>
        <p>If your OpenSearch Serverless collection is in a VPC, make sure you give Amazon Data Firehose the
            permissions that are described in the previous section. In addition, you need to give
            Amazon Data Firehose the following permissions to enable it to access your OpenSearch Serverless
            collection's VPC.</p>
        <div class="itemizedlist">
             
             
             
             
             
             
             
             
        <ul class="itemizedlist"><li class="listitem">
                <p><code class="code">ec2:DescribeVpcs</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeVpcAttribute</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeSubnets</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeSecurityGroups</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DescribeNetworkInterfaces</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:CreateNetworkInterface</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:CreateNetworkInterfacePermission</code></p>
            </li><li class="listitem">
                <p><code class="code">ec2:DeleteNetworkInterface</code></p>
            </li></ul></div>


     
        
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Do not revoke these permissions after you create the Firehose stream. If you revoke these
                permissions, your Firehose stream will be degraded or stop delivering data to your
                OpenSearch service domain whenever the service attempts to query or update
                ENIs.</p></div></div> 
        
        
        
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>When you specify subnets for delivering data to the destination in a private VPC, make sure you have enough number 
            of free IP addresses in chosen subnets. If there is no available free IP address in a specified subnet, Firehose cannot create or 
            add ENIs for the data delivery in the private VPC, and the delivery will be degraded or fail.
            
        </p></div></div>
        <p>When you create or update your Firehose stream, you specify a security group for Firehose to
            use when it sends data to your OpenSearch Serverless collection. You can use the same
            security group that the OpenSearch Serverless collection uses or a different one. If you
            specify a different security group, ensure that it allows outbound HTTPS traffic to the
            OpenSearch Serverless collection's security group. Also ensure that the OpenSearch
            Serverless collection's security group allows HTTPS traffic from the security group you
            specified when you configured your Firehose stream. If you use the same security group for
            both your Firehose stream and the OpenSearch Serverless collection, make sure the security
            group inbound rule allows HTTPS traffic. For more information about security group
            rules, see <a href="https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules">Security group rules</a> in the Amazon VPC documentation.</p>
     
        <h2 id="using-iam-splunk">Grant Firehose access to a Splunk destination</h2>
        <p>When you're using a Splunk destination, Amazon Data Firehose delivers data to your Splunk HTTP Event
            Collector (HEC) endpoint. It also backs up that data to the Amazon S3 bucket that you
            specify, and you can optionally use an AWS KMS key that you own for Amazon S3 server-side

            encryption. If error logging is enabled, Firehose sends data delivery errors to your CloudWatch
            log streams. You can also use AWS Lambda for data transformation.</p>
        <p>If you use an AWS load balancer, make sure that it is a Classic Load Balancer or an Application Load Balancer. Also, enable duration-based sticky sessions with
            cookie expiration disabled for Classic Load Balancer and expiration is set to the maximum (7 days) for Application Load Balancer. For information about how to do this, see Duration-Based Session Stickiness 
            for <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html#enable-sticky-sessions-duration">Classic Load Balancer</a> or  
            an <a href="https://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html">Application Load Balancer</a>.</p>
        
        <p>You must have an IAM role when you create a Firehose stream. Firehose assumes that IAM
            role and gains access to the specified bucket, key, and CloudWatch log group and
            streams.</p>
        <p>Use the following access policy to enable Amazon Data Firehose to access your S3 bucket. If you don't
            own the S3 bucket, add <code class="code">s3:PutObjectAcl</code> to the list of Amazon S3 actions, which
            grants the bucket owner full access to the objects delivered by Amazon Data Firehose. This policy also
            grants Amazon Data Firehose access to CloudWatch for error logging and to AWS Lambda for data transformation.
            The policy also has a statement that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams
            as your data source, you can remove that statement. Amazon Data Firehose doesn't use IAM to access
            Splunk. For accessing Splunk, it uses your HEC token.</p>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",  
    "Statement":
    [    
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"		    
            ]     
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:key/<code class="replaceable">key-id</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.<code class="replaceable">region</code>.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket/prefix</code>*"
               }
           }
        },     
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:stream/<code class="replaceable">stream-name</code>"
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:log-group:<code class="replaceable">log-group-name</code>:log-stream:*"
           ]
        },
        <span>{</span>
           "Effect": "Allow", 
           "Action": [
               "lambda:InvokeFunction", 
               "lambda:GetFunctionConfiguration" 
           ],
           "Resource": [
               "arn:aws:lambda:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:function:<code class="replaceable">function-name</code>:<code class="replaceable">function-version</code>"
           ]
        }
    ]
}</code></pre>
        <p>For more information about allowing other AWS services to access your AWS
            resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating a
                Role to Delegate Permissions to an AWS Service</a> in the
                <em>IAM User Guide</em>.</p>
     
        <h2 id="using-iam-splunk-vpc">Accessing Splunk in VPC</h2>

        <p>If your Splunk platform is in a VPC, it must be publicly accessible with a public IP
            address. Also, grant Amazon Data Firehose access to your Splunk platform by unblocking the Amazon Data Firehose IP
            addresses. Amazon Data Firehose currently uses the following CIDR blocks.</p>
        
        <div class="table-container"><div class="table-contents"><table id="w80aac33c17c33b5"><thead>
                    <tr>
                        <th>Region</th>
                        <th>CIDR blocks</th>
                        
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">US East (Ohio)</td>
                        <td tabindex="-1">
                            <p><code class="code">18.216.68.160/27, 18.216.170.64/27,
                                18.216.170.96/27</code>\</p>
                        </td>
                        
                    </tr>
                    <tr>
                        <td tabindex="-1">US East (N. Virginia)</td>
                        <td tabindex="-1"><code class="code">34.238.188.128/26, 34.238.188.192/26,
                            34.238.195.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">US West (N. California)</td>
                        <td tabindex="-1"><code class="code">13.57.180.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">US West (Oregon)</td>
                        <td tabindex="-1"><code class="code">34.216.24.32/27, 34.216.24.192/27,
                            34.216.24.224/27</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">AWS GovCloud (US-East)</td>
                        <td tabindex="-1"><code class="code">18.253.138.192/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">AWS GovCloud (US-West)</td>
                        <td tabindex="-1"><code class="code">52.61.204.192/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Hong Kong)</td>
                        <td tabindex="-1"><code class="code">18.162.221.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Mumbai)</td>
                        <td tabindex="-1"><code class="code">13.232.67.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Seoul)</td>
                        <td tabindex="-1"><code class="code">13.209.71.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Singapore)</td>
                        <td tabindex="-1"><code class="code">13.229.187.128/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Sydney)</td>
                        <td tabindex="-1"><code class="code">13.211.12.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Tokyo)</td>
                        <td tabindex="-1"><code class="code">13.230.21.0/27, 13.230.21.32/27</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Canada (Central)</td>
                        <td tabindex="-1"><code class="code">35.183.92.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Canada West (Calgary)</td>
                        <td tabindex="-1"><code class="code">40.176.98.128/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Frankfurt)</td>
                        <td tabindex="-1"><code class="code">18.194.95.192/27, 18.194.95.224/27,
                            18.195.48.0/27</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Ireland)</td>
                        <td tabindex="-1"><code class="code">34.241.197.32/27, 34.241.197.64/27,
                            34.241.197.96/27</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (London)</td>
                        <td tabindex="-1"><code class="code">18.130.91.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Paris)</td>
                        <td tabindex="-1"><code class="code">35.180.112.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Spain)</td>
                        <td tabindex="-1"><code class="code">18.100.194.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Stockholm)</td>
                        <td tabindex="-1"><code class="code">13.53.191.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Middle East (Bahrain)</td>
                        <td tabindex="-1"><code class="code">15.185.91.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">South America (SÃ£o Paulo)</td>
                        <td tabindex="-1"><code class="code">18.228.1.192/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Milan)</td>
                        <td tabindex="-1"><code class="code">15.161.135.192/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Africa (Cape Town)</td>
                        <td tabindex="-1"><code class="code">13.244.165.128/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Osaka)</td>
                        <td tabindex="-1"><code class="code">13.208.217.0/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">China (Beijing)</td>
                        <td tabindex="-1"><code class="code">52.81.151.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">China (Ningxia)</td>
                        <td tabindex="-1"><code class="code">161.189.23.128/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Jakarta)</td>
                        <td tabindex="-1"><code class="code">108.136.221.128/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Middle East (UAE)</td>
                        <td tabindex="-1"><code class="code">3.28.159.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Israel (Tel Aviv)</td>
                        <td tabindex="-1"><code class="code">51.16.102.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Zurich)</td>
                        <td tabindex="-1"><code class="code">16.62.183.64/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Hyderabad)</td>
                        <td tabindex="-1"><code class="code">18.60.192.192/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Melbourne)</td>
                        <td tabindex="-1"><code class="code">16.50.161.192/26</code></td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Malaysia)</td>
                        <td tabindex="-1"><code class="code">43.216.44.192/26</code></td>
                    </tr>
                </table></div></div>
        
     
    <h2 id="vpc-splunk-tutorial">Ingest VPC flow logs into Splunk using Amazon Data Firehose</h2>
    <p>To learn more about how to create a VPC flow log subscription, publish to Firehose, and send
        the VPC flow logs to a supported destination see <a href="https://www.splunk.com/en_us/blog/partners/streamline-your-amazon-vpc-flow-logs-ingestion-to-splunk.html" rel="noopener noreferrer" target="_blank"><span>Ingest VPC flow logs into Splunk using Amazon Data Firehose</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a>.</p>


 
        <h2 id="using-snowflake-http-endpoint">Accessing Snowflake or HTTP end
                point</h2>
        
        <p>There is no subset of <a href="https://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html">AWS IP address ranges</a>
            specific to Amazon Data Firehose when the destination is HTTP end point or Snowflake public
            clusters. </p>
        <p>To add Firehose to an allow list for public Snowflake clusters or to your public HTTP or
            HTTPS endpoints, add all the current <a href="https://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html">AWS IP address ranges</a> to
            your ingress rules. </p>
        <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>Notifications aren't always sourced from IP addresses in the same AWS Region as
                their associated topic. You must include the AWS IP address range for all
                Regions.</p></div></div>
        <p> </p>
     
        <h2 id="using-iam-snowflake">Grant Firehose access to a Snowflake
                destination</h2>
        <p>When you're using Snowflake as a destination, Firehose delivers data to a Snowflake account using your Snowflake account URL. It also backs up 
            error data to the Amazon Simple Storage Service bucket that you specify, and you can optionally use an AWS Key Management Service key that you own for Amazon S3 server-side encryption. 
            If error logging is enabled, Firehose sends data delivery errors to your CloudWatch Logs streams.</p>
        
        <p>You must have an IAM role before you create a Firehose stream. Firehose assumes that IAM role
            and gains access to the specified bucket, key, and CloudWatch Logs group and streams. Use the
            following access policy to enable Firehose to access your S3 bucket. If you don't own the
            S3 bucket, add <code class="code">s3:PutObjectAcl</code> to the list of Amazon Simple Storage Service actions, which
            grants the bucket owner full access to the objects delivered by Firehose. This policy also
            grants Firehose access to CloudWatch for error logging. The policy also has a statement that
            allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your data source, you can remove
            that statement. Firehose doesn't use IAM to access Snowflake. For accessing Snowflake, it
            uses your Snowflake account Url and PrivateLink Vpce Id in the case of a private
            cluster. </p>
<pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (json)--><code class="json "><span>{</span>
"Version": "2012-10-17",  
    "Statement":
    [    
        <span>{</span>
"Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"            
            ]     
        },
        <span>{</span>
"Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"           
           ],
           "Condition": <span>{</span>
"StringEquals": <span>{</span>
"kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": <span>{</span>
"kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/prefix*"
               }
           }
        },     
        <span>{</span>
"Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
        },
        <span>{</span>
"Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:*"
           ]
        }
    ]
}</code></pre>
        <p>For more information about allowing other AWS services to access your AWS resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating a Role to Delegate Permissions to an AWS Service</a>
            in the <em>IAM User Guide</em>.</p>
     
        <h2 id="using-iam-snowflake-vpc">Accessing Snowflake in VPC</h2>
        <p>If your Snowflake cluster is private link enabled, Firehose will use one of the following
            VPC endpoints at time of private link creation to deliver data to your private cluster
            without going through public internet. For this, create Snowflake network rules to allow
            ingress from the following <code class="code">AwsVpceIds</code> for the AWS Region your cluster is
            in. For more information, see <a href="https://docs.snowflake.com/en/sql-reference/sql/create-network-rule" rel="noopener noreferrer" target="_blank"><span>Creating
                network rule</span><awsui-icon class="awsdocs-link-icon" name="external"></awsui-icon></a> in <em>Snowflake User Guide</em>. </p>
      
        <div class="table-container"><div class="table-contents"><table id="w80aac33c17c41b5"><caption>VPC Endpoint Ids to use based on Regions your cluster is in</caption><thead>
                    <tr>
                        <th>AWS Region</th>
                        <th><code class="code">VPCE IDs</code></th>
                    </tr>
                </thead>
                    <tr>
                        <td tabindex="-1">US East (Ohio)</td>
                        <td tabindex="-1">
                            <p>vpce-0d96cafcd96a50aeb</p>
                            <p>vpce-0cec34343d48f537b</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">US East (N. Virginia)</td>
                        <td tabindex="-1">
                            <p>vpce-0b4d7e8478e141ba8</p>
                            <p>vpce-0b75cd681fb507352</p>
                            <p>vpce-01c03e63820ec00d8</p>
                            <p>vpce-0c2cfc51dc2882422</p>
                            <p>vpce-06ca862f019e4e056</p>
                            <p>vpce-020cda0cfa63f8d1c</p>
                            <p>vpce-0b80504a1a783cd70</p>
                            <p>vpce-0289b9ff0b5259a96</p>
                            <p>vpce-0d7add8628bd69a12</p>
                            <p>vpce-02bfb5966cc59b2af</p>
                            <p>vpce-09e707674af878bf2</p>
                            <p>vpce-049b52e96cc1a2165</p>
                            <p>vpce-0bb6c7b7a8a86cdbb</p>
                            <p>vpce-03b22d599f51e80f3</p>
                            <p>vpce-01d60dc60fc106fe1</p>
                            <p>vpce-0186d20a4b24ecbef</p>
                            <p>vpce-0533906401a36e416</p>
                            <p>vpce-05111fb13d396710e</p>
                            <p>vpce-0694613f4fbd6f514</p>
                            <p>vpce-09b21cb25fe4cc4f4</p>
                            <p>vpce-06029c3550e4d2399</p>
                            <p>vpce-00961862a21b033da</p>
                            <p>vpce-01620b9ae33273587</p>
                            <p>vpce-078cf4ec226880ac9</p>
                            <p>vpce-0d711bf076ce56381</p>
                            <p>vpce-066b7e13cbfca6f6e</p>
                            <p>vpce-0674541252d9ccc26</p>
                            <p>vpce-03540b88dedb4b000</p>
                            <p>vpce-0b1828e79ad394b95</p>
                            <p>vpce-0dc0e6f001fb1a60d</p>
                            <p>vpce-0d8f82e71a244098a</p>
                            <p>vpce-00e374d9e3f1af5ce</p>
                            <p>vpce-0c1e3d6631ddb442f</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">US West (Oregon)</td>
                        <td tabindex="-1">
                            <p>vpce-0f60f72da4cd1e4e7</p>
                            <p>vpce-0c60d21eb8b1669fd</p>
                            <p>vpce-01c4e3e29afdafbef</p>
                            <p>vpce-0cc6bf2a88da139de</p>
                            <p>vpce-0797e08e169e50662</p>
                            <p>vpce-033cbe480381b5c0e</p>
                            <p>vpce-00debbdd8f9eb10a5</p>
                            <p>vpce-08ec2f386c809e889</p>
                            <p>vpce-0856d14310857b545</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Frankfurt)</td>
                        <td tabindex="-1">
                            <p>vpce-068dbb7d71c9460fb</p>
                            <p>vpce-0a7a7f095942d4ec9</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Ireland)</td>
                        <td tabindex="-1">
                            <p>vpce-06857e59c005a6276</p>
                            <p>vpce-04390f4f8778b75f2</p>
                            <p>vpce-011fd2b1f0aa172fd</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Tokyo)</td>
                        <td tabindex="-1">
                            <p>vpce-06369e5258144e68a</p>
                            <p>vpce-0f2363cdb8926fbe8</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Singapore)</td>
                        <td tabindex="-1">
                            <p>vpce-049cd46cce7a12d52</p>
                            <p>vpce-0e8965a1a4bdb8941</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Seoul)</td>
                        <td tabindex="-1">
                            <p>vpce-0aa444d9001e1faa1</p>
                            <p>vpce-04a49d4dcfd02b884</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Sydney)</td>
                        <td tabindex="-1">
                            <p>vpce-048a60a182c52be63</p>
                            <p>vpce-03c19949787fd1859</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Mumbai)</td>
                        <td tabindex="-1">
                            <p>vpce-0d68cb822f6f0db68</p> 
                            <p>vpce-0517d32692ffcbde2</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (London)</td>
                        <td tabindex="-1">
                            <p>vpce-0fd1874a0ba3b9374</p>
                            <p>vpce-08091b1a85e206029</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">South America (Sao Paulo)</td>
                        <td tabindex="-1">
                            <p>vpce-065169b8144e4f12e</p>
                            <p>vpce-0493699f0e5762d63</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Canada (Central)</td>
                        <td tabindex="-1">
                            <p>vpce-07e6ed81689d5271f</p>
                            <p>vpce-0f53239730541394c</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Paris)</td>
                        <td tabindex="-1">
                            <p>vpce-09419680077e6488a</p>
                            <p>vpce-0ea81ba2c08140c14</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Osaka)</td>
                        <td tabindex="-1">
                            <p>vpce-0a9f003e6a7e38c05</p>
                            <p>vpce-02886510b897b1c5a</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Europe (Stockholm)</td>
                        <td tabindex="-1">
                            <p>vpce-0d96410833219025a</p>
                            <p>vpce-060a32f9a75ba969f</p>
                        </td>
                    </tr>
                    <tr>
                        <td tabindex="-1">Asia Pacific (Jakarta)</td>
                        <td tabindex="-1">
                            <p>vpce-00add4b9a25e5c649</p>
                            <p>vpce-004ae2de34338a856</p>
                        </td>
                    </tr>
                   
                </table></div></div>
    
     
        <h2 id="using-iam-http">Grant Firehose access to an HTTP endpoint
                destination</h2>

        <p>You can use Amazon Data Firehose to deliver data to any HTTP endpoint destination. Amazon Data Firehose also backs
            up that data to the Amazon S3 bucket that you specify, and you can optionally use an AWS KMS
            key that you own for Amazon S3 server-side encryption. If error logging is enabled, Amazon Data Firehose
            sends data delivery errors to your CloudWatch log streams. You can also use AWS Lambda for data
            transformation. </p>
        <p>You are required to have an IAM role when creating a Firehose stream. Amazon Data Firehose assumes
            that IAM role and gains access to the specified bucket, key, and CloudWatch log group and
            streams.</p>
        <p>Use the following access policy to enable Amazon Data Firehose to access the S3 bucket that you
            specified for data backup. If you don't own the S3 bucket, add
                <code class="code">s3:PutObjectAcl</code> to the list of Amazon S3 actions, which grants the bucket
            owner full access to the objects delivered by Amazon Data Firehose. This policy also grants Amazon Data Firehose
            access to CloudWatch for error logging and to AWS Lambda for data transformation. The policy
            also has a statement that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your
            data source, you can remove that statement. </p>
        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Amazon Data Firehose doesn't use IAM to access HTTP endpoint destinations owned by supported
                third-party service providers, including Datadog, Dynatrace, LogicMonitor, MongoDB,
                New Relic, Splunk, or Sumo Logic. For accessing a specified HTTP endpoint
                destination owned by a supported third-party service provider, contact that service
                provider to obtain the API key or the access key that is required to enable data
                delivery to that service from Amazon Data Firehose.</p></div></div>
        <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",  
    "Statement":
    [    
        <span>{</span>      
            "Effect": "Allow",      
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],      
            "Resource": [        
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"		    
            ]     
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:key/<code class="replaceable">key-id</code>"           
           ],
           "Condition": <span>{</span>
               "StringEquals": <span>{</span>
                   "kms:ViaService": "s3.<code class="replaceable">region</code>.amazonaws.com"
               },
               "StringLike": <span>{</span>
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket/prefix</code>*"
               }
           }
        },     
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:stream/<code class="replaceable">stream-name</code>"
        },
        <span>{</span>
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:log-group:<code class="replaceable">log-group-name</code>:log-stream:*"
           ]
        },
        <span>{</span>
           "Effect": "Allow", 
           "Action": [
               "lambda:InvokeFunction", 
               "lambda:GetFunctionConfiguration" 
           ],
           "Resource": [
               "arn:aws:lambda:<code class="replaceable">region</code>:<code class="replaceable">account-id</code>:function:<code class="replaceable">function-name</code>:<code class="replaceable">function-version</code>"
           ]
        }
    ]
}</code></pre>
        <p>For more information about allowing other AWS services to access your AWS
            resources, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html">Creating a
                Role to Delegate Permissions to an AWS Service</a> in the
                <em>IAM User Guide</em>.</p>

        <div class="awsdocs-note awsdocs-important"><div class="awsdocs-note-title"><awsui-icon name="status-warning" variant="error"></awsui-icon><h6>Important</h6></div><div class="awsdocs-note-text"><p>Currently Amazon Data Firehose does NOT support data delivery to HTTP endpoints in a VPC.</p></div></div>
     
        <h2 id="cross-account-delivery-msk">Cross-account delivery from Amazon MSK</h2>
     
        <p>When you're creating a Firehose stream from your Firehose account (for example, Account B) and
            your source is an MSK cluster in another AWS account (Account A), you must have the
            following configurations in place. </p>
   
        <p><b>Account A:</b></p>
        <div class="procedure"><ol><li><p>In the Amazon MSK console, choose the provisioned cluster and then choose <b>Properties</b>.</p></li><li><p>Under <b>Network settings</b>, choose <b>Edit</b> and turn on <b>Multi-VPC connectivity</b>.</p></li><li><p>Under <b>Security settings</b> choose <b>Edit cluster policy</b>.</p>
            
            <ol><li><p>If the cluster does not already have a policy configured, check <b>Include Firehose service principal</b> and <b>Enable Firehose cross-account S3 delivery</b>. The AWS Management Console will 
                    automatically generate a policy with the appropriate permissions.</p></li><li> <p>If the cluster already has a policy configured, add the following permissions to the existing policy:</p>
                    <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (json)--><code class="json "><span>{</span>
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": "arn:aws:iam::<code class="replaceable">arn</code>:role/mskaasTestDeliveryRole"
      },
      "Action": [
        "kafka:GetBootstrapBrokers",
        "kafka:DescribeCluster",
        "kafka:DescribeClusterV2",
        "kafka-cluster:Connect"
      ],
      "Resource": "arn:aws:kafka:us-east-1:<code class="replaceable">arn</code>:cluster/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20"  // ARN of the cluster
    },
    <span>{</span>
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": "arn:aws:iam::<code class="replaceable">arn</code>:role/mskaasTestDeliveryRole"
      },
      "Action": [
        "kafka-cluster:DescribeTopic",
        "kafka-cluster:DescribeTopicDynamicConfiguration",
        "kafka-cluster:ReadData"
      ],
      "Resource": "arn:aws:kafka:us-east-1:<code class="replaceable">arn</code>:topic/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*"//topic of the cluster
    },
    <span>{</span>
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": "arn:aws:iam::233450236687:role/mskaasTestDeliveryRole"
      },
      "Action": "kafka-cluster:DescribeGroup",
      "Resource": "arn:aws:kafka:us-east-1:<code class="replaceable">arn</code>:group/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*" //topic of the cluster
    },
 }
</code></pre></li></ol>
                
            </li><li><p>Under <b>AWS principal</b>, enter the principal ID from Account B.</p></li><li><p>Under <b>Topic</b>, specify the Apache Kafka topic from which you want your
                    Firehose stream to ingest data. Once the Firehose stream is created, you cannot update
                    this topic.</p></li><li><p>Choose <b>Save changes</b></p></li></ol></div>
        <p><b>Account B:</b></p>
        <div class="procedure"><ol><li><p>In the Firehose console, choose <b>Create Firehose stream</b> using Account B.</p></li><li><p>Under <b>Source</b>, choose <b>Amazon Managed Streaming for Apache Kafka</b>.</p></li><li><p>Under <b>Source settings</b>, for the <b>Amazon Managed Streaming for Apache Kafka cluster</b>, enter the ARN of the Amazon MSK cluster in Account A.</p></li><li><p>Under <b>Topic</b>, specify the Apache Kafka topic from which you want your
                    Firehose stream to ingest data. Once the Firehose stream is created, you cannot update
                    this topic.</p></li><li> <p>In <b>Delivery stream name</b> specify the name for your Firehose stream. </p></li></ol></div>     
        
        
        
        
  
                
                
                
 <p>In Account B when you're creating your Firehose stream, you must have an IAM role (created by
            default when using the AWS Management Console) that grants the Firehose stream 'read' access to the
            cross-account Amazon MSK cluster for the configured topic.</p>
                    <p>The following is what gets configured by the AWS Management Console:</p>               
  <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (json)--><code class="json "><span>{</span>
    "Sid": "",
    "Effect": "Allow",
    "Action": [
        "kafka:GetBootstrapBrokers",
        "kafka:DescribeCluster",
        "kafka:DescribeClusterV2",
        "kafka-cluster:Connect"
        ],
    "Resource": "arn:aws:kafka:us-east-1:<code class="replaceable">arn</code>:cluster/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*" //topic of the cluster
    },
    <span>{</span>
    "Sid": "",
    "Effect": "Allow",
    "Action": [
        "kafka-cluster:DescribeTopic",
        "kafka-cluster:DescribeTopicDynamicConfiguration",
        "kafka-cluster:ReadData"
    ],
    "Resource": "arn:aws:kafka:us-east-1:<code class="replaceable">arn</code>:topic/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/mskaas_test_topic" //topic of the cluster
    },
    <span>{</span>
    "Sid": "",
    "Effect": "Allow",
    "Action": [
        "kafka-cluster:DescribeGroup"
    ],
    "Resource": "arn:aws:kafka:us-east-1:<code class="replaceable">arn</code>:group/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*" //topic of the cluster
    },
 }        	
</code></pre>              
                
             
          
                <p>Next, you can complete the optional step of configuring record transformation and
                    record format conversion. For more information, see <a href="./create-transform.html">(Optional) Configure record transformation and format
            conversion</a>.</p>
                        
        
           
            
        
     
        <h2 id="cross-account-delivery-s3">Cross-account delivery to an Amazon S3
                destination</h2>

        <p>You can use the AWS CLI or the Amazon Data Firehose APIs to create a Firehose stream in one AWS
            account with an Amazon S3 destination in a different account. The following procedure shows
            an example of configuring a Firehose stream owned by account A to deliver data to
            an Amazon S3 bucket owned by account B.</p>

        <div class="procedure"><ol><li>
                <p>Create an IAM role under account A using steps described in <a href="https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3">Grant Firehose Access to an Amazon S3 Destination</a>. </p>
                <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>The Amazon S3 bucket specified in the access policy is owned by account B in
                        this case. Make sure you add <code class="code">s3:PutObjectAcl</code> to the list of
                        Amazon S3 actions in the access policy, which grants account B full access to the
                        objects delivered by Amazon Data Firehose. This permission is required for cross
                        account delivery. Amazon Data Firehose sets the "x-amz-acl" header on the request to
                        "bucket-owner-full-control".</p></div></div>
            </li><li>
                <p>To allow access from the IAM role previously created, create an S3 bucket
                    policy under account B. The following code is an example of the bucket policy.
                    For more information, see <a href="https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html">Using
                        Bucket Policies and User Policies</a>. </p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>

    "Version": "2012-10-17",
    "Id": "PolicyID",
    "Statement": [
        <span>{</span>
            "Sid": "StmtID",
            "Effect": "Allow",
            "Principal": <span>{</span>
                "AWS": "arn:aws:iam::<code class="replaceable">accountA-id</code>:role/<code class="replaceable">iam-role-name</code>"
            },
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject",
                "s3:PutObjectAcl"
            ],
            "Resource": [
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>",
                "arn:aws:s3:::<code class="replaceable">amzn-s3-demo-bucket</code>/*"
            ]
        }
    ]
}
                        </code></pre>
            </li><li>
                <p>Create a Firehose stream under account A using the IAM role that you
                    created in step 1.</p>
            </li></ol></div>
     
        <h2 id="cross-account-delivery-es">Cross-account delivery to an OpenSearch Service
                destination</h2>

        <p>You can use the AWS CLI or the Amazon Data Firehose APIs to create a Firehose stream in one AWS
            account with an OpenSearch Service destination in a different account. The following procedure shows
            an example of how you can create a Firehose stream under account A and configure it to
            deliver data to an OpenSearch Service destination owned by account B.</p>

        <div class="procedure"><ol><li>
                <p>Create an IAM role under account A using the steps described in <a href="#using-iam-es">Grant Firehose access to a public OpenSearch Service destination</a>. </p>
            </li><li>
                <p>To allow access from the IAM role that you created in the previous step,
                    create an OpenSearch Service policy under account B. The following JSON is an
                    example.</p>
                <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
  "Version": "2012-10-17",
  "Statement": [
    <span>{</span>
      "Effect": "Allow",
      "Principal": <span>{</span>
        "AWS": "arn:aws:iam::<code class="replaceable">Account-A-ID</code>:role/firehose_delivery_role "
      },
      "Action": "es:ESHttpGet",
      "Resource": [
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/_all/_settings",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/_cluster/stats",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/roletest*/_mapping/roletest",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/_nodes",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/_nodes/stats",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/_nodes/*/stats",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/_stats",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/roletest*/_stats",
        "arn:aws:es:us-east-1:<code class="replaceable">Account-B-ID</code>:domain/cross-account-cluster/"
      ]
    }
  ]
}                   </code></pre>
            </li><li>
                <p>Create a Firehose stream under account A using the IAM role that you
                    created in step 1. When you create the Firehose stream, use the AWS CLI or the
                    Amazon Data Firehose APIs and specify the <code class="code">ClusterEndpoint</code> field instead of
                        <code class="code">DomainARN</code> for OpenSearch Service.</p>
            </li></ol></div>
        <div class="awsdocs-note"><div class="awsdocs-note-title"><awsui-icon name="status-info" variant="link"></awsui-icon><h6>Note</h6></div><div class="awsdocs-note-text"><p>To create a Firehose stream in one AWS account with an OpenSearch Service
                destination in a different account, you must use the AWS CLI or the Amazon Data Firehose APIs. You
                can't use the AWS Management Console to create this kind of cross-account configuration.</p></div></div>
     
        <h2 id="tag-based-access-control">Using tags to control access</h2>
        <p>You can use the optional <code class="code">Condition</code> element (or <code class="code">Condition</code>
            <em>block</em>) in an IAM policy to fine-tune access to Amazon Data Firehose operations
            based on tag keys and values. The following subsections describe how to do this for the
            different Amazon Data Firehose operations. For more on the use of the <code class="code">Condition</code> element
            and the operators that you can use within it, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html">IAM JSON Policy Elements: Condition</a>.</p>
         
            <h3 id="aws-requesttag">CreateDeliveryStream</h3>
            <p>For the <code class="code">CreateDeliveryStream</code> operation, use the
                    <code class="code">aws:RequestTag</code> condition key. In the following example,
                    <code class="code">MyKey</code> and <code class="code">MyValue</code> represent the key and corresponding
                value for a tag. For more information, see <a href="./firehose-tagging-basics.html">Understand tag basics</a></p>

            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",
    "Statement": [<span>{</span>
        "Effect": "Allow",
        "Action": [
            "firehose:CreateDeliveryStream",
            "firehose:TagDeliveryStream"
        ],
        "Resource": "*",
        "Condition": <span>{</span>
            "StringEquals": <span>{</span>
                "aws:RequestTag/MyKey": "MyValue"
            }
        }
    }]
}</code></pre>
         





         
            <h3 id="aws-tagkeys">TagDeliveryStream</h3>
            <p>For the <code class="code">TagDeliveryStream</code> operation, use the <code class="code">aws:TagKeys</code>
                condition key. In the following example, <code class="code">MyKey</code> is an example tag
                key.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",
    "Statement": [
        <span>{</span>
            "Effect": "Allow",
            "Action": "firehose:TagDeliveryStream",
            "Resource": "*",
            "Condition": <span>{</span>
                "ForAnyValue:StringEquals": <span>{</span>
                    "aws:TagKeys": "MyKey"
                 }
            }
        }
    ]
}</code></pre>
         




         
            <h3 id="aws-untagkeys">UntagDeliveryStream</h3>
            <p>For the <code class="code">UntagDeliveryStream</code> operation, use the
                    <code class="code">aws:TagKeys</code> condition key. In the following example,
                    <code class="code">MyKey</code> is an example tag key.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",
    "Statement": [
        <span>{</span>
            "Effect": "Allow",
            "Action": "firehose:UntagDeliveryStream",
            "Resource": "*",
            "Condition": <span>{</span>
                "ForAnyValue:StringEquals": <span>{</span>
                    "aws:TagKeys": "MyKey"
                 }
            }
        }
    ]
}</code></pre>
         



         
            <h3 id="list-delivery-streams">ListDeliveryStreams</h3>
            <p>You can't use tag-based access control with
                <code class="code">ListDeliveryStreams</code>.</p>
         
         
            <h3 id="firehose-resourcetag">Other operations</h3>
            <p>For all Firehose operations other than <code class="code">CreateDeliveryStream</code>,
                    <code class="code">TagDeliveryStream</code>, <code class="code">UntagDeliveryStream</code>, and
                    <code class="code">ListDeliveryStreams</code>, use the <code class="code">aws:RequestTag</code> condition
                key. In the following example, <code class="code">MyKey</code> and <code class="code">MyValue</code> represent
                the key and corresponding value for a tag.</p>
            <p><code class="code">ListDeliveryStreams</code>, use the <code class="code">firehose:ResourceTag</code>
                condition key to control access based on the tags on that Firehose stream.</p>

            <p>In the following example, <code class="code">MyKey</code> and <code class="code">MyValue</code> represent
                the key and corresponding value for a tag. The policy would only apply to Data
                Firehose streams having a tag named <code class="code">MyKey</code> with a value of
                    <code class="code">MyValue</code>. For more information about controlling access based on
                resource tags, see <a href="https://docs.aws.amazon.com/IAM/latest/UserGuide/access_tags.html#access_tags_control-resources">Controlling access to AWS resources using tags</a> in the
                    <em>IAM User Guide</em>.</p>
            <pre class="programlisting"><div class="code-btn-container"><div class="btn-copy-code" title="Copy"><awsui-icon name="copy"></awsui-icon></div></div><!--DEBUG: cli (JSON)--><code class="JSON "><span>{</span>
    "Version": "2012-10-17",
    "Statement": [
      <span>{</span>
            "Effect": "Deny",
            "Action": "firehose:DescribeDeliveryStream",
            "Resource": "*",
            "Condition": <span>{</span>
                "StringEquals": <span>{</span>
	                     "firehose:ResourceTag/MyKey": "MyValue"
	                 }
            }
        }
    ]
}</code></pre>
         
    <awsdocs-copyright class="copyright-print"></awsdocs-copyright><awsdocs-thumb-feedback right-edge="{{$ctrl.thumbFeedbackRightEdge}}"></awsdocs-thumb-feedback></div><noscript><div><div><div><div id="js_error_message"><p><img src="https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png" alt="Warning" /> <strong>Javascript is disabled or is unavailable in your browser.</strong></p><p>To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.</p></div></div></div></div></noscript><div id="main-col-footer" class="awsui-util-font-size-0"><div id="doc-conventions"><a target="_top" href="/general/latest/gr/docconventions.html">Document Conventions</a></div><div class="prev-next"><div id="previous" class="prev-link" accesskey="p" href="./encryption.html">Data Protection</div><div id="next" class="next-link" accesskey="n" href="./using-secrets-manager.html">Authenticate with
            AWS Secrets Manager</div></div></div><awsdocs-page-utilities></awsdocs-page-utilities></div><div id="quick-feedback-yes" style="display: none;"><div class="title">Did this page help you? - Yes</div><div class="content"><p>Thanks for letting us know we're doing a good job!</p><p>If you've got a moment, please tell us what we did right so we can do more of it.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Firehose&amp;topic_url=https://docs.aws.amazon.com/en_us/firehose/latest/dev/controlling-access.html"></awsui-button></p></div></div><div id="quick-feedback-no" style="display: none;"><div class="title">Did this page help you? - No</div><div class="content"><p>Thanks for letting us know this page needs work. We're sorry we let you down.</p><p>If you've got a moment, please tell us how we can make the documentation better.</p><p><awsui-button id="fblink" rel="noopener noreferrer" target="_blank" text="Feedback" click="linkClick($event)" href="https://docs.aws.amazon.com/forms/aws-doc-feedback?hidden_service_name=Firehose&amp;topic_url=https://docs.aws.amazon.com/en_us/firehose/latest/dev/controlling-access.html"></awsui-button></p></div></div></div></body></div></awsdocs-view><div class="page-loading-indicator" id="page-loading-indicator"><awsui-spinner size="large"></awsui-spinner></div></div><div id="tools-panel" dom-region="tools"><awsdocs-tools-panel id="awsdocs-tools-panel"></awsdocs-tools-panel></div></awsui-app-layout><awsdocs-cookie-banner class="doc-cookie-banner"></awsdocs-cookie-banner></div></body></html>