
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Ff3b9bf4c3c0597563b289c0512e98d4ce81f886e%2Ftensorflow%2Fpython%2Ftools%2Fsaved_model_cli.py)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Ff3b9bf4c3c0597563b289c0512e98d4ce81f886e%2Ftensorflow%2Fpython%2Ftools%2Fsaved_model_cli.py)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  835](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 f3b9bf4
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e)
2. /[tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow)
3. /[python](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python)
4. /[tools](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/tools)
/
# saved\_model\_cli.py

 Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/tools/saved_model_cli.py)1289 lines (1115 loc) · 48.7 KB f3b9bf4
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e)
2. /[tensorflow](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow)
3. /[python](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python)
4. /[tools](/tensorflow/tensorflow/tree/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/tools)
/
# saved\_model\_cli.py

Top
## File metadata and controls

* Code
* Blame

1289 lines (1115 loc) · 48.7 KB[Raw](https://github.com/tensorflow/tensorflow/raw/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/tools/saved_model_cli.py)1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451461471481491501511521531541551561571581591601611621631641651661671681691701711721731741751761771781791801811821831841851861871881891901911921931941951961971981992002012022032042052062072082092102112122132142152162172182192202212222232242252262272282292302312322332342352362372382392402412422432442452462472482492502512522532542552562572582592602612622632642652662672682692702712722732742752762772782792802812822832842852862872882892902912922932942952962972982993003013023033043053063073083093103113123133143153163173183193203213223233243253263273283293303313323333343353363373383393403413423433443453463473483493503513523533543553563573583593603613623633643653663673683693703713723733743753763773783793803813823833843853863873883893903913923933943953963973983994004014024034044054064074084094104114124134144154164174184194204214224234244254264274284294304314324334344354364374384394404414424434444454464474484494504514524534544554564574584594604614624634644654664674684694704714724734744754764774784794804814824834844854864874884894904914924934944954964974984995005015025035045055065075085095105115125135145155165175185195205215225235245255265275285295305315325335345355365375385395405415425435445455465475485495505515525535545555565575585595605615625635645655665675685695705715725735745755765775785795805815825835845855865875885895905915925935945955965975985996006016026036046056066076086096106116126136146156166176186196206216226236246256266276286296306316326336346356366376386396406416426436446456466476486496506516526536546556566576586596606616626636646656666676686696706716726736746756766776786796806816826836846856866876886896906916926936946956966976986997007017027037047057067077087097107117127137147157167177187197207217227237247257267277287297307317327337347357367377387397407417427437447457467477487497507517527537547557567577587597607617627637647657667677687697707717727737747757767777787797807817827837847857867877887897907917927937947957967977987998008018028038048058068078088098108118128138148158168178188198208218228238248258268278288298308318328338348358368378388398408418428438448458468478488498508518528538548558568578588598608618628638648658668678688698708718728738748758768778788798808818828838848858868878888898908918928938948958968978988999009019029039049059069079089099109119129139149159169179189199209219229239249259269279289299309319329339349359369379389399409419429439449459469479489499509519529539549559569579589599609619629639649659669679689699709719729739749759769779789799809819829839849859869879889899909919929939949959969979989991000# Copyright 2017 The TensorFlow Authors. All Rights Reserved.## Licensed under the Apache License, Version 2.0 (the "License");# you may not use this file except in compliance with the License.# You may obtain a copy of the License at## http://www.apache.org/licenses/LICENSE-2.0## Unless required by applicable law or agreed to in writing, software# distributed under the License is distributed on an "AS IS" BASIS,# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.# See the License for the specific language governing permissions and# limitations under the License.# =============================================================================="""Command-line interface to inspect and execute a graph in a SavedModel.
For detailed usages and examples, please refer to:https://www.tensorflow.org/guide/saved\_model#cli\_to\_inspect\_and\_execute\_savedmodel
"""
import argparseimport astimport osimport reimport sys
from absl import app # pylint: disable=unused-importimport numpy as npimport six
from tensorflow.core.example import example\_pb2from tensorflow.core.framework import types\_pb2from tensorflow.core.protobuf import config\_pb2from tensorflow.python.client import sessionfrom tensorflow.python.debug.wrappers import local\_cli\_wrapperfrom tensorflow.python.eager import def\_functionfrom tensorflow.python.eager import function as defunfrom tensorflow.python.framework import meta\_graph as meta\_graph\_libfrom tensorflow.python.framework import ops as ops\_libfrom tensorflow.python.framework import tensor\_specfrom tensorflow.python.lib.io import file\_iofrom tensorflow.python.platform import tf\_logging as loggingfrom tensorflow.python.saved\_model import loadfrom tensorflow.python.saved\_model import loaderfrom tensorflow.python.saved\_model import savefrom tensorflow.python.saved\_model import signature\_constantsfrom tensorflow.python.tools import saved\_model\_aot\_compilefrom tensorflow.python.tools import saved\_model\_utilsfrom tensorflow.python.tpu import tpufrom tensorflow.python.util.compat import collections\_abc
\_XLA\_DEBUG\_OPTIONS\_URL = ( 'https://github.com/tensorflow/tensorflow/blob/master/' 'tensorflow/compiler/xla/debug\_options\_flags.cc')
# Set of ops to denylist.\_OP\_DENYLIST = set(['WriteFile', 'ReadFile', 'PrintV2'])
def \_show\_tag\_sets(saved\_model\_dir): """Prints the tag-sets stored in SavedModel directory.
 Prints all the tag-sets for MetaGraphs stored in SavedModel directory.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect. """ tag\_sets = saved\_model\_utils.get\_saved\_model\_tag\_sets(saved\_model\_dir) print('The given SavedModel contains the following tag-sets:') for tag\_set in sorted(tag\_sets): print('%r' % ', '.join(sorted(tag\_set)))
def \_show\_signature\_def\_map\_keys(saved\_model\_dir, tag\_set): """Prints the keys for each SignatureDef in the SignatureDef map.
 Prints the list of SignatureDef keys from the SignatureDef map specified by the given tag-set and SavedModel directory.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect. tag\_set: Group of tag(s) of the MetaGraphDef to get SignatureDef map from, in string format, separated by ','. For tag-set contains multiple tags, all tags must be passed in. """ signature\_def\_map = get\_signature\_def\_map(saved\_model\_dir, tag\_set) print('The given SavedModel MetaGraphDef contains SignatureDefs with the ' 'following keys:') for signature\_def\_key in sorted(signature\_def\_map.keys()): print('SignatureDef key: \"%s\"' % signature\_def\_key)
def \_get\_inputs\_tensor\_info\_from\_meta\_graph\_def(meta\_graph\_def, signature\_def\_key): """Gets TensorInfo for all inputs of the SignatureDef.
 Returns a dictionary that maps each input key to its TensorInfo for the given signature\_def\_key in the meta\_graph\_def
 Args: meta\_graph\_def: MetaGraphDef protocol buffer with the SignatureDef map to look up SignatureDef key. signature\_def\_key: A SignatureDef key string.
 Returns: A dictionary that maps input tensor keys to TensorInfos.
 Raises: ValueError if `signature\_def\_key` is not found in the MetaGraphDef. """ if signature\_def\_key not in meta\_graph\_def.signature\_def: raise ValueError( f'Could not find signature "{signature\_def\_key}". Please choose from: ' f'{", ".join(meta\_graph\_def.signature\_def.keys())}') return meta\_graph\_def.signature\_def[signature\_def\_key].inputs
def \_get\_outputs\_tensor\_info\_from\_meta\_graph\_def(meta\_graph\_def, signature\_def\_key): """Gets TensorInfos for all outputs of the SignatureDef.
 Returns a dictionary that maps each output key to its TensorInfo for the given signature\_def\_key in the meta\_graph\_def.
 Args: meta\_graph\_def: MetaGraphDef protocol buffer with the SignatureDefmap to look up signature\_def\_key. signature\_def\_key: A SignatureDef key string.
 Returns: A dictionary that maps output tensor keys to TensorInfos. """ return meta\_graph\_def.signature\_def[signature\_def\_key].outputs
def \_show\_inputs\_outputs(saved\_model\_dir, tag\_set, signature\_def\_key, indent=0): """Prints input and output TensorInfos.
 Prints the details of input and output TensorInfos for the SignatureDef mapped by the given signature\_def\_key.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect. tag\_set: Group of tag(s) of the MetaGraphDef, in string format, separated by ','. For tag-set contains multiple tags, all tags must be passed in. signature\_def\_key: A SignatureDef key string. indent: How far (in increments of 2 spaces) to indent each line of output. """ meta\_graph\_def = saved\_model\_utils.get\_meta\_graph\_def(saved\_model\_dir, tag\_set) inputs\_tensor\_info = \_get\_inputs\_tensor\_info\_from\_meta\_graph\_def( meta\_graph\_def, signature\_def\_key) outputs\_tensor\_info = \_get\_outputs\_tensor\_info\_from\_meta\_graph\_def( meta\_graph\_def, signature\_def\_key)
 indent\_str = ' ' \* indent def in\_print(s): print(indent\_str + s)
 in\_print('The given SavedModel SignatureDef contains the following input(s):') for input\_key, input\_tensor in sorted(inputs\_tensor\_info.items()): in\_print(' inputs[\'%s\'] tensor\_info:' % input\_key) \_print\_tensor\_info(input\_tensor, indent+1)
 in\_print('The given SavedModel SignatureDef contains the following ' 'output(s):') for output\_key, output\_tensor in sorted(outputs\_tensor\_info.items()): in\_print(' outputs[\'%s\'] tensor\_info:' % output\_key) \_print\_tensor\_info(output\_tensor, indent+1)
 in\_print('Method name is: %s' % meta\_graph\_def.signature\_def[signature\_def\_key].method\_name)
def \_show\_defined\_functions(saved\_model\_dir): """Prints the callable concrete and polymorphic functions of the Saved Model.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect. """ meta\_graphs = saved\_model\_utils.read\_saved\_model(saved\_model\_dir).meta\_graphs has\_object\_graph\_def = False
 for meta\_graph\_def in meta\_graphs: has\_object\_graph\_def |= meta\_graph\_def.HasField('object\_graph\_def') if not has\_object\_graph\_def: return with ops\_lib.Graph().as\_default(): trackable\_object = load.load(saved\_model\_dir)
 print('\nConcrete Functions:', end='') children = list( save.\_AugmentedGraphView(trackable\_object) # pylint: disable=protected-access .list\_children(trackable\_object)) children = sorted(children, key=lambda x: x.name) for name, child in children: concrete\_functions = [] if isinstance(child, defun.ConcreteFunction): concrete\_functions.append(child) elif isinstance(child, def\_function.Function): concrete\_functions.extend( child.\_list\_all\_concrete\_functions\_for\_serialization()) # pylint: disable=protected-access else: continue print('\n Function Name: \'%s\'' % name) concrete\_functions = sorted(concrete\_functions, key=lambda x: x.name) for index, concrete\_function in enumerate(concrete\_functions, 1): args, kwargs = None, None if concrete\_function.structured\_input\_signature: args, kwargs = concrete\_function.structured\_input\_signature elif concrete\_function.\_arg\_keywords: # pylint: disable=protected-access # For pure ConcreteFunctions we might have nothing better than # \_arg\_keywords. args = concrete\_function.\_arg\_keywords # pylint: disable=protected-access if args: print(' Option #%d' % index) print(' Callable with:') \_print\_args(args, indent=4) if kwargs: \_print\_args(kwargs, 'Named Argument', indent=4)
def \_print\_args(arguments, argument\_type='Argument', indent=0): """Formats and prints the argument of the concrete functions defined in the model.
 Args: arguments: Arguments to format print. argument\_type: Type of arguments. indent: How far (in increments of 2 spaces) to indent each line of output. """ indent\_str = ' ' \* indent
 def \_maybe\_add\_quotes(value): is\_quotes = '\'' \* isinstance(value, str) return is\_quotes + str(value) + is\_quotes
 def in\_print(s, end='\n'): print(indent\_str + s, end=end)
 for index, element in enumerate(arguments, 1): if indent == 4: in\_print('%s #%d' % (argument\_type, index)) if isinstance(element, six.string\_types): in\_print(' %s' % element) elif isinstance(element, tensor\_spec.TensorSpec): print((indent + 1) \* ' ' + '%s: %s' % (element.name, repr(element))) elif (isinstance(element, collections\_abc.Iterable) and not isinstance(element, dict)): in\_print(' DType: %s' % type(element).\_\_name\_\_) in\_print(' Value: [', end='') for value in element: print('%s' % \_maybe\_add\_quotes(value), end=', ') print('\b\b]') elif isinstance(element, dict): in\_print(' DType: %s' % type(element).\_\_name\_\_) in\_print(' Value: {', end='') for (key, value) in element.items(): print('\'%s\': %s' % (str(key), \_maybe\_add\_quotes(value)), end=', ') print('\b\b}') else: in\_print(' DType: %s' % type(element).\_\_name\_\_) in\_print(' Value: %s' % str(element))
def \_print\_tensor\_info(tensor\_info, indent=0): """Prints details of the given tensor\_info.
 Args: tensor\_info: TensorInfo object to be printed. indent: How far (in increments of 2 spaces) to indent each line output """ indent\_str = ' ' \* indent def in\_print(s): print(indent\_str + s)
 in\_print(' dtype: ' + {value: key for (key, value) in types\_pb2.DataType.items()}[tensor\_info.dtype]) # Display shape as tuple. if tensor\_info.tensor\_shape.unknown\_rank: shape = 'unknown\_rank' else: dims = [str(dim.size) for dim in tensor\_info.tensor\_shape.dim] shape = ', '.join(dims) shape = '(' + shape + ')' in\_print(' shape: ' + shape) in\_print(' name: ' + tensor\_info.name)
def \_show\_all(saved\_model\_dir): """Prints tag-set, SignatureDef and Inputs/Outputs information in SavedModel.
 Prints all tag-set, SignatureDef and Inputs/Outputs information stored in SavedModel directory.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect. """ tag\_sets = saved\_model\_utils.get\_saved\_model\_tag\_sets(saved\_model\_dir) for tag\_set in sorted(tag\_sets): print("\nMetaGraphDef with tag-set: '%s' " "contains the following SignatureDefs:" % ', '.join(tag\_set))
 tag\_set = ','.join(tag\_set) signature\_def\_map = get\_signature\_def\_map(saved\_model\_dir, tag\_set) for signature\_def\_key in sorted(signature\_def\_map.keys()): print('\nsignature\_def[\'' + signature\_def\_key + '\']:') \_show\_inputs\_outputs(saved\_model\_dir, tag\_set, signature\_def\_key, indent=1) \_show\_defined\_functions(saved\_model\_dir)
def get\_meta\_graph\_def(saved\_model\_dir, tag\_set): """DEPRECATED: Use saved\_model\_utils.get\_meta\_graph\_def instead.
 Gets MetaGraphDef from SavedModel. Returns the MetaGraphDef for the given tag-set and SavedModel directory.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect or execute. tag\_set: Group of tag(s) of the MetaGraphDef to load, in string format, separated by ','. For tag-set contains multiple tags, all tags must be passed in.
 Raises: RuntimeError: An error when the given tag-set does not exist in the SavedModel.
 Returns: A MetaGraphDef corresponding to the tag-set. """ return saved\_model\_utils.get\_meta\_graph\_def(saved\_model\_dir, tag\_set)
def get\_signature\_def\_map(saved\_model\_dir, tag\_set): """Gets SignatureDef map from a MetaGraphDef in a SavedModel.
 Returns the SignatureDef map for the given tag-set in the SavedModel directory.
 Args: saved\_model\_dir: Directory containing the SavedModel to inspect or execute. tag\_set: Group of tag(s) of the MetaGraphDef with the SignatureDef map, in string format, separated by ','. For tag-set contains multiple tags, all tags must be passed in.
 Returns: A SignatureDef map that maps from string keys to SignatureDefs. """ meta\_graph = saved\_model\_utils.get\_meta\_graph\_def(saved\_model\_dir, tag\_set) return meta\_graph.signature\_def
def scan\_meta\_graph\_def(meta\_graph\_def): """Scans meta\_graph\_def and reports if there are ops on denylist.
 Print ops if they are on black list, or print success if no denylisted ops found.
 Args: meta\_graph\_def: MetaGraphDef protocol buffer. """ all\_ops\_set = set( meta\_graph\_lib.ops\_used\_by\_graph\_def(meta\_graph\_def.graph\_def)) denylisted\_ops = \_OP\_DENYLIST & all\_ops\_set if denylisted\_ops: # TODO(yifeif): print more warnings print( 'MetaGraph with tag set %s contains the following denylisted ops:' % meta\_graph\_def.meta\_info\_def.tags, denylisted\_ops) else: print('MetaGraph with tag set %s does not contain denylisted ops.' % meta\_graph\_def.meta\_info\_def.tags)
def run\_saved\_model\_with\_feed\_dict(saved\_model\_dir, tag\_set, signature\_def\_key, input\_tensor\_key\_feed\_dict, outdir, overwrite\_flag, worker=None, init\_tpu=False, use\_tfrt=False, tf\_debug=False): """Runs SavedModel and fetch all outputs.
 Runs the input dictionary through the MetaGraphDef within a SavedModel specified by the given tag\_set and SignatureDef. Also save the outputs to file if outdir is not None.
 Args: saved\_model\_dir: Directory containing the SavedModel to execute. tag\_set: Group of tag(s) of the MetaGraphDef with the SignatureDef map, in string format, separated by ','. For tag-set contains multiple tags, all tags must be passed in. signature\_def\_key: A SignatureDef key string. input\_tensor\_key\_feed\_dict: A dictionary maps input keys to numpy ndarrays. outdir: A directory to save the outputs to. If the directory doesn't exist, it will be created. overwrite\_flag: A boolean flag to allow overwrite output file if file with the same name exists. worker: If provided, the session will be run on the worker. Valid worker specification is a bns or gRPC path. init\_tpu: If true, the TPU system will be initialized after the session is created. use\_tfrt: If true, TFRT session will be used. tf\_debug: A boolean flag to use TensorFlow Debugger (TFDBG) to observe the intermediate Tensor values and runtime GraphDefs while running the SavedModel.
 Raises: ValueError: When any of the input tensor keys is not valid. RuntimeError: An error when output file already exists and overwrite is not enabled. """ # Get a list of output tensor names. meta\_graph\_def = saved\_model\_utils.get\_meta\_graph\_def(saved\_model\_dir, tag\_set)
 # Re-create feed\_dict based on input tensor name instead of key as session.run # uses tensor name. inputs\_tensor\_info = \_get\_inputs\_tensor\_info\_from\_meta\_graph\_def( meta\_graph\_def, signature\_def\_key)
 # Check if input tensor keys are valid. for input\_key\_name in input\_tensor\_key\_feed\_dict.keys(): if input\_key\_name not in inputs\_tensor\_info: raise ValueError( '"%s" is not a valid input key. Please choose from %s, or use ' '--show option.' % (input\_key\_name, '"' + '", "'.join(inputs\_tensor\_info.keys()) + '"'))
 inputs\_feed\_dict = { inputs\_tensor\_info[key].name: tensor for key, tensor in input\_tensor\_key\_feed\_dict.items() } # Get outputs outputs\_tensor\_info = \_get\_outputs\_tensor\_info\_from\_meta\_graph\_def( meta\_graph\_def, signature\_def\_key) # Sort to preserve order because we need to go from value to key later. output\_tensor\_keys\_sorted = sorted(outputs\_tensor\_info.keys()) output\_tensor\_names\_sorted = [ outputs\_tensor\_info[tensor\_key].name for tensor\_key in output\_tensor\_keys\_sorted ]
 config = None if use\_tfrt: logging.info('Using TFRT session.') config = config\_pb2.ConfigProto( experimental=config\_pb2.ConfigProto.Experimental(use\_tfrt=True)) with session.Session(worker, graph=ops\_lib.Graph(), config=config) as sess: if init\_tpu: print('Initializing TPU System ...') # This is needed for freshly started worker, or if the job # restarts after a preemption. sess.run(tpu.initialize\_system())
 loader.load(sess, tag\_set.split(','), saved\_model\_dir)
 if tf\_debug: sess = local\_cli\_wrapper.LocalCLIDebugWrapperSession(sess)
 outputs = sess.run(output\_tensor\_names\_sorted, feed\_dict=inputs\_feed\_dict)
 for i, output in enumerate(outputs): output\_tensor\_key = output\_tensor\_keys\_sorted[i] print('Result for output key %s:\n%s' % (output\_tensor\_key, output))
 # Only save if outdir is specified. if outdir: # Create directory if outdir does not exist if not os.path.isdir(outdir): os.makedirs(outdir) output\_full\_path = os.path.join(outdir, output\_tensor\_key + '.npy')
 # If overwrite not enabled and file already exist, error out if not overwrite\_flag and os.path.exists(output\_full\_path): raise RuntimeError( 'Output file %s already exists. Add \"--overwrite\" to overwrite' ' the existing output files.' % output\_full\_path)
 np.save(output\_full\_path, output) print('Output %s is saved to %s' % (output\_tensor\_key, output\_full\_path))
def preprocess\_inputs\_arg\_string(inputs\_str): """Parses input arg into dictionary that maps input to file/variable tuple.
 Parses input string in the format of, for example, "input1=filename1[variable\_name1],input2=filename2" into a dictionary looks like {'input\_key1': (filename1, variable\_name1), 'input\_key2': (file2, None)} , which maps input keys to a tuple of file name and variable name(None if empty).
 Args: inputs\_str: A string that specified where to load inputs. Inputs are separated by semicolons. \* For each input key: '<input\_key>=<filename>' or '<input\_key>=<filename>[<variable\_name>]' \* The optional 'variable\_name' key will be set to None if not specified.
 Returns: A dictionary that maps input keys to a tuple of file name and variable name.
 Raises: RuntimeError: An error when the given input string is in a bad format. """ input\_dict = {} inputs\_raw = inputs\_str.split(';') for input\_raw in filter(bool, inputs\_raw): # skip empty strings # Format of input=filename[variable\_name]' match = re.match(r'([^=]+)=([^\[\]]+)\[([^\[\]]+)\]$', input\_raw)
 if match: input\_dict[match.group(1)] = match.group(2), match.group(3) else: # Format of input=filename' match = re.match(r'([^=]+)=([^\[\]]+)$', input\_raw) if match: input\_dict[match.group(1)] = match.group(2), None else: raise RuntimeError( '--inputs "%s" format is incorrect. Please follow' '"<input\_key>=<filename>", or' '"<input\_key>=<filename>[<variable\_name>]"' % input\_raw)
 return input\_dict
def preprocess\_input\_exprs\_arg\_string(input\_exprs\_str, safe=True): """Parses input arg into dictionary that maps input key to python expression.
 Parses input string in the format of 'input\_key=<python expression>' into a dictionary that maps each input\_key to its python expression.
 Args: input\_exprs\_str: A string that specifies python expression for input keys. Each input is separated by semicolon. For each input key: 'input\_key=<python expression>' safe: Whether to evaluate the python expression as literals or allow arbitrary calls (e.g. numpy usage).
 Returns: A dictionary that maps input keys to their values.
 Raises: RuntimeError: An error when the given input string is in a bad format. """ input\_dict = {}
 for input\_raw in filter(bool, input\_exprs\_str.split(';')): if '=' not in input\_exprs\_str: raise RuntimeError('--input\_exprs "%s" format is incorrect. Please follow' '"<input\_key>=<python expression>"' % input\_exprs\_str) input\_key, expr = input\_raw.split('=', 1) if safe: try: input\_dict[input\_key] = ast.literal\_eval(expr) except: raise RuntimeError( f'Expression "{expr}" is not a valid python literal.') else: # ast.literal\_eval does not work with numpy expressions input\_dict[input\_key] = eval(expr) # pylint: disable=eval-used return input\_dict
def preprocess\_input\_examples\_arg\_string(input\_examples\_str): """Parses input into dict that maps input keys to lists of tf.Example.
 Parses input string in the format of 'input\_key1=[{feature\_name: feature\_list}];input\_key2=[{feature\_name:feature\_list}];' into a dictionary that maps each input\_key to its list of serialized tf.Example.
 Args: input\_examples\_str: A string that specifies a list of dictionaries of feature\_names and their feature\_lists for each input. Each input is separated by semicolon. For each input key: 'input=[{feature\_name1: feature\_list1, feature\_name2:feature\_list2}]' items in feature\_list can be the type of float, int, long or str.
 Returns: A dictionary that maps input keys to lists of serialized tf.Example.
 Raises: ValueError: An error when the given tf.Example is not a list. """ input\_dict = preprocess\_input\_exprs\_arg\_string(input\_examples\_str) for input\_key, example\_list in input\_dict.items(): if not isinstance(example\_list, list): raise ValueError( 'tf.Example input must be a list of dictionaries, but "%s" is %s' % (example\_list, type(example\_list))) input\_dict[input\_key] = [ \_create\_example\_string(example) for example in example\_list ] return input\_dict
def \_create\_example\_string(example\_dict): """Create a serialized tf.example from feature dictionary.""" example = example\_pb2.Example() for feature\_name, feature\_list in example\_dict.items(): if not isinstance(feature\_list, list): raise ValueError('feature value must be a list, but %s: "%s" is %s' % (feature\_name, feature\_list, type(feature\_list))) if isinstance(feature\_list[0], float): example.features.feature[feature\_name].float\_list.value.extend( feature\_list) elif isinstance(feature\_list[0], str): example.features.feature[feature\_name].bytes\_list.value.extend( [f.encode('utf8') for f in feature\_list]) elif isinstance(feature\_list[0], bytes): example.features.feature[feature\_name].bytes\_list.value.extend( feature\_list) elif isinstance(feature\_list[0], six.integer\_types): example.features.feature[feature\_name].int64\_list.value.extend( feature\_list) else: raise ValueError( 'Type %s for value %s is not supported for tf.train.Feature.' % (type(feature\_list[0]), feature\_list[0])) return example.SerializeToString()
def load\_inputs\_from\_input\_arg\_string(inputs\_str, input\_exprs\_str, input\_examples\_str): """Parses input arg strings and create inputs feed\_dict.
 Parses '--inputs' string for inputs to be loaded from file, and parses '--input\_exprs' string for inputs to be evaluated from python expression. '--input\_examples' string for inputs to be created from tf.example feature dictionary list.
 Args: inputs\_str: A string that specified where to load inputs. Each input is separated by semicolon. \* For each input key: '<input\_key>=<filename>' or '<input\_key>=<filename>[<variable\_name>]' \* The optional 'variable\_name' key will be set to None if not specified. \* File specified by 'filename' will be loaded using numpy.load. Inputs can be loaded from only .npy, .npz or pickle files. \* The "[variable\_name]" key is optional depending on the input file type as descripted in more details below. When loading from a npy file, which always contains a numpy ndarray, the content will be directly assigned to the specified input tensor. If a variable\_name is specified, it will be ignored and a warning will be issued. When loading from a npz zip file, user can specify which variable within the zip file to load for the input tensor inside the square brackets. If nothing is specified, this function will check that only one file is included in the zip and load it for the specified input tensor. When loading from a pickle file, if no variable\_name is specified in the square brackets, whatever that is inside the pickle file will be passed to the specified input tensor, else SavedModel CLI will assume a dictionary is stored in the pickle file and the value corresponding to the variable\_name will be used. input\_exprs\_str: A string that specifies python expressions for inputs. \* In the format of: '<input\_key>=<python expression>'. \* numpy module is available as np. input\_examples\_str: A string that specifies tf.Example with dictionary. \* In the format of: '<input\_key>=<[{feature:value list}]>'
 Returns: A dictionary that maps input tensor keys to numpy ndarrays.
 Raises: RuntimeError: An error when a key is specified, but the input file contains multiple numpy ndarrays, none of which matches the given key. RuntimeError: An error when no key is specified, but the input file contains more than one numpy ndarrays. """ tensor\_key\_feed\_dict = {}
 inputs = preprocess\_inputs\_arg\_string(inputs\_str) input\_exprs = preprocess\_input\_exprs\_arg\_string(input\_exprs\_str, safe=False) input\_examples = preprocess\_input\_examples\_arg\_string(input\_examples\_str)
 for input\_tensor\_key, (filename, variable\_name) in inputs.items(): data = np.load(file\_io.FileIO(filename, mode='rb'), allow\_pickle=True) # pylint: disable=unexpected-keyword-arg
 # When a variable\_name key is specified for the input file if variable\_name: # if file contains a single ndarray, ignore the input name if isinstance(data, np.ndarray): logging.warn( 'Input file %s contains a single ndarray. Name key \"%s\" ignored.' % (filename, variable\_name)) tensor\_key\_feed\_dict[input\_tensor\_key] = data else: if variable\_name in data: tensor\_key\_feed\_dict[input\_tensor\_key] = data[variable\_name] else: raise RuntimeError( 'Input file %s does not contain variable with name \"%s\".' % (filename, variable\_name)) # When no key is specified for the input file. else: # Check if npz file only contains a single numpy ndarray. if isinstance(data, np.lib.npyio.NpzFile): variable\_name\_list = data.files if len(variable\_name\_list) != 1: raise RuntimeError( 'Input file %s contains more than one ndarrays. Please specify ' 'the name of ndarray to use.' % filename) tensor\_key\_feed\_dict[input\_tensor\_key] = data[variable\_name\_list[0]] else: tensor\_key\_feed\_dict[input\_tensor\_key] = data
 # When input is a python expression: for input\_tensor\_key, py\_expr\_evaluated in input\_exprs.items(): if input\_tensor\_key in tensor\_key\_feed\_dict: logging.warn( 'input\_key %s has been specified with both --inputs and --input\_exprs' ' options. Value in --input\_exprs will be used.' % input\_tensor\_key) tensor\_key\_feed\_dict[input\_tensor\_key] = py\_expr\_evaluated
 # When input is a tf.Example: for input\_tensor\_key, example in input\_examples.items(): if input\_tensor\_key in tensor\_key\_feed\_dict: logging.warn( 'input\_key %s has been specified in multiple options. Value in ' '--input\_examples will be used.' % input\_tensor\_key) tensor\_key\_feed\_dict[input\_tensor\_key] = example return tensor\_key\_feed\_dict
def show(args): """Function triggered by show command.
 Args: args: A namespace parsed from command line. """ # If all tag is specified, display all information. if args.all: \_show\_all(args.dir) else: # If no tag is specified, display all tag\_set, if no signature\_def key is # specified, display all SignatureDef keys, else show input output tensor # information corresponding to the given SignatureDef key if args.tag\_set is None: \_show\_tag\_sets(args.dir) else: if args.signature\_def is None: \_show\_signature\_def\_map\_keys(args.dir, args.tag\_set) else: \_show\_inputs\_outputs(args.dir, args.tag\_set, args.signature\_def)
def run(args): """Function triggered by run command.
 Args: args: A namespace parsed from command line.
 Raises: AttributeError: An error when neither --inputs nor --input\_exprs is passed to run command. """ if not args.inputs and not args.input\_exprs and not args.input\_examples: raise AttributeError( 'At least one of --inputs, --input\_exprs or --input\_examples must be ' 'required') tensor\_key\_feed\_dict = load\_inputs\_from\_input\_arg\_string( args.inputs, args.input\_exprs, args.input\_examples) run\_saved\_model\_with\_feed\_dict( args.dir, args.tag\_set, args.signature\_def, tensor\_key\_feed\_dict, args.outdir, args.overwrite, worker=args.worker, init\_tpu=args.init\_tpu, use\_tfrt=args.use\_tfrt, tf\_debug=args.tf\_debug)
def scan(args): """Function triggered by scan command.
 Args: args: A namespace parsed from command line. """ if args.tag\_set: scan\_meta\_graph\_def( saved\_model\_utils.get\_meta\_graph\_def(args.dir, args.tag\_set)) else: saved\_model = saved\_model\_utils.read\_saved\_model(args.dir) for meta\_graph\_def in saved\_model.meta\_graphs: scan\_meta\_graph\_def(meta\_graph\_def)
def convert\_with\_tensorrt(args): """Function triggered by 'convert tensorrt' command.
 Args: args: A namespace parsed from command line. """ # Import here instead of at top, because this will crash if TensorRT is # not installed from tensorflow.python.compiler.tensorrt import trt\_convert as trt # pylint: disable=g-import-not-at-top
 if not args.convert\_tf1\_model: params = trt.DEFAULT\_TRT\_CONVERSION\_PARAMS.\_replace( max\_workspace\_size\_bytes=args.max\_workspace\_size\_bytes, precision\_mode=args.precision\_mode, minimum\_segment\_size=args.minimum\_segment\_size) converter = trt.TrtGraphConverterV2( input\_saved\_model\_dir=args.dir, input\_saved\_model\_tags=args.tag\_set.split(','), \*\*params.\_asdict()) try: converter.convert() except Exception as e: raise RuntimeError( '{}. Try passing "--convert\_tf1\_model=True".'.format(e)) converter.save(output\_saved\_model\_dir=args.output\_dir) else: trt.create\_inference\_graph( None, None, max\_batch\_size=1, max\_workspace\_size\_bytes=args.max\_workspace\_size\_bytes, precision\_mode=args.precision\_mode, minimum\_segment\_size=args.minimum\_segment\_size, is\_dynamic\_op=True, input\_saved\_model\_dir=args.dir, input\_saved\_model\_tags=args.tag\_set.split(','), output\_saved\_model\_dir=args.output\_dir)
def freeze\_model(args): """Function triggered by freeze\_model command.
 Args: args: A namespace parsed from command line. """ checkpoint\_path = ( args.checkpoint\_path or os.path.join(args.dir, 'variables/variables')) if not args.variables\_to\_feed: variables\_to\_feed = [] elif args.variables\_to\_feed.lower() == 'all': variables\_to\_feed = None # We will identify them after. else: variables\_to\_feed = args.variables\_to\_feed.split(',')
 saved\_model\_aot\_compile.freeze\_model( checkpoint\_path=checkpoint\_path, meta\_graph\_def=saved\_model\_utils.get\_meta\_graph\_def( args.dir, args.tag\_set), signature\_def\_key=args.signature\_def\_key, variables\_to\_feed=variables\_to\_feed, output\_prefix=args.output\_prefix)
def aot\_compile\_cpu(args): """Function triggered by aot\_compile\_cpu command.
 Args: args: A namespace parsed from command line. """ checkpoint\_path = ( args.checkpoint\_path or os.path.join(args.dir, 'variables/variables')) if not args.variables\_to\_feed: variables\_to\_feed = [] elif args.variables\_to\_feed.lower() == 'all': variables\_to\_feed = None # We will identify them after. else: variables\_to\_feed = args.variables\_to\_feed.split(',')
 saved\_model\_aot\_compile.aot\_compile\_cpu\_meta\_graph\_def( checkpoint\_path=checkpoint\_path, meta\_graph\_def=saved\_model\_utils.get\_meta\_graph\_def( args.dir, args.tag\_set), signature\_def\_key=args.signature\_def\_key, variables\_to\_feed=variables\_to\_feed, output\_prefix=args.output\_prefix, target\_triple=args.target\_triple, target\_cpu=args.target\_cpu, cpp\_class=args.cpp\_class, multithreading=args.multithreading.lower() not in ('f', 'false', '0'))
def add\_show\_subparser(subparsers): """Add parser for `show`.""" show\_msg = ( 'Usage examples:\n' 'To show all tag-sets in a SavedModel:\n' '$saved\_model\_cli show --dir /tmp/saved\_model\n\n' 'To show all available SignatureDef keys in a ' 'MetaGraphDef specified by its tag-set:\n' '$saved\_model\_cli show --dir /tmp/saved\_model --tag\_set serve\n\n' 'For a MetaGraphDef with multiple tags in the tag-set, all tags must be ' 'passed in, separated by \';\':\n' '$saved\_model\_cli show --dir /tmp/saved\_model --tag\_set serve,gpu\n\n' 'To show all inputs and outputs TensorInfo for a specific' ' SignatureDef specified by the SignatureDef key in a' ' MetaGraph.\n' '$saved\_model\_cli show --dir /tmp/saved\_model --tag\_set serve' ' --signature\_def serving\_default\n\n' 'To show all available information in the SavedModel:\n' '$saved\_model\_cli show --dir /tmp/saved\_model --all') parser\_show = subparsers.add\_parser( 'show', description=show\_msg, formatter\_class=argparse.RawTextHelpFormatter) parser\_show.add\_argument( '--dir', type=str, required=True, help='directory containing the SavedModel to inspect') parser\_show.add\_argument( '--all', action='store\_true', help='if set, will output all information in given SavedModel') parser\_show.add\_argument( '--tag\_set', type=str, default=None, help='tag-set of graph in SavedModel to show, separated by \',\'') parser\_show.add\_argument( '--signature\_def', type=str, default=None, metavar='SIGNATURE\_DEF\_KEY', help='key of SignatureDef to display input(s) and output(s) for') parser\_show.set\_defaults(func=show)
def add\_run\_subparser(subparsers): """Add parser for `run`.""" run\_msg = ('Usage example:\n' 'To run input tensors from files through a MetaGraphDef and save' ' the output tensors to files:\n' '$saved\_model\_cli show --dir /tmp/saved\_model --tag\_set serve \\\n' ' --signature\_def serving\_default \\\n' ' --inputs input1\_key=/tmp/124.npz[x],input2\_key=/tmp/123.npy ' '\\\n' ' --input\_exprs \'input3\_key=np.ones(2)\' \\\n' ' --input\_examples ' '\'input4\_key=[{"id":[26],"weights":[0.5, 0.5]}]\' \\\n' ' --outdir=/out\n\n' 'For more information about input file format, please see:\n' 'https://www.tensorflow.org/guide/saved\_model\_cli\n') parser\_run = subparsers.add\_parser( 'run', description=run\_msg, formatter\_class=argparse.RawTextHelpFormatter) parser\_run.add\_argument( '--dir', type=str, required=True, help='directory containing the SavedModel to execute') parser\_run.add\_argument( '--tag\_set', type=str, required=True, help='tag-set of graph in SavedModel to load, separated by \',\'') parser\_run.add\_argument( '--signature\_def', type=str, required=True, metavar='SIGNATURE\_DEF\_KEY', help='key of SignatureDef to run') msg = ('Loading inputs from files, in the format of \'<input\_key>=<filename>,' ' or \'<input\_key>=<filename>[<variable\_name>]\', separated by \';\'.' ' The file format can only be from .npy, .npz or pickle.') parser\_run.add\_argument('--inputs', type=str, default='', help=msg) msg = ('Specifying inputs by python expressions, in the format of' ' "<input\_key>=\'<python expression>\'", separated by \';\'. ' 'numpy module is available as \'np\'. Please note that the expression ' 'will be evaluated as-is, and is susceptible to code injection. ' 'When this is set, the value will override duplicate input keys from ' '--inputs option.') parser\_run.add\_argument('--input\_exprs', type=str, default='', help=msg) msg = ( 'Specifying tf.Example inputs as list of dictionaries. For example: ' '<input\_key>=[{feature0:value\_list,feature1:value\_list}]. Use ";" to ' 'separate input keys. Will override duplicate input keys from --inputs ' 'and --input\_exprs option.') parser\_run.add\_argument('--input\_examples', type=str, default='', help=msg) parser\_run.add\_argument( '--outdir', type=str, default=None, help='if specified, output tensor(s) will be saved to given directory') parser\_run.add\_argument( '--overwrite',[View remainder of file in raw view](https://github.com/tensorflow/tensorflow/raw/f3b9bf4c3c0597563b289c0512e98d4ce81f886e/tensorflow/python/tools/saved_model_cli.py)

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

