=== Content from git.kernel.org_101e3b05_20250111_171040.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Filipe Manana <fdmanana@suse.com> | 2024-02-28 11:37:56 +0000 |
| --- | --- | --- |
| committer | Sasha Levin <sashal@kernel.org> | 2024-03-26 18:16:51 -0400 |
| commit | [ced63fffd63072c0ca55d5a451010d71bf08c0b3](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)) | |
| tree | [3d2092bde798d6459fec6747635f56b21750314f](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3) | |
| parent | [50a5eeb566eb8e36d3575475dcfd7afb36d76fe9](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=50a5eeb566eb8e36d3575475dcfd7afb36d76fe9) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3&id2=50a5eeb566eb8e36d3575475dcfd7afb36d76fe9)) | |
| download | [linux-ced63fffd63072c0ca55d5a451010d71bf08c0b3.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-ced63fffd63072c0ca55d5a451010d71bf08c0b3.tar.gz) | |

btrfs: fix race when detecting delalloc ranges during fiemap[ Upstream commit 978b63f7464abcfd364a6c95f734282c50f3decf ]
For fiemap we recently stopped locking the target extent range for the
whole duration of the fiemap call, in order to avoid a deadlock in a
scenario where the fiemap buffer happens to be a memory mapped range of
the same file. This use case is very unlikely to be useful in practice but
it may be triggered by fuzz testing (syzbot, etc).
This however introduced a race that makes us miss delalloc ranges for
file regions that are currently holes, so the caller of fiemap will not
be aware that there's data for some file regions. This can be quite
serious for some use cases - for example in coreutils versions before 9.0,
the cp program used fiemap to detect holes and data in the source file,
copying only regions with data (extents or delalloc) from the source file
to the destination file in order to preserve holes (see the documentation
for its --sparse command line option). This means that if cp was used
with a source file that had delalloc in a hole, the destination file could
end up without that data, which is effectively a data loss issue, if it
happened to hit the race described below.
The race happens like this:
1) Fiemap is called, without the FIEMAP\_FLAG\_SYNC flag, for a file that
has delalloc in the file range [64M, 65M[, which is currently a hole;
2) Fiemap locks the inode in shared mode, then starts iterating the
inode's subvolume tree searching for file extent items, without having
the whole fiemap target range locked in the inode's io tree - the
change introduced recently by commit b0ad381fa769 ("btrfs: fix
deadlock with fiemap and extent locking"). It only locks ranges in
the io tree when it finds a hole or prealloc extent since that
commit;
3) Note that fiemap clones each leaf before using it, and this is to
avoid deadlocks when locking a file range in the inode's io tree and
the fiemap buffer is memory mapped to some file, because writing
to the page with btrfs\_page\_mkwrite() will wait on any ordered extent
for the page's range and the ordered extent needs to lock the range
and may need to modify the same leaf, therefore leading to a deadlock
on the leaf;
4) While iterating the file extent items in the cloned leaf before
finding the hole in the range [64M, 65M[, the delalloc in that range
is flushed and its ordered extent completes - meaning the corresponding
file extent item is in the inode's subvolume tree, but not present in
the cloned leaf that fiemap is iterating over;
5) When fiemap finds the hole in the [64M, 65M[ range by seeing the gap in
the cloned leaf (or a file extent item with disk\_bytenr == 0 in case
the NO\_HOLES feature is not enabled), it will lock that file range in
the inode's io tree and then search for delalloc by checking for the
EXTENT\_DELALLOC bit in the io tree for that range and ordered extents
(with btrfs\_find\_delalloc\_in\_range()). But it finds nothing since the
delalloc in that range was already flushed and the ordered extent
completed and is gone - as a result fiemap will not report that there's
delalloc or an extent for the range [64M, 65M[, so user space will be
mislead into thinking that there's a hole in that range.
This could actually be sporadically triggered with test case generic/094
from fstests, which reports a missing extent/delalloc range like this:
# generic/094 2s ... - output mismatch (see /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad)
# --- tests/generic/094.out 2020-06-10 19:29:03.830519425 +0100
# +++ /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad 2024-02-28 11:00:00.381071525 +0000
# @@ -1,3 +1,9 @@
# QA output created by 094
# fiemap run with sync
# fiemap run without sync
# +ERROR: couldn't find extent at 7
# +map is 'HHDDHPPDPHPH'
# +logical: [ 5.. 6] phys: 301517.. 301518 flags: 0x800 tot: 2
# +logical: [ 8.. 8] phys: 301520.. 301520 flags: 0x800 tot: 1
# ...
# (Run 'diff -u /home/fdmanana/git/hub/xfstests/tests/generic/094.out /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad' to see the entire diff)
So in order to fix this, while still avoiding deadlocks in the case where
the fiemap buffer is memory mapped to the same file, change fiemap to work
like the following:
1) Always lock the whole range in the inode's io tree before starting to
iterate the inode's subvolume tree searching for file extent items,
just like we did before commit b0ad381fa769 ("btrfs: fix deadlock with
fiemap and extent locking");
2) Now instead of writing to the fiemap buffer every time we have an extent
to report, write instead to a temporary buffer (1 page), and when that
buffer becomes full, stop iterating the file extent items, unlock the
range in the io tree, release the search path, submit all the entries
kept in that buffer to the fiemap buffer, and then resume the search
for file extent items after locking again the remainder of the range in
the io tree.
The buffer having a size of a page, allows for 146 entries in a system
with 4K pages. This is a large enough value to have a good performance
by avoiding too many restarts of the search for file extent items.
In other words this preserves the huge performance gains made in the
last two years to fiemap, while avoiding the deadlocks in case the
fiemap buffer is memory mapped to the same file (useless in practice,
but possible and exercised by fuzz testing and syzbot).
Fixes: b0ad381fa769 ("btrfs: fix deadlock with fiemap and extent locking")
Reviewed-by: Josef Bacik <josef@toxicpanda.com>
Signed-off-by: Filipe Manana <fdmanana@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)

| -rw-r--r-- | [fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/btrfs/extent_io.c?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3) | 221 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 160 insertions, 61 deletions

| diff --git a/fs/btrfs/extent\_io.c b/fs/btrfs/extent\_io.cindex 8b4bef05e22217..7761d7d93ba989 100644--- a/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=50a5eeb566eb8e36d3575475dcfd7afb36d76fe9)+++ b/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=ced63fffd63072c0ca55d5a451010d71bf08c0b3)@@ -2453,12 +2453,65 @@ next: return try\_release\_extent\_state(tree, page, mask); } +struct btrfs\_fiemap\_entry {+ u64 offset;+ u64 phys;+ u64 len;+ u32 flags;+};+ /\*- \* To cache previous fiemap extent+ \* Indicate the caller of emit\_fiemap\_extent() that it needs to unlock the file+ \* range from the inode's io tree, unlock the subvolume tree search path, flush+ \* the fiemap cache and relock the file range and research the subvolume tree.+ \* The value here is something negative that can't be confused with a valid+ \* errno value and different from 1 because that's also a return value from+ \* fiemap\_fill\_next\_extent() and also it's often used to mean some btree search+ \* did not find a key, so make it some distinct negative value.+ \*/+#define BTRFS\_FIEMAP\_FLUSH\_CACHE (-(MAX\_ERRNO + 1))++/\*+ \* Used to:+ \*+ \* - Cache the next entry to be emitted to the fiemap buffer, so that we can+ \* merge extents that are contiguous and can be grouped as a single one; \*- \* Will be used for merging fiemap extent+ \* - Store extents ready to be written to the fiemap buffer in an intermediary+ \* buffer. This intermediary buffer is to ensure that in case the fiemap+ \* buffer is memory mapped to the fiemap target file, we don't deadlock+ \* during btrfs\_page\_mkwrite(). This is because during fiemap we are locking+ \* an extent range in order to prevent races with delalloc flushing and+ \* ordered extent completion, which is needed in order to reliably detect+ \* delalloc in holes and prealloc extents. And this can lead to a deadlock+ \* if the fiemap buffer is memory mapped to the file we are running fiemap+ \* against (a silly, useless in practice scenario, but possible) because+ \* btrfs\_page\_mkwrite() will try to lock the same extent range. \*/ struct fiemap\_cache {+ /\* An array of ready fiemap entries. \*/+ struct btrfs\_fiemap\_entry \*entries;+ /\* Number of entries in the entries array. \*/+ int entries\_size;+ /\* Index of the next entry in the entries array to write to. \*/+ int entries\_pos;+ /\*+ \* Once the entries array is full, this indicates what's the offset for+ \* the next file extent item we must search for in the inode's subvolume+ \* tree after unlocking the extent range in the inode's io tree and+ \* releasing the search path.+ \*/+ u64 next\_search\_offset;+ /\*+ \* This matches struct fiemap\_extent\_info::fi\_mapped\_extents, we use it+ \* to count ourselves emitted extents and stop instead of relying on+ \* fiemap\_fill\_next\_extent() because we buffer ready fiemap entries at+ \* the @entries array, and we want to stop as soon as we hit the max+ \* amount of extents to map, not just to save time but also to make the+ \* logic at extent\_fiemap() simpler.+ \*/+ unsigned int extents\_mapped;+ /\* Fields for the cached extent (unsubmitted, not ready, extent). \*/ u64 offset; u64 phys; u64 len;@@ -2466,6 +2519,28 @@ struct fiemap\_cache { bool cached; }; +static int flush\_fiemap\_cache(struct fiemap\_extent\_info \*fieinfo,+ struct fiemap\_cache \*cache)+{+ for (int i = 0; i < cache->entries\_pos; i++) {+ struct btrfs\_fiemap\_entry \*entry = &cache->entries[i];+ int ret;++ ret = fiemap\_fill\_next\_extent(fieinfo, entry->offset,+ entry->phys, entry->len,+ entry->flags);+ /\*+ \* Ignore 1 (reached max entries) because we keep track of that+ \* ourselves in emit\_fiemap\_extent().+ \*/+ if (ret < 0)+ return ret;+ }+ cache->entries\_pos = 0;++ return 0;+}+ /\* \* Helper to submit fiemap extent. \*@@ -2480,8 +2555,8 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo, struct fiemap\_cache \*cache, u64 offset, u64 phys, u64 len, u32 flags) {+ struct btrfs\_fiemap\_entry \*entry; u64 cache\_end;- int ret = 0;  /\* Set at the end of extent\_fiemap(). \*/ ASSERT((flags & FIEMAP\_EXTENT\_LAST) == 0);@@ -2494,7 +2569,9 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo, \* find an extent that starts at an offset behind the end offset of the \* previous extent we processed. This happens if fiemap is called \* without FIEMAP\_FLAG\_SYNC and there are ordered extents completing- \* while we call btrfs\_next\_leaf() (through fiemap\_next\_leaf\_item()).+ \* after we had to unlock the file range, release the search path, emit+ \* the fiemap extents stored in the buffer (cache->entries array) and+ \* the lock the remainder of the range and re-search the btree. \* \* For example we are in leaf X processing its last item, which is the \* file extent item for file range [512K, 1M[, and after@@ -2607,11 +2684,35 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo,  emit: /\* Not mergeable, need to submit cached one \*/- ret = fiemap\_fill\_next\_extent(fieinfo, cache->offset, cache->phys,- cache->len, cache->flags);- cache->cached = false;- if (ret)- return ret;++ if (cache->entries\_pos == cache->entries\_size) {+ /\*+ \* We will need to research for the end offset of the last+ \* stored extent and not from the current offset, because after+ \* unlocking the range and releasing the path, if there's a hole+ \* between that end offset and this current offset, a new extent+ \* may have been inserted due to a new write, so we don't want+ \* to miss it.+ \*/+ entry = &cache->entries[cache->entries\_size - 1];+ cache->next\_search\_offset = entry->offset + entry->len;+ cache->cached = false;++ return BTRFS\_FIEMAP\_FLUSH\_CACHE;+ }++ entry = &cache->entries[cache->entries\_pos];+ entry->offset = cache->offset;+ entry->phys = cache->phys;+ entry->len = cache->len;+ entry->flags = cache->flags;+ cache->entries\_pos++;+ cache->extents\_mapped++;++ if (cache->extents\_mapped == fieinfo->fi\_extents\_max) {+ cache->cached = false;+ return 1;+ } assign: cache->cached = true; cache->offset = offset;@@ -2737,8 +2838,8 @@ static int fiemap\_search\_slot(struct btrfs\_inode \*inode, struct btrfs\_path \*path \* neighbour leaf). \* We also need the private clone because holding a read lock on an \* extent buffer of the subvolume's b+tree will make lockdep unhappy- \* when we call fiemap\_fill\_next\_extent(), because that may cause a page- \* fault when filling the user space buffer with fiemap data.+ \* when we check if extents are shared, as backref walking may need to+ \* lock the same leaf we are processing. \*/ clone = btrfs\_clone\_extent\_buffer(path->nodes[0]); if (!clone)@@ -2778,34 +2879,16 @@ static int fiemap\_process\_hole(struct btrfs\_inode \*inode, \* it beyond i\_size. \*/ while (cur\_offset < end && cur\_offset < i\_size) {- struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end; u64 prealloc\_start;- u64 lockstart;- u64 lockend; u64 prealloc\_len = 0; bool delalloc; - lockstart = round\_down(cur\_offset, inode->root->fs\_info->sectorsize);- lockend = round\_up(end, inode->root->fs\_info->sectorsize);-- /\*- \* We are only locking for the delalloc range because that's the- \* only thing that can change here. With fiemap we have a lock- \* on the inode, so no buffered or direct writes can happen.- \*- \* However mmaps and normal page writeback will cause this to- \* change arbitrarily. We have to lock the extent lock here to- \* make sure that nobody messes with the tree while we're doing- \* btrfs\_find\_delalloc\_in\_range.- \*/- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, cur\_offset, end, delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) break; @@ -2973,6 +3056,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, u64 start, u64 len) { const u64 ino = btrfs\_ino(inode);+ struct extent\_state \*cached\_state = NULL; struct extent\_state \*delalloc\_cached\_state = NULL; struct btrfs\_path \*path; struct fiemap\_cache cache = { 0 };@@ -2985,26 +3069,33 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, bool stopped = false; int ret; + cache.entries\_size = PAGE\_SIZE / sizeof(struct btrfs\_fiemap\_entry);+ cache.entries = kmalloc\_array(cache.entries\_size,+ sizeof(struct btrfs\_fiemap\_entry),+ GFP\_KERNEL); backref\_ctx = btrfs\_alloc\_backref\_share\_check\_ctx(); path = btrfs\_alloc\_path();- if (!backref\_ctx || !path) {+ if (!cache.entries || !backref\_ctx || !path) { ret = -ENOMEM; goto out; } +restart: range\_start = round\_down(start, sectorsize); range\_end = round\_up(start + len, sectorsize); prev\_extent\_end = range\_start; + lock\_extent(&inode->io\_tree, range\_start, range\_end, &cached\_state);+ ret = fiemap\_find\_last\_extent\_offset(inode, path, &last\_extent\_end); if (ret < 0)- goto out;+ goto out\_unlock; btrfs\_release\_path(path);  path->reada = READA\_FORWARD; ret = fiemap\_search\_slot(inode, path, range\_start); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* \* No file extent item found, but we may have delalloc between@@ -3051,7 +3142,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, backref\_ctx, 0, 0, 0, prev\_extent\_end, hole\_end); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* fiemap\_fill\_next\_extent() told us to stop. \*/ stopped = true;@@ -3107,7 +3198,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, extent\_gen, backref\_ctx); if (ret < 0)- goto out;+ goto out\_unlock; else if (ret > 0) flags |= FIEMAP\_EXTENT\_SHARED; }@@ -3118,9 +3209,9 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, }  if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) {- /\* fiemap\_fill\_next\_extent() told us to stop. \*/+ /\* emit\_fiemap\_extent() told us to stop. \*/ stopped = true; break; }@@ -3129,12 +3220,12 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, next\_item: if (fatal\_signal\_pending(current)) { ret = -EINTR;- goto out;+ goto out\_unlock; }  ret = fiemap\_next\_leaf\_item(inode, path); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* No more file extent items for this inode. \*/ break;@@ -3143,22 +3234,12 @@ next\_item: }  check\_eof\_delalloc:- /\*- \* Release (and free) the path before emitting any final entries to- \* fiemap\_fill\_next\_extent() to keep lockdep happy. This is because- \* once we find no more file extent items exist, we may have a- \* non-cloned leaf, and fiemap\_fill\_next\_extent() can trigger page- \* faults when copying data to the user space buffer.- \*/- btrfs\_free\_path(path);- path = NULL;- if (!stopped && prev\_extent\_end < range\_end) { ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx, 0, 0, 0, prev\_extent\_end, range\_end - 1); if (ret < 0)- goto out;+ goto out\_unlock; prev\_extent\_end = range\_end; } @@ -3166,28 +3247,16 @@ check\_eof\_delalloc: const u64 i\_size = i\_size\_read(&inode->vfs\_inode);  if (prev\_extent\_end < i\_size) {- struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end;- u64 lockstart;- u64 lockend; bool delalloc; - lockstart = round\_down(prev\_extent\_end, sectorsize);- lockend = round\_up(i\_size, sectorsize);-- /\*- \* See the comment in fiemap\_process\_hole as to why- \* we're doing the locking here.- \*/- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, prev\_extent\_end, i\_size - 1, &delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) cache.flags |= FIEMAP\_EXTENT\_LAST; } else {@@ -3195,9 +3264,39 @@ check\_eof\_delalloc: } } +out\_unlock:+ unlock\_extent(&inode->io\_tree, range\_start, range\_end, &cached\_state);++ if (ret == BTRFS\_FIEMAP\_FLUSH\_CACHE) {+ btrfs\_release\_path(path);+ ret = flush\_fiemap\_cache(fieinfo, &cache);+ if (ret)+ goto out;+ len -= cache.next\_search\_offset - start;+ start = cache.next\_search\_offset;+ goto restart;+ } else if (ret < 0) {+ goto out;+ }++ /\*+ \* Must free the path before emitting to the fiemap buffer because we+ \* may have a non-cloned leaf and if the fiemap buffer is memory mapped+ \* to a file, a write into it (through btrfs\_page\_mkwrite()) may trigger+ \* waiting for an ordered extent that in order to complete needs to+ \* modify that leaf, therefore leading to a deadlock.+ \*/+ btrfs\_free\_path(path);+ path = NULL;++ ret = flush\_fiemap\_cache(fieinfo, &cache);+ if (ret)+ goto out;+ ret = emit\_last\_fiemap\_cache(fieinfo, &cache); out: free\_extent\_state(delalloc\_cached\_state);+ kfree(cache.entries); btrfs\_free\_backref\_share\_ctx(backref\_ctx); btrfs\_free\_path(path); return ret; |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 17:09:17 +0000



=== Content from git.kernel.org_3f45f938_20250111_171040.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=978b63f7464abcfd364a6c95f734282c50f3decf)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=978b63f7464abcfd364a6c95f734282c50f3decf)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=978b63f7464abcfd364a6c95f734282c50f3decf)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=978b63f7464abcfd364a6c95f734282c50f3decf)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Filipe Manana <fdmanana@suse.com> | 2024-02-28 11:37:56 +0000 |
| --- | --- | --- |
| committer | David Sterba <dsterba@suse.com> | 2024-03-05 18:12:37 +0100 |
| commit | [978b63f7464abcfd364a6c95f734282c50f3decf](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=978b63f7464abcfd364a6c95f734282c50f3decf) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=978b63f7464abcfd364a6c95f734282c50f3decf)) | |
| tree | [09655300bbc3a18172f63c90efd4bbc42a5f65ea](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=978b63f7464abcfd364a6c95f734282c50f3decf) | |
| parent | [ae6bd7f9b46a29af52ebfac25d395757e2031d0d](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=ae6bd7f9b46a29af52ebfac25d395757e2031d0d) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=978b63f7464abcfd364a6c95f734282c50f3decf&id2=ae6bd7f9b46a29af52ebfac25d395757e2031d0d)) | |
| download | [linux-978b63f7464abcfd364a6c95f734282c50f3decf.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-978b63f7464abcfd364a6c95f734282c50f3decf.tar.gz) | |

btrfs: fix race when detecting delalloc ranges during fiemapFor fiemap we recently stopped locking the target extent range for the
whole duration of the fiemap call, in order to avoid a deadlock in a
scenario where the fiemap buffer happens to be a memory mapped range of
the same file. This use case is very unlikely to be useful in practice but
it may be triggered by fuzz testing (syzbot, etc).
This however introduced a race that makes us miss delalloc ranges for
file regions that are currently holes, so the caller of fiemap will not
be aware that there's data for some file regions. This can be quite
serious for some use cases - for example in coreutils versions before 9.0,
the cp program used fiemap to detect holes and data in the source file,
copying only regions with data (extents or delalloc) from the source file
to the destination file in order to preserve holes (see the documentation
for its --sparse command line option). This means that if cp was used
with a source file that had delalloc in a hole, the destination file could
end up without that data, which is effectively a data loss issue, if it
happened to hit the race described below.
The race happens like this:
1) Fiemap is called, without the FIEMAP\_FLAG\_SYNC flag, for a file that
has delalloc in the file range [64M, 65M[, which is currently a hole;
2) Fiemap locks the inode in shared mode, then starts iterating the
inode's subvolume tree searching for file extent items, without having
the whole fiemap target range locked in the inode's io tree - the
change introduced recently by commit b0ad381fa769 ("btrfs: fix
deadlock with fiemap and extent locking"). It only locks ranges in
the io tree when it finds a hole or prealloc extent since that
commit;
3) Note that fiemap clones each leaf before using it, and this is to
avoid deadlocks when locking a file range in the inode's io tree and
the fiemap buffer is memory mapped to some file, because writing
to the page with btrfs\_page\_mkwrite() will wait on any ordered extent
for the page's range and the ordered extent needs to lock the range
and may need to modify the same leaf, therefore leading to a deadlock
on the leaf;
4) While iterating the file extent items in the cloned leaf before
finding the hole in the range [64M, 65M[, the delalloc in that range
is flushed and its ordered extent completes - meaning the corresponding
file extent item is in the inode's subvolume tree, but not present in
the cloned leaf that fiemap is iterating over;
5) When fiemap finds the hole in the [64M, 65M[ range by seeing the gap in
the cloned leaf (or a file extent item with disk\_bytenr == 0 in case
the NO\_HOLES feature is not enabled), it will lock that file range in
the inode's io tree and then search for delalloc by checking for the
EXTENT\_DELALLOC bit in the io tree for that range and ordered extents
(with btrfs\_find\_delalloc\_in\_range()). But it finds nothing since the
delalloc in that range was already flushed and the ordered extent
completed and is gone - as a result fiemap will not report that there's
delalloc or an extent for the range [64M, 65M[, so user space will be
mislead into thinking that there's a hole in that range.
This could actually be sporadically triggered with test case generic/094
from fstests, which reports a missing extent/delalloc range like this:
generic/094 2s ... - output mismatch (see /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad)
--- tests/generic/094.out 2020-06-10 19:29:03.830519425 +0100
+++ /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad 2024-02-28 11:00:00.381071525 +0000
@@ -1,3 +1,9 @@
QA output created by 094
fiemap run with sync
fiemap run without sync
+ERROR: couldn't find extent at 7
+map is 'HHDDHPPDPHPH'
+logical: [ 5.. 6] phys: 301517.. 301518 flags: 0x800 tot: 2
+logical: [ 8.. 8] phys: 301520.. 301520 flags: 0x800 tot: 1
...
(Run 'diff -u /home/fdmanana/git/hub/xfstests/tests/generic/094.out /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad' to see the entire diff)
So in order to fix this, while still avoiding deadlocks in the case where
the fiemap buffer is memory mapped to the same file, change fiemap to work
like the following:
1) Always lock the whole range in the inode's io tree before starting to
iterate the inode's subvolume tree searching for file extent items,
just like we did before commit b0ad381fa769 ("btrfs: fix deadlock with
fiemap and extent locking");
2) Now instead of writing to the fiemap buffer every time we have an extent
to report, write instead to a temporary buffer (1 page), and when that
buffer becomes full, stop iterating the file extent items, unlock the
range in the io tree, release the search path, submit all the entries
kept in that buffer to the fiemap buffer, and then resume the search
for file extent items after locking again the remainder of the range in
the io tree.
The buffer having a size of a page, allows for 146 entries in a system
with 4K pages. This is a large enough value to have a good performance
by avoiding too many restarts of the search for file extent items.
In other words this preserves the huge performance gains made in the
last two years to fiemap, while avoiding the deadlocks in case the
fiemap buffer is memory mapped to the same file (useless in practice,
but possible and exercised by fuzz testing and syzbot).
Fixes: b0ad381fa769 ("btrfs: fix deadlock with fiemap and extent locking")
Reviewed-by: Josef Bacik <josef@toxicpanda.com>
Signed-off-by: Filipe Manana <fdmanana@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=978b63f7464abcfd364a6c95f734282c50f3decf)

| -rw-r--r-- | [fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/btrfs/extent_io.c?id=978b63f7464abcfd364a6c95f734282c50f3decf) | 221 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 160 insertions, 61 deletions

| diff --git a/fs/btrfs/extent\_io.c b/fs/btrfs/extent\_io.cindex e6a2b6eb89e19b..fbb05b0f7ebc5c 100644--- a/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=ae6bd7f9b46a29af52ebfac25d395757e2031d0d)+++ b/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=978b63f7464abcfd364a6c95f734282c50f3decf)@@ -2453,12 +2453,65 @@ next: return try\_release\_extent\_state(tree, page, mask); } +struct btrfs\_fiemap\_entry {+ u64 offset;+ u64 phys;+ u64 len;+ u32 flags;+};+ /\*- \* To cache previous fiemap extent+ \* Indicate the caller of emit\_fiemap\_extent() that it needs to unlock the file+ \* range from the inode's io tree, unlock the subvolume tree search path, flush+ \* the fiemap cache and relock the file range and research the subvolume tree.+ \* The value here is something negative that can't be confused with a valid+ \* errno value and different from 1 because that's also a return value from+ \* fiemap\_fill\_next\_extent() and also it's often used to mean some btree search+ \* did not find a key, so make it some distinct negative value.+ \*/+#define BTRFS\_FIEMAP\_FLUSH\_CACHE (-(MAX\_ERRNO + 1))++/\*+ \* Used to:+ \*+ \* - Cache the next entry to be emitted to the fiemap buffer, so that we can+ \* merge extents that are contiguous and can be grouped as a single one; \*- \* Will be used for merging fiemap extent+ \* - Store extents ready to be written to the fiemap buffer in an intermediary+ \* buffer. This intermediary buffer is to ensure that in case the fiemap+ \* buffer is memory mapped to the fiemap target file, we don't deadlock+ \* during btrfs\_page\_mkwrite(). This is because during fiemap we are locking+ \* an extent range in order to prevent races with delalloc flushing and+ \* ordered extent completion, which is needed in order to reliably detect+ \* delalloc in holes and prealloc extents. And this can lead to a deadlock+ \* if the fiemap buffer is memory mapped to the file we are running fiemap+ \* against (a silly, useless in practice scenario, but possible) because+ \* btrfs\_page\_mkwrite() will try to lock the same extent range. \*/ struct fiemap\_cache {+ /\* An array of ready fiemap entries. \*/+ struct btrfs\_fiemap\_entry \*entries;+ /\* Number of entries in the entries array. \*/+ int entries\_size;+ /\* Index of the next entry in the entries array to write to. \*/+ int entries\_pos;+ /\*+ \* Once the entries array is full, this indicates what's the offset for+ \* the next file extent item we must search for in the inode's subvolume+ \* tree after unlocking the extent range in the inode's io tree and+ \* releasing the search path.+ \*/+ u64 next\_search\_offset;+ /\*+ \* This matches struct fiemap\_extent\_info::fi\_mapped\_extents, we use it+ \* to count ourselves emitted extents and stop instead of relying on+ \* fiemap\_fill\_next\_extent() because we buffer ready fiemap entries at+ \* the @entries array, and we want to stop as soon as we hit the max+ \* amount of extents to map, not just to save time but also to make the+ \* logic at extent\_fiemap() simpler.+ \*/+ unsigned int extents\_mapped;+ /\* Fields for the cached extent (unsubmitted, not ready, extent). \*/ u64 offset; u64 phys; u64 len;@@ -2466,6 +2519,28 @@ struct fiemap\_cache { bool cached; }; +static int flush\_fiemap\_cache(struct fiemap\_extent\_info \*fieinfo,+ struct fiemap\_cache \*cache)+{+ for (int i = 0; i < cache->entries\_pos; i++) {+ struct btrfs\_fiemap\_entry \*entry = &cache->entries[i];+ int ret;++ ret = fiemap\_fill\_next\_extent(fieinfo, entry->offset,+ entry->phys, entry->len,+ entry->flags);+ /\*+ \* Ignore 1 (reached max entries) because we keep track of that+ \* ourselves in emit\_fiemap\_extent().+ \*/+ if (ret < 0)+ return ret;+ }+ cache->entries\_pos = 0;++ return 0;+}+ /\* \* Helper to submit fiemap extent. \*@@ -2480,8 +2555,8 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo, struct fiemap\_cache \*cache, u64 offset, u64 phys, u64 len, u32 flags) {+ struct btrfs\_fiemap\_entry \*entry; u64 cache\_end;- int ret = 0;  /\* Set at the end of extent\_fiemap(). \*/ ASSERT((flags & FIEMAP\_EXTENT\_LAST) == 0);@@ -2494,7 +2569,9 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo, \* find an extent that starts at an offset behind the end offset of the \* previous extent we processed. This happens if fiemap is called \* without FIEMAP\_FLAG\_SYNC and there are ordered extents completing- \* while we call btrfs\_next\_leaf() (through fiemap\_next\_leaf\_item()).+ \* after we had to unlock the file range, release the search path, emit+ \* the fiemap extents stored in the buffer (cache->entries array) and+ \* the lock the remainder of the range and re-search the btree. \* \* For example we are in leaf X processing its last item, which is the \* file extent item for file range [512K, 1M[, and after@@ -2607,11 +2684,35 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo,  emit: /\* Not mergeable, need to submit cached one \*/- ret = fiemap\_fill\_next\_extent(fieinfo, cache->offset, cache->phys,- cache->len, cache->flags);- cache->cached = false;- if (ret)- return ret;++ if (cache->entries\_pos == cache->entries\_size) {+ /\*+ \* We will need to research for the end offset of the last+ \* stored extent and not from the current offset, because after+ \* unlocking the range and releasing the path, if there's a hole+ \* between that end offset and this current offset, a new extent+ \* may have been inserted due to a new write, so we don't want+ \* to miss it.+ \*/+ entry = &cache->entries[cache->entries\_size - 1];+ cache->next\_search\_offset = entry->offset + entry->len;+ cache->cached = false;++ return BTRFS\_FIEMAP\_FLUSH\_CACHE;+ }++ entry = &cache->entries[cache->entries\_pos];+ entry->offset = cache->offset;+ entry->phys = cache->phys;+ entry->len = cache->len;+ entry->flags = cache->flags;+ cache->entries\_pos++;+ cache->extents\_mapped++;++ if (cache->extents\_mapped == fieinfo->fi\_extents\_max) {+ cache->cached = false;+ return 1;+ } assign: cache->cached = true; cache->offset = offset;@@ -2737,8 +2838,8 @@ static int fiemap\_search\_slot(struct btrfs\_inode \*inode, struct btrfs\_path \*path \* neighbour leaf). \* We also need the private clone because holding a read lock on an \* extent buffer of the subvolume's b+tree will make lockdep unhappy- \* when we call fiemap\_fill\_next\_extent(), because that may cause a page- \* fault when filling the user space buffer with fiemap data.+ \* when we check if extents are shared, as backref walking may need to+ \* lock the same leaf we are processing. \*/ clone = btrfs\_clone\_extent\_buffer(path->nodes[0]); if (!clone)@@ -2778,34 +2879,16 @@ static int fiemap\_process\_hole(struct btrfs\_inode \*inode, \* it beyond i\_size. \*/ while (cur\_offset < end && cur\_offset < i\_size) {- struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end; u64 prealloc\_start;- u64 lockstart;- u64 lockend; u64 prealloc\_len = 0; bool delalloc; - lockstart = round\_down(cur\_offset, inode->root->fs\_info->sectorsize);- lockend = round\_up(end, inode->root->fs\_info->sectorsize);-- /\*- \* We are only locking for the delalloc range because that's the- \* only thing that can change here. With fiemap we have a lock- \* on the inode, so no buffered or direct writes can happen.- \*- \* However mmaps and normal page writeback will cause this to- \* change arbitrarily. We have to lock the extent lock here to- \* make sure that nobody messes with the tree while we're doing- \* btrfs\_find\_delalloc\_in\_range.- \*/- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, cur\_offset, end, delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) break; @@ -2973,6 +3056,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, u64 start, u64 len) { const u64 ino = btrfs\_ino(inode);+ struct extent\_state \*cached\_state = NULL; struct extent\_state \*delalloc\_cached\_state = NULL; struct btrfs\_path \*path; struct fiemap\_cache cache = { 0 };@@ -2985,26 +3069,33 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, bool stopped = false; int ret; + cache.entries\_size = PAGE\_SIZE / sizeof(struct btrfs\_fiemap\_entry);+ cache.entries = kmalloc\_array(cache.entries\_size,+ sizeof(struct btrfs\_fiemap\_entry),+ GFP\_KERNEL); backref\_ctx = btrfs\_alloc\_backref\_share\_check\_ctx(); path = btrfs\_alloc\_path();- if (!backref\_ctx || !path) {+ if (!cache.entries || !backref\_ctx || !path) { ret = -ENOMEM; goto out; } +restart: range\_start = round\_down(start, sectorsize); range\_end = round\_up(start + len, sectorsize); prev\_extent\_end = range\_start; + lock\_extent(&inode->io\_tree, range\_start, range\_end, &cached\_state);+ ret = fiemap\_find\_last\_extent\_offset(inode, path, &last\_extent\_end); if (ret < 0)- goto out;+ goto out\_unlock; btrfs\_release\_path(path);  path->reada = READA\_FORWARD; ret = fiemap\_search\_slot(inode, path, range\_start); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* \* No file extent item found, but we may have delalloc between@@ -3051,7 +3142,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, backref\_ctx, 0, 0, 0, prev\_extent\_end, hole\_end); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* fiemap\_fill\_next\_extent() told us to stop. \*/ stopped = true;@@ -3107,7 +3198,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, extent\_gen, backref\_ctx); if (ret < 0)- goto out;+ goto out\_unlock; else if (ret > 0) flags |= FIEMAP\_EXTENT\_SHARED; }@@ -3118,9 +3209,9 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, }  if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) {- /\* fiemap\_fill\_next\_extent() told us to stop. \*/+ /\* emit\_fiemap\_extent() told us to stop. \*/ stopped = true; break; }@@ -3129,12 +3220,12 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, next\_item: if (fatal\_signal\_pending(current)) { ret = -EINTR;- goto out;+ goto out\_unlock; }  ret = fiemap\_next\_leaf\_item(inode, path); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* No more file extent items for this inode. \*/ break;@@ -3143,22 +3234,12 @@ next\_item: }  check\_eof\_delalloc:- /\*- \* Release (and free) the path before emitting any final entries to- \* fiemap\_fill\_next\_extent() to keep lockdep happy. This is because- \* once we find no more file extent items exist, we may have a- \* non-cloned leaf, and fiemap\_fill\_next\_extent() can trigger page- \* faults when copying data to the user space buffer.- \*/- btrfs\_free\_path(path);- path = NULL;- if (!stopped && prev\_extent\_end < range\_end) { ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx, 0, 0, 0, prev\_extent\_end, range\_end - 1); if (ret < 0)- goto out;+ goto out\_unlock; prev\_extent\_end = range\_end; } @@ -3166,28 +3247,16 @@ check\_eof\_delalloc: const u64 i\_size = i\_size\_read(&inode->vfs\_inode);  if (prev\_extent\_end < i\_size) {- struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end;- u64 lockstart;- u64 lockend; bool delalloc; - lockstart = round\_down(prev\_extent\_end, sectorsize);- lockend = round\_up(i\_size, sectorsize);-- /\*- \* See the comment in fiemap\_process\_hole as to why- \* we're doing the locking here.- \*/- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, prev\_extent\_end, i\_size - 1, &delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) cache.flags |= FIEMAP\_EXTENT\_LAST; } else {@@ -3195,9 +3264,39 @@ check\_eof\_delalloc: } } +out\_unlock:+ unlock\_extent(&inode->io\_tree, range\_start, range\_end, &cached\_state);++ if (ret == BTRFS\_FIEMAP\_FLUSH\_CACHE) {+ btrfs\_release\_path(path);+ ret = flush\_fiemap\_cache(fieinfo, &cache);+ if (ret)+ goto out;+ len -= cache.next\_search\_offset - start;+ start = cache.next\_search\_offset;+ goto restart;+ } else if (ret < 0) {+ goto out;+ }++ /\*+ \* Must free the path before emitting to the fiemap buffer because we+ \* may have a non-cloned leaf and if the fiemap buffer is memory mapped+ \* to a file, a write into it (through btrfs\_page\_mkwrite()) may trigger+ \* waiting for an ordered extent that in order to complete needs to+ \* modify that leaf, therefore leading to a deadlock.+ \*/+ btrfs\_free\_path(path);+ path = NULL;++ ret = flush\_fiemap\_cache(fieinfo, &cache);+ if (ret)+ goto out;+ ret = emit\_last\_fiemap\_cache(fieinfo, &cache); out: free\_extent\_state(delalloc\_cached\_state);+ kfree(cache.entries); btrfs\_free\_backref\_share\_ctx(backref\_ctx); btrfs\_free\_path(path); return ret; |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 17:09:17 +0000



=== Content from git.kernel.org_82b821e9_20250111_171039.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=49d640d2946c35a17b051d54171a032dd95b0f50)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=49d640d2946c35a17b051d54171a032dd95b0f50)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=49d640d2946c35a17b051d54171a032dd95b0f50)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=49d640d2946c35a17b051d54171a032dd95b0f50)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Filipe Manana <fdmanana@suse.com> | 2024-02-28 11:37:56 +0000 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-04-10 16:35:46 +0200 |
| commit | [49d640d2946c35a17b051d54171a032dd95b0f50](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=49d640d2946c35a17b051d54171a032dd95b0f50) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=49d640d2946c35a17b051d54171a032dd95b0f50)) | |
| tree | [8be53873c87d97ccfeba59e644eaaa7ff879cf58](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=49d640d2946c35a17b051d54171a032dd95b0f50) | |
| parent | [8cc484e85e0c6bf72ec7c3c8c697865355873cfb](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=8cc484e85e0c6bf72ec7c3c8c697865355873cfb) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=49d640d2946c35a17b051d54171a032dd95b0f50&id2=8cc484e85e0c6bf72ec7c3c8c697865355873cfb)) | |
| download | [linux-49d640d2946c35a17b051d54171a032dd95b0f50.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-49d640d2946c35a17b051d54171a032dd95b0f50.tar.gz) | |

btrfs: fix race when detecting delalloc ranges during fiemap[ Upstream commit 978b63f7464abcfd364a6c95f734282c50f3decf ]
For fiemap we recently stopped locking the target extent range for the
whole duration of the fiemap call, in order to avoid a deadlock in a
scenario where the fiemap buffer happens to be a memory mapped range of
the same file. This use case is very unlikely to be useful in practice but
it may be triggered by fuzz testing (syzbot, etc).
This however introduced a race that makes us miss delalloc ranges for
file regions that are currently holes, so the caller of fiemap will not
be aware that there's data for some file regions. This can be quite
serious for some use cases - for example in coreutils versions before 9.0,
the cp program used fiemap to detect holes and data in the source file,
copying only regions with data (extents or delalloc) from the source file
to the destination file in order to preserve holes (see the documentation
for its --sparse command line option). This means that if cp was used
with a source file that had delalloc in a hole, the destination file could
end up without that data, which is effectively a data loss issue, if it
happened to hit the race described below.
The race happens like this:
1) Fiemap is called, without the FIEMAP\_FLAG\_SYNC flag, for a file that
has delalloc in the file range [64M, 65M[, which is currently a hole;
2) Fiemap locks the inode in shared mode, then starts iterating the
inode's subvolume tree searching for file extent items, without having
the whole fiemap target range locked in the inode's io tree - the
change introduced recently by commit b0ad381fa769 ("btrfs: fix
deadlock with fiemap and extent locking"). It only locks ranges in
the io tree when it finds a hole or prealloc extent since that
commit;
3) Note that fiemap clones each leaf before using it, and this is to
avoid deadlocks when locking a file range in the inode's io tree and
the fiemap buffer is memory mapped to some file, because writing
to the page with btrfs\_page\_mkwrite() will wait on any ordered extent
for the page's range and the ordered extent needs to lock the range
and may need to modify the same leaf, therefore leading to a deadlock
on the leaf;
4) While iterating the file extent items in the cloned leaf before
finding the hole in the range [64M, 65M[, the delalloc in that range
is flushed and its ordered extent completes - meaning the corresponding
file extent item is in the inode's subvolume tree, but not present in
the cloned leaf that fiemap is iterating over;
5) When fiemap finds the hole in the [64M, 65M[ range by seeing the gap in
the cloned leaf (or a file extent item with disk\_bytenr == 0 in case
the NO\_HOLES feature is not enabled), it will lock that file range in
the inode's io tree and then search for delalloc by checking for the
EXTENT\_DELALLOC bit in the io tree for that range and ordered extents
(with btrfs\_find\_delalloc\_in\_range()). But it finds nothing since the
delalloc in that range was already flushed and the ordered extent
completed and is gone - as a result fiemap will not report that there's
delalloc or an extent for the range [64M, 65M[, so user space will be
mislead into thinking that there's a hole in that range.
This could actually be sporadically triggered with test case generic/094
from fstests, which reports a missing extent/delalloc range like this:
# generic/094 2s ... - output mismatch (see /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad)
# --- tests/generic/094.out 2020-06-10 19:29:03.830519425 +0100
# +++ /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad 2024-02-28 11:00:00.381071525 +0000
# @@ -1,3 +1,9 @@
# QA output created by 094
# fiemap run with sync
# fiemap run without sync
# +ERROR: couldn't find extent at 7
# +map is 'HHDDHPPDPHPH'
# +logical: [ 5.. 6] phys: 301517.. 301518 flags: 0x800 tot: 2
# +logical: [ 8.. 8] phys: 301520.. 301520 flags: 0x800 tot: 1
# ...
# (Run 'diff -u /home/fdmanana/git/hub/xfstests/tests/generic/094.out /home/fdmanana/git/hub/xfstests/results//generic/094.out.bad' to see the entire diff)
So in order to fix this, while still avoiding deadlocks in the case where
the fiemap buffer is memory mapped to the same file, change fiemap to work
like the following:
1) Always lock the whole range in the inode's io tree before starting to
iterate the inode's subvolume tree searching for file extent items,
just like we did before commit b0ad381fa769 ("btrfs: fix deadlock with
fiemap and extent locking");
2) Now instead of writing to the fiemap buffer every time we have an extent
to report, write instead to a temporary buffer (1 page), and when that
buffer becomes full, stop iterating the file extent items, unlock the
range in the io tree, release the search path, submit all the entries
kept in that buffer to the fiemap buffer, and then resume the search
for file extent items after locking again the remainder of the range in
the io tree.
The buffer having a size of a page, allows for 146 entries in a system
with 4K pages. This is a large enough value to have a good performance
by avoiding too many restarts of the search for file extent items.
In other words this preserves the huge performance gains made in the
last two years to fiemap, while avoiding the deadlocks in case the
fiemap buffer is memory mapped to the same file (useless in practice,
but possible and exercised by fuzz testing and syzbot).
Fixes: b0ad381fa769 ("btrfs: fix deadlock with fiemap and extent locking")
Reviewed-by: Josef Bacik <josef@toxicpanda.com>
Signed-off-by: Filipe Manana <fdmanana@suse.com>
Signed-off-by: David Sterba <dsterba@suse.com>
Signed-off-by: Sasha Levin <sashal@kernel.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=49d640d2946c35a17b051d54171a032dd95b0f50)

| -rw-r--r-- | [fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/fs/btrfs/extent_io.c?id=49d640d2946c35a17b051d54171a032dd95b0f50) | 221 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |

1 files changed, 160 insertions, 61 deletions

| diff --git a/fs/btrfs/extent\_io.c b/fs/btrfs/extent\_io.cindex 45d427c3033d7f..5acb2cb79d4bfe 100644--- a/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=8cc484e85e0c6bf72ec7c3c8c697865355873cfb)+++ b/[fs/btrfs/extent\_io.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/fs/btrfs/extent_io.c?id=49d640d2946c35a17b051d54171a032dd95b0f50)@@ -2410,12 +2410,65 @@ next: return try\_release\_extent\_state(tree, page, mask); } +struct btrfs\_fiemap\_entry {+ u64 offset;+ u64 phys;+ u64 len;+ u32 flags;+};+ /\*- \* To cache previous fiemap extent+ \* Indicate the caller of emit\_fiemap\_extent() that it needs to unlock the file+ \* range from the inode's io tree, unlock the subvolume tree search path, flush+ \* the fiemap cache and relock the file range and research the subvolume tree.+ \* The value here is something negative that can't be confused with a valid+ \* errno value and different from 1 because that's also a return value from+ \* fiemap\_fill\_next\_extent() and also it's often used to mean some btree search+ \* did not find a key, so make it some distinct negative value.+ \*/+#define BTRFS\_FIEMAP\_FLUSH\_CACHE (-(MAX\_ERRNO + 1))++/\*+ \* Used to:+ \*+ \* - Cache the next entry to be emitted to the fiemap buffer, so that we can+ \* merge extents that are contiguous and can be grouped as a single one; \*- \* Will be used for merging fiemap extent+ \* - Store extents ready to be written to the fiemap buffer in an intermediary+ \* buffer. This intermediary buffer is to ensure that in case the fiemap+ \* buffer is memory mapped to the fiemap target file, we don't deadlock+ \* during btrfs\_page\_mkwrite(). This is because during fiemap we are locking+ \* an extent range in order to prevent races with delalloc flushing and+ \* ordered extent completion, which is needed in order to reliably detect+ \* delalloc in holes and prealloc extents. And this can lead to a deadlock+ \* if the fiemap buffer is memory mapped to the file we are running fiemap+ \* against (a silly, useless in practice scenario, but possible) because+ \* btrfs\_page\_mkwrite() will try to lock the same extent range. \*/ struct fiemap\_cache {+ /\* An array of ready fiemap entries. \*/+ struct btrfs\_fiemap\_entry \*entries;+ /\* Number of entries in the entries array. \*/+ int entries\_size;+ /\* Index of the next entry in the entries array to write to. \*/+ int entries\_pos;+ /\*+ \* Once the entries array is full, this indicates what's the offset for+ \* the next file extent item we must search for in the inode's subvolume+ \* tree after unlocking the extent range in the inode's io tree and+ \* releasing the search path.+ \*/+ u64 next\_search\_offset;+ /\*+ \* This matches struct fiemap\_extent\_info::fi\_mapped\_extents, we use it+ \* to count ourselves emitted extents and stop instead of relying on+ \* fiemap\_fill\_next\_extent() because we buffer ready fiemap entries at+ \* the @entries array, and we want to stop as soon as we hit the max+ \* amount of extents to map, not just to save time but also to make the+ \* logic at extent\_fiemap() simpler.+ \*/+ unsigned int extents\_mapped;+ /\* Fields for the cached extent (unsubmitted, not ready, extent). \*/ u64 offset; u64 phys; u64 len;@@ -2423,6 +2476,28 @@ struct fiemap\_cache { bool cached; }; +static int flush\_fiemap\_cache(struct fiemap\_extent\_info \*fieinfo,+ struct fiemap\_cache \*cache)+{+ for (int i = 0; i < cache->entries\_pos; i++) {+ struct btrfs\_fiemap\_entry \*entry = &cache->entries[i];+ int ret;++ ret = fiemap\_fill\_next\_extent(fieinfo, entry->offset,+ entry->phys, entry->len,+ entry->flags);+ /\*+ \* Ignore 1 (reached max entries) because we keep track of that+ \* ourselves in emit\_fiemap\_extent().+ \*/+ if (ret < 0)+ return ret;+ }+ cache->entries\_pos = 0;++ return 0;+}+ /\* \* Helper to submit fiemap extent. \*@@ -2437,8 +2512,8 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo, struct fiemap\_cache \*cache, u64 offset, u64 phys, u64 len, u32 flags) {+ struct btrfs\_fiemap\_entry \*entry; u64 cache\_end;- int ret = 0;  /\* Set at the end of extent\_fiemap(). \*/ ASSERT((flags & FIEMAP\_EXTENT\_LAST) == 0);@@ -2451,7 +2526,9 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo, \* find an extent that starts at an offset behind the end offset of the \* previous extent we processed. This happens if fiemap is called \* without FIEMAP\_FLAG\_SYNC and there are ordered extents completing- \* while we call btrfs\_next\_leaf() (through fiemap\_next\_leaf\_item()).+ \* after we had to unlock the file range, release the search path, emit+ \* the fiemap extents stored in the buffer (cache->entries array) and+ \* the lock the remainder of the range and re-search the btree. \* \* For example we are in leaf X processing its last item, which is the \* file extent item for file range [512K, 1M[, and after@@ -2564,11 +2641,35 @@ static int emit\_fiemap\_extent(struct fiemap\_extent\_info \*fieinfo,  emit: /\* Not mergeable, need to submit cached one \*/- ret = fiemap\_fill\_next\_extent(fieinfo, cache->offset, cache->phys,- cache->len, cache->flags);- cache->cached = false;- if (ret)- return ret;++ if (cache->entries\_pos == cache->entries\_size) {+ /\*+ \* We will need to research for the end offset of the last+ \* stored extent and not from the current offset, because after+ \* unlocking the range and releasing the path, if there's a hole+ \* between that end offset and this current offset, a new extent+ \* may have been inserted due to a new write, so we don't want+ \* to miss it.+ \*/+ entry = &cache->entries[cache->entries\_size - 1];+ cache->next\_search\_offset = entry->offset + entry->len;+ cache->cached = false;++ return BTRFS\_FIEMAP\_FLUSH\_CACHE;+ }++ entry = &cache->entries[cache->entries\_pos];+ entry->offset = cache->offset;+ entry->phys = cache->phys;+ entry->len = cache->len;+ entry->flags = cache->flags;+ cache->entries\_pos++;+ cache->extents\_mapped++;++ if (cache->extents\_mapped == fieinfo->fi\_extents\_max) {+ cache->cached = false;+ return 1;+ } assign: cache->cached = true; cache->offset = offset;@@ -2694,8 +2795,8 @@ static int fiemap\_search\_slot(struct btrfs\_inode \*inode, struct btrfs\_path \*path \* neighbour leaf). \* We also need the private clone because holding a read lock on an \* extent buffer of the subvolume's b+tree will make lockdep unhappy- \* when we call fiemap\_fill\_next\_extent(), because that may cause a page- \* fault when filling the user space buffer with fiemap data.+ \* when we check if extents are shared, as backref walking may need to+ \* lock the same leaf we are processing. \*/ clone = btrfs\_clone\_extent\_buffer(path->nodes[0]); if (!clone)@@ -2735,34 +2836,16 @@ static int fiemap\_process\_hole(struct btrfs\_inode \*inode, \* it beyond i\_size. \*/ while (cur\_offset < end && cur\_offset < i\_size) {- struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end; u64 prealloc\_start;- u64 lockstart;- u64 lockend; u64 prealloc\_len = 0; bool delalloc; - lockstart = round\_down(cur\_offset, inode->root->fs\_info->sectorsize);- lockend = round\_up(end, inode->root->fs\_info->sectorsize);-- /\*- \* We are only locking for the delalloc range because that's the- \* only thing that can change here. With fiemap we have a lock- \* on the inode, so no buffered or direct writes can happen.- \*- \* However mmaps and normal page writeback will cause this to- \* change arbitrarily. We have to lock the extent lock here to- \* make sure that nobody messes with the tree while we're doing- \* btrfs\_find\_delalloc\_in\_range.- \*/- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, cur\_offset, end, delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) break; @@ -2930,6 +3013,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, u64 start, u64 len) { const u64 ino = btrfs\_ino(inode);+ struct extent\_state \*cached\_state = NULL; struct extent\_state \*delalloc\_cached\_state = NULL; struct btrfs\_path \*path; struct fiemap\_cache cache = { 0 };@@ -2942,26 +3026,33 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, bool stopped = false; int ret; + cache.entries\_size = PAGE\_SIZE / sizeof(struct btrfs\_fiemap\_entry);+ cache.entries = kmalloc\_array(cache.entries\_size,+ sizeof(struct btrfs\_fiemap\_entry),+ GFP\_KERNEL); backref\_ctx = btrfs\_alloc\_backref\_share\_check\_ctx(); path = btrfs\_alloc\_path();- if (!backref\_ctx || !path) {+ if (!cache.entries || !backref\_ctx || !path) { ret = -ENOMEM; goto out; } +restart: range\_start = round\_down(start, sectorsize); range\_end = round\_up(start + len, sectorsize); prev\_extent\_end = range\_start; + lock\_extent(&inode->io\_tree, range\_start, range\_end, &cached\_state);+ ret = fiemap\_find\_last\_extent\_offset(inode, path, &last\_extent\_end); if (ret < 0)- goto out;+ goto out\_unlock; btrfs\_release\_path(path);  path->reada = READA\_FORWARD; ret = fiemap\_search\_slot(inode, path, range\_start); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* \* No file extent item found, but we may have delalloc between@@ -3008,7 +3099,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, backref\_ctx, 0, 0, 0, prev\_extent\_end, hole\_end); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* fiemap\_fill\_next\_extent() told us to stop. \*/ stopped = true;@@ -3064,7 +3155,7 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, extent\_gen, backref\_ctx); if (ret < 0)- goto out;+ goto out\_unlock; else if (ret > 0) flags |= FIEMAP\_EXTENT\_SHARED; }@@ -3075,9 +3166,9 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, }  if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) {- /\* fiemap\_fill\_next\_extent() told us to stop. \*/+ /\* emit\_fiemap\_extent() told us to stop. \*/ stopped = true; break; }@@ -3086,12 +3177,12 @@ int extent\_fiemap(struct btrfs\_inode \*inode, struct fiemap\_extent\_info \*fieinfo, next\_item: if (fatal\_signal\_pending(current)) { ret = -EINTR;- goto out;+ goto out\_unlock; }  ret = fiemap\_next\_leaf\_item(inode, path); if (ret < 0) {- goto out;+ goto out\_unlock; } else if (ret > 0) { /\* No more file extent items for this inode. \*/ break;@@ -3100,22 +3191,12 @@ next\_item: }  check\_eof\_delalloc:- /\*- \* Release (and free) the path before emitting any final entries to- \* fiemap\_fill\_next\_extent() to keep lockdep happy. This is because- \* once we find no more file extent items exist, we may have a- \* non-cloned leaf, and fiemap\_fill\_next\_extent() can trigger page- \* faults when copying data to the user space buffer.- \*/- btrfs\_free\_path(path);- path = NULL;- if (!stopped && prev\_extent\_end < range\_end) { ret = fiemap\_process\_hole(inode, fieinfo, &cache, &delalloc\_cached\_state, backref\_ctx, 0, 0, 0, prev\_extent\_end, range\_end - 1); if (ret < 0)- goto out;+ goto out\_unlock; prev\_extent\_end = range\_end; } @@ -3123,28 +3204,16 @@ check\_eof\_delalloc: const u64 i\_size = i\_size\_read(&inode->vfs\_inode);  if (prev\_extent\_end < i\_size) {- struct extent\_state \*cached\_state = NULL; u64 delalloc\_start; u64 delalloc\_end;- u64 lockstart;- u64 lockend; bool delalloc; - lockstart = round\_down(prev\_extent\_end, sectorsize);- lockend = round\_up(i\_size, sectorsize);-- /\*- \* See the comment in fiemap\_process\_hole as to why- \* we're doing the locking here.- \*/- lock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); delalloc = btrfs\_find\_delalloc\_in\_range(inode, prev\_extent\_end, i\_size - 1, &delalloc\_cached\_state, &delalloc\_start, &delalloc\_end);- unlock\_extent(&inode->io\_tree, lockstart, lockend, &cached\_state); if (!delalloc) cache.flags |= FIEMAP\_EXTENT\_LAST; } else {@@ -3152,9 +3221,39 @@ check\_eof\_delalloc: } } +out\_unlock:+ unlock\_extent(&inode->io\_tree, range\_start, range\_end, &cached\_state);++ if (ret == BTRFS\_FIEMAP\_FLUSH\_CACHE) {+ btrfs\_release\_path(path);+ ret = flush\_fiemap\_cache(fieinfo, &cache);+ if (ret)+ goto out;+ len -= cache.next\_search\_offset - start;+ start = cache.next\_search\_offset;+ goto restart;+ } else if (ret < 0) {+ goto out;+ }++ /\*+ \* Must free the path before emitting to the fiemap buffer because we+ \* may have a non-cloned leaf and if the fiemap buffer is memory mapped+ \* to a file, a write into it (through btrfs\_page\_mkwrite()) may trigger+ \* waiting for an ordered extent that in order to complete needs to+ \* modify that leaf, therefore leading to a deadlock.+ \*/+ btrfs\_free\_path(path);+ path = NULL;++ ret = flush\_fiemap\_cache(fieinfo, &cache);+ if (ret)+ goto out;+ ret = emit\_last\_fiemap\_cache(fieinfo, &cache); out: free\_extent\_state(delalloc\_cached\_state);+ kfree(cache.entries); btrfs\_free\_backref\_share\_ctx(backref\_ctx); btrfs\_free\_path(path); return ret; |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 17:09:16 +0000


