
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_matrix.h)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Ftensorflow%2Ftensorflow%2Fblob%2Fmaster%2Ftensorflow%2Fcore%2Fkernels%2Fsparse%2Fsparse_matrix.h)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fblob%2Fshow&source=header-repo&source_repo=tensorflow%2Ftensorflow)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[tensorflow](/tensorflow)
/
**[tensorflow](/tensorflow/tensorflow)**
Public

* [Notifications](/login?return_to=%2Ftensorflow%2Ftensorflow) You must be signed in to change notification settings
* [Fork
  74.4k](/login?return_to=%2Ftensorflow%2Ftensorflow)
* [Star
   187k](/login?return_to=%2Ftensorflow%2Ftensorflow)

* [Code](/tensorflow/tensorflow)
* [Issues
  835](/tensorflow/tensorflow/issues)
* [Pull requests
  5k+](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects
  2](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

Additional navigation options

* [Code](/tensorflow/tensorflow)
* [Issues](/tensorflow/tensorflow/issues)
* [Pull requests](/tensorflow/tensorflow/pulls)
* [Actions](/tensorflow/tensorflow/actions)
* [Projects](/tensorflow/tensorflow/projects)
* [Security](/tensorflow/tensorflow/security)
* [Insights](/tensorflow/tensorflow/pulse)

## Files

 master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
5. /[sparse](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels/sparse)
/
# sparse\_matrix.h

 Blame  Blame
## Latest commit

## History

[History](/tensorflow/tensorflow/commits/master/tensorflow/core/kernels/sparse/sparse_matrix.h)655 lines (589 loc) · 22.5 KB master
## Breadcrumbs

1. [tensorflow](/tensorflow/tensorflow/tree/master)
2. /[tensorflow](/tensorflow/tensorflow/tree/master/tensorflow)
3. /[core](/tensorflow/tensorflow/tree/master/tensorflow/core)
4. /[kernels](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels)
5. /[sparse](/tensorflow/tensorflow/tree/master/tensorflow/core/kernels/sparse)
/
# sparse\_matrix.h

Top
## File metadata and controls

* Code
* Blame

655 lines (589 loc) · 22.5 KB[Raw](https://github.com/tensorflow/tensorflow/raw/refs/heads/master/tensorflow/core/kernels/sparse/sparse_matrix.h)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655/\* Copyright 2019 The TensorFlow Authors. All Rights Reserved.
Licensed under the Apache License, Version 2.0 (the "License");you may not use this file except in compliance with the License.You may obtain a copy of the License at
 http://www.apache.org/licenses/LICENSE-2.0
Unless required by applicable law or agreed to in writing, softwaredistributed under the License is distributed on an "AS IS" BASIS,WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.See the License for the specific language governing permissions andlimitations under the License.==============================================================================\*/
#ifndef TENSORFLOW\_CORE\_KERNELS\_SPARSE\_SPARSE\_MATRIX\_H\_#define TENSORFLOW\_CORE\_KERNELS\_SPARSE\_SPARSE\_MATRIX\_H\_
#define EIGEN\_USE\_THREADS
#if GOOGLE\_CUDA || TENSORFLOW\_USE\_ROCM#define EIGEN\_USE\_GPU#endif
#include "unsupported/Eigen/CXX11/Tensor" // from @eigen\_archive#include "tensorflow/core/framework/op\_kernel.h"#include "tensorflow/core/framework/tensor.h"#include "tensorflow/core/framework/tensor\_shape.h"#include "tensorflow/core/framework/tensor\_types.h"#include "tensorflow/core/framework/variant.h"#include "tensorflow/core/framework/variant\_encode\_decode.h"#include "tensorflow/core/framework/variant\_op\_registry.h"#include "tensorflow/core/platform/errors.h"
namespace tensorflow {
class CSRSparseMatrix { // CreateCSRSparseMatrix is the main method used to construct a // CSRSparseMatrix. The representations for both 2D and 3D // (batched) CSR Sparse Matrices are the same: // // dtype: The datatype of the values. // dense\_shape: The dense shape of the matrix. // \* Host int64 vector, size 2 or 3. // \* Takes on values: (rows, cols) or (batch\_size, rows, cols). // batch\_pointers: Batch offset pointers into col\_indices and values. // \* Host int32 vector, size (batch\_size + 1). // \* Takes on values: (0, nnz[0], nnz[0] + nnz[1], ..., total\_nnz). // row\_pointers: Row offset pointers into col\_indices and values. // \* Device int32 vector, size ((rows + 1) \* batch\_size). // \* Each block of size (rows + 1) takes on values: // (0, num\_rows{b}[0], num\_rows{b}[0] + num\_rows{b}[1], ..., nnz[b]). // for b = 0 .. batch\_size - 1. // col\_indices: Column values for the given row and column index. // \* Device int32 vector, size total\_nnz. // values: Actual values for the given row and column index. // \* Device dtype vector, size total\_nnz. // // The storage agreement is such that for a given (batch, row, ix): // offset = batch\_pointers(batch) + row\_pointers(batch \* (rows + 1) + row) // col = col\_indices(offset + ix) // val = values(offset + ix) // where ix < #nnz columns in (batch, row). // Then: // matrix(batch, row, col) = val. // // All other elements in the dense representation are treated as 0 / empty. // // For example, for a 2D sparse matrix m shaped (3, 4) such that: // // m[0, 0] = 1.0 // m[0, 1] = 2.0 // m[0, 2] = 3.0 // m[2, 2] = 4.0 // m[2, 3] = 5.0 // // The corresponding representation is: // // dtype: DT\_FLOAT // dense\_shape: (3, 4) // batch\_pointers: (0, 5) // row\_pointers: (0, 3, 3, 5) // col\_indices: concat((0, 1, 2), (), (2, 3)) // values: concat((1.0, 2.0, 3.0), (), (4.0, 5.0)) // // For a 3D sparse matrix m shaped (2, 3, 4) such that: // // m[0, 0, 0] = 1.0 // m[0, 0, 2] = 2.0 // m[0, 2, 3] = 3.0 // m[1, 0, 3] = 4.0 // m[1, 1, 0] = 5.0 // // The corresponding representation is: // dtype: DT\_FLOAT // dense\_shape: (2, 3, 4) // batch\_pointers: (0, 3, 5) // row\_pointers: concat((0, 2, 2, 3), (0, 1, 2, 2)) // col\_indices: concat(concat((0, 2), (), (3,)), // concat((3,), (), (0,))) // values: concat(concat((1.0, 2.0), (3.0,), ()), /// concat((4.0,), (5.0,), ())) // public: static constexpr const char kTypeName[] = "tensorflow::CSRSparseMatrix";
 CSRSparseMatrix() : metadata\_{false, DT\_INVALID} {}
 CSRSparseMatrix(const CSRSparseMatrix& rhs) : metadata\_(rhs.metadata\_), dense\_shape\_(rhs.dense\_shape\_), batch\_pointers\_(rhs.batch\_pointers\_), row\_pointers\_(rhs.row\_pointers\_), col\_indices\_(rhs.col\_indices\_), values\_(rhs.values\_) { SetupVecs(); }
 CSRSparseMatrix(CSRSparseMatrix&& rhs) : metadata\_(rhs.metadata\_), dense\_shape\_(std::move(rhs.dense\_shape\_)), batch\_pointers\_(std::move(rhs.batch\_pointers\_)), row\_pointers\_(std::move(rhs.row\_pointers\_)), col\_indices\_(std::move(rhs.col\_indices\_)), values\_(std::move(rhs.values\_)) { SetupVecs(); rhs.metadata\_.validated = false; rhs.metadata\_.dtype = DT\_INVALID; rhs.ClearVecs(); }
 CSRSparseMatrix& operator=(CSRSparseMatrix&& rhs) { if (this == &rhs) return \*this; metadata\_ = rhs.metadata\_; metadata\_.validated = rhs.metadata\_.validated; dense\_shape\_ = std::move(rhs.dense\_shape\_); batch\_pointers\_ = std::move(rhs.batch\_pointers\_); row\_pointers\_ = std::move(rhs.row\_pointers\_); col\_indices\_ = std::move(rhs.col\_indices\_); values\_ = std::move(rhs.values\_); SetupVecs(); rhs.metadata\_ = {false, DT\_INVALID}; rhs.ClearVecs(); return \*this; }
 static absl::Status CreateCSRSparseMatrix( DataType dtype, const Tensor& dense\_shape, // on host const Tensor& batch\_pointers, // on host const Tensor& row\_pointers, const Tensor& col\_indices, const Tensor& values, CSRSparseMatrix\* matrix) { \*matrix = CSRSparseMatrix(dtype, dense\_shape, batch\_pointers, row\_pointers, col\_indices, values); absl::Status s = matrix->Validate(); matrix->metadata\_.validated = s.ok(); matrix->SetupVecs(); return s; }
 absl::Status Validate() const { return ValidateTypesAndShapes(metadata\_.dtype, dense\_shape\_, batch\_pointers\_, row\_pointers\_, col\_indices\_, values\_); }
 void Clear() { metadata\_ = {false, DT\_INVALID}; dense\_shape\_ = Tensor(); batch\_pointers\_ = Tensor(); row\_pointers\_ = Tensor(); col\_indices\_ = Tensor(); values\_ = Tensor(); ClearVecs(); }
 bool valid() const { return metadata\_.validated && dense\_shape\_.IsInitialized() && batch\_pointers\_.IsInitialized() && row\_pointers\_.IsInitialized() && col\_indices\_.IsInitialized() && values\_.IsInitialized() && dense\_shape\_.NumElements() > 1 && batch\_pointers\_.NumElements() > 0 && row\_pointers\_.NumElements() > 0; }
 DataType dtype() const { DCHECK(valid()); return metadata\_.dtype; }
 inline int dims() const { DCHECK(valid()); return dense\_shape\_.NumElements(); }
 inline int nnz(int batch) const { DCHECK\_LT(batch, batch\_size()); return (\*batch\_pointers\_vec\_)(batch + 1) - (\*batch\_pointers\_vec\_)(batch); }
 inline int batch\_offset(int batch) const { DCHECK\_LT(batch, batch\_size()); return (\*batch\_pointers\_vec\_)(batch); }
 inline int total\_nnz() const { DCHECK(valid()); return (\*batch\_pointers\_vec\_)(batch\_size()); }
 inline Tensor& dense\_shape() { DCHECK(valid()); return dense\_shape\_; }
 inline const Tensor& dense\_shape() const { DCHECK(valid()); return dense\_shape\_; }
 inline TTypes<int32>::UnalignedVec row\_pointers\_vec(int batch) { DCHECK(valid()); DCHECK\_LT(batch, batch\_size()); const int64\_t rows = dense\_shape().vec<int64\_t>()((dims() == 2) ? 0 : 1); const int offset = batch \* (rows + 1); return TTypes<int32>::UnalignedVec(row\_pointers\_vec\_->data() + offset, rows + 1); }
 inline TTypes<int32>::UnalignedConstVec row\_pointers\_vec(int batch) const { DCHECK(valid()); DCHECK\_LT(batch, batch\_size()); const int64\_t rows = dense\_shape().vec<int64\_t>()((dims() == 2) ? 0 : 1); const int offset = batch \* (rows + 1); return TTypes<int32>::UnalignedConstVec(row\_pointers\_vec\_->data() + offset, rows + 1); }
 inline TTypes<int32>::UnalignedVec col\_indices\_vec(int batch) { DCHECK(valid()); DCHECK\_LT(batch, batch\_size()); const int offset = (\*batch\_pointers\_vec\_)(batch); const int nnz\_in\_batch = nnz(batch); return TTypes<int32>::UnalignedVec(col\_indices\_vec\_->data() + offset, nnz\_in\_batch); }
 inline TTypes<int32>::UnalignedConstVec col\_indices\_vec(int batch) const { DCHECK(valid()); DCHECK\_LT(batch, batch\_size()); const int offset = (\*batch\_pointers\_vec\_)(batch); const int nnz\_in\_batch = nnz(batch); return TTypes<int32>::UnalignedConstVec(col\_indices\_vec\_->data() + offset, nnz\_in\_batch); }
 template <typename T> inline typename TTypes<T>::UnalignedVec values\_vec(int batch) { DCHECK(valid()); DCHECK\_LT(batch, batch\_size()); const int offset = (\*batch\_pointers\_vec\_)(batch); const int nnz\_in\_batch = nnz(batch); return typename TTypes<T>::UnalignedVec(values().vec<T>().data() + offset, nnz\_in\_batch); }
 template <typename T> inline typename TTypes<T>::UnalignedConstVec values\_vec(int batch) const { DCHECK(valid()); DCHECK\_LT(batch, batch\_size()); const int offset = (\*batch\_pointers\_vec\_)(batch); const int nnz\_in\_batch = nnz(batch); return typename TTypes<T>::UnalignedConstVec( values().vec<T>().data() + offset, nnz\_in\_batch); }
 inline Tensor& row\_pointers() { DCHECK(valid()); return row\_pointers\_; }
 inline const Tensor& row\_pointers() const { DCHECK(valid()); return row\_pointers\_; }
 inline Tensor& col\_indices() { DCHECK(valid()); return col\_indices\_; }
 inline const Tensor& col\_indices() const { DCHECK(valid()); return col\_indices\_; }
 inline Tensor& values() { DCHECK(valid()); return values\_; }
 inline const Tensor& values() const { DCHECK(valid()); return values\_; }
 inline Tensor& batch\_pointers() { DCHECK(valid()); return batch\_pointers\_; }
 inline const Tensor& batch\_pointers() const { DCHECK(valid()); return batch\_pointers\_; }
 std::string TypeName() const { return kTypeName; }
 // TODO(ebrevdo): A better debug string. std::string DebugString() const { return dense\_shape\_.DebugString(); }
 // Returns the number of elements. This is equal to 1 if the // CSRSparseMatrix is a singleton matrix (dense\_shape is length 2). int batch\_size() const { DCHECK(valid()); return batch\_pointers\_.NumElements() - 1; }
 bool Decode(const VariantTensorData& p) { if (p.tensors\_.empty()) return false; Metadata metadata; if (!p.get\_metadata(&metadata)) return false; const bool validated = metadata.validated; const DataType dtype = metadata.dtype;
 // p.tensors\_ should contain tensors {dense\_shape, batch\_pointers, // row\_pointers, col\_indices, values}. if (p.tensors\_.size() != 5) return false;
 Tensor dense\_shape = p.tensors\_[0]; if (dense\_shape.dtype() != DT\_INT64) return false; if (dense\_shape.dims() != 1) return false; int rank = dense\_shape.dim\_size(0); if (rank < 2 || rank > 3) return false;
 Tensor batch\_pointers(p.tensors\_[1]); Tensor row\_pointers(p.tensors\_[2]); Tensor col\_indices(p.tensors\_[3]); Tensor values(p.tensors\_[4]);
 // Check that the validated bool is consistent with the data. absl::Status s = ValidateTypesAndShapes(dtype, dense\_shape, batch\_pointers, row\_pointers, col\_indices, values); if (s.ok() != validated) return false;
 // Save to this object. metadata\_ = metadata; dense\_shape\_ = std::move(dense\_shape); batch\_pointers\_ = std::move(batch\_pointers); row\_pointers\_ = std::move(row\_pointers); col\_indices\_ = std::move(col\_indices); values\_ = std::move(values); SetupVecs(); return true; }
 void Encode(VariantTensorData\* p) const { DCHECK(valid());
 // Store metadata\_ to p's metadata p->set\_metadata(metadata\_);
 // Store dense\_shape, row\_pointers, col\_indices, and values to p->tensors\_. p->tensors\_.reserve(5); p->tensors\_.push\_back(dense\_shape\_); p->tensors\_.push\_back(batch\_pointers\_); p->tensors\_.push\_back(row\_pointers\_); p->tensors\_.push\_back(col\_indices\_); p->tensors\_.push\_back(values\_); }
 // This static method copies CSRSparseMatrices in all directions: // Host->Device, Device->Host, and Device->Device. static absl::Status DeviceCopy( const CSRSparseMatrix& from, CSRSparseMatrix\* to, const UnaryVariantOpRegistry::AsyncTensorDeviceCopyFn& copy) { VLOG(2) << "DeviceCopy from type: " << DataTypeString(from.dtype()) << " and shape: " << from.dense\_shape().DebugString(); Tensor to\_row\_ptr(DT\_INT32); Tensor to\_col\_ind(DT\_INT32); Tensor to\_values(from.dtype()); TF\_RETURN\_IF\_ERROR(copy(from.row\_pointers(), &to\_row\_ptr)); TF\_RETURN\_IF\_ERROR(copy(from.col\_indices(), &to\_col\_ind)); TF\_RETURN\_IF\_ERROR(copy(from.values(), &to\_values)); return CreateCSRSparseMatrix(from.dtype(), from.dense\_shape(), // Always on host. from.batch\_pointers(), // Always on host. to\_row\_ptr, to\_col\_ind, to\_values, to); }
 private: CSRSparseMatrix(DataType dtype, const Tensor& dense\_shape, const Tensor& batch\_pointers, const Tensor& row\_pointers, const Tensor& col\_indices, const Tensor& values) : metadata\_{false, dtype}, dense\_shape\_(dense\_shape), batch\_pointers\_(batch\_pointers), row\_pointers\_(row\_pointers), col\_indices\_(col\_indices), values\_(values) {}
 void SetupVecs() { if (!metadata\_.validated) return; batch\_pointers\_vec\_.reset( new TTypes<int32>::Vec(batch\_pointers\_.vec<int32>())); row\_pointers\_vec\_.reset(new TTypes<int32>::Vec(row\_pointers\_.vec<int32>())); col\_indices\_vec\_.reset(new TTypes<int32>::Vec(col\_indices\_.vec<int32>())); }
 void ClearVecs() { batch\_pointers\_vec\_.reset(); row\_pointers\_vec\_.reset(); col\_indices\_vec\_.reset(); }
 static absl::Status ValidateTypesAndShapes(DataType dtype, const Tensor& dense\_shape, const Tensor& batch\_pointers, const Tensor& row\_pointers, const Tensor& col\_indices, const Tensor& values) { // TODO(ebrevdo): Consider adding support for other floating point types // (namely, float16). if (dtype != DT\_FLOAT && dtype != DT\_DOUBLE && dtype != DT\_COMPLEX64 && dtype != DT\_COMPLEX128) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: dtype = ", DataTypeString(dtype), " not in {float32, float64, complex64, complex128}"); } // dense\_shape checks if (dense\_shape.dtype() != DT\_INT64) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: dense\_shape.dtype() = ", DataTypeString(dense\_shape.dtype()), " != int64"); } if (dense\_shape.dims() != 1) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: dense\_shape should be a vector, but saw " "tensor: ", dense\_shape.DebugString()); } int rank = dense\_shape.dim\_size(0); if (rank < 2 || rank > 3) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: dense\_shape should be a 2- or 3- vector, " "but saw: ", dense\_shape.SummarizeValue(5)); } auto dense\_shape\_t = dense\_shape.vec<int64\_t>(); const int64\_t batch\_size = (rank == 2) ? 1 : dense\_shape\_t(0); const int64\_t num\_rows = (rank == 2) ? dense\_shape\_t(0) : dense\_shape\_t(1);
 if (batch\_pointers.dtype() != DT\_INT32) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: batch\_pointers.dtype() = ", DataTypeString(batch\_pointers.dtype()), " != int32"); } if (batch\_pointers.dims() != 1) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: batch\_indices is not a vector, saw " "shape: ", batch\_pointers.shape().DebugString()); }
 // batch size checks if (batch\_size != batch\_pointers.NumElements() - 1) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: dense\_shape is ", dense\_shape.SummarizeValue(5), " but batch pointers implies batch size is ", batch\_pointers.NumElements() - 1); }
 if (row\_pointers.dtype() != DT\_INT32) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: row\_pointers.dtype() = ", DataTypeString(row\_pointers.dtype()), " != int32"); } if (row\_pointers.dims() != 1) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: row\_pointers is not a vector, saw " "shape: ", row\_pointers.shape().DebugString()); } if (row\_pointers.dim\_size(0) != batch\_size \* (num\_rows + 1)) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: row\_pointers should have size batch\_size " "\* (num\_rows + 1), saw shapes: ", dense\_shape.DebugString(), " vs. ", row\_pointers.shape().DebugString()); } if (col\_indices.dtype() != DT\_INT32) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: col\_indices.dtype() = ", DataTypeString(col\_indices.dtype()), " != int32"); } if (col\_indices.dims() != 1) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: col\_indices is not a vector, saw shape: ", col\_indices.shape().DebugString()); } if (values.dtype() != dtype) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: values.dtype() = ", DataTypeString(values.dtype()), " != dtype = ", DataTypeString(dtype)); } if (values.dims() != 1) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: values is not a vector, saw shape: ", values.shape().DebugString()); } if (col\_indices.dim\_size(0) != values.dim\_size(0)) { return errors::InvalidArgument( "CSRSparseMatrix::Validate: size(col\_indices) = ", col\_indices.dim\_size(0), " != size(values) = ", values.dim\_size(0)); } return absl::OkStatus(); }
 struct Metadata { bool validated; DataType dtype; }; Metadata metadata\_; Tensor dense\_shape\_; Tensor batch\_pointers\_; Tensor row\_pointers\_; Tensor col\_indices\_; Tensor values\_; std::unique\_ptr<TTypes<int32>::Vec> batch\_pointers\_vec\_; std::unique\_ptr<TTypes<int32>::Vec> row\_pointers\_vec\_; std::unique\_ptr<TTypes<int32>::Vec> col\_indices\_vec\_;};
// Call BinaryFunctor<Device, T>()(ctx, a, b, c)// where T depends on a.dtype(). T will be one of: float, double,// complex64, complex128.template <typename Device, template <typename, typename> class BinaryFunctor>absl::Status CSRSparseMatrixBinaryHelper(OpKernelContext\* ctx, const CSRSparseMatrix& a, const CSRSparseMatrix& b, CSRSparseMatrix\* c) { DataType dt = a.dtype(); if (dt != b.dtype()) { return errors::InvalidArgument( "CSRSparseMatrixBinaryHelper: Inconsistent dtypes for input matrices, " "a " "dtype: ", DataTypeString(dt), ", b dtype: ", DataTypeString(b.dtype())); } switch (dt) { case DT\_FLOAT: { BinaryFunctor<Device, float> functor(ctx); return functor(a, b, c); } case DT\_DOUBLE: { BinaryFunctor<Device, double> functor(ctx); return functor(a, b, c); } case DT\_COMPLEX64: { BinaryFunctor<Device, complex64> functor(ctx); return functor(a, b, c); } case DT\_COMPLEX128: { BinaryFunctor<Device, complex128> functor(ctx); return functor(a, b, c); } default: return errors::InvalidArgument( "CSRSparseMatrixBinaryHelper: a.dtype (", DataTypeString(dt), ") is not one of: float, double, complex64, complex128"); }}
// Call UnaryFunctor<Device, T>()(ctx, a, b)// where T depends on a.dtype(). T will be one of: float, double,// complex64, complex128.template <typename Device, template <typename, typename> class UnaryFunctor>absl::Status CSRSparseMatrixUnaryHelper(OpKernelContext\* ctx, const CSRSparseMatrix& a, CSRSparseMatrix\* b) { DataType dt = a.dtype(); switch (dt) { case DT\_FLOAT: { UnaryFunctor<Device, float> functor(ctx); return functor(a, b); } case DT\_DOUBLE: { UnaryFunctor<Device, double> functor(ctx); return functor(a, b); } case DT\_COMPLEX64: { UnaryFunctor<Device, complex64> functor(ctx); return functor(a, b); } case DT\_COMPLEX128: { UnaryFunctor<Device, complex128> functor(ctx); return functor(a, b); } default: return errors::InvalidArgument( "CSRSparseMatrixUnaryHelper: a.dtype (", DataTypeString(dt), ") is not one of: float, double, complex64, complex128"); }}
template <typename T>struct ConstCSRComponent { TTypes<int32>::UnalignedConstVec row\_ptr; TTypes<int32>::UnalignedConstVec col\_ind; typename TTypes<T>::UnalignedConstVec values; TTypes<int64\_t>::ConstVec dense\_shape\_host;};
template <typename T>struct CSRComponent { TTypes<int32>::UnalignedVec row\_ptr; TTypes<int32>::UnalignedVec col\_ind; typename TTypes<T>::UnalignedVec values; TTypes<int64\_t>::Vec dense\_shape\_host;};
template <typename T>absl::Status ExtractVariantFromInput(OpKernelContext\* ctx, int index, const T\*\* value) { const Tensor& input\_t = ctx->input(index); if (!TensorShapeUtils::IsScalar(input\_t.shape())) { return errors::InvalidArgument( "Invalid input matrix: Shape must be rank 0 but is rank ", input\_t.dims()); } const Variant& input\_variant = input\_t.scalar<Variant>()(); \*value = input\_variant.get<T>(); if (\*value == nullptr) { return errors::InvalidArgument("Could not retrieve Variant input ", index); } if (!(\*value)->valid()) { return errors::InvalidArgument("Variant input ", index, " is not valid."); } return absl::OkStatus();}
} // namespace tensorflow
#endif // TENSORFLOW\_CORE\_KERNELS\_SPARSE\_SPARSE\_MATRIX\_H\_

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

