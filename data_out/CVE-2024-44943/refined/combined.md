=== Content from git.kernel.org_b07b0638_20250111_081654.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=f442fa6141379a20b48ae3efabee827a3d260787)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=f442fa6141379a20b48ae3efabee827a3d260787)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=f442fa6141379a20b48ae3efabee827a3d260787)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=f442fa6141379a20b48ae3efabee827a3d260787)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Yang Shi <yang@os.amperecomputing.com> | 2024-06-28 12:14:58 -0700 |
| --- | --- | --- |
| committer | Andrew Morton <akpm@linux-foundation.org> | 2024-07-06 11:39:51 -0700 |
| commit | [f442fa6141379a20b48ae3efabee827a3d260787](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=f442fa6141379a20b48ae3efabee827a3d260787) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=f442fa6141379a20b48ae3efabee827a3d260787)) | |
| tree | [bc6e4c783fbc49aff1fd5cd451a3cdf1b7c06cad](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=f442fa6141379a20b48ae3efabee827a3d260787) | |
| parent | [a9e1ddc09ca55746079cc479aa3eb6411f0d99d4](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=a9e1ddc09ca55746079cc479aa3eb6411f0d99d4) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=f442fa6141379a20b48ae3efabee827a3d260787&id2=a9e1ddc09ca55746079cc479aa3eb6411f0d99d4)) | |
| download | [linux-f442fa6141379a20b48ae3efabee827a3d260787.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-f442fa6141379a20b48ae3efabee827a3d260787.tar.gz) | |

mm: gup: stop abusing try\_grab\_folioA kernel warning was reported when pinning folio in CMA memory when
launching SEV virtual machine. The splat looks like:
[ 464.325306] WARNING: CPU: 13 PID: 6734 at mm/gup.c:1313 \_\_get\_user\_pages+0x423/0x520
[ 464.325464] CPU: 13 PID: 6734 Comm: qemu-kvm Kdump: loaded Not tainted 6.6.33+ #6
[ 464.325477] RIP: 0010:\_\_get\_user\_pages+0x423/0x520
[ 464.325515] Call Trace:
[ 464.325520] <TASK>
[ 464.325523] ? \_\_get\_user\_pages+0x423/0x520
[ 464.325528] ? \_\_warn+0x81/0x130
[ 464.325536] ? \_\_get\_user\_pages+0x423/0x520
[ 464.325541] ? report\_bug+0x171/0x1a0
[ 464.325549] ? handle\_bug+0x3c/0x70
[ 464.325554] ? exc\_invalid\_op+0x17/0x70
[ 464.325558] ? asm\_exc\_invalid\_op+0x1a/0x20
[ 464.325567] ? \_\_get\_user\_pages+0x423/0x520
[ 464.325575] \_\_gup\_longterm\_locked+0x212/0x7a0
[ 464.325583] internal\_get\_user\_pages\_fast+0xfb/0x190
[ 464.325590] pin\_user\_pages\_fast+0x47/0x60
[ 464.325598] sev\_pin\_memory+0xca/0x170 [kvm\_amd]
[ 464.325616] sev\_mem\_enc\_register\_region+0x81/0x130 [kvm\_amd]
Per the analysis done by yangge, when starting the SEV virtual machine, it
will call pin\_user\_pages\_fast(..., FOLL\_LONGTERM, ...) to pin the memory.
But the page is in CMA area, so fast GUP will fail then fallback to the
slow path due to the longterm pinnalbe check in try\_grab\_folio().
The slow path will try to pin the pages then migrate them out of CMA area.
But the slow path also uses try\_grab\_folio() to pin the page, it will
also fail due to the same check then the above warning is triggered.
In addition, the try\_grab\_folio() is supposed to be used in fast path and
it elevates folio refcount by using add ref unless zero. We are guaranteed
to have at least one stable reference in slow path, so the simple atomic add
could be used. The performance difference should be trivial, but the
misuse may be confusing and misleading.
Redefined try\_grab\_folio() to try\_grab\_folio\_fast(), and try\_grab\_page()
to try\_grab\_folio(), and use them in the proper paths. This solves both
the abuse and the kernel warning.
The proper naming makes their usecase more clear and should prevent from
abusing in the future.
peterx said:
: The user will see the pin fails, for gpu-slow it further triggers the WARN
: right below that failure (as in the original report):
:
: folio = try\_grab\_folio(page, page\_increm - 1,
: foll\_flags);
: if (WARN\_ON\_ONCE(!folio)) { <------------------------ here
: /\*
: \* Release the 1st page ref if the
: \* folio is problematic, fail hard.
: \*/
: gup\_put\_folio(page\_folio(page), 1,
: foll\_flags);
: ret = -EFAULT;
: goto out;
: }
[1] https://lore.kernel.org/linux-mm/1719478388-31917-1-git-send-email-yangge1116@126.com/
[shy828301@gmail.com: fix implicit declaration of function try\_grab\_folio\_fast]
Link: https://lkml.kernel.org/r/CAHbLzkowMSso-4Nufc9hcMehQsK9PNz3OSu-+eniU-2Mm-xjhA@mail.gmail.com
Link: [https://lkml.kernel.org/r/20240628191458.2605553-1-yang@os.amperecomputing.com](https://lkml.kernel.org/r/20240628191458.2605553-1-yang%40os.amperecomputing.com)
Fixes: 57edfcfd3419 ("mm/gup: accelerate thp gup even for "pages != NULL"")
Signed-off-by: Yang Shi <yang@os.amperecomputing.com>
Reported-by: yangge <yangge1116@126.com>
Cc: Christoph Hellwig <hch@infradead.org>
Cc: David Hildenbrand <david@redhat.com>
Cc: Peter Xu <peterx@redhat.com>
Cc: <stable@vger.kernel.org> [6.6+]
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=f442fa6141379a20b48ae3efabee827a3d260787)

| -rw-r--r-- | [mm/gup.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/gup.c?id=f442fa6141379a20b48ae3efabee827a3d260787) | 289 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |
| -rw-r--r-- | [mm/huge\_memory.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/huge_memory.c?id=f442fa6141379a20b48ae3efabee827a3d260787) | 2 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [mm/internal.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/internal.h?id=f442fa6141379a20b48ae3efabee827a3d260787) | 4 | |  |  |  | | --- | --- | --- | |

3 files changed, 156 insertions, 139 deletions

| diff --git a/mm/gup.c b/mm/gup.cindex 469799f805f1fd..f1d6bc06eb523e 100644--- a/[mm/gup.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/gup.c?id=a9e1ddc09ca55746079cc479aa3eb6411f0d99d4)+++ b/[mm/gup.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/gup.c?id=f442fa6141379a20b48ae3efabee827a3d260787)@@ -97,95 +97,6 @@ retry: return folio; } -/\*\*- \* try\_grab\_folio() - Attempt to get or pin a folio.- \* @page: pointer to page to be grabbed- \* @refs: the value to (effectively) add to the folio's refcount- \* @flags: gup flags: these are the FOLL\_\* flag values.- \*- \* "grab" names in this file mean, "look at flags to decide whether to use- \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the folio's refcount.- \*- \* Either FOLL\_PIN or FOLL\_GET (or neither) must be set, but not both at the- \* same time. (That's true throughout the get\_user\_pages\*() and- \* pin\_user\_pages\*() APIs.) Cases:- \*- \* FOLL\_GET: folio's refcount will be incremented by @refs.- \*- \* FOLL\_PIN on large folios: folio's refcount will be incremented by- \* @refs, and its pincount will be incremented by @refs.- \*- \* FOLL\_PIN on single-page folios: folio's refcount will be incremented by- \* @refs \* GUP\_PIN\_COUNTING\_BIAS.- \*- \* Return: The folio containing @page (with refcount appropriately- \* incremented) for success, or NULL upon failure. If neither FOLL\_GET- \* nor FOLL\_PIN was set, that's considered failure, and furthermore,- \* a likely bug in the caller, so a warning is also emitted.- \*/-struct folio \*try\_grab\_folio(struct page \*page, int refs, unsigned int flags)-{- struct folio \*folio;-- if (WARN\_ON\_ONCE((flags & (FOLL\_GET | FOLL\_PIN)) == 0))- return NULL;-- if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(page)))- return NULL;-- if (flags & FOLL\_GET)- return try\_get\_folio(page, refs);-- /\* FOLL\_PIN is set \*/-- /\*- \* Don't take a pin on the zero page - it's not going anywhere- \* and it is used in a \*lot\* of places.- \*/- if (is\_zero\_page(page))- return page\_folio(page);-- folio = try\_get\_folio(page, refs);- if (!folio)- return NULL;-- /\*- \* Can't do FOLL\_LONGTERM + FOLL\_PIN gup fast path if not in a- \* right zone, so fail and let the caller fall back to the slow- \* path.- \*/- if (unlikely((flags & FOLL\_LONGTERM) &&- !folio\_is\_longterm\_pinnable(folio))) {- if (!put\_devmap\_managed\_folio\_refs(folio, refs))- folio\_put\_refs(folio, refs);- return NULL;- }-- /\*- \* When pinning a large folio, use an exact count to track it.- \*- \* However, be sure to \*also\* increment the normal folio- \* refcount field at least once, so that the folio really- \* is pinned. That's why the refcount from the earlier- \* try\_get\_folio() is left intact.- \*/- if (folio\_test\_large(folio))- atomic\_add(refs, &folio->\_pincount);- else- folio\_ref\_add(folio,- refs \* (GUP\_PIN\_COUNTING\_BIAS - 1));- /\*- \* Adjust the pincount before re-checking the PTE for changes.- \* This is essentially a smp\_mb() and is paired with a memory- \* barrier in folio\_try\_share\_anon\_rmap\_\*().- \*/- smp\_mb\_\_after\_atomic();-- node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, refs);-- return folio;-}- static void gup\_put\_folio(struct folio \*folio, int refs, unsigned int flags) { if (flags & FOLL\_PIN) {@@ -203,58 +114,59 @@ static void gup\_put\_folio(struct folio \*folio, int refs, unsigned int flags) }  /\*\*- \* try\_grab\_page() - elevate a page's refcount by a flag-dependent amount- \* @page: pointer to page to be grabbed- \* @flags: gup flags: these are the FOLL\_\* flag values.+ \* try\_grab\_folio() - add a folio's refcount by a flag-dependent amount+ \* @folio: pointer to folio to be grabbed+ \* @refs: the value to (effectively) add to the folio's refcount+ \* @flags: gup flags: these are the FOLL\_\* flag values \* \* This might not do anything at all, depending on the flags argument. \* \* "grab" names in this file mean, "look at flags to decide whether to use- \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the page's refcount.+ \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the folio's refcount. \* \* Either FOLL\_PIN or FOLL\_GET (or neither) may be set, but not both at the same- \* time. Cases: please see the try\_grab\_folio() documentation, with- \* "refs=1".+ \* time. \* \* Return: 0 for success, or if no action was required (if neither FOLL\_PIN \* nor FOLL\_GET was set, nothing is done). A negative error code for failure: \*- \* -ENOMEM FOLL\_GET or FOLL\_PIN was set, but the page could not+ \* -ENOMEM FOLL\_GET or FOLL\_PIN was set, but the folio could not \* be grabbed.+ \*+ \* It is called when we have a stable reference for the folio, typically in+ \* GUP slow path. \*/-int \_\_must\_check try\_grab\_page(struct page \*page, unsigned int flags)+int \_\_must\_check try\_grab\_folio(struct folio \*folio, int refs,+ unsigned int flags) {- struct folio \*folio = page\_folio(page);- if (WARN\_ON\_ONCE(folio\_ref\_count(folio) <= 0)) return -ENOMEM; - if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(page)))+ if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(&folio->page))) return -EREMOTEIO;  if (flags & FOLL\_GET)- folio\_ref\_inc(folio);+ folio\_ref\_add(folio, refs); else if (flags & FOLL\_PIN) { /\* \* Don't take a pin on the zero page - it's not going anywhere \* and it is used in a \*lot\* of places. \*/- if (is\_zero\_page(page))+ if (is\_zero\_folio(folio)) return 0;  /\*- \* Similar to try\_grab\_folio(): be sure to \*also\*- \* increment the normal page refcount field at least once,+ \* Increment the normal page refcount field at least once, \* so that the page really is pinned. \*/ if (folio\_test\_large(folio)) {- folio\_ref\_add(folio, 1);- atomic\_add(1, &folio->\_pincount);+ folio\_ref\_add(folio, refs);+ atomic\_add(refs, &folio->\_pincount); } else {- folio\_ref\_add(folio, GUP\_PIN\_COUNTING\_BIAS);+ folio\_ref\_add(folio, refs \* GUP\_PIN\_COUNTING\_BIAS); } - node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, 1);+ node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, refs); }  return 0;@@ -515,6 +427,102 @@ static int record\_subpages(struct page \*page, unsigned long sz,  return nr; }++/\*\*+ \* try\_grab\_folio\_fast() - Attempt to get or pin a folio in fast path.+ \* @page: pointer to page to be grabbed+ \* @refs: the value to (effectively) add to the folio's refcount+ \* @flags: gup flags: these are the FOLL\_\* flag values.+ \*+ \* "grab" names in this file mean, "look at flags to decide whether to use+ \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the folio's refcount.+ \*+ \* Either FOLL\_PIN or FOLL\_GET (or neither) must be set, but not both at the+ \* same time. (That's true throughout the get\_user\_pages\*() and+ \* pin\_user\_pages\*() APIs.) Cases:+ \*+ \* FOLL\_GET: folio's refcount will be incremented by @refs.+ \*+ \* FOLL\_PIN on large folios: folio's refcount will be incremented by+ \* @refs, and its pincount will be incremented by @refs.+ \*+ \* FOLL\_PIN on single-page folios: folio's refcount will be incremented by+ \* @refs \* GUP\_PIN\_COUNTING\_BIAS.+ \*+ \* Return: The folio containing @page (with refcount appropriately+ \* incremented) for success, or NULL upon failure. If neither FOLL\_GET+ \* nor FOLL\_PIN was set, that's considered failure, and furthermore,+ \* a likely bug in the caller, so a warning is also emitted.+ \*+ \* It uses add ref unless zero to elevate the folio refcount and must be called+ \* in fast path only.+ \*/+static struct folio \*try\_grab\_folio\_fast(struct page \*page, int refs,+ unsigned int flags)+{+ struct folio \*folio;++ /\* Raise warn if it is not called in fast GUP \*/+ VM\_WARN\_ON\_ONCE(!irqs\_disabled());++ if (WARN\_ON\_ONCE((flags & (FOLL\_GET | FOLL\_PIN)) == 0))+ return NULL;++ if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(page)))+ return NULL;++ if (flags & FOLL\_GET)+ return try\_get\_folio(page, refs);++ /\* FOLL\_PIN is set \*/++ /\*+ \* Don't take a pin on the zero page - it's not going anywhere+ \* and it is used in a \*lot\* of places.+ \*/+ if (is\_zero\_page(page))+ return page\_folio(page);++ folio = try\_get\_folio(page, refs);+ if (!folio)+ return NULL;++ /\*+ \* Can't do FOLL\_LONGTERM + FOLL\_PIN gup fast path if not in a+ \* right zone, so fail and let the caller fall back to the slow+ \* path.+ \*/+ if (unlikely((flags & FOLL\_LONGTERM) &&+ !folio\_is\_longterm\_pinnable(folio))) {+ if (!put\_devmap\_managed\_folio\_refs(folio, refs))+ folio\_put\_refs(folio, refs);+ return NULL;+ }++ /\*+ \* When pinning a large folio, use an exact count to track it.+ \*+ \* However, be sure to \*also\* increment the normal folio+ \* refcount field at least once, so that the folio really+ \* is pinned. That's why the refcount from the earlier+ \* try\_get\_folio() is left intact.+ \*/+ if (folio\_test\_large(folio))+ atomic\_add(refs, &folio->\_pincount);+ else+ folio\_ref\_add(folio,+ refs \* (GUP\_PIN\_COUNTING\_BIAS - 1));+ /\*+ \* Adjust the pincount before re-checking the PTE for changes.+ \* This is essentially a smp\_mb() and is paired with a memory+ \* barrier in folio\_try\_share\_anon\_rmap\_\*().+ \*/+ smp\_mb\_\_after\_atomic();++ node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, refs);++ return folio;+} #endif /\* CONFIG\_ARCH\_HAS\_HUGEPD || CONFIG\_HAVE\_GUP\_FAST \*/  #ifdef CONFIG\_ARCH\_HAS\_HUGEPD@@ -535,7 +543,7 @@ static unsigned long hugepte\_addr\_end(unsigned long addr, unsigned long end, \*/ static int gup\_hugepte(struct vm\_area\_struct \*vma, pte\_t \*ptep, unsigned long sz, unsigned long addr, unsigned long end, unsigned int flags,- struct page \*\*pages, int \*nr)+ struct page \*\*pages, int \*nr, bool fast) { unsigned long pte\_end; struct page \*page;@@ -558,9 +566,15 @@ static int gup\_hugepte(struct vm\_area\_struct \*vma, pte\_t \*ptep, unsigned long sz page = pte\_page(pte); refs = record\_subpages(page, sz, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);- if (!folio)- return 0;+ if (fast) {+ folio = try\_grab\_folio\_fast(page, refs, flags);+ if (!folio)+ return 0;+ } else {+ folio = page\_folio(page);+ if (try\_grab\_folio(folio, refs, flags))+ return 0;+ }  if (unlikely(pte\_val(pte) != pte\_val(ptep\_get(ptep)))) { gup\_put\_folio(folio, refs, flags);@@ -588,7 +602,7 @@ static int gup\_hugepte(struct vm\_area\_struct \*vma, pte\_t \*ptep, unsigned long sz static int gup\_hugepd(struct vm\_area\_struct \*vma, hugepd\_t hugepd, unsigned long addr, unsigned int pdshift, unsigned long end, unsigned int flags,- struct page \*\*pages, int \*nr)+ struct page \*\*pages, int \*nr, bool fast) { pte\_t \*ptep; unsigned long sz = 1UL << hugepd\_shift(hugepd);@@ -598,7 +612,8 @@ static int gup\_hugepd(struct vm\_area\_struct \*vma, hugepd\_t hugepd, ptep = hugepte\_offset(hugepd, addr, pdshift); do { next = hugepte\_addr\_end(addr, end, sz);- ret = gup\_hugepte(vma, ptep, sz, addr, end, flags, pages, nr);+ ret = gup\_hugepte(vma, ptep, sz, addr, end, flags, pages, nr,+ fast); if (ret != 1) return ret; } while (ptep++, addr = next, addr != end);@@ -625,7 +640,7 @@ static struct page \*follow\_hugepd(struct vm\_area\_struct \*vma, hugepd\_t hugepd, ptep = hugepte\_offset(hugepd, addr, pdshift); ptl = huge\_pte\_lock(h, vma->vm\_mm, ptep); ret = gup\_hugepd(vma, hugepd, addr, pdshift, addr + PAGE\_SIZE,- flags, &page, &nr);+ flags, &page, &nr, false); spin\_unlock(ptl);  if (ret == 1) {@@ -642,7 +657,7 @@ static struct page \*follow\_hugepd(struct vm\_area\_struct \*vma, hugepd\_t hugepd, static inline int gup\_hugepd(struct vm\_area\_struct \*vma, hugepd\_t hugepd, unsigned long addr, unsigned int pdshift, unsigned long end, unsigned int flags,- struct page \*\*pages, int \*nr)+ struct page \*\*pages, int \*nr, bool fast) { return 0; }@@ -729,7 +744,7 @@ static struct page \*follow\_huge\_pud(struct vm\_area\_struct \*vma, gup\_must\_unshare(vma, flags, page)) return ERR\_PTR(-EMLINK); - ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (ret) page = ERR\_PTR(ret); else@@ -806,7 +821,7 @@ static struct page \*follow\_huge\_pmd(struct vm\_area\_struct \*vma, VM\_BUG\_ON\_PAGE((flags & FOLL\_PIN) && PageAnon(page) && !PageAnonExclusive(page), page); - ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (ret) return ERR\_PTR(ret); @@ -968,8 +983,8 @@ static struct page \*follow\_page\_pte(struct vm\_area\_struct \*vma, VM\_BUG\_ON\_PAGE((flags & FOLL\_PIN) && PageAnon(page) && !PageAnonExclusive(page), page); - /\* try\_grab\_page() does nothing unless FOLL\_GET or FOLL\_PIN is set. \*/- ret = try\_grab\_page(page, flags);+ /\* try\_grab\_folio() does nothing unless FOLL\_GET or FOLL\_PIN is set. \*/+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (unlikely(ret)) { page = ERR\_PTR(ret); goto out;@@ -1233,7 +1248,7 @@ static int get\_gate\_page(struct mm\_struct \*mm, unsigned long address, goto unmap; \*page = pte\_page(entry); }- ret = try\_grab\_page(\*page, gup\_flags);+ ret = try\_grab\_folio(page\_folio(\*page), 1, gup\_flags); if (unlikely(ret)) goto unmap; out:@@ -1636,20 +1651,19 @@ next\_page: \* pages. \*/ if (page\_increm > 1) {- struct folio \*folio;+ struct folio \*folio = page\_folio(page);  /\* \* Since we already hold refcount on the \* large folio, this should never fail. \*/- folio = try\_grab\_folio(page, page\_increm - 1,- foll\_flags);- if (WARN\_ON\_ONCE(!folio)) {+ if (try\_grab\_folio(folio, page\_increm - 1,+ foll\_flags)) { /\* \* Release the 1st page ref if the \* folio is problematic, fail hard. \*/- gup\_put\_folio(page\_folio(page), 1,+ gup\_put\_folio(folio, 1, foll\_flags); ret = -EFAULT; goto out;@@ -2797,7 +2811,6 @@ EXPORT\_SYMBOL(get\_user\_pages\_unlocked); \* This code is based heavily on the PowerPC implementation by Nick Piggin. \*/ #ifdef CONFIG\_HAVE\_GUP\_FAST- /\* \* Used in the GUP-fast path to determine whether GUP is permitted to work on \* a specific folio.@@ -2962,7 +2975,7 @@ static int gup\_fast\_pte\_range(pmd\_t pmd, pmd\_t \*pmdp, unsigned long addr, VM\_BUG\_ON(!pfn\_valid(pte\_pfn(pte))); page = pte\_page(pte); - folio = try\_grab\_folio(page, 1, flags);+ folio = try\_grab\_folio\_fast(page, 1, flags); if (!folio) goto pte\_unmap; @@ -3049,7 +3062,7 @@ static int gup\_fast\_devmap\_leaf(unsigned long pfn, unsigned long addr, break; } - folio = try\_grab\_folio(page, 1, flags);+ folio = try\_grab\_folio\_fast(page, 1, flags); if (!folio) { gup\_fast\_undo\_dev\_pagemap(nr, nr\_start, flags, pages); break;@@ -3138,7 +3151,7 @@ static int gup\_fast\_pmd\_leaf(pmd\_t orig, pmd\_t \*pmdp, unsigned long addr, page = pmd\_page(orig); refs = record\_subpages(page, PMD\_SIZE, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; @@ -3182,7 +3195,7 @@ static int gup\_fast\_pud\_leaf(pud\_t orig, pud\_t \*pudp, unsigned long addr, page = pud\_page(orig); refs = record\_subpages(page, PUD\_SIZE, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; @@ -3222,7 +3235,7 @@ static int gup\_fast\_pgd\_leaf(pgd\_t orig, pgd\_t \*pgdp, unsigned long addr, page = pgd\_page(orig); refs = record\_subpages(page, PGDIR\_SIZE, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; @@ -3276,7 +3289,8 @@ static int gup\_fast\_pmd\_range(pud\_t \*pudp, pud\_t pud, unsigned long addr, \* pmd format and THP pmd format \*/ if (gup\_hugepd(NULL, \_\_hugepd(pmd\_val(pmd)), addr,- PMD\_SHIFT, next, flags, pages, nr) != 1)+ PMD\_SHIFT, next, flags, pages, nr,+ true) != 1) return 0; } else if (!gup\_fast\_pte\_range(pmd, pmdp, addr, next, flags, pages, nr))@@ -3306,7 +3320,8 @@ static int gup\_fast\_pud\_range(p4d\_t \*p4dp, p4d\_t p4d, unsigned long addr, return 0; } else if (unlikely(is\_hugepd(\_\_hugepd(pud\_val(pud))))) { if (gup\_hugepd(NULL, \_\_hugepd(pud\_val(pud)), addr,- PUD\_SHIFT, next, flags, pages, nr) != 1)+ PUD\_SHIFT, next, flags, pages, nr,+ true) != 1) return 0; } else if (!gup\_fast\_pmd\_range(pudp, pud, addr, next, flags, pages, nr))@@ -3333,7 +3348,8 @@ static int gup\_fast\_p4d\_range(pgd\_t \*pgdp, pgd\_t pgd, unsigned long addr, BUILD\_BUG\_ON(p4d\_leaf(p4d)); if (unlikely(is\_hugepd(\_\_hugepd(p4d\_val(p4d))))) { if (gup\_hugepd(NULL, \_\_hugepd(p4d\_val(p4d)), addr,- P4D\_SHIFT, next, flags, pages, nr) != 1)+ P4D\_SHIFT, next, flags, pages, nr,+ true) != 1) return 0; } else if (!gup\_fast\_pud\_range(p4dp, p4d, addr, next, flags, pages, nr))@@ -3362,7 +3378,8 @@ static void gup\_fast\_pgd\_range(unsigned long addr, unsigned long end, return; } else if (unlikely(is\_hugepd(\_\_hugepd(pgd\_val(pgd))))) { if (gup\_hugepd(NULL, \_\_hugepd(pgd\_val(pgd)), addr,- PGDIR\_SHIFT, next, flags, pages, nr) != 1)+ PGDIR\_SHIFT, next, flags, pages, nr,+ true) != 1) return; } else if (!gup\_fast\_p4d\_range(pgdp, pgd, addr, next, flags, pages, nr))diff --git a/mm/huge\_memory.c b/mm/huge\_memory.cindex db7946a0a28c4b..2120f7478e55ca 100644--- a/[mm/huge\_memory.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/huge_memory.c?id=a9e1ddc09ca55746079cc479aa3eb6411f0d99d4)+++ b/[mm/huge\_memory.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/huge_memory.c?id=f442fa6141379a20b48ae3efabee827a3d260787)@@ -1331,7 +1331,7 @@ struct page \*follow\_devmap\_pmd(struct vm\_area\_struct \*vma, unsigned long addr, if (!\*pgmap) return ERR\_PTR(-EFAULT); page = pfn\_to\_page(pfn);- ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (ret) page = ERR\_PTR(ret); diff --git a/mm/internal.h b/mm/internal.hindex 6902b7dd85091c..cc2c5e07fad3ba 100644--- a/[mm/internal.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/internal.h?id=a9e1ddc09ca55746079cc479aa3eb6411f0d99d4)+++ b/[mm/internal.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/internal.h?id=f442fa6141379a20b48ae3efabee827a3d260787)@@ -1182,8 +1182,8 @@ int migrate\_device\_coherent\_page(struct page \*page); /\* \* mm/gup.c \*/-struct folio \*try\_grab\_folio(struct page \*page, int refs, unsigned int flags);-int \_\_must\_check try\_grab\_page(struct page \*page, unsigned int flags);+int \_\_must\_check try\_grab\_folio(struct folio \*folio, int refs,+ unsigned int flags);  /\* \* mm/huge\_memory.c |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 08:15:31 +0000



=== Content from git.kernel.org_0db190bf_20250111_081653.html ===


| [cgit logo](/) | [index](/) : [kernel/git/stable/linux.git](/pub/scm/linux/kernel/git/stable/linux.git/) | linux-2.6.11.y linux-2.6.12.y linux-2.6.13.y linux-2.6.14.y linux-2.6.15.y linux-2.6.16.y linux-2.6.17.y linux-2.6.18.y linux-2.6.19.y linux-2.6.20.y linux-2.6.21.y linux-2.6.22.y linux-2.6.23.y linux-2.6.24.y linux-2.6.25.y linux-2.6.26.y linux-2.6.27.y linux-2.6.28.y linux-2.6.29.y linux-2.6.30.y linux-2.6.31.y linux-2.6.32.y linux-2.6.33.y linux-2.6.34.y linux-2.6.35.y linux-2.6.36.y linux-2.6.37.y linux-2.6.38.y linux-2.6.39.y linux-3.0.y linux-3.1.y linux-3.10.y linux-3.11.y linux-3.12.y linux-3.13.y linux-3.14.y linux-3.15.y linux-3.16.y linux-3.17.y linux-3.18.y linux-3.19.y linux-3.2.y linux-3.3.y linux-3.4.y linux-3.5.y linux-3.6.y linux-3.7.y linux-3.8.y linux-3.9.y linux-4.0.y linux-4.1.y linux-4.10.y linux-4.11.y linux-4.12.y linux-4.13.y linux-4.14.y linux-4.15.y linux-4.16.y linux-4.17.y linux-4.18.y linux-4.19.y linux-4.2.y linux-4.20.y linux-4.3.y linux-4.4.y linux-4.5.y linux-4.6.y linux-4.7.y linux-4.8.y linux-4.9.y linux-5.0.y linux-5.1.y linux-5.10.y linux-5.11.y linux-5.12.y linux-5.13.y linux-5.14.y linux-5.15.y linux-5.16.y linux-5.17.y linux-5.18.y linux-5.19.y linux-5.2.y linux-5.3.y linux-5.4.y linux-5.5.y linux-5.6.y linux-5.7.y linux-5.8.y linux-5.9.y linux-6.0.y linux-6.1.y linux-6.10.y linux-6.11.y linux-6.12.y linux-6.2.y linux-6.3.y linux-6.4.y linux-6.5.y linux-6.6.y linux-6.7.y linux-6.8.y linux-6.9.y linux-rolling-lts linux-rolling-stable master |
| --- | --- | --- |
| Linux kernel stable tree | Stable Group |

| [about](/pub/scm/linux/kernel/git/stable/linux.git/about/)[summary](/pub/scm/linux/kernel/git/stable/linux.git/)[refs](/pub/scm/linux/kernel/git/stable/linux.git/refs/?id=26273f5f4cf68b29414e403837093408a9c98e1f)[log](/pub/scm/linux/kernel/git/stable/linux.git/log/)[tree](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=26273f5f4cf68b29414e403837093408a9c98e1f)[commit](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=26273f5f4cf68b29414e403837093408a9c98e1f)[diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=26273f5f4cf68b29414e403837093408a9c98e1f)[stats](/pub/scm/linux/kernel/git/stable/linux.git/stats/) | log msg author committer range |
| --- | --- |

**diff options**

|  | |
| --- | --- |
| context: | 12345678910152025303540 |
| space: | includeignore |
| mode: | unifiedssdiffstat only |
|  |  |

| author | Yang Shi <yang@os.amperecomputing.com> | 2024-06-28 12:14:58 -0700 |
| --- | --- | --- |
| committer | Greg Kroah-Hartman <gregkh@linuxfoundation.org> | 2024-08-19 06:04:24 +0200 |
| commit | [26273f5f4cf68b29414e403837093408a9c98e1f](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=26273f5f4cf68b29414e403837093408a9c98e1f) ([patch](/pub/scm/linux/kernel/git/stable/linux.git/patch/?id=26273f5f4cf68b29414e403837093408a9c98e1f)) | |
| tree | [3e13c2fe46c4b66d865235ebee38a4e1a02f04e0](/pub/scm/linux/kernel/git/stable/linux.git/tree/?id=26273f5f4cf68b29414e403837093408a9c98e1f) | |
| parent | [9eae19001439f5004e1fb189972d929201db29ef](/pub/scm/linux/kernel/git/stable/linux.git/commit/?id=9eae19001439f5004e1fb189972d929201db29ef) ([diff](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=26273f5f4cf68b29414e403837093408a9c98e1f&id2=9eae19001439f5004e1fb189972d929201db29ef)) | |
| download | [linux-26273f5f4cf68b29414e403837093408a9c98e1f.tar.gz](/pub/scm/linux/kernel/git/stable/linux.git/snapshot/linux-26273f5f4cf68b29414e403837093408a9c98e1f.tar.gz) | |

mm: gup: stop abusing try\_grab\_foliocommit f442fa6141379a20b48ae3efabee827a3d260787 upstream.
A kernel warning was reported when pinning folio in CMA memory when
launching SEV virtual machine. The splat looks like:
[ 464.325306] WARNING: CPU: 13 PID: 6734 at mm/gup.c:1313 \_\_get\_user\_pages+0x423/0x520
[ 464.325464] CPU: 13 PID: 6734 Comm: qemu-kvm Kdump: loaded Not tainted 6.6.33+ #6
[ 464.325477] RIP: 0010:\_\_get\_user\_pages+0x423/0x520
[ 464.325515] Call Trace:
[ 464.325520] <TASK>
[ 464.325523] ? \_\_get\_user\_pages+0x423/0x520
[ 464.325528] ? \_\_warn+0x81/0x130
[ 464.325536] ? \_\_get\_user\_pages+0x423/0x520
[ 464.325541] ? report\_bug+0x171/0x1a0
[ 464.325549] ? handle\_bug+0x3c/0x70
[ 464.325554] ? exc\_invalid\_op+0x17/0x70
[ 464.325558] ? asm\_exc\_invalid\_op+0x1a/0x20
[ 464.325567] ? \_\_get\_user\_pages+0x423/0x520
[ 464.325575] \_\_gup\_longterm\_locked+0x212/0x7a0
[ 464.325583] internal\_get\_user\_pages\_fast+0xfb/0x190
[ 464.325590] pin\_user\_pages\_fast+0x47/0x60
[ 464.325598] sev\_pin\_memory+0xca/0x170 [kvm\_amd]
[ 464.325616] sev\_mem\_enc\_register\_region+0x81/0x130 [kvm\_amd]
Per the analysis done by yangge, when starting the SEV virtual machine, it
will call pin\_user\_pages\_fast(..., FOLL\_LONGTERM, ...) to pin the memory.
But the page is in CMA area, so fast GUP will fail then fallback to the
slow path due to the longterm pinnalbe check in try\_grab\_folio().
The slow path will try to pin the pages then migrate them out of CMA area.
But the slow path also uses try\_grab\_folio() to pin the page, it will
also fail due to the same check then the above warning is triggered.
In addition, the try\_grab\_folio() is supposed to be used in fast path and
it elevates folio refcount by using add ref unless zero. We are guaranteed
to have at least one stable reference in slow path, so the simple atomic add
could be used. The performance difference should be trivial, but the
misuse may be confusing and misleading.
Redefined try\_grab\_folio() to try\_grab\_folio\_fast(), and try\_grab\_page()
to try\_grab\_folio(), and use them in the proper paths. This solves both
the abuse and the kernel warning.
The proper naming makes their usecase more clear and should prevent from
abusing in the future.
peterx said:
: The user will see the pin fails, for gpu-slow it further triggers the WARN
: right below that failure (as in the original report):
:
: folio = try\_grab\_folio(page, page\_increm - 1,
: foll\_flags);
: if (WARN\_ON\_ONCE(!folio)) { <------------------------ here
: /\*
: \* Release the 1st page ref if the
: \* folio is problematic, fail hard.
: \*/
: gup\_put\_folio(page\_folio(page), 1,
: foll\_flags);
: ret = -EFAULT;
: goto out;
: }
[1] https://lore.kernel.org/linux-mm/1719478388-31917-1-git-send-email-yangge1116@126.com/
[shy828301@gmail.com: fix implicit declaration of function try\_grab\_folio\_fast]
Link: https://lkml.kernel.org/r/CAHbLzkowMSso-4Nufc9hcMehQsK9PNz3OSu-+eniU-2Mm-xjhA@mail.gmail.com
Link: [https://lkml.kernel.org/r/20240628191458.2605553-1-yang@os.amperecomputing.com](https://lkml.kernel.org/r/20240628191458.2605553-1-yang%40os.amperecomputing.com)
Fixes: 57edfcfd3419 ("mm/gup: accelerate thp gup even for "pages != NULL"")
Signed-off-by: Yang Shi <yang@os.amperecomputing.com>
Reported-by: yangge <yangge1116@126.com>
Cc: Christoph Hellwig <hch@infradead.org>
Cc: David Hildenbrand <david@redhat.com>
Cc: Peter Xu <peterx@redhat.com>
Cc: <stable@vger.kernel.org> [6.6+]
Signed-off-by: Andrew Morton <akpm@linux-foundation.org>
Signed-off-by: Greg Kroah-Hartman <gregkh@linuxfoundation.org>
[Diffstat](/pub/scm/linux/kernel/git/stable/linux.git/diff/?id=26273f5f4cf68b29414e403837093408a9c98e1f)

| -rw-r--r-- | [mm/gup.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/gup.c?id=26273f5f4cf68b29414e403837093408a9c98e1f) | 251 | |  |  |  | | --- | --- | --- | |
| --- | --- | --- | --- | --- | --- | --- |
| -rw-r--r-- | [mm/huge\_memory.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/huge_memory.c?id=26273f5f4cf68b29414e403837093408a9c98e1f) | 6 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [mm/hugetlb.c](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/hugetlb.c?id=26273f5f4cf68b29414e403837093408a9c98e1f) | 2 | |  |  |  | | --- | --- | --- | |
| -rw-r--r-- | [mm/internal.h](/pub/scm/linux/kernel/git/stable/linux.git/diff/mm/internal.h?id=26273f5f4cf68b29414e403837093408a9c98e1f) | 4 | |  |  |  | | --- | --- | --- | |

4 files changed, 135 insertions, 128 deletions

| diff --git a/mm/gup.c b/mm/gup.cindex f50fe2219a13b6..fdd75384160d8d 100644--- a/[mm/gup.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/gup.c?id=9eae19001439f5004e1fb189972d929201db29ef)+++ b/[mm/gup.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/gup.c?id=26273f5f4cf68b29414e403837093408a9c98e1f)@@ -97,95 +97,6 @@ retry: return folio; } -/\*\*- \* try\_grab\_folio() - Attempt to get or pin a folio.- \* @page: pointer to page to be grabbed- \* @refs: the value to (effectively) add to the folio's refcount- \* @flags: gup flags: these are the FOLL\_\* flag values.- \*- \* "grab" names in this file mean, "look at flags to decide whether to use- \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the folio's refcount.- \*- \* Either FOLL\_PIN or FOLL\_GET (or neither) must be set, but not both at the- \* same time. (That's true throughout the get\_user\_pages\*() and- \* pin\_user\_pages\*() APIs.) Cases:- \*- \* FOLL\_GET: folio's refcount will be incremented by @refs.- \*- \* FOLL\_PIN on large folios: folio's refcount will be incremented by- \* @refs, and its pincount will be incremented by @refs.- \*- \* FOLL\_PIN on single-page folios: folio's refcount will be incremented by- \* @refs \* GUP\_PIN\_COUNTING\_BIAS.- \*- \* Return: The folio containing @page (with refcount appropriately- \* incremented) for success, or NULL upon failure. If neither FOLL\_GET- \* nor FOLL\_PIN was set, that's considered failure, and furthermore,- \* a likely bug in the caller, so a warning is also emitted.- \*/-struct folio \*try\_grab\_folio(struct page \*page, int refs, unsigned int flags)-{- struct folio \*folio;-- if (WARN\_ON\_ONCE((flags & (FOLL\_GET | FOLL\_PIN)) == 0))- return NULL;-- if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(page)))- return NULL;-- if (flags & FOLL\_GET)- return try\_get\_folio(page, refs);-- /\* FOLL\_PIN is set \*/-- /\*- \* Don't take a pin on the zero page - it's not going anywhere- \* and it is used in a \*lot\* of places.- \*/- if (is\_zero\_page(page))- return page\_folio(page);-- folio = try\_get\_folio(page, refs);- if (!folio)- return NULL;-- /\*- \* Can't do FOLL\_LONGTERM + FOLL\_PIN gup fast path if not in a- \* right zone, so fail and let the caller fall back to the slow- \* path.- \*/- if (unlikely((flags & FOLL\_LONGTERM) &&- !folio\_is\_longterm\_pinnable(folio))) {- if (!put\_devmap\_managed\_page\_refs(&folio->page, refs))- folio\_put\_refs(folio, refs);- return NULL;- }-- /\*- \* When pinning a large folio, use an exact count to track it.- \*- \* However, be sure to \*also\* increment the normal folio- \* refcount field at least once, so that the folio really- \* is pinned. That's why the refcount from the earlier- \* try\_get\_folio() is left intact.- \*/- if (folio\_test\_large(folio))- atomic\_add(refs, &folio->\_pincount);- else- folio\_ref\_add(folio,- refs \* (GUP\_PIN\_COUNTING\_BIAS - 1));- /\*- \* Adjust the pincount before re-checking the PTE for changes.- \* This is essentially a smp\_mb() and is paired with a memory- \* barrier in page\_try\_share\_anon\_rmap().- \*/- smp\_mb\_\_after\_atomic();-- node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, refs);-- return folio;-}- static void gup\_put\_folio(struct folio \*folio, int refs, unsigned int flags) { if (flags & FOLL\_PIN) {@@ -203,58 +114,59 @@ static void gup\_put\_folio(struct folio \*folio, int refs, unsigned int flags) }  /\*\*- \* try\_grab\_page() - elevate a page's refcount by a flag-dependent amount- \* @page: pointer to page to be grabbed- \* @flags: gup flags: these are the FOLL\_\* flag values.+ \* try\_grab\_folio() - add a folio's refcount by a flag-dependent amount+ \* @folio: pointer to folio to be grabbed+ \* @refs: the value to (effectively) add to the folio's refcount+ \* @flags: gup flags: these are the FOLL\_\* flag values \* \* This might not do anything at all, depending on the flags argument. \* \* "grab" names in this file mean, "look at flags to decide whether to use- \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the page's refcount.+ \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the folio's refcount. \* \* Either FOLL\_PIN or FOLL\_GET (or neither) may be set, but not both at the same- \* time. Cases: please see the try\_grab\_folio() documentation, with- \* "refs=1".+ \* time. \* \* Return: 0 for success, or if no action was required (if neither FOLL\_PIN \* nor FOLL\_GET was set, nothing is done). A negative error code for failure: \*- \* -ENOMEM FOLL\_GET or FOLL\_PIN was set, but the page could not+ \* -ENOMEM FOLL\_GET or FOLL\_PIN was set, but the folio could not \* be grabbed.+ \*+ \* It is called when we have a stable reference for the folio, typically in+ \* GUP slow path. \*/-int \_\_must\_check try\_grab\_page(struct page \*page, unsigned int flags)+int \_\_must\_check try\_grab\_folio(struct folio \*folio, int refs,+ unsigned int flags) {- struct folio \*folio = page\_folio(page);- if (WARN\_ON\_ONCE(folio\_ref\_count(folio) <= 0)) return -ENOMEM; - if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(page)))+ if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(&folio->page))) return -EREMOTEIO;  if (flags & FOLL\_GET)- folio\_ref\_inc(folio);+ folio\_ref\_add(folio, refs); else if (flags & FOLL\_PIN) { /\* \* Don't take a pin on the zero page - it's not going anywhere \* and it is used in a \*lot\* of places. \*/- if (is\_zero\_page(page))+ if (is\_zero\_folio(folio)) return 0;  /\*- \* Similar to try\_grab\_folio(): be sure to \*also\*- \* increment the normal page refcount field at least once,+ \* Increment the normal page refcount field at least once, \* so that the page really is pinned. \*/ if (folio\_test\_large(folio)) {- folio\_ref\_add(folio, 1);- atomic\_add(1, &folio->\_pincount);+ folio\_ref\_add(folio, refs);+ atomic\_add(refs, &folio->\_pincount); } else {- folio\_ref\_add(folio, GUP\_PIN\_COUNTING\_BIAS);+ folio\_ref\_add(folio, refs \* GUP\_PIN\_COUNTING\_BIAS); } - node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, 1);+ node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, refs); }  return 0;@@ -647,8 +559,8 @@ static struct page \*follow\_page\_pte(struct vm\_area\_struct \*vma, VM\_BUG\_ON\_PAGE((flags & FOLL\_PIN) && PageAnon(page) && !PageAnonExclusive(page), page); - /\* try\_grab\_page() does nothing unless FOLL\_GET or FOLL\_PIN is set. \*/- ret = try\_grab\_page(page, flags);+ /\* try\_grab\_folio() does nothing unless FOLL\_GET or FOLL\_PIN is set. \*/+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (unlikely(ret)) { page = ERR\_PTR(ret); goto out;@@ -899,7 +811,7 @@ static int get\_gate\_page(struct mm\_struct \*mm, unsigned long address, goto unmap; \*page = pte\_page(entry); }- ret = try\_grab\_page(\*page, gup\_flags);+ ret = try\_grab\_folio(page\_folio(\*page), 1, gup\_flags); if (unlikely(ret)) goto unmap; out:@@ -1302,20 +1214,19 @@ next\_page: \* pages. \*/ if (page\_increm > 1) {- struct folio \*folio;+ struct folio \*folio = page\_folio(page);  /\* \* Since we already hold refcount on the \* large folio, this should never fail. \*/- folio = try\_grab\_folio(page, page\_increm - 1,- foll\_flags);- if (WARN\_ON\_ONCE(!folio)) {+ if (try\_grab\_folio(folio, page\_increm - 1,+ foll\_flags)) { /\* \* Release the 1st page ref if the \* folio is problematic, fail hard. \*/- gup\_put\_folio(page\_folio(page), 1,+ gup\_put\_folio(folio, 1, foll\_flags); ret = -EFAULT; goto out;@@ -2541,6 +2452,102 @@ static void \_\_maybe\_unused undo\_dev\_pagemap(int \*nr, int nr\_start, } } +/\*\*+ \* try\_grab\_folio\_fast() - Attempt to get or pin a folio in fast path.+ \* @page: pointer to page to be grabbed+ \* @refs: the value to (effectively) add to the folio's refcount+ \* @flags: gup flags: these are the FOLL\_\* flag values.+ \*+ \* "grab" names in this file mean, "look at flags to decide whether to use+ \* FOLL\_PIN or FOLL\_GET behavior, when incrementing the folio's refcount.+ \*+ \* Either FOLL\_PIN or FOLL\_GET (or neither) must be set, but not both at the+ \* same time. (That's true throughout the get\_user\_pages\*() and+ \* pin\_user\_pages\*() APIs.) Cases:+ \*+ \* FOLL\_GET: folio's refcount will be incremented by @refs.+ \*+ \* FOLL\_PIN on large folios: folio's refcount will be incremented by+ \* @refs, and its pincount will be incremented by @refs.+ \*+ \* FOLL\_PIN on single-page folios: folio's refcount will be incremented by+ \* @refs \* GUP\_PIN\_COUNTING\_BIAS.+ \*+ \* Return: The folio containing @page (with refcount appropriately+ \* incremented) for success, or NULL upon failure. If neither FOLL\_GET+ \* nor FOLL\_PIN was set, that's considered failure, and furthermore,+ \* a likely bug in the caller, so a warning is also emitted.+ \*+ \* It uses add ref unless zero to elevate the folio refcount and must be called+ \* in fast path only.+ \*/+static struct folio \*try\_grab\_folio\_fast(struct page \*page, int refs,+ unsigned int flags)+{+ struct folio \*folio;++ /\* Raise warn if it is not called in fast GUP \*/+ VM\_WARN\_ON\_ONCE(!irqs\_disabled());++ if (WARN\_ON\_ONCE((flags & (FOLL\_GET | FOLL\_PIN)) == 0))+ return NULL;++ if (unlikely(!(flags & FOLL\_PCI\_P2PDMA) && is\_pci\_p2pdma\_page(page)))+ return NULL;++ if (flags & FOLL\_GET)+ return try\_get\_folio(page, refs);++ /\* FOLL\_PIN is set \*/++ /\*+ \* Don't take a pin on the zero page - it's not going anywhere+ \* and it is used in a \*lot\* of places.+ \*/+ if (is\_zero\_page(page))+ return page\_folio(page);++ folio = try\_get\_folio(page, refs);+ if (!folio)+ return NULL;++ /\*+ \* Can't do FOLL\_LONGTERM + FOLL\_PIN gup fast path if not in a+ \* right zone, so fail and let the caller fall back to the slow+ \* path.+ \*/+ if (unlikely((flags & FOLL\_LONGTERM) &&+ !folio\_is\_longterm\_pinnable(folio))) {+ if (!put\_devmap\_managed\_page\_refs(&folio->page, refs))+ folio\_put\_refs(folio, refs);+ return NULL;+ }++ /\*+ \* When pinning a large folio, use an exact count to track it.+ \*+ \* However, be sure to \*also\* increment the normal folio+ \* refcount field at least once, so that the folio really+ \* is pinned. That's why the refcount from the earlier+ \* try\_get\_folio() is left intact.+ \*/+ if (folio\_test\_large(folio))+ atomic\_add(refs, &folio->\_pincount);+ else+ folio\_ref\_add(folio,+ refs \* (GUP\_PIN\_COUNTING\_BIAS - 1));+ /\*+ \* Adjust the pincount before re-checking the PTE for changes.+ \* This is essentially a smp\_mb() and is paired with a memory+ \* barrier in folio\_try\_share\_anon\_rmap\_\*().+ \*/+ smp\_mb\_\_after\_atomic();++ node\_stat\_mod\_folio(folio, NR\_FOLL\_PIN\_ACQUIRED, refs);++ return folio;+}+ #ifdef CONFIG\_ARCH\_HAS\_PTE\_SPECIAL /\* \* Fast-gup relies on pte change detection to avoid concurrent pgtable@@ -2605,7 +2612,7 @@ static int gup\_pte\_range(pmd\_t pmd, pmd\_t \*pmdp, unsigned long addr, VM\_BUG\_ON(!pfn\_valid(pte\_pfn(pte))); page = pte\_page(pte); - folio = try\_grab\_folio(page, 1, flags);+ folio = try\_grab\_folio\_fast(page, 1, flags); if (!folio) goto pte\_unmap; @@ -2699,7 +2706,7 @@ static int \_\_gup\_device\_huge(unsigned long pfn, unsigned long addr,  SetPageReferenced(page); pages[\*nr] = page;- if (unlikely(try\_grab\_page(page, flags))) {+ if (unlikely(try\_grab\_folio(page\_folio(page), 1, flags))) { undo\_dev\_pagemap(nr, nr\_start, flags, pages); break; }@@ -2808,7 +2815,7 @@ static int gup\_hugepte(pte\_t \*ptep, unsigned long sz, unsigned long addr, page = nth\_page(pte\_page(pte), (addr & (sz - 1)) >> PAGE\_SHIFT); refs = record\_subpages(page, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; @@ -2879,7 +2886,7 @@ static int gup\_huge\_pmd(pmd\_t orig, pmd\_t \*pmdp, unsigned long addr, page = nth\_page(pmd\_page(orig), (addr & ~PMD\_MASK) >> PAGE\_SHIFT); refs = record\_subpages(page, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; @@ -2923,7 +2930,7 @@ static int gup\_huge\_pud(pud\_t orig, pud\_t \*pudp, unsigned long addr, page = nth\_page(pud\_page(orig), (addr & ~PUD\_MASK) >> PAGE\_SHIFT); refs = record\_subpages(page, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; @@ -2963,7 +2970,7 @@ static int gup\_huge\_pgd(pgd\_t orig, pgd\_t \*pgdp, unsigned long addr, page = nth\_page(pgd\_page(orig), (addr & ~PGDIR\_MASK) >> PAGE\_SHIFT); refs = record\_subpages(page, addr, end, pages + \*nr); - folio = try\_grab\_folio(page, refs, flags);+ folio = try\_grab\_folio\_fast(page, refs, flags); if (!folio) return 0; diff --git a/mm/huge\_memory.c b/mm/huge\_memory.cindex 7ac2877e76629b..f2816c9a1f3ec8 100644--- a/[mm/huge\_memory.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/huge_memory.c?id=9eae19001439f5004e1fb189972d929201db29ef)+++ b/[mm/huge\_memory.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/huge_memory.c?id=26273f5f4cf68b29414e403837093408a9c98e1f)@@ -1056,7 +1056,7 @@ struct page \*follow\_devmap\_pmd(struct vm\_area\_struct \*vma, unsigned long addr, if (!\*pgmap) return ERR\_PTR(-EFAULT); page = pfn\_to\_page(pfn);- ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (ret) page = ERR\_PTR(ret); @@ -1214,7 +1214,7 @@ struct page \*follow\_devmap\_pud(struct vm\_area\_struct \*vma, unsigned long addr, return ERR\_PTR(-EFAULT); page = pfn\_to\_page(pfn); - ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (ret) page = ERR\_PTR(ret); @@ -1475,7 +1475,7 @@ struct page \*follow\_trans\_huge\_pmd(struct vm\_area\_struct \*vma, VM\_BUG\_ON\_PAGE((flags & FOLL\_PIN) && PageAnon(page) && !PageAnonExclusive(page), page); - ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags); if (ret) return ERR\_PTR(ret); diff --git a/mm/hugetlb.c b/mm/hugetlb.cindex fb7a531fce7174..0acb04c3e95291 100644--- a/[mm/hugetlb.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/hugetlb.c?id=9eae19001439f5004e1fb189972d929201db29ef)+++ b/[mm/hugetlb.c](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/hugetlb.c?id=26273f5f4cf68b29414e403837093408a9c98e1f)@@ -6532,7 +6532,7 @@ struct page \*hugetlb\_follow\_page\_mask(struct vm\_area\_struct \*vma, \* try\_grab\_page() should always be able to get the page here, \* because we hold the ptl lock and have verified pte\_present(). \*/- ret = try\_grab\_page(page, flags);+ ret = try\_grab\_folio(page\_folio(page), 1, flags);  if (WARN\_ON\_ONCE(ret)) { page = ERR\_PTR(ret);diff --git a/mm/internal.h b/mm/internal.hindex abed947f784b7b..ef8d787a510c5c 100644--- a/[mm/internal.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/internal.h?id=9eae19001439f5004e1fb189972d929201db29ef)+++ b/[mm/internal.h](/pub/scm/linux/kernel/git/stable/linux.git/tree/mm/internal.h?id=26273f5f4cf68b29414e403837093408a9c98e1f)@@ -938,8 +938,8 @@ int migrate\_device\_coherent\_page(struct page \*page); /\* \* mm/gup.c \*/-struct folio \*try\_grab\_folio(struct page \*page, int refs, unsigned int flags);-int \_\_must\_check try\_grab\_page(struct page \*page, unsigned int flags);+int \_\_must\_check try\_grab\_folio(struct folio \*folio, int refs,+ unsigned int flags);  /\* \* mm/huge\_memory.c |
| --- |

generated by [cgit 1.2.3-korg](https://git.zx2c4.com/cgit/about/) ([git 2.43.0](https://git-scm.com/)) at 2025-01-11 08:15:30 +0000


