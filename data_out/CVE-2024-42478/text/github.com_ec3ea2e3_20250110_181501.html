
[Skip to content](#start-of-content)

## Navigation Menu

Toggle navigation

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp%2Fcommit%2Fb72942fac998672a79a1ae3c03b340f7e629980b)

* Product

  + [GitHub Copilot
    Write better code with AI](https://github.com/features/copilot)
  + [Security
    Find and fix vulnerabilities](https://github.com/features/security)
  + [Actions
    Automate any workflow](https://github.com/features/actions)
  + [Codespaces
    Instant dev environments](https://github.com/features/codespaces)
  + [Issues
    Plan and track work](https://github.com/features/issues)
  + [Code Review
    Manage code changes](https://github.com/features/code-review)
  + [Discussions
    Collaborate outside of code](https://github.com/features/discussions)
  + [Code Search
    Find more, search less](https://github.com/features/code-search)

  Explore
  + [All features](https://github.com/features)
  + [Documentation](https://docs.github.com)
  + [GitHub Skills](https://skills.github.com)
  + [Blog](https://github.blog)
* Solutions

  By company size
  + [Enterprises](https://github.com/enterprise)
  + [Small and medium teams](https://github.com/team)
  + [Startups](https://github.com/enterprise/startups)
  By use case
  + [DevSecOps](/solutions/use-case/devsecops)
  + [DevOps](/solutions/use-case/devops)
  + [CI/CD](/solutions/use-case/ci-cd)
  + [View all use cases](/solutions/use-case)

  By industry
  + [Healthcare](/solutions/industry/healthcare)
  + [Financial services](/solutions/industry/financial-services)
  + [Manufacturing](/solutions/industry/manufacturing)
  + [Government](/solutions/industry/government)
  + [View all industries](/solutions/industry)

  [View all solutions](/solutions)
* Resources

  Topics
  + [AI](/resources/articles/ai)
  + [DevOps](/resources/articles/devops)
  + [Security](/resources/articles/security)
  + [Software Development](/resources/articles/software-development)
  + [View all](/resources/articles)

  Explore
  + [Learning Pathways](https://resources.github.com/learn/pathways)
  + [White papers, Ebooks, Webinars](https://resources.github.com)
  + [Customer Stories](https://github.com/customer-stories)
  + [Partners](https://partner.github.com)
  + [Executive Insights](https://github.com/solutions/executive-insights)
* Open Source

  + [GitHub Sponsors
    Fund open source developers](/sponsors)
  + [The ReadME Project
    GitHub community articles](https://github.com/readme)
  Repositories
  + [Topics](https://github.com/topics)
  + [Trending](https://github.com/trending)
  + [Collections](https://github.com/collections)
* Enterprise

  + [Enterprise platform
    AI-powered developer platform](/enterprise)
  Available add-ons
  + [Advanced Security
    Enterprise-grade security features](https://github.com/enterprise/advanced-security)
  + [GitHub Copilot
    Enterprise-grade AI features](/features/copilot#enterprise)
  + [Premium Support
    Enterprise-grade 24/7 support](/premium-support)
* [Pricing](https://github.com/pricing)

Search or jump to...

# Search code, repositories, users, issues, pull requests...

Search

Clear

[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)

# Provide feedback

We read every piece of feedback, and take your input very seriously.

Include my email address so I can be contacted

  Cancel

 Submit feedback

# Saved searches

## Use saved searches to filter your results more quickly

Name

Query

To see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).

  Cancel

 Create saved search

[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp%2Fcommit%2Fb72942fac998672a79a1ae3c03b340f7e629980b)

[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E%2Fvoltron%2Fcommit_fragments%2Frepo_layout&source=header-repo&source_repo=ggerganov%2Fllama.cpp)
Reseting focus

You signed in with another tab or window. Reload to refresh your session.
You signed out in another tab or window. Reload to refresh your session.
You switched accounts on another tab or window. Reload to refresh your session.

Dismiss alert

{{ message }}

[ggerganov](/ggerganov)
/
**[llama.cpp](/ggerganov/llama.cpp)**
Public

* [Notifications](/login?return_to=%2Fggerganov%2Fllama.cpp) You must be signed in to change notification settings
* [Fork
  10.2k](/login?return_to=%2Fggerganov%2Fllama.cpp)
* [Star
   70.5k](/login?return_to=%2Fggerganov%2Fllama.cpp)

* [Code](/ggerganov/llama.cpp)
* [Issues
  268](/ggerganov/llama.cpp/issues)
* [Pull requests
  332](/ggerganov/llama.cpp/pulls)
* [Discussions](/ggerganov/llama.cpp/discussions)
* [Actions](/ggerganov/llama.cpp/actions)
* [Projects
  9](/ggerganov/llama.cpp/projects)
* [Wiki](/ggerganov/llama.cpp/wiki)
* [Security](/ggerganov/llama.cpp/security)
* [Insights](/ggerganov/llama.cpp/pulse)

Additional navigation options

* [Code](/ggerganov/llama.cpp)
* [Issues](/ggerganov/llama.cpp/issues)
* [Pull requests](/ggerganov/llama.cpp/pulls)
* [Discussions](/ggerganov/llama.cpp/discussions)
* [Actions](/ggerganov/llama.cpp/actions)
* [Projects](/ggerganov/llama.cpp/projects)
* [Wiki](/ggerganov/llama.cpp/wiki)
* [Security](/ggerganov/llama.cpp/security)
* [Insights](/ggerganov/llama.cpp/pulse)

## Commit

[Permalink](/ggerganov/llama.cpp/commit/b72942fac998672a79a1ae3c03b340f7e629980b)

This commit does not belong to any branch on this repository, and may belong to a fork outside of the repository.

Merge commit from fork

[Browse files](/ggerganov/llama.cpp/tree/b72942fac998672a79a1ae3c03b340f7e629980b)
Browse the repository at this point in the history

* Loading branch information

[![@ggerganov](https://avatars.githubusercontent.com/u/1991296?s=40&v=4)](/ggerganov)

[ggerganov](/ggerganov/llama.cpp/commits?author=ggerganov "View all commits by ggerganov")
authored
Aug 9, 2024

1 parent
[6afd1a9](/ggerganov/llama.cpp/commit/6afd1a99dc9792096d4567ab9fa1ad530c81c6cd)

commit b72942f

 Show file tree

 Hide file tree

Showing
**4 changed files**
with
**53 additions**
and
**3 deletions**.

* Whitespace
* Ignore whitespace

* Split
* Unified

* examples/rpc

  + examples/rpc/README.md
    [README.md](#diff-46a7790ca3a9ea56ad20cb6035d93aa64a2cda39f1957b9a7d1621be1169bdd7)
  + examples/rpc/rpc-server.cpp
    [rpc-server.cpp](#diff-2acddc36e8e023a85caf88a8373fbc597710cfc596f5b3cebfc38540b986f380)
* ggml/src

  + ggml/src/ggml-rpc.cpp
    [ggml-rpc.cpp](#diff-7c08b9677b00130d85388646c2ed975c2f8b8320845c226b2c24c235f1d19928)
  + ggml/src/ggml.c
    [ggml.c](#diff-f028a352a33ee20b42faca7dcc389e8f0f9c9a55e016cccffed45fe90bcc13f8)

## There are no files selected for viewing

4 changes: 4 additions & 0 deletions

4
[examples/rpc/README.md](#diff-46a7790ca3a9ea56ad20cb6035d93aa64a2cda39f1957b9a7d1621be1169bdd7 "examples/rpc/README.md")

Show comments

[View file](/ggerganov/llama.cpp/blob/b72942fac998672a79a1ae3c03b340f7e629980b/examples/rpc/README.md)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |

|  |  | @@ -1,5 +1,9 @@ |
|  |  | ## Overview |
|  |  |  |
|  |  | > [!IMPORTANT] |
|  |  | > This example and the RPC backend are currently in a proof-of-concept development stage. As such, the functionality is fragile and |
|  |  | > insecure. \*\*Never run the RPC server on an open network or in a sensitive environment!\*\* |
|  |  |  |
|  |  | The `rpc-server` allows running `ggml` backend on a remote host. |
|  |  | The RPC backend communicates with one or several instances of `rpc-server` and offloads computations to them. |
|  |  | This can be used for distributed LLM inference with `llama.cpp` in the following way: |
| Expand Down | |  |

13 changes: 12 additions & 1 deletion

13
[examples/rpc/rpc-server.cpp](#diff-2acddc36e8e023a85caf88a8373fbc597710cfc596f5b3cebfc38540b986f380 "examples/rpc/rpc-server.cpp")

Show comments

[View file](/ggerganov/llama.cpp/blob/b72942fac998672a79a1ae3c03b340f7e629980b/examples/rpc/rpc-server.cpp)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -16,7 +16,7 @@ |
|  |  | #include <stdio.h> |
|  |  |  |
|  |  | struct rpc\_server\_params { |
|  |  | std::string host = "0.0.0.0"; |
|  |  | std::string host = "127.0.0.1"; |
|  |  | int port = 50052; |
|  |  | size\_t backend\_mem = 0; |
|  |  | }; |
| Expand Down  Expand Up | | @@ -114,6 +114,17 @@ int main(int argc, char \* argv[]) { |
|  |  | fprintf(stderr, "Invalid parameters\n"); |
|  |  | return 1; |
|  |  | } |
|  |  |  |
|  |  | if (params.host != "127.0.0.1") { |
|  |  | fprintf(stderr, "\n"); |
|  |  | fprintf(stderr, "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"); |
|  |  | fprintf(stderr, "WARNING: Host ('%s') is != '127.0.0.1'\n", params.host.c\_str()); |
|  |  | fprintf(stderr, " Never expose the RPC server to an open network!\n"); |
|  |  | fprintf(stderr, " This is an experimental feature and is not secure!\n"); |
|  |  | fprintf(stderr, "!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!\n"); |
|  |  | fprintf(stderr, "\n"); |
|  |  | } |
|  |  |  |
|  |  | ggml\_backend\_t backend = create\_backend(); |
|  |  | if (!backend) { |
|  |  | fprintf(stderr, "Failed to create backend\n"); |
| Expand Down | |  |

36 changes: 35 additions & 1 deletion

36
[ggml/src/ggml-rpc.cpp](#diff-7c08b9677b00130d85388646c2ed975c2f8b8320845c226b2c24c235f1d19928 "ggml/src/ggml-rpc.cpp")

Show comments

[View file](/ggerganov/llama.cpp/blob/b72942fac998672a79a1ae3c03b340f7e629980b/ggml/src/ggml-rpc.cpp)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -197,6 +197,10 @@ static std::shared\_ptr<socket\_t> create\_server\_socket(const char \* host, int por |
|  |  | fprintf(stderr, "Failed to set SO\_REUSEADDR\n"); |
|  |  | return nullptr; |
|  |  | } |
|  |  | if (inet\_addr(host) == INADDR\_NONE) { |
|  |  | fprintf(stderr, "Invalid host address: %s\n", host); |
|  |  | return nullptr; |
|  |  | } |
|  |  | struct sockaddr\_in serv\_addr; |
|  |  | serv\_addr.sin\_family = AF\_INET; |
|  |  | serv\_addr.sin\_addr.s\_addr = inet\_addr(host); |
| Expand Down  Expand Up | | @@ -879,6 +883,14 @@ ggml\_tensor \* rpc\_server::deserialize\_tensor(struct ggml\_context \* ctx, const rp |
|  |  | if (result->buffer && buffers.find(result->buffer) == buffers.end()) { |
|  |  | return nullptr; |
|  |  | } |
|  |  |  |
|  |  | // require that the tensor data does not go beyond the buffer end |
|  |  | uint64\_t tensor\_size = (uint64\_t) ggml\_nbytes(result); |
|  |  | uint64\_t buffer\_start = (uint64\_t) ggml\_backend\_buffer\_get\_base(result->buffer); |
|  |  | uint64\_t buffer\_size = (uint64\_t) ggml\_backend\_buffer\_get\_size(result->buffer); |
|  |  | GGML\_ASSERT(tensor->data + tensor\_size >= tensor->data); // check for overflow |
|  |  | GGML\_ASSERT(tensor->data >= buffer\_start && tensor->data + tensor\_size <= buffer\_start + buffer\_size); |
|  |  |  |
|  |  | result->op = (ggml\_op) tensor->op; |
|  |  | for (uint32\_t i = 0; i < GGML\_MAX\_OP\_PARAMS / sizeof(int32\_t); i++) { |
|  |  | result->op\_params[i] = tensor->op\_params[i]; |
| Expand All | | @@ -898,7 +910,7 @@ bool rpc\_server::set\_tensor(const std::vector<uint8\_t> & input) { |
|  |  | const rpc\_tensor \* in\_tensor = (const rpc\_tensor \*)input.data(); |
|  |  | uint64\_t offset; |
|  |  | memcpy(&offset, input.data() + sizeof(rpc\_tensor), sizeof(offset)); |
|  |  | size\_t size = input.size() - sizeof(rpc\_tensor) - sizeof(offset); |
|  |  | const size\_t size = input.size() - sizeof(rpc\_tensor) - sizeof(offset); |
|  |  |  |
|  |  | struct ggml\_init\_params params { |
|  |  | /\*.mem\_size =\*/ ggml\_tensor\_overhead(), |
| Expand All | | @@ -913,6 +925,17 @@ bool rpc\_server::set\_tensor(const std::vector<uint8\_t> & input) { |
|  |  | return false; |
|  |  | } |
|  |  | GGML\_PRINT\_DEBUG("[%s] buffer: %p, data: %p, offset: %" PRIu64 ", size: %zu\n", \_\_func\_\_, (void\*)tensor->buffer, tensor->data, offset, size); |
|  |  |  |
|  |  | // sanitize tensor->data |
|  |  | { |
|  |  | const size\_t p0 = (size\_t) ggml\_backend\_buffer\_get\_base(tensor->buffer); |
|  |  | const size\_t p1 = p0 + ggml\_backend\_buffer\_get\_size(tensor->buffer); |
|  |  |  |
|  |  | if (in\_tensor->data + offset < p0 || in\_tensor->data + offset >= p1 || size > (p1 - in\_tensor->data - offset)) { |
|  |  | GGML\_ABORT("[%s] tensor->data out of bounds\n", \_\_func\_\_); |
|  |  | } |
|  |  | } |
|  |  |  |
|  |  | const void \* data = input.data() + sizeof(rpc\_tensor) + sizeof(offset); |
|  |  | ggml\_backend\_tensor\_set(tensor, data, offset, size); |
|  |  | ggml\_free(ctx); |
| Expand Down  Expand Up | | @@ -943,6 +966,17 @@ bool rpc\_server::get\_tensor(const std::vector<uint8\_t> & input, std::vector<uint |
|  |  | return false; |
|  |  | } |
|  |  | GGML\_PRINT\_DEBUG("[%s] buffer: %p, data: %p, offset: %" PRIu64 ", size: %" PRIu64 "\n", \_\_func\_\_, (void\*)tensor->buffer, tensor->data, offset, size); |
|  |  |  |
|  |  | // sanitize tensor->data |
|  |  | { |
|  |  | const size\_t p0 = (size\_t) ggml\_backend\_buffer\_get\_base(tensor->buffer); |
|  |  | const size\_t p1 = p0 + ggml\_backend\_buffer\_get\_size(tensor->buffer); |
|  |  |  |
|  |  | if (in\_tensor->data + offset < p0 || in\_tensor->data + offset >= p1 || size > (p1 - in\_tensor->data - offset)) { |
|  |  | GGML\_ABORT("[%s] tensor->data out of bounds\n", \_\_func\_\_); |
|  |  | } |
|  |  | } |
|  |  |  |
|  |  | // output serialization format: | data (size bytes) | |
|  |  | output.resize(size, 0); |
|  |  | ggml\_backend\_tensor\_get(tensor, output.data(), offset, size); |
| Expand Down | |  |

3 changes: 2 additions & 1 deletion

3
[ggml/src/ggml.c](#diff-f028a352a33ee20b42faca7dcc389e8f0f9c9a55e016cccffed45fe90bcc13f8 "ggml/src/ggml.c")

Show comments

[View file](/ggerganov/llama.cpp/blob/b72942fac998672a79a1ae3c03b340f7e629980b/ggml/src/ggml.c)
Edit file

Delete file

This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters.
[Learn more about bidirectional Unicode characters](https://github.co/hiddenchars)

  [Show hidden characters](%7B%7B%20revealButtonHref%20%7D%7D)

| Original file line number | Diff line number | Diff line change |
| --- | --- | --- |
| Expand Up | | @@ -3724,7 +3724,8 @@ static struct ggml\_tensor \* ggml\_new\_tensor\_impl( |
|  |  | struct ggml\_tensor \* view\_src, |
|  |  | size\_t view\_offs) { |
|  |  |  |
|  |  | assert(n\_dims >= 1 && n\_dims <= GGML\_MAX\_DIMS); |
|  |  | GGML\_ASSERT(type >= 0 && type < GGML\_TYPE\_COUNT); |
|  |  | GGML\_ASSERT(n\_dims >= 1 && n\_dims <= GGML\_MAX\_DIMS); |
|  |  |  |
|  |  | // find the base tensor and absolute offset |
|  |  | if (view\_src != NULL && view\_src->view\_src != NULL) { |
| Expand Down | |  |

Toggle all file notes
Toggle all file annotations

### 0 comments on commit `b72942f`

Please
[sign in](/login?return_to=https%3A%2F%2Fgithub.com%2Fggerganov%2Fllama.cpp%2Fcommit%2Fb72942fac998672a79a1ae3c03b340f7e629980b) to comment.

## Footer

© 2025 GitHub, Inc.

### Footer navigation

* [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)
* [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)
* [Security](https://github.com/security)
* [Status](https://www.githubstatus.com/)
* [Docs](https://docs.github.com/)
* [Contact](https://support.github.com?tags=dotcom-footer)
* Manage cookies
* Do not share my personal information

You can’t perform that action at this time.

